organizations:
  - organization_id: 1
    organization_name: 52°North Spatial Information Research GmbH
    no_of_ideas: 3
    ideas_content: |
                1. KomMonitor
                Angular migration of the KomMonitor Web Client
                Explanation
                KomMonitor is a web based tool that combines methods of GIS (Geographic information System) and statistical data and helps in providing a simpler and easier way to monitor geo-spatial data. Many municipalities have established KomMonitor to address a wide range of challenges in fields such as urban planning, environmental management, and disaster response. The current version of the KomMonitor Web Client has been developed using AngularJS, which has served as a reliable foundation for its functionalities. However, AngularJS has been deprecated for some years now. Therefore, relying on the current code base has several potential drawbacks associated with using AngularJS, such as compatibility issues, limited community support, reduced performance, and version support. To overcome these challenges and take KomMonitor to the next level, it is necessary to adopt the KomMonitor Web Client to the more modern and widely-supported framework Angular. As part of GSoC 2023, essential work has been done by developing a general approach for the Angular migration. The Web Client has been restructured so that it can be deployed as a hybrid web application, which runs both legacy AngularJS components and migrated or new Angular components. This year, the project aims to continue the migration tasks. Hence, the goal of this project is to reimplement several selected components of the KomMonitor Web Client by using the Angular framework.

                Expected Results
                As a result of the project, it is expected that several selected components of the KomMonitor Web Client will have been reimplemented with the Angular framework. The resulting UI of the reimplemented components should be as close as possible to the previous design to preserve the current look&feel. As an additional requirement, the reimplementation should take into account best practices and common design patterns in Angular. This results in also restructuring some of the existing components rather than simply transferring a component from AngularJS to Angular. Finally, the hybrid Web Client, including legacy AngularJS components and new Angular components side-by-side, should run properly without any bugs.

                Code Challenge
                Migrate the kommonitorToastHelperService of the KomMonitor Web Client to Angular and make use of it in a new Angular component as part of the Web Client. Follow the steps below:

                Create a fork of https://github.com/KomMonitor/web-client and checkout the GSoC2025 Branch
                Create a new Angular service as part of the KomMonitor Web Client that provides the same functionality as the existing AngularJS version of the kommonitorToastHelperService
                Create a new Angular component that makes use of the previously implemented kommonitorToastHelperService. Take into account these requirements:
                The component should be opened and closed by clicking on a button on the left sidebar.
                The component should include a text area and a button.
                The required functionality should be to display a message as toast on the screen by filling the text area and clicking on the button. For this purpose the kommonitorToastHelperService should be used.
                Push the code to your fork at GitHub
                Link to the fork within your official GSoC application. Your GSoC application should also include a description of which components you plan to migrate during GSoC as well as an estimation of time required for implementing it.


                Community and Code License
                Apache Software License, Version 2

                Mentors
                Sebastian Drost (s.drost @52north.org), Christoph Wagner (c.wagner @52north.org)

                Project Duration
                The duration of the project is estimated at 175 hours. An extension is possible.

                Chat
                TBD

                ~~~~~~~~~~

                2. LLM and GeoData
                Explanation
                During 52°North’s Student Innovation Challenge in 2024, a first open-source implementation connecting spatial data and Large Language Models (LLM) was developed.

                The ambition was to address the pain points of searchability in Research and Spatial Data Infrastructures (RDI/SDI). Search functionality in such systems is typically limited to a metadata-based approach. However, geospatial data – whether vector or raster based – provides a wealth of interesting data that can currently only be identified by looking at the individual dataset. The challenge of the 2024 Student Innovation Prize was to develop a concept and a possible implementation that allows searching within datasets of/and RDI/SDI, e.g. on the attribute level. There are many interesting aspects related to this challenge: technical solutions, taxonomies and semantics, language/i18n, searching in raster data, and many more such as LLMs.

                The available Proof of Concept (PoC) features a prompt that makes it easier to search and access to spatial data. More user stories are documented in the Innovation Prize project backlog on GitHub: https://github.com/52North/innovation-prize.

                Expected Results
                The PoC should be hardened and developed beyond its current state. For example, less verbose prompts are needed as more sophisticated LLMs emerge. Also, improved software frameworks may provide a better development experience. Various extensions are possible and a selection should be outlined in the proposal. Additional user stories from the backlog in the github project (see above) could be addressed. Another interesting extension could also entail a federated architecture. Furthermore, the use of different LLMs is also a possible option for further development.

                Code Challenge
                Set up the entire working environment based on the existing open source code

                https://github.com/52North/innovation-prize/tree/2024

                and add two more data sets. Share the code and the deployed system.

                Community and Code License
                TBChecked: Apache Software License, Version 2

                Mentors
                Henning Bredel (h.bredel @52north.org), Simeon Wetzel

                Project duration
                The duration of the project is estimated at 175 hours. An extension is possible.

                ~~~~~~~~~~

                3. Weather Routing Tool
                Explanation
                The open-source 52°North Weather Routing Tool (WRT) was initially developed during the MariData project. It provides means to find an optimal ship route that minimizes fuel consumption under varying weather conditions. In the optimization process, several constraints can be integrated, e.g. water depth and traffic separation zones. Currently, there are two algorithms available: an isofuel algorithm and a genetic algorithm. Details of the MariData project and example applications of the Weather Routing Tool can be found in the following publication: https://proceedings.open.tudelft.nl/imdc24/article/view/875.

                Expected Results
                The Weather Routing Tool should be extended by new features and its robustness should be improved. There are three major directions of possible developments:

                Ship speed optimization
                Currently, only the geometry of the route is optimized while the ship speed is assumed to be constant. To cover a broader range of real-world use cases, the Weather Routing Tool should provide the option to optimize ship speed. This could be along a fixed route or simultaneous with the route geometry.
                Genetic algorithm
                The implementation of the genetic algorithm is still very basic. Possible improvements include the generation of the initial population and the strategies for crossover and mutation. Moreover, a multi-objective optimization could be implemented.
                General consumption model
                An important aspect of the Weather Routing Tool is the underlying (fuel) consumption model. The best results can generally be obtained by using a consumption model which is developed specifically for a ship, e.g. based on hydrodynamic modeling or machine learning models. However, developing such specific models is cumbersome and restricts the applicability of the tool. Thus, having a general consumption model which only requires a few characteristics of a ship (e.g. type of vessel, length, breadth, displacement) would be a great improvement. The model should have reasonable accuracy. As this feature includes research aspects and can only be successfully developed with the necessary background knowledge, interested candidates have to provide a clear plan of their approach.
                The features can be implemented in different ways. How they are implemented is up to the candidate and might include deterministic, machine learning or AI methods.

                Code Challenge
                New ship class:

                Implement a new ship class
                It should inherit from the Boat base class
                The get_ship_parameters method has to be implemented; it should return a “synthetic” fuel rate which depends on at least one environmental parameter (e.g. wave height)
                Make sure the fuel rates (kg per second) are within a reasonable value range. Besides the weather conditions, typical fuel rates also depend on the ship size, type (e.g. container ship, tanker, fishing vessel) and speed.
                The choice of the considered environmental parameters and the type of the function is free
                You can take the ConstantFuelBoat class as an example
                Prepare weather conditions
                Options:
                Create your own synthetic weather conditions
                Download actual historical or forecast data from public portals (Copernicus, NOAA, …). You can use the Python package maridatadownloader directly or indirectly by setting “DATA_MODE” to “automatic“.
                Run the Weather Routing Tool with your new ship class and a route of your free choice
                Hint: because the Python package mariPower is not publicly available, you need to comment or delete the corresponding lines in ship.py.
                Configuration:
                Set “ALGORITHM_TYPE” to “isofuel”
                Provide the expected results for review
                Mandatory:
                Final route as GeoJSON file
                Python code of new ship class
                Optional:
                Log file (info.log)
                Snapshots of routing steps (WRT_FIGURE_PATH)
                Used weather data
                Community and Code License
                MIT License

                Mentors
                Martin Pontius (m.pontius @52north.org), Katharina Demmich (k.demmich @52north.org)

                Project Duration
                The duration of the project is estimated at 175 hours. An extension is possible.

                TBD

                Cloud Native OGC SensorThings API 2
                enviroCar
    totalCharacters_of_ideas_content_parent: 10019
    totalwords_of_ideas_content_parent: 1397
    totalTokenCount_of_ideas_content_parent: 2059
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/52north-spatial-information-research-gmbh/
    idea_list_url: https://52north.org/outreach-dissemination/google-summer-of-code/project-ideas/


  - organization_id: 2
    organization_name: AFLplusplus
    no_of_ideas: 4
    ideas_content: |
      Proposal 1: Tool for Automated generic/bounds simplification
        Create a (general, not LibAFL-specific) rust tool to simplify/minimze bounds

        Description
        As commented by many users and maintainers of LibAFL, our codebase is absolutely full of complicated generics. We use these to allow for structured and statically-checked compatibility between various components provided in our codebase, and is a critical part of how LibAFL is structured.

        Unfortunately, these can be very difficult to maintain. Our goal is to develop a tool capable of assisting developers in this maintenance process.

        Please check out issue #2868 for more details.

        Expected Outcomes
        A tool that works on any rust code, tries to minimize the used bounds, and fixes the code

        Skills Expected
        Rust
        A good understanding of Generics and the Rust Type system
        Possible Mentors
        @addisoncrump
        @tokatoka
        Expected size of the project
        The project is expected to take either 175 or 350 hours.

        Difficulty Rating
        The overall difficulty of this project is expected to be medium.
        ~~~~~~~~~~
        Proposal 2: Adapt qemuafl Frontend to LibAFL QEMU
        The project consists of adapting the frontend of qemuafl, the AFL++'s QEMU fork, with LibAFL QEMU.

        Description
        The end goal of this project would be to run fuzzers built for qemuafl while using LibAFL QEMU as the backend, in a retrocompatible way.
        A draft PR is already available and can be used as a starting point by the student.
        Ideally, the student would measure the performance (in terms of exec/s and coverage) of the new qemuafl adaptation with some fuzzers to evaluate how the final implementation compares with the reference.

        Expected Outcomes
        In short, we expect the student to make the new frontend work for most fuzzers developed for qemuafl while maintaining (at least) similar performance.

        See #1983 for an initial implementation that still lacks features.

        The main tasks the student would have to perform are the following:

        Speak the AFL++ forkserver protocol (check the draft PR).
        Add TCG caching to the LibAFL QEMU forkserver
        Use LibAFL QEMU snapshots where possible
        Add as many env variable features as possible
        Skills Expected
        We expect the student to:

        have a strong background in the Rust and C languages.
        be familiar with fuzzing.
        ideally, have some experience using AFL++ and / or LibAFL.
        ideally, have prior experience with the QEMU project.
        Possible Mentors
        The possible mentors for this project are:

        @domenukk
        @rmalmain
        Expected size of the project
        The project is expected to take either 175 or 350 hours.

        Difficulty Rating
        The overall difficulty of this project is expected to be medium.

        Original post
        This proposition is mostly an adaptation of issue #2964.
        ~~~~~~~~~~
        Proposal 3: Network Emulation for LibAFL_QEMU
        Implement syscall emulation for filesystem and network in libafl_qemu.

        Description
        The student must implement something similar to preeny and FitM to hook the network API and an emulator filesystem that can be snapshot-restored always hooking the syscall in libafl_qemu user mode

        Expected Outcomes
        A working network emulation layer for LibAFL_QEMU

        Required Skills
        Good understanding of Rust, C, system programming
        Ideally: prior knowledge in emulators and fuzzing
        Difficulty Rating
        The overall difficulty of this project is expected to be medium.

        Possible mentors
        @domenukk
        @rmalmain
        Expected size of the project
        The project is expected to take either 175 or 350 hours, depending on details
        ~~~~~~~~~~
        Proposal 4: Remote Worker Stage
        Mutations and execution of a Stage is always on the machine LibAFL runs at. For very slow targets it may be beneficial to offload the actual executions to stateless worker.

        Description
        We could add a RemoteWorkerLauncherStage that builds n work packages, each including a next scheduled corpus entry, all metadata for this Testcase, the current feedback state, as well as additional random corpus entries for splicing.
        The work package should then be posted to Redis or some other queue db (very much like celery, whatever a rust alternative is).
        After the execution, the results should be collected in an extra stage

        Expected Outcome:
        The implementation and a set of working examples, including:
        LibAFL Workers / RemoteWorkerLauncherStage + RemoteWorkerCollectorStage

        Required Skills
        Rust
        Prior knowledge in distributed computing and/or fuzzing are a plus
        Difficulty Rating
        easy to medium

        Possible mentors
        @domenukk
        @tokatoka
        @addisoncrump
        Length
        175 hours
    totalCharacters_of_ideas_content_parent: 4418
    totalwords_of_ideas_content_parent: 600
    totalTokenCount_of_ideas_content_parent: 1003
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/aflplusplus/
    idea_list_url: https://github.com/AFLplusplus/LibAFL/issues/2992

  - organization_id: 3
    organization_name: AOSSIE
    no_of_ideas: 13
    ideas_content: |
      Agora Blockchain
        Project Type: Medium
        Description:
        Agora Blockchain is a decentralized voting platform designed to enhance electoral integrity and accessibility. It enables transparent, tamper-proof voting through smart contracts, leveraging Chainlink CCIP for cross-chain functionality. Agora ensures fair participation and trust in election results by eliminating centralized control and providing a verifiable, immutable ledger of votes.

        Key features include:

        Multi-algorithm voting: Supports different voting mechanisms like ranked choice, quadratic voting, and stake-based voting.
        Cross-chain voting: Uses Chainlink CCIP to enable voting across multiple blockchains.
        Gas-efficient smart contracts: Optimized Solidity contracts reduce transaction costs.
        Decentralized governance: Community-driven elections and decision-making.
        User-friendly interface: Built with Next.js, Wagmi, and MetaMask for seamless interaction.
        Expected Outcomes:
        Smart Contract Enhancements:

        Implement private elections for confidential voting.
        Further optimize election factory contracts for gas efficiency.
        Cross-Chain Expansion:

        Extend Chainlink CCIP integration to support multiple blockchains.
        Frontend & dApp Integration:

        Build an intuitive UI using Next.js and Wagmi.
        Ensure smooth wallet connectivity and real-time vote updates.
        Analytics & Insights:

        Develop a real-time dashboard for election statistics.
        Track voter participation and engagement metrics.
        Required Skills:
        Solidity
        Hardhat
        Chainlink CCIP
        Next.js
        MetaMask
        Wagmi
        TailwindCSS
        Zustand
        Mentors:
        Ronnie

        ~~~~~~~~~~

        BabyNest
        Project Type: Large
        Description:
        Pregnancy is a life-changing journey filled with crucial medical appointments, tests, and healthcare decisions. However, expecting parents often struggle to keep track of these milestones, which can lead to missed appointments and added stress. Studies show that adherence to prenatal checkups directly impacts pregnancy outcomes, yet there is no universally accessible tool to assist parents in navigating healthcare requirements based on their country and trimester.

        BabyNest is designed to solve this problem through a minimalist React Native app integrated with an AI-powered assistant. This intelligent assistant acts as a personal pregnancy planner and guide, ensuring that expecting parents stay informed, organized, and stress-free.

        Users can benefit from features such as:

        Automated tracking of trimester-specific medical appointments
        Country-specific healthcare requirement notifications
        Offline access to pregnancy care guidelines
        AI-powered personalized recommendations and reminders
        Expected Outcomes:

        Mobile application built with React Native for cross-platform support
        AI agent integration for intelligent pregnancy milestone scheduling, reminders and tracking
        Offline-first architecture with local storage of healthcare guidelines
        Required Skills:

        Frontend Development (React Native)
        Backend Development (Node.js, FastAPI)
        AI and NLP (Python, LangChain)
        Database Management (SQLite, Pinecone)
        Mentors: Bhavik Mangla

        ~~~~~~~~~~
        DebateAI
        Project Type: Large
        Description:
        DebateAI is an interactive, AI-enhanced debate game platform designed to improve users communication skills through structured competitive debates. Users can engage in real-time debates against both human opponents and AI-driven challengers on a wide range of real-world topics. The platform mimics formal debate competition structures, making it an effective practice and competitive tool.

        Expected Outcomes:
        User vs. User Debates:

        Real-time interaction using WebSockets and WebRTC for audio, video, and text communication.
        Structured debate formats with timed rounds, including opening statements, rebuttals, cross-examinations, and closing arguments.
        User vs. AI Debates:

        AI-driven opponents using LLMs to generate realistic counterarguments and adapt to user inputs.
        User Management and Profiles:

        Secure authentication and access control.
        Personal dashboards to track debate history and manage settings.
        Elo rating system for matchmaking and ranking users.
        Custom Debate Spaces:

        Users can create private rooms to debate on topics of their choice.
        Platform Enhancement & Codebase Refactoring:

        Refactor the existing codebase for better maintainability, scalability, and performance.
        Improve real-time communication efficiency and backend services.
        Required Skills:
        ReactJS
        TypeScript
        GoLang
        Python
        Databases
        LLMs
        Mentors:
        Bruno Keshav


        ~~~~~~~~~~
        Devr.AI
        Project Type: Large
        Description:
        Devr.AI is an AI-powered Developer Relations (DevRel) assistant designed to seamlessly integrate with open-source communities across platforms like Discord, Slack, GitHub, and Discourse. It acts as a virtual DevRel advocate, helping maintainers engage with contributors, onboard new developers, and provide real-time project updates.

        By leveraging LLMs, knowledge retrieval, and workflow automation, the assistant enhances community engagement, simplifies contributor onboarding, and ensures open-source projects remain active and well-supported.

        Expected Outcomes:
        AI-Driven Contributor Engagement

        Automates interactions, welcomes new contributors, and guides them through onboarding.
        Automated Issue Triage & PR Assistance

        Helps maintainers prioritize issues and assists contributors in resolving them efficiently.
        Knowledge Base & FAQ Automation

        Provides instant answers to common queries, reducing repetitive maintainer workload.
        AI-Powered Community Analytics

        Tracks engagement metrics, identifies active contributors, and generates insights.
        Required Skills:
        GenAI
        Supabase
        FastAPI
        Integrations:
        Discord
        Slack
        GitHub
        Mentors:
        Chandan


        ~~~~~~~~~~
        DocPilot
        Project Type: Large
        Description:
        Build a new age EMR application using conversational AI at its best. Existing EMR solutioning is Age-old! Doctors resist the overwhelming software which is high on costs and difficult to operate. Last innovation was made in 1990's. DocPilot listens to the whole consultation conversation between a doctor and patient, and generates a prescription for the doctor to just sign, print and save digitally.

        The app should be able to separate out things like symptoms, diagnosis, medications and tests from the conversation it listens to. These are just the basic requirements. Research more on OPD appointments and include them in our solutioning.

        Expected Outcomes:
        Conversational AI-powered EMR that listens and auto-generates prescriptions.
        Eliminates outdated, complex, and costly software for doctors.
        Affordable and easy to use, reducing resistance from medical professionals.
        Extracts symptoms, diagnosis, medications, and tests from conversations.
        Allows doctors to review, sign, print, and save prescriptions digitally.
        Integrates OPD appointment management for a seamless experience.
        A modern solution replacing decades-old EMR systems.
        Required Skills:
        Flutter
        AI
        Appwrite
        Mentors:
        Jaideep

        ~~~~~~~~~~

        EduAid
        Project Type: Medium
        Description:
        EduAid is an AI-driven tool designed to enhance online learning by generating quizzes from educational content, helping students improve retention and engagement. Currently available as a browser extension, we aim to expand it into a full-fledged platform with a website, optimized model pipelines, and better system performance.

        Our current model supports difficulty-controlled quizzes for short-answer and multiple-choice questions (MCQs). We plan to extend this functionality to other formats, including fill-in-the-blanks, boolean, and match-the-following, by improving our models for diverse question generation. Additionally, we seek to integrate EduAid with other educational platforms to make it a seamless part of the learning ecosystem.

        Expected Outcomes:
        Fully deploy the EduAid browser extension and website.
        Optimize model pipelines for better accuracy and response time.
        Improve system performance for a smoother user experience.
        Expand difficulty-controlled question generation to new formats.
        Enhance UI/UX for better usability.
        Integrate with other educational platforms for wider adoption.
        Required Skills:
        Frontend Development
        Backend Development
        PyTorch & NLP
        System Design & Architecture
        Mentors:
        Aditya Dubey


        ~~~~~~~~~~
        Ell-ena
        Project Type: Large
        Description:
        Ell-ena is an AI-powered product manager that automates task management by creating to-do items, tickets, and transcribing meetings while maintaining full work context. It is input-agnostic and features a chat interface where users can interact naturally.

        Users can ask Ell-ena to perform tasks such as:

        Create a ticket to work on the dark mode feature.
        Add a to-do list item for my math assignment.
        The AI understands the context and adds relevant details automatically. Advanced algorithms like Graph RAG can be leveraged for efficient context retrieval and decision-making.

        Expected Outcomes:
        AI-powered system that generates tasks, tickets, and meeting transcriptions.
        Seamless chat-based interface for intuitive user interactions.
        Context-aware automation to enrich task details automatically.
        Implementation of Graph RAG or similar techniques for intelligent processing.
        Scalable backend to support real-time task creation and management.
        Required Skills:
        ReactJS / NextJS
        NodeJS / Any backend tech stack
        AI / NLP
        Graph RAG
        Mentors:
        Jaideep


        ~~~~~~~~~~

        Inpact
        Project Type: Large
        Description:
        Inpact is an AI-powered creator collaboration and sponsorship matchmaking platform designed to connect content creators, brands, and agencies through data-driven insights. This open-source platform enables influencers to discover relevant sponsorship deals, collaborate with like-minded creators, and optimize brand partnerships.

        By leveraging GenAI, audience analytics, and engagement metrics, Inpact ensures highly relevant sponsorship opportunities for creators while maximizing ROI for brands investing in influencer marketing.

        Expected Outcomes:
        AI-Driven Sponsorship Matchmaking

        Automatically connects creators with brands based on audience demographics, engagement rates, and content style.
        AI-Powered Creator Collaboration Hub

        Facilitates partnerships between creators with complementary audiences and content niches.
        AI-Based Pricing & Deal Optimization

        Provides fair sponsorship pricing recommendations based on engagement, market trends, and historical data.
        AI-Powered Negotiation & Contract Assistant

        Assists in structuring deals, generating contracts, and optimizing terms using AI insights.
        Performance Analytics & ROI Tracking

        Enables brands and creators to track sponsorship performance, audience engagement, and campaign success.
        Required Skills:
        ReactJS
        GenAI
        Supabase
        FastAPI
        Mentors:
        Chandan

        ~~~~~~~~~~
        Monumento
        Project Type: Large
        Description:
        Monumento is an AR-integrated social app that transforms how you connect with the world’s most iconic landmarks. Through Monumento, you can check in to popular monuments, explore famous sites, and discover new people, all within a social platform dedicated to cultural and historical experiences. Whether you're a traveler or a history enthusiast, Monumento offers an immersive way to engage with the world’s most treasured locations.

        Expected Outcomes:
        Improved UI responsiveness

        Improve the app's responsiveness across different devices and screen sizes.
        Ensure a seamless user experience on various platforms.
        Better social system

        Improve the social aspect of the app by improving the feed and user profiles and the ability to interact with other users.
        Introduce new features like events, communities to keep users engaged
        Make Popular Monumnets Dynamic

        Introduce a dynamic system where popular monuments can be updated with new information and images by the users.
        Allow users to add new monuments to the app and make them available for users to check in to.
        Itineray

        Introduce a itinerary feature to help users plan their trips and discover new places.
        Allow users to save their favorite monuments and create personalized itineraries.
        Required Skills:
        Flutter
        Appwrite/Pocketbase/Supabase
        Generative AI
        ARCore/ARKit
        UI/UX Design
        Mentor:
        Mohammed Mohsin

        ~~~~~~~~~~

        Neurotrack
        Project Type: Medium
        Description:
        Neurotrack is an AI-powered platform designed for schools and therapy centers to detect, assess, and manage neurodevelopmental conditions like Autism, ADHD, and learning difficulties. By automating assessments, personalized education plans, and therapy tracking, it empowers educators, therapists, and parents to provide more effective, data-driven support.

        Expected Outcomes:
        AI-Powered Student Grouping

        Identifies patterns and groups students with similar needs for tailored interventions.
        Automated Individualized Education Plans (IEPs)

        Creates personalized learning strategies with AI-driven recommendations.
        Digital Assessments

        Conducts efficient, research-backed evaluations to track progress.
        Real-Time Reports & Insights

        Provides actionable data for educators, therapists, and parents.
        Comprehensive Therapy Tracking

        Logs sessions, progress, and improvements over time.
        Parent Support Assistant

        AI-driven chat support for guidance and resource recommendations.
        Seamless Scheduling

        Simplifies session planning for educators and therapists.
        Required Skills:
        GenAI
        Supabase/Appwrite
        Flutter
        Mentors:
        Mohsin
        ~~~~~~~~~~
        Perspective
        Project Type: Large
        Description:
        In today's digital landscape, personalized content algorithms and social media feeds often create echo chambers of various news and different perspectives and narratives. Users are repeatedly exposed to viewpoints confirming their beliefs. This reinforcement of confirmation bias leads to increased polarization and limits critical thinking.

        The Perspective app tackles the issue of echo chambers and confirmation bias by actively presenting users with well-researched, alternative viewpoints alongside their regularly consumed content. It analyzes the current narrative of a news article, social media post, or online discussion, then curates counterarguments from credible sources. This exposure encourages critical evaluation and helps users see beyond the single perspective they might be constantly fed, ultimately fostering a more balanced and nuanced understanding of complex facts. You don't need to rely on truncated news, get complete facts.

        Users can benefit from features such as:

        Counter-perspective: Instantly see counterarguments and narration of why other perspective.
        Reasoned Thinking: The tool will provide a counter-narrative of the same fact with strongly connected facts.
        Updated Facts: With the help of context-aware LLMs, we will provide the latest facts and counter-facts.
        Seamless Integration: Works with news, blogs, and social media applications.
        Real-Time Analysis: You don't need to wait for any author, make Perspective your companion for immediate insights as you browse.
        Expected Outcomes:

        Less Bias in narratives: Break out of echo chambers.
        Wider Perspectives: Broaden your understanding of the news you are watching.
        Better Discourse: More balanced discussions.
        Sharper Analysis: Improved critical thinking and decreased your mind's polarisation.
        Required Skills:

        Frontend Development (ReactJS)
        Backend Development (Python, FastAPI)
        AI and NLP (Python, LangChain, Langgraph, Prompt Engineering)
        Database Management (Any VectorDB)
        Mentors: Manav Sarkar

        ~~~~~~~~~~

        Pictopy
        Project Type: Medium
        Description:
        Pictopy is currently built using Tauri, relying on Rust, but it comes with platform-specific dependencies that make it difficult to containerize and ship. Electron has been considered as an alternative, but issues with rendering local machine photos and bypassing security have caused challenges in the past. This has led to difficulty in onboarding new contributors as many give up during the setup process, resulting in fewer active contributors.

        The backend has been stable but stagnant and could use refactoring and design enhancements to improve its growth and functionality. While the backend is working without issues, there is potential for improvement and future scaling.

        Expected Outcomes:
        Rework the frontend to explore other options that can simplify setup and containerization.
        Address issues related to Electron, including photo rendering and security bypassing.
        Increase contributions from new developers by simplifying the setup process.
        Refactor and enhance the backend for better growth and scalability.
        Provide design improvements to the backend for smoother development and future expansions.
        Required Skills:
        Rust
        Electron
        Backend Development
        Frontend Development
        Mentors:
        Pranav Aggarwal
        ~~~~~~~~~~
        Resonate
        Project Type: Medium
        Description:
        Resonate is an open-source social voice platform designed to enable real-time audio interactions, storytelling, and voice-based social networking. The project is built with a strong focus on open collaboration, accessibility, and innovation in voice communication. Whether it's live discussions, pair chats, or immersive story experiences, Resonate is designed to put voice at the center of social engagement.

        Expected Outcomes:
        Expanded Audio Story Marketplace

        Develop a fully-fledged marketplace for audio stories, allowing users to create, browse, and follow creators.
        Implement profile pages with a follower system, showcasing user content and social interactions.
        User & Creator Search Functionality

        Enhance the explore page by adding user search functionality.
        Enable users to follow creators, view their profiles, and stay updated on their latest audio stories.
        Friend System for Personal Communication

        Implement a friend request and acceptance system.
        Enable direct personal chats and voice calls between friends.
        Improved Pair Chat Experience

        Introduce a lobby system where users can see the number of people waiting before joining a pair chat.
        Improve UI/UX to enhance user engagement and interaction.
        Required Skills:
        Flutter
        Appwrite
        LiveKit
        WebRTC
        UI/UX Design
        Mentor:
        Aarush Acharya
    totalCharacters_of_ideas_content_parent: 17886
    totalwords_of_ideas_content_parent: 2039
    totalTokenCount_of_ideas_content_parent: 3492
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/aossie/
    idea_list_url: https://aossie.org/ideas

  
  - organization_id: 4
    organization_name: API Dash
    no_of_ideas: 10
    ideas_content: |

          1. DashBot
          Related Issue - #621

          Develop DashBot - the AI assistant for API Dash which supercharges developer productivity by helping developers automate tedious tasks, follow best practices, interact & obtain contextual suggestions, all via natural-language input. DashBot must be designed in a modular and extensible manner and provide the following list of features (suggestive, not exhaustive):

          Explain responses & identify any discrepancy
          Debug requests based on Status codes & Error messages
          Generate API documentation
          Understand API and generate tests
          Generate plots & visualizations for API responses along with ability to customize
          Generate API integration frontend code for frontend frameworks like React, Flutter, etc.
          For each of the tasks you are also required to prepare benchmark evaluations so that it is easier for end users to choose the right backend LLM.

          Skills: AI, Agent, LLM Evaluation, Testing, Python, Dart, Flutter
          Difficulty: Medium-High
          Length: 175 hours

          ~~~~~~~~~~

          2. AI Agent for API Testing & Tool Generation
          Related Issue - #620

          Develop an AI Agent which leverages the power of Large Language Models (LLMs) to automate and enhance the process of testing APIs. Also, simplify the process of converting APIs into structured tool definitions to enable seamless integration with popular AI agent frameworks like crewAI, smolagents, pydantic-ai, langgraph, etc.

          Traditional API testing involves manually crafting requests, validating responses, and writing test cases. However, AI Agents can significantly streamline this process by generating test cases, validating API responses against expected outputs, and even suggesting improvements based on API documentation. Developers can describe test scenarios in natural language, and the agent can automatically generates API requests, parameter variations, and edge cases. It can also interpret API responses, checking for correctness, consistency, and performance benchmarks. This reduces manual effort while increasing coverage and efficiency, making API testing smarter and more efficient.

          You are also required to prepare benchmark dataset & evaluations so that the right backend LLM can be selected for the end user.

          Skills: AI, Agent, LLM Evaluation, Testing, Python, Dart, Flutter
          Difficulty: Medium-High
          Length: 175 hours

          ~~~~~~~~~~

          3. API Explorer
          Related Issue - #619

          This project is designed to enhance the API Dash user experience by integrating a curated library of popular and publicly available APIs. This feature allows users to discover, browse, search, and directly import API endpoints into their workspace for seamless testing and exploration. Developers can access pre-configured API request templates, complete with authentication details, sample payloads, and expected responses. This eliminates the need to manually set up API requests, reducing onboarding time and improving efficiency. APIs spanning various domains—such as AI, finance, weather, and social media—are organized into categories, making it easy for users to find relevant services. You are required to develop the entire process backend in the form of an automation pipeline which parses OpenAPI/HTML files, auto-tag it to relevant category, enrich the data, create templates. You can also add features such as user ratings, reviews, and community contributions (via GitHub) to ensure accurate and up-to-date resources.

          Skills: UX Design, OpenAPI, Automation, Dart, Flutter
          Difficulty: Low-Medium
          Length: 175 hours

          ~~~~~~~~~~

          4. AI API Eval Framework
          Related Issue - #618

          Develop an end-to-end AI API eval framework and integrate it in API Dash. This framework should (list is suggestive, not exhaustive):

          Provide an intuitive interface for configuring API requests, where users can input test datasets, configure request parameters, and send queries to various AI API services
          Support evaluation AI APIs (text, multimedia, etc) across various industry task benchmarks
          Allow users to add custom dataset/benchmark & criteria for evaluation. This custom scoring mechanisms allow tailored evaluations based on specific project needs
          Visualize the results of API eval via tables, charts, and graphs, making it easy to identify trends, outliers, and performance variations
          Allow execution of batch evaluations
          Work with both offline & online models and datasets
          Skills: AI, Evaluations, Dart, Python, Flutter
          Difficulty: Medium-High
          Length: 175 hours

          ~~~~~~~~~~

          5. API Testing Support for - WebSocket, SSE, MQTT & gRPC
          Related Issue - #15 #115 #116 #14

          Testing WebSocket, MQTT (Message Queuing Telemetry Transport), and SSE (Server-Sent Events) protocols is crucial for ensuring the reliability, scalability, and security of real-time communication systems. Whereas, gRPC (Remote Procedure Call) facilitates efficient communication between distributed systems using Protocol Buffers (protobuf) as its interface definition language (IDL) and offers features such as bi-directional streaming, authentication, and built-in support for load balancing and health checking. Each of these API protocols/styles serves different purposes and is utilized in various applications ranging from finance to web applications to IoT (Internet of Things) devices. The objective of this project is to design the architecture of the core library, understand the specs & implement the support for testing, visualization & integration code generation of these APIs in API Dash.

          Skills: Understanding Specs/Protocols, UX Design, Dart, Flutter
          Difficulty: Medium-High
          Length: 350 hours

          ~~~~~~~~~~

          6. AI UI Designer for APIs
          Related Issue - #617

          Develop an AI Agent which transforms API responses into dynamic, user-friendly UI components, enabling developers to visualize and interact with data effortlessly. By analyzing API response structures—such as JSON or XML—the agent automatically generates UI elements like tables, charts, forms, and cards, eliminating the need for manual UI development. One can connect an API endpoint, receive real-time responses, and instantly generate UI components that adapt to the data format. It must also support customization options, allowing developers to configure layouts, styles, and interactive elements such as filters, pagination, and sorting. Finally, users must be able to easily export the generated UI and integrate it in their Flutter or Web apps.

          Skills: AI, UX, Parsing, XML, JSON, Python, Dart, Flutter
          Difficulty: Easy-Medium
          Length: 90 hours

          ~~~~~~~~~~

          7. API Testing Suite, Workflow Builder, Collection Runner & Monitor
          Related Issues - #96 #100 #120

          The objective of this project to design and implement an API testing & workflow builder suite which allows various types of API testing:

          Validation Testing: Verify that the API meets functional and business requirements. Automate the testing & validation of responses received from an API against predefined expectations (assertions), Schema validations, etc.
          Integration Testing: Checks proper interaction between different APIs
          Security Testing: Identifies vulnerabilities and safeguards data
          Performance Testing: Measures speed, responsiveness, and stability under varying loads
          Scalability Testing: Evaluates the system's ability to grow with demand
          Users should be able to easily create collections of APIs for testing. It will also be useful to provide a API workflow builder (a drag and drop environment) to create API workflows and chain requests. The UI must allow users to execute this collection of API requests and test it in a systematic and automated manner (Collection Runner) and finally monitor the results.

          Skills: UI/UX Design, Automation, Testing, Dart, Flutter
          Difficulty: Medium-High
          Length: 350 hours

          ~~~~~~~~~~

          8. Adding Support for API Authentication Methods
          Issue - #609

          Add support for various API authentication methods:

          Basic authentication: Sending a verified username and password with API request Add API Auth: Basic authentication #610
          API key: Sending a key-value pair to the API either in the request headers or query parameters Add API Auth: API key #611
          Bearer token: Authenticate using an access key, such as a JSON Web Token (JWT) Add API Auth: Bearer token #612
          JWT Bearer: Generate JWT bearer tokens to authorize requests Add API Auth: JWT Bearer #613
          Digest Auth: Client must send two requests. First request sent to the server receives a nonce value, which is then used to produce a one-time-use hash key to authenticate the request Add API Auth: Digest Auth #614
          OAuth 1.0 Add API Auth: OAuth 1.0 #615
          OAuth 2.0 Implement OAuth 2.0 authentication #481
          Skills: Authentication, Dart, Flutter
          Difficulty: Low-Medium
          Length: 90 hours

          ~~~~~~~~~~

          9. mem0 for Dart
          mem0 is the goto memory layer for developing personalized AI Agents in Python. It offers comprehensive memory management, self-improving memory capabilities, cross-platform consistency, and centralized memory control. It leverages advanced LLMs and algorithms to detect, store, and retrieve memories from conversations and interactions. It identifies key information such as facts, user preferences, and other contextual information, smartly updates memories over time by resolving contradictions, and supports the development of an AI Agent that evolves with the user interactions. When needed, mem0 employs a smart search system to find memories, ranking them based on relevance, importance, and recency to ensure only the most useful information is presented.

          Currently, we lack this memory layer in Flutter AI applications and your task is to port mem0 to Dart.

          Skills: AI, Database, Data Structures, Python, Dart, Flutter
          Difficulty: Medium-High
          Length: 175 hours

          ~~~~~~~~~~    

          10. API Dash Feature Improvements
          We always believe in improving our core features to help the end user. A suggestive list of features that can be improved are:

          Adding pre-request script/post request script Pre-request and post-request for api collections #557
          Importing from/Exporting to OpenAPI/Swagger specification Importing Requests from OpenAPI Specification file #121
          Adding support for more content types in request Support for application/x-www-form-urlencoded Content-Type as body type formdata currently only supports multipart/form-data #337 Support File as Request Body #352
          JSON body syntax highlighting, beautification, validation - Enhance Request Body Editor: JSON formatting, syntax highlighting, validation and other features #22 Add option to automatically/manually beautify JSON request body #581 Add syntax highlighting for JSON request body #582 Add validation for JSON request body #583 Add environment variable support in request body #590 Env. Variable Support for Text request body #591 Env. Variable Support for JSON request body #592 Env. Variable Support for Form request body #593
          Support for comments in JSON body Support comments in JSON request body #599
          Reading environment variables from OS environment Reading environment variables directly from OS environment #600
          Adding color support for environments (like RED for prod, GREEN for dev) Adding color support for environments #601
          Tab & whitespace settings
          Notification when new app updates are available [feat] in-app update check #373
          Better GraphQL editor
          Beautify and expand/collapse feature for GraphQL query
          Allow inspecting GraphQL schema
          Support for GraphQL variables, fragments, mutation, subscription, etc.
          More widget & integration tests
          More code coverage
          Skills: UX Design, Dart, Flutter
          Difficulty: Easy-Medium
          Length: 175 hours
    totalCharacters_of_ideas_content_parent: 12602
    totalwords_of_ideas_content_parent: 2654
    totalTokenCount_of_ideas_content_parent: 2473
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/api-dash/
    idea_list_url: https://github.com/foss42/apidash/discussions/565


  
  - organization_id: 5
    organization_name: AboutCode
    no_of_ideas: 10
    ideas_content: |
        PURLdb - DeadCode: track End-Of-Life code
        Code Repositories: https://github.com/aboutcode-org/purldb

        Description:

        Eventually old code goes unmaintained and dies. The goal of this project are:

        To add data structures, models, and APIs in purldb to track end-of-life code and in general package and projects activities
        To improve purl coverage at endoflife.date, see https://github.com/endoflife-date/endoflife.date/issues/763
        To import and sync data from projects such as https://github.com/endoflife-date/endoflife.date
        To design a module that can detect when
        a project is turning end-of-life (using the above)
        a project is unmaintained (use metrics from scorecard/other tools)
        Note that on the endoflife.date side, we need to help improve PURL coverage of the database there, as this would be key to integrate with purldb. There

        Priority: High

        Size: Large

        Difficulty Level: Advanced

        Tags:

        Python
        Django
        PostgreSQL
        EOL
        End of life
        Mentors:

        @pombredanne
        @JonoYang
        @AyanSinhaMahapatra
        Related Issues:

        https://github.com/aboutcode-org/purldb/issues/42
        https://github.com/aboutcode-org/vulnerablecode/issues/722
        https://github.com/endoflife-date/endoflife.date/issues/763

        ~~~~~~~~~~
        PURLdb - PopularCode - Find and track actually used and most popular open source code
        Code Repositories: https://github.com/aboutcode-org/purldb

        Description:

        There are between 100 and 200 million open source projects and repos out there. Not all of them are equal. Some are much more useful than others, and some could be safely ignored. For instance, the linux kernel is more important, used and popular than a 1st year computer student school assignment project. The goal of this project is to determine when a project is popular and what are the most popular projects. If we do not know what code is used, we can spend a lot of resources to index less used code.

        There are some simple approaches to this, using available statistics for downloads or Github stars, but that is not satisfying alone.

        An idea would be to consider multiple factors to rank popularity and usage.

        For instance: create a (current and updated) graph of dependencies and compute something like a pagerank but for packages
        Then create with a metric on the freshness of the code like when last release and how much downloaded or based on git activity (excluding bots). This would grow for used code and decay for declining packages
        Then combine this with the dependencies "connectedness"
        Or, just a use the graph connections and no download stats, just a giant graph on top of purldb

        Or something like this:

        Finding strongly connected components
        Relate packages ignoring versions
        Find most connected
        Discount distant connections, boost closest
        Apply decay based on version freshness or git activity
        The approach would be to start small with a single ecosystem as PoC and then extend this to all packages types.

        Ideally, this should be exposed in PurlDB API and integrated in data collection operations.

        Priority: High

        Size: Large

        Difficulty Level: Advanced

        Tags:

        Python
        Django
        PostgreSQL
        Popularity
        Mentors:

        @pombredanne
        @JonoYang
        @AyanSinhaMahapatra

        ~~~~~~~~~~
        VulnerableCode project ideas
        There are two main categories of projects for VulnerableCode:

        A. COLLECTION: this category is to mine and collect or infer more new and improved data. This includes collecting new data sources, inferring and improving existing data or collecting new primary data (such as finding a fix commit of a vulnerability)

        B. USAGE: this category is about using and consuming the vulnerability database and includes the API proper, the GUI, the integrations, and data sharing, feedback and curation.

        VulnerableCode: Process unstructured data sources for vulnerabilities (Category A)
        Code Repositories:

        https://github.com/aboutcode-org/vulnerablecode
        Description:

        The project would be to provide a way to effectively mine unstructured data sources for possible unreported vulnerabilities.

        For a start this should be focused on a few prominent repos. This project could also find Fix Commits.

        Some sources are:

        mailing lists
        changelogs
        reflogs of commit
        bug and issue trackers
        This requires systems to "understand" vulnerability descriptions: as often security advisories do not provide structured information on which package and package versions are vulnerable. The end goal is creating a system which would infer vulnerable package name and version(s) by parsing the vulnerability description using specialized techniques and heuristics.

        There is no need to train a model from scratch, we can use AI models pre-trained on code repositories (maybe https://github.com/bigcode-project/starcoder?) and then fine-tune on some prepared datasets of CVEs in code.

        We can either use NLP/machine Learning and automate it all, potentially training data masking algorithms to find these specific data (this also involved creating a dataset) but that's going to be super difficult.

        We could also start to craft a curation queue and parse as much as we can to make it easy to curate by humans and progressively also improve some mini NLP models and classification to help further automate the work.

        References: https://github.com/aboutcode-org/vulnerablecode/issues/251

        Priority: Medium

        Size: Large

        Difficulty Level: Advanced

        Tags:

        Python
        Django
        PostgreSQL
        Security
        Vulnerability
        NLP
        AI/ML
        Mentors:

        @pombredanne
        @tg1999
        @keshav-space
        @Hritik14
        @AyanSinhaMahapatra
        Related Issues:

        https://github.com/aboutcode-org/vulnerablecode/issues/251

        ~~~~~~~~~~
        VulnerableCode: Add more data sources and mine the graph to find correlations between vulnerabilities (Category A)
        Code Repositories:

        https://github.com/aboutcode-org/vulnerablecode
        Description:

        See https://github.com/aboutcode-org/vulnerablecode#how for background info. We want to search for more vulnerability data sources and consume them.

        There is a large number of pending tickets for data sources. See https://github.com/aboutcode-org/vulnerablecode/issues?q=is%3Aissue+is%3Aopen+label%3A"Data+collection"

        Also see tutorials for adding new importers and improvers:

        https://vulnerablecode.readthedocs.io/en/latest/tutorial_add_new_importer.html
        https://vulnerablecode.readthedocs.io/en/latest/tutorial_add_new_improver.html
        More reference documentation in improvers and importers:

        https://vulnerablecode.readthedocs.io/en/latest/reference_importer_overview.html
        https://vulnerablecode.readthedocs.io/en/latest/reference_improver_overview.html
        Note that this is similar to this GSoC 2022 project (a continuation):

        https://summerofcode.withgoogle.com/organizations/aboutcode/projects/details/7d7Sxtqo
        References: https://github.com/aboutcode-org/vulnerablecode/issues?q=is%3Aissue+is%3Aopen+label%3A"Data+collection"

        Priority: High

        Size: Medium/Large

        Difficulty Level: Intermediate

        Tags:

        Django
        PostgreSQL
        Security
        Vulnerability
        API
        Scraping
        Mentors:

        @pombredanne
        @tg1999
        @keshav-space
        @Hritik14
        @jmhoran
        Related Issues:

        https://github.com/aboutcode-org/vulnerablecode/issues?q=is%3Aissue+is%3Aopen+label%3A"Data+collection"

        ~~~~~~~~~~
        VulnerableCode: On demand live evaluation of packages (Category A)
        Code Repositories: https://github.com/aboutcode-org/vulnerablecode

        Description:

        Currently VulnerableCode runs importers in bulk where all the data from advisories are imported (and reimported) at once and stored to be displayed and queried.

        The objective of this project is to have another endpoint and API where we can dynamically import available advisories for a single PURL at a time.

        At a high level this would mean:

        Support querying a specific package by PURL. This is not for an approximate search but only an exact PURL lookup.

        Visit advisories/package ecosystem-specific vulnerability data sources and query for this specific package. For instance, for PyPi, the vulnerabilities may be available when querying the main API. An example is https://pypi.org/pypi/lxml/4.1.0/json that lists vulnerabilities. In some other cases, we may need to fetch larger datasets, like when doing this in batch.

        This is irrespective of whether data related to this package being present in the db (i.e. both for new packages and refreshing old packages).

        A good test case would be to start with a completely empty database. Then we call the new API endpoint for one PURL, and the vulnerability data is fetched, imported/stored on the fly and the API results are returned live to the caller. After that API call, the database should now have vulnerability data for that one PURL.

        This would likely imply to modify or update importers to support querying by purl to get advisory data for a specific package. The actual low level fetching should likely be done in FetchCode.

        This is not straightforward as many advisories data source do not store data keyed by package, as they are not package-first, but they are stored by security issue. See specific issues/discussions on these importers for more info. See also how things are done in vulntotal.

        Priority: Medium

        Size: Medium/Large

        Difficulty Level: Intermediate

        Tags:

        Python
        Django
        PostgreSQL
        Security
        web
        Vulnerability
        API
        Mentors:

        @pombredanne
        @tg1999
        @keshav-space
        Related Issues:

        https://github.com/aboutcode-org/vulnerablecode/issues/1046
        https://github.com/aboutcode-org/vulnerablecode/issues/1008

        ~~~~~~~~~~
        ScanCode.io project ideas
        ScanCode.io: Create file-system tree view for project scans
        Code Repositories:

        https://github.com/aboutcode-org/scancode.io
        Description:

        When large packages/containers are scanned in scancode.io it is useful to have a tree-view to explore thorugh the file-tree for that package/container to look into scan data for a particular subset of the file-tree/directory or to research more into detections and detection issues.

        This would be something similar to what we have at scancode-workbench for example: https://scancode-workbench.readthedocs.io/en/develop/ui-reference/directory-tree.html

        I.e. we need the following features:

        To be able to toggle showing the directory contents from the directory icon
        Show nested directory contents in a tree like structure
        Have this view ideally in a pane left to the table-view of resources
        Show only info from the selected directory in the table-view of resources
        Note that we do have a ProjectCodebaseView in the projects page currently in scancode.io but this is fairly limited as it only lets you browse through the codebase one directory at a time (only shows the files/directories in one directory), and lets you navigate to directories in the current directory or the parent directory from there.

        Priority: High

        Size: Large

        Difficulty Level: Intermediate

        Tags:

        Python
        Django
        UI/UX
        File-system
        Navigation
        Mentors:

        @tdruez
        @pombredanne
        @AyanSinhaMahapatra
        Related Issues:

        https://github.com/aboutcode-org/scancode.io/issues/697

        ~~~~~~~~~~
        ScanCode.io: Add ability to store/query downloaded packages
        Code Repositories:

        https://github.com/aboutcode-org/scancode.io
        Description:

        Packages which are downloaded and scanned in SCIO can be optionally stored and accessed to have a copy of the packages which are being used for a specific product for reference and future use, and could be used to meet source redistribution obligations.

        The specific tasks would be:

        Store all packages/archives which are downloaded and scanned in SCIO
        Create an API and index by URL/checksum to get these packages on-demand
        Create models to store metadata/history and logs for these downloaded/stored packages
        Additionally support and design external storage/fetch options
        There should be configuration variable to turn this on to enable these features, and connect external databases/storage.

        Priority: Low

        Size: Medium

        Difficulty Level: Intermediate

        Tags:

        Python
        Django
        CI
        Security
        Vulnerability
        SBOM
        Mentors:

        @tdruez
        @keshav-space
        @jyang
        @pombredanne
        Related Issues:

        https://github.com/aboutcode-org/scancode.io/issues/1063


        ~~~~~~~~~~

        ScanCode.io: Update SCIO/SCTK for use in CI/CD:
        Code Repositories:

        https://github.com/aboutcode-org/scancode.io
        https://github.com/aboutcode-org/scancode-action
        Description:

        Enhance SCIO/SCTK to be integrated into CI/CD pipelines such as Github Actions, Azure Piplines, Gitlab, Jenkins. We can start with any one CI/CD provider like GitHub Actions and later support others.

        These should be enabled and configured as required by scancode configuration files to enable specific functions to be carried out in the pipeline.

        There are several types of CI/CD pipelines to choose from potentially:

        Generate SBOM/VDRs/VEX with scan results:

        Scan the repo to get all purls: packages, dependencies/requirements
        Scan repository for package, license and copyrights
        Query public.vulnerablecode.io for Vulnerabilities by PackageURL
        Generate SPDX/CycloneDX SBOMs from them with scan and vulnerability data
        License/other Compliance CI/CD pipelines

        Scan repo for licenses and check for detection accuracy
        Scan repo for licenses and check for license clarity score
        Scan repo for licenses and check compliance with specified license policy
        Check for OpenSSF scorecard data and specified policy on community health metrics
        The jobs should pass/fail based on the scan results of these specific cases, so we can have:
        a special mode to fail with error codes
        description of issues and failure reasons, and docs on how to fix these
        ways to configure and set up for these cases with configuration files
        Dependency checkers/linters:

        download and scan all package dependencies, get scan results/SBOM/SBOMs
        check for vulnerable packages and do non-vulnerable dependency resolutuion
        check for test failures after dependency upgrades and add PR only if passes
        Jobs which checks and fixes for misc other errors:

        Replaces standard license notices with SPDX license declarations
        checks and adds ABOUT files for vendored code
        We have an initial CI runner at https://github.com/nexB/scancode-action but we need to improve this with more functions, specially checking against predefined policies and failing/successful CI based on that.

        References:

        https://github.com/aboutcode-org/scancode.io/issues/599
        https://github.com/aboutcode-org/scancode.io/issues/1582
        Priority: High

        Size: Large

        Difficulty Level: Intermediate

        Tags:

        Python
        Django
        CI
        Security
        License
        SBOM
        Compliance
        Mentors:

        @pombredanne
        @tdruez
        @keshav-space
        @tg1999
        @AyanSinhaMahapatra
        Related Issues:

        https://github.com/aboutcode-org/scancode.io/issues/599

        ~~~~~~~~~~
        ScanCode Toolkit project ideas
        Have variable license sections in license rules:
        Code Repositories:

        https://github.com/aboutcode-org/scancode-toolkit
        Description:

        There are lots of variability in license notices and declarations in practice, and one example of modeling this is the SPDX matching guidelines. Note that this was also one of the major ways scancode used to detect licenses earlier.

        Support grammar for variability in license rules (brackets, no of words)
        Do a massive analysis on license rules and check for similarity and variable sections This can be used to add variable sections (for copyright/names/companies) and reduce rules.
        Support variability in license detection post-processing for extra-words case
        Add scripts to add variable sections to rules from detection issues (like bsd detections)
        Priority: Medium

        Size: Medium

        Difficulty Level: Intermediate

        Tags:

        Python
        Licenses
        LicenseDetection
        SPDX
        Matching
        Mentors:

        @AyanSinhaMahapatra
        @pombredanne
        @jyang
        @DennisClark
        Related Issues:

        https://github.com/aboutcode-org/scancode-toolkit/issues/3601

        ~~~~~~~~~~

        Mark required phrases for rules automatically using NLP/AI:
        Code Repositories:

        https://github.com/aboutcode-org/scancode-toolkit
        Description:

        Required phrases are present in rules to make sure the rule is not matched to text in a case where the required phrase is not present in the text, which would be a false-positive detection.

        We are marking required phrases automatically based on what is present in other rules and license attributes, but this still leaves a lot of rules without them. See https://github.com/aboutcode-org/scancode-toolkit/pull/3924 where we are also adding a script to add required phrases as individual rules if applicable and also adding required phrases added to other rules.

        research and choose a model pre-trained on code (StarCoder?)
        use the dataset of current SCTK rules to train a model
        Mark required phrases in licenses automatically with the model
        Test required phrase additions, improve and iterate
        Bonus: Create a minimal UI to review rule updates massively
        Priority: Medium

        Size: Medium

        Difficulty Level: Advanced

        Tags:

        Python
        ML/AI
        Licenses
        Mentors:

        @AyanSinhaMahapatra
        @tg1999
        @pombredanne
        Related Issues:

        https://github.com/aboutcode-org/scancode-toolkit/issues/2878

          
    totalCharacters_of_ideas_content_parent: 19350
    totalwords_of_ideas_content_parent: 4455
    totalTokenCount_of_ideas_content_parent: 4378
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/aboutcode/
    idea_list_url: https://github.com/aboutcode-org/aboutcode/wiki/GSOC-2025-Project-Ideas




  - organization_id: 6
    organization_name: Accord Project
    no_of_ideas: 7
    ideas_content: |
        1. Linter for Concerto
        Write a linter in TypeScript for Concerto Source files. It should make use of existing functionality to validate the Concerto DSL syntax and JSON AST of Concerto model against a set of rules. Rules should be defined in Typescript and which rules are run should be configurable. You may be able to make use of a tool like Spectral as the framework for defining our own rules over the Concerto AST (JSON).

        Expected Outcomes:
        A tool that allow users to:

        Specify the naming of declarations. E.g. all names of scalars should be in camel case.
        Specify the naming of properties, enum cases e.t.c
        Specify which language features can be used. E.g. disallow maps, disallow forward references in regex validators.
        Enforce the use of certain features. E.g. all string properties should have a length validator.
        Enforce the use of @Term decorators on all declarations and properties e.t.c
        All concepts in a namespace should extend a given concept
        All concepts in a namespace must have unique names across multiple namespaces
        Skills required/preferred:
        Algorithms, Functional programming, Back end development, NodeJS, TypeScript

        Possible Mentors:
        Jamie Shorten, Sanket Shevkar

        Expected size of project:
        175 hours (medium)

        Expected difficulty:
        Medium

        ~~~~~~~~~~

        2. Decorator Command Set JSON<->YAML Convertor
        Design and implement a convertor that would convert Decorator Command Sets JSON Objects to a much more human readable YAML format and vice-versa. Currently DCS JSON objects are very verbose to read, write and edit. With the new custom YAML format we aim to make DCS objects much more easier to read, write and edit.

        Expected Outcomes:
        A utility/method in DecoratorManager to convert DCS JSON to YAML and from YAML to JSON.
        1:1 conversion is not expected. YAML should have a custom format that is less verbose and more readable.
        Skills required/preferred:
        NodeJS, Typescript, Javascript, Basic understanding of Data Formats like JSON and YAML

        Possible Mentors:
        Sanket Shevkar

        Expected size of project:
        175 hours (medium)

        Expected difficulty:
        Medium

        ~~~~~~~~~~

        3. Accord Project Agreement Protocol
        The Accord Project Agreement Protocol (APAP) defines the protocol used between a document generation engine or contract management platform and an agreement server that provides agreement features like template management, document generation, format conversion etc.

        Expected Outcomes:
        Updated Open API specification
        Updated reference implementation for the specification
        Address (some of) open issues
        Skills required/preferred:
        NodeJS, Typescript, Javascript, REST API design

        Possible Mentors:
        Dan Selman, Niall Roche

        Expected size of project:
        350 hours (large)

        Expected difficulty:
        Medium

        ~~~~~~~~~~

        4. Specification Conformance Tests
        Our specification conformance testing is in need of an overhaul! We'd like to migrate to a robust, proven testing framework like Vitest which would support ESM, and be performant and have a new dedicated concerto package used for Concerto conformance testing. An AI tool may be useful in helping with the migration, so feel free to mention how AI could help you with this project! The goal is to have a set of tests that can be run against any Concerto implementation to assess whether it is conformant with the specification.

        Expected Outcomes:
        Migration to Vitest (or other appropriate framework)
        Consolidation of testing methodology and tooling
        New concerto package for tests, focused on conformance
        Build a set of tests for the Concerto validation rules
        Skills required/preferred:
        Node / Javascript
        Unit testing (Mocha / Jest for example)
        Behaviour driven testing (optional, Cucumber, for example)
        Possible Mentors:
        Dan Selman, Ertugrul Karademir

        Expected size of project:
        175 hours (medium)

        Expected difficulty:
        Medium

        ~~~~~~~~~~

        5. Incorporating AI into Template Playground
        Our Template Playground web application is used to help onboard users to our technologies. We'd love to make this even easier by adding AI features to make it easier to create, edit, and preview contract templates. This project will build upon the work that was carried out last year in the context of VS Code.

        Expected Outcomes:
        Allow users to upload a file and we'd use AI to convert it to an Accord Project template
        Possibly incorporate auto-complete suggestions when editing using the code editors built into the web app
        Skills required/preferred:
        ReactJS, AI tooling

        Possible Mentors:
        Diana Lease

        Expected size of project:
        350 hours (large)

        Expected difficulty:
        Medium

        ~~~~~~~~~~

        6. Testing for Code Generation Targets
        We have tools that allow users to generate code from their Concerto models, supporting several languages. We would like to introduce a way of testing this code generation that compiles code for each language we are generating.

        Expected Outcomes:
        Set of Docker images for each code generation target
        Run code gen tests within the correct image using GitHub actions, for example, generate Java code and then compile and run it using javac to ensure the generated code is correct
        Skills required/preferred:
        Systems engineering, CI/CD
        Docker, Docker compose
        GitHub actions
        Possible Mentors:
        Dan Selman, Ertugrul Karademir

        Expected size of project:
        175 hours (medium)

        Expected difficulty:
        Medium

        ~~~~~~~~~~

        7. Migration of Template Playground to use Tailwind CSS
        As mentioned previously, our Template Playground web application is used to help onboard users to our technologies. By using a popular, well-maintained CSS framework like Tailwind, we could improve performance and code maintainability.

        Expected Outcomes:
        Template Playground updated to use Tailwind CSS
        Existing UI tests updated
        Possibly other UI changes to make user experience better, more performant, and/or optimized for multiple screen sizes
        Skills required/preferred:
        ReactJS, Tailwind CSS

        Possible Mentors:
        Diana Lease

        Expected size of project:
        175 hours (medium) - 350 hours (large)

        Expected difficulty:
        Medium


          
    totalCharacters_of_ideas_content_parent: 6850
    totalwords_of_ideas_content_parent: 1663
    totalTokenCount_of_ideas_content_parent: 1391
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/accord-project/
    idea_list_url: https://github.com/accordproject/techdocs/wiki/Google-Summer-of-Code-2025-Ideas-List



  - organization_id: 7
    organization_name: Alaska 
    no_of_ideas: 15
    ideas_content: |
        [1] Automated coastline extraction for erosion modeling in Alaska.

        Mentors: Frank Witmer (fwitmer -at- alaska.edu) and Rawan Elframawy (rawann.elframawy -at- gmail.com)

        Overview: The rapidly warming Arctic is leading to increased rates of coastal erosion, placing hundreds of Alaska communities at the frontline of climate change. Understanding current rates of coastline change and accurately forecasting future changes is critical for communities to mitigate and adapt to these changes. Current modeling approaches typically use a simple linear model based solely on historical coastline positions to measure rates of change and extrapolate them into the future. In doing so, these models fail to capture the dynamic effects associated with decreasing sea ice, increasing annual wave energy, and increasing temperatures. To improve the quality of these coastal models, we need to increase the quantity of digitized coastlines, but manual photointerpretation is slow and laborious.

        Current Status: An initial model and pipeline have been developed to automatically extract coastlines from PlanetLabs imagery. An auto-download script is available to retrieve PlanetLabs imagery (3-5m spatial resolution) by specifying any timeframe, cloud coverage percentage, and geometry. Additionally, NDWI with a majority sliding window has been introduced, allowing a specific threshold for each window to improve water detection accuracy. The DeepWaterMap algorithm was originally trained with the Global Surface Water (GSW) dataset at 30 m resolution from Landsat imagery, but the model did not not work well applied to PlanetLabs imagery. We are working to re-train the model using PlanetLabs imagery automatically labeled using the NDWI thresholding method. This project extends and expands on the progress made in 2024.

        Potential areas of improvement:

        Data Expansion (Deering 2017–2019 and Beyond): Currently using data from 2017 to 2019 for Deering; we plan to include more recent data to extend the time series.
        Improved Cliff Area Segmentation: Enhance segmentation performance specifically in steep or cliff-like coastal areas.
        Handling Challenging Conditions: Improve segmentation in regions with water shadows, buildings, satellite artifacts, and other data quality issues.
        SWIR and Elevation Data Integration: Investigate combining short-wave infrared (SWIR) data and elevation data (e.g., DEMs) to further refine segmentation accuracy.
        Expected Outcomes: A finished model with high accuracy that automatically extracts a vectorized coastline representation from PlanetLabs satellite imagery. Then, the model can be applied to large amounts of imagery to model coastline changes over time.

        Required Skills: Python

        Code Challenge: Experience with multi-band satellite imagery, geospatial data processing, and machine learning.

        Source Code: https://github.com/fwitmer/CoastlineExtraction

        Discussion Forum: https://github.com/fwitmer/CoastlineExtraction/discussions

        Effort: 350 Hours

        Difficulty Level: Medium

        ~~~~~~~~~~

        [2] Support for Logarithmic Number Systems in a Deep-Learning Framework.

        Mentors: Mark Arnold (markgarnold -at- yahoo.com), Ed Chester (ed.chester -at- gmail.com), and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: The Logarithmic Number System (LNS) is an alternative to built-in Floating Point (FP), which makes multiplication and division easy at the expense of more difficult addition. Using overloaded operators, xlns provides an open-source Python library for LNS arithmetic. Interest in fabricating LNS hardware has grown since it may reduce power consumption for applications that tolerate approximate results, such as deep learning (see [1]-[5]). The problem is deep learning often relies on open-source Python frameworks (like Tensorflow or Pytorch) that are hardcoded to use FP hardware. A key feature of these frameworks is the ability to automatically compute gradients (based on the chain rule) by recording extra information about the computation stored in FP format. Such gradients are used during backpropagation training to update network weights.

        Current Status: xlns, Tensorflow and Pytorch are all interoperable with the widely-used open-source Numpy library, but xlns is not interoperable with the Tensorflow and Pytorch frameworks because both frameworks are hard coded to use built-in int or FP data internally instead of LNS.

        Expected Outcomes: The goal of this project is to provide support for a deep learning framework that uses xlns instead of FP internally (including network specification, automatic gradient, forward inference, and back-propagation training) while keeping high-level compatibility with the framework. This might be as part of xlns, or as a forked version of the chosen framework, or both. The contributor may choose either Pytorch or Tensorflow. The contributor should justify these decisions as part of the proposed design.

        Required Skills: Calculus, Python, Numpy, and either Pytorch or Tensorflow

        Code Challenge: The following three challenges illustrate the breath of issues involved. Each involves only a few lines of Python. Each involves working with both xlns and the framework. Doing all three in both Tensorflow and Pytorch might give evidence for which framework is more likely to lead to the expected outcome.

        Currently, when the data starts in xlns format, Pytorch/Tensorflow converts to FP. As part of the code challenge, we expect the contributor to provide short Python code snippets that demonstrate that if the data starts in xlns format, the computation cannot be carried out in the xlns format.

        xlns/examples/arn_generic.py is a hard-coded illustration of training a fully connected MLP with 28*28 input nodes, 100 hidden nodes and 10 output nodes using MNIST digit set. The hidden layer uses RELU and the output layer uses softmax. The FP weights for this are initialized as:

        W1 = np.array((list(np.random.normal(0, 0.1, (785, 100)))))                    
        W2 = np.array((list(np.random.normal(0, 0.1, (101, 10)))))
        Because there is an extra weight for a constant 1.0 input in each layer, the number of rows is one larger than the inputs to the layer. The example can be run with various data types, for example with xlnsnp (LNS internally implemented with int64 Numpy ufuncs):

        python3 arn_generic.py --type xlnsnp --num_epoch 7
        or more conventionally

        python3 arn_generic.py --type float --num_epoch 7
        The code challenge is to implement a similar size fully connected network (in FP) using the provided features of Pytorch or Tensorflow and compare its convergence with arn_generic.py (Note: arn_generic.py uses manual differentiation, ie, the derivative of RELU is a constant, which depends on the sign of the argument, and elementary backpropagation implements the chain rule).

        Consider LNS addition (1+2=3 and 3-1=2). The following illustrates the overloaded operator and xlnsnp internal representation (sign is LSB of the int64 value; the log portion is the rest):
        >>> import xlns as xl
        >>> x=xl.xlnsnp([2.0, 3.0])
        >>> x
        xlnsnp([xlns(1.9999999986889088) xlns(2.9999999688096786)])
        >>> x.nd
        array([16777216, 26591258])
        By default, the log portion here is given with 23 bits of precision (see help for xl.xlnssetF for details on how to lower the precision as would be useful in machine learning), which is why the log(2.0) is given as 16777216.

        >>> 2*np.int64(np.log2([2.0, 3.0])*2**23)
        array([16777216, 26591258])
        The expression with log2 double checks the answer for x in 23-bit format (with the additional *2 to make room for the sign bit). Had the +2.0 been -2.0, the representation would have been 16777217.

        >>> y=xl.xlnsnp([1.,-1.])
        >>> y
        xlnsnp([xlns(1.0) xlns(-1.0)])
        >>> y.nd
        array([0, 1])
        The above illustrates that the log(1.0)=0, and that the sign bit is one for negative values.

        >>> x+y
        xlnsnp([xlns(2.9999999688096786) xlns(1.9999999986889088)])
        >>> (x+y).nd
        array([26591258, 16777216])
        Although the Pytorch/Tensorflow frameworks don’t support LNS, LNS can be constructed from int64 and float operations (which is how xlnsnp works). In xlns/src/xlns.py, there is a function sbdb_ufunc_ideal(x,y). If you call this with the following code:

        >>> import numpy as np
        >>> def myadd(x,y):  
                  return np.maximum(x,y)+xl.sbdb_ufunc_ideal(-np.abs(x//2-y//2), (x^y)&1) ))
        it performs the same operation internally on int64 values as the overloaded operator:

        >>> myadd(x.nd,y.nd)
        array([26591258, 16777216])
        Such operations are supported by the frameworks (rather than here from np). This code challenge is to do a similar toy example within the tensor types provided by the framework, which gives a small taste of the difficulty involved in this project. (The code above for myadd is a slight oversimplification of xl.xlnsnp.__add__; see this for details on the treatment of 0.0.)

        References:

        [1] G. Alsuhli, et al., “Number Systems for Deep Neural Network Architectures: A Survey,” https://arxiv.org/abs/2307.05035, 2023.

        [2] M. Arnold, E. Chester, et al., “Training neural nets using only an approximate tableless LNS ALU”. 31st International Conference on Application-specific Systems, Architectures and Processors. IEEE. 2020, pp. 69–72. https://doi.org/10.1109/ASAP49362.2020.00020

        [3] O. Kosheleva, et al., “Logarithmic Number System Is Optimal for AI Computations: Theoretical Explanation of Empirical Success”, https://www.cs.utep.edu/vladik/2024/tr24-55.pdf

        [4] D. Miyashita, et al., “Convolutional Neural Networks using Logarithmic Data Representation,” https://arxiv.org/abs/1603.01025, Mar 2016.

        [5] J. Zhao et al., “LNS-Madam: Low-Precision Training in Logarithmic Number System Using Multiplicative Weight Update,” IEEE Trans. Computers, vol. 71, no. 12, pp.3179–3190, Dec. 2022, https://doi.org/10.1109/TC.2022.3202747

        Source Code: https://github.com/xlnsresearch/xlns

        Discussion Forum: https://github.com/xlnsresearch/xlns/discussions

        Effort: 350 Hours

        Difficulty Level: Hard

        ~~~~~~~~~~

        [3] Developing Distributed Algorithm for Metagenomic Error Correction and Assembly.

        Mentors: Arghya Kusum Das (akdas -at- alaska.edu) and Yali Wang (ywang35 -at- alaska.edu)

        Overview: A metagenomics study of Alaska would explore the diverse microbial communities in its unique environments, including the Arctic, marine, and terrestrial ecosystems. Such research could uncover insights into microbial adaptation to extreme conditions and contribute to understanding environmental and climate-related changes in the region. Metagenomic study has an immense impact on multiple science and engineering projects in Alaska such as, arctic healthcare, arctic water pollution, bio leaching on rare earth elements, arctic environmental sustainability and resilience, understanding boreal forest dynamics, wildfire mitigation, and so on. The list is never ending. Shotgun metagenomics, which involves sequencing DNA from a mixed sample of genomes within a community, offers a high-throughput approach to examine the genomic diversity of microbial populations. A key step in metagenomic analysis is assembling the shotgun reads into longer contiguous sequences, or contigs. However, genome assemblies from short reads are often highly fragmented, potentially generating millions of contigs per sample, especially in diverse communities. This challenge arises due to issues like sequence repeats within and between genomes, low coverage of certain species, and strain variability.

        Current Status: Because of the variability in abundance in multiple species in the mixed sample of genomes, it is hard to design a theoretically solid algorithm to rectify the error in the sample and assemble it accurately. The low abundance species in the mixed sample are often wrongly classified as error if we use a traditional/existing algorithms that can rectify the error in a single species’ whole genome sequence. For the similar reason, the existing metagenomic assemblers are perform sub-optimally. Further, the existing software are limited in terms of their data handling capability. Most of them are capable to operate in a single node only. So, their data nailing is severely limited by the RAM available in one node. Also the time consumed for large datasets are often unreasonable.

        Expected Outcomes: In this project, we will address the first two steps in metagenomic analysis i.e., error correction and assembly which are paramount for any downstream project. Metagenomic data is often large in size spanning to hundreds of gigabytes to terabyte scale. Our motivation is to develop distributed, HPC compatible solution for metagenomic error correction and assembly

        (1) We are looking for working solutions (a solid algorithm and its implementation) for metagenomic error correction and assembly. The solutions should be theoretically justifiable and/or biologically meaningful. (2) The algorithm and the software implementation for both error correction and assembly should be distributed in nature. (3) We are open for AI/ML-enabled solutions but that is not a requirement. (4) GPU-enabled solutions are also encouraged but, it’s also not a requirement.

        Required Skills: Python and experience with Deep Neural Networks

        Code Challenge: Prior experience creating deep learning models is expected.

        Source Code: https://github.com/akdasUAF/Metagenome

        Discussion Forum: https://github.com/akdasUAF/Metagenome/discussions/

        Effort: 350 Hours

        Difficulty Level: Medium/Hard

        ~~~~~~~~~~

        [4] Telehealth over L4S.

        Mentors: Kolawole Daramola (koladaramola -at- icloud.com) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: Low Latency, Low Loss, and Scalable Throughput (L4S) Internet Service 1, 2, 3 has shown promising performance, by rethinking congestion control. Can we have a telehealth deployment with pairs of L4S nodes? Perhaps starting with something simple, such as two DICOM endpoints to send radiographic images in between? Linux kernel with L4S patches can be a good point to start for the endpoints. How L4S, with telehealth and other applications, as well as classic non-L4S traffic, share the network will be an interesting test.

        Current Status: A prototype has been built as part of the GSoC 2024. As rural Alaska is largely unconnected by the road network, people often need to fly into larger towns such as Fairbanks and Anchorage for their healthcare needs. This state of affairs has steered the telehealth initiatives in Alaska much more than elsewhere in the US. Our research partners from healthcare organizations such as Alaska Native Tribal Health Consortium (ANTHC) utilize telehealth in their daily operations. Improved telehealth access and performance can significantly benefit the patients and providers in terms of patient satisfaction and comfort.

        Expected Outcomes: This project will review the latest advances from the research, deployment, and testing perspectives with using L4S in telehealth. The contributor will look into how this can be deployed in practice for various telehealth applications – sending DICOM images for diagnostics (high volume of data but tolerance for high latency), telemonitoring via wearable devices (low volume of data but demand for low latency), televisits (a video call through apps such as Zoom – high volume of data and demand for high latency). As a result of this project, we will understand whether we need any optimizations for L4S to use for telehealth applications and potential alternative approaches.

        Required Skills: Python

        Code Challenge: Experience with network protocols and installing Linux servers is a plus. Coding experience demonstrating such experiences is considered positive.

        Source Code: https://github.com/KathiraveluLab/L4SBOA

        Discussion Forum: https://github.com/KathiraveluLab/L4SBOA/discussions

        Effort: 350 Hours

        Difficulty Level: Hard

        ~~~~~~~~~~

        [5] Creating shareable "albums" from locally stored DICOM images

        Mentors: Ananth Reddy (bananthreddy30 -at- gmail.com) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: DICOM data sets downloaded from PACS environments typically remain in the local environments, such as a research server or a cluster where the DICOM retriever (C-MOVE) is run. To use this data, researchers must identify certain subsets of data. This can be achieved by querying the retrieved data. DICOM images consist of textual metadata. By querying the metadata, subsets of images can be identified. However, currently, creating "albums" from locally stored DICOM images is not seamless.

        Current Status: This feature does not exist in our open-source frameworks. We share images through other orthogonal approaches (via rclone, for example). This project will implement a stand-alone utility to effectively create albums from locally stored DICOM images.

        Expected Outcomes: Several approaches to implementing such album features exist. One approach is to use Kheops to provide an interface to create and view the albums. MEDIator can be extended to create subsets and share the images via a unique URL as well. The proposed feature will make the images accessible to more researchers for their experiments by replacing the current manual data sharing efforts. Moreover, Kheops natively integrates with OHIF Viewer. As such, images retrieved locally can be viewed through OHIF Viewer by creating albums with Kheops. Contributors are encouraged to use Kheops or alternatives rather than reinventing the wheel (unless there is a convincing reason).

        Required Skills: Python and Java.

        Code Challenge: Experience working with DICOM images from previous projects or through a sample dummy project will be a plus.

        Source Code: https://github.com/KathiraveluLab/Diomede (New Project).

        Discussion Forum: https://github.com/KathiraveluLab/Diomede/discussions

        Effort: 350 Hours

        Difficulty Level: Easy

        ~~~~~~~~~~

        [6] Beehive: Integrated Community Health Metrics Framework for Behavioral Health to Supplement Healthcare Practice in Alaska.

        Mentors: David Moxley (dpmoxley -at- alaska.edu) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: This project, a collaboration between the University of Alaska Anchorage Departments of Computer Science and Human Services, seeks to create a digital approach to translating the digitalization of art and photographic images into a digital database that stores in retrievable formats those images for use in advancing the delivery of human services and health care to people who experience considerable vulnerability and marginalization within the community. One of the project goals is to create a digital repository of these images, many of which reflect Outsider Art since the people who produce them are not formally trained as artists and experience considerable discrimination. The repository can be used to support research on Outsider art and Outsider Artists, education of health and human services practitioners about the impact of negative stereotypes on the health and well-being of people who are highly vulnerable, and arts programs devoted to advancing the health of vulnerable people.

        This project aims to develop Beehive, a prototype implementation as an open-source data federation framework that can be used in research environments in Alaska and elsewhere.

        Current Status: A prototype has been built as part of Alaska Season of Code. We are researching the approach for its use with our community partners in Anchorage, aiming to support marginalized folks such as the unhoused.

        Expected Outcomes: In this project, the contributor will develop the Beehive platform for (1) translating digital images into the database, (2) developing the database to support user interactions with content, and (3) facilitating retrieval of images. The contributor will obtain an orientation to the project, instruction in how the arts and photography can represent health and well-being, and insight into using digital representations as an advocacy tool for improving the well-being of highly vulnerable people.

        Required Skills: Database (MySQL or Mongo) and Python or Java. A build management tool such as Apache Maven is recommended if using Java.

        Code Challenge: Prior experience with database management through established coding examples.

        Source Code: https://github.com/kathiraveluLab/beehive.

        Discussion Forum: https://github.com/KathiraveluLab/Beehive/discussions/

        Effort: 350 Hours

        Difficulty Level: Medium

        ~~~~~~~~~~

        [7] DICOM Image Retrieval and Processing in Matlab.

        Mentors: Ananth Reddy (bananthreddy30 -at- gmail.com) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: DICOM (Digital Imaging and Communications in Medicine) is a radiographic imaging standard for how various modalities of scanners, PACS (Picture archiving and communication system) and other imaging systems communicate. As a storage protocol, it defines how images are stored in a standard way. It also functions as a messaging protocol, an extension to TCP.

        Many DICOM processing tools exist. They support receiving images from the scanners and PACS to a research cluster in real-time as an imaging stream or on-demand selectively. They also provide means to anonymize the DICOM images to preserve patient privacy, export the DICOM images into a format such as PNG or JPEG, and extract the textual metadata from DICOM files to store it in a CSV file format or a database. Machine learning pipelines cannot be executed in clinical systems such as scanners and PACS. Therefore, the DICOM images and their metadata in the research clusters can be used to run machine learning pipelines.

        Matlab has some out-of-the-box support for certain DICOM functions, and it could make our job easy in certain projects. This facilitates processing the files from the file system 2. Region-of-Interest is natively supported for DICOM-RT files in Matlab 3. It also supports deep learning on DICOM and NifTi files 4. Matlab currently does not support receiving images from DICOM systems such as PACS and Scanners over the network. Matlab used to have functions that utilize the Dicom toolkit to pull images from another server. It was available through Matlab's file exchange at one point called "dicom server connection." This is not publicly available anymore. However, we have the implementation available locally. The code was not recently tested, and therefore, its usability with the latest Matlab versions needs to be confirmed.

        Current Status: This project is currently in the research stage.

        Expected Outcomes: This project aims to create an easy-to-use open-source Matlab DICOM processing framework. We start with processing DICOM images since the current status of the DICOM networking in Matlab is unknown. But we will explore it, if possible and time permitting. Since this is a research project, we should study the existing projects first to avoid re-inventing the wheel. From Google Scholar, we see many processing and pipelines (ROI, deep learning, ...) on DICOM/DICOM-RT have been implemented using Matlab. Regardless of the scientific novelty, we can get an open-source solution to help with further ML stuff using Matlab on the DICOM files. However, we should also observe how this could be a scientific contribution and its merits beyond what is already available. We can use readily available public DICOM data sources to test our implementations, such as the Cancer Imaging Archive (TCIA), as that avoids having to deal with sensitive patient data with PHI. We will narrow down on a specific research use case to highlight the framework's usage in research.

        Required Skills: Matlab

        Code Challenge: Experience working with DICOM images from previous projects and prior experience with Matlab, as demonstrated through code examples, will be a plus.

        Source Code: https://github.com/KathiraveluLab/Diomede (New Project).

        Discussion Forum: https://github.com/KathiraveluLab/Diomede/discussions

        Effort: 350 Hours

        Difficulty Level: Hard


        ~~~~~~~~~~

        [8] Making ZeroMQ a first-class feature of concore.

        Mentors: Shivang vijay (shivangvijay -at- gmail.com), Rahul Jagwani (rahuljagwani1012 -at- gmail.com), and Mayuresh Kothare (mvk2 -at- lehigh.edu)

        Overview: concore is a lightweight framework for closed-loop peripheral neuromodulation control systems. concore consists of a file-sharing based concore protocol to communicate between the programs in a study. concore also allows a shared-memory based communication between programs. This project will implement a ZeroMQ-based communication between programs, as an alternative to the file-sharing based and shared-memory based communications. ZeroMQ is a message-oriented middleware implemented in multiple languages, which natively supports communications across computing nodes. Such an implementation will improve the usability of concore in distributed environments.

        The study with 0MQ

        Current Status: We experimented with an osparc-control based communication as an alternative to this default file-sharing based concore protocol. osparc-control is an extension of ZeroMQ. Our experimental osparc-control based implementation replaces the file-sharing mechanism restricted to one local machine with message queues that can be transmitted between locally networked machines. The contributor will use this osparc-control based communication as an inspiration for the proposed ZeroMQ-based implementation, which will function as a first-class approach to implement the edges of concore without using osparc-control. In our current experimental osparc-control based implementation, these ZeroMQ edges are not visible in the concore editor, the browser-based visual editor for concore. Consequently, studies with osparc-control are represented as forests instead of directed hypergraphs due to the "invisible" ZeroMQ communication. This also means to run a concore study with ZeroMQ communication, we have to run each hypergraph in the forest separately.

        Expected Outcomes: We need to promote a unified experience in concore, whether the edges are implemented via the default file-sharing approach, shared-memory approach, or through this ZeroMQ message-based approach. In the concore file-sharing approach, we label the edges with alphabetical characters. In the concore shared-memory approach, we label the edges starting with positive decimal integers (specifying the memory channels used for the sharing). Therefore, to denote the concore ZeroMQ-based edges, the contributor should assume that all the ZeroMQ-edges must start with "0" in their labels, followed by a hexadecimal port, followed by an underscore (_). For example, edge 0x1234_Y assigns the logical Y to port 1234 and edge 0xabcd_U assigns the logical U to port abcd. Once such a graph with ZeroMQ-edges is made (a single directed hypergraph, rather than a forest with disjoint two or more directed hypergraphs), we should be able to seamlessly build and run the study regardless of the underlying communication mechanism. Thus, we aim to demonstrate the possibility of a seamless local vs. distributed execution in a cluster through ZeroMQ.

        As the expected outcome of this project, we propose a ZeroMQ-based communication for concore with Python. In addition, the contributor may also implement the ZeroMQ-based communication with other programming languages supported by concore such as Matlab and C++. The contributor may also get inspiration from how the shared-memory based communication is implemented in concore.

        Required Skills: Python

        Code Challenge: Prior experience in Python must be demonstrated. Prior experience with message-oriented middleware frameworks such as ZeroMQ can be a plus, although not mandatory.

        Source Code: https://github.com/ControlCore-Project/concore

        Discussion Forum: https://github.com/ControlCore-Project/concore/discussions

        Effort: 350 Hours

        Difficulty Level: Medium


        ~~~~~~~~~~

        [9] Dynamic DICOM Endpoints.

        Mentors: Ananth Reddy (bananthreddy30 -at- gmail.com) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: DICOM (Digital Imaging and Communications in Medicine) is a radiographic imaging standard for how various modalities of scanners, PACS (Picture archiving and communication system), and other imaging systems communicate. As a storage protocol, it defines how images are stored in a standard way. It also functions as a messaging protocol, an extension to TCP. DICOM implementations often have a queue to hold the images sent from the source. Since this is a networking communication, a queue may degrade the performance or introduce data loss. DICOM communications are defined by static source, query, and destination endpoints. Each endpoint is defined by hostname/IP address, port, and AE (Application Entity) Title. A DICOM endpoint such as a PACS or a scanner usually has these endpoints statically configured to ensure security and patient privacy.

        This project attempts to send data from a source to dynamic destinations based on the queue and the performance. This can be a use case for teleradiology with multiple remote healthcare/radiologist sites present or a potential framework to enable federated learning on radiographic images. Orthanc can be set up as a DICOM endpoint that mimics a PACS 1. With multiple Orthanc servers configured, such a federated deployment can be prototyped. Ultimately, this project aims to study the possibilities and opportunities of supporting dynamic DICOM endpoints in practice.

        Current Status: This project is currently in the research stage.

        Expected Outcomes: A prototype implementation that supports dynamic DICOM endpoints.

        Required Skills: Python

        Code Challenge: Experience working with DICOM images from previous projects or through a sample dummy project will be a plus.

        Source Code: https://github.com/KathiraveluLab/Diomede (New Project).

        Discussion Forum: https://github.com/KathiraveluLab/Diomede/discussions

        Effort: 350 Hours

        Difficulty Level: Hard

        ~~~~~~~~~~

        [10] Bio-Block: A Blockchain-based Data Repository and Payment Portal.

        Mentors: Chalinda Weerasinghe (chalindaweerasinghe -at- gmail.com), Erik Zvaigzne (erik.zvaigzne-at-gmail.com), and Forrester Kane Manis (Forrester-at-headword.co)

        Overview: Most biological, genomic, genetic, medical, and behavioral data are currently collected, stored, and sold by vendors who initially offer products and services to clients in order to accumulate this data. The data, once given to companies, remains the property of the company, with very little compensation and autonomy offered to customers who provided the data in the first place. Can we create a secure, decentralized, and scalable data repository of such information for humans and animals, a true bio-block available to all and open-sourced, whereby the data owners get directly compensated? This project offers a response in the affirmative and leverages blockchains for data distribution, archiving, recording, and payments using a dual-chain structure on the Ethereum blockchain.

        Current Status: This project is currently in the research stage.

        Expected Outcomes: This overall project will be one of the first offerings of an open-source platform for all biological/medical/genomic/behavioral data that leverages the advantages of blockchains. While proprietary dual-chain blockchain architectures are used by companies in this space, our endeavor, through its sub-projects, aims to proof up the architecture that can be scaled and extended to all forms of client-submitted data and multiple retrieval and payment options. A proof of concept of the architecture will be tested using multivariate, heterogenous synthetic data.

        Required Skills: Python is proposed as the programming language. However, students can also propose their preferred alternative programming language and frameworks. Prior experience developing on Ethereum is a plus.

        Code Challenge: Prior experience in Python (or the proposed alternative language) and, preferably, Ethereum blockchain through established coding examples. Students are expected to establish their experience with Blockchain technologies and architecting and programming them through previous projects - ideally through their respective GitHub repository (or similar code repositories).

        Source Code: https://github.com/bio-block/healthy (New Project).

        Discussion Forum: https://github.com/bio-block/healthy/discussions

        Effort: 350 hours

        Difficulty Level: Hard

        ~~~~~~~~~~

        [11] Adopting Nunaliit for Alaska Native Healthcare Practices.

        Mentors: Jessica Ross (jmross2 -at- alaska.edu) and Maria Williams (mdwilliams6 -at- alaska.edu)

        Overview: Nughejagh is an Alaska Native holistic healthcare application. It uses Nunaliit as its map-based interface to store its data. The data is curated from various sources in the form of images, stories, and videos - which are stored using the Nunaliit map-based interface, supported by its CouchDB database. However, currently, Nunaliit lacks several desired features for Nughejagh. This project aims to fill the gap by implementing those features and developing scripts to automate the installation, configuration, and data loading process.

        Current Status: This project is currently in the research stage.

        Expected Outcomes: The expected goal is to have Nunaliit fine-tuned and configured to run Nughejagh with all its requirements. The project outcome might be a new stand-alone repository that uses Nunaliit, a forked version of Nunaliit, or more likely both. The contributor should justify their design decisions as part of the proposed design.

        Required Skills: Prior experience in Javascript, Java, and Python.

        Code Challenge: Deploy and configure Nunaliit locally and share a screenshot of a locally-running Nunaliit instance. Nunaliit runs well on Ubuntu 24.04.

        Source Code: https://github.com/Nughejagh/nughejagh (New Project).

        Discussion Forum: https://github.com/Nughejagh/nughejagh/discussions

        Effort: 350 hours

        Difficulty Level: Medium

        ~~~~~~~~~~

        [12] AWANTA: A Virtual Router based on RIPE Atlas Internet Measurements.

        Mentors: Ananth Reddy (bananthreddy30 -at- gmail.com) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: RIPE Atlas is an Internet Measurement network composed of small network devices, known as RIPE Atlas Probes and Anchors, connected to the participating volunteers' routers. Using RIPE Atlas, we can measure the Internet latency and routing path through ping and traceroute measurements. This project aims to develop a software router that dynamically uses RIPE Atlas measurements to change the scheduling path. Before the implementation of the project, we should study the existing works on using RIPE Atlas probe for such network optimization tasks at the Internet scale to quickly understand the state-of-the-art and ensure scientific novelty in our approach.

        Current Status: A prototype has been built as part of the GSoC 2024. We observe the use of such a framework in the Circumpolar North. Such an approach can provide significant benefits, especially in Alaska and the Canadian North, where Internet connectivity can be spotty.

        Expected Outcomes: This project extends the RIPE Atlas client to use the measurements in network scheduling decisions. First, the measurements should be streamlined to perform periodically across several probes set as sources and destinations. The measurements across several probes in a single city can provide a more generalized measurement for a city rather than restricting to individual changes of any given probe when multiple such probes are available to a given city. Second, we will build a virtual router to use these measurements to dynamically influence the network scheduling decisions across several nodes. As the network performance changes with time, we can observe how the network path changes with time. We have more than 60 million RIPE Atlas credits that we accumulated by hosting a RIPE Atlas probe for the past five years. So, we have sufficient resources for these Internet measurement experiments.

        Required Skills: Python.

        Code Challenge: Prior experience in Python through established coding examples.

        Source Code: https://github.com/KathiraveluLab/AWANTA

        Discussion Forum: https://github.com/KathiraveluLab/AWANTA/discussions/

        Effort: 350 Hours

        Difficulty Level: Medium


        ~~~~~~~~~~

        [13] Alaska Wildfire Prediction Using Satellite Imagery.

        Mentors: Yali Wang (ywang35 -at- alaska.edu) and Arghya Kusum Das (akdas -at- alaska.edu)

        Overview: Given Alaska’s unique wildfire patterns, where large-scale fires occur annually in boreal forests, tundra, and remote wilderness, predicting fire-prone areas can help mitigate disasters and optimize resource allocation. The presence of vegetation (fuel) is necessary for a fire, but the determining factors are weather conditions (humidity, wind speed, temperature) and an ignition source (lightning, human activity, etc.). This project aims to develop a hybrid deep learning model to predict wildfire risk in Alaska by integrating optical, thermal, and synthetic aperture radar (SAR) satellite imagery with ground-based weather data. Traditional wildfire prediction relies on weather data, historical fire records, and human observations, which can be delayed or inaccurate in remote areas like Alaska. In contrast, satellite imagery provides real-time, high-resolution insights into vegetation health, thermal anomalies, burn severity mapping, soil moisture, fuel dryness, and even cloud-penetrating fire detection.

        Satellite choices:

        Satellite	Resolution	Revisit Frequency	Why Use It?
        Landsat 8 & 9 (NASA/USGS)	30m (multispectral), 100m (thermal)	16 days	Tracks pre/post-fire vegetation and burn severity with great detail.
        Sentinel-2 (ESA)	10m (RGB, NIR), 20m (SWIR)	5 days	High-resolution images for fire risk classification and early warnings.
        MODIS (Terra/Aqua, NASA)	250m (fire detection), 1km (thermal)	Daily	Provides historical fire perimeters and active fire locations.
        VIIRS (Suomi NPP & NOAA-20)	375m (fire detection), 750m (thermal)	Daily	Real-time fire monitoring, capturing active hotspots.
        Sentinel-1 (ESA)	5m - 20m	6-12 days	SAR imaging for vegetation moisture & burned area mapping.
        ALOS-2 (JAXA)	10m - 100m	14 days	L-band SAR for detecting dry fuel and terrain changes.
        Additional ground data sources:

        1). ERA5 Climate Reanalysis (ECMWF): Provides historical & real-time temperature, wind, and humidity data.

        2). NOAA NWS Weather Data: Near real-time humidity, wind, and temperature.

        3). Alaska Fire Service (AFS) Wildfire Data: Historical ignition source data (lightning, human activity).

        Current Status: This project is currently in the research stage.

        Expected Outcomes: This project aims to develop a deep-learning model that predicts wildfire risk in Alaska using a combination of satellite and ground-based weather data. The expected outcome of this project would involve both the dataset preprocessing pipeline and the performance of the developed model. Especially, the dataset preprocessing would include how to process the pre-fire and post-fire images efficiently and integrate the ground-based data with satellite imagery. Expected outcomes include:

        Minimum viable product (MVP):

        Fire risk classification: Given pre-fire satellite images, the model predicts the probability of a fire occurring within a defined time frame like 1 month, 3 months, or 6 months. The classifications should be "High Fire Risk," "Moderate Risk," or "No Risk."

        1). Data pipeline development:

        Preprocessing satellite images: Band selection, geospatial cropping, cloud removal (For this step, we are mostly interested in analyzing Sentinel-2 data);

        Synthetic Aperture Radar (SAR) analysis: Extracting fuel moisture & terrain features (For this step, we are mostly interested in extracting information like vegetation density and soil moisture from Sentinel-1 SAR data);

        Time-series weather data integration: Incorporating temperature, wind, and humidity. We have access to past decades of weather data for almost the past 30 years for multiple different places in Alaska.

        2). Model training and prediction:

        A hybrid model such as CNN-LSTM that analyzes satellite data and time-series weather trends (CNN-LSTM is just an example. We are open to multiple different types of analysis methodology);

        A web-based GIS dashboard to visualize fire-prone regions in Alaska;

        A report on model performance and fire risk metrics.

        Required Skills: Python. Experience with deep learning and machine learning.

        Code Challenge: Experience with multi-band satellite imagery, geospatial data processing (like ArcGIS Pro), and remote sensing.

        Source Code: https://github.com/YaliWang2019/AK-Satellite-Imagery-Wildfire-Prediction (New Project)

        Discussion Forum: https://github.com/YaliWang2019/AK-Satellite-Imagery-Wildfire-Prediction/discussions

        Effort: 350 Hours

        Difficulty Level: Medium/Hard

        You are welcome to propose new open-source project ideas, especially those that serve the state of Alaska and its people. Please use the below template to create new project ideas. However, if you are proposing a new project idea as a contributor, make sure they are relevant to Alaska specifically and the circumpolar north in general. Also, contact potential mentors from the above-listed mentors and confirm their interest in your project idea before drafting an entire proposal based on your own idea.

        ~~~~~~~~~~
        
        [14] Support for Logarithmic Number Systems in Large Language Models.

        Mentors: Mark Arnold (markgarnold -at- yahoo.com) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: The Logarithmic Number System (LNS) is an alternative to built-in Floating Point (FP), which makes multiplication and division easy at the expense of more difficult addition. Using overloaded operators, xlnscpp provides an open-source C++ library for both 16- and 32-bit LNS arithmetic. Interest in fabricating LNS hardware has grown since it may reduce power consumption for applications that tolerate approximate results, such as deep learning (see [1]-[5]). Although LNS has been studied extensively for feed-forward networks, only recently [6] has LNS been considered for Large Language Models (LLMs).

        LLMs consist of two main computations: a) feed-forward neural networks for which LNS has been shown to be useful, and b) an operation known as attention. The training of an LLM produces weights for both of these computations, which are often quantized to reduce data storage requirements. These quantized weights are reconstructed (usually in either 16- or 32-bit FP) and operated on by vectors of tokens (usually in similar FP format).

        Existing LLM engines, such as the open-source llama.cpp, perform vector/matrix/tensor operations (mostly matrix multiply) between the FP tokens and the weights (in a variety of formats, not including LNS).

        llama.cpp uses a library called ggml to do the actual math. The design of ggml supports a variety of FP hardware, such as CPUs and GPUs.

        Current Status: xlnscpp is not supported by llama.cpp or ggml. Weights can be stored in a variety of built-in int or FP formats instead of LNS. Matrix operations are carried out in FP.

        Expected Outcomes: The goal of this project is to provide support for xlnscpp instead of FP in ggml (and indirectly) llama.com. At a minimum, this involves modifying ggml to support a "virtual" LNS "machine" using xlnscpp to perform the actual LNS computation, but which appears to the calling llama.cpp like another hardware platform, like a GPU. The storage format of the quantized weights would still be the same, but they would be converted to LNS for computations like attention on LNS-format tokens. It is not expected that the speed would be as fast as if hardware FP were used, although a design that minimizes the slowdown is desirable (for instance, converting to LNS once, and reusing LNS many times, much as data is transferred to GPU memory and reused many times there). The purpose is a proof of concept that LNS yields valid output from an LLM. The design needs to implement enough ggml features to support an actual LLM, like Deepseek.

        Required Skills: C++ and some familarity with LLMs

        Code Challenge:

        Run the xlns16test.cpp and xlns32test.cpp examples.

        Go through the ggml example for 32-bit FP matrix multiplication on CPU ( https://huggingface.co/blog/introduction-to-ggml) which illustrates concepts like: ggml_backend (the code that does the computation on a GPU or CPU), ggml_context (a "container" that holds data), ggml_cgraph: (what computation the backend performs), ggml_backend_buffer: (hold the data of multiple tensors), and ggml_backend_buffer_type: (a "memory allocator" connected to each ggml_backend). This is quite involved because of the ggml_backend concept. Such experience will help you design a new ggml_backend for LNS (which your design proposal will describe as running on CPU using xlnscpp).

        Write a standalone C++ program that has a function to do 32-bit FP matrix multiply with a main program that prints the FP result. Test it with the same matrix data as the previous ggml example. (Hint: use nested for loops to compute the sum of products that form the matrix product).

        Modify this program to include xlns32.cpp (define xlns_ideal first) and perform the internal computation in LNS format. The main program and the signature of the function it calls remain the same (32-bit FP), which requires that the function convert to/from LNS before and after the matrix multiply. (Hint: if you do it properly, the overloaded xlnscpp assignment operator takes care of this automatically.) The sum of products should be computed entirely in LNS (not FP). Notice the numeric results are close to what FP produces.

        Modify the program to include xlns16.cpp instead. Notice the numeric results are slightly less accurate (the 16-bit LNS product is stored in the 32-bit FP result). This illustrates the tradeoff of using reduced precision LNS, which is what we want to experiment with in this project.

        These code challenges provide possible insight as to how the LNS-CPU backend your design proposal will describe can "look like" an FP backend to llama.cpp. When data would be transferred to the backend, it is converted to LNS. When data is transfered back to llama.cpp, it is converted back to 32-bit FP. This is one idea for this project. You may incorporate improvements to this concept in your design proposal that considers the features of ggml.

        References:

        [1] G. Alsuhli, et al., “Number Systems for Deep Neural Network Architectures: A Survey,” https://arxiv.org/abs/2307.05035, 2023.

        [2] M. Arnold, E. Chester, et al., “Training neural nets using only an approximate tableless LNS ALU”. 31st International Conference on Application-specific Systems, Architectures and Processors. IEEE. 2020, pp. 69–72. https://doi.org/10.1109/ASAP49362.2020.00020

        [3] O. Kosheleva, et al., “Logarithmic Number System Is Optimal for AI Computations: Theoretical Explanation of Empirical Success”, https://www.cs.utep.edu/vladik/2024/tr24-55.pdf

        [4] D. Miyashita, et al., “Convolutional Neural Networks using Logarithmic Data Representation,” https://arxiv.org/abs/1603.01025, Mar 2016.

        [5] J. Zhao et al., “LNS-Madam: Low-Precision Training in Logarithmic Number System Using Multiplicative Weight Update,” IEEE Trans. Computers, vol. 71, no. 12, pp.3179–3190, Dec. 2022, https://doi.org/10.1109/TC.2022.3202747

        [6] P. Haghi, C. Wu, Z. Azad, Y. Li, A. Gui, Y. Hao, A. Li, and T. T. Geng, “Bridging the Gap Between LLMs and LNS with Dynamic Data Format and Architecture Codesign ,” in 2024 57th IEEE/ACM International Symposium on Microarchitecture (MICRO). Los Alamitos, CA, USA: IEEE Computer Society, Nov. 2024, pp. 1617–1631. https://doi.ieeecomputersociety.org/10.1109/MICRO61859.2024.00118

        Source Code: https://github.com/xlnsresearch/xlnscpp

        Discussion Forum: https://github.com/xlnsresearch/xlnscpp/discussions

        Effort: 350 Hours

        Difficulty Level: Hard

        ~~~~~~~~~~

        [15] Time and Ordering in Beehive.

        Mentors: Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu) and David Moxley (dpmoxley -at- alaska.edu)

        Overview: Beehive was initiated as a collaboration between the University of Alaska Anchorage Departments of Computer Science and Human Services, but grew largely into a software platform through open-source contributions. Beehive seeks to create a digital approach to translating the digitalization of art and photographic images into a digital database that stores in retrievable formats those images for use in advancing the delivery of human services and health care to people who experience considerable vulnerability and marginalization within the community. One of the project goals is to extend the current Beehive software as a repository of photomemories (a 2D projection of 3D spaces) X time. This project aims to extend Beehive with these additional capacities and develop data mining algorithms to support this use case of photos as frozen snapshots in an individual's life.

        Current Status: The current Beehive prototype does not consider the complexities of time and ordering in the use of behavioral patterns and narratives in the journey to recovery.

        Expected Outcomes: In this project, the contributor will (1) extend the Beehive platform to support time and ordering as attributes across images, (2) develop algorithms to understand the impact of past events through the series of images and their narratives, and (3) implement data mining algorithms that could fetch and understannd evolving narratives around photomemories. We see spaces as 3D or 2D if we are referring to geolocations. Photos are 2D projections of a 3D space. There is one dimension that we omit in most of these projections. That is time. Time as a 4th dimension is not entirely new in research and applications. A search on spatiotemporal data and space-time continuum will give you plenty of examples, from climate change to science novels. Time, or more specifically, ordering, is an essential variable in behavior. Don't you wonder how you see places differently just because you have seen the same or something similar before? Where it gets more interesting or challenging (depending on how you see it) is how the time affects the exact location and even those "near" it. When we say "near," it is in terms of data, not necessarily in terms of geographical proximity. Sometimes, it is just a minor change, and the location is the same! In data mining, we call this "near duplicates." A change in the name of a place (can be a city or a restaurant!). Other times, these are two entirely different places. Perhaps, Kivalina has moved over time due to the Arctic Erosion (sadly). But that is still geographical proximity. For instance, your visit to Portugal will influence your visits to other Portuguese-speaking nations (such as Angola and Brazil) because they share a language and culture, although they are oceans apart. On a smaller scale, your experience in a library will impact how you perceive another library in a different location. How do we consider time (or in a more accurate sense, "relative time" or "ordering") in our analysis/perception? This is intertwined as the 4th dimension (or 3rd dimension, if you are already projecting the 3D world into a 2D map/photo). This project aims to understand these complexities in a prototype version over simulated/synthetic data.

        Required Skills: Database (MySQL or Mongo) and Python or Java. Experience and interest in data mining is a plus.

        Code Challenge: Prior experience with database management through established coding examples.

        Source Code: https://github.com/kathiraveluLab/beehive.

        Discussion Forum: https://github.com/KathiraveluLab/Beehive/discussions/

        Effort: 350 Hours

        Difficulty Level: Medium

        [N] PROJECT TITLE.

        Mentors: FIRSTNAME1 LASTNAME1 (email-address) and FIRSTNAME2 LASTNAME2 (email-address)

        Overview:

        Current Status:

        Expected Outcomes:

        Required Skills:

        Code Challenge:

        Source Code:

        Discussion Forum:

        Effort: 90/175/350 Hours

        Difficulty Level: Easy/Medium/Hard


          
    totalCharacters_of_ideas_content_parent: 54320
    totalwords_of_ideas_content_parent: 9380
    totalTokenCount_of_ideas_content_parent: 12130
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/alaska/
    idea_list_url: https://github.com/uaanchorage/GSoC




  - organization_id: 8
    organization_name: AnkiDroid
    no_of_ideas: 5
    ideas_content: |
    
          Multiple Profiles (175 hours)
          Problem
          Currently, AnkiDroid only allows a single profile as opposed to Anki (Desktop) and AnkiMobile (iphone) which allow multiple profiles. In particular, a family using a shared device will be able to have one profile per user, instead of sharing data. If you have multiple ankiweb accounts, you can sync all of them on your android. You can see discussion about this topic on https://github.com/ankidroid/Anki-Android/issues/2545.


          Expected Outcomes
          A user should be able to add a profile, sync this profile with an ankiweb account, switch between those accounts, and update the preference on a profile-by-profile level.
          Each profile should have its own collection, as in Anki. 

          There are at least three big questions that you need to consider. The UI, the backend, and the data structure. 
          The UI
          Firstly, you should design the UI. Your proposal should show us what would be the path the user will take to add a second profile, and switch to another profile. 
          The data structure
          AnkiDroid follows anki data structure. We have a folder, called Ankidroid, which contains all the files used to store user data. We should figure out a way to change the data structure in order to allow us to store data of multiple profiles.
          When the device does not use scoped storage, the AnkiDroid folder is in the top level general purpose folder of the AndroidDevice. We expect and hope most users understand this folder is used by ankidroid and leave it alone. We can’t just add other top level folders as this may clutter the user storage system and increase the risk a user delete folder, hence losing their data.
          The backend
          We need to figure out everything that will need to be changed. At the very least:
          We need a way to determine which profile is currently being used, and remember this information when ankidroid is restarted
          Each access to the data structure needs to take the profile into account, in order to access the right collection and media folder. This information should be available to the backend; so we should determine whether any change to the backend is required (probably not)
          We need to determine which preferences are profile based and which are used by the whole app. We need to update all preferences access to ensure we use the profile ones. We probably will need a lint rule that ensure that most preferences are profile-dependent unless there is a good reason not to. When creating an account, we need to determine whether to use default preferences or copy existing ones.


          Stretch goals
          If you have remaining time after the main project is done, there are two extensions that could be worth considering.

          Advertise this feature

          On the first update where multiple accounts are available, show a message to the user inviting them to add other accounts. This message should be similar to the message to new users.
          Saving space by avoiding to duplicate the media

          If multiple accounts have the same media (let’s say, the device is used by multiple users, who all should learn Ultimate Geography or Anking deck), ensure that the media are not duplicated in order to save storage on the device. This may require collaboration with the backend, because this optimization is not done on desktop. 
          It is probably worth doing it because storage is very precious on mobile.
          Language:
          Kotlin & XML
          Potentially some rust if we need to touch the backend for the stretch goal
          Difficulty: Medium
          Mentor(s):
          Arthur Milchior
          Shridhar Goel



          ~~~~~~~~~~



          Review Reminder (175 hours)
          Problem
          The user can request AnkiDroid to send them a daily notification in Android to remind them to review their cards if there are cards to review today.
          At least in theory. In practice those notifications have been broken for a long time. We tried years ago to solve the issue. Our solution was to remove most features, but what remains is still far from ideal.  It’s now clear that we should just scratch the current notification system and recreate one from scratch (and automatically migrate users from the previous feature to the new one). 
          Expected Outcomes
          In your proposal, you should tell us what the notification system will look like.
          We need to know what user interface you plan to implement. Every journey the user can take.

          The most basic idea is to have a notification shown if any card is due. This is what we currently have. Also let the user decide at which hour the notification should be shown. Maybe the notification should have a snooze button, to remind the user later (when?)
          We could also consider adding notification for specific decks.
          If so, there should probably be a way to see all notifications currently planned, in order to easily remove them, or edit them together.
          We should also find a way to test those notifications, manually and with automated tests. Ensuring they only trigger once a day in order not to overwhelm the user.
          You may consider reaching users over reddit and the forum in order to gather feedback 

          Language:
          EITHER:
          Kotlin & XML
          Difficulty: Hard
          Mentor(s):
          Arthur Milchior
          criticalAY


          ~~~~~~~~~~

          Note Editor: Note Type Preview (175 hours)
          Problem
          AnkiDroid is a flashcard app with a complex HTML/field-based templating engine. We currently have difficulties explaining a number of concepts to new users, both while onboarding, and for intermediate users:
          The unexpected fact that the user adds ‘notes’ to the app, not ‘cards’
          One note can generate multiple cards
          Various ‘Note Types’ have unique properties
          A user can create or download additional note types
          Currently, the user is provided with a text-based selection screen:

          Expected Outcomes
          In order to resolve the above issues, we want to modify this screen to provide a preview of each note type available in the system, showing
          The number of cards which will be produced when the note type is used
          A visual preview of how each of the cards will look
          Each card has a separate HTML template, so the designs may vary
          Taking into account some special features: 
          A note type may request that the user types in the answer
          Cloze deletions: 1 input produces 1…n cards
          Image occlusion: 1 input
          The ability to open our Card Template Editor
          The screen should allow a user to open up our Note Type Management screen and our manual. We should aim for the screen to prefer graphical elements over text
          Language:
          EITHER:
          Kotlin & XML
          If the screen is Android-specific
          Svelte (Typescript + HTML)
          If the screen is to be integrated into all Anki clients
          Difficulty: Medium
          Mentor(s):
          David Allison
          criticalAY

          ~~~~~~~~~~



          Tablet & Chromebook UI (175/350 hours)
          Problem
          AnkiDroid was initially designed for Android mobile phones. Over the years, Android has come to tablets and Chromebooks, but our UI has continued to be designed around the mobile phone.

          We currently have ~10% of our users on Tablets or Chromebooks, and we want to improve their user experience using the app, both with the aim to improve the user experience for our existing users, and increasing the number of users who can effectively use our app on larger devices

          Sanjay Sargam greatly improved the user experience on table and chromebook through GSoC 24’, and I invite you to read his report. Still, much remains to do, and what was done can certainly be polished.
          Expected Outcomes
          This primarily depends on your proposal. 
          Any screen in the app is open for your suggestions. 

          Suggestions
          Show NoteEditor and Previewer Side by Side
          Currently, the NoteEditor and Previewer are separate screens in AnkiDroid. On mobile devices, this makes sense due to limited scree n space. However,on tablets and Chromebooks, users have larger displays, and constantly switching between editing and previewing can feel cumbersome.

          Resizable Layout in DeckPicker and CardTemplateEditor
          The goal is to introduce a draggable slider that lets users dynamically adjust the size of two sections.

          Language: Kotlin, XML
          Difficulty: Medium
          Mentor(s):
          David Allison
          Arthur Milchior
          Sanjay Sargam


          ~~~~~~~~~~

          Additional Widgets (175/350 hours)
          Problem
          Widgets were introduced to AnkiDroid in 2010. These provide significant benefit to our power users and we started using them through GSoC 24. I invite you to read last year’s contributor’s report to see what was done.

          
          Expected Outcomes
          Android 12 Widget-based functionality is evaluated and integrated with the widgets when appropriate


          The GSoC proposal is expected to propose additional widgets that would be useful to our users
          Language: Kotlin, XML, UI & UX
          Difficulty: Medium
          Mentor(s):
          David Allison
          criticalAY





          
    totalCharacters_of_ideas_content_parent: 9691
    totalwords_of_ideas_content_parent: 2448
    totalTokenCount_of_ideas_content_parent: 1986
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/ankidroid/
    idea_list_url: https://docs.google.com/document/d/1Va6IWEYcWTkK4KDtyoFxtOKzpdcYe54GdrVpuMcFvlI/edit?pli=1&tab=t.0



  - organization_id: 9
    organization_name: Apache DataFusion
    no_of_ideas: 11
    ideas_content: |
        
        Implement Continuous Monitoring of DataFusion Performance
        Description and Outcomes: DataFusion lacks continuous monitoring of how performance evolves over time – we do this somewhat manually today. Even though performance has been one of our top priorities for a while now, we didn’t build a continuous monitoring system yet. This linked issue contains a summary of all the previous efforts that made us inch closer to having such a system, but a functioning system needs to built on top of that progress. A student successfully completing this project would gain experience in building an end-to-end monitoring system that integrates with GitHub, scheduling/running benchmarks on some sort of a cloud infrastructure, and building a versatile web UI to expose the results. The outcome of this project will benefit Apache DataFusion on an ongoing basis in its quest for ever-more performance.

        Category: Tooling

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): alamb and mertak-synnada

        Skills: DevOps, Cloud Computing, Web Development, Integrations

        Expected Project Size: 175 to 350 hours*

        ~~~~~~~~~~

        Supporting Correlated Subqueries
        Description and Outcomes: Correlated subqueries are an important SQL feature that enables some users to express their business logic more intuitively without thinking about “joins”. Even though DataFusion has decent join support, it doesn’t fully support correlated subqueries. The linked epic contains bite-size pieces of the steps necessary to achieve full support. For students interested in internals of data systems and databases, this project is a good opportunity to apply and/or improve their computer science knowledge. The experience of adding such a feature to a widely-used foundational query engine can also serve as a good opportunity to kickstart a career in the area of databases and data systems.

        Category: Core

        Difficulty: Advanced

        Possible Mentor(s) and/or Helper(s): jayzhan-synnada and xudong963

        Skills: Databases, Algorithms, Data Structures, Testing Techniques

        Expected Project Size: 350 hours

        ~~~~~~~~~~

        Improving DataFusion DX (e.g. 1 and 2)
        Description and Outcomes: While performance, extensibility and customizability is DataFusion’s strong aspects, we have much work to do in terms of user-friendliness and ease of debug-ability. This project aims to make strides in these areas by improving terminal visualizations of query plans and increasing the “deployment” of the newly-added diagnostics framework. This project is a potential high-impact project with high output visibility, and reduce the barrier to entry to new users.

        Category: DX

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): eliaperantoni and mkarbo

        Skills: Software Engineering, Terminal Visualizations

        Expected Project Size: 175 to 350 hours*

        ~~~~~~~~~~

        Robust WASM Support
        Description and Outcomes: DataFusion can be compiled today to WASM with some care. However, it is somewhat tricky and brittle. Having robust WASM support improves the embeddability aspect of DataFusion, and can enable many practical use cases. A good conclusion of this project would be the addition of a live demo sub-page to the DataFusion homepage.

        Category: Build

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): alamb and waynexia

        Skills: WASM, Advanced Rust, Web Development, Software Engineering

        Expected Project Size: 175 to 350 hours*

        ~~~~~~~~~~

        High Performance Aggregations
        Description and Outcomes: An aggregation is one of the most fundamental operations within a query engine. Practical performance in many use cases, and results in many well-known benchmarks (e.g. ClickBench), depend heavily on aggregation performance. DataFusion community has been working on improving aggregation performance for a while now, but there is still work to do. A student working on this project will get the chance to hone their skills on high-performance, low(ish) level coding, intricacies of measuring performance, data structures and others.

        Category: Core

        Difficulty: Advanced

        Possible Mentor(s) and/or Helper(s): jayzhan-synnada and Rachelint

        Skills: Algorithms, Data Structures, Advanced Rust, Databases, Benchmarking Techniques

        Expected Project Size: 350 hours

        ~~~~~~~~~~

        Improving Python Bindings
        Description and Outcomes: DataFusion offers Python bindings that enable users to build data systems using Python. However, the Python bindings are still relatively low-level, and do not expose all APIs libraries like Pandas and Polars with a end-user focus offer. This project aims to improve DataFusion’s Python bindings to make progress towards moving it closer to such libraries in terms of built-in APIs and functionality.

        Category: Python Bindings

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): timsaucer

        Skills: APIs, FFIs, DataFrame Libraries

        Expected Project Size: 175 to 350 hours*

        ~~~~~~~~~~

        Optimizing DataFusion Binary Size
        Description and Outcomes: DataFusion is a foundational library with a large feature set. Even though we try to avoid adding too many dependencies and implement many low-level functionalities inside the codebase, the fast moving nature of the project results in an accumulation of dependencies over time. This inflates DataFusion’s binary size over time, which reduces portability and embeddability. This project involves a study of the codebase, using compiler tooling, to understand where code bloat comes from, simplifying/reducing the number of dependencies by efficient in-house implementations, and avoiding code duplications.

        Category: Core/Build

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): comphead and alamb

        Skills: Software Engineering, Refactoring, Dependency Management, Compilers

        Expected Project Size: 175 to 350 hours*

        ~~~~~~~~~~

        Ergonomic SQL Features
        Description and Outcomes: DuckDB has many innovative features that significantly improve the SQL UX. Even though some of those features are already implemented in DataFusion, there are many others we can implement (and get inspiration from). This page contains a good summary of such features. Each such feature will serve as a bite-size, achievable milestone for a cool GSoC project that will have user-facing impact improving the UX on a broad basis. The project will start with a survey of what is already implemented, what is missing, and kick off with a prioritization proposal/implementation plan.

        Category: SQL FE

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): berkaysynnada

        Skills: SQL, Planning, Parsing, Software Engineering

        Expected Project Size: 350 hours


        ~~~~~~~~~~

        Advanced Interval Analysis
        Description and Outcomes: DataFusion implements interval arithmetic and utilizes it for range estimations, which enables use cases in data pruning, optimizations and statistics. However, the current implementation only works efficiently for forward evaluation; i.e. calculating the output range of an expression given input ranges (ranges of columns). When propagating constraints using the same graph, the current approach requires multiple bottom-up and top-down traversals to narrow column bounds fully. This project aims to fix this deficiency by utilizing a better algorithmic approach. Note that this is a very advanced project for students with a deep interest in computational methods, expression graphs, and constraint solvers.

        Category: Core

        Difficulty: Advanced

        Possible Mentor(s) and/or Helper(s): ozankabak and berkaysynnada

        Skills: Algorithms, Data Structures, Applied Mathematics, Software Engineering

        Expected Project Size: 350 hours

        ~~~~~~~~~~

        Spark-Compatible Functions Crate
        Description and Outcomes: In general, DataFusion aims to be compatible with PostgreSQL in terms of functions and behaviors. However, there are many users (and downstream projects, such as DataFusion Comet) that desire compatibility with Apache Spark. This project aims to collect Spark-compatible functions into a separate crate to help such users and/or projects. The project will be an exercise in creating the right APIs, explaining how to use them, and then telling the world about them (e.g. via creating a compatibility-tracking page cataloging such functions, writing blog posts etc.).

        Category: Extensions

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): alamb and andygrove

        Skills: SQL, Spark, Software Engineering

        Expected Project Size: 175 to 350 hours*

        ~~~~~~~~~~

        SQL Fuzzing Framework in Rust
        Description and Outcomes: Fuzz testing is a very important technique we utilize often in DataFusion. Having SQL-level fuzz testing enables us to battle-test DataFusion in an end-to-end fashion. Initial version of our fuzzing framework is Java-based, but the time has come to migrate to Rust-native solution. This will simplify the overall implementation (by avoiding things like JDBC), enable us to implement more advanced algorithms for query generation, and attract more contributors over time. This project is a good blend of software engineering, algorithms and testing techniques (i.e. fuzzing techniques).

        Category: Extensions

        Difficulty: Advanced

        Possible Mentor(s) and/or Helper(s): 2010YOUY01

        Skills: SQL, Testing Techniques, Advanced Rust, Software Engineering

        Expected Project Size: 175 to 350 hours*

        *There is enough material to make this a 350-hour project, but it is granular enough to make it a 175-hour project as well. The student can choose the size of the project based on their availability and interest.

          
    totalCharacters_of_ideas_content_parent: 10170
    totalwords_of_ideas_content_parent: 1940
    totalTokenCount_of_ideas_content_parent: 2086
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/apache-datafusion/
    idea_list_url: https://datafusion.apache.org/contributor-guide/gsoc_project_ideas



  - organization_id: 10
    organization_name: ArduPilot
    no_of_ideas: 6 
    ideas_content: |
          Non-GPS Position Estimation Using 3D Camera and Pre-Generated Map¶
          Skills required: Python, C++

          Mentor: Randy Mackay

          Expected Size: 175h

          Level of Difficulty: Hard

          Expected Outcome: Copter with low-cost 3D camera estimates its local position by comparing the camera point cloud to a pre-generated 3D map

          The goal of this project is to allow a Copter to estimate its local position using a low-cost 3D camera (e.g. Intel D465) by comparing the camera’s point cloud to a pre-generated 3D map. The steps involved include:

          Create a tool to capture a 3D map of the flight area. The resulting map should be loaded onto the vehicle’s companion computer (e.g. RPI5)

          Mount a low-cost 3D camera (e.g. Intel D465) onto an ArduPilot copter (e.g. EDU650 or similar) equipped with a companion computer

          Write localisation software (e.g. python code) to compare the output of the 3D camera to the pre-generated 3D map and send the estimated position to the vehicle’s EKF (see Non-GPS Position Estimation)

          Implement a simulator of the system (e.g. gazebo)

          Document the setup and operation for future developers and users

          Funding will be provided for hardware including a copter (e.g. Hexsoon EDU650), companion computer and 3D camera (e.g. Intel D465) if necessary

          ~~~~~~~~~~

          AI Chat WebTool for use with MP and/or QGC
          Skills required: JavaScript, OpenAI, Google Gemini

          Mentor: Randy Mackay

          Expected Size: 175h

          Level of Difficulty: Medium

          Expected Outcome: Web tool capable following a pilot’s verbal commands and converting them to MAVLink in order to control an ArduPilot multicopter

          This project involves re-implementing the MAVProxy’s AI chat module (see blog here) to run as a WebTool

          Once complete the WebTool should be capable of:

          Connecting to the vehicle via Mission Planner or QGC

          Responding to verbal or written questions and commands from the pilot

          Arming the vehicle

          Issuing takeoff commands and flying the vehicle a specified distance in any direction

          Changing the vehicle’s flight mode

          Most of the development can be completed using the SITL simulator and any OpenAI or Google Gemini usage costs will be covered

          ~~~~~~~~~~
           
          AI Chat Integration with all WebTools¶
          Skills required: JavaScript, OpenAI, Google Gemini

          Mentor: Randy Mackay

          Expected Size: 175h

          Level of Difficulty: Medium

          Expected Outcome: All WebTools include AI chat to help users understand and use the tool

          This project involves adding an OpenAI or Google Gemini chat window into some or all of the ArduPilot Webtools

          Once complete some or all of the WebTools should:

          Include a new chat widget allowing users to ask an AI assistant questions about the tool using text or voice

          Allow the AI assistant to operate the tool based on user input (e.g. push buttons, change zoom of graphs, etc)

          The top priority WebTool is the “UAV Log viewer” although simpler tools like the “Hardware Report” could be a good starting point

          Most of the development can be completed using the SITL simulator and any OpenAI or Google Gemini usage costs will be covered
          ~~~~~~~~~~


          Gazebo Plug-in Model of a Motor¶
          Skills required: Gazebo, C++

          Mentor: Nate Mailhot

          Expected Size: 175h

          Level of Difficulty: Medium

          Expected Outcome: ArduPilot Gazebo plugin simulates a Motor

          As part of the ArduPilot_Gazebo plugin, we ask a student to model the electromechanical properties of a motor (no thrust/aero, just the motor angular acceleration/power itself)
          ~~~~~~~~~~

          SITL AI Reinforcement Learning Concept Script¶
          Skills required: Gaazebo, Lua, AI

          Mentor: Nate Mailhot

          Expected Size: 175h

          Level of Difficulty: Medium

          Expected Outcome: Lua script that uses re-inforcement learning to automate changing some parameters

          An AP-SITL reinforcement learning script concept, focuses on using Lua applets or some python to automate parameter changes according to some basic implementation of online reinforcement learning (actor-critic/SARSA/Q-learning)
          ~~~~~~~~~~

          SITL Test Script for Controls Testing¶
          Skills required: Gaazebo, Python

          Mentor: Nate Mailhot

          Expected Size: 175h

          Level of Difficulty: Medium

          Expected Outcome: Python code that allows easily setting up an AP vehicle in SITL for controls testing

          A safe “for education/rookies” SITL test script that strips away the majority of complexity in set-up and gives a Copter (and Plane if time permits) that requires some basic tuning and gives hints/pointers in a UI (this could lower the threshold for earlier year mech/electrical engineers to get their hands dirty on some software and try out basic controls testing)

          
    totalCharacters_of_ideas_content_parent: 5201
    totalwords_of_ideas_content_parent: 1290
    totalTokenCount_of_ideas_content_parent: 1143
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/ardupilot/
    idea_list_url: https://ardupilot.org/dev/docs/gsoc-ideas-list.html


  - organization_id: 11
    organization_name: AsyncAPI
    no_of_ideas: 9
    ideas_content: |
          1) Enhancing Performance and Reliability of AsyncAPI CLI
          Improve the AsyncAPI CLI by optimizing performance, enhancing test reliability, and introducing long-requested features such as publishing and syncing AsyncAPI files with remote repositories.

          🎯 Outcome: Achieve a faster CLI execution, stable tests, file sync/publish support, and enhanced validation.
          🛠️ Skills Required: JavaScript/TypeScript, Node.js, Testing Frameworks, API, and testing automation.
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @AayushSaini101 | @Souvikns
          ⏳ Length: 175 Hours


          ~~~~~~~~~~
          2) AI-Powered Assistant for AsyncAPI
          Build an AI-powered assistant fine-tuned on AsyncAPI to provide accurate answers, generate code snippets, debug specifications, and recommend best practices.

          🎯 Outcome: A fine-tuned LLM-powered chatbot integrated with AsyncAPI’s ecosystem for enhanced developer support.
          🛠️ Skills Required: Javascript/Typescript, Machine Learning (LLMs), NLP, OpenAI/Llama, Chatbot Integration.
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @AceTheCreator
          ⏳ Length: 175 Hours

          ~~~~~~~~~~
          3) AsyncAPI Generator Maintainership
          This initiative aims to guide you from contributing to maintaining the project. You'll gain insight into the responsibilities of a maintainer, which involve tasks beyond mere coding.

          🎯 Outcome: Responsible for the project's future and continuous improvement.
          🛠️ Skills: JavaScript/TypeScript, testing libraries, Docker, virtualization, and test automation.
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @derberg
          ⏳ Length: 350 Hours

          ~~~~~~~~~~
          4) AsyncAPI Conference Website UI Kit Development
          Develop a comprehensive UI Kit to enhance design consistency, modularity, and maintainability of the AsyncAPI Conference website.

          🎯 Outcome: A structured UI Kit with reusable components, Storybook integration, and improved design consistency.
          🛠️ Skills Required: React, TypeScript, Storybook, UI/UX Design, Component Development.
          🧩 Difficulty: Medium
          👩🏿‍🏫 Mentor(s): @AceTheCreator
          ⏳ Length: 175 Hours

          ~~~~~~~~~~
          5) VS Code Extension Maintainership
          This initiative will guide you from contributing to becoming a maintainer of the VS Code AsyncAPI Preview extension. You'll learn the responsibilities of a maintainer, including code contributions, issue triaging, release management, and community engagement.

          🎯 Outcome: Taking ownership of the VS Code extension to ensure its long-term stability and improvement.
          🛠️ Skills Required: TypeScript/JavaScript, VS Code Extensions, Spectral Linting, Testing, and Open Source Contribution.
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @ivangsa
          ⏳ Length: 350 Hours

          ~~~~~~~~~~
          6) Java + Quarkus Template for AsyncAPI Generator
          Develop a new AsyncAPI Generator template for Java with Quarkus, leveraging its growing adoption in cloud-native development.

          🎯 Outcome: A fully functional Java + Quarkus template for generating AsyncAPI-based applications.
          🛠️ Skills Required: Java, Quarkus, Templating Engines (Nunjucks/Handlebars), AsyncAPI Generator.
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @AayushSaini101, @Souvikns
          ⏳ Length: 350 Hours
          ~~~~~~~~~~
          7) Refactor the Scripts inside the website and add Integration tests
          Add the script execution to a new folder inside the website, and add integration tests for those scripts.

          🎯 Outcome: A full Unit + Integration tests setup will be added for the scripts to fully test the functionalities
          🛠️ Skills Required: Typescript, Node js, Jest, Github actions
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @akshatnema
          ⏳ Length: 350 Hours
          ~~~~~~~~~~
          8) Add E2E tests for the Website critical flows
          Add E2E tests for the website where some of the critical flows (that are centered around user experience are tested thoroughly).

          🎯 Outcome: This project will ensure that we are not breaking any critical flows where user experience is our topmost priority
          🛠️ Skills Required: Typescript, Node js, E2E Testing, Github actions
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @sambhavgupta0705
          ⏳ Length: 175 hours
          ~~~~~~~~~~
          9) Redesign of website and addition of Dark theme
          Create new designs for the website pages based on the theme chosen by @Mayaleeeee and replicate those designs inside the website, along with the Dark mode theme.

          🎯 Outcome: This project will ensure that we are not breaking any critical flows where user experience is our topmost priority
          🛠️ Skills Required: Typescript, Node js, Figma, TailwindCSS
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @Mayaleeeee, @devilkiller-ag
          ⏳ Length: 350 hours

          
    totalCharacters_of_ideas_content_parent: 5231
    totalwords_of_ideas_content_parent: 1242
    totalTokenCount_of_ideas_content_parent: 1147
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/asyncapi/
    idea_list_url: https://github.com/asyncapi/community/blob/master/mentorship/summerofcode/2025/asyncapi-gsoc-ideas-page.md



  - organization_id: 12 
    organization_name: BRL-CAD 
    no_of_ideas: 25
    ideas_content: |
          Improving the k-File to BRL-CAD Converter
          Outline
          In the past years, we put some effort in the development of a LS-DYNA keyword file to BRL-CAD converter. Although we made great progress there, we still can't convert every k-file to g, i.e. the native BRL-CAD format. The goal of this project is to increase the number of covertable k-files.

          Details
          The sources of the current k-file to BRL-CAD converter can be found in the brlcad repository at src/conv/g. You have to compile BRL-CAD from its sources to work on this project and see the effects of your changes.

          Examples of k-files, which cannot be converted with k-g, can be found here: THUMS You can however use your own examples.

          Expected Outcome
          We expect an improved k-g LS-DYNA keyword file to BRL-CAD converting program as the outcome from this project.

          Project Properties
          Skills
          C/C++
          LS-DYNA or a similar FE solver software, which can read k-files (needed as reference for how the geometry should look like)
          Difficulty
          medium

          Size
          This project could have any size, short (90h), medium (175h) or long (350h), depending on the amount of functionality you want to add.

          Additional Information
          Potential mentor(s):
          Ali Haydar
          Daniel Rossberg
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com

          ~~~~~~~~~~

          Development and Build Support for Native Windows
          Outline
          OpenSCAD is multi-platform desktop application, with official support for Windows, macOS and Linux, and unoffical support for various other Unix-like OSes like FreeBSD.

          While OpenSCAD does support Windows, Windows development and build setup is a bit suboptimal:

          Windows binaries are built on Linux using the MXE cross compilation environment (https://mxe.cc). Build setup
          Windows native builds, including tests are done on msys2 (https://www.msys2.org) Build setup
          Goal of this project is to improve Windows support for native Windows development.

          Details
          Adjust OpenSCAD source code as needed to build OpenSCAD using MSVC
          Adjust the CMake build system as needed to support MSVC
          Find a way of managing building (and packaging if needed) 3rd party dependencies. OpenSCAD depends on a number of 3rd party packages (e.g. Qt, QScintilla2, CGAL, Manifold, GMP, MPFR, boost, OpenCSG, GLEW, Eigen, glib2, fontconfig, freetype2, harfbuzz, libzip, Bison, Flex, double-conversion). Not all of these have great Windows build support.
          Integrate library building/packaging into our Continuous Integration framework (e.g. GitHub Actions or CircleCI).
          Build OpenSCAD on MSVC + run tests natively for every PR, as we do for other build environments. This to make sure contributions don't fall out of maintenance.
          Establish support for debugging OpenSCAD in the MSVC debugger, and documentation on how to set that up, if necessary
          Write/update documentation on how to establish a native WIndows development environment
          Consider switching the official OpenSCAD Windows build to use MSVC.
          Prior work: openscad/openscad#4976

          Expected Outcome
          A native MSVC build environment for OpenSCAD is reasonable easy to set up, and such an environment is continuously integrated.

          Project Properties
          Skills
          Good understanding of the Windows OS and native components (DLLs, executables) on a low enough level to be able to debug odd behaviors.
          Experience using MSVC and native Windows development for C++ projects
          Good understanding of how 3rd party libraries are built and distributed.
          Experience with or interest in acquiring skills using CMake and writing custom CMake configs and macros
          Experience with GitHub CI or CircleCI is a bonus
          Difficulty
          medium

          Size
          long (350h)

          Additional Information
          Potential mentor(s): Marius Kintel (IRC: kintel), Torsten Paul (IRC: teepee)
          Note: None of the mentors have relevant Windows skills, but have excellent understanding on how all the relevant technologies work and how they are integrated with OpenSCAD. It's important that the candidate is able to acquire any necessary Windows-specific skills independently.
          Organization website: https://www.openscad.org/

          ~~~~~~~~~~

          Integrated language help feature in OpenSCAD #100
          Outline
          Add more interactive help features for built-in functions and modules. Right now there's already a nice summary of parameters linked as cheat sheet. Scope of this projects would be to use this information in extended form and make it available in a more direct way in the editor.

          Details
          Convert the cheat sheet information into machine readable format
          Find a way to generate the existing HTML format based on the core data
          Add context help to editor giving help for built-in functions and modules, e.g. by adding formatted help output to the console window, including the links to further documentation like the language manual on Wikibooks
          Expected Outcome
          Cheat sheet is integrated into the application and additional context help for built-in functions and modules is available.

          Project Properties
          Skills
          Programming language is C++
          GUI programming with the Qt framework
          Difficulty
          Easy

          Size
          Medium (175h)

          Additional Information
          Potential mentor(s): Marius Kintel (IRC: kintel), Torsten Paul (IRC: teepee)
          Organization website: https://www.openscad.org/


          ~~~~~~~~~~

          Create a compelling interface and functionality for the IfcOpenShell WASM / pyodide module #99

          Outline
          http://wasm.ifcopenshell.org/

          Details
          Expected Outcome
          Future Possibilities
          Project Properties
          Skills
          Difficulty
          Size
          Additional Information
          Potential mentor(s): NAME
          Organization website: https://
          Communication channels: https://******.zulipchat.com


          ~~~~~~~~~~

          Authoring interface for IFC4.3 alignment geometry in Bonsai #98
          Outline
          Industry Foundation Classes (IFC) offer the ability for rich information exchanges between modeling, analysis, planning, and other software tools in the Architecture, Engineering, and Construction (AEC) industry. Specifically, the latest release of IFC (version 4.3, also referred to as IFC4X3) adds linear referencing via alignment modeling, which is core to describing the construction and maintenance of infrastructure assets such as roads, bridges, and railways.

          Details
          Alignment import (read) capabilities have been added to IfcOpenShell and the Bonsai add-in for Blender. They have reached a state of maturity such that the next logic step is to enable alignment authoring (write) capabilities.

          Expected Outcome
          Alignment authoring will take place in Blender via the Bonsai add-in. A user-focused workflow has been developed and documented, along with preliminary user interface mockups. This project would add alignment authoring capabilities via new panels and other items within Blender. The ifcopenshell.api namespace will also need to be enhanced incrementally to support the new user interface tools.

          Project Properties
          Skills
          Understanding and general working knowledge of python.

          Difficulty
          Medium

          Size
          Medium (175 h)
          The participant focuses on authoring horizontal alignments via the PI method. This could be via interactive icons or primarily through a table-based interface. The user would need to be able to add, edit, and remove PI (point of intersection) points. Additionally the user would need to be able to adjust the radius that corresponds to each PI point. Though not strictly required for this project, the authoring tool would also enable definition and editing of entry and exit transition curve type (clothoid, sine spiral, polynomial spiral, etc.) and length.

          Long (350 h)
          PI-based alignment would be added for vertical and cant as well. A basic corridor modeling UI tools would be implemented to allow for sweeping geometry (open or closed profile) along an alignment curve to generate 3D linear geometry via IfcSectionedSolidHorizontal and related IFC entities.

          Additional information
          Mentors: Rick Brice @RickBrice & Scott Lecher @civilx64

          Organization website: https://ifcopenshell.org

          Communication channels: https://github.com/IfcOpenShell/IfcOpenShell/discussions

          Technical resources:

          https://docs.bonsaibim.org/guides/development/index.html

          Blender 4.3: Precise Modeling for Architecture, Engineering, and 3D Printing

          Python Scripting in Blender


          ~~~~~~~~~~

          Manifoldness repair 
          Outline
          Repair triangle soup that are not manifold.

          Details
          Basically, a valid solid mesh should be both manifold and has no self-intersection. However, models from the internet may contain defects. This project is about coming up with an algorithm that converts and repair a triangle soup into a manifold mesh.

          This will contain a lot of heuristics, basically what we need is:

          Stitching faces together, and maybe join faces that are close enough.
          Fill holes.
          Duplicate vertices and edges such that the result is a manifold in terms of connectivity.
          Expected Outcome
          Implementation of said algorithm.

          Future Possibilities
          Project Properties
          Skills
          C++
          Graph data structure.
          Algorithms.
          Difficulty
          Hard.

          Size
          Long (350h)

          Additional Information
          Potential mentor(s): @elalish @pca006132
          Organization website: https://manifoldcad.org/
          Communication channels: https://github.com/elalish/manifold/discussions

          ~~~~~~~~~~

          Overlap removal
          Outline
          Remove overlaps in meshes that contain self-intersection, assuming the mesh is a manifold.

          Details
          Basically, a valid solid mesh should be both manifold and has no self-intersection. However, models from the internet may contain defects. This project is about coming up with an algorithm that removes self-intersections.

          See elalish/manifold#289 for details about ideas for the algorithm.

          Expected Outcome
          Implementation of said algorithm.

          Future Possibilities
          Project Properties
          Skills
          C++
          Graph data structure.
          Algorithms.
          Difficulty
          Hard.

          Size
          Long (350h)

          Additional Information
          Potential mentor(s): @elalish
          Organization website: https://manifoldcad.org/
          Communication channels: https://github.com/elalish/manifold/discussions

          ~~~~~~~~~~

          Creation of an IFC geometry library in IfcOpenShell that uses Manifold

          Outline
          For the past 10 years, IfcOpenShell has had a tight coupling with OpenCASCADE as its only geometry library and OCCT providing the datatypes in the IfcOpenShell C++ APIs.

          In IfcOpenShell v0.8 an additional abstraction is introduced over the geometric concepts in IFC (taxonomy.h) and the evaluation of such concepts using pre-existing geometry libraries (AbstractKernel).

          Also in v0.8, CGAL is introduced as an additional runtime selectable choice besides OpenCASCADE, because of (a) it's extensive set of modules for analysis (e.g convex decomposition, skeleton, ...) and (b) it's arbitrarily robust (and precise) implementation of boolean operations using Nef polyhedra on a number type represents a binary tree of operands taking part in the construction of that number.

          Both OpenCASCADE and CGAL are high quality efforts, but quite complex and resulting in fairly large compiled object sizes. This project proposal aims at introducing Manifold as a 3rd geometry library implementation. Manifold is modern, efficient and robust.

          https://github.com/elalish/manifold

          cc @elalish just fyi.

          Expected Outcome
          Another AbstractKernel implementation that uses Manifold to evaluate a small set of geometrical concepts (boolean, extrusion, brep for example) in IFC. Expecting reasonable outcomes on a small building model (such as the Duplex A model) without necessarily resolving all complexities and corner cases encountered in that model.

          Future Possibilities
          Comparison between implementations and development of a hybrid composition of these libraries that based on prior inspection picks the most suitable implementation for a specific IfcProduct or representation item. For example, OpenCASCADE will likely still excel at curved surfaces (e.g nurbs), but suffers a monumental performance overhead when ingesting detailed triangular meshes (that are also prevalent in IFC) due the overheads of it BRep data model.

          Additional Information
          Potential mentor(s): Thomas Krijnen (aothms)



          ~~~~~~~~~~

          Turn BlenderBIM into a client for remote BIM-collaboration on existing OpenCDE-API-server with a graph backend

          Outline
          The project aim is to turn BlenderBIM into a client for remote BIM-collaboration and a client for remote BIM-model-sharing through a Common Data Environment (a CDE working as BIM/IFC-server) using the already developed OpenCDE API server and the OpenCDE API specifications provided by buildingSMART: BCF API and Documents API.

          OpenCDE API:s are open standards. This project will hence enable usage of BlenderBIM as a client on other BIM-servers that implements the OpenCDE API:s.

          Details
          An OpenCDE API server that implements all buildingSMART OpenCDE API:s (BCF API, Documents API and Foundation API) has been developed in python and the FastAPI framework. Solibri Office was used as a client for testing this server software during development.

          The code of the OpenCDE server is located in the IfcOpenShell repository here: https://github.com/IfcOpenShell/IfcOpenShell/tree/v0.7.0/src/opencdeserver

          The OpenCDE API:s is a set of open API-specifications provided by buildingSMART. https://github.com/buildingSMART/OpenCDE-API

          BIM Collaboration Format (BCF) API is used for collaboration on shared BIM models through a remote BCF-server. BCF API has the same purpose as BCF XML (which is a file format) but the difference is that the data is communicated as JSON through a BCF-server, instead of sending XML-files. https://github.com/buildingSMART/BCF-API
          Documents API is used communication between a client and a CDE (acc. ISO 19650-1). The purpose is a common data environement for sharing models, documents et.c. https://github.com/buildingSMART/documents-API
          Foundation API is used for authentication et.c. and must be implemented by any client or server that implements anyone of the other two OpenCDE API:s. https://github.com/buildingSMART/foundation-API
          To summarize: The model (the IFC data) will normally be shared to the server using Documents API, and downloaded form the server using Documents API. BCF API can be used for remote collaboration on the models located on the server et.c.

          The purpose of the open API specification is to enable independent development of clients and servers that can communication with eachother. A server has already been developed and shared as open source on IfcOpenShell. However, at the moment there is no open source client with a graphical user interface for the OpenCDE API:s. A python library for BCF API communication is available: https://pypi.org/project/bcf-client/.

          The aim of this project is to turn BlenderBIM into a OpenCDE-client (a client that already have BIM-capabilities) that can communicate remotely with (and make use of) the existing open source OpenCDE-server on: https://github.com/IfcOpenShell/IfcOpenShell/tree/v0.7.0/src/opencdeserver

          An add-on for GIT-collaboration have already been developed:

          https://blenderbim.org/docs/users/git_support.html
          https://www.youtube.com/watch?v=cJZhSCSSWdA
          Collaboration using Documents API and BCF API is just another way of collaboration. This way of collaboration might be more suitable for AEC-professionals who does not have experience of GIT. Som features of GIT are not possible. But other features that are possible when using the OpenCDE API:s are not possible using GIT.

          Expected Outcome
          The BlenderBIM can connect as a client to the OpenCDE API server using the Foundation API
          User management functionality is added to OpenCDE API server: Register, invite, delete users
          BlenderBIM is a BCF API client - can collaborate on BIM-models remotely using the already developed OpenCDE-server
          BlenderBIM is a Documents API client - can share/download BIM-models remotely with the already developed OpenCDE-server
          User interface in BlenderBIM for setting up OpenCDE-server on localhost and user management (inviting collegues, adding/deleting users et.c.)
          User interface in BlenderBIM for remote BIM collaboration using BCF API
          User interface in BlenderBIM for remote model download and sharing using Documents API
          Simplify the process of turning your computer into an OpenCDE-server and inviting colleages to collaborate on your BIM model
          Simplify the process of deploying the OpenCDE-server as a BIM-server to the cloud for remote collaboration with BlenderBIM as a client
          Extra: Implement som of the routes/endpoints of the OpenCDE API specifications that Solibri Office does not support. I.e. implement the full official buildingSMART open specifications using the open source server (OpenCDE API server) and open source client (BlenderBIM).

          Future Possibilities
          IFC-server capabilities: Round-tripping of IFC data between IFC STEP (or python or C++ objects in IfcOpenShell) and the OpenCDE API server graph DB. More info on storing IFC data as label property graph (LPG) here: https://www.sciencedirect.com/science/article/pii/S0926580523000389
          Potential synergies with the other GSoC project "Web-based UI integration with Blender" Web-based UI integration with Blender #87 because the Web-based UI could be hosted by the same OpenCDE API server as in this project.
          Visualization of IFC data as graph in that Web-based UI. For example using pyviz or similar tools.
          Project Properties
          Skills
          Python, including how to setup a minimal basic server on localhost using FastAPI. https://fastapi.tiangolo.com/
          Blender Python API to develop user interfaces in BlenderBIM.
          Cypher query language and any graph DB that implements Cypher (such as Neo4j or MemGraph). https://neo4j.com/docs/cypher-manual/current/introduction/
          API development.
          Difficulty
          Hard

          Size
          Long (350h)

          Additional Information
          Potential mentor(s): [Martin Wiss]
          Organization website: https://blenderbim.org/ http://ifcopenshell.org/
          Communication channels: OSArch

          ~~~~~~~~~~

          Geometry Verification and Validation GUI in Qt (AI Project)

          Outline
          Help develop a new GUI application that checks geometry for common issues and/or helps fix them.

          Details
          A new GUI is in prototype development (built on Arbalest) that checks geometry files for common verification and validation (V&V) issues such as topology errors, solidity errors, and more. It's very much an experimental work in progress and we'd like your help to make it complete. The overarching goal of this effort is to extend our prototype in a significant way, either improving usability, checking for more issues, improving the Qt GUI infrastructure integration, integrating workflow(s) for review and repair, or leveraging AI to identify and/or fix issues.

          Expected Outcome
          You will propose a complete project description that identifies the specific objectives you'll aim to achieve. It's expected that you'll leverage the previous work (talk with us to get access to those materials). The proposal should identify 3-10 primary objectives that are researched and specific, starting with our previous effort.

          We essentially want a tool that "compiles" geometry reporting warnings and errors for issues encountered, akin to compiling source code in Visual Studio or Eclipse. There are questions of application architecture to resolve (e.g., whether to extend 'arbalest', integrate 'qged', integrate 'gist', etc). We want the tool to be graphical and interactive. We want it to have the ability to generate reports for auditing. Some of those capabilities exist in isolation, but none exist as a tool tailor-made for 3D geometry V&V.

          Future Possibilities
          This is a long term priority project with future possibilities in:

          GUI infrastructure
          AI integration
          geometry healing and repair workflows
          geometry auditing
          geometry standards development
          Skills
          Qt, C/C++

          Difficulty
          Easy or Medium depending on the objectives

          Size
          long (350h) preferred, but medium (175h) also possible

          Additional Information
          Potential mentor(s): Sean Morrison
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com
          https://brlcad.org/design/v&v/


          ~~~~~~~~~~

          Blender UI / integration with voxelisation toolkit software

          Outline
          There is software known as the Voxelisation Toolkit (pip install voxec). It converts the 3D model into voxels (e.g. 3D cubes that represent geometry), analyses and transforms those voxels, and outputs statistics (e.g. distance between voxels, etc).

          Image

          Image

          Voxels are super cool and can be used to calculate head heights, resolve complex non-manifold geometry, egress distances, or concrete formwork areas and strutting distances, and air volume for mechanical calculations. All of this stuff is useful for engineers and construction professionals.

          This project is to add a UI in Blender to start making this general purpose analysis tool available to non-programmers.

          Details
          You will be expected to design an interface for the voxelisation toolkit, prepack some simple recipes, and write scripts that take the output (currently visualised as images or plots) and instead visualise the results in 3D by generating 3D coloured meshes that represent the output.

          Expected Outcome
          Bundle the voxelisation toolkit software with Blender.
          A UI to execute the voxelisation toolkit.
          Simple presets to run the toolkit.
          Visualise the output of the voxelisation analysis as a 3D coloured mesh.
          Future Possibilities
          Bundle scripts for common usecases, like formwork calculation, air volume calculation, or external / internal metadata addition.

          Project Properties
          Skills
          Python
          Difficulty
          Medium

          Size
          Medium to Long

          Additional Information
          Potential mentor(s): Dion Moult, Thomas Krijnen
          Organization website: https://blenderbim.org http://ifcopenshell.org
          Communication channels: https://osarch.org/chat


          ~~~~~~~~~~

          Features for CG artists to visualise beautiful IFC models in Blender 
          Outline
          The architecture, engineering, and construction industry creates 3D models of buildings. These models are generally quite poor and do not contain any textures, lighting, or high quality objects that are suitable for 3D rendering. They often hire artists to help create beautiful renders of their designs.

          This project will build utility functions and workflows to easily get beautiful pictures of 3D models.

          Details
          3D artists typically do the following steps to make a 3D model look beautiful. They:

          Set camera angles with specific camera settings, with "clay" (e.g. all white colours) materials.
          Add lights and sun / sky settings.
          Add simple colours and textures.
          Remodel low quality geometry
          Add new objects (e.g. entourage) to decorate the scene, like trees, grass, people, extra furniture, walruses, shrimp, etc.
          Set common compositing and post processing rules
          You will use the Blender Python API to set simple presets for most of these steps to allow less skilled artists to quickly setup renders. You will also setup a workflow to guide artists on how to organise their files relative to the IFC model and keep the IFC model separate so that when the IFC model is changed, the artists doesn't need to start from scratch or play spot the difference.

          You do not need to be an expert in 3D modeling or CG visualisation or rendering. You will be taught what type of settings and options are appropriate for presets and the details of the workflow. However, you will be expected to automate that detail (every aspect of the Blender settings can be set using Python trivially).

          You will also be expected to create a Blender interface to interact with the settings, e.g. a button to add camera, a button to set a preset sky, etc.

          Expected Outcome
          Note: scope is flexible and you may achieve less or more or different to the below:

          A graphical interface in Blender that relate to the 6 steps above
          Buttons to add cameras, set common camera aspect ratios and settings. Buttons to add common types of lights, set sun angles and sky settings with bundled HDRI textures.
          Buttons to add simple material presets.
          Buttons to mark an object to be replaced by another
          A few preset assets using Blender's built in asset tools to drag and drop in entourage.
          Future Possibilities
          Project Properties
          Skills
          Python (definitely required!)
          Artistic sense (do you like 3D graphics? rendering?) If you have ever rendered a 3D scene before, this is the project for you!
          Difficulty
          Easy to Medium

          Size
          Medium to Long

          Additional Information
          Potential mentor(s): Dion Moult
          Organization website: https://blenderbim.org http://ifcopenshell.org
          Communication channels: https://osarch.org/chat

          ~~~~~~~~~~

          Implement 3D mesh offset
          Outline
          Implement efficient 3D mesh offset, instead of using minkowski sum with high resolution spheres. (elalish/manifold#192)

          Details
          3D mesh offset is a useful feature that many users asked for, but is difficult to implement efficiently. Many users use minkowski sum with sphere to perform positive offset, but this can be very slow due to the need for exact convex decomposition.

          Our approach will only work for positive offset, negative offset can be implemented by performing additional mesh boolean operations, so this is not an issue. The approach has four phases:

          Figure out all pairs of faces that do not share any vertex and may overlap after offsetting. (let's call them conflict pairs)
          Cut the mesh in a way such that for each part, no two faces are in the same conflict pair. (decomposition step, requires monte carlo tree search)
          Perform the positive offset on each part, using a modified algorithm from Offset Triangular Mesh Using the Multiple Normal Vectors of a Vertex. Note that we need to figure out how to blend the surfaces for smooth results.
          Union the parts.
          Expected Outcome
          A fast 3D mesh decomposition algorithm!

          Project Properties
          Skills
          C++
          Graph data structure.
          Algorithms.
          Difficulty
          Hard.
          Size
          Long.
          Additional Information
          Potential mentor(s): @elalish @pca006132 @zalo
          Organization website: https://manifoldcad.org/
          Communication channels: https://github.com/elalish/manifold/discussions


          ~~~~~~~~~~

          Add fuzzing tests

          Outline
          Add more fuzzing tests for both 2D and 3D operations.

          Details
          Fuzzing is an effective technique to expose bugs in software. Fuzzing tests randomly generate structured inputs (according to specification), and test if the program crashes/failed assertions.

          This project aims to test 2D and 3D CSG operations on geometrically valid polygons/meshes. To do this, we will define a very simple AST for our CSG operations, and use the recursive domain feature of fuzztest for the tests.

          We will also randomly apply slight perturbation to make the valid geometry only epsilon-valid, to test for robustness of the algorithm.

          Expected Outcome
          Fuzz tests that test for union, intersection, difference, 2D extrude/revolve, etc.

          Project Properties
          Skills
          C++
          Basic understanding of graph data structure.
          Difficulty
          Medium
          Size
          Medium
          Additional Information
          Potential mentor(s): @pca006132
          Organization website: https://manifoldcad.org/
          Communication channels: https://github.com/elalish/manifold/discussions


          ~~~~~~~~~~

          Physically-Based Rendering (PBR) advanced shaders
          Outline
          Get BRL-CAD physically-based rendering working with advanced shaders.

          Details
          BRL-CAD recently integrated with Appleseed which provides physically-based rendering. It's presently a command-line renderer called 'art'. For art rendering to work, a shader and colors are specified on geometry. BRL-CAD has preliminary support for material objects including OSL shaders and MaterialX shaders in art, however their support has only been tested with basic shaders such as the Disney Principled Shader. It's hard-wired to single-file shaders.

          Expected Outcome
          The goal of this task will be to make art read and work with any OSL or MaterialX shader networks, including ones using texturing, emission, subsurface scattering, etc. applied to BRL-CAD geometry.

          Project Properties
          Skills
          Decent C/C++ skills
          Some basic familiarity with PBR.
          Basic familiarity with shaders.
          Difficulty
          medium

          Size
          long

          Additional Information
          Potential mentor(s): Sean Morrison
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com


          ~~~~~~~~~~

          Improve FreeCAD Hidden Line Removal
          Outline
          FreeCAD's Technical Drawing module (TechDraw) relies heavily on the OpenCascade Hidden Line Removal algorithms. These algorithms can be very slow, do not provide progress reporting and do not provide any linkage between the input shape and the output.

          Details
          The TechDraw module provides projections, section views and detail views of 3D model components and assemblies developed in FreeCAD modules such as Part, PartDesign and Draft.

          Expected Outcome
          a) develop new code for projecting shapes and creating the geometry for technical drawings.
          -or-
          b) modify the existing OpenCascade code as an enhancement.

          Project Properties
          Both OpenCascade and TechDraw are written in C++.

          Skills
          The student should have a good knowledge of C++ and be familar with graphics topics such as the painters algorithm, face detection and hidden line removal.
          Knowledge of technical drawing standards and previous exposure to Qt will be helpful. Familiarity with OpenCascade is a definite plus.

          Difficulty
          Hard

          Size
          long

          Additional Information
          Potential mentor(s): wandererfan
          Organization website: https://freecadweb.org
          Communication channels: https://forum.freecadweb.org


          ~~~~~~~~~~

          Continuation of a prior BRL-CAD GSoC effort
          Outline
          BRL-CAD has been participating in GSoC for over 10 years with nearly 100 students! Any past accepted projects can be submitted as a continuation project.

          Details
          You can find all past participants documented on BRL-CAD's wiki by selecting a given year (e.g., 2018). Even the most successful and completely integrated projects have room for improvement! If any of those past efforts for any prior year sound very interesting to you, you can propose a continuation effort for it.

          Of course, you will need to research the prior effort to determine the status of the work, whether code was integrated or is sitting pending integration in a patch, whether it's functional or was in an intermediate state, etc. You'll also want to come chat with us on Zulip to make sure there is mentoring support for it, but there usually is if you're passionate and independently productive.

          For your proposal, note that it's a continuation effort. Explain what you are doing and how it relates to the prior effort. It's strongly recommended that your development plan focus on production-quality integration aspects such as making sure there are no usability or user experience (UX) issues, no build integration issues, that testing is covered adequately, and with focus on UX.

          Expected Outcome
          The expected outcome of a continuation effort is new capability and features that are "complete", integrated, bug-free, and issue-free, in the hands of users. This means your project covers all vertical integration aspects of development integration including build system and usability / UX concerns. Not prototyped. Not simply rewritten or re-attempted.

          If the prior effort was integrated, your outcome will be specific polish, adaptiveness, and robustness improvements.

          If the prior effort was not integrated, your outcome will be issue-free integration that addresses prior issues preventing integration (which will require research and understanding on your part).

          Project Properties
          Skills
          This varies greatly by continuation. There are continuation projects for C/C++, Python, Javascript/Node.js, Tcl/Tk, OpenCL, OpenGL, Qt, GPGPU, and more.

          Difficulty
          Varies.

          Size
          You are welcome to scope your project medium (175h) or long (350h) depending on the objectives and development scope.

          Additional Information
          Potential mentor(s): Morrison (contact devs@brlcad.org)
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com

          ~~~~~~~~~~

          Implement AP242 STEP geometry importer for BRL-CAD
          Outline
          Implement a geometry importer for the ISO 10303 STEP AP242 standard.

          Details
          BRL-CAD has geometry import support for STEP AP203 (v1), but AP242 has emerged as its industry replacement. This project entails implementing as comprehensive import support as possible in BRL-CAD.

          In order to track implementation progress and manage development risk, you will need to track implementation coverage by setting up a dashboard similar to what is used by the CAx-IF -- it can be a simple text file or web page.

          Existing conversion support can be examined for AP203 and other formats in BRL-CAD's repository under src/conv/step

          Expected Outcome
          New AP242 importer that converts STEP entities into BRL-CAD's .g geometry file format.

          Future Possibilities
          AP242 export support...

          Project Properties
          Skills
          C/C++
          STEPcode

          Difficulty
          Hard.

          Size
          This project can be scoped medium (175h) or long (350h) depending on your familiarity and expertise, or you can propose a subset of entities in a shorter timeframe (note though that advanced boundary representation entities should be prioritized).

          Additional Information
          Potential mentor(s): Morrison (contact devs@brlcad.org)
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com

          ~~~~~~~~~~

          BRL-CAD Python bindings
          Outline
          Implement bindings for the BRL-CAD functionality to Python programming language

          Details
          There are long time on-going efforts to wrap BRL-CAD functionality with python code, e.g.

          https://github.com/kanzure/python-brlcad
          https://github.com/nmz787/python-brlcad-tcl
          These projects are however still in early development stages.

          Expected Outcome
          A Python module which can read and write BRL-CAD databases, and provide access to their contents to read, create, and modify the objects.

          Project Properties
          Skills
          C/C++
          Python
          Difficulty
          This project may be of easy or medium difficulty, depending on your familiarity and expertise.

          Size
          This project can be scoped medium (175h) or long (350h), depending on the amount of functionality you want to include.

          Additional Information
          Potential mentor(s):
          Daniel Rossberg
          Sean Morrison
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com


          ~~~~~~~~~~

          Webapp to create and check BIM project exchange requirements for IfcOpenShell
          Outline
          When projects exchange data, we often need to set contractual requirements about what data we expect to see in their CAD or Building information data. The is an international standard for describing project requirements in XML called the Information Delivery Specifications (IDS).

          There is a half-built webapp which allows viewing and minor editing of IDS files here: https://blenderbim.org/ifctester/

          Your job would be to finish this web app, building features for more editing, drag and drop from a library of specifications, adding and removing requirements, etc.

          Expected Outcome
          A working example of the web application.

          Project Properties
          Skills
          HTML, CSS, and vanilla Javascript (i.e. no frameworks).
          Difficulty
          Easy

          Additional Information
          Potential mentor(s): Dion Moult
          Organization website: https://ifcopenshell.org
          Communication channels: https://community.osarch.org , ##architect on Freenode , and https://github.com/IfcOpenShell/IfcOpenShell/issues


          ~~~~~~~~~~

          Scripts for generating simple animations (e.g. appear / disappear, bounce, appear left to right, fade in from above, etc)

          Outline
          Often, construction firms need to visualise animations of construction sequencing. A project timeline will be created, and related to individual model elements. For example, when a concrete slab is poured, it is linked to a 3D object called a slab. We need the ability to automatically generate animations from Blender where objects appear / disappear in various different ways when they start / end their task in the project timeline. The systems for describing project timelines is already in place, so now we need a little animation generator!

          Details
          Expected Outcome
          A series of small scripts that take objects and can automatically animate the visibility, locations, or staggered appearances of building elements, as well as sub elements, and basic scripts that correlate real world time to animation frames, and frames per second, and generate an animated timeline bar in various styles.

          Future Possibilities
          This animation system can be then used from BIM models either in Blender, FreeCAD, or via other software altogether, so it has quite a large impact on the ecosystem.

          Skills
          Basic knowledge of the principles of animation (keyframing)
          Basic Blender animation (you can do some tutorials and get up to speed pretty quick)
          Python
          Artistic sense! We should offer beautiful and elegant animations!
          Difficulty
          Easy

          Additional Information
          Potential mentor(s): Dion Moult
          Organization website: https://ifcopenshell.org
          Communication channels: https://community.osarch.org , ##architect on Freenode , and https://github.com/IfcOpenShell/IfcOpenShell/issues


          ~~~~~~~~~~

          NURBS Editing Support in BRL-CAD

          Outline
          Implement the prerequisites for NURBS editing in BRL-CAD's GUIs

          Details
          BRL-CAD has support for raytracing of NURBS surfaces implemented, but they are handed over as BLOBs to the openNURBS library. Beyond basic operations such as rotation and translation, the BRL-CAD core has no ability to edit them. This project would implement support for editing NURBS curves and surfaces in the BRL-CAD core, thus creating the prerequisites to handle them with higher level (i.e. GUI) tools.

          See this task's description in former GSoCs for some more information: https://brlcad.org/wiki/NURBS_Editing_Support

          The key-feature would be to have ged command(s) that lets you build NURBS objects from scratch. This could be done by having a declarative ASCII description of these entities and/or wrapping the openNURBS library by a scripting language.

          Describe in your proposal which approach you want to use and why. You may let inspire you by solutions in other programs:

          NURBS-Python: https://github.com/orbingol/NURBS-Python
          Blender: https://blender.stackexchange.com/questions/7020/create-nurbs-surface-with-python
          Web3D: https://www.web3d.org/x3d/content/examples/Basic/NURBS/
          3DSMax/Maya: https://help.autodesk.com/view/3DSMAX/2016/ENU/?guid=__files_GUID_75CD4DE9_8024_4E25_B147_0A0EC8B10031_htm
          Ayam: http://ayam.sourceforge.net/docsdraft/ayam-6.html
          Expected Outcome
          Implementing the necessary logic for NURBS handling in librt, libbrep, and libged

          Future Possibilities
          Implementing a visual NURBS editor in a BRL-CAD GUI (mged, Archer, Arbalest)

          Project Properties
          Skills
          C/C++
          Difficulty
          medium

          Size
          long (350h)

          Additional Information
          Potential mentor(s): Daniel Rossberg, Sean Morrison
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com


          ~~~~~~~~~~

          New BRL-CAD GUI

          Outline
          Develop further the new GUI for BRL-CAD!

          Details
          BRL-CAD has two main graphical applications called 'mged' and 'archer' which look like they were developed in the 80's and 90's respectively (because they were). We need a modern GUI, ideally using Qt.

          This new GUI will need to leverage our existing libraries in a big way. This includes the C++ coreInterface ( see https://brlcad.org/wiki/Object-oriented_interfaces) or its successor MOOSE (see https://github.com/BRL-CAD/MOOSE) and LIBGED (see src/libged). The latter is basically all commands available to both mged and archer.

          During past GSoCs an amazing start was made with arbalest. Based on this, the development of a GUI called 'qged' (see src/qged) was started, which you should include in your considerations too. This program implements the traditional BRL-CAD workflow under a modern Qt-based user interface.

          You may propose a complete different approach, but we recommend to use arbalest as starting point for your work. Which additions would you like to program in this years GSoC? You can use the results of the former prototype CAD GUI Google Code-in tasks (http://brlcad.org/gci/data/uncategorized/, search for CAD_GUI there) for inspiration.

          Keep your proposal lean and simple. The main emphasis should be on adding features and/or improvements to our next generation GUI.

          Expected Outcome
          An improved BRL-CAD GUI.

          Project Properties
          Skills
          C/C++
          Qt
          Difficulty
          medium

          Size
          This project can be scoped medium (175h) or long (350h), depending on the amount of functionality you want to include.

          Additional Information
          Potential mentor(s):
          Daniel Rossberg
          Himanshu Sekhar Nayak
          Sean Morrison
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com

          ~~~~~~~~~~

          Online Geometry Viewer (OGV)

          Outline
          Write a proposal that leverages rewrite of the existing application in the latest tech stack for frontend and backend.

          Details
          We have been working on OGV for over many years. It started with PHP and then was revamped to meteor.js. We want to focus on the backend of OGV, making sure it works properly, converts the models properly, and basically finish a 1.0 version of OGV so we can launch it for the masses! For that, we are planning to change the legacy backend to be rewritten along with the frontend.

          You can use any tech stack (react, vue) for frontend and node, C/C++ for the backend. We faced some problems like removing certain deprecated dependencies and adding new features with Meteor. We are planning to port the application and add all specified features.

          Possible New Features
          Integrating BRL-CAD GCV(Geometry Conversion Vocabulary) to add support for more file formats like .stl, .obj, and .3dm.
          Automated Conversion for Web Display. Convert uploaded files automatically into polygonal formats for web visualization. Ensure smooth rendering and compatibility with web-based 3D viewers.
          Implementing a Model Repository based project architecture for storing and downloading 3d models.
          Conduct a full STIG compliance audit (Security Technical Implementation Guide), which involves ~200+ security checks.
          Run security scans using OWASP and Dependency-Check, addressing any reported vulnerabilities.
          However, you don't have to limit yourself to those ideas.

          Checklist to write proposal for OGV
          Download and clone OGV from https://github.com/BRL-CAD/OGV-meteor
          Setup and Run OGV on your local machine.
          Fork OGV repo
          Understand the flow of existing application
          Talk to mentors
          Choose list of issues that you would like to solve this summer
          Make a detailed weekly implementation plan
          Share your proposal with your mentors
          Submit it to the GSoC website
          Expected Outcome
          You're expected to propose an outcome useful to end-users. That is a broad range of possibilities that will depend on your interests and experience level. For example, you might propose focusing on the backend conversion to triangles for display (C/C++/Node.js). Or you might propose changing the backend to NURBS surfaces (C/C++) and using verbnurb or three.js (Javascript) to display them instead of triangles. Or you might propose keeping the backend the way it is and focus on front-end robustness (Vue, React), website features, or deployment infrastructure. You hopefully get the idea.

          Project Properties
          Skills
          JavaScript (Vue, React)
          Node.js (required)
          C/C++ (optional)
          Verbnurb (optional)
          Three.js (optional)
          Difficulty
          Hard

          Size
          This project can be scoped medium (175h) or long (350h), depending on the amount of functionality you want to include.

          Additional Information
          Potential mentor(s):
          Amanjot Singh
          Daniel Rossberg
          Divyanshu Garg
          Sean Morrison
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com

          ~~~~~~~~~~

          Add OpenSCAD support for exporting models in STEP format
          Outline
          The STEP format is widely used in the industry to transfer CAD data between different systems. Currently OpenSCAD does not support STEP import or export. Adding STEP export would open up a number of new usecases or simplify the workflow as no external conversion tools are needed to convert to STEP. This includes the design of 3D models for other CAD tools, e.g. for KiCAD where STEP models are used to render 3D representations of PCBs. Other use cases are for manufacturing where sometimes only STEP files are accepted as input, e.g. for CNC milling services.

          Details
          The main focus of this project is to get the ground work done for exporting more detailed models, as opposed to just exporting the fully rendered single mesh which is the normal case right now.

          Topics that need to be solved

          Research options of usable libraries
          Investigate what type of STEP files are accepted as input by various tools
          Select library and integrate into OpenSCAD
          Implement base functionality to export single meshes
          Add test cases to verify the new export functionality
          Update build system to include the new library into installers
          Prototype how more advanced models can be exported
          Expected Outcome
          OpenSCAD supports exporting single meshes as STEP
          (optional) Understanding/Plan of how to support additional features supported by STEP
          Project Properties
          Skills
          Programming language is C++
          Understand and use APIs from external libraries
          Integrate new libraries into the build system for the 3 supported platforms
          Add test cases with files using the new features to allow regression testing
          Difficulty
          Hard

          Size
          Long (350h)

          Additional Information
          Potential mentor(s): Marius Kintel (IRC: kintel), Torsten Paul (IRC: teepee)
          Organization website: https://www.openscad.org/
          Known libraries:

          StepCode - http://stepcode.org/ (https://github.com/stepcode/stepcode)
          OpenCASCADE - https://www.opencascade.com/


          
    totalCharacters_of_ideas_content_parent: 51942
    totalwords_of_ideas_content_parent: 12320
    totalTokenCount_of_ideas_content_parent: 10905
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/brl-cad/
    idea_list_url: https://github.com/opencax/GSoC/issues?q=is%3Aissue+is%3Aopen+label%3A%22GSoC+2025%22



  - organization_id: 13
    organization_name: BeagleBoard.org
    no_of_ideas: 5
    ideas_content: |
        Deep Learning 
        Medium complexity 175 hours

        A Conversational AI Assistant for BeagleBoard using RAG and Fine-tuning
        BeagleBoard currently lacks an AI-powered assistant to help users troubleshoot errors. This project aims to address that need while also streamlining the onboarding process for new contributors, enabling them to get started more quickly.

        Goal: Develop a domain-specific chatbot for BeagleBoard using a combination of RAG and fine-tuning of an open-source LLM (like Llama 3, Mixtral, or Gemma). This chatbot will assist users with troubleshooting, provide information about BeagleBoard products, and streamline the onboarding process for new contributors.
        Hardware Skills: Ability to test applications on BeagleBone AI-64/BeagleY-AI and optimize for performance using quantization techniques.
        Software Skills: Python, RAG, Scraping techniques, Fine tuning LLMs, Gradio, Hugging Face Inference Endpoints, NLTK/spaCy, Git
        Possible Mentors: Aryan Nanda

        ~~~~~~~~~~



        Linux kernel improvements
         Medium complexity 350 hours

        Update beagle-tester for mainline testing
        Utilize the beagle-tester application and Buildroot along with device-tree and udev symlink concepts within the OpenBeagle continuous integration server context to create a regression test suite for the Linux kernel and device-tree overlays on various Beagle computers.

        Goal: Execution on Beagle test farm with over 30 mikroBUS boards testing all mikroBUS enabled cape interfaces (PWM, ADC, UART, I2C, SPI, GPIO and interrupt) performing weekly mainline Linux regression verification
        Hardware Skills: basic wiring, embedded serial interfaces
        Software Skills: device-tree, Linux, C, OpenBeagle CI, Buildroot
        Possible Mentors: Deepak Khatri, Anuj Deshpande, Dhruva Gole

        ~~~~~~~~~~

        Linux kernel improvements
         Medium complexity 175 hours

        Upstream wpanusb and bcfserial
        These are the drivers that are used to enable Linux to use a BeagleConnect Freedom as a SubGHz IEEE802.15.4 radio (gateway). They need to be part of upstream Linux to simplify on-going support. There are several gaps that are known before they are acceptable upstream.

        Goal: Add functional gaps, submit upstream patches for these drivers and respond to feedback
        Hardware Skills: wireless communications
        Software Skills: C, Linux
        Possible Mentors: Ayush Singh, Jason Kridner

        ~~~~~~~~~~

        Automation and industrial I/O Medium complexity 175 hours

        librobotcontrol support for newer boards
        Preliminary librobotcontrol support for BeagleBone AI, BeagleBone AI-64 and BeagleV-Fire has been drafted, but it needs to be cleaned up. We can also work on support for Raspberry Pi if UCSD releases their Hat for it.

        Goal: Update librobotcontrol for Robotics Cape on BeagleBone AI, BeagleBone AI-64 and BeagleV-Fire
        Hardware Skills: basic wiring, motors
        Software Skills: C, Linux
        Possible Mentors: Deepak Khatri, Jason Kridner

        ~~~~~~~~~~

        RTOS/microkernel imporvements
        Medium complexity 350 hours

        Upstream Zephyr Support on BBAI-64 R5
        Incorporating Zephyr RTOS support onto the Cortex-R5 cores of the TDA4VM SoC along with Linux operation on the A72 core. The objective is to harness the combined capabilities of both systems to support BeagleBone AI-64.

        Goal: submit upstream patches to support BeagleBone AI-64 and respond to feedback
        Hardware Skills: Familiarity with ARM Cortex R5
        Software Skills: C, RTOS
        Possible Mentors: Dhruva Gole, Nishanth Menon
        Upstream Repository: The primary repository for Zephyr Project

          
    totalCharacters_of_ideas_content_parent: 3803
    totalwords_of_ideas_content_parent: 786
    totalTokenCount_of_ideas_content_parent: 816
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/beagleboard.org/
    idea_list_url:  https://gsoc.beagleboard.io/ideas/


  - organization_id: 14
    organization_name: Blender
    no_of_ideas: 15
    ideas_content: |
        Flamenco¶
        Flamenco is Blender's render farm management system. For all the ideas below, a requirement is that you've set up Flamenco for yourself and used it to render things. Of course also some experience with Blender itself is needed.

        Statistics¶
        Description: Design & build a system for Flamenco to collect and display statistics.
        The goal is to show per-job, per-task, and per-worker statistics.
        This should make it possible for users to predict how long a render job will be, as they can look up things like render times of similar render jobs.
        The underlying design should be generic enough to store all kinds of statistics and events, not specific to Blender render times only.
        This project would include the technical design of this feature, the frontend / UI / UX design, and the implementation of both front- and back-end.
        Optional: record more statistics, such as per-frame render time, memory usage, etc.
        Optional: show progress of jobs in the jobs list.
        Expected outcomes: A way for users to get a better understanding of how a new render job will behave, as they can look up information about past & currently running jobs.
        Skills required: Familiarity with Go and unit testing. Familiarity with web languages (HTML/CSS/JavaScript, VueJS).
        Possible mentors: Sybren Stüvel.
        Expected project size: 350 hours
        Difficulty: hard

        ~~~~~~~~~~
        RNA Overrides¶
        Description: Render jobs should be able to specify "RNA overrides" (#101569). In other words, the job definition should be able to include some Python code that sets certain properties in Blender to certain values.
        Design a way to include this in a job definition, and how it affects tasks & commands.
        This could include the ability to add new RNA overrides to existing jobs.
        This should include the ability to update those override values via the web interface.
        Design how such additions / changes affect already-created tasks/commands in the database. Or a way to make this work without changing things in the database?
        This can be used both when a user wants to change something (like re-rendering with increased sample count), or for Flamenco itself to adjust things in the blend file without having to save those values in the blend file itself (#104264)
        Expected outcomes: Give users a simpler way to configure Flamenco for their needs.
        Skills required: Familiarity with Blender (for making the RNA overrides themselves work). Familiarity with Go and unit testing for adjusting Flamenco. Familiarity with web languages (HTML/CSS/JavaScript, VueJS) for the web frontend.
        Possible mentors: Sybren Stüvel.
        Expected project size: 350 hours
        Difficulty: hard

        ~~~~~~~~~~
        Configuration Web Interface¶
        Description: Flamenco's configuration file can be created via its Setup Assistant, but that's only for the initial configuration. For managing more complex things, like the two-way variables for cross-platform support, users still have to manually edit the YAML file. This project is about introducing a configuration editor in the web frontend, and potentially new backend API functions to support that.
        New tab in the frontend for managing the configuration.
        A way to retrieve and visualise the configuration.
        New front-end widgets to represent these, including more complex cases like one-way and two-way variables.
        A way to save the edited configuration.
        Optional: A validator for the configuration options, so that changes can be checked before they take hold.
        Optional: A way for Flamenco Manager to load and apply the configuration without restarting the process.
        Optional: A custom job type for validating configuration paths, so that, for example, a macOS path can be actually checked on a Worker running macOS.
        Expected outcomes: Give users a simpler way to configure Flamenco for their needs.
        Skills required: Familiarity with web languages (HTML/CSS/JavaScript, VueJS, OpenAPI). Potentially also familiarity with Go in case of backend work.
        Possible mentors: Sybren Stüvel.
        Expected project size: 350 hours
        Difficulty: hard

        ~~~~~~~~~~
        Polish & Shine¶
        Description: Fix various issues & implement missing pieces to solve common bumps in the road.
        Reconsider some design aspects of the web frontend, so that it works better on narrower / smaller screens.
        Allow finishing setup assistant without Blender on Manager (#100195).
        Introduce per-Worker logs on the Manager, for introspection and debugging.
        Fix issues with two-way variables (#104336, #104293)
        Add a web interface for the mass deletion of jobs. There is already an API call for this, which deletes all jobs older than a certain timestamp.
        Other issues from the tracker.
        Expected outcomes: Improve the overall experience people have when working with Flamenco.
        Skills required: Familiarity with web languages (HTML/CSS/JavaScript, VueJS) for front-end work. Familiarity with Go and OpenAPI for backend work.
        Possible mentors: Sybren Stüvel.
        Expected project size: 175 hours
        Difficulty: medium

        ~~~~~~~~~~
        Geometry Nodes¶
        Regression Testing¶
        Description: As people build more assets on top of Geometry Nodes, it becomes more and more important to ensure good backwards compatibility. This project focuses on improving our regression tests to cover more issues as early as possible. This involves:
        Adding new tests in our existing test framework.
        Extending the test framework to cover node tools, baking and maybe other areas we still have to find.
        Preparing more complex production files for use in regression tests.
        Expected outcomes: Improved stability of Geometry Nodes.
        Skills required: Good in C/C++ and Python.
        Possible mentors: Jacques Lucke, Hans Goudey
        Expected project size: 90 or 175 hours depending on how many of the mentioned areas are covered
        Difficulty: Easy (using existing framework) and Medium (extending framework)

        ~~~~~~~~~~
        Modeling¶
        Improve Edit-Mesh Mirror¶
        Description: Blender's mesh mirroring in mesh edit-mode works for basic transformations, but does not work for most other operations such as sliding, smoothing, marking seams, etc. In practice, this makes the edit-mode mirror only useful in very specific circumstances and not for general modeling.

        While supporting every operation isn't practical, enabling it for a subset of operators such as those that only adjust existing geometry (rather than adding or removing geometry) would be immediately useful for artists.

        Expected outcomes: Improved edit-mesh mirror support for existing tools.
        Skills required: Proficient in C/C++.
        Possible mentors: Campbell Barton
        Expected project size: 175 or 350 hours
        Difficulty: medium

        ~~~~~~~~~~
        Sculpt & Paint¶
        Mesh Sculpting Performance Improvements¶
        Description: Last year's sculpting rewrite project gave a large improvement in performance, but the team didn't have the time to pursue everything. This task lists possible future improvements. This GSoC project would explore one or more of those ideas with in depth performance testing and experimentation.
        Expected outcomes: More interactive sculping with large meshes
        Skills required: Proficient in C++, familiarity with data-oriented-design.
        Possible mentors: Hans Goudey
        Expected project size: 175 or 350 hours
        Difficulty: medium or hard
        
        ~~~~~~~~~~
        VFX & Video¶
        Hardware accelerated video encoding/decoding¶
        Description: Currently Blender encodes and decodes video though ffmpeg C libraries, on the CPU. ffmpeg also has support for hardware video processing (various kinds depending on platform), this project would enable usage of that.
        Build ffmpeg with hardware video processing support included.
        Note: Blender can't include "non-free" ffmpeg libraries (which means cuda_nvcc, cuda_sdk, libnpp can't be used).
        On Blender's video decoding and encoding side, implement code that would use any relevant ffmpeg C libraries parts for hardware video processing, when supported.
        Decide which additional UI settings need to be exposed to the user, to control hardware video processing.
        Implement code needed to transfer video frames between hardware memory and CPU memory as needed (the rest of VSE processing pipeline is purely on CPU currently).
        Expected outcomes: Video encoding or decoding is more efficient by using dedicated hardware.
        Skills required: Proficient in C/C++, familiarity with ffmpeg.
        Possible mentors: Aras Pranckevicius
        Expected project size: 350 hours
        Difficulty: medium

        ~~~~~~~~~~
        High Dynamic Range (HDR) support for video¶
        Description: This project has several partially dependent parts that are all about HDR support within VSE:
        Make Sequencer preview window be able to display HDR content on a capable display (like 3D viewport or Image window can).
        Make blender movie reading code be able to decode HDR videos into proper scene-linear or sequencer color space as needed. HDR video data might be PQ or HLG encoded, and this might need special decoding into destination color space.
        Make blender movie writing code be able to encode HDR videos. Blender already can encode 10/12 bit videos, but only for regular LDR. Additional PQ or HLG data encoding and necessary video metadata is not currently done.
        Expected outcomes: HDR video handling is improved within Blender.
        Skills required: Proficient in C/C++, familiarity with ffmpeg, knowledge of color spaces and color science.
        Possible mentors: Aras Pranckevicius
        Expected project size: 350 hours
        Difficulty: medium

        ~~~~~~~~~~
        VSE: OpenTimelineIO support¶
        Description: built-in support for OpenTimelineIO import/export within Blender VSE. Blender Studio has experimented with it in 2021, by using and extending a 3rd party addon vse_io. It might be useful to have built-in support for this.
        Expected outcomes: Blender VSE can import and export .otio files.
        Skills required: Proficient in C/C++, familiarity with video editing workflows.
        Possible mentors: Aras Pranckevicius
        Expected project size: 350 hours
        Difficulty: medium

        ~~~~~~~~~~
        VSE: Pitch correction for sound playback¶
        Description: Currently when audio is retimed, the pitch changes, would be nice to have an option to preserve pitch. Different approaches could be researched and implemented (e.g. pitch correction for mostly human speech might be different from pitch correction of music). Might need integration of some 3rd party library if it is suitable for the task, or implementing the correction algorithms manually.
        Expected outcomes: Retimed sound playback has options to preserve original pitch.
        Skills required: Proficient in C/C++, sound processing algorithms.
        Possible mentors: Aras Pranckevicius
        Expected project size: 350 hours
        Difficulty: medium

        ~~~~~~~~~~
        VSE: Animation retiming¶
        Description: Modify animation of strips, when changing their playback speed. Retiming allows changing playback speed of strips, but when strips are animated, the animation keys are fixed in position. These could be moved, such that animation is seemingly mapped to frames of the content.
        Expected outcomes: Animation proportionally is scaled with strip when retiming.
        Skills required: Proficient in C++.
        Possible mentors: Richard Antalik
        Expected project size: 175 hours
        Difficulty: medium

        ~~~~~~~~~~
        VSE: Keyframing in preview¶
        Description: Open workflow quick animation in VSE preview region. In 3D viewport it is possible to transform object and press I key to add key for its position. This also could be done in sequencer preview. This feature should follow same rules and preferences.
        Expected outcomes: Possibility of quick and easy animation in VSE preview
        Skills required: Proficient in C++.
        Possible mentors: Richard Antalik
        Expected project size: 90 hours
        Difficulty: medium

        ~~~~~~~~~~
        Compositor: Implement new nodes¶
        Description: The compositor has been rewritten to be more efficient and future proof. Moving forward, it would be nice to implement new nodes to make the compositor as powerful as it can be. Interested students are encouraged to propose their own ideas. Some example nodes include:
        Define low / high points
        Expected outcomes: Implemented one or more nodes for both CPU and GPU backends.
        Skills required: Good in C/C++, image processing algorithms, familiarity with shaders.
        Possible mentors: Habib Gahbiche / Omar Emara
        Expected project size: 90 or 175 hours depending on the node
        Difficulty: Easy or Medium depending on the node

        ~~~~~~~~~~
        Compositor: UI improvements¶
        Description: The compositor has been rewritten to be more efficient and future proof. It would be nice to improve the UI of some nodes as well as the workflow overall. Interested students are encouraged to suggest ideas. Some examples include:
        Implement 2D gizmos for exisiting nodes.
        Re-design the UI of exisiting nodes
        Expected outcomes: Improved UI within node editors.
        Skills required: Proficient in C/C++, familiarity with design patterns.
        Possible mentors: Habib Gahbiche / Omar Emara
        Expected project size: 90 or 175 hours depending on the scope of the project
        Difficulty: Easy or Medium depending on the scope

          
    totalCharacters_of_ideas_content_parent: 14181
    totalwords_of_ideas_content_parent: 3076
    totalTokenCount_of_ideas_content_parent: 2963
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/blender-foundation/
    idea_list_url: https://developer.blender.org/docs/programs/gsoc/ideas/

  - organization_id: 15
    organization_name: CCExtractor Development
    no_of_ideas: 13
    ideas_content: |
      
        CCExtractor Release 1.00	This is our ambitious project for the summer - work directly with the core team to prepare 1.00 - our first major version bump ever, by getting our PR's from last year vetted, tested and integrated	Some of these: Rust, C, Flutter, Docker, GitHub actions	The rest from the previous list.	Hard	350 hours
        ~~~~~~~~~~
        Ultimate Alarm Clock III	The ultimate alarm clock, with features no other one has. And free!	Flutter	Good application design	Medium	350 hours
        ~~~~~~~~~~
        Beacon Watch Companion	Beacon was started in 2021 and it got a great push also during 2022 and 2024. It aims to ease the group travelling (or hiking). This project is intended to be a companion for the beacon project for smart watches.	Flutter	Scalability	Medium	175 hours
        ~~~~~~~~~~
        Ultimate Alarm Clock Watch Companion	Ultimate Alarm Clock launched in 2023 and gained significant momentum in 2024. It aims to offer unique features that set it apart from other alarm clock apps—all for free!. This project is intended to be a companion for the ultimate alarm clock project for smart watches.	Flutter	Scalability	Medium	175 hours
        ~~~~~~~~~~
        Smart Health Reminder	A fun and interactive health tracking app with smart reminders, challenges, and gamification. Stay healthy effortlessly!	Flutter	Gamification & UX design	Medium	350 hours
        ~~~~~~~~~~
        support more torrent clients	We'd like to add support for other clients to our ruTorrent mobile interface (which of course will get a new name): Flood and Deluge.	Flutter	API, Teamwork	Medium	Discuss
        ~~~~~~~~~~
        URL shortener, with a twist	A URL shortener converts a long URL into a shorter one. There are many use cases. Some times it's just the shortening itself we want, for example to share it on twitter. Other times it's about obfuscation. We want to create our own, but with some unique features.	Any language you want	Internet infrastructure	Medium	175 hours
        ~~~~~~~~~~
        COSMIC Session For Regolith	COSMIC is a wayland based desktop environment written from scratch in rust, with modularity in mind. We're interested in swapping the GNOME components of Regolith DE with COSMIC.	Rust	Wayland, Iced, DBus, etc	Medium	350 hours
        ~~~~~~~~~~
        Add complex layouts to sway	Sway is a drop-in replacement for i3, a popular windows manager for Linux that finally gets rid of the ancient X11 protocol. It's fantastic, but it's still missing support for complex scenarios. We'd like you to work on that support.	C	Sway	Hard	350 hours
        ~~~~~~~~~~
        Expose ectool functionality as a library	ectool is a CLI that lets you interact with an embedded controller for laptops. Expose its functionality as a library so it's possible to use it without spawning the CLI.	C, Python	Interlanguage connectivity	Medium	350 hours
        ~~~~~~~~~~
        CCSync	This project aims to develop a comprehensive platform that can be used sync tasks with taskserver.A hosted solution for syncing your TaskWarrior client.Setting up your own TaskServer takes some effort.And platforms like inthe.am,freecinc have shut down their services.So we want to create a platform similar to inthe.am , freecinc and wingtask.	Any language you want	Internet infrastructure	Medium	175 hours
        ~~~~~~~~~~
        Mouseless for Linux v2 - i3 edition	Mouseless is a nice tool to practice keyboard shortcuts for a few popular apps. Unfortunately it's only available for Mac. Last year we created an open source one that runs on Linux. Using that work or not (this is your choice) we want to create one that helps use i3vm (the fantastic windows manager) using keys only.	Your choice	??	Unknown	175 hours
        ~~~~~~~~~~
        Desktop Actions in Ilia	Desktop Actions defined in .desktop files are used by app launcher to provide access to additional functionalities, typically via context menus. Ilia is an app launcher that currently doesn't support for Desktop Actions due to its keyboard based approach.	Vala, GTK	GTK	Medium	175 hours




          
    totalCharacters_of_ideas_content_parent: 4077
    totalwords_of_ideas_content_parent: 734
    totalTokenCount_of_ideas_content_parent: 964
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/ccextractor-development/
    idea_list_url: https://ccextractor.org/docs/ideas_page_for_summer_of_code_2025/

  - organization_id: 16
    organization_name: CERN-HSF
    no_of_ideas: 37
    ideas_content: |
          Precision Recovery in Lossy-Compressed Floating Point Data for High Energy Physics
          Description
          ATLAS is one of the particle physics experiments at the Large Hadron Collider (LHC) at CERN. With the planned upgrade of the LHC (the so-called High Luminosity phase), allowing for even more detailed exploration of fundamental particles and forces of nature, it is expected that the recorded data rate will be up to ten times greater than today. One of the methods of addressing this storage challenge is data compression. The traditional approach involves lossless compression algorithms such as zstd and zlib. To further reduce storage footprint, methods involving lossy compression are being investigated. One of the solutions in High Energy Physics is the reduction of floating point precision, as stored precision may be higher than detector resolution. However, when reading data back, physicists may be interested in restoring the precision of the floating point numbers. This is obviously impossible in the strict sense, as the process of removing bits is irreversible. Nevertheless, given that the data volume is high, some variables are correlated, and follow specific distributions, one may consider a machine learning approach to recover the lossy-compressed floating-point data.

          Task ideas
          Perform lossy compression of data sample from the ATLAS experiment
          Investigate ML techniques for data recovery, prediction and upscaling
          Integrate the chosen technique into HEP workflow
          Expected results
          Implementation of ML-based procedure to restore precision of lossy-compressed floating-point numbers in ATLAS data
          Evaluation of the method’s performance (decompression accuracy) and its applicability in HEP workflow
          Requirements
          C++, Python, Machine Learning
          Links
          IEEE_754
          Implementation of FloatCompressor in Athena
          Mentors
          Maciej Szymański - ANL
          Peter Van Gemmeren - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: July-September
          Corresponding Project
          ATLAS
          Participating Organizations
          ANL
          CERN

          ~~~~~~~~~~

          The rise of the machine (learning) in data compression for high energy physics and beyond
    

          Short description of the project
          The Large Hadron Collider (LHC) hosts multiple large-scale experiments, LHC experiments such as ATLAS, ALICE, LHCb, and CMS. These together produce roughly 1 Petabyte of data per second, but bandwidth and storage limitations force them to only pick the most interesting data, and discard the rest. The final data stored on disk is roughly 1 Petabyte per day [1]. Despite such steep methods of data reduction, the upgraded High Luminosity LHC in 2029 will produce 10 times more particle collisions. This is a great improvement for the potential to discover new physics, but poses a challenge both for data processing and data storage, as the resources needed in both departments are expected to be 3 and 5 times larger than the projected resources available [2][3].

          Data compression would be the go-to solution to this issue, but general data formats used for big data and the ROOT data format used at the LHC are already highly compressed, meaning that the data does not compress much under normal loss-less compression methods like zip [4]. However, since the observables in these experiments benefit from more events and higher statistics, lossy compression is a good alternative. By using lossy compression some data accuracy is lost, but the compression will allow for the storage of more data which will increase the statistical precision of the final analysis.

          BALER is a compression tool undergoing development at the particle physics division of the University of Manchester. BALER uses autoencoder and other neural networks as a type of lossy machine learning-based compression to compress multi-dimensional data and evaluate the accuracy of the dataset after compression.

          Since data storage is a problem in many fields of science and industry, BALER aims to be an open source tool that can support the compression of data formats from vastly different fields of science. For example, catalog data in astronomy and time series data in computational fluid dynamics.

          This project aims to work on the machine learning models in BALER to optimize performance for LHC data and evaluate its performance in real LHC analyses.

          Task ideas
          This internship can focus on a range of work packages, and the project can be tailored to the intern. Possible projects include:

          New auto-encoder models could be developed, better identifying correlations between data objects in a given particle physics dataset entry (event, typically containing thousands of objects and around 1MB each). New models could also improve performance on live / unseen data. These could include transformer, GNN, probabilistic and other tiypes of networks.
          Existing models could be applied on an FPGA, potentially significantly reducing latency and power consumption, opening the possibility of live compression before transmission of data on a network.
          BALER could also be integrated into standard research data storage formats and programs used by hundreds of thousands of physics researchers (ROOT).
          Finally the compression could be applied to particle physics datasets and the effect on the physics discovery sensitivity of an analysis could be assessed and compared to the possible increased sensitivity from additional data bandwidth.
          Ideas from the intern are also welcomed.

          Expected results
          An improved compression performance with documentation and figures of merit that may include:

          Plots made in matplotlib that demonstrate the performance of the new models compared to the old
          Documentation of the design choices made for the improved models
          Documented evaluation of a physics analysis on data before and after compression
          Requirements
          The candidate should have experience with the python language and a Linux environment, familiarity with AI fundamentals, and familiarity with PyTorch.

          Desirable skills include familiarity with AI fundamentals including transformers and/or graph neural networks, particle physics theory and experiments, PyTorch, FPGA programming and/or simulation.

          Links
          BALER GitHub
          BALER Paper

          Previous work:
          Thesis by Eric Wulff, Lund University
          Thesis by Erik Wallin, Lund University
          GSOC 2020 project: Medium post by Honey Gupta
          GSOC 2021 project: Zenodo entry by George Dialektakis
          ROOT
          Jupyter
          PyTorch
          Mentors
          James Smith - UManchester
          Caterina Doglioni - CERN
          Leonid Didukh
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-August
          Corresponding Project
          baler
          Participating Organizations
          baler
          UManchester
          CERN

          ~~~~~~~~~~

          Probabilistic circuit for lossless HEP data compression
          

          Short description of the project
          Neural data compression is an efficient solution for reducing the cost and computational resources of data storage in many LHC experiments. However, it suffers from the ability to precisely reconstruct compressed data, as most of the neural compression algorithms perform the decompression with the information loosage. On another hand, the lossless neural data compression schemas (VAE, IDF) have a lower compression ratio and are not fast enough for file IO. This project’s task is to overcome the disadvantages of the neural compression algorithm by using the probabilistic circuit for HEP data compression.

          Task ideas
          Implement the probabilistic circuit using the PyTorch
          Train and compress the HEP data (Higgs data, TopQuark Dataset)
          Measure the cost and quantify the optimal compression ratio of the probabilistic circuit
          Perform the benchmark, and compare the results with AE, Transformer
          Expected results
          An improved compression performance with documentation and figures of merit that may include:

          Implemented model of the probabilistic circuit
          Documentation of the benchmark and experiment of compression of the HEP data
          Requirements
          Required: Good knowledge of UNIX, Python, matplotlib, Pytorch, Julia, Pandas, ROOT.

          Links
          Previous work:

          GSOC 2021 project: Zenodo entry by George Dialektakis
          Baler – Machine Learning Based Compression of Scientific Data
          ROOT
          Jupyter
          Lossless compression with probabilistic circuits
          iFlow: Numerically Invertible Flows for Efficient Lossless Compression via a Uniform Coder
          Integer Discrete Flows and Lossless Compression
          Mentors
          Leonid Didukh
          Caterina Doglioni - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October (with 3 weeks mentor vacation where student will work independently with minimal guidance)
          Corresponding Project
          baler
          Participating Organizations
          CERN

          ~~~~~~~~~~
          Agent-Based Simulation of CAR-T Cell Therapy Using BioDynaMo
          Description
          Chimeric Antigen Receptor T-cell (CAR-T) therapy has revolutionized cancer treatment by harnessing the immune system to target and destroy tumor cells. While CAR-T has demonstrated success in blood cancers, its effectiveness in solid tumors remains limited due to challenges such as poor tumor infiltration, immune suppression, and T-cell exhaustion. To improve therapy outcomes, computational modeling is essential for optimizing treatment parameters, predicting failures, and testing novel interventions. However, existing models of CAR-T behavior are often overly simplistic or computationally expensive, making them impractical for large-scale simulations.

          This project aims to develop a scalable agent-based simulation of CAR-T therapy using BioDynaMo, an open-source high-performance biological simulation platform. By modeling T-cell migration, tumor engagement, and microenvironmental factors, we will investigate key treatment variables such as dosage, administration timing, and combination therapies. The simulation will allow researchers to explore how tumor microenvironment suppression (e.g., regulatory T-cells, hypoxia, immunosuppressive cytokines) affects CAR-T efficacy and what strategies such as checkpoint inhibitors or cytokine support can improve outcomes.

          The final deliverable will be a fully documented, reproducible BioDynaMo simulation, along with analysis tools for visualizing treatment dynamics. The model will provide insights into the optimal CAR-T cell dosing, tumor penetration efficiency, and factors influencing therapy resistance. This project will serve as a foundation for in silico testing of immunotherapies, reducing the need for costly and time-consuming laboratory experiments while accelerating the development of more effective cancer treatments.

          Expected plan of work:
          Phase 1: Initial Setup & Simple T-cell Dynamics
          Phase 2: Advanced CAR-T Cell Behavior & Tumor Interaction
          Phase 3: Integration of Immunosuppressive Factors & Data Visualization
          Expected deliverables
          A fully documented BioDynaMo simulation of CAR-T therapy.
          Analysis scripts for visualizing tumor reduction and CAR-T efficacy.
          Performance benchmarks comparing different treatment strategies.
          A research-style report summarizing findings.
          Requirements
          C++ (for BioDynaMo simulations)
          Agent-based modeling (understanding immune dynamics)
          Basic immunology & cancer biology (optional but helpful)
          Data visualization (Python, Matplotlib, Seaborn)
          Links
          Mapping CAR T-Cell Design Space Using Agent-Based Models
          BioDynaMo: A Modular Platform for High-Performance Agent-Based Simulation
          Computational Modeling of Chimeric Antigen Receptor (CAR) T-Cell Therapy of a Binary Model of Antigen Receptors in Breast Cancer
          Investigating Two Modes of Cancer-Associated Antigen Presentation in CAR T-Cell Therapy Using Agent-Based Modeling
          BioDynaMo: Cutting-Edge Software Helps Battle Cancer
          Mentors
          Vassil Vassilev
          Lukas Breitwieser - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          BioDynamo
          Participating Organizations
          CERN
          CompRes

          ~~~~~~~~~~

          Development of an auto-tuning tool for the CLUEstering library
          Description
          CLUE is a fast and fully parallelizable density-based clustering algorithm, optimized for high- occupancy scenarios, where the number of clusters is much larger than the average number of hits in a cluster (Rovere et al. 2020). The algorithm uses a grid spatial index for fast querying of neighbors and its timing scales linearly with the number of points within the range considered. It is currently used in the CMS and CLIC event reconstruction software for clustering calorimetric hits in two dimensions based on their energy. The CLUE algorithm has been generalized to an arbitrary number of dimensions and to a wider range of applications in CLUEstering, a general purpose clustering library, with the backend implemented in C++ and providing a Python interface for easier use. The backend can be executed on multiple backends (serial, TBB, GPUs, ecc) thanks to the Alpaka performance portability library. One feature currently lacking from CLUEstering and that would be extremely useful for every user, is an autotuning of the parameters, that given the expected number of clusters computes the combination of input parameters that results in the best clustering.
          For this task, one of the options to be explored is “The Optimizer”, a Python library developed by the Patatrack group of the CMS experiment which provides a collection of optimization algorithm, in particular MOPSO (Multi-Objective Particle Swarm Optimization).

          Expected results
          Consider the best techniques and tools for the task
          Develop an auto-tuning tool for the parameters of CLUEstering
          Test it on a wide range of commonly used datasets
          Benchmark and profile to identify the bottlenecks of the tool and optimize it
          Evaluation Task
          Interested students please contact simone.balducci@cern.ch

          Technologies
          C++, Python
          Desirable skills
          Experience with development in C++17/20
          Experience with GPU computing
          Experience with machine learning and optimization techniques
          Experience with development of Python libraries
          Links
          CLUE
          CLUEstering
          Alpaka
          Mentors
          Simone Balducci - CERN UNIBO
          Felice Pantaleo - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Patatrack
          Participating Organizations
          CERN


          ~~~~~~~~~~

          Evaluate Distribution of ML model files on CVMFS
          Description
          Particle physicists studying nature at highest energy scales at the Large Hadron Collider rely on simulations and data processing for their experiments. These workloads run on the “computing grid”, a massive globally distributed computing infrastructure. Deploying software efficiently and reliable to this grid is an important and challenging task. CVMFS is an optimised shared file system developed specifically for this purpose: it is implemented as a POSIX read-only file system in user space (a FUSE module). Files and directories are hosted on standard web servers and mounted in the universal namespace /cvmfs. In many cases, it replaces package managers and shared software areas on cluster file systems as means to distribute the software used to process experiment data.

          Task idea
          CVMFS is optimized for the distribution of software (header files, scripts and libraries), taking advantage of the repeated access pattern for its caching, and the possibility to deduplicate files present in several versions. CVMFS is capable to provide a general read-only POSIX file system view on data in external storage. A very common use case is to make conditions databases available to workloads running in distributed computing infrastructure, but various datasets have been published in CVMFS. How efficient CVMFS can be always depends on the details in these use cases - often the benefit for the users is simply in leveraging the existing server and proxy infrastructure.

          In this project proposal, we’d like to evaluate CVMFS as a means to distribute machine learning model files used in inference, for example .onnx files. The main focus will be on creating a test deployment and benchmarking the access, as well as possible coding utilities and scripts to aid in the deployment of models on CVMFS. We’d also like to contrast CVMFS to existing inference servers like KServe, and see if it could integrate as a backend storage.

          Expected results and milestones
          Familiarization with the CVMFS server infrastructure
          Familiarization with the ML model usage at CERN, Survey of different common inference model file formats.
          Test deployment of models relevant to ML4EP
          Benchmark and evaluation of inference using models served from CVMFS
          Addition of the benchmark to the CVMFS continuous benchmarking infrastructure
          Writing a best practices document for the CVMFS documentation
          Requirements
          UNIX/Linux
          Interest in scientific computing devops
          Familiarity with common ML libraries, in particular ONNX
          Links
          CVMFS
          KServe
          Mentors
          Valentin Volkl - CERN
          Lorenzo Moneta - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 175 hours
          Mentor availability: June-October
          Corresponding Project
          CernVM-FS
          Participating Organizations
          CERN

          ~~~~~~~~~~

          Implement and improve an efficient, layered tape with prefetching capabilities
          Description
          In mathematics and computer algebra, automatic differentiation (AD) is a set of techniques to numerically evaluate the derivative of a function specified by a computer program. Automatic differentiation is an alternative technique to Symbolic differentiation and Numerical differentiation (the method of finite differences). Clad is based on Clang which provides the necessary facilities for code transformation. The AD library can differentiate non-trivial functions, to find a partial derivative for trivial cases and has good unit test coverage.

          The most heavily used entity in AD is a stack-like data structure called a tape. For example, the first-in last-out access pattern, which naturally occurs in the storage of intermediate values for reverse mode AD, lends itself towards asynchronous storage. Asynchronous prefetching of values during the reverse pass allows checkpoints deeper in the stack to be stored furthest away in the memory hierarchy. Checkpointing provides a mechanism to parallelize segments of a function that can be executed on independent cores. Inserting checkpoints in these segments using separate tapes enables keeping the memory local and not sharing memory between cores. We will research techniques for local parallelization of the gradient reverse pass, and extend it to achieve better scalability and/or lower constant overheads on CPUs and potentially accelerators. We will evaluate techniques for efficient memory use, such as multi-level checkpointing support. Combining already developed techniques will allow executing gradient segments across different cores or in heterogeneous computing systems. These techniques must be robust and user-friendly, and minimize required application code and build system changes.

          This project aims to improve the efficiency of the clad tape and generalize it into a tool-agnostic facility that could be used outside of clad as well.

          Expected Results
          Optimize the current tape by avoiding re-allocating on resize in favor of using connected slabs of array
          Enhance existing benchmarks demonstrating the efficiency of the new tape
          Add the tape thread safety
          Implement multilayer tape being stored in memory and on disk
          [Stretch goal] Support cpu-gpu transfer of the tape
          [Stretch goal] Add infrastructure to enable checkpointing offload to the new tape
          [Stretch goal] Performance benchmarks
          Requirements
          Automatic differentiation
          C++ programming
          Clang frontend
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes


          ~~~~~~~~~~

          Enhancing LLM Training with Clad for efficient differentiation
          Description
          This project aims to leverage Clad, an automatic differentiation (AD) plugin for Clang, to optimize large language model (LLM) training primarily in C++. Automatic differentiation is a crucial component of deep learning training, enabling efficient computation of gradients for optimization algorithms such as stochastic gradient descent (SGD). While most modern LLM frameworks rely on Python-based ecosystems, their heavy reliance on interpreted code and dynamic computation graphs can introduce performance bottlenecks. By integrating Clad into C++-based deep learning pipelines, we can enable high-performance differentiation at the compiler level, reducing computational overhead and improving memory efficiency. This will allow developers to build more optimized training workflows without sacrificing flexibility or precision.

          Beyond performance improvements, integrating Clad with LLM training in C++ opens new possibilities for deploying AI models in resource-constrained environments, such as embedded systems and HPC clusters, where minimizing memory footprint and maximizing computational efficiency are critical. Additionally, this work will bridge the gap between modern deep learning research and traditional scientific computing by providing a more robust and scalable AD solution for physics-informed machine learning models. By optimizing the differentiation process at the compiler level, this project has the potential to enhance both research and production-level AI applications, aligning with compiler-research.org’s broader goal of advancing computational techniques for scientific discovery.

          Expected Results
          Develop a simplified LLM setup in C++
          Apply Clad to compute gradients for selected layers and loss functions
          Enhance clad to support it if necessary, and prepare performance benchmarks
          Enhance the LLM complexity to cover larger projects such as llama
          Repeat bugfixing and benchmarks
          Develop tests to ensure correctness, numerical stability, and efficiency
          Document the approach, implementation details, and performance gains
          Present progress and findings at relevant meetings and conferences
          Requirements
          Automatic differentiation
          Parallel programming
          Reasonable expertise in C++ programming
          Background in LLM is preferred but not required
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes


          ~~~~~~~~~~

          Enable Clad on ONNX-based models
          Description
          Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++ source code of a mathematical function, it can automatically generate C++ code for computing derivatives of the function. Clad is useful in powering statistical analysis and uncertainty assessment applications. ONNX (Open Neural Network Exchange) provides a standardized format for machine learning models, widely used for interoperability between frameworks like PyTorch and TensorFlow

          This project aims to integrate Clad, an automatic differentiation (AD) plugin for Clang, with ONNX-based machine learning models. Clad can generate derivative computations for C++ functions, making it useful for sensitivity analysis, optimization, and uncertainty quantification. By extending Clad’s capabilities to ONNX models, this project will enable efficient differentiation of neural network operations within an ONNX execution environment.

          Expected Results
          Enumerate ONNX modules with increasing complexity and analyze their differentiation requirements.
          Develop a structured plan for differentiating the identified ONNX operations.
          Implement forward mode differentiation for selected ONNX operations.
          Extend support to reverse mode differentiation for more complex cases.
          Create comprehensive tests to validate correctness and efficiency.
          Write clear documentation to ensure ease of use and future maintenance.
          Present results at relevant meetings and conferences.
          Requirements
          Automatic differentiation
          Parallel programming
          Reasonable expertise in C++ programming
          Basic knowledge of Clang is preferred but not mandatory
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Enable automatic differentiation of OpenMP programs with Clad
          Description
          Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++ source code of a mathematical function, it can automatically generate C++ code for computing derivatives of the function. Clad is useful in powering statistical analysis and uncertainty assessment applications. OpenMP (Open Multi-Processing) is an application programming interface (API) that supports multi-platform shared-memory multiprocessing programming in C, C++, and other computing platforms.

          This project aims to develop infrastructure in Clad to support the differentiation of programs that contain OpenMP primitives.

          Expected Results
          Extend the pragma handling support
          List the most commonly used OpenMP concurrency primitives and prepare a plan for how they should be handled in both forward and reverse accumulation in Clad
          Add support for concurrency primitives in Clad’s forward and reverse mode automatic differentiation.
          Add proper tests and documentation.
          Present the work at the relevant meetings and conferences.
          Requirements
          Automatic differentiation
          C++ programming
          Parallel Programming
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Integrate Clad to PyTorch and compare the gradient execution times
          Description
          PyTorch is a popular machine learning framework that includes its own automatic differentiation engine, while Clad is a Clang plugin for automatic differentiation that performs source-to-source transformation to generate functions capable of computing derivatives at compile time.

          This project aims to integrate Clad-generated functions into PyTorch using its C++ API and expose them to a Python workflow. The goal is to compare the execution times of gradients computed by Clad with those computed by PyTorch’s native autograd system. Special attention will be given to CUDA-enabled gradient computations, as PyTorch also offers GPU acceleration capabilities.

          Expected Results
          Incorporate Clad’s API components (such as clad::array and clad::tape) into PyTorch using its C++ API
          Pass Clad-generated derivative functions to PyTorch and expose them to Python
          Perform benchmarks comparing the execution times and performance of Clad-derived gradients versus PyTorch’s autograd
          Automate the integration process
          Document thoroughly the integration process and the benchmark results and identify potential bottlenecks in Clad’s execution
          Present the work at the relevant meetings and conferences.
          Requirements
          Automatic differentiation
          C++ programming
          Clang frontend
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Enable automatic differentiation of C++ STL concurrency primitives in Clad
          Description
          Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++ source code of a mathematical function, it can automatically generate C++ code for computing derivatives of the function. This project focuses on enabling automatic differentiation of codes that utilise C++ concurrency features such as std::thread, std::mutex, atomic operations and more. This will allow users to fully utilize their CPU resources.

          Expected Results
          Explore C++ concurrency primitives and prepare a report detailing the associated challenges involved and the features that can be feasibly supported within the given timeframe.
          Add concurrency primitives support in Clad’s forward-mode automatic differentiation.
          Add concurrency primitives support in Clad’s reverse-mode automatic differentiation.
          Add proper tests and documentation.
          Present the work at the relevant meetings and conferences.
          An example demonstrating the use of differentiation of codes utilizing parallelization primitives:

          #include <cmath>
          #include <iostream>
          #include <mutex>
          #include <numeric>
          #include <thread>
          #include <vector>
          #include "clad/Differentiator/Differentiator.h"

          using VectorD = std::vector<double>;
          using MatrixD = std::vector<VectorD>;

          std::mutex m;

          VectorD operator*(const VectorD &l, const VectorD &r) {
            VectorD v(l.size());
            for (std::size_t i = 0; i < l.size(); ++i)
              v[i] = l[i] * r[i];
            return v;
          }

          double dot(const VectorD &v1, const VectorD &v2) {
            VectorD v = v1 * v2;
            return std::accumulate(v.begin(), v.end(), 0.0);
          }

          double activation_fn(double z) { return 1 / (1 + std::exp(-z)); }

          double compute_loss(double y, double y_estimate) {
            return -(y * std::log(y_estimate) + (1 - y) * std::log(1 - y_estimate));
          }

          void compute_and_add_loss(VectorD x, double y, const VectorD &weights, double b,
                                    double &loss) {
            double z = dot(x, weights) + b;
            double y_estimate = activation_fn(z);
            std::lock_guard<std::mutex> guard(m);
            loss += compute_loss(y, y_estimate);
          }

          /// Compute total loss associated with a single neural neural-network.
          /// y_estimate = activation_fn(dot(X[i], weights) + b)
          /// Loss of a training data point = - (y_actual * std::log(y_estimate) + (1 - y_actual) * std::log(1 - y_estimate))
          /// total loss: summation of loss for all the data points
          double compute_total_loss(const MatrixD &X, const VectorD &Y,
                                    const VectorD &weights, double b) {
            double loss = 0;
            const std::size_t num_of_threads = std::thread::hardware_concurrency();
            std::vector<std::thread> threads(num_of_threads);
            int thread_id = 0;
            for (std::size_t i = 0; i < X.size(); ++i) {
              if (threads[thread_id].joinable())
                threads[thread_id].join();
              threads[thread_id] =
                  std::thread(compute_and_add_loss, std::cref(X[i]), Y[i],
                              std::cref(weights), b, std::ref(loss));
              thread_id = (thread_id + 1) % num_of_threads;
            }
            for (std::size_t i = 0; i < num_of_threads; ++i) {
              if (threads[i].joinable())
                threads[i].join();
            }

            return loss;
          }

          int main() {
            auto loss_grad = clad::gradient(compute_total_loss);
            // Fill the values as required!
            MatrixD X;
            VectorD Y;
            VectorD weights;
            double b;

            // derivatives
            // Zero the derivative variables and make them of the same dimension as the
            // corresponding primal values.
            MatrixD d_X;
            VectorD d_Y;
            VectorD d_weights;
            double d_b = 0;

            loss_grad.execute(X, Y, weights, b, &d_X, &d_Y, &d_weights, &d_b);

            std::cout << "dLossFn/dW[2]: " << d_weights[2] << "\n"; // Partial derivative of the loss function w.r.t weight[2]
            std::cout << "dLossFn/db: " << d_b << "\n"; // Partial derivative of the loss function w.r.t b
          }
          Requirements
          Automatic differentiation
          Parallel programming
          Reasonable expertise in C++ programming
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Support usage of Thrust API in Clad
          Description
          The rise of ML has shed light into the power of GPUs and researchers are looking for ways to incorporate them in their projects as a lightweight parallelization method. Consequently, General Purpose GPU programming is becoming a very popular way to speed up execution time.

          Clad is a clang plugin for automatic differentiation that performs source-to-source transformation and produces a function capable of computing the derivatives of a given function at compile time. This project aims to enhance Clad by adding support for Thrust, a parallel algorithms library designed for GPUs and other accelerators. By supporting Thrust, Clad will be able to differentiate algorithms that rely on Thrust’s parallel computing primitives, unlocking new possibilities for GPU-based machine learning, scientific computing, and numerical optimization.

          Expected Results
          Research and decide on the most valuable Thrust functions to support in Clad
          Create pushforward and pullback functions for these Thrust functions
          Write tests that cover the additions
          Include demos of using Clad on open source code examples that call Thrust functions
          Write documentation on which Thrust functions are supported in Clad
          Present the work at the relevant meetings and conferences.
          Requirements
          Automatic differentiation
          C++ programming
          Clang frontend
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes

          ~~~~~~~~~~
          
          Extending the User Interface
          Description
          Constellation is a framework used for lab setups or small-scale experiments in HEP. One of its most important goals is that the framework should be easy to use for both scientists implementing new devices as well as experiment operators.

          Constellation features a Qt-based User Interfaces to control and monitor all devices in the experimental setup. The focus of this GSoC project is to add new user interfaces to Constellation and extend the current ones.

          Project Milestones
          Creating a new GUI to display monitoring data from devices using Qt Charts
          Modularization of UI elements into reusable Qt widgets
          Adding the monitoring widget to the existing GUI for device control
          Requirements
          Modern C++
          Knowledge of Qt is helpful but not required
          Practical experience with Unix and git
          Links
          Repository
          Documentation
          Mentors
          Stephan Lachnit - DESY
          Simon Spannagel - DESY
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-August
          Corresponding Project
          Constellation
          Participating Organizations
          DESY

          ~~~~~~~~~~

          Implement CppInterOp API exposing memory, ownership and thread safety information
          Description
          Incremental compilation pipelines process code chunk-by-chunk by building an ever-growing translation unit. Code is then lowered into the LLVM IR and subsequently run by the LLVM JIT. Such a pipeline allows creation of efficient interpreters. The interpreter enables interactive exploration and makes the C++ language more user friendly. The incremental compilation mode is used by the interactive C++ interpreter, Cling, initially developed to enable interactive high-energy physics analysis in a C++ environment.

          Clang and LLVM provide access to C++ from other programming languages, but currently only exposes the declared public interfaces of such C++ code even when it has parsed implementation details directly. Both the high-level and the low-level program representation has enough information to capture and expose more of such details to improve language interoperability. Examples include details of memory management, ownership transfer, thread safety, externalized side-effects, etc. For example, if memory is allocated and returned, the caller needs to take ownership; if a function is pure, it can be elided; if a call provides access to a data member, it can be reduced to an address lookup. The goal of this project is to develop API for CppInterOp which are capable of extracting and exposing such information AST or from JIT-ed code and use it in cppyy (Python-C++ language bindings) as an exemplar. If time permits, extend the work to persistify this information across translation units and use it on code compiled with Clang.

          Project Milestones
          Collect and categorize possible exposed interop information kinds
          Write one or more facilities to extract necessary implementation details
          Design a language-independent interface to expose this information
          Integrate the work in clang-repl and Cling
          Implement and demonstrate its use in cppyy as an exemplar
          Present the work at the relevant meetings and conferences.
          Requirements
          C++ programming
          Python programming
          Knowledge of Clang and LLVM
          Links
          Repo
          Mentors
          Aaron Jomy - CompRes
          Vassil Vassilev - CompRes
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          CppInterOp
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Incorporate a Large Language Model to assist users
          Description
          The amount of data that is processed by individual scientists has grown hugely in the past decade. It is not unusual for a user to have data processed on tens of thousands of processors with these located at tens of different locations across the globe. The Ganga user interface was created to allow for the management of such large calculations. It helps the user to prepare the calculations, submitting the tasks to a resource broker, keeping track of which parts of the task that has been completed, and putting it all together in the end.

          As a scripting and command line interface, there will naturally be users that have problems with getting the syntax correct. To solve this, they will often spend time searching through mailing lists, FAQs and discussion fora or indeed just wait for another more advanced coder to debug their problem. The idea of this project is to integrate a Large Language Model (LLM) into the command prompt in Ganga. This should allow the user to describe in words what they would like to do and get an example that they can incorporate. It should also intercept exceptions thrown by the Ganga interface, help the user to understand them and propose solutions.

          We have an interface based on ollama that will build a RAG that contains extra information about Ganga that has not been available for the training of the underlying LLM.

          Task ideas
          Integrate the interaction with the LLM and RAG into Ganga.
          Integrate past input and output in the CLI to provide context for the CLI.
          Setup a server such that the LLM can run on a remote server requiring minimal installation by the user.
          Test which samples are most useful for adding to the RAG (mailing list discussions, manuals, instant messages)
          Develop continuous integration tests that ensures that LLM integration will keep working.
          Expected results
          For the scientific users of Ganga, this will speed up their development cycle as they will get a faster response to the usage queries that they have.

          As a student, you will gain experience with the challenges of large scale computing where some tasks of a large processing chain might take several days to process, have intermittent failures and have thousands of task processing in parallel. You will get experience with how LLMs can be integrated directly into projects to assist users in the use of the CLI and in understanding error messages.

          Evaluation Task
          Interested students please contact Ulrik (see contact below) to ask questions and for an evaluation task.

          Requirements
          Python programming (advanced), Linux command line experience (intermediate), use of git for code development and continuous integration testing (intermediate)

          Links
          Ganga
          Mentors
          Alex Richards - Imperial College
          Mark Smith - Imperial College
          Ulrik Egede - Monash University
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: May-November
          Corresponding Project
          Ganga
          Participating Organizations
          ImperialCollege
          MonashUniversity

          ~~~~~~~~~~

          Implement a deprecation system to keep code up to date
          Description
          The amount of data that is processed by individual scientists has grown hugely in the past decade. It is not unusual for a user to have data processed on tens of thousands of processors with these located at tens of different locations across the globe. The Ganga user interface was created to allow for the management of such large calculations. It helps the user to prepare the calculations, submitting the tasks to a resource broker, keeping track of which parts of the task that has been completed, and putting it all together in the end.

          As code that has developed over many years, there are part of the API that has become redundant. This means that for a period of time there will be both the old and now deprecated API as well as the new way of doing things. At the moment Ganga is missing a formal way of deprecating code. This means that warnings about using something deprecated are non-uniform and there is also very old code that has never been cleaned up.

          The idea in this project is to formalise the way that code can be declared deprecated and then use the continuous integration to ensure that the code eventually is deleted.

          Task ideas
          Have a well defined way of marking plugins, functions etc as deprecated with a warning about when they will be removed. Building on top of the python package deprecated might be an idea.
          Run tests in the testing framework that will alert developers to that certain parts of the code can now be removed.
          Apply in the testing framework a similar system that will identify when deprecated python features are used when moving to a new python version.
          Apply the deprecation system to parts of the code that is already deprecated.
          Expected results
          Obtain a cleaner code base where very old and since long deprecated code is no longer present. Provide the end user with consistent warnings about their use of deprecated code as well as when it will be removed.

          As a student, you will gain experience with the challenges of large scale computing where some tasks of a large processing chain might take several days to process, have intermittent failures and have thousands of task processing in parallel. You will get experience with working within a large code base that has gone through many developments.

          Evaluation Task
          Interested students please contact Ulrik (see contact below) to ask questions and for an evaluation task.

          Requirements
          Python programming (advanced), Linux command line experience (intermediate), use of git for code development and continuous integration testing (intermediate)

          Links
          Ganga
          Mentors
          Alex Richards - Imperial College
          Mark Smith - Imperial College
          Ulrik Egede - Monash University
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: May-November
          Corresponding Project
          Ganga
          Participating Organizations
          ImperialCollege
          MonashUniversity

          ~~~~~~~~~~

          Geant4-FastSim - Data Representation Optimisation for Generative Model-based Fast Calorimeter Shower Simulation
          Description
          High energy physics experiments such as those operated at the Large Hadron Collider (LHC) fundamentally rely on detailed and realistic simulations of particle interactions with the detector. The state-of-the-art Geant4 toolkit provides a means of conducting these simulations with Monte Carlo procedures. However, the simulation of particle showers in the calorimeter systems of collider detectors with such tools is a computationally intensive task. For this reason, alternative fast simulation approaches based on generative models have received significant attention, with these models now being deployed in production by current experiments at the LHC. In order to develop the next generation of fast simulation tools, approaches are being explored that would be able to handle larger data dimensionalities stemming from the higher granularity present in future detectors, while also being efficient enough to provide a sizable simulation speed-up for low energy showers.

          A shower representation which has the potential to meet these criteria is a point cloud, which can be constructed from the position, energy and time of hits in the calorimeter. Since Geant4 provides access to the (very numerous) individual physical interactions simulated in the calorimeter, it also provides a means to create a representation independent of the physical readout geometry of the detector. This project will explore different approaches to clustering these individual simulated hits into a point cloud, seeking to minimise the number of points while preserving key calorimetric observables.

          First Steps
          Gain a basic understanding of calorimeter shower simulation (G4FastSim)
          Try simulating some electromagnetic particle showers with the Key4hep framework (see test)
          Propose different approaches to clustering, with justification
          Project Milestones
          Survey different approaches to clustering
          Implement and experiment with the different methods
          Investigate the impact of varying the detector granularity on the performance of separate clustering algorithms
          If time allows, hadronic showers could also be investigated
          Expected Results
          A comparison of different approaches to clustering, with a performance evaluation in terms of the effect on calorimetric observables.
          An evaluation of the impact of varying the granularity of the detector readout on the performance of the clustering algorithm
          Requirements
          C++, Python
          Familiarity with PyTorch could be an advantage
          Evaluation Tasks and Timeline
          Find the test here. Please submit it by 9:00 CET 17th March 2025 along with a short proposal (2 pages max) describing how you would approach the problem. See submission instructions in the test doc. Please don’t forget to start the subject line with “GSoC’25 FastSim”.
          We will make the selections based on the test, short proposal and resume by 17:00 CET 24th March.
          Selected candidates will then write the full proposal and submit it according to the official GSoC timeline.
          Links
          G4FastSim
          CaloChallenge 2022: A Community Challenge for Fast Calorimeter Simulation
          Mentors
          Peter McKeown - CERN
          Piyush Raikwar - CERN
          Anna Zaborowska - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Geant4
          Participating Organizations
          CERN

          ~~~~~~~~~~

          Using ROOT in the field of genome sequencing
          Description
          The ROOT is a framework for data processing, born at CERN, at the heart of the research on high-energy physics. Every day, thousands of physicists use ROOT applications to analyze their data or to perform simulations. The ROOT software framework is foundational for the HEP ecosystem, providing capabilities such as IO, a C++ interpreter, GUI, and math libraries. It uses object-oriented concepts and build-time modules to layer between components. We believe additional layering formalisms will benefit ROOT and its users.

          ROOT has broader scientific uses than the field of high energy physics. Several studies have shown promising applications of the ROOT I/O system in the field of genome sequencing. This project is about extending the developed capability in GeneROOT and understanding better the requirements of the field.

          Expected results
          Reproduce the results based on previous comparisons against ROOT master
          Investigate and compare the latest compression strategies used by Samtools for conversions to BAM, with RAM(ROOT Alignment Maps).
          Explore ROOT’s RNTuple format to efficiently store RAM maps, in place of the previously used TTree.
          Investigate different ROOT file splitting techniques
          Produce a comparison report
          Requirements
          C++ and Python programming
          Familiarity with Git
          Knowledge of ROOT and/or the BAM file formats is a plus.
          Links
          Latest Presentation on GeneROOT
          ROOT
          GeneROOT
          Mentors
          Martin Vasilev - Uni Plovdiv
          Jonas Rembser - CERN
          Fons Rademakers - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-November
          Corresponding Project
          ROOT
          Participating Organizations
          CERN
          CompRes

          ~~~~~~~~~~

          Highly Granular Quantization for CICADA
          Description
          The CICADA (Calorimeter Image Convolutional Anomaly Detection Algorithm) project aims to provide an unbiased detection of new physics signatures in proton-proton collisions at the Large Hadron Collider’s Compact Muon Solenoid experiment (CMS). It detects anomalies in low-level trigger calorimeter information with a convolutional autoencoder, whose behaviour is transferred to a smaller model through knowledge distillation. Careful quantization of the deployed model allows it to meet the requirement of sub-500ns inference times on FPGAs. While CICADA currently employs Quantization Aware Training with different quantization schemes for each layer of the distilled model, a new gradient-based quantization optimization approach published in 2024 offers the possibility of optimizing quantization at the individual weight level. This project would explore implementing this highly granular quantization method to CICADA’s distilled model and evaluating its effects on both model performance and resource consumption on FPGAs. The work would involve implementing the new quantization approach, comparing it with the current implementation, and investigating the impact on both detection performance and hardware resource utilization while maintaining the strict timing requirements.

          Task ideas
          Transition CICADA’s quantization tool from QKeras to HGQ
          Optimize student model’s quantization with higher granularity
          Compare resulting model’s performance with legacy model
          Emulate deployment on FPGA w/ Vivado to evaluate resource consumption
          Expected results
          Extend existing training / quantization scripts to use HGQ in addition to QKeras
          A trained student model with highly granular quantization
          Estimates of that model’s performance and resource consumption on an FPGA
          Requirements
          Python, Tensorflow, Quantization

          Links
          CICADA (homepage)
          CICADA (code)
          HGQ (Paper)
          HGQ (code)
          Mentors
          Lino Gerlach - CERN
          Isobel Ojalvo - Princeton
          Jennifer Ngadiuba - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: Flexible
          Corresponding Project
          CICADA
          Participating Organizations
          princeton

          ~~~~~~~~~~

          Intelligent Log Analysis for the HSF Conditions Database
          Description
          The nopayloaddb project works as an implementation of the Conditions Database reference for the HSF. It provides a RESTful API for managing payloads, global tags, payload types, and associated data.

          Our current system, composed of Nginx, Django, and database (link to helm chart), lacks a centralized logging solution making it difficult to effectively monitor and troubleshoot issues. This task will address this deficiency by implementing a centralized logging system aggregating logs from multiple components, and develop a machine learning model to perform intelligent log analysis. The model will identify unusual log entries indicative of software bugs, database bottlenecks, or other performance issues, allowing us to address problems before they escalate. Additionally, by analyzing system metrics, the model will provide insights for an optimal adjustment of parameters during periods of increased request rates.

          Steps
          Set up a centralized logging system
          Collect and structure logs from Nginx, Django, and the database
          Develop an ML model for log grouping and anomaly detection
          Implement Kubernetes-based database with replication
          Train an ML model to optimize Kubernetes parameters dynamically
          Expected Results
          A centralized logging system for improved monitoring and troubleshooting
          ML-powered anomaly detection
          ML-driven dynamic configuration for optimal performance
          Requirements
          Python and basic understanding of ML frameworks
          Kubernetes, basic understanding, k8s, Helm, Operators, OpenShift
          Django and Nginx, basic understanding of web frameworks and logging
          Database knowledge, PostgreSQL, database replication
          Links
          Django REST API: https://github.com/BNLNPPS/nopayloaddb
          Automized deployment with helm-chart: https://github.com/BNLNPPS/nopayloaddb-charts
          Mentors
          Ruslan Mashinistov - BNL
          John S. De Stefano Jr. - BNL
          Michel Hernandez Villanueva - BNL
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          HSFCondDB
          Participating Organizations
          BNL

          ~~~~~~~~~~

          Interactive Differential Debugging - Intelligent Auto-Stepping and Tab-Completion
          Description
          Differential debugging is a time-consuming task that is not well supported by existing tools. Existing state-of-the-art tools do not consider a baseline(working) version while debugging regressions in complex systems, often leading to manual efforts by developers to achieve an automatable task.

          The differential debugging technique analyzes a regressed system and identifies the cause of unexpected behaviors by comparing it to a previous version of the same system. The idd tool inspects two versions of the executable – a baseline and a regressed version. The interactive debugging session runs both executables side-by-side, allowing the users to inspect and compare various internal states.

          This project aims to implement intelligent stepping (debugging) and tab completions of commands. IDD should be able to execute until a stack frame or variable diverges between the two versions of the system, then drop to the debugger. This may be achieved by introducing new IDD-specific commands. IDD should be able to tab complete the underlying GDB/LLDB commands. The contributor is also expected to set up the necessary CI infrastructure to automate the testing process of IDD.

          Expected Results
          Enable stream capture
          Enable IDD-specific commands to execute until diverging stack or variable value.
          Enable tab completion of commands.
          Set up CI infrastructure to automate testing IDD.
          Present the work at the relevant meetings and conferences.
          Requirements
          Python & C/C++ programming
          Familiarity debugging with GDB/LLDB
          Links
          IDD Repository
          Mentors
          Vipul Cariappa - CompRes
          Martin Vasilev - University of Plovdiv
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          CppInterOp
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Julia Interfaces to HepMC3
          Description
          In high-energy physics experiments at CERN it is necessary to simulate physics events in order to compare predicted observations with those that the LHC experiments actually observe. A key piece of the software chain used to do that is the HepMC3 event record library, which encodes the output from physics event generators in a standard way, so that they can be used by downstream detector simulation and analysis codes.

          There is now increasing interest in using Julia as a language for HEP software, as it combines the ease of programming in interactive languages, e.g., Python, with the speed of compiled language, such as C++. As part of building up the ecosystem of supporting packages for Julia in high-energy physics, developing interfaces to read, manipulated and write HepMC3 event records in Julia is the aim of this project.

          Task ideas
          This project would develop a wrapper library for HepMC3 allowing the HepMC3 data objects and methods, in C++, to be called from Julia.

          It would utilise the general underlying wrapper interfaces in CxxWrap and the automated wrapper code generator WrapIt! to allow for as easy and maintainable an interface as possible.

          A key outcome would be a set of unit tests and examples, based on the HepMC3 ones, demonstrating how to use the library and proving that the code is correct.

          Expected results and milestones
          Reading of HepMC3 event files
          Particularly the ASCII format will be targeted first
          Access to event data structures
          Access to particle properties
          Navigation of the event and the vertices between parent and child particles
          Access to run information
          Update of HepMC3 data structures
          Creation of new HepMC3 events
          Re-serialisation of these events to file
          Initially ASCII
          Documentation and examples on how to use the Julia interfaces
          HepMC3.jl package registered in the Julia general registry
          Extension of serialisation to ROOT format (stretch goal)
          Requirements
          Programming experience in C++
          Prior experience in Julia (very advantageous)
          A background understanding of high-energy physics (advantageous)
          Evaluation Exercise
          TBD

          Links
          Julia Programming Language
          JuliaHEP HSF Group
          HepMC3 Repository
          CxxWrap
          WrapIt!
          Mentors
          Graeme Stewart - CERN
          Mateusz Fila - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 175 hours
          Mentor availability: June-July- August
          Corresponding Project
          JuliaHEP
          Participating Organizations
          CERN


          ~~~~~~~~~~

          MCnet/MCviz - graph and 3D-viewer tools for simulated particle collisions
          Description
          Simulations are key to particle-physics research: many modern theoretical models have such complex consequences that we test theory not by comparing measurements of particle collisions to predicted functional forms, but by generating simulated collision-events from the theory and analyzing them identically to the real ones from the particle collider.

          This means that event generators are incredibly important to particle physics, as the most-used link between experiment and theory, and as a crucial data format for exchange of ideas. They are also an excellent way to introduce new researchers and the public to particle-physics concepts. However, the toolset for MC event manipulation and visualisation is less powerful and coherent than it should be, and this project seeks to improve that situation!

          Task ideas
          This project will pick up old ideas and code for MC-event visualisation – both of the interaction graph that illustrates the internal theory computation, and the external appearance of the resulting collision decay-products – and produce a new set of tools useful both to physicists and for public outreach.

          Expected results and milestones
          Extend the mcgraph tool to be usable with both the HepMC and LHE MC-event formats.
          Refactor mcgraph into a library capable of rendering to a web browser in a server app.
          Interface the Phoenix event-viewer library to display 3D events (with and without a dummy detector model) to a web browsers.
          Display interactive particle information and jet clustering in graph and 3D view interfaces.
          Requirements
          Command-line tools
          Python
          Web technologies
          Gitlab CI
          git
          Links
          Phoenix event view library
          Old MCview web-based MC event viewer
          MC event-graph viewer
          Old MCviz event-graph viewer
          HepMC3 event format
          LHE event format
          Mentors
          Andy Buckley - CERN
          Chris Gutschow - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          MCnet
          Participating Organizations
          UofGlasgow


          ~~~~~~~~~~

          MCnet/OpenData - tools and exercises for open-data exploration with MC simulations
          Description
          CERN’s experiments are committed to publishing their data in a form that is accessible to all, both for research purposes and for education. For example, the ATLAS experiment provides Jupyter notebook exercises based on live-analysing reduced forms of the real collider data.

          But particle-physics researchers also use simulations of data as a crucial tool for testing theories and for understanding the background processes that new physics effects have to be isolated from. For this we use Monte Carlo (MC) event-generator codes, which are statistical implementations of the fundamental physics theory that sample real-looking events from the predicted particle types and kinematics. These are not yet represented in open-data exercises.

          Task ideas
          In this project we will develop new tools and exercises for extending open-data analysis resources to include MC event simulations. It will both reduce the entry barriers to outreach with open data and enable more engaging exercises with hypothetical new-physics models.

          Expected results and milestones
          Develop a library of wrapper functions to make open-data analysis more approachable for non-experts.
          Create functions and datasets for loading and analysing MC event samples through Jupyter.
          Develop a new Jupyter+Binder worksheet for outreach-oriented open-data MC analysis.
          Requirements
          Python
          Jupyter
          Binder
          Gitlab CI
          git
          Links
          ATLAS open data
          Example open-data analysis notebook
          Jupyter
          Binder
          Mentors
          Andy Buckley - CERN
          Chris Gutschow - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 175 hours
          Mentor availability: June-October
          Corresponding Project
          MCnet
          Participating Organizations
          UofGlasgow


          ~~~~~~~~~~

          Integrating Support for Google XLS in HLS4ML
          Description
          Google XLS (Accelerated Hardware Synthesis) is an advanced open-source framework for high-level hardware design, offering flexible and efficient synthesis for FPGA and ASIC applications. By integrating XLS into HLS4ML, a framework for translating machine learning models into FPGA-friendly code, we can leverage XLS’s optimizing compiler and domain-specific language to improve resource efficiency, performance, and portability. This integration will enable seamless generation of highly optimized hardware implementations for ML models while maintaining the ease of use that HLS4ML provides.

          HLS4ML currently supports traditional HLS tools like Vivado HLS and Intel HLS, but adding XLS can bring further benefits such as better compilation times, improved hardware efficiency, and wider vendor compatibility. This project will focus on developing an interface between HLS4ML and XLS, allowing ML models to be translated into XLS IR and synthesized efficiently.

          Task Ideas
          Develop a backend in HLS4ML that translates neural network layers into XLS Intermediate Representation (IR).
          Implement the key ML operations (e.g., matrix multiplications, activations, and pooling) via XLS’s DSLX language and map them to HLS4ML operations.
          Benchmark and compare performance, resource utilization, and synthesis results against existing HLS4ML backends.
          Extend HLS4ML’s configuration options to allow selection of XLS as a backend, ensuring ease of integration.
          Expected Results
          A prototype of a backend in HLS4ML supporting XLS-based synthesis.
          Conversion scripts to map ML operations to XLS IR.
          Performance evaluation of XLS and existing HLS backends.
          Documentation and tutorials for using XLS with HLS4ML.
          Requirements
          Proficiency in Python and C++.
          Knowledge of hardware and compiler design.
          Basic familiarity with neural networks.
          Familiarity with version control systems like Git/GitHub.
          Links
          hls4ml documentation
          hls4ml Repository
          Google XLS documentation
          Google XLS repository
          Mentors
          Vladimir Loncar - CERN
          Dimitrios Danopoulos - CERN
          Additional Information
          Difficulty level (low / medium / high): medium/high
          Duration: 350 hours
          Mentor availability: Flexible
          Corresponding Project
          ML4EP
          Participating Organizations
          CERN


          ~~~~~~~~~~

          Optimizing Model Splitting in hls4ml for Efficient Multi-Graph Inference
          Description
          hls4ml is an open-source tool that enables the deployment of machine learning (ML) models on FPGAs using High-Level Synthesis (HLS). It automatically converts pre-trained models from popular deep learning frameworks (e.g., Keras, PyTorch, and ONNX) into optimized firmware for FPGA-based inference.

          Traditionally, the entire ML model is synthesized as a monolithic graph, which can lead to long synthesis times and complicated debugging, especially for large model topologies. Splitting the model graph at specified layers into independent subgraphs allows for parallel synthesis and step-wise optimization. However, finding the ‘optimal’ splitting points and optimizing FIFO buffers in between the subgraphs remains a challenge, especially when dealing with dynamic streaming architectures.

          This project aims to investigate optimal splitting strategies for complex ML models in hls4ml, focusing on efficient FIFO depth optimization across multi-graph designs. The goal is to develop methodologies that can be integrated into hls4ml to enable automated and optimal graph splitting for improved performance.

          Task ideas
          The contributor will start by familiarizing themselves with hls4ml and building ML models using multi-graph designs. They will implement profiling techniques (e.g., VCD logging) to measure FIFO occupancy and backpressure in order to develop a FIFO optimization strategy for multi-graph designs. They will also investigate multi-objective optimization algorithms to determine optimal splitting points based on subgraph resource usage or dataflow patterns. Finally, they will integrate these methodologies with hls4ml and run benchmarks to validate improvements in latency, resource utilization, etc.

          Expected results and milestones
          Familiarization with hls4ml: Understand the hls4ml workflow, including synthesis, and simulation.
          Research and Evaluation: Explore FIFO profiling and optimization strategies along with algorithms to partition the model graph given specific optimization objectives.
          Validation: Benchmark against monolithic implementations and compare differences in latency and resource utilization.
          Requirements
          Proficiency with computer architecture, FPGA design and simulation tools (e.g., Vivado)
          Experience with Python
          Understanding of ML concepts is beneficial.
          Familiarity with version control systems like Git/GitHub.
          Links
          hls4ml documentation
          hls4ml Repository
          Vivado Design Implementation
          Mentors
          Vladimir Loncar - CERN
          Dimitrios Danopoulos - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: Flexible
          Corresponding Project
          ML4EP
          Participating Organizations
          CERN

          ~~~~~~~~~~

          RNTuple in JSROOT
          Description
          RNTuple is the next-generation data format for high-energy physics (HEP) data collected from the LHC. It is part of ROOT, a cornerstone software package for the storage, visualization and analysis of scientific data, widely used in the scientific community and particularly in HEP. ROOT is a C++ and Python framework, but it recently became available in the browsers as well through a Javascript implementation of some of its parts: JSROOT. Since RNTuple is still in the experimental phase, it currently lacks a JSROOT interface and its contents cannot be visualized in the browser, a common and desirable property of many ROOT objects. The goal of this project is filling this gap by making JSROOT able to read and display data stored inside an RNTuple.

          Task ideas
          In this project, the student will learn the internals of the RNTuple binary format and use this knowledge to implement a Javascript interface to expose RNTuple to JSROOT.

          Expected results and milestones
          Familiarize with the JSROOT framework, understanding how to integrate new components into it;
          read and implement (a subset of) the RNTuple binary format specifications, in Javascript; this will concretely mean implementing the deserialization code from a binary blob to a RNTuple object that may be used by JSROOT;
          enable the visualization of an RNTuple’s fields in the browser, leveraging the existing framework in JSROOT.
          Requirements
          Knowledge of Javascript / ES6
          Basic knowledge of “low-level” programming (primitive types binary layouts, bit-level manipulations, reinterpreting bytes as different types, …)
          Experience with git / github
          (Bonus): familiarity with any binary format
          Links
          ROOT Project homepage
          ROOT Project repository
          JSROOT homepage
          JSROOT repository
          Introduction to RNTuple
          RNTuple architecture overview
          RNTuple Binary Specification
          Mentors
          Serguei Linev - CERN
          Giacomo Parolini - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          ROOT
          Participating Organizations
          CERN

          ~~~~~~~~~~

          Rucio WebUI Revamp
          Description
          Rucio is an open-source software framework that provides functionality to scientific collaborations to organize, manage, monitor, and access their distributed data and dataflows across heterogeneous infrastructures. Originally developed to meet the requirements of the high-energy physics experiment ATLAS, Rucio has been continuously enhanced to support diverse scientific communities. Since 2016, Rucio has orchestrated multiple exabytes of data access and data transfers globally.

          The Rucio WebUI is a Next.js application utilized by various users within collaborating communities to access, monitor, and manage their distributed data. Key features of the Rucio WebUI include:

          SDK for Streaming: Facilitates seamless data streaming from the Rucio server to page components, ensuring a responsive user interface.
          Typed in TypeScript with Generics: Strict typing ensures code integrity and enhances development efficiency.
          Accessibility and Responsiveness: Designed with accessibility and responsiveness in mind, ensuring usability across various devices.
          Testing and Stability: Extensive testing ensures robustness and reliability in all components.
          Feature Toggles: Dynamic feature toggles provide flexibility in enabling or disabling specific functionalities as needed.
          Component Library: Utilizes Storybook and TailwindCSS to enhance development speed and consistency.
          Tasks
          Upgrade to Next.js 15, React 19, TailwindCSS 4.x:
          Migrate the existing codebase to Next.js 15 to leverage the latest features and performance improvements.
          Utilize Server Side Rendering and React Query in Client Side Components to enhance data-fetching capabilities.
          Migrate tailwind.config.js to new CSS based configuration for TailwindCSS 4.x.
          Enhance User Experience for Site Administrators and Operators:
          Currently the WebUI focuses on List/Get views with the exception of allowing users to Create Rules. Add features to Create/Edit resources for site administrators and operational experts.
          Investigate legacy views in the previous Flask application and migrate them to the new WebUI.
          Redesign these views to be more user-friendly, incorporating feedback from site administrators and operators.
          Migrate Authentication to NextAuth (Auth.js):
          Transition existing x509 and user/password authentication mechanisms to NextAuth.
          Ensure compatibility with various authentication flows, including OAuth and OpenID Connect.
          Develop an RBAC system to ensure users have access only to functionalities relevant to their roles, enhancing security and usability.
          Transition to a Monorepo Structure:
          Migrate the Rucio WebUI to a monorepo structure to improve code organization and facilitate the sharing of common components across different projects.
          Requirements
          Mandatory:

          Proficiency in React.js and Next.js
          Experience with TailwindCSS
          Strong knowledge of JavaScript (ECMAScript 6) and TypeScript
          Familiarity with Python 3 and Flask
          Proficiency with Linux, Git, and Docker
          Good to Have:

          Understanding of NX Monorepos
          Experience with AGGrid Data Tables
          Experience with GitHub Actions
          Knowledge of HTTP REST APIs
          Familiarity with OpenID Connect and x509 protocols
          Expected Results
          By the end of GSoC 2025, we expect to have a revamped Rucio WebUI that:

          Is upgraded to Next.js 15 with integrated React Query.
          Utilizes both client and server-side components as per React 19’s stable features.
          Supports TailwindCSS 4.0 for a modern design system.
          Offers enhanced user experiences tailored for site administrators and operators.
          Employs NextAuth for streamlined authentication processes.
          Implements a robust RBAC system.
          Adopts a monorepo structure for improved code organization and component sharing.
          Links
          Rucio GitHub Repository
          Rucio UI Presentation
          Rucio Documentation
          Rucio System Overview Journal Article (Springer)
          Rucio Operational Experience Article (IEEE Computer Society)
          Mentors
          Mayank Sharma - University of Michigan, Ann Arbor
          Martin Barisits - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-November
          Corresponding Project
          Rucio
          Participating Organizations
          CERN

          ~~~~~~~~~~

          Background Enrichment augmented Anomaly Detection (BEAD) for new physics searches at LHC
          

          Short description of the project
          A long-standing mystery of fundamental physics is the existence of dark matter (DM), a type of matter that has little interaction with ordinary matter but is supported by various astrophysical and cosmological observations and is six times more abundant than ordinary matter in the universe. Several Large Hadron Collider (LHC) experiments are conducting searches aimed at detecting dark matter. Unsupervised and semi-supervised learning outlier detection techniques are advantageous to these searches, for casting a wide net on a variety of possibilities for how dark matter manifests, as they impose minimal constraints from specific physics model details, but rather learn to separate characteristics of rare signals starting from the knowledge of the background they’ve been trained on. Developing innovative search techniques for probing dark matter signatures is crucial for broadening the DM search program at the LHC, and BEAD is a Python package that uses deep learning based methods for anomaly detection in HEP data for such new physics searches. BEAD has been designed with modularity in mind, to enable usage of various unsupervised latent variable models for any task.

          BEAD has five main running modes:

          Data handling: Deals with handling file types, conversions between them and pre-processing the data to feed as inputs to the DL models.

          Training: Trains a model to learn implicit representations of the background data that may come from multiple sources(/generators) to get a single, encriched latent representation of it.

          Inference: Using a model trained on an enriched background, the user can feed in samples where to detect anomalies in.

          Plotting: After running Inference, or Training, one can generate plots. These include performance plots as well as different visualizations of the learned data.

          Diagnostics: Enabling this mode allows running profilers that measure a host of metrics connected to the usage of the compute node to help optimization of the code (using CPU-GPU metrics).

          The package is under active development. The student in this project will work on the machine learning models available in BEAD, and implementing new models to perform anomaly detection, initially on simulated data.

          Task ideas
          Possible projects include:

          New auto-encoder models could be developed, better identifying correlations between data objects in a given particle physics dataset entry (containing event level and/or physics object level information). New models could also improve performance on live / unseen data. These could include transformer, GNN, probabilistic and other tiypes of networks.
          Existing models could be tested on different datasets, potentially identifying distinct latent spaces populated by the different LHC physics processes, that can enable improved anomaly detection.
          Ideas from the student working on this project are also welcome.

          Expected results
          An improved performance of selected models, with documentation and figures of merit that may include:

          Plots made in matplotlib that demonstrate the performance of the new models compared to the old
          Documentation of the design choices made for the improved models
          Documented evaluation of a physics analysis on data before and after compression
          Requirements
          Python
          Linux environment
          ML / unsupervised algorithms key concepts
          PyTorch

          Desired skills: transformers and/or graph neural networks, particle physics theory and experiments, particle physics simulations
          Links
          Paper on unsupervised ML algorithms using HEP datasets
          Review of LHC searches using unsupervised learning
          BEAD GitHub repository (WIP)
          ROOT
          Jupyter
          PyTorch
          Mentors
          Pratik Jawahar - CERN
          Sukanya Sinha - CERN
          Caterina Doglioni - Backup Mentor - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-August
          Corresponding Project
          BEAD
          Participating Organizations
          SMARTHEP
          UManchester

          ~~~~~~~~~~

          Estimating the energy cost of ML scientific software
          Description
          At a time where “energy crisis” is something that we hear daily, we can’t help but wonder whether our research software can be made more sustainable, and more efficient as a byproduct. In particular, this question arises for ML scientific software used in high-throughput scientific computing, where large datasets composed of many similar chunks are analysed with similar operations on each chunk of data. Moreover, CPU/GPU-efficient software algorithms are crucial for the real-time data selection (trigger) systems in LHC experiments, as the initial data analysis necessary to select interesting collision events is executed on a computing farm located at CERN that has finite CPU resources.

          The questions we want to start answering in this work are:

          what is the trade off between performance of a ML algorithm and its energetic efficiency?
          can small efficiency improvements in ML algorithms running on Large Hadron Collider data have a sizable energetic impact?
          how do these energy efficiency improvements vary when using different computing architectures (1) and/or job submission systems (2)?
          Task ideas
          The students in this project will use metrics from the Green Software Foundation and from other selected resources to estimate the energy efficiency of machine learning software from LHC experiments (namely, top tagging using ATLAS Open data) and from machine learning algorithms for data compression (there is another GSoC project developing this code, called Baler). This work will build on previous GSoC / Master’s thesis work, and will expand these results for GPU architectures. If time allows, the student will then have the chance to make small changes to the code to make it more efficient, and evaluate possible savings.

          Expected results and milestones
          Understand and summarise the metrics for software energy consumption, focusing on computing resources at CERN;
          Become familiar with running and debugging the selected software frameworks and algorithms;
          Set up tests and visualisation for applying metrics to the selected software
          Run tests and visualise results (preferably using a Jupyter notebook)
          Vary platforms and job submission systems
          Identify possible improvements, apply them, and run tests again
          Requirements
          Python
          git
          Jupyter notebooks
          PyTorch or equivalent ML toolkit
          Desirable: code profiling experience
          Links
          (1) Green Software Foundation course
          (2) Code by the previous GSoC student
          Mentors
          Caterina Doglioni - CERN
          Tobias Fitschen - Backup Mentor - CERN
          James Smith - Backup Mentor - University of Manchester
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October (with 2-3 weeks mentor vacation where student will work independently with minimal guidance)
          Corresponding Project
          SMARTHEP
          Participating Organizations
          UManchester
          CERN

          ~~~~~~~~~~

          Sustainable Quantum Computing algorithms for particle physics reconstruction
          Description
          Reconstructing the trajectories of charged particles as they traverse several detector layers is a key ingredient for event reconstruction at any LHC experiment. The limited bandwidth available, together with the high rate of tracks per second, makes this problem exceptionally challenging from the computational perspective. With this in mind, Quantum Computing is being explored as a new technology for future detectors, where larger datasets will further complicate this task. Furthermore, when choosing such alternative sustainability will play a crucial role and needs to be studied in detail. This project will consist in the implementation of both Quantum and Classical Machine Learning algorithms for track reconstruction, and using open-source, realistic event simulations to benchmark them from both a physics performance and an energy consumption perspective.

          First steps
          Basic understanding of track reconstruction at LHC using ACTS and/or Allen framework.
          Familiarizing her/himself with trackML simulation datasets https://www.kaggle.com/competitions/trackml-particle-identification/data?select=train_sample.zip.
          Learning how to use the quantum simulator for QML algorithms https://pennylane.ai/.
          Milestones
          Choosing a ML algorithm (or part of) in quantum computing and its classical counterpart for track reconstruction.
          Mapping of track reconstruction problem to Ising-like Hamiltonian.
          Prototype implementation of classical and quantum track reconstruction using trackML simulation inputs.
          Expected results
          Benchmarking physics output and energy consumption of the classical and quantum algorithm.
          Requirements
          CUDA, python, C++
          Evaluation Tasks and Timeline
          To be completed
          Corresponding Project
          QuantumForTracking
          Participating Organizations
          CERN

          ~~~~~~~~~~

          TMVA SOFIE - GPU Support for Machine Learning Inference
          Description
          SOFIE (System for Optimized Fast Inference code Emit) is a Machine Learning Inference Engine within TMVA (Toolkit for Multivariate Data Analysis) in ROOT. SOFIE offers a parser capable of converting ML models trained in Keras, PyTorch, or ONNX format into its own Intermediate Representation, and generates C++ functions that can be easily invoked for fast inference of trained neural networks. Using the IR, SOFIE can produce C++ header files that can be seamlessly included and used in a ‘plug-and-go’ style.

          SOFIE currently supports various Machine Learning operators defined by the ONNX standards, as well as a Graph Neural Network (GNN) implementation. It supports the parsing and inference of Graph Neural Networks trained using DeepMind Graph Nets.

          As SOFIE continues to evolve, there’s a need to enable inference on GPUs. This project aims to explore different GPU stacks (such as CUDA, ROCm, ALPAKA) and implement GPU-based inference functionalities in SOFIE. There is already a SYCL implementation for SOFIE, developed in 2023, which can serve as a reference for future development.

          Task ideas
          In this project, the contributor will gain experience with GPU programming and its role in Machine Learning inference. They will start by understanding SOFIE and running inference on CPUs. After researching GPU stacks and methods of their integration with SOFIE, the contributor will implement GPU support for inference, ensuring the code is efficient and well-integrated with GPU technologies.

          Expected results and milestones
          Familiarization with TMVA SOFIE: Understanding the SOFIE architecture, working with its internals, and running inference on CPUs.
          Research and Evaluation: Analyzing various GPU stacks (CUDA, ROCm, ALPAKA, etc.) and determining their alignment with SOFIE.
          Implementation of GPU Inference: Developing functionalities for GPU-based inference in SOFIE.
          [Optional] Benchmarking: Evaluating the performance of the new GPU functionality by benchmarking memory usage, execution time, and comparing results with other frameworks (such as TensorFlow or PyTorch).
          Requirements
          Proficiency in C++ and Python.
          Knowledge of GPU programming (e.g., CUDA).
          Familiarity with version control systems like Git/GitHub.
          Links
          ROOT Project homepage
          ROOT Project repository
          SOFIE Repository
          Implementation of SOFIE-SYCL
          Accelerating Machine Learning Inference on GPUs with SYCL
          Mentors
          Lorenzo Moneta - CERN
          Sanjiban Sengupta - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: Flexible
          Corresponding Project
          ML4EP
          Participating Organizations
          CERN


          ~~~~~~~~~~

          TMVA SOFIE - HLS4ML Integration for Machine Learning Inference
          Description
          SOFIE (System for Optimized Fast Inference code Emit) is a Machine Learning Inference Engine within TMVA (Toolkit for Multivariate Data Analysis) in ROOT. SOFIE offers a parser capable of converting ML models trained in Keras, PyTorch, or ONNX format into its own Intermediate Representation, and generates C++ functions that can be easily invoked for fast inference of trained neural networks. Using the IR, SOFIE can produce C++ header files that can be seamlessly included and used in a ‘plug-and-go’ style.

          Currently, SOFIE supports various machine learning operators defined by ONNX standards, as well as a Graph Neural Network implementation. It supports parsing and inference of Graph Neural Networks trained using DeepMind Graph Nets.

          As SOFIE evolves, there is a growing need for inference capabilities on models trained across a variety of frameworks. This project will focus on integrating hls4ml in SOFIE, thereby enabling generation of C++ inference functions on models parsed by hls4ml.

          Task ideas
          In this project, the contributor will gain experience with C++ and Python programming, hls4ml, and their role in machine learning inference. The contributor will start by familiarizing themselves with SOFIE and running inference on CPUs. After researching the possibilities for integration with hls4ml, they will implement functionalities that ensure efficient inference of ML models parsed by hls4ml, which were previously trained in external frameworks like TensorFlow and PyTorch.

          Expected results and milestones
          Familiarization with TMVA SOFIE: Understanding the SOFIE architecture, working with its internals, and running inference on CPUs.
          Research and Evaluation: Exploring hls4ml, its support for Keras and PyTorch, and possible integration with SOFIE.
          Integration with hls4ml: Developing functionalities for running inference on models parsed by hls4ml.
          Requirements
          Proficiency in C++ and Python.
          Knowledge of hls4ml
          Familiarity with version control systems like Git/GitHub.
          Links
          ROOT Project homepage
          ROOT Project repository
          SOFIE Repository
          hls4ml documentation
          hls4ml Repository
          Mentors
          Lorenzo Moneta - CERN
          Sanjiban Sengupta - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: Flexible
          Corresponding Project
          ML4EP
          Participating Organizations
          CERN

          ~~~~~~~~~~

          TMVA SOFIE - Enhancing Keras Parser and JAX/FLAX Integration
          Description
          SOFIE (System for Optimized Fast Inference code Emit) is a Machine Learning Inference Engine within TMVA (Toolkit for Multivariate Data Analysis) in ROOT. SOFIE offers a parser capable of converting ML models trained in Keras, PyTorch, or ONNX format into its own Intermediate Representation, and generates C++ functions that can be easily invoked for fast inference of trained neural networks. Using the IR, SOFIE can produce C++ header files that can be seamlessly included and used in a ‘plug-and-go’ style.

          SOFIE currently supports various Machine Learning operators defined by the ONNX standards, as well as a Graph Neural Network (GNN) implementation. It supports the parsing and inference of Graph Neural Networks trained using DeepMind Graph Nets.

          As SOFIE continues to evolve, this project aims to:

          Enhance the Keras parser to support models trained in the latest TensorFlow v2.18.0, which introduces NumPy 2.0 compatibility.
          Integrate JAX/FLAX support, enabling SOFIE to generate C++ inference functions for models developed using JAX/FLAX.
          Task ideas
          In this project, the contributor will gain experience with C++ and Python programming, TensorFlow/Keras and its storage formats for trained machine learning models, and JAX/FLAX for accelerated machine learning. They will begin by familiarizing themselves with SOFIE and its Keras parser. After researching the changes required to support the latest TensorFlow version, they will implement functionalities to ensure the successful generation of inference code for the latest Keras models. In the next phase, they will explore the JAX/FLAX library and investigate its potential integration with SOFIE.

          Expected results and milestones
          Familiarization with TMVA SOFIE: Understand the SOFIE architecture, run inference using the existing Keras parser, and analyze the current parser’s capabilities.
          Researching latest TensorFlow/Keras: Investigate the latest TensorFlow/Keras developments and assess their alignment with SOFIE.
          Improving the Keras Parser: Implement parser enhancements to support the latest TensorFlow version and validate inference results.
          JAX/FLAX Integration: Design and develop a parsing mechanism for JAX/FLAX models, ensuring compatibility with SOFIE’s IR and further generation of inference code.
          Requirements
          Proficiency in C++ and Python.
          Knowledge of TensorFlow/Keras and JAX/FLAX.
          Familiarity with version control systems like Git/GitHub.
          Links
          ROOT Project homepage
          ROOT Project repository
          SOFIE Repository
          Keras: The high-level API for TensorFlow
          JAX Documentation
          FLAX Documentation
          Mentors
          Lorenzo Moneta - CERN
          Sanjiban Sengupta - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: Flexible
          Corresponding Project
          ML4EP
          Participating Organizations
          CERN

          ~~~~~~~~~~

          Implementing Debugging Support
          Description
          xeus-cpp is an interactive execution environment for C++ in Jupyter notebooks, built on the Clang-Repl C++ interpreter, provided by CppInterOp. While xeus-cpp enables a seamless workflow for running C++ code interactively, the lack of an integrated debugging experience remains a gap, especially when dealing with code that is dynamically compiled and executed through LLVM’s JIT(Just-In-Time) infrastructure.

          Jupyter’s debugging system follows the Debug Adapter Protocol (DAP), enabling seamless integration of debuggers into interactive kernels. Existing Jupyter kernels, such as the IPython & the xeus-python kernel, have successfully implemented debugging workflows that support breakpoints, variable inspection, and execution control, even in dynamically executed environments. These implementations address challenges such as symbol resolution and source mapping for dynamically generated code, ensuring that debugging within Jupyter remains intuitive and user-friendly.

          However, debugging C++ inside an interactive environment presents unique challenges, particularly due to Clang-Repl’s use of LLVM’s ORC JIT to compile and execute code dynamically. To integrate debugging into xeus-cpp, the project will explore existing solutions for DAP implementations like lldb_dap and debuggers like lldb that can interface with Jupyter while effectively supporting the execution model of Clang-Repl.

          Project Milestones
          Seamless debugging integration, establishing reliable interactions between xeus-cpp, a Debug Adapter Protocol (DAP) implementation, and a debugger.
          Implement a testing framework through xeus-zmq to thoroughly test the debugger. This can be inspired by an existing implementation in xeus-python.
          Present the work at the relevant meetings and conferences.
          Requirements
          C/C++
          Basic understanding of the Debug Adapter Protocol
          Basic understanding of the stack used by xeus-cpp: xeus, cppinterop, clang-repl
          Research on different DAP implementations like lldb_dap and debuggers like lldb/gdb that can be utilized for the project.
          Links
          Repo
          Debug Adaptor Protocol
          Debugging support through Jupyter:
          https://jupyterlab.readthedocs.io/en/stable/user/debugger.html
          https://jupyter-client.readthedocs.io/en/latest/messaging.html#debug-request
          Mentors
          Anutosh Bhat - QuantStack
          Johan Mabille - QuantStack
          Vipul Cariappa - CompRes
          Aaron Jomy - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Xeus-Cpp
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Enable GPU support and Python Interoperability via a Plugin System
          Description
          Xeus-Cpp integrates Clang-Repl with the xeus protocol via CppInterOp, providing a powerful platform for C++ development within Jupyter Notebooks.

          This project aims to introduce a plugin system for magic commands (cell, line, etc.), enabling a more modular and maintainable approach to extend Xeus-Cpp. Traditionally, magic commands introduce additional code and dependencies directly into the Xeus-Cpp kernel, increasing its complexity and maintenance burden. By offloading this functionality to a dedicated plugin library, we can keep the core kernel minimal while ensuring extensibility. This approach allows new magic commands to be developed, packaged, and deployed independently—eliminating the need to rebuild and release Xeus-Cpp for each new addition. Initial groundwork has already been laid with the Xplugin library, and this project will build upon that foundation. The goal is to clearly define magic command compatibility across different platforms while ensuring seamless integration. A key objective is to reimplement existing features, such as the LLM cell magic and the in-development Python magic, as plugins. This will not only improve modularity within Xeus-Cpp but also enable these features to be used in other Jupyter kernels.

          As an extended goal, we aim to develop a new plugin for GPU execution, leveraging CUDA or OpenMP to support high-performance computing workflows within Jupyter.

          Project Milestones
          Move the currently implemented magics and reframe using xplugin
          Complete the on-going work on the Python interoperability magic
          Implement a test suite for the plugins
          Extended: To be able to execute on GPU using CUDA or OpenMP
          Optional: Extend the magics for the wasm use case (xeus-cpp-lite)
          Present the work at the relevant meetings and conferences
          Requirements
          Python
          C/C++
          GPU programming; CUDA/OpenMP
          Links
          Repo
          Related Issues:
          https://github.com/compiler-research/xeus-cpp/issues/4
          https://github.com/compiler-research/xeus-cpp/issues/140
          Mentors
          Anutosh Bhat - QuantStack
          Johan Mabille - QuantStack
          Vipul Cariappa - CompRes
          Aaron Jomy - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Xeus-Cpp
          Participating Organizations
          CompRes

          
    totalCharacters_of_ideas_content_parent: 107186
    totalwords_of_ideas_content_parent: 25550
    totalTokenCount_of_ideas_content_parent: 20259
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/cern-hsf/
    idea_list_url: https://hepsoftwarefoundation.org/gsoc/2025/summary.html


  - organization_id: 17
    organization_name: CGAL Project
    no_of_ideas: 11
    ideas_content: |
          Enhancing the 2D Regularized Boolean Operation Demo
          Mentor: Efi Fogel

          Project description: The new demonstration program of the "2D Regularized Boolean Operations" package demonstrates various operations on polygons, such as, union, intersection, and Minkowski sum. It also demonstrates the application of several operations in a pipeline fashion. The demo has not been published yet; it requires a few enhancements, such as the support of Boolean operations on general polygons bounded by non-linear curves.

          Required Skills: Qt6, geometry, code development tools (e.g., git), and C++14 proficiency

          Contact: efifogel@gmail.com

          Duration: 350h

          ~~~~~~~~~~

          Tetrahedral Isotropic Remeshing Parallelization
          Mentor: Jane Tournois

          Project description:

          The goal of this project is to parallelize the code of the Tetrahedral Remeshing algorithm available in CGAL. This multi-material tetrahedral remeshing algorithm [2] is based on local and atomic operations such as edge collapse, edge split and edge flip, that could be performed in parallel to improve the performances of the code. The 3D Triangulations [3] and Tetrahedral Mesh Generation package [4] provide a framework to implement mesh operations concurrently. The same framework will be used to parallelize the remeshing algorithm, with the Intel TBB library [5].

          Resources:

          [1] CGAL Tetrahedral Remeshing package
          [2] The original publication Multi-Material Adaptive Volume Remesher
          [3] CGAL 3D Triangulations
          [4] CGAL Tetrahedral Mesh Generation package
          [5] Intel Threading Building Blocks
          Required Skills: C++17, Mesh Processing, Computational Geometry, Parallelism with TBB

          Contact: jane.tournois@geometryfactory.com

          Duration: 350h

          ~~~~~~~~~~

          New Mesh Subdivision Methods
          Mentor: Mael Rouxel-Labbé

          Project description:

          Subdivision methods are efficient techniques to produce smooth surfaces from polygonal meshes. Within CGAL [1], a handful of classic subdivision techniques already exist (CatmullClark subdivision, Loop subdivision DooSabin subdivision, Sqrt3 subdivision). The goal of this project is two-fold: (a) implement newer subdivision techniques -- such as Interpolatory SQRT(3) Subdivision [2], which builds upon an algorithm that is already found in CGAL -- and compare them to our existing algorithms (b) Investigate the use of these newer techniques as a preprocessing step in some of CGAL's newer remeshing techniques (such as adaptive remeshing).

          Resources:

          [1] CGAL Subdivision package
          [2] Interpolatory SQRT(3) Subdivision
          [3] Gaussian-Product Subdivision Surfaces
          [4] CGAL's upcoming adaptive remeshing algorithms
          Required Skills: C++17, Mesh Processing

          Contact: mael.rouxel.labbe@geometryfactory.com

          Duration: 350h

          ~~~~~~~~~~

          Enhanced Dual Contouring
          Mentor: Mael Rouxel-Labbé, Pierre Alliez

          Project description:

          A previous GSoC launched the process of adding classic contouring methods to CGAL: Marching Cubes and Dual Contouring. This package is about to be finalized and will be integrated soon into CGAL (https://github.com/CGAL/cgal/pull/6849). Many enhancements exist for the Dual Contouring method to improve its robustness: placement of the dual point, improved conditioning of the SVD matrices, or on-the-fly refinement of the underlying grid [1]. Another aspect is speed, as a grid structure is well adapted to GPU computation.

          The project will first focus on manifold contouring methods and robustness in standard C++. If there is time and the candidate has the required skills, we can also explore runtime aspects and the conversion to a GPU implementation. If there is time and the candidate does not have the required skills, we shall explore the implementation of other contouring methods such as Dual Marching Cubes [2].

          Resources:

          [1] Manifold Dual Contouring
          [2] Dual Marching Cubes
          Feature-Sensitive Subdivision and Isosurface Reconstruction
          Required Skills: C++17, Dual Contouring, linear algebra / quadric error metrics, possibly GPU algorithms

          Contact: mael.rouxel.labbe@geometryfactory.com

          Duration: 350h

          ~~~~~~~~~~

          Topological Filtering of Features in Triangle Meshes
          Mentor: Sebastien Loriot

          Project description:

          Remeshing algorithms in CGAL requires the proper extraction of sharp features so that they can be represented in the output mesh (like here for example). Classical method to detect sharp features are based on collecting edges with sharp dihedral surface angles. However, depending on the quality of the input mesh, some noisy edges might be detected, or some edges might be detected. To workaround these issues, it might be interesting to rely on tools from Topological Data Analysis, like for example persistence. Indeed, extra data or missing data are all related to a notion of scale at which the problem is looked at. The goal of this project is to implement such a strategy for provide curated feature edge graph to the meshing algorithm of CGAL. If time allows, extension to detection of significant handles might also be looked at.

          Resources:

          A Practical Solver for Scalar Data Topological Simplification
          To cut or to fill: a global optimization approach to topological simplification
          Topological Simplification of Nested Shapes
          Gudhi library
          Required Skills: C++17, Mesh Processing, Topological Data Analysis

          Contact: sebastien.loriot@geometryfactory.com

          Duration: 350h

          ~~~~~~~~~~

          Improving ARAP in CGAL
          Mentor: Andreas Fabri

          Project description:

          As-Rigid-As-Possible (ARAP) surface modeling is one of the most well known approach for deformation of surfaces. It has been implemented in CGAL, within the Surface Mesh Deformation package (https://doc.cgal.org/latest/Surface_mesh_deformation/index.html#Chapter_SurfaceMeshDeformation). Since the original paper (Sorkine & Alexa, 2007 - As-Rigid-As-Possible Surface Modeling), which is implemented in CGAL, a number of improvements have been proposed. The goal of this project is to investigate these improvements, and enhance the CGAL implementation. Another direction of interest is the extension of the ARAP formulation to the setting of volume deformation of tetrahedral meshes.

          Resources:

          As-Rigid-As-Possible Surface Modeling
          ARAP Revisited Discretizing the Elastic Energy using Intrinsic Voronoi Cells
          Higher Order Continuity for Smooth As-Rigid-As-Possible Shape Modeling
          Required Skills: C++17, linear algebra

          Contact: andreas.fabri@geometryfactory.com

          Duration: 350h

          ~~~~~~~~~~

          Extending 2D Arrangement Drawings
          Mentor: Efi Fogel

          Project description: The "2D Arrangement" package partially supports limited drawing of a 2D arrangements. The goal of this project is extend the capabilities of 2D arrangement drawing. In particular:

          The drawing is limited. An instance of the the Arrangement_2<Traits,Dcel> template can be used to represent 2D arrangements on the plane. The 2D Arrangement package supports ten traits classes that can substitute the Traits parameter. A traits class determines the family of curves that induce the arrangement, e.g., Bezier curves. Currently, arrangement induced by curves of several families cannot be drawn.
          The drawing is inefficient and should be optimized.
          The drawing of arrangements induced by geodesic arcs on the sphere in 3D is deficient. Currently only the curves are drawn (and the faces are not). The Earth demo exhibit some drawing of such arrangements, but it applies a trick that restricts the drawing to faces that do not cross the equator of the sphere. Addressing this item requires knowledge and experience in 3D graphics.
          Required Skills: Qt6 and 3D graphics, geometry, code development tools (e.g., git), and C++17 proficiency

          Contact: efifogel@gmail.com

          Duration: 350h

          ~~~~~~~~~~

          Hexahedral mesh generation
          Mentor: Guillaume Damiand

          Project description:

          The goal of this project is to implement the method of the paper [1] "A template-based approach for parallel hexahedral two-refinement", Steven J. Owen, Ryan M. Shih, Corey D. Ernst; in CGAL. This method allows to generate a locally refined hexahedral mesh, starting from a coarse grid, and using different templates for refinement. It will be implemented using a 3D linear cell complex [2] as underlying data-structure. To implement the different templates, we can use the volumic Query-replace operation [3]. The project was started last year and a preliminary version of the method already exists. The goal of this project is to finish this development, and to propose an integration in CGAL. To do so, the work to do is: (1) finish the sequential version, adding displacement of new vertices in order to obtain smooth meshes; (2) validate results on many different input meshes; (3) write the doc and the examples; (4) finish the parallel version.

          Resources:

          [1] The paper to be implemented: "A template-based approach for parallel hexahedral two-refinement"
          [2] CGAL Linear cell complex package
          [3] Query-replace operations for topologically controlled 3D mesh editing and the Gitlab repository
          Required Skills: C++17, Geometry Processing, Mesh Processing, Computational Geometry

          Contact: guillaume.damiand@cnrs.fr

          Duration: 175h

          ~~~~~~~~~~

          Cut by plane a volumetric mesh
          Mentor: Guillaume Damiand and Sebastien Loriot

          Project description:

          The goal of this project is to implement a method allowing to cut a 3D volumetric mesh (represented by a 3D linear cell complex) by a plane. There are some code available for the two first steps of the method (insert vertices on the cut edges, and insert edges between the new vertices to split faces); it remains the last step which consists in inserting new faces along path of edges. The method must be robust, i.e. deal with any configuration of volumetric mesh. To do so, the work to do is: (1) implement the 3 steps in CGAL; (2) validate results on many different input meshes; (3) write the doc and the examples.

          Required Skills: C++17, Geometry Processing, Mesh Processing, Computational Geometry

          Contact: guillaume.damiand@cnrs.fr sloriot.ml@gmail.com

          Duration: 175h

          ~~~~~~~~~~

          Improvement of Named Parameters
          Mentor: Sebastien Loriot and Laurent Rineau

          Project description:

          The goal of this project is to continue the work started in the pull-request https://github.com/CGAL/cgal/pull/7966. This change proposal implements a mechanism that allows the user to check at compile time that the options passed are used by the function (currently a flow of our mechanism). The proof of concept is there, but now we need to apply it globally in CGAL to all the functions using named parameters. As the function are documented, one way to tackle this project is to write a (python?) script that will collect for all the function the expected named parameters and add the macro calls in the function. There are also other improvements that can be implemented during this project if time allows (automatic extraction of a subset of options, more friendly developer interface, ...)

          Required Skills: C++17, Scritping Language such as Python, with knowledge in parsing

          Contact: sloriot.ml@gmail.com

          Duration: 175h

          ~~~~~~~~~~

          Adding Support for New File Formats for Meshes
          Mentor: Sebastien Loriot and Mael Rouxel-Labbé

          Project description:

          The CGAL library provides several functions to read and write meshes (surface and volume) in the Stream Support package. The list of currently supported file format is available here. The goal of this project is to add support to more file formats. We could for example add support for glTF, gmsh format, 3mf v2, ... The duration of the project will depend on the file format proposed for addition.

          Required Skills: C++17

          Contact: sloriot.ml@gmail.com

          Duration: 90h, 175h, or 350h

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://github.com/CGAL/cgal/wiki/Project-Ideas
    idea_list_url: https://github.com/CGAL/cgal/wiki/Project-Ideas


  - organization_id: 18
    organization_name: CHAOSS
    no_of_ideas: 3
    ideas_content: |
      Idea: Enhance Conversational Topic Modelling Capabilities in CHAOSS Software
      Hours: 350

      Micro-tasks and place for questions

      This project will add GenSIM logic, and other capabilities to the Clustering Worker inside of Augur Software, and be extended into a generalized Open Source Software Conversational Topic Modeling Instrument.

      CHOASS/augur has several workers that store machine learning information derived from computational linguistic analysis of data in the message table. The message table includes messages from issue, pull request, pull request review, and email messages. They are related to their origin with bridge tables like pull_request_message_ref. The ML/CL workers are all run against all the messages, regardless of origin.

      Clustering Worker (clusters created and topics modeled)
      message analysis worker (sentiment and novelty analysis)
      discourse analysis worker (speech act classification (question, answer, approval, etc.)
      Clustering Worker Notes:

      Clustering Worker: 2 Models.

      Models:
      Topic modeling, but it needs a better way of estimating number of topics.
      Tables - repo_topic - topic_words
      Computational linguistic clustering
      Tables - repo_cluster_messages
      Key Needs
      Add GenSim algorithms to topic modeling section #1199
      The topics, and associated topic words need to be persisted after each run. At the moment, the topic words get overwritten for each topic modeling run.
      Description/optimization of the parameters used to create the computational linguistic clusters.
      Periodic deletion of models (heuristic: If 3 months pass, OR there’s a 10% increase in the messages, issues, or PRs in a repo, rebuild the models)
      Establish some kind of model archiving with appropriate metadata (lower priority)
      Discourse Analysis Worker Notes:

      discourse_insights table (select max(data_collection_date) for each msg_id)

      sequence is reassembled from the timestamp in the message table (look at msg_timestamp)
      issues_msg_ref, pull_request_message_ref, pull_request_review_msg_ref
      Message Analysis Worker

      message_analysis
      message_analysis_summary
      augur-tech

      The aims of the project are as follows:

      Advance topic modeling of open source software conversations captured in GitHub.
      Integrate this information into clearer, more parsimonious CHAOSS metrics.
      Automate the management machine learning insights, and topic models over time.
      (Stretch Goal) Improve the operation of the overall machine learning insights pipeline in CHAOSS/augur, and generalize these capabilities.
      
      ~~~~~~~~~~
      IDEA: Implement Conversion Rate Metric in CHAOSS Software
      Hours: 350

      Micro-tasks and place for questions

      Conversion Rate
      Question: What are the rates at which new contributors become more sustained contributors?

      Description
      The conversion rate metric is primarily aimed at identifying how new community members become more sustained contributors over time. However, the conversion rate metric can also help understand the changing roles of contributors, how a community is growing or declining, and paths to maintainership within an open source community.

      Objectives (why)
      Observe if new members are becoming more involved with an open source project
      Observe if new members are taking on leadership roles within an open source project
      Observe if outreach efforts are generating new contributors to an open source project
      Observe if outreach efforts are impacting roles of existing community members
      Observe if community conflict results in changing roles within an open source community
      Identify casual, regular, and core contributors
      Implementation
      This project could be implemented using either the CHAOSS/Augur, or CHAOSS/Grimoirelab (including stack components noted in references) technology stacks.

      The aims of the project are as follows:

      Implement the Conversion Rate Metric in CHAOSS Software
      After discussion, consider which CHAOSS Software Stack you wish to work with
      In collaboration with mentors, define the technology framework, and initial path to a "hello world" version of the metric
      Iterative development of the metric
      Assist in the deployment of this metric for a pre-determined collection of repositories in a publicly viewable website linked to the CHAOSS project.
      Advance the work of the chaoss metrics models working group.
      Difficulty: Medium
      Requirements: Knowledge of Python is desired. Some knowledge of Javascript or twitter/bootstrap is also desired. Key requirement is a keenness to dig into this challenge!
      Recommended: Python experience.
      Mentors: Sean Goggins
      Filters (optional)
      Commits
      Issue creation
      Issue comments
      Change request creation
      Change request comments
      Merged change requests
      Code Reviews
      Code Review Comments
      Reactions (emoji)
      Chat platform messages
      Maillist messages
      Meetup attendance
      Visualizations


      Source: https://chaoss.github.io/grimoirelab-sigils/assets/images/screenshots/sigils/overall-community-structure.png



      Source: https://opensource.com/sites/default/files/uploads/2021-09-15-developer-level-02.png

      Tools Providing the Metric
      Augur
      openEuler Infra
      Data Collection Strategies
      The following is an example from the openEuler community:

      A group of people who attended an offline event A held by the community, can be identified as Group A. Demographic information of Group A could be fetched from an on-line survey when people register for the event. To identify the conversation rate of these participants:
      Some people from Group A started watching and forking the repos, indicating they have shown some interest in this community. We marked them as subgroup D0 (Developer Level 0) as a subset of Group A.
      Conversion rate from the total number of people in Group A to the number of people in subgroup D0 is: D0/Group A
      Some people from subgroup D0 make more contributions beyond just watching or forking, including creating issues, making comments on an issue, or performed a code review. We marked them as subgroup D1 (Developer Level 1) as a subset of D0.
      Conversion rate from the total number of people in Subgroup D0 to the number of people in subgroup D1 is: D1/D0.
      Some people from subgroup D1 continue to make more contributions, like code contributions, to the project. This could include creating merge requests and merging new project code. We marked them as subgroup D2 (Developer Level 2) as a subset of D1.
      Conversion rate from the total number of people in subgroup D1 to the number of people in subgroup D2 is: D2/D1.


      Definition:

      Developer Level 0 (D0) example: Contributors who have given the project a star, or are watching or have forked the repository
      Developer Level 1 (D1): Contributors who have created issues, made comments on an issue, or performed a code review
      Developer Level 2 (D2): Contributors who have created a merge request and successfully merged code
      Conversion Rate (Group A -> D0): CR (Group A -> D2) = D0/Group A
      Conversion Rate (D0 -> D1): CR (D0 -> D1) = D1/D0
      Conversion Rate (D1 -> D2): CR (D1 -> D2) = D2/D1
      References
      https://opensource.com/article/21/11/data-open-source-contributors
      https://github.com/chaoss/augur
      https://gitee.com/openeuler/website-v2/blob/master/web-ui/docs/en/blog/zhongjun/2021-09-15-developer-level.md
      https://chaoss.github.io/grimoirelab-sigils/common/onion_analysis/
      https://mikemcquaid.com/2018/08/14/the-open-source-contributor-funnel-why-people-dont-contribute-to-your-open-source-project/
      Contributors
      Sean Goggins
      Andrew Brain
      John McGinness

      ~~~~~~~~~~
      IDEA: Open Source Software Health Metrics Visualization Exploration
      Hours: 350

      Micro-tasks and place for questions

      The CHAOSS Community currently delivers pre-packaged visualizations of open source software health data through Augur APIs (https://github.com/chaoss/augur/blob/main/augur/routes/pull_request_reports.py and https://github.com/chaoss/augur/blob/main/augur/routes/contributor_reports.py), and the https://github.com/chaoss/augur-community-reports repository. This project seeks to expand, refine, and standardize the visualization of different classes of community health metrics data. Specifically, some analyses are temporal, others are anomaly driven, and in some cases contrasts across repositories and communities are required. In each case, the visualization of data is an essential component for metrics, and what we are now referring to as metrics models (https://github.com/chaoss/wg-metrics-models).

      Additional resources include: http://new.augurlabs.io/ && https://github.com/augurlabs/augur_view which demonsrate the updated twitter/bootstrap Augur frontend.

      The aims of the project are as follows:

      Experiment with standard metrics visualizations using direct Augur database connections, or through the Augur API.
      Refine metrics, and metrics model visualizations using Jupyter Notebooks are similar technology.
      Transform visualizations, as they are completed, into Augur API endpoints, following the pull request, and contributor reports examples.
      Difficulty: Medium
      Requirements: Strong interest in data visualization.
      Recommended: Experience with Python is desirable, and experience designing, or developing visualizations is desirable.
      Mentors: Isaac Milarsky, Andrew Brain

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/chaoss/
    idea_list_url: https://github.com/chaoss/augur/blob/main/gsoc-ideas.md


  - organization_id: 19
    organization_name: CNCF
    no_of_ideas: 22
    ideas_content: |
        etcd
        etcd cache
        Description: Develop a generic, high-performance caching library for etcd, inspired by the Kubernetes watch cache, to facilitate building scalable and efficient etcd-based applications.
        Expected Outcome:
        A well-tested and performant library providing core caching primitives similar to Kubernetes' watch cache, significantly reducing etcd load and latency for generic etcd use cases.
        The library will offer feature parity with Kubernetes watch cache, including support for:
        Caching watch events and demultiplexing requests.
        Caching non-consistent list requests using a B-tree structure, updated via watch events.
        Handling requests during cache initialization and re-initialization.
        Custom encoders/decoders for data serialization.
        Custom indexing for optimized lookups.
        Consistent reads.
        Exact stale reads via B-tree snapshots.
        Comprehensive documentation, examples, benchmarks, and metrics to enable easy adoption and monitoring. This includes e2e and robustness tests.
        Recommended Skills: Go, Distributes Systems
        Expected project size: small
        Mentor(s):
        Marek Siarkowicz (@serathius, siarkowicz@google.com) - primary
        Madhav Jivrajani (@MadhavJivrajani, madhav.jiv@gmail.com)
        Upstream Issue (URL): etcd-io/etcd#19371

        ~~~~~~~~~~
        Harbor
        Enhance Harbor Satellite for Artifact Replication from Remote Registry to Edge
        Description: The Harbor Satellite project aims to enable decentralized artifact replication in edge computing environments. This project currently focuses on Use Case #1, where Harbor Satellite will pull images from a central Harbor registry and store them in a local OCI-compliant registry for use by edge devices. The solution is designed for environments with limited or intermittent internet connectivity, ensuring continuous access to required artifacts by local edge devices even when connectivity is unavailable.
        Expected Outcome:
        Enhance Harbor Satellite to enable reliable artifact replication from a central Harbor registry to a local OCI-compliant registry at the edge.
        Implement secure synchronization between central and local registries, especially in air-gapped environments.
        Optimize configuration management for edge container runtimes to pull images from the local registry.
        Provide clear documentation and setup guides for deploying Harbor Satellite in edge environments.
        Recommended Skills: Go, OCI-Registries, Distribution-spec
        Expected project size: medium (~175 hour projects)
        Mentor(s):
        Vadim Bauer (@vad1mo, vb@container-registry.com) - primary
        Orlin Vasilev (@OrlinVasilev, orlin@orlix.org)
        Prasanth Baskar (@bupd, bupdprasanth@gmail.com)
        Upstream Issue (URL): goharbor/harbor#21605

        ~~~~~~~~~~
        Jaeger
        Service performance analysis on top of Elasticsearch / OpenSearch data
        Description: Jaeger is an open-source, distributed tracing platform designed to monitor and troubleshoot transactions in distributed systems. In its basic deployment it allows collecting tracing data, storing it in a database, and querying & analyzing individual traces in the UI. This workflow is great for deep-diving into individual requests, but it does not answer some higher level questions like "which endpoints in my service are the slowest?" To address those questions Jaeger has a special feature called SPM (Service Performance Management), which allows the user to see the trends of services' and endpoints' performance and to drill down into the outliers. However, this feature requires a more complicated deployment where a special real-time processor is running and extracting metrics from the traces and storing those metrics in a Prometheus-compatible remote storage. Some of the storage backends supported by Jaeger, such as Elasticsearch & OpenSearch, can provide the same aggregate answers directly from the trace data, which can significantly simplify the deployment. This project aims to enable this integration.
        Expected Outcome:
        Support SPM functionality directly in Elasticsearch / OpenSearch backends by implementing the metrics query API
        Enhance existing e2e integration tests to continuously test this new capability
        Recommended Skills: Go, basic familiarity with Elasticsearch
        Expected project size: large (~350 hour projects)
        Mentors:
        Yuri Shkuro (@yurishkuro, github@ysh.us) - primary
        Jonah Kowall (@jkowall, jkowall@kowall.net)
        Upstream Issue (URL): jaegertracing/jaeger#6641

        ~~~~~~~~~~
        KCL
        KCL OCI third-party dependency management enhancement
        Description: KCL is an open-source constraint-based record & functional language mainly used in configuration and policy scenarios. KPM is a package management tool for the KCL language that supports the management of KCL packages in the OCI registry and Git Repo. This topic only applies to third-party dependencies from the OCI registry. Use the layering mechanism in OCI to help KPM implement dependency management of KCL third-party dependencies.

        Expected Outcome:

        Refactor the current KPM dependency management module with the OCI's layered mechanism.
        Recommended Skills: Go, OCI

        Expected project size: medium (~175 hour projects)

        Mentor(s):

        Zhe Zong (@zong-zhe, zongzhe1024@163.com)
        Heipa (@He1pa, he1pa404@gmail.com)
        Upstream Issue (URL): kcl-lang/kpm#598

        ~~~~~~~~~~
        Knative Functions
        Dynamic AI Agent Callbacks
        Description: Knative Functions is well-suited for AI agent integration. The serverless nature and isolated runtime environment of Functions make them ideal for creating lightweight, purpose-built services that can be dynamically invoked and even created by agents.
        Expected Outcome: This project would be a combination of research and practicum. First, an analysis of current AI agent interaction patterns, including emergent protocols and available frameworks. Second, the development of a Proof-of-concept integration between Functions and AI agents. This would involve at a minimum invocation, with a stretch goal of implementation and deployment by the agent based on a human prompt.
        Recommended Skills:
        Strong language and communication skills, with the ability to both research deeply and communicate clearly.
        Experience with AI/ML agents and desire to learn about programmatic LLM integrations.
        Familiarity with the Go programming language (ideal) or Python (secondarily), and web services.
        Familiarity with kubernetes, serveless, and microservices a plus.
        Expected project size: Large
        Mentor(s):
        Luke Kingland @lkingland (kingland AT redhat DOT com) - primary
        Aleksander Slominski @aslom (aslomins AT redhat DOT com)
        Upstream Issue (URL): knative/func#2690
        
        ~~~~~~~~~~
        Konveyor
        Extend usage of Konveyor AI to detect and update deprecated Kubernetes API usage in golang applications
        Description: Konveyor is an application modernization platform that helps organizations migrate legacy applications to Kubernetes at scale. As part of this effort, you will contribute to Konveyor AI (Kai), an intelligent code assistant that automates source code updates using data from static code analysis and changelog histories. Your work will focus on applying Generative AI techniques to detect and update deprecated Kubernetes APIs in Golang applications. You’ll build a tool that uses a LLM to generate Konveyor static code analysis rules from published documentation such as the Kubernetes deprecated API guide. Additionally, you’ll create workflows to identify deprecated API usage in legacy applications and automate code suggestions for updates — all powered by Konveyor AI.

        Expected Outcome:

        Develop a prototype tool to convert Kubernetes API deprecation documentation into static code analysis rules.
        Collaborate with the Konveyor AI team to extend support for Golang applications, identify issues, and contribute improvements.
        Demonstrate Konveyor AI’s ability to detect and suggest fixes for deprecated API usage in Golang projects.
        Recommended Skills: Golang, Python, Kubernetes, Generative AI

        Expected project size: # Large (~350 hours)

        Mentor(s):

        John Matthews (@jwmatthews, jwmatthews@gmail.com) - primary
        Savitha Raghunathan (@savitharaghunathan, saveetha13@gmail.com)
        Upstream Issue (URL): konveyor/kai#644

        ~~~~~~~~~~
        KubeArmor
        Improve KubeArmor Observability Spectrum
        Description: KubeArmor is a security enforcement system that provides runtime protection for Kubernetes workloads. To enhance observability, this task involves exposing key Prometheus metrics related to KubeArmor’s policy enforcement. These metrics will provide insights into security policy activity and alerting within a Kubernetes cluster.

        For starters, the following metrics can be started with:

        Number of Policies Applied
        Number of Alerts Triggered
        List of Active Policies
        Policy Status (Active/Inactive)
        Expected Outcome: Prometheus metrics are successfully integrated into KubeArmor, allowing users to monitor policy enforcement and security events effectively. The metrics should be accessible via a Prometheus endpoint and conform to best practices for Prometheus metric exposition.

        Recommended Skills: Go, Prometheus, Kubernetes.

        Expected project size: 175 hrs

        Mentor(s):

        Rishabh Soni (@rootxrishabh, risrock02@gmail.com)
        Prateek Nandle (@Prateeknandle, prateeknandle@gmail.com)
        Barun Acharya (@daemon1024, barun1024@gmail.com)
        Nishant Singh (@tesla59, talktonishantsingh.ns@gmail.com)
        Upstream Issue (URL): kubearmor/KubeArmor#1902

        ~~~~~~~~~~
        KubeBuilder
        Automating Operator Maintenance: Driving Better Results with Less Overhead
        Description:
        Code-generation tools like Kubebuilder and Operator-SDK have transformed cloud-native application development by providing scalable, community-driven frameworks. These tools simplify complexity, accelerate results, and enable developers to create tailored solutions while avoiding common pitfalls, laying a strong foundation for innovation.
        However, as these tools evolve with ecosystem changes and new features, projects risk becoming outdated. Manual updates are time-consuming, error-prone, and make it challenging to maintain security, adopt advancements, and stay aligned with modern standards.
        This project introduces an automated solution for Kubebuilder, with potential applications for similar tools or those built on its foundation. By streamlining maintenance, projects remain aligned with modern standards, improve security, and adopt the latest advancements. It fosters growth and innovation across the ecosystem, letting developers focus on what matters most: building great solutions.
        Note that the initial idea is to solve this with 3-way Git merges. However, users will face conflicts, and in the first phase, we want to study whether AI could help resolve these conflicts in a future phase to achieve this goal.

        Expected Outcome

        Conduct research on 3-Way Merge & Advanced Merge Options in Git.
        Conduct research on how AI could help resolve conflicts. If open-source solutions are available and align with the proposal, include them for consideration in a second phase.
        Develop a Proof of Concept (POC) implementing a GitHub Action that automatically creates a Pull Request (PR) in a mock repository, demonstrating the feasibility of the proposed solution.
        Successfully complete the proposal for PEP.
        Introduce a new Kubebuilder Plugin that scaffolds the GitHub Action based on the POC. This plugin will be released as an alpha feature, allowing users to opt-in for automated updates. The initial solution does not need to have AI, but AI integration could be a future enhancement if feasible.
        Recommended Skills

        Golang
        GitHub Actions
        Software Automation
        CI/CD
        Git
        IA
        Expected project size: Large (~350 hour projects)

        Mentor(s)

        Camila Macedo (@camilamacedo86, camilamacedo86@gmail.com) - Primary
        Varsha Prasad (@varshaprasad96, varshaprasad1507@gmail.com)
        TianYi(Tony) (@Kavinjsir)
        Upstream Issue: WIP - Proposal: Automating Operator Maintenance: Driving Better Results with Less Overhead
        ~~~~~~~~~~
        KubeStellar
        AI/ML Model Monitoring and Drift Detection in Disconnected Clusters using KubeStellar
        Description: AI/ML models deployed in disconnected environments, such as edge clusters and air-gapped systems, often suffer from model drift—a degradation in model performance due to changes in input data distributions. Without continuous monitoring, models may become inaccurate, leading to unreliable predictions.

        This project aims to integrate model monitoring and drift detection into KubeStellar, enabling Kubernetes-based AI workloads to detect data drift locally and sync monitoring metrics when connectivity is restored. The solution will use lightweight monitoring agents deployed alongside ML models to track data distribution changes and alert mechanisms to trigger model retraining when necessary.

        The system will also include policies for efficient metric storage and synchronization between disconnected and central clusters while minimizing bandwidth usage.

        Expected Outcome:

        A KubeStellar-compatible AI/ML monitoring component that tracks model drift in disconnected clusters.
        Efficient local storage and synchronization of monitoring metrics when connectivity is restored.
        Policies for adaptive model retraining triggers based on drift detection signals.
        Integration with existing ML tools (e.g., Prometheus, TensorFlow Extended, OpenTelemetry).
        Open-source documentation and example workflows demonstrating how KubeStellar manages AI model monitoring across disconnected clusters.
        Recommended Skills:

        Kubernetes and container orchestration
        AI/ML model deployment & monitoring
        Python, Go (for Kubernetes integrations)
        Experience with logging/monitoring tools (Prometheus, OpenTelemetry)
        Familiarity with KubeStellar (preferred but not required)
        Expected Project Size: Large (~350 hours) This project requires implementing multiple components: local monitoring, drift detection, synchronization, and integration with KubeStellar. It also involves research into efficient data synchronization strategies for low-bandwidth environments.

        Mentor(s):

        Andy Anderson (@clubanderson, andy@clubanderson.com) - Primary Mentor
        [Second Mentor's Name] (@second-mentor-github, second-mentor-email)
        Upstream Issue (URL): kubestellar/kubestellar#2791

        ~~~~~~~~~~

        Kubewarden
        Allow policies to be written using JavaScript
        Description: Kubewarden is a Policy Engine powered by WebAssembly policies that enforces security and compliance in Kubernetes clusters. Its policies can be written in CEL, Rego (OPA & Gatekeeper flavours), Rust, Go, YAML, and others.

        Kubewarden does not have a JavaScript SDK yet. Recent work done inside of the Bytecode Alliance made possible to compile Javascript code into WebAssembly . This means It's now possible to create such a SDK. This task consists on writing a JavaScript SDK that provides an idiomatic way to write Kubewarden policies.

        Expected Outcome: A new JavaScript SDK is created. The SDK API is documented, and the policy tutorial as well.

        Recommended Skills: JavaScript, Kubernetes.

        Expected project size: Large

        Mentor(s):

        Victor Cuadrado (@viccuad, vcuadradojuan@suse.com) - primary
        Flavio Castelli (@flavio, fcastelli@suse.com)
        José Guilherme Vanz (@jvanz, jguilhermevanz@suse.com)
        Fabrizio Sestito (@fabriziosestito, fabrizio.sestito@suse.com)
        Upstream Issue (URL): kubewarden/community#37

        ~~~~~~~~~~

        Elevate our .NET SDK into a first class citizen
        Description: Kubewarden is a Policy Engine powered by WebAssembly policies that enforces security and compliance in Kubernetes clusters. Its policies can be written in CEL, Rego (OPA & Gatekeeper flavours), Rust, Go, YAML, and others.

        Kubewarden has a .NET SDK that allows policy authors to write policies in C#. Starting with .NET 8, a big chunk of the work from https://github.com/dotnet/dotnet-wasi-sdk made its way upstream. This means it's a good time to revisit Kubewarden's .NET SDK for policies. This task consists on bringing our .NET SDK up to standard with the rest of our SDKs such as the Go or Rust ones.

        Expected Outcome: Our .NET SDK has been ported to .NET 9, and supports the same capabilities as our other SDKs. The SDK API is documented, and the policy tutorial as well.

        Recommended Skills: C#, .NET, Kubernetes.

        Expected project size: medium

        Mentor(s):

        Victor Cuadrado (@viccuad, vcuadradojuan@suse.com) - primary
        Flavio Castelli (@flavio, fcastelli@suse.com)
        José Guilherme Vanz (@jvanz, jguilhermevanz@suse.com)
        Fabrizio Sestito (@fabriziosestito, fabrizio.sestito@suse.com)
        Upstream Issue (URL): kubewarden/policy-sdk-dotnet#47

        ~~~~~~~~~~
        Lima
        VM plugin subsystem
        Description: Lima (https://lima-vm.io) is a project that provides Linux virtual machines with a focus on running containers. Lima supports several VM backends via built-in drivers: qemu, vz (Apple Virtualization.framework), and wsl2 (see lima/pkg/driverutil/instance.go). The idea for GSoC is to make a plugin subsystem that decouples the built-in VM drivers into separate binaries that communicate with the main Lima binary via some RPC (probably gRPC). This idea will improve the maintainability of the code base, and also help supporting additional VM backends (e.g., vfkit and cloud-based drivers).
        Expected Outcome:
        Design the plugin subsystem and its RPC (probably gRPC)
        Migrate the existing built-in VM drivers to the new plugin subsystem
        Implement additional VM plugins if the time allows
        Recommended Skills: Go, gRPC, QEMU, macOS
        Expected project size: medium (~175 hour projects)
        Mentor(s):
        Akihiro Suda (@AkihiroSuda, suda.kyoto@gmail.com) - primary
        Anders Björklund (@afbjorklund, anders.f.bjorklund@gmail.com)
        Upstream Issue (URL): lima-vm/lima#2007
        
        ~~~~~~~~~~
        LitmusChaos
        Terraform Support for LitmusChaos
        Description: LitmusChaos is an open-source Chaos Engineering platform that helps teams uncover weaknesses and potential outages in their applications by running controlled chaos experiments. However, before injecting chaos, several prerequisite steps must be completed, including user and project creation, connecting target infrastructure, and setting up experiments. To streamline this process, developers and SREs often seek automation, especially when integrating chaos testing into CI/CD pipelines. This Google Summer of Code (GSoC) project proposes developing a Terraform provider for LitmusChaos, enabling users to automate these essential setup steps and seamlessly manage chaos experiments through Terraform.

        Expected Outcome:

        LitmusChaos will have a terraform provider supporting user, project, infrastructure, and experiment resource operations along with proper documentation and usage scripts.
        A stretch goal for the mentee would be to become an official maintainer of the Litmus Terraform provider project.
        Recommended Skills: Golang, Terraform

        Expected project size: large (~175 hour projects)

        Mentor(s):

        Saranya Jena (@Saranya-jena, saranya.jena@harness.io)
        Sarthak Jain (@SarthakJain26, sarthak.jain@harness.io)
        Upstream Issue (URL): litmuschaos/litmus#5042

        ~~~~~~~~~~
        Meshery
        Multi-player Collaboration: Resilient Websockets and GraphQL Subscriptions
        Description: Meshery's current implementation of websockets and GraphQL subscriptions is in need of refactoring for increased reliability and resiliency. This client and server-side refactoring includes use of webworkers and separation of concerns for the client-side, and the use of a message broker for the server-side. The project has implications on Meshery's implementation of multi-player collaboration functionality.

        Expected Outcome: Resilient websockets and GraphQL subscriptions for Meshery, enabling multi-player collaboration functionality.

        Recommended Skills: Golang, Kubernetes, Azure, well-written and well-spoken English

        Expected project size: large (~175 hour project)

        Mentor(s):

        Lee Calcote (@leecalcote, leecalcote@gmail.com)
        Aabid Sofi (@aabidsofi19, mailtoaabid01@gmail.com)
        Upstream Issue: meshery/meshery#13554

        ~~~~~~~~~~

        Support for Azure in Meshery
        Description: Enhance Meshery's existing orchestration capabilities to include support for Azure. The Azure Service OperatorAzure Service Operator (ASO) provides a wide variety of Azure Resources via Kubernetes custom resources. as first-class Meshery Models. This involves enabling Meshery to manage and orchestrate Azure services and their resources, similar to how it handles other Kubernetes resources. The project will also include generating support for Azure services and their resources in Meshery's Model generator.

        Expected Outcome: Meshery will be able to orchestrate and manage all Azure services supported by ASO. This includes the ability to discover, configure, deploy, and operate the lifecycle of Azure services through Meshery. The Meshery Model generator will be updated to automatically generate models for Azure services, simplifying their integration and management within Meshery. This will be an officially supported feature of Meshery.

        Recommended Skills: Golang, Kubernetes, Azure, well-written and well-spoken English

        Expected project size: large (~175 hour project)

        Mentor(s):

        Lee Calcote (@leecalcote, leecalcote@gmail.com)
        Mia Grenell (@miacycle, mia.grenell2337@gmail.com)
        Upstream Issue: meshery/meshery#11244

        ~~~~~~~~~~

        Distributed client-side inference (policy evaluation) with WebAssembly (WASM) and OPA in Meshery
        Description: Meshery's highly dynamic infrastructure configuration capabilities require real-time evaluation of complex policies. Policies of various types and with a high number of parameters need to be evaluted client-side. With policies expressed in Rego, the goal of this project is to incorporate use of the https://github.com/open-policy-agent/golang-opa-wasm project into Meshery UI, so that a powerful, real-time user experience is possible.

        Expected Outcome: The goal of this project is to enhance Meshery's infrastructure configuration capabilities by incorporating real-time policy evaluation using the golang-opa-wasm project. This project will integrate the capabilities of golang-opa-wasm into the Meshery UI, enabling users to experience the existing, powerful, server-side policy evaluation client-side.

        Recommended Skills: WebAssembly, Golang, Open Policy Agent, well-written and well-spoken English

        Expected project size: large (~175 hour project)

        Mentor(s): Lee Calcote (@leecalcote, leecalcote@gmail.com), James Horton (@hortison, james.horton2337@gmail.com)

        Upstream Issue: meshery/meshery#13555

        ~~~~~~~~~~
        Open Cluster Management
        Privacy-preserving and efficient AI model training across multi-cluster
        Description: Open Cluster Management (OCM) streamlines multi-cluster workload management through APIs that align with SIG-Multicluster standards. Beyond traditional workload orchestration, OCM enables scalable AI training and inference across distributed environments.

        As machine learning (ML) expands across clusters, data privacy becomes a critical concern. ML models rely on vast datasets, making it essential to safeguard sensitive information across clusters without compromising model performance.

        This project integrates Federated Learning (FL) into OCM, enabling privacy-preserving, collaborative model training without transferring raw data between clusters. Instead, training occurs locally where the data resides, ensuring compliance, enhancing efficiency, and reducing bandwidth and storage costs.

        By leveraging OCM's Placement, ManifestWork, and other APIs. we standardize FL workflows and seamlessly integrate frameworks like Flower and OpenFL through a unified interface. This approach harnesses OCM's capabilities to deliver scalable, cost-efficient, and privacy-preserving AI solutions in multi-cluster environments.

        Expected Outcome:

        Comprehensive Documentation:
        Define the scenarios addressed by the prototype, highlighting its purpose and value.
        Provide an intuitive and architectural comparison between Federated Learning (FL) and OCM, mapping FL terminology to OCM APIs to showcase OCM’s native support for FL.
        Illustrate the complete Federated Learning workflow within Open Cluster Management.
        Extended Prototype (or CRD) Support:
        Enable model aggregation persistence in AWS S3 (currently supports only native PVC).
        Extend compatibility to support additional Federated Learning frameworks like OpenFL (currently supports Flower). This requires understanding how OpenFL works, containerizing it, and integrating it into the prototype.
        Recommended Skills: Golang, Kubernetes, Federated Learning, Open Cluster Management, Scheduling

        Expected project size: medium (~175 hour projects)

        Mentor(s):

        Meng Yan (@yanmxa, myan@redhat.com) - primary
        Qing Hao (@haoqing0110, qhao@redhat.com)
        Upstream Issue (URL): open-cluster-management-io/ocm#825

        ~~~~~~~~~~    
        ORAS
        Enhance Java ORAS SDK
        Description: The ORAS project aims to enhance its Java SDK to support a broader range of features from the OCI Distribution spec. This involves implementing missing functionality, improving existing features, and expanding the SDK’s overall capabilities.
        Expected Outcome:
        Implement missing features from the OCI Distribution and Image Specifications, such as chunked uploads and the Referrers API
        Improve existing features, robustness and tests to ensure full compatibility with the OCI Distribution and Image Specifications.
        Enhance documentation and provide more comprehensive examples.
        Add support for additional authentication methods, including using credentials from docker config.json
        Recommended Skills: java, oci
        Expected project size: medium (~175 hour projects)
        Mentor(s):
        Valentin Delaye (@jonesbusy, jonesbusy@gmail.com) - primary
        Feynman Zhou (@FeynmanZhou, zpf0610@gmail.com)
        Upstream Issues: https://github.com/oras-project/oras-java/issues
        The Update Framework (TUF)
        Snapshot Merkle trees
        Description: The TUF snapshot role is responsible for consistency proofs in a TUF repository. In certain high-volume repositories, the related snapshot metadata file can become prohibitively large, and thus impose a significant overhead for TUF clients. TAP 16 proposes a method for reducing the size of snapshot metadata a client must download without significantly weakening the security properties of TUF. In this project you will add TAP 16 support to python-tuf.
        Expected Outcome: Snapshot Merkle trees are implemented in python-tuf Metadata API and ngclient
        Recommended Skills: Python, data structures (merkle trees)
        Expected project size: medium (~175 hour projects)
        Mentor(s):
        Lukas Pühringer (@lukpueh) - primary
        Justin Cappos (@JustinCappos)
        Upstream Issue (URL): theupdateframework/taps#134

        ~~~~~~~~~~
        Vitess
        Enhancements for FAQ Chatbot for Vitess
        Description: Vitess is a distributed database system built on MySQL. Developers often need to search through documentation, Slack discussions, and GitHub issues to find answers. We are starting a project to implement an AI-powered FAQ chatbot using Retrieval-Augmented Generation, integrating vector search with an LLM (such as OpenAI, DeepSeek, GPT-4, Mistral, Llama 3). The chatbot will be available via a CLI and Slack bot for developer support.

        In the next phase, which will be implemented in this Summer Of Code (SOC) project, we will be adding more features like:

        Content filtering for chatbot safety and response validation
        Fine-tuning the model for improved accuracy
        Pipelines for refreshing data from new/updated docs
        Caching previous replies to reduce LLM costs
        Rate-limiting
        Better benchmarking for iterative improvements
        User feedback integration to improve relevancy
        Expected Outcome: Improved chatbot that provides accurate Vitess-related answers via CLI and Slack, using indexed documentation and discussions for retrieval.

        Recommended Skills: golang, python, LLM APIs, vector databases

        Expected project size: large (~350 hour projects)

        Mentor(s):

        Rohit Nayak (@rohit-nayak-ps, rohit@planetscale.com)
        Manan Gupta (@GuptaManan100, manan@planetscale.com)
        Upstream Issue: vitessio/vitess#17690

        ~~~~~~~~~~

        WasmEdge
        Virtual filesystem security for WasmEdge plug-ins with exporting WASI APIs
        Description: The WASI proposal defines the variety of rules to guarantee the virtual filesystem security and isolation when executing WASM binaries. However, besides using WASI directly in WASM, developers can also implement the host functions to access the filesystem in their guest programming language. This will break the sandbox of WebAssembly. In this program, our goal is to export the WASI APIs in WasmEdge, and use the APIs in WasmEdge plug-ins to ensure the filesystem security and WebAssembly isolation.
        Expected Outcome:
        Export needed WASI APIs in WasmEdge internal to provide the functions of checking and accessing host filesystem.
        Apply the APIs in some WasmEdge plug-ins which accessing the filesystem, such as WASI-NN.
        Implement test suites to verify the above behaviors.
        Recommended Skills:
        C++
        WebAssembly
        Expected project size: Large (~350 hour projects)
        Mentor(s):
        YiYing He (@q82419 , yiying@secondstate.io) - Primary
        Shen-Ta Hsieh (@ibmibmibm , beststeve@secondstate.io)
        Upstream Issue (URL): WasmEdge/WasmEdge#4012

        ~~~~~~~~~~
        Port WasmEdge and the WASI-NN ggml backend to the s390x platform
        Description: WasmEdge provides cross-platform support for amd64 and arm64 for executing AI/LLM applications. We would like to support as many new hardware platforms as possible, so developers and users will no longer need to worry about the actual hardware. All they need to do is develop their AI agent or LLM applications once and deploy their services anywhere. For more information, please check the upstream issue.
        Expected Outcome:
        Make the WasmEdge toolchain support the s390x platform, including the interpreter and the AOT mode.
        Ensure the WASI-NN ggml plugin can execute without any issues on the s390x platform.
        Implement test suites to verify the above behaviors.
        Write a document discussing the compilation, installation, execution, and verification of the work.
        Recommended Skills:
        C++
        s390x
        LLVM
        Expected project size: Large (~350 hour projects)
        Mentor(s):
        Hung-Ying Tai (@hydai, hydai@secondstate.io) - Primary
        dm4 (@dm4, dm4@secondstate.io)
        Upstream Issue (URL): WasmEdge/WasmEdge#4010

        ~~~~~~~~~~

        Use Runwasi with WasmEdge runtime to test multiple WASM apps as cloud services
        Description: With WasmEdge serving as one of Runwasi’s standard runtimes, and as our C++-implemented library continues to evolve, we also need a verification process integrated into Runwasi to streamline and validate the stability of both container and cloud environments.
        Expected Outcome:
        A concise GitHub workflow demonstrates Runwasi end-to-end testing on Kubernetes.
        Need to design an interactive application scenario that supports multiple nodes
        Try to incorporate the use of the WasmEdge plugin into this scenario
        Document
        Recommended Skills:
        Rust
        C++
        GDB
        git / github workflow
        shell script
        Expected project size: Large (~350 hour projects)
        Mentor(s):
        Vincent (@CaptainVincent, vincent@secondstate.io) - Primary
        yi (@0yi0 yi@secondstate.io)
        Upstream Issue (URL): WasmEdge/WasmEdge#4011

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/cncf/
    idea_list_url: https://github.com/cncf/mentoring/blob/main/programs/summerofcode/2025.md


  - organization_id: 20
    organization_name: CRIU 
    no_of_ideas: 5
    ideas_content: |
        Project ideas
        Add support for memory compression
        Summary: Support compression for page images

        We would like to support memory page files compression in CRIU using one of the fastest algorithms (it's matter of discussion which one to choose!).

        This task does not require any Linux kernel modifications and scope is limited to CRIU itself. At the same time it's complex enough as we need to touch memory dump/restore codepath in CRIU and also handle many corner cases like page-server and stuff.

        Details:

        Skill level: intermediate
        Language: C
        Expected size: 350 hours
        Suggested by: Andrei Vagin <avagin@gmail.com>
        Mentors: Radostin Stoyanov <rstoyanov@fedoraproject.org>, Alexander Mikhalitsyn <alexander@mihalicyn.com>, Andrei Vagin <avagin@gmail.com>

        ~~~~~~~~~~
        Use eBPF to lock and unlock the network
        Summary: Use eBPF instead of external iptables-restore tool for network lock and unlock.

        During checkpointing and restoring CRIU locks the network to make sure no network packets are accepted by the network stack during the time the process is checkpointed. Currently CRIU calls out to iptables-restore to create and delete the corresponding iptables rules. Another approach which avoids calling out to the external binary iptables-restore would be to directly inject eBPF rules. There have been reports from users that iptables-restore fails in some way and eBPF could avoid this external dependency.

        Links:

        https://www.criu.org/TCP_connection#Checkpoint_and_restore_TCP_connection
        https://github.com/systemd/systemd/blob/master/src/core/bpf-firewall.c
        https://blog.zeyady.com/2021-08-16/gsoc-criu
        Details:

        Skill level: intermediate
        Language: C
        Expected size: 350 hours
        Mentors: Radostin Stoyanov <rstoyanov@fedoraproject.org>, Prajwal S N <prajwalnadig21@gmail.com>
        Suggested by: Adrian Reber <areber@redhat.com>

        ~~~~~~~~~~
        Files on detached mounts
        Summary: Initial support of open files on "detached" mounts

        When criu dumps a process with an open fd on a file, it gets the mount identifier (mnt_id) via /proc/<pid>/fdinfo/<fd>, so that criu knows from which exact mount the file was initially opened. This way criu can restore this fd by opening the same exact file from topologically the same mount in restored mount tree.

        Restoring fd from the right mount can be important in different cases, for instance if the process would later want to resolve paths relative to the fd, and obviously resolving from the same file on different mount can lead to different resolved paths, or if the process wants to check path to the file via /proc/<pid>/fd/<fd>.

        But we have a problem finding on which mount we need to reopen the file at restore if we only know mnt_id but can't find this mnt_id in /proc/<pid>/mountinfo.

        Mountinfo file shows the mount tree topology of current mntns: parent - child relations, sharing group information, mountpoint and fs root information. And if we don't see mnt_id in it we don't know anything about this mount.

        This can happen in two cases

        1) external mount or file - if file was opened from e.g. host it's mount would not be visible in container mountinfo
        2) mount was lazily unmounted
        In case of 1) we have criu options to help criu handle external dependencies.

        In case of 2) or no options provided criu can't resolve mnt_id in mountinfo and criu fails.

        Solution: We can handle 2) with: resolving major/minor via fstat, using name_to_handle_at and open_by_handle_at to open same file on any other available mount from same superblock (same major/minor) in container. Now we have fd2 of the same file as fd, but on existing mount we can dump it as usual instead, and mark it as "detached" in image, now criu on restore knows where to find this file, but instead of just opening fd2 from actually restored mount, we create a temporary bindmount which is lazy unmounted just after open making the file appear as a file on detached mount.

        Known problems with this approach:

        Stat on btrfs gives wrong major/minor
        file handles does not work everywhere
        file handles can return fd2 on deleted file or on other hardlink, this needs special handling.
        Additionally (optional part): We can export real major/minor in fdinfo (kernel). We can think of new kernel interface to get mount's major/minor and root (shift from fsroot) for detached mounts, if we have it we don't need file handle hack to find file on other mount (see fsinfo or getvalues kernel patches in LKML, can we add this info there?).

        Details:

        Skill level: intermediate
        Language: C
        Expected size: 350 hours
        Mentor: Pavel Tikhomirov <ptikhomirov@virtuozzo.com>
        Suggested by: Pavel Tikhomirov <ptikhomirov@virtuozzo.com>
        Checkpointing of POSIX message queues
        Summary: Add support for checkpoint/restore of POSIX message queues

        POSIX message queues are a widely used inter-process communication mechanism. Message queues are implemented as files on a virtual filesystem (mqueue), where a file descriptor (message queue descriptor) is used to perform operations such as sending or receiving messages. To support checkpoint/restore of POSIX message queues, we need a kernel interface (similar to MSG_PEEK) that would enable the retrieval of messages from a queue without removing them. This project aims to implement such an interface that allows retrieving all messages and their priorities from a POSIX message queue.

        Links:

        https://github.com/checkpoint-restore/criu/issues/2285
        https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/ipc/mqueue.c
        https://www.man7.org/tlpi/download/TLPI-52-POSIX_Message_Queues.pdf
        Details:

        Skill level: intermediate
        Language: C
        Expected size: 350 hours
        Mentors: Radostin Stoyanov <rstoyanov@fedoraproject.org>, Pavel Tikhomirov <ptikhomirov@virtuozzo.com>, Prajwal S N <prajwalnadig21@gmail.com>
        Suggested by: Pavel Tikhomirov <ptikhomirov@virtuozzo.com>

        ~~~~~~~~~~


        Add support for arm64 Guarded Control Stack (GCS)
        Summary: Support arm64 Guarded Control Stack (GCS)

        The arm64 Guarded Control Stack (GCS) feature provides support for hardware protected stacks of return addresses, intended to provide hardening against return oriented programming (ROP) attacks and to make it easier to gather call stacks for applications such as profiling (taken from [1]). We would like to support arm64 Guarded Control Stack (GCS) in CRIU, which means that CRIU should be able to Checkpoint/Restore applications using GCS.

        This task should not require any Linux kernel modifications but will require a lot of effort to understand Linux kernel and glibc support patches. We have a good example of support for x86 shadow stack [4].

        Links:

        [1] kernel support https://lore.kernel.org/all/20241001-arm64-gcs-v13-0-222b78d87eee@kernel.org
        [2] libc support https://inbox.sourceware.org/libc-alpha/20250117174119.3254972-1-yury.khrustalev@arm.com
        [3] libc tests https://inbox.sourceware.org/libc-alpha/20250210114538.1723249-1-yury.khrustalev@arm.com
        [4] x86 support https://github.com/checkpoint-restore/criu/pull/2306
        Details:

        Skill level: expert (a lot of moving parts: Linux kernel / libc / CRIU)
        Language: C
        Expected size: 350 hours
        Suggested by: Mike Rapoport <rppt@kernel.org>
        Mentors: Mike Rapoport <rppt@kernel.org>, Andrei Vagin <avagin@gmail.com>, Alexander Mikhalitsyn <alexander@mihalicyn.com>

        ~~~~~~~~~~
        Coordinated checkpointing of distributed applications
        Summary: Enable coordinated container checkpointing with Kubernetes.

        Checkpointing support has been recently introduced in Kubernetes, where the smallest deployable unit is a Pod (a group of containers). Kubernetes is often used to deploy applications that are distributed across multiple nodes. However, checkpointing such distributed applications requires a coordination mechanism to synchronize the checkpoint and restore operations. To address this challenge, we have developed a new tool called criu-coordinator that relies on the action-script functionality of CRIU to enable synchronization in distributed environments. This project aims to extend this tool to enable seamless integration with the checkpointing functionality of Kubernetes.

        Links:

        https://github.com/checkpoint-restore/criu-coordinator
        https://lpc.events/event/18/contributions/1803/
        https://sched.co/1YeT4
        https://kubernetes.io/blog/2022/12/05/forensic-container-checkpointing-alpha/
        Details:

        Skill level: intermediate
        Language: Rust / Go / C
        Expected size: 350 hours
        Mentors: Radostin Stoyanov <rstoyanov@fedoraproject.org>, Prajwal S N <prajwalnadig21@gmail.com>
        Suggested by: Radostin Stoyanov <rstoyanov@fedoraproject.org>

        

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/criu/
    idea_list_url: https://criu.org/Google_Summer_of_Code_Ideas
  

  - organization_id: 21
    organization_name: Center for Translational Data Science
    no_of_ideas: 7
    ideas_content: |
        Google Summer of Code - Project Ideas 2025
        #1 Project Name: Towards Personalized Medicine with FHIR Integration and Data Driven Discovery
        Mentor(s): Alex VanTol, Kyle Burton
        Project Description
        FHIR (Fast Healthcare Interoperability Resources, pronounced “fire”) is the standard for ensuring smooth data exchange and interoperability in electronic health records (EHR) and widely used in hospital settings. This project will focus on integrating a FHIR server into an open-source data platform used for managing and analyzing distributed biomedical data and supporting federated AI for data driven discovery.
        As part of this endeavor, you will work on enabling this platform to support FHIR standards, using synthetic data to ensure the functionality of the solutions developed. You will gain valuable experience at the intersection of healthcare and technology, working on tasks that include cloud infrastructure and modern data standards.
        Gain a deep understanding of the FHIR standard and how it supports interoperability of EHR systems.
        Learn about cloud-based architectures for managing and sharing biomedical data.
        Hone your ability to write, translate, and estimate business and technical requirements through user stories, tickets, and epics.
        Develop and deploy code, as well as create integration tests for proof of concept scenarios.
        Contribute to the enhancement of healthcare data interoperability.
        Expand your technical skills by working with cloud infrastructure and standardized data protocols.
        Acquire hands-on experience contributing to an impactful open-source software project.
        Expected Outcomes
        Automated deployment and configuration of a FHIR server within the data platform.
        Capability for the data platform to import and export FHIR data seamlessly.
        Skills Required/Preferred
        Required: 
        Python programming experience
        Some experience with cloud infrastructure

        Preferred:
        Some familiarity with healthcare data
        Java programming experience
        Javascript programming experience
        Expected Size and Difficulty
        350 hours
        Difficulty - Medium

        ~~~~~~~~~~

        #2 Project Name: Supporting an Open-Source Data Lake Architecture with Graph-like Data
        Mentor(s): Alex VanTol, Michael Lukowski
        Project Description
        This project focuses on enhancing a data platform by implementing a versatile solution for data ingestion and storage using a data lakehouse architecture. The aim is to prototype a method for converting graph-structured data into Avro-based files, specifically utilizing a file format called the Portable Format for Biomedical data (PFB). This format supports exporting and importing bulk clinical and other structured data within healthcare data platforms.
        You will engage in designing and developing tooling to convert data from original sources, representing graph-like models, into serialized Avro files for seamless ingestion into a data lake. This project offers a unique opportunity to delve into data lakehouse architectures, graph data models, and serialization techniques, enriching your expertise in these areas.
        Understand and work with data lakehouse architectures for managing diverse datasets.
        Learn to convert data from graph models into an Avro-based serialized format.
        Develop skills in creating extensible methodologies and tooling for data ingestion.
        Gain familiarity with querying and visualizing graph models contained within serialized files.
        Explore the intersection of data management, bioinformatics, and healthcare data platforms.
        Contribute to the development of advanced data ingestion and storage solutions.
        Enhance your understanding of data lakehouses and serialization formats like Avro.
        Acquire hands-on experience with graph data models and their applications.
        Participate in an open-source project that has real-world impact in the healthcare field.
        Expected Outcomes
        Develop methodology and tools for converting graph-structured data into Avro-based serialized files.
        Potentially include tools for querying and visualizing graph models within the serialized format, depending on project scope.
        Skills Required/Preferred
        Required:
        Python programming experience
        Preferred:
        Knowledge of graph models
        Some familiarity with serialization formats (specifically, Avro)
        Knowledge of UX and/or client side tooling
        Expected Size and Difficulty
        175 hours 
        Difficulty - Medium

        ~~~~~~~~~~

        #3 Project Name: Improve Scalable Data Download Functionality Using Globus and an Open-Source Python SDK & CLI
        Mentor(s): Alex VanTol, Pauline Ribeyre
        Project Description
        This project aims to enhance the data download capabilities of a Python SDK & CLI used to interact with a large-scale data management platform. The goal is to create a consistent and efficient tool for researchers to download and stream large biomedical data sets. This involves integrating with existing RESTful APIs and Globus, a service for secure and reliable data transfer.
        You will work on implementing data download functionality within the Python SDK & CLI, writing unit tests to ensure robust code, and optimizing the download process using asynchronous capabilities in Python. This tool will be extensively used by researchers and scientists to stream large data sets to virtual workspaces for analysis.
        Gain experience in enhancing data download functionalities in a scalable manner.
        Learn to work with RESTful APIs and how to interact with them programmatically.
        Get hands-on experience with Globus for secure data transfer.
        Develop skills in Python programming, particularly in creating efficient and asynchronous code.
        Learn to write thorough unit tests to ensure high code quality.
        Understand the challenges and requirements of streaming large biomedical data sets.
        Contribute to improving tools that support large-scale data management and research.
        Enhance your programming skills, particularly in Python and Golang.
        Work on real-world projects that benefit researchers and scientists in the biomedical field.
        Gain experience in using modern data transfer technologies and optimizing performance.
        Expected Outcomes
        Implemented data download functionality within the Python SDK & CLI, integrated with Globus.
        Achieve 100% unit test coverage for the new code.
        Optimized data download process for improved performance.
        Skills Required/Preferred
        Required:
        Ability to read and understand Golang
        Ability to code in Python
        Preferred:
        Familiarity with RESTful APIs
        Familiarity with testing
        Familiarity with command line interfaces and/or UX
        Familiarity with concepts around concurrency
        Expected Size and Difficulty
        175 hours
        Difficulty - Medium

        ~~~~~~~~~~

        #4 Project Name: Towards a Data Commons Operations Center with Observability and Monitoring
        Mentor(s): Jawad Qureshi
        Project Description
        The goal of this project is to develop an Operations Center dashboard (CSOC) to manage multiple standalone and interconnected data commons running Gen3, a well-established open source platform for biomedical research. This dashboard will streamline the deployment, monitoring, and management of Gen3 data commons and meshes through a unified interface. The project will involve creating a distributed system with a Go-based backend and Next.js frontend, integrating with Kubernetes, Grafana, Helm, and Terraform, and ensuring secure server-agent communication.

        Expected Outcomes
        Production-ready Operations Center: A functional dashboard with a Go backend and Next.js frontend.
        RBAC and Security Policy Administration: Implementation of role-based access control (RBAC) and security policies.
        Observability Platform: Complete observability integrated with Prometheus/Grafana for monitoring.
        User-Friendly Dashboard: An intuitive interface for Gen3 commons deployment and management.
        Secure Server-Agent Communication: Infrastructure to ensure secure communication between server and agents.
        Comprehensive Documentation: Detailed system documentation and deployment guides.

        Skills Required/Preferred
        Go programming experience
        React/Next.js development skills / Javascript
        Understanding of Kubernetes, Helm, and Terraform
        Understanding of Cloud Infrastructure
        Experience with gRPC
        Understanding the pillars of observability (metrics, logs, tracing)
        Expected Size and Difficulty
        Number of hours 1000
        Difficulty - (Medium - Difficult)

        ~~~~~~~~~~

        #5 Project Name: Enhance Data Solutions with Native Graph Database Integration
        Mentor(s): Craig Barnes, Andrew Prokhorenkov, Alex VanTol
        Project Description
        This project aims to significantly improve the efficiency and capabilities of our data platform by transitioning from a custom PostgreSQL backend to a native graph database solution. With the increasing reliability and performance of graph databases like neo4j, this transition will enhance how we manage, analyze, and query complex biomedical data.
        Your role will involve developing a new Python-based microservice that supports the same RESTful APIs as our current submission and query services. Additionally, the microservice will dynamically generate GraphQL (or GraphQL-like) APIs based on a configured data schema, facilitating advanced search and query capabilities.
        Expected Outcomes
        Evaluate and analyze the best native graph database solutions for integration.
        Implement the selected graph database to replace the current PostgreSQL backend.
        Develop a new microservice in Python to support the existing RESTful and GraphQL (or GraphQL-like) APIs.
        Ensure seamless data submission, access, and querying within our data platform.
        This project will enhance our data platform's performance and flexibility, offering more robust solutions for managing biomedical data. Your contribution will provide significant improvements in data querying and management capabilities, benefiting the broader biomedical research community.
        Skills Required/Preferred
        Required: 
        Proficiency in Python
        Basic understanding of GitHub or other version control platforms
        Familiarity with RESTful APIs
        Understanding of graph databases
        Knowledge of user authorization and security principles

        Preferred:
        Familiarity with relational databases
        Understanding of microservice architecture, Docker, and containerization
        Expected Size and Difficulty
        Number of hours: 350 hours
        Difficulty - Hard

        ~~~~~~~~~~

        #6 Project Name: GPU Cluster Orchestration and Observability
        Mentors: Salman Sikandar and Bilal Baqar
        Project Description
        This project focuses on developing a CPU-based control plane to orchestrate jobs on an existing GPU cluster used by ML/AI researchers. The current setup is rudimentary, and the goal is to implement an automated job scheduling system along with comprehensive observability. The intern will design and implement a solution using technologies like Slurm for orchestration, and Prometheus/Grafana for monitoring and alerting.
        Expected Outcomes:
        Implement a job scheduler with priority queues and preemption capabilities for GPU workloads
        Develop a centralized dashboard displaying GPU/CPU utilization, job queue status, and thermal metrics
        Create Terraform/Ansible playbooks for reproducible cluster provisioning
        Design and implement automated alerting based on predefined thresholds and anomaly detection
        Skills Required/Preferred
        Required:
        Python or Go programming
        Linux systems administration
        Basic networking concepts
        Containerization (Docker)
        Preferred:
        Experience with Slurm
        Familiarity with Prometheus and Grafana
        GPU architecture knowledge (CUDA/NCCL)
        Experience with distributed systems

        Expected Size and Difficulty
        Number of Hours: 300-350 hours (8-10 weeks)
        Difficulty: Intermediate to Advanced

        ~~~~~~~~~~


        #7 Project Name: Staging Inference Cluster with CI/CD
        Mentors:
        Salman Sikandar and Bilal Baqar
        Project Description
        This project involves building a staging inference cluster to host production versions of ML models with auto scaling capabilities and CI/CD pipelines. The intern will set up an environment that allows for seamless promotion of trained models to production, implementing canary deployments and rollback mechanisms. The project will utilize technologies such as KEDA or Vertical Pod Autoscaler for autoscaling, and ArgoCD or Flux for GitOps-driven CI/CD.
        Expected Outcomes:

        Establish a staging inference cluster with autoscaling triggered by request latency/throughput thresholds
        Implement a GitHub Actions pipeline for model validation, containerization, and deployment
        Develop GitOps-driven CI/CD pipelines using ArgoCD or Flux for automated deployments
        Create a system for canary deployments and automated rollbacks based on performance metrics

        Skills Required/Preferred
        Required:
        Python or Go programming
        CI/CD concepts and tools
        Containerization (Docker)
        Basic understanding of ML workflows
        Preferred:
        Knowledge of ML model serving frameworks
        Familiarity with GitOps principles

        Expected Size and Difficulty
        Number of Hours: 300-350 hours (8-10 weeks)
        Difficulty: Intermediate to Advanced


          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/center-for-translational-data-science/
    idea_list_url: https://docs.google.com/document/d/1kiEDB6tw2xD8Qj3uxpSELjazW35llHM1a9Nt_LQKwHw/edit?usp=sharing

  - organization_id: 22
    organization_name: Ceph Foundation
    no_of_ideas: 7
    ideas_content: |
      
      Teuthology on Podman ¶
      Mentor name(s): Zack Cerza, Kamoltat (Junior) Sirivadhna Aishwarya Mathuria, Vallari Agrawal
      Mentor email(s): zack1@ibm.com, ksirivad@ibm.com, aishwarya.mathuria@ibm.com, vallari.agrawal@ibm.com
      Difficulty: Hard
      Project Hours: 175
      Skills needed: python, containerisation, linux
      Subcomponent of Ceph: Ceph Integration Test Framework
      Description of project:
      ceph-devstack is an in-development tool that uses rootless podman containers to deploy a scaled-down teuthology lab. It has proven useful for testing changes to teuthology and its related services, allowing us to more easily and flexibly make changes to components without worrying about causing outages.
      It has some basic ability to run Ceph tests, but could benefit significantly from more investment in that area.
      Improve and extend ceph-devstack's ability to perform teuthology tests against Ceph builds. This project will involve writing Python code and tests to orchestrate podman containers, and working with security systems like SELinux, CGroups, and Linux capabilities.
      Standup/weekly call mentee could attend?: Teuthology weekly meeting
      Steps to evaluate an applicant for the project: TBD
      1-2 short paragraphs about what first 2 weeks of work would look like during the internship: TBD
      Expected Outcome:
      Extend ceph-devstack's ability to perform teuthology tests

      ~~~~~~~~~~
      smartmontools drivedb.h postprocessor ¶
      Mentor name(s): Anthony D'Atri, Sunil Angadi
      Mentor email(s): anthony.datri@ibm.com, sunil.angadi@ibm.com
      Difficulty: Intermediate
      Project Hours: 90
      Skills needed: c++, maybe python or golang
      Subcomponent of Ceph: Observability
      Description of project:
      smartmontools (smartctl) is pretty much the only game in town for harvesting metrics and counters from storage devices: SMART for SATA, a few things for SAS, and passthrough to nvme-cli for NVMe. It leverages a runtime file named drivedb.h that directs what attributes are to be found with what numeric IDs, and how to interpret them. drivedb.h is a mess, and upstream smartmontools would likely resist wholesale refactoring. For example, SSD wear might be labeled as "lifetime remaining" or "wear level" or multiple other strings. Some devices also report wear used, others wear remaining.
      One task would be to add an interpretation primitive to the c++ code so that a drivedb.h entry can specify that the result should be subtracted from 100.
      The larger task would be to write a postprocessor for drivedb.h that more or less is a sequence of regex invocations that converges the existing freeform attribute label names into a normalized, defined set. Many tools just pass through the text labels, so doing meaningful analysis or queries is difficult; often only a fraction of the data is actually captured as a result. The output also includes numeric attribute IDs, which are less varied, but relying on them instead of the text labels is fraught because these numeric IDs are not strictly standardized either. I have seen drives that report a metric on a different numeric ID than most others, and/or that report a different metric on a specific numeric than most others report on that ID.
      For extra credit, interface with the central telemetry DB as described in project "Public telemetry slice/dice of SMART data".
      Standup/weekly call mentee could attend?: TBD
      Steps to evaluate an applicant for the project: Ability to leverage code libraries and write the glue code.
      1-2 short paragraphs about what first 2 weeks of work would look like during the internship: TBD

      ~~~~~~~~~~
      The More The Merrier ¶
      Mentor name(s): Yuval Lifshitz
      Mentor email(s): ylifshit@ibm.com
      Difficulty: Hard
      Project Hours: 350
      Skills needed: C++, Python
      Subcomponent of Ceph: RGW
      Description of project:
      Detailed description of the project and evalution steps can be found here.
      Persistent bucket notifications are a very useful and powerful feature
      tech talk: https://www.youtube.com/watch?v=57Ejl6R-L20
      usecase example: https://www.youtube.com/watch?v=57Ejl6R-L20
      However, they can pose a performance issue, since the notifications regarding a specific bucket are written to a single RADOS queue (unlike the writes to the bucket which are distributed across multiple bucket shards. So, in case that small objects are written to the bucket, the overhead of the notifications is considerable. In this project, our goal would be to create a sharded bucket notifications queue, to allow for better performance of sending persistent bucket notifications.
      Standup/weekly call mentee could attend?: RGW daily Standup, RGW weekly refactoring meeting
      Steps to evaluate an applicant for the project:
      build ceph from source and run basic bucket notification tests
      fix low-hanging-fruit issues in bucket notifications
      1-2 short paragraphs about what first 2 weeks of work would look like during the internship: TBD
      Expected outcome:
      sharded implementation of persistent topic queue

      ~~~~~~~~~~
      stretch goal: perf test proving performance improvement
      Public telemetry slice/dice of SMART data ¶
      Mentor name(s): Anthony D'Atri
      Mentor email(s): anthony.datri@ibm.com
      Difficulty: Medium
      Project Hours: 175
      Skills needed: Some coding language, Python or Go, jq or JSON parsing or other text library.
      Subcomponent of Ceph: telemetry
      Description of project:
      Public telemetry today offers a few Grafana panels and downloadable archives of anonymized data. One field is a JSON blob of smartctl output. Parse this, apply a normalization layer, deduplicate, and present in one or more formats that facilitate analysis:
      CSV file containing attributes for only the latest report found for a given device
      The number of data points might be too high, but possibly a Grafana dashboard or even spreadsheet with template variables for manufacturer/model, interface type, etc. with various panes:
      Histograms of power_on hours, normalized endurance used or remaining, etc
      histogram or table of endurance remaining vs power on hours or TBW, i.e. allowing one to predict drive lifetime and inform purchase decisions, vs. assuming that SSDs especially QLC lack endurance or that high-endurance SKUs are required.
      reallocated sectors over time, etc.
      Standup/weekly call mentee could attend?: TBD
      Steps to evaluate an applicant for the project: Coding experience beyond Karel
      1-2 short paragraphs about what first 2 weeks of work would look like during the internship:
      Gain familiarity with the data format, including JSON. Discuss input filtering: skip over invalid entries, handle submissions from older smartmontools, uniqify, learn about SMART -- and how dumb it is, the need for nomalization of counters.
      Expected outcome:
      Described above under Description. More specifically, deriving the rate of wear over time for each specific SSD for which we have more than say a month of data: capture the delta between earliest and latest wear levels reported for each given serial number, and the time delta between those samples. Divide the wear delta by the time delta for rate of wear over time.
      
      ~~~~~~~~~~
      Warm and Fuzzy ¶
      Mentor name(s): Yuval Lifshitz, Pritha Srivastava
      Mentor email(s): ylifshit@ibm.com, Pritha.Srivastava@ibm.com
      Difficulty: Medium
      Project Hours: 175
      Skills needed: C++, Python and also depending with the tool
      Subcomponent of Ceph: RGW
      Description of project:
      The RGW's frontend is an S3 REST API server, and in this project we would like to use a REST API fuzzer to test the RGW for security issues (and other bugs). First step of the project would be to select the right tool (e.g. https://github.com/microsoft/restler-fuzzer), feed it with the AWS S3 OpenAPI spec, and see what happens when we let it connect to the RGW. Fixing issues the fuzzer finds would nice, but the real stretch goal would be to integrate these tests into teuthology.
      Standup/weekly call mentee could attend: RGW daily Standup, RGW weekly refactoring meeting
      Steps to evaluate an applicant for the project:
      Detailed description of the project and evalution steps can be found here.
      1-2 short paragraphs about what first 2 weeks of work would look like during the internship: TBD
      Expected outcome:
      find and fix security issues in the RGW found by the fuzzing tool
      stretch goal: integrate tool into automated teuthology runs

      ~~~~~~~~~~
      Ceph Dashboard Usability Improvements ¶
      Mentor name(s): Afreen Misbah
      Mentor email(s): afreen@ibm.com
      Difficulty: Easy
      Project Hours: 175
      Skills needed: Typescript, Angular, and basic understanding of HTML & CSS.
      Subcomponent of Ceph: Dashboard
      Description of project:
      Ceph Dashboard is Ceph's management and monitoring tool. It's a web application tool with Angular/Typescript on frontend side and Python as backend.
      We are in an effort to provide more usability workflows and solve UX issues to make management and monitoring easy for Ceph users.
      The task includes improving the notification system and creating a workflow for managing NVMe-oF devices from dashboard.
      Standup/weekly call mentee could attend?: Dashboard daily sync
      Steps to evaluate an applicant for the project:
      Build ceph dashboard locally via docker-compose and kcli both
      Able to understand issues and ask useful questions
      Eagerness to learn and contribute
      1-2 short paragraphs about what first 2 weeks of work would look like during the internship:
      Learning about ceph and storage and gradually contributing to the dashboard.
      Expected Outcome:
      Improve dashboard usability.

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/ceph-foundation/
    idea_list_url: https://ceph.io/en/developers/google-summer-of-code/

  - organization_id: 23
    organization_name: Checker Framework
    no_of_ideas: 4
    ideas_content: |
      Evaluate a type system or a Checker Framework feature
      These projects evaluate a recently-written type system or a feature used by multiple type systems. Using the type systems on real code is our most important source of new ideas and improvements. Many people have started out “just” doing a case study but have ended up making deep, fundamental contributions and even publishing scientific papers about their discoveries.

      One possible outcome is to identify weaknesses in the type-checker so that we can improve it. Another possible outcome is to provide evidence that the type-checker is effective and convince more users to adopt it. You will probably also discover defects (bugs) in the codebase being type-checked.

      Signature strings
      Determine whether the ASM library, or some other library, properly handles signature strings.

      Some challenging aspects of this case study are:

      Some libraries define their own new signature string formats (!), which you need to define in the Signature String Checker.
      Sometimes the library's documentation is incorrect, and in other cases the string format is not defined.
      Preventing mixed signed/unsigned computations
      An unsigned integer's bits are interpreted differently than a signed integer's bits. It is meaningless to add a signed and an unsigned integer — the result will be nonsense bits. The same is true of printing and of other numeric operators such as multiplication and comparison.

      We have a prototype compile-time verification tool that detects and prevents these errors. The goal of this project is to perform case studies to determine how often programmers make signedness errors (our initial investigation suggests that this is common!) and to improve the verification tool.

      The research questions are:

      How often do programmers make signedness errors?
      Is it feasible to automatically detect signedness errors? What techniques are useful?
      What is the false positive rate of a signedness verification tool — that is, false alarms from the tool?
      How much effort is required from a programmer?
      The methodology is:

      find open-source projects that use unsigned arithmetic
      run the verification tool on them
      for each tool warning, determine whether it is a defect in the project or a limitation of the verification tool. For example, the Signedness Checker does not currently handle boxed integers and BigInteger; these haven't yet come up in case studies but could be worthwhile enhancements. You may also need to write more annotations for libraries such as the JDK.
      submit bug reports against the project, or improve the verification tool
      A good way to find projects that use unsigned arithmetic is to find a library that supports unsigned arithmetic, then search on GitHub for projects that use that library.

      Here are some relevant libraries.

      In the JDK's Integer and Long, these include compareUnsigned, divideUnsigned, parseUnsignedInt, remainderUnsigned, and toUnsignedLong.
      Classes like DataInputStream, ObjectInputStream, and RandomAccessFile have readUnsignedByte.
      Arrays has compareUnsigned. The JDK is already annotated; search for @Unsigned within https://github.com/typetools/jdk.
      In Guava, see its unsigned support, such as UnsignedBytes, UnsignedLong, UnsignedLongs, etc. Guava is already annotated; search for @Unsigned within https://github.com/typetools/guava.
      The jOOU library consists of support for unsigned integers.
      Another possibility is to find Java projects that could use an unsigned arithmetic library but do not. For example, bc-java defines its own unsigned libraries, and some other programs might do direct bit manipulation.

      Whole-program type inference
      A type system is useful because it prevents certain errors. The downside of a type system is the effort required to write the types. Type inference is the process of writing the types for a program.

      The Checker Framework includes a whole-program inference that inserts type qualifiers in the user's program. It works well on some programs, but needs more enhancements to work well on all programs.

      Sound checking by default
      By default, the Checker Framework is unsound in several circumstances. “Unsound” means that the Checker Framework may report no warning even though the program can misbehave at run time.

      The reason that the Checker Framework is unsound is that we believe that enabling these checks would cause too many false positive warnings: warnings that the Checker Framework issues because it cannot prove that the code is safe (even though a human can see that the code is safe). Having too many false positive warnings would irritate users and lead them not to use the checker at all, or would force them to simply disable those checks.

      We would like to do studies of these command-line options to see whether our concern is justified. Is it prohibitive to enable sound checking? Or can we think of enhancements that would let us turn on those checks that are currently disabled by default?

      There is no need to annotate new code for this project. Just use existing annotated codebases, such as those that are type-checked as part of the Checker Framework's Azure Pipeline. In other words, you can start by enabling Azure Pipelines for your fork and then changing the default behavior in a branch. The Azure Pipelines job will show you what new warnings appear.

      Comparison to other tools
      Many other tools exist for prevention of programming errors, such as Error Prone, NullAway, FindBugs, JLint, PMD, and IDEs such as Eclipse and IntelliJ. These tools are not as powerful as the Checker Framework (some are bug finders rather than verification tools, and some perform a shallower analysis), but they may be easier to use. Programmers who use these tools wonder, "Is it worth my time to switch to using the Checker Framework?"

      The goal of this project is to perform a head-to-head comparison of as many different tools as possible. You will quantify:

      the number of annotations that need to be written
      the number of bugs detected
      the number of bugs missed
      the number of false positive warnings
      This project will help programmers to choose among the different tools — it will show when a programmer should or should not use the Checker Framework. This project will also indicate how each tool should be improved.

      One place to start would be with an old version of a program that is known to contain bugs. Or, start with the latest version of the program and re-introduce fixed bugs. (Either of these is more realistic than introducing artificial bugs into the program.) A possibility would be to use the Lookup program that has been used in previous case studies.

      Android support annotations
      Android uses its own annotations that are similar to some in the Checker Framework. Examples include the Android Studio support annotations, including @NonNull, @IntRange, @IntDef, and others.

      The goal of this project is to implement support for these annotations. That is probably as simple as creating aliased annotations by calling method addAliasedTypeAnnotation() in AnnotatedTypeFactory.

      Then, do a case study to show the utility (or not) of pluggable type-checking, by comparison with how Android Studio currently checks the annotations.
      
      ~~~~~~~~~~

      Annotate a library
      These projects annotate a library, so that it is easier to type-check clients of the library. Another benefit is that this may find bugs in the library. It can also give evidence for the usefulness of pluggable type-checking, or point out ways to improve the Checker Framework.
      When type-checking a method call, the Checker Framework uses the method declaration's annotations. This means that in order to type-check code that uses a library, the Checker Framework needs an annotated version of the library.
      The Checker Framework comes with a few annotated libraries. Increasing this number will make the Checker Framework even more useful, and easier to use.
      After you have chosen a library, fork the library's source code, adjust its build system to run the Checker Framework, and add annotations to it until the type-checker issues no warnings.
      Before you get started, be sure to read How to get started annotating legacy code. More generally, read the relevant sections of the Checker Framework manual.
      Choosing a library to annotate
      There are several ways to choose a library to annotate:
      The best way to choose a library is to try to annotate a program and notice that library annotations are needed in order to type-check the program.
      Alternately, you can choose a popular Java library.
      When annotating a library, it is important to type-check both the library and at least one client that uses it. Type-checking the client will ensure that the library annotations are accurate.
      Whatever library you choose, you will need to deeply understand its source code. You will find it easier to work with a library that is well-designed and well-documented.
      You should choose a library that is not already annotated. There are two exceptions to this.
      A library might be annotated for one type system, but you add annotations for a different type system. One advantage of this is that the library's build system is already set up to run the Checker Framework. You can tell which type systems a library is annotated for by examining its source code.
      A library might be annotated, but the annotations have not been verified by running the type-checker on the library source code. You would verify that the annotations in the library are correct.
      Guava library
      Guava is already partially annotated with nullness annotations — in part by Guava's developers, and in part by the Checker Framework team. However, Guava does not yet type-check without errors. Doing so could find more errors (the Checker Framework has found nullness and indexing errors in Guava in the past) and would be a good case study to learn the limitations of the Nullness Checker.
      
      ~~~~~~~~~~
      Create a new type system
      The Checker Framework is shipped with about 20 type-checkers. Users can create a new checker of their own. However, some users don't want to go to that trouble. They would like to have more type-checkers packaged with the Checker Framework for easy use.
      Each of these projects requires you to design a new type system, implement it, and perform case studies to demonstrate that it is both usable and effective in finding/preventing bugs.
      Ownership type system
      The lightweight ownership mechanism of the Resource Leak Checker is not implemented as a type system, but it should be. That would enable writing ownership annotations on generic type arguments, like List<@Owning Socket>. It would also enable changing the Resource Leak Checker so that non-@Owning formal parameters do not have their @MustCall annotation erased.
      We have some notes on possible implementation strategies.
      Non-Empty Checker for precise handling of Queue.peek() and poll()
      The Nullness Checker issues a false positive warning for this code:
      import java.util.PriorityQueue;
      import org.checkerframework.checker.nullness.qual.NonNull;
      
      public class MyClass {
          public static void usePriorityQueue(PriorityQueue<@NonNull Object> active) {
              while (!(active.isEmpty())) {
                  @NonNull Object queueMinPathNode = active.peek();
              }
          }
      }
      The Checker Framework does not determine that active.peek() returns a non-null value in this context.
      The contract of peek() is that it returns a non-null value if the queue is not empty and the queue contains no null values.
      To handle this code precisely, the Nullness Checker needs to know, for each queue, whether it is empty. This is analogous to how the Nullness Checker tracks whether a particular value is a key in a map.
      It should be handled the same way: by adding a new subchecker, called the Nonempty Checker, to the Nullness Checker. Its types are:
      @UnknownNonEmpty — the queue might or might not be empty
      @NonEmpty — the queue is definitely non-empty
      There is a start at this type-checker in branch nonempty-checker. It:
      defines the annotations
      creates the integration into the Nullness Checker
      However, it is not done. (In fact, it doesn't even compile.) For information about what needs to be done, see issue #399.
      When you are done, the Nullness Checker should issue only the // :: diagnostics from checker/tests/nullness/IsEmptyPoll.java — no more and no fewer. You can test that by running the Nullness Checker on the file, and when you are done you should delete the // @skip-test line so that the file is run as part of the Checker Framework test suite.
      Iteration Checker to prevent NoSuchElementException
      A Java program that uses an Iterator can throw NoSuchElementException if the program calls next() on the Iterator but the Iterator has no more elements to iterate over. Such exceptions even occur in production code (for example, in Eclipse's rdf4j).
      We would like a compile-time guarantee that this run-time error will never happen. Our analysis will statically determine whether the hasNext() method would return true. The basic type system has two type qualifiers: @HasNext is a subtype of @UnknownHasNext.
      A variable's type is @HasNext if the program calls hasNext() and it returns true. Implementing this is easy (see the dataflow section in the "How to create a new checker" chapter). The analysis can also permit some calls to next() even if the programmer has not called hasNext(). For example, a call to next() is permitted on a newly-constructed iterator that is made from a non-empty collection. (This special case could build upon the Non-Empty Checker mentioned above.) There are probably other special cases, which experimentation will reveal.
      Parts of this are already implemented, but it needs to be enhanced. Once case studies have demonstrated its effectiveness, then it can be released to the world, and a scientific paper can be written.
      Preventing injection vulnerabilities via specialized taint analysis
      Many security vulnerabilities result from use of untrusted data without sanitizing it first. Examples include SQL injection, cross-site scripting, command injection, and many more. Other vulnerabilities result from leaking private data, such as credit card numbers.
      We have built a generalized taint analysis that can address any of these problems. However, because it is so general, it is not very useful. A user must customize it for each particular problem.
      The goal of this project is to make those customizations, and to evaluate their usefulness. A specific research question is: "To what extent is a general taint analysis useful in eliminating a wide variety of security vulnerabilities? How much customization, if any, is needed?"
      The generalized taint analysis is the Checker Framework's a Tainting Checker. It requires customization to a particular domain:
      rename the @Tainted and @Untainted qualifiers to something more specific (such as @Private or @PaymentDetails or @HtmlQuoted), and
      annotate libraries.
      The first part of this project is to make this customization easier to do — preferably, a user will not have to change any code in the Checker Framework (the Subtyping Checker already works this way). As part of making customization easier, a user should be able to specify multiple levels of taint — many information classification hierarchies have more than two levels. For example, the US government separates information into four categories: Unclassified, Confidential, Secret, and Top Secret.
      The second part of this project is to provide several examples, and do case studies showing the utility of compile-time taint checking.
      Possible examples include:
      SQL injection
      OS command injection
      the @PrivacySource and @PrivacySink annotations used by the Meta Infer static analyzer.
      information flow
      many of the CWE/SANS most dangerous software programming errors (and the "on the cusp" ones too)
      For some microbenchmarks, see the Juliette test suite for Java from CWE.
      Warn about unsupported operations
      In Java, some objects do not fully implement their interface; they throw UnsupportedOperationException for some operations. One example is unmodifiable collections. They throw the exception when a mutating operation is called, such as add, addAll, put, remove, etc.
      The goal of this project is to design a compile-time verification tool to track which operations might not be supported. This tool will issue a warning whenever an UnsupportedOperationException might occur at run time. This helps programmers to avoid run-time exceptions (crashes) in their Java programs.
      The research questions include:
      Is it is possible to build a verification tool to prevent UnsupportedOperationException? What design is effective?
      How difficult is such a tool to use, in terms of programmer effort and number of false alarms?
      Are potential UnsupportedOperationException exceptions pervasive in Java programs? Is it possible to eliminate them?
      The methodology is:
      design a static (compile-time) analysis
      implement it
      evaluate it on open-source projects
      report bugs in the projects, and improve the tool
      Here is a possible design, as a pluggable type system.
        @Unmodifiable
             |
        @Modifiable
      In other words, the @Unmodifiable type qualifier is a supertype of @Modifiable. This means that a @Modifiable List can be used where an @Unmodifiable List is expected, but not vice versa.
      @Modifable is the default, and methods such as Arrays.asList and Collections.emptyList must be annotated to return the less-capable supertype.
      Overflow checking
      Overflow is when 32-bit arithmetic differs from ideal arithmetic. For example, in Java the int computation 2,147,483,647 + 1 yields a negative number, -2,147,483,648. The goal of this project is to detect and prevent problems such as these.
      One way to write this is as an extension of the Constant Value Checker, which already keeps track of integer ranges. It even already checks for overflow, but it never issues a warning when it discovers possible overflow. Your variant would do so.
      This problem is so challenging that there has been almost no previous research on static approaches to the problem. (Two relevant papers are IntScope: Automatically Detecting Integer Overflow Vulnerability in x86 Binary Using Symbolic Execution and Integer Overflow Vulnerabilities Detection in Software Binary Code.) Researchers are concerned that users will have to write a lot of annotations indicating the possible ranges of variables, and that even so there will be a lot of false positive warnings due to approximations in the conservative analysis. For example, will every loop that contains i++ cause a warning that i might overflow? That would not be acceptable: users would just disable the check.
      You can convince yourself of the difficulty by manually analyzing programs to see how clever the analysis has to be, or manually simulating your proposed analysis on a selection of real-world code to learn its weaknesses. You might also try it on good and bad binary search code.
      One way to make the problem tractable is to limit its scope: instead of being concerned with all possible arithmetic overflow, focus on a specific use case. As one concrete application, the Index Checker is currently unsound in the presence of integer overflow. If an integer i is known to be @Positive, and 1 is added to it, then the Index Checker believes that its type remains @Positive. If i was already Integer.MAX_VALUE, then the result is negative — that is, the Index Checker's approximation to it is unsound.
      This project involves removing this unsoundness by implementing a type system to track when an integer value might overflow — but this only matters for values that are used as an array index. That is, checking can be restricted to computations that involve an operand of type @IntRange). Implementing such an analysis would permit the Index Checker to extend its guarantees even to programs that might overflow.
      This analysis is important for some indexing bugs in practice. Using the Index Checker, we found 5 bugs in Google Guava related to overflow. Google marked these as high priority and fixed them immediately. In practice, there would be a run-time exception only for an array of size approximately Integer.MAX_INT.
      You could write an extension of the Constant Value Checker, which already keeps track of integer ranges and even determines when overflow is possible. It doesn't issue a warning, but your checker could record whether overflow was possible (this could be a two-element type system) and then issue a warning, if the value is used as an array index. Other implementation strategies may be possible.
      Here are some ideas for how to avoid the specific problem of issuing a warning about potential overflow for every i++ in a loop (but maybe other approaches are possible):
      The loop checks whether i == Integer.MAX_VALUE before incrementing. This wide-scale, disruptive code change is not acceptable.
      Make the default array size (the length of an unannotated array) be @ArrayLenRange(0, Integer.MAX_VALUE-1) rather than @UnknownVal, which is equivalent to @ArrayLenRange(0, Integer.MAX_VALUE-1). Now, every array construction requires the client to establish that the length is not Integer.MAX_VALUE. I don't have a feel for whether this would be unduly burdensome to users.
      Index checking for mutable length data structures
      The Index Checker is currently restricted to fixed-size data structures. A fixed-size data structure is one whose length cannot be changed once it is created, such as arrays and Strings. This limitation prevents the Index Checker from verifying indexing operations on mutable-size data structures, like Lists, that have add or remove methods. Since these kind of collections are common in practice, this is a severe limitation for the Index Checker.
      The limitation is caused by the Index Checker's use of types that are dependent on the length of data structures, like @LTLengthOf("data_structure"). If data_structure's length could change, then the correctness of this type might change.
      A naive solution would be to invalidate these types any time a method is called on data_structure. Unfortunately, aliasing makes this still unsound. Even more, a great solution to this problem would keep the information in the type when a method like add or remove is called on data_structure. A more complete solution might involve some special annotations on List that permit the information to be persisted.
      Another approach would be to run a pointer analysis before type-checking, then use that information for precise information about what lists might be changed by each call to add or remove. One possible pointer analysis would be that of Doop.
      This project would involve designing and implementing a solution to this problem.
      Nullness bug detector
      Verifying a program to be free of errors can be a daunting task. When starting out, a user may be more interested in bug-finding than verification. The goal of this project is to create a nullness bug detector that uses the powerful analysis of the Checker Framework and its Nullness Checker, but omits some of its more confusing or expensive features. The goal is to create a fast, easy-to-use bug detector. It would enable users to start small and advance to full verification in the future, rather than having to start out doing full verification.
      This could be structured as a new NullnessLight Checker, or as a command-line argument to the current Nullness Checker. Here are some differences from the real Nullness checker:
      No initialization analysis; the checker assumes that every value is initialized.
      No map key analysis; assume that, at every call to Map.get, the given key appears in the map.
      No invalidation of dataflow facts. Assume all method calls are pure, so method calls do not invalidate dataflow facts. Assume there is no aliasing, so field updates do not invalidate dataflow facts.
      Assume that boxing of primitives is @Pure: it returns the same value on every call.
      If the Checker Framework cannot infer a type argument, assume that the type argument is @NonNull.
      Each of these behaviors should be controlled by its own command-line argument, as well as being enabled in the NullnessLight Checker.
      The implementation may be relatively straightforward, since in most cases the behavior is just to disable some functionality of existing checkers.
      Tools such as FindBugs, NullAway, NullnessLight, and the Nullness Checker form a spectrum from easy-to-use bug detectors to sound verification. NullnessLight represents a new point in the design space. It will be interesting to compare these checkers:
      How much easier is it to use? For example, how many fewer annotations need to be written?
      How many more fewer true positives does it report — in other words, how many more false negatives does it suffer?
      How many fewer false positives does it report?
      Uber's NullAway tool is also an implementation of this idea (that is, a fast, but incomplete and unsound, nullness checker). NullAway doesn't let the user specify Java Generics: it assumes that every type parameter is @NonNull. Does Uber's tool provide users a good introduction to the ideas that a user can use to transition to a nullness type system later?
      
      ~~~~~~~~~~
      Enhance the toolset
      Indicate library methods that should be used instead
      Sometimes, the best way to avoid a checker warning is to use an annotated library method. Consider this code:
      @FqBinaryName String fqBinaryName = ...;
      @ClassGetName String componentType = fqBinaryName.substring(0, fqBinaryName.indexOf('['));
      The Signature String Checker issues a warning, because it does not reason about arbitrary string manipulations. The code is correct, but it is in bad style. It is confusing to perform string manipulations to convert between different string representations. It is clearer and less error-prone (the above code is buggy when fqBinaryName is not an array type!) to use a library method, and the checker accepts this code because the library method is appropriately annotated:
      import org.plumelib.reflection.Signatures;
      ...
      @ClassGetName String componentType = Signatures.getArrayElementType(fqBinaryName);
      However, users may not know about the library method. Therefore, the Checker Framework should issue a warning message, along with the error message, notifying users of the library method. For example, the Signature String Checker would heuristically mention the Signatures.getArrayElementType() method when it issues an error about string manipulation where some input is a FqBinaryName and the output is annotated as ClassGetName. It would behave similarly for other library methods.
      Improving error messages
      Compiler writers have come to realize that clarity of error messages is as important as the speed of the executable (1, 2, 3, 4). This is especially true when the language or type system has rich features.
      The goal of this project is to improve a compiler's error messages. Here are some distinct challenges:
      Some type errors can be more concisely or clearly expressed than the standard "found type A, expected type B" message.
      Some types are complex. The error message could explain them, or link to the manual, or give suggested fixes.
      Compiler messages currently show the effective type, which may be different than what the user wrote due to defaulting, inference, and syntactic sugar. For example, a user-written @IndexFor("a") annotation is syntactic sugar for @NonNegative @LTLengthOf("a"), and those types are the ones that currently appear in error messages. It might be good to show simpler types or ones that the user wrote.
      Some checkers combine multiple cooperating type systems; the Nullness Checker and the Index Checker are examples. If there is a problem with a variable's lower bound type, then its upper bound type should not be shown in the error message. This will make the message shorter and more specific, and avoid distracting the user with irrelevant information.
      When a checker has multiple type systems, a type error or the lack of one may depend on facts from multiple type systems, and this should be expressed to the user.
      Replace JavaParser by javac
      The Checker Framework uses JavaParser to parse a Java expressions. However, JavaParser is buggy and poorly maintained. The goal of this project is to replace every use of JavaParser by a use of javac-parse.
      Java expression parser
      A number of type annotations take, as an argument, a Java expression. The representation for these is as a JavaExpression. The goal of this project is to remove it.
      The JavaExpression class represents an AST. There is no need for the Checker Framework to define its own AST when the javac AST already exists and is maintained.
      The goals for the project include:
      Replace every use of JavaExpression by a use of the javac class class com.sun.tools.javac.tree.JCTree.JCExpression.html.
      Replace every use of a subclass of JavaExpression (listed in the "Direct Known Subclasses" section of the JavaExpression API documentation) by a use of a subclass of JCTree.JCExpression.html. For example, replace every use of MethodCall by JCTree.JCMethodInvocation.
      Replace the JavaExpressionParseUtil class and delete ExpressionToReceiverVisitor.
      Direct replacement of the classes is not possible, or we would have done it already. For example, JavaExpression contains some methods that javac lacks, such as isUnassignableByOtherCode. As a first step before doing the tasks listed above, you may want to convert these methods from instance methods of JavaExpression into static methods in JavaExpressions, making JavaExpression more like a standard AST that can be replaced by JavaParser classes. You also need to decide how to store the type field of JavaExpression, when JavaExpression is eliminated. An alternate design (or a partial step in the refactoring process) would be to retain the JavaExpression class, but make it a thin wrapper around javac classes that do most of the real work.
      Another aspect of this project is fixing the issues that are labeled "JavaExpression".
      Dataflow enhancements
      The Checker Framework's dataflow framework (manual here) implements flow-sensitive type refinement (local type inference) and other features. It is used in the Checker Framework and also in Error Prone, NullAway, and elsewhere.
      There are a number of open issues — both bugs and feature requests — related to the dataflow framework. The goal of this project is to address as many of those issues as possible, which will directly improve all the tools that use it.
      Side effect analysis, also known as purity analysis
      A side effect analysis reports what side effects a procedure may perform, such as what variable values it may modify. A side effect analysis is essential to other program analyses. A program analysis technique makes estimates about the current values of expressions. When a method call occurs, the analysis has to throw away most of its estimates, because the method call might change any variable. However, if the method is known to have no side effects, then the analysis doesn't need to throw away its estimates, and the analysis is more precise. Thus, an improvement to the foundational side effect analysis can improve many other program analyses.
      The goal of this project is to evaluate existing side effect analysis algorithms and implementations, in order to determine what is most effective and to improve them. The research questions include:
      What side effect analysis algorithms are most effective? What are their limitations?
      Can the most effective algorithms be combined to become even effective? Or can their limitations be overcome?
      How much does accurate side effect analysis improve other programming tasks?
      The methodology is to collect existing side effect analysis tools (two examples are Soot and Geffken); run them on open-source projects; examine the result; and then improve them.
      Javadoc support
      Currently, type annotations are only displayed in Javadoc if they are explicitly written by the programmer. However, the Checker Framework provides flexible defaulting mechanisms, reducing the annotation overhead. This project will integrate the Checker Framework defaulting phase with Javadoc, showing the signatures after applying defaulting rules.
      There are other type-annotation-related improvements to Javadoc that can be explored, e.g. using JavaScript to show or hide only the type annotations currently of interest.
      
      

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/checker-framework/
    idea_list_url: https://rawgit.com/typetools/checker-framework/master/docs/developer/new-contributor-projects.html

  - organization_id: 24
    organization_name: Chromium
    no_of_ideas: 14
    ideas_content: |
      1. Interaction to Next Paint (INP) "subparts" (Medium Size)




      Project Description
      The web performance specifications define how browsers are supposed to be behaving when it comes to the various web performance APIs, and the Core Web Vitals (CWV) program uses those apis to automatically measure the performance and UX of most websites in the world, and shares the data publicly via the Chrome User Experience Report (CrUX). Last year a new metric, Interaction to Next Paint (INP), was added to the CWV. This year, we would like your help to give developers additional insights into INP latency issues by also reporting INP "subparts", similar to what we did for LCP last year.  For example: a developer should know if any INP responsiveness issues are caused by: long input delay (maybe the page as blocked and busy)
      event processing times (maybe the interaction event listeners were too complex) rendering/pixel presentation delays (maybe the page content is too complex/bloated) …or other task scheduling issues. We’ve recently instrumented the measurement code (i.e. the Event Timing API) to measure these time points, but we need your help to finish the job: moving the data from Renderer code to Browser code (using Mojo IPC), adding it to field metrics reporting (UKM), and eventually helping teammates integrate into CrUX experimental data – while also writing tests for the above. This is an open source project and some of the contributions will be useful to developers for local lab testing, as well (as for other downstream browsers). Finally, there are also several stretch technical opportunities related to the Event Timing API / INP metric.
      Proposal Doc for more information: Link
      Location to ask project specific questions not answered above: here (preferred), or chromium-gsoc-project1@chromium.org
      Beginner Bugs: https://issues.chromium.org/issues/40858679 
      Requirements: C++, JavaScript, Performance tooling (DevTools performance panel). Time zone flexible but hosts are in Eastern time zone.

      ~~~~~~~~~~


      2. Android Virtual Printer Application (Large Size)


      Project Description
      An Android application which can pretend to be a printer (act as a virtual printer), which can handle interactions between Android devices, software and printer itself. Once this virtual printer Android application is installed, the Android device can detect a new printer, set up the printer via network connection, users can use it to print and change settings based on its capability, and the virtual printer can respond to print jobs. This virtual printer application should allow configuration on printer capabilities, and print job response, in this way it can be used to test different functionalities and validate handling errors.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project2@chromium.org
      Requirements: Android application development, Kotlin, Rust, Java, C++, C

      ~~~~~~~~~~

      3. Chrome Extension APIs (Large Size)

      Project Description
      We have a number of new APIs and features that we would like to add to the Chrome extensions platform but don't currently have prioritized (for example, improvements to the declarative network request API used for network filtering, and new features in the `chrome.sidePanel` API). Many of these involve work in the W3C WebExtensions Community Group. We would like to offer a contributor the opportunity to own a work item from this list.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here  (preferred), chromium-gsoc-project3@chromium.org
      Beginner Bugs: 
      Requirements: C++ for the Chromium codebase.  JavaScript needed for writing extensions.


      ~~~~~~~~~~


      4. Structured DNS Errors (Small Size)

      Project Description
      Chrome should implement enough of the emerging Public DNS Errors standards to allow public DNS servers to indicate to clients when certain DNS resolutions are blocked for legal reasons.
      https://github.com/mnot/public-resolver-errors
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project4@chromium.org
      Beginner Bugs: https://issues.chromium.org/hotlists/6689006
      Requirements: C++, Chromium Net Stack. Must overlap with US East Coast timezone.

      ~~~~~~~~~~


      5. FedCM API Test Coverage and Flakiness (Medium Size)

      Project Description
      The FedCM API comprises of multiple tests which require the bot to go through a federated authentication process. The project consists of documenting the existing test coverage, improving it, and fixing test flakiness.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project5@chromium.org
      Beginner Bugs: https://issues.chromium.org/issues/41482163
      Requirements: C++, as well as a little bit of HTML, JS, Python. US East is preferred but not required


      ~~~~~~~~~~


      6. Add 3rd Party Theme Support for Tab Groups (Small Size)

      Project Description
      Add an API to allow 3rd party theme developers to customize the colors used for tab groups.

      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project6@chromium.org
      Beginner Bugs: https://issues.chromium.org/issues/40711397, https://issues.chromium.org/issues/370416945 https://issues.chromium.org/issues/40929354
      Requirements: C++ prior experience is requested, ability to work in PST is requested.

      ~~~~~~~~~~

      7. ChromeOS Platform Input Device Quality Monitoring (Medium Size)

      Project Description
      ChromeOS devices generally contain user-input devices (touchscreens, touchpads, etc.) that contain firmware and communicate over internal buses. This firmware can have bugs, sometimes needs to be updated in the field, and the communication buses can show errors.

      Improved testing during development, and logging for production devices, can reduce shipped issues and reduction of in-field failures, and improved analysis leading to better OEM response to such issues.

      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project7@chromium.org
      Beginner Bugs: https://issuetracker.google.com/397520373, https://issuetracker.google.com/397521060, https://issuetracker.google.com/397520674
      Requirements: ChromeOS development tech stack (C++, shell scripts), experience or patience to learn ChromeOS build system and loading custom software onto a ChromeBook, moderate overlap with US-Pacific timezone.


      ~~~~~~~~~~


      8. Farfetchd: tracing/replay (Medium Size)

      Project Description
      Preloading files into memory (or prefetch) is a useful mechanism for improving application “cold start” performance. On ChromiumOS, this technique is used via ureadahead to speed up boot times by up to 20%. Farfetchd is a general purpose D-Bus service that allows prefetch of application binaries and associated resources and allows the optimization of cold start times.
      This proposal aims to add support to farfetchd for:
      1) Tracing: via tracefs, tracing file pages that are fetched for an application during a given workload and standardized tracepoints.
      2) Replay: Using the collected trace, preload the specific pages from disk and measure improvements in application performance.

      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project8@chromium.org
      Beginner Bugs: https://issuetracker.google.com/issues/397539111, https://issuetracker.google.com/issues/397539767
      Requirements: C++, linux kernel, tracing, no TZ requirements

      ~~~~~~~~~~


      9. Develop fwupd plugin to handle touch firmware updates (Large Size)

      Project Description
      A number of components like storage devices use fwupd to handle firmware updates in ChromeOS. The platform inputs team would like to start using fwupd to manage and handle firmware updates for touch controllers. This project aims to build out a handful of fwupd plugins for touch controllers.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project9@chromium.org
      Beginner Bugs: https://issuetracker.google.com/issues/172340186, https://issuetracker.google.com/issues/397567795
      Requirements: C, C++

      ~~~~~~~~~~


      10. Debug WebUI For Tabstrip states (Medium Size)

      Project Description
      Tabstrip state and session states for browsers are complicated and rely on correct ordering of tabs in the tabstrip model, groups and sessions to restore tabs in the right position and selection state. As a result this has resulted in numerous bugs and it is often a pain point to figure out if it is a tabstrip model issue or a client issue. A webUI that captures the live state of the backend of the browser and tabstrip models will be really helpful in finding issues and edge cases.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project10@chromium.org
      Beginner Bugs: WebUI TabStrip Bug, Print Preview + Tab Dragging Bug, Keyboard Shortcut Bug
      Requirements: Familiarity with HTML, CSS and JS, Proficiency in C++ codebases and concepts, Working from PST 9:00 AM - 5:00 PM hours

      ~~~~~~~~~~

      11. Improve Chromium Web Audio Testing (Medium Size)

      Project Description
      The audit.js WebAudio test helper library was introduced in 2016 and is currently used by over 300 test files in Chromium’s blink/web_test directory. This library was initially created to run tests sequentially with callback/promise support and to provide utility functions for audio-specific assertions. However, the W3C Test Harness (testharness.js) offers superior support for test runners and assertions, rendering many features in audit.js redundant. Removing audit.js from Chromium would reduce resource consumption in the Chrome team’s Continuous Integration Infrastructure and allow us to leverage the well-supported and well-maintained W3C Test Harness library.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project11@chromium.org
      Beginner Bugs: crbug.com/396477778
      Requirements: Proficiency in JavaScript (reading, writing, debugging), Familiarity with HTML and CSS

      ~~~~~~~~~~
      12. ChromeStatus Search UI Enhancement Project (Medium Size)

      Project Description
      Enhance the search functionality on chromestatus.com and webstatus.dev with several new auto-complete details.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project12@chromium.org
      Beginner Bugs: https://github.com/GoogleChrome/chromium-dashboard/issues?q=is%3Aissue%20state%3Aopen%20label%3Agoodfirstbug
      Requirements: HTML, CSS, TypeScript, Python, Go, Web components, UX / Usability

      ~~~~~~~~~~


      13. Enhancing the webstatus.dev User Experience (Medium Size)


      Project Description
      webstatus.dev is a valuable resource for web developers, providing up-to-date information on the browser compatibility of various web technologies. This project aims to enhance the user experience of webstatus.dev by making it more accessible and user-friendly across a wider range of devices and user preferences, with a particular focus on mobile devices and dark mode support. The project will involve redesigning key pages (overview, feature detail, and stats) for optimal mobile viewing, implementing a comprehensive dark theme, and ensuring compatibility with the Lit framework, Google Charts, and Shoelace components.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project13@chromium.org
      Beginner Bugs: https://github.com/GoogleChrome/chromium-dashboard/issues?q=is%3Aissue%20state%3Aopen%20label%3Agoodfirstbug
      Requirements: Lit, TypeScript, HTML, CSS Google Charts, Shoelace Web Test Runner (for unit tests) Playwright (for E2E testing), Docker (for local environment provisioning)

      ~~~~~~~~~~


      14. WebGPU Texel Buffers (Medium Size)


      Project Description
      WebGPU is a new graphics API, shipped in Chromium in 2023, that brings modern GPU capabilities to the web. The goal of this project is to implement new functionality in Chromium to further advance the capabilities of WebGPU, allowing a broader range of applications to target the API. Specifically, the "texel buffers" feature has already been proposed at the W3C standards committee, and the next steps are to prototype the functionality so that we can get feedback from real users and push the standardization process forwards.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project14@chromium.org
      Beginner Bugs: crbug.com/42250870 and crbug.com/42250968
      Requirements: C++ proficiency, timezone compatible with North American mentors


          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/chromium/
    idea_list_url: https://docs.google.com/presentation/d/1ozDiULkf2Gi4HH1XA_Ad9O7rQpP9SP0yPEs_dpcBZKM/edit?usp=sharing

  - organization_id: 25
    organization_name: CircuitVerse.org
    no_of_ideas: 7
    ideas_content: |
      
      Project 1: Circuit Management & Performance Enhancement
      Duration: 175 hours
      Difficulty: Medium
      Technologies: Ruby on Rails, JavaScript
      This project focuses on refining the organizational structure and performance of the CircuitVerse platform. The objective is to enhance user efficiency by introducing a systematic approach to circuit management and optimizing backend operations. Participants will implement a folder-based system for subcircuits, enabling users to categorize their work effectively. Additionally, the project includes developing a feature for circuits with group-specific visibility, ensuring accessibility within designated teams while maintaining privacy. Performance improvements will involve optimizing Ruby on Rails N+1 queries. The scope also extends to creating a comprehensive circuits explore page with search functionality, integrating a leaderboard for weekly contests, and enabling locale switching from the homepage to improve accessibility.
      Learning Path:
      Acquire proficiency in Ruby on Rails through The Odin Project’s Full-Stack Ruby on Rails Course, covering foundational and advanced concepts.
      Enhance Rails expertise with Pragmatic Studio’s Rails Course for structured, practical training.
      Develop JavaScript skills using JavaScript.info to support frontend enhancements.
      Possible Mentors: Vaibhav Upreti, Smriti Garg

      ~~~~~~~~~~
      Project 2: Desktop Application & Vue Frontend Updates
      Duration: 175 hours
      Difficulty: Medium
      Technologies: VueJS, Ruby on Rails, TypeScript, JavaScript
      This project aims to extend CircuitVerse’s reach by improving our lightweight desktop application using Tauri, ensuring efficient performance across operating systems, and establishing an automated release pipeline for streamlined deployment. Participants will refactor web-based components into reusable, platform-agnostic units suitable for both web and desktop environments, optimizing resource usage for desktop contexts. A reliable update mechanism will be implemented to deliver future improvements seamlessly. The project also entails modernizing the frontend by converting the JavaScript codebase to TypeScript, replacing jQuery with Vue’s reactivity system, and addressing issues in the Verilog module and layout rendering. Enhancements to the TestBench will improve usability and output compatibility, supported by thorough testing with Vitest. Synchronization with the main CircuitVerse repository will ensure consistency across platforms.
      Learning Path:
      Gain expertise in VueJS via the Vue.js Official Guide for reactive frontend development.
      Study TypeScript fundamentals at TypeScript Documentation to facilitate codebase migration.
      Learn Tauri application development through its Official Docs.
      Prepare for testing with Vitest Documentation covering unit, integration, and end-to-end tests.
      Possible Mentors: Vedant Jain, Aryann Dwivedi, Niladri Adhikary

      ~~~~~~~~~~
      Project 3: Migrate to View Components & Improve Search Experience
      Duration: 175 hours
      Difficulty: Easy
      Technologies: HTML, CSS, JavaScript, Figma, Ruby on Rails
      This project focuses on modernizing CircuitVerse’s technical foundation and enhancing the user experience. Participants will migrate UI elements to ViewComponents for better maintainability and scalability. Responsive design principles will be applied to ensure compatibility across devices. Candidates will also utilize Figma to design and implement UI improvements while refactoring CSS to reduce redundancy and effectively use grid and flexbox with Bootstrap utility classes.
      Additionally, the project includes an initiative to improve the search experience within CircuitVerse. This will involve analyzing existing search functionality, optimizing query performance, and enhancing the UI/UX to make search results more intuitive and accessible.
      Learning Path:
      Build foundational skills in HTML, CSS, and JavaScript with FreeCodeCamp’s Responsive Web Design.
      Learn UI/UX design with Figma through Figma’s Official Tutorials.
      Study Rails ViewComponents at ViewComponent Docs and Hotwire via Hotwire Docs.
      Possible Mentors: Aman Asrani, Siddhant-K-code

      ~~~~~~~~~~
      Project 4: Assignment Suite Enhancement
      Duration: 175 hours
      Difficulty: Easy
      Technologies: Ruby on Rails, JavaScript
      This project seeks to advance CircuitVerse’s educational tools by enhancing classroom and assignment management capabilities. The scope includes developing a multi-level classroom structure, allowing students to form subgroups for collaborative projects, and creating a flexible assignment management system for both individual and group submissions. Participants will introduce features such as pre-built circuit submissions with integrated test cases, incorporate auto-verification from practice sessions, and refine the assignment submission process for efficiency. Integration with Canvas LMS will be improved to strengthen CircuitVerse’s utility in academic settings, supporting educators and students with robust, user-friendly tools.
      Learning Path:
      Develop Rails proficiency with The Odin Project’s Ruby on Rails Course.
      Enhance JavaScript knowledge at MDN Web Docs for dynamic functionality.
      Review Canvas LMS integration through its Developer Docs.
      Learning tools interoperability (LTI)[https://en.wikipedia.org/wiki/Learning_Tools_Interoperability]
      Possible Mentors: Aman Asrani, Siddharth Asthana, Yashika Jotwani

      ~~~~~~~~~~
      Project 5: Enhanced Verilog Support & Stability
      Duration: 175 hours
      Difficulty: Hard
      Technologies: JavaScript, Canvas
      This project targets the enhancement of CircuitVerse’s Verilog module and overall simulator stability. The goal is to refine the Verilog interface, making it more intuitive and enabling users to generate, view, edit, and test circuits comprehensively. Detailed documentation will accompany these improvements to assist users. Additional enhancements include adding play/pause functionality to simulations, implementing a full-screen view for the Boolean Logic Table This project requires a strong focus on technical precision to strengthen a critical component of the platform.
      Learning Path:
      Master JavaScript for simulation logic with Eloquent JavaScript.
      Learn Canvas rendering techniques at MDN Canvas Tutorial.
      Possible Mentors: Vedant Jain, Niladri Adhikary, Josh Varga

      ~~~~~~~~~~
      Project 6: Open Hardware Component Library
      Duration: 90 hours
      Difficulty: Hard
      Technologies: JavaScript, Ruby on Rails
      This project aims to expand CircuitVerse’s digital component library and introduce hardware integration capabilities. Participants will enrich the platform by adding components such as shift registers, sensors, and counters, broadening its appeal to hardware-focused users. The initiative also involves enabling serial device connectivity to facilitate interaction with physical hardware. Though shorter in duration, this project demands a high level of technical skill and innovation to advance CircuitVerse’s utility in hardware education.
      Learning Path:
      Strengthen Rails knowledge with Rails Guides.
      Study hardware integration concepts via Arduino Tutorials.
      Deepen JavaScript proficiency at You Don’t Know JS.
      Possible Mentors: Smriti Garg
      ~~~~~~~~~~
      Project 7: Flutter Upgrade
      Duration: 90 hours
      Difficulty: Easy
      Technologies: Dart, JavaScript
      This project focuses on updating the CircuitVerse mobile application to ensure compatibility with the latest Flutter framework. Participants will upgrade the app to the current Flutter version, optimizing its performance, and implement circuit embedding functionality to enhance mobile usability. This concise project offers an opportunity to contribute to the platform’s mobile presence with a focus on modern development practices.
      Learning Path:
      Learn Flutter development at Flutter Official Docs.
      Study Dart essentials with the Dart Language Tour.
      Review JavaScript fundamentals at MDN JavaScript Guide.
      

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/circuitverse.org/
    idea_list_url: https://github.com/CircuitVerse/CircuitVerse/wiki/GSoC'25-Project-List


  - organization_id: 26
    organization_name: CloudCV
    no_of_ideas: 3
    ideas_content: |
     
      
      Enhanced Test Suite and Improved User Experience
      SQL Django AngularJS AWS
      This project is focused on significantly improving EvalAI’s usability by enhancing exsiting comprehensive test suite alongside a series of user experience enhancements. By increasing our test coverage, automating critical workflows, and refining the platform’s interface and documentation, this initiative aims to create a more robust, user-friendly, and resilient environment for both challenge hosts and participants.
      The enhanced test suite will ensure that all core functionalities, from challenge creation to submission processing are verified, reducing bugs and increasing system reliability. In parallel, targeted user experience improvements will simplify navigation, enhance error reporting, and streamline user interactions, leading to a more intuitive and supportive EvalAI ecosystem.
      Project Size: Medium (175 hours)
      Difficulty Rating: Medium
      Participate in the issue corresponding to this project to get started
      Enhanced Test Suite and Improved User Experience together with gautamjajoo Yes, let's do it

      ~~~~~~~~~~
      Mitigating Biases & Prompt Effects in Vision-Language Models
      Python PyTorch/TensorFlow NLP Vision-Language Models LLMs Bias and Fairness in AI
      This research project aims to investigate how prompt engineering influences the behaviour and outputs of Vision-Language Models (VLLMs), with a particular focus on the emergence and amplification of biases. By systematically studying the relationship between prompt formulations and model responses, the project seeks to uncover the mechanisms through which biases are introduced and propose effective mitigation strategies.
      Project Size: Medium (175 hours)
      Difficulty Rating: Medium to Advanced
      Sorry but currently we don't have any mentoring project ...

      ~~~~~~~~~~
      RAG-Based Chat Bot for Enhanced Challenge Support
      Python Natural Language Processing (NLP) Machine Learning Retrieval Augmented Generation (RAG) Django SQL
      This project aims to enhance the user experience for both challenge hosts and participants by developing an intelligent, RAG (Retrieval Augmented Generation) based chatbot. The chatbot will efficiently address queries related to challenge hosting, guidelines, troubleshooting, and FAQs. By integrating state-of-the-art NLP techniques with robust retrieval mechanisms, the solution will ensure prompt, accurate, and context-aware responses that reduce support overhead and streamline communication.
      Using the RAG approach, the chatbot will retrieve relevant information from challenge documentation and combine it with generative models to create coherent and helpful answers. This will empower hosts to manage challenges more effectively and assist participants in resolving queries, ultimately contributing to a smoother and more interactive challenge experience.
      Project Size: Medium (175 hours)
      Difficulty Rating: Medium
      Participate in the issue corresponding to this project to get started
      RAG-Based Chat Bot for Enhanced Challenge Support together with gautamjajoo Yes, let's do it
      

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/cloudcv/
    idea_list_url: https://gsoc.cloudcv.org/


  - organization_id: 27
    organization_name: D Language Foundation
    no_of_ideas: 4
    ideas_content: |
      Translate DRuntime Hooks to Templates
      Mentor: Teodor Duțu

      Spec	Details
      Difficulty Level	hard
      Project Duration	350 hours
      Number of Contributors	2
      Prerequisites	Familiarity with compilers, build systems; low-level programming
      Description
      High-level language constructs are often compiled into lower-level function calls that implement the same functionality. This process is called lowering It simplifies compiler design by offloading complex code into simpler function calls. These functions are implemented in D’s runtime library (called DRuntime) and are commonly called runtime hooks.

      Below is an example of such a runtime hook:

      struct S { ... }

      S[3] a, b;

      // Original code
      b = a;  // b is a copy of a 

      // Resulting DRuntime hook
      _d_arrayassign_l(b, a)  // copies a into b

      _d_arrayassign_l handles array (re)allocation and assignment operators according to the types of a and b (S[3]) to simplify the compiler’s work.

      As shown in the example above, runtime hooks require type information, such as which assignment operator to call and the arrays’ sizes. D supports templates, but runtime hooks pre-date the introduction of templates to D. Therefore, they retrieve the necessary type information at runtime by receiving an extra argument, whose type is TypeInfo. This object contains the size, constructors, destructors and overloaded operators of a given type. However, because this information is processed at run time, this approach is slower than the alternative of having the compiler send it to the runtime hook via template arguments. Due to D’s high flexibility regarding metaprogramming, translating each hook to a template function would allow its code to specialise according to the types of its arguments at compile time.

      In general, these are the steps required to convert a runtime hook to a template:

      Implement a new template version of the hook in DRuntime.
      Change the lowering in the compiler to use the new hook.
      Run a benchmark to measure the increase in performance generated by using the new hook.
      Remove the old hook from DRuntime.
      The hooks that are yet to be templated can be split into 2 categories:

      rt/aa.d implements associative arrays as language builtins. This module is made up of multiple hooks, all of them using TypeInfo. Therefore, this module is to be reimplemented using templates. Associative arrays are defined as an opaque structure called Impl. It receives a TypeInfo argument in its constructor. This structure is accessed via the runtime hooks listed below. The plan for this direction is the following:
      Template the hooks below and temporarily extract the TypeInfo structure required by Impl from the template arguments using typeid. Each hook will require changes to DRuntime and the compiler.
      Template the Impl structure and modify the previously templated hooks to use the template arguments itself instead of TypeInfo.
      The list of hooks for associative arrays is:

      _aaApply
      _aaApply2
      _aaDelX
      _aaEqual
      _aaGetRvalueX
      _aaGetX
      _aaInX
      _aaLen
      _d_assocarrayliteralTX

      Somewhat more independent hooks, which still have interdependencies. They are mostly implemented in rt/lifetime.d. A goal of this project is to remove this file and replace all its code with templated implementations. Each hook can be handled individually and separately. There was previous work on _d_arrayliteralTX so it might be a good starting point. Another promising starting point are _d_arrayset{capacity,lengthT,lengthiT} or _d_arrayappendcTX. The latter three already have wrapper template hooks that call the functions from rt/lifetime.d. What is needed in their case is to fully move the underlying implementation to the template hooks. The full list of hooks is below:

      _d_arraysetcapacity
      _d_arraysetlengthiT
      _d_arraysetlengthT
      _d_arrayshrinkfit
      _d_arrayappendcTX
      _d_arrayliteralTX
      _d_interface_cast
      _d_isbaseof
      _d_isbaseof2
      _adEq2

      Resources
      Initial project proposal and discussion
      PRs converting some of the DRuntime hooks to templates
      Weekly reports regarding the earlier work
      DConf presentations from 2022 and 2024 on the work on DRuntime hooks
      Instructions on how to build the reference compiler - DMD

      ~~~~~~~~~~

      Separate Semantic Routines From AST Nodes
      Mentor: Razvan Nitu

      Spec	Details
      Difficulty Level	easy-medium
      Project Duration	175 hours
      Number of Contributors	1
      Prerequisites	Familiarity with compiler organization, visitor pattern, object oriented programming
      Description
      In the DMD compiler codebase, AST nodes are defined as classes within various files. The ideal structure for these nodes is to have minimal fields and methods focused solely on field queries. However, the current state of the DMD frontend deviates from this ideal. AST nodes are laden with numerous methods that either perform or are dependent on semantic analysis. Furthermore, many AST node files contain free functions related to semantic analysis. Our objective is to decouple AST nodes from these functions.

      How to start working on this project
      Clone the compile repository - check this guideline.
      Choose an AST node file: start by selecting a file from this list of AST node definition files.
      Examine Imports: open your chosen file and scrutinize the top-level imports.
      Isolate semantic imports: temporarily comment out one of the imports that includes semantic routines, particularly those ending in sem (e.g., dsymbolsem, expressionsem, etc.).
      Build and identify dependencies: compile DMD and observe any unresolved symbols that emerge.
      Relocate functions: shift the functions reliant on the unresolved symbols to the semantic file where the import was commented out.
      Move and test a function: select a function for relocation and ensure it functions correctly in its new location.
      Submit a Pull Request: Once you’re satisfied with the changes, create a PR that follows the guidelines.
      Check this PR for an illustration of the above steps.

      Sometimes, more intricate solutions are required. For instance, if an overridden method in an AST node calls a semantic function, it can’t be simply relocated. In these cases, using a visitor to collate all overrides, along with the original method, into the appropriate semantic file is the way forward. A notable instance of this approach is detailed in this pull request.

      Other complex scenarios may arise, especially when dealing with AST nodes that interact with the backend. Finding solutions to those will be the fun part of the project.

      This project helps advance the development of the compiler library by creating a clear separation between compilation phases.

      This project is ideal for someone that has no prior experience with real-life compilers but wants to start by doing valuable work.

      Resources
      Compiler codebase
      List of files that need to have semantic separated out of them
      How to start
      Building the compiler

      ~~~~~~~~~~

      Performance Regression Publisher
      Mentor: Dennis Korpel

      Spec	Details
      Difficulty Level	easy-medium
      Project Duration	175 hours
      Number of Contributors	1
      Prerequisites	Github actions, webdev, performance testing
      Description
      The D compiler currently does not have an automated performance regression test. Oftentimes pull requests that claim to improve compiler performance are being made (be it spatial or temporal). However, it’s up to the reviewer to actually believe the committer or to test things on their own. To make things simpler and more transparent, we want to implement a bot that monitors all the pull requests made to the compiler codebase and analyzes the compiler’s performance with and without the pull request.

      The list of stats should include, but not be limited to:

      size of some predefined binaries (like a “hello world” program)
      compile time of popular projects
      compiler size
      runtime of test suite
      Adding more performance tests, such as stress tests also falls under the scope of this project. Ideally the bot could also store a history of performance regressions within a web page.

      Project milestones:
      Analyze the best way to publish the results: it could be a GitHub action, a bot that sends data to a website. Depending on your skills and preferences, we expect you propose something and toghether we will decide what’s best.
      Implement the initial part that simply collects how long running the testing pipeline took and publishes the result.
      Decide on other metrics that need to be collected and implement them.
      Add more stress tests to the compiler testing suite.
      Resources
      Compiler pull request queue

      ~~~~~~~~~~
      Json Library
      Mentor: Adam Wilson

      Spec	Details
      Difficulty Level	medium
      Project Duration	175 hours
      Number of Contributors	1
      Prerequisites	json, parsers, object oriented programming
      Description
      D currently does not have a json parser integrated in the standard library and it is the year 2025. There are 3rd party libraries that implement some pieces to a certain extent, however they are not at industry level requirements. The purpose of this project is to create a json library that offers all the facilities required for working with json objects. The goal is to eventually integrate it in the standard library, however, an initial step is to publish as a dub (D package manager) package.

      Although there is no json library in the D ecosystem, there are multiple json parser implementations. We can start by picking up a notable json parser as a basis for our implementation. Next, we can built higher level functionalities on top of the existing parser.

      This project is of high priority and impact, as json objects essentially rule the world.

      Project Milestones
      Initial Package Setup and Porting from jsoniopipe.
      Object Model Design/Implementation.
      Object Model Serialization/Deserialization
      Streaming Serialization/Deserialization
      Stretch Goal: Object Serialization/Deserialization (Direct serialization/deserialization from a D object instead of using the object model.)
      Resources
      jsoniopipe

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/d-language-foundation/
    idea_list_url: https://dlang.github.io/GSoC/gsoc-2025/project-ideas.html


  - organization_id: 28
    organization_name: DBpedia
    no_of_ideas: 5
    ideas_content: |
      Towards Amharic DBpedia
      Description
      DBpedia is a collaborative initiative focused on extracting structured information from Wikipedia and presenting it as Linked Open Data. This is a continuation of GSoC 2024. In GSoC 2024, we successfully integrated Amharic parsers and extractors into the DBpedia chapter. However, due to time constraints, we could not add sufficient mappings to extract data from Wikipedia. This year, we plan to add more new mappings, build a robust landing page for presentation, and clean the existing data.

      Goal
      The primary goal of this project is to enhance the Amharic DBpedia chapter 3:

      Extend the existing Amharic DBpedia chapter in the DBpedia knowledge graph with data from Amharic Wikipedia.
      Add additional mappings.
      Extend the DBpedia extraction framework to extract citations, disambiguation, personal data, topical concepts, anchor text, and shared resources from Amharic Wikipedia.
      Create an automatic extraction framework and mapping.
      Make the knowledge graph available to end users via a web page.
      Create documentation for processes, tools, and techniques used for sustainable development, following FAIR principles.
      Impact
      Enable users to access and utilize structured data in Amharic DBpedia more effectively.
      This will promote linguistic diversity and support research, education, and applications that rely on multilingual knowledge graphs.
      NLP downstream tasks: Apply knowledge graphs from DBpedia to NLP applications such as machine translation and sentiment analysis.
      Community engagement: Encourage the community to contribute and collaborate in sustaining and expanding Amharic DBpedia.
      Warm-up tasks
      Please read the following papers:
      GitHub Repository 6

      Amharic Wikipedia 1
      Arabic DBpedia 1
      Korean DBpedia
      German DBpedia 1
      Skills Required
      A good understanding of Java and Python
      Optionally, good knowledge of SPARQL, RDF, and other Semantic Web technologies
      Good documentation and communication skills
      Project Size
      350 hours

      Mentors
      Hizkiel Alemayehu 3

      Tilahun Tafa 2

      Ricardo Usbeck 1

      Keywords
      Amharic DBpedia, Semantic Web, Extraction Framework

      ~~~~~~~~~~

      DBpedia Hindi Chapter - GSoC 2025

      DBpedia is an open knowledge graph in continuous evolution. Unlike Wikidata, where the RDF content is directly edited as a wiki, DBpedia relies strictly on Wikipedia, meaning that every single triple in DBpedia — except for ontology statements — can be traced back to some infobox, sentence or table cell in Wikipedia.

      The graph exposed at the root domain of DBpedia is derived solely from English Wikipedia (e.g. https://dbpedia.org/page/India 4). Purpose of this project is to create a graph derived solely from Hindi Wikipedia. Methods to generate triples rely on the Extraction Framework 15 6 for infobox extraction or through novel NLP-based approaches such as the Neural Extraction Framework 2. Unfortunately, the latter approach only supports the English language. We thus welcome NLP and/or LLM-based solutions to target multilingual text. We have proposed the first edition on DBpedia Hindi Chapter in 2024 GSoC proposal for Configuring different extractors for hindi in DBpedia extraction framework and included a neural pipeline for extracting tuples directly from hindi wiki. In this proposal we are extending the first edition of DBpedia Hindi Chapter with extended goals.

      Goal
      Extending the DBpedia Chapter in Hindi language to be reached at hi.dbpedia.org 4. In particular:

      Create the knowledge graph with data from Hindi Wikipedia 6by including more indic neural extractor. It aims for extracting information in the form of relational triples(subject → predicate → object) from unstructured text in hindi Wikipedia articles that can be added to the DBpedia knowledge base
      Automating the knowledge graph with the availability of new LLMs by creating Indic embeddings, so that missing links can be generated automatically.
      Create a SPARQL endpoint to make it queryable.
      Material
      See Warm-up tasks.

      Project size
      This project is medium-sized (175 hours).

      Impact
      Cultural and Educational Enrichment: Empower Hindi-speaking users with culturally relevant and easily accessible knowledge, fostering educational enrichment and linguistic inclusivity.
      Semantic Search and NLP Applications: Enable advanced semantic search and natural language processing (NLP) applications in Hindi, opening avenues for innovation in information retrieval and analysis.
      Community Engagement: Encourage community contributions, feedback, and collaboration in maintaining and expanding the Hindi ontology, ensuring continuous improvement and relevance.
      In summary, this project seeks to contribute significantly to linguistic diversity in the semantic web domain by extending the DBpedia ontology to Hindi, promoting a more inclusive and accessible knowledge landscape
      for Hindi-speaking users.

      Warm-up tasks
      Please read carefully our overview on creating new DBpedia Chapters 11.
      Read the paper Internationalization of Linked Data: The case of the Greek DBpedia edition 7 by Kontokostas et al.
      Learn about the DBpedia Extraction Framework 6, the software used to transform Wikipedia infobox data into RDF triples.
      Check the mapping in Hindi of the DBpedia ontology 8 and Indic embeddings.
      Go through the list of current chapters can be found at this address 7 to get an idea of how they are structured.
      Get familiar with SPARQL on the DBpedia endpoint 7.
      Run a local DBpedia Virtuoso endpoint 5.
      Mentors
      Sanju Tiwari (@tiwarisanju18), Debarghya Dutta, Ananya, Ronak Panchal


      ~~~~~~~~~~

      This project started in 2021 and is looking to its 5th participation in DBpedia’s GSoC.

      Description
      Every Wikipedia article links to a number of other articles. In DBpedia, we keep track of these links through the dbo:wikiPageWikiLink property. Thanks to them, we know that the :Berlin_Wall 3 entity (at the time of writing this) is semantically connected to 299 base entities.

      However, only 9 out of 299 base entities are linked from :Berlin_Wall via also another predicate. This suggests that in the large majority of cases, it is not clear what kind of relationship exists between the entities. In other words, DBpedia does not know what specific RDF predicate links the subject (in our case, :Berlin_Wall) to any of the objects above.

      Currently, such relationships are extracted from tables and the infobox (usually found top right of a Wikipedia article) via the Extraction Framework 4. Instead of extracting RDF triples from semi-structured data only, we want to leverage information found in the entirety of a Wikipedia article, including page text.

      wiki-meme
      wiki-meme
      500×683 108 KB
      The repository where all source code will be stored is the following:


      GitHub

      GitHub - dbpedia/neural-extraction-framework: Repository for the GSoC project... 32
      Repository for the GSoC project 'Towards a Neural Extraction Framework' - dbpedia/neural-extraction-framework

      Goal
      The goal of this project is to develop a framework for predicate resolution of wiki links among entities.

      During GSoC 2022, we employed a suite of machine-learning models 7 to perform joint entity-relation extraction on open-domain text.
      During GSoC 2023, we implemented an end-to-end system 4 that translates any English sentence into triples using the DBpedia vocabulary.
      Last year, we improved the quality of output triples using a chain-of-thought approach powered by a large language model.
      However, the current algorithm still has the following issues. Now, we want to devise a method that can solve as many of them as possible.

      When an RDF property representing the predicate is not found, our algorithm cannot make any suggestions for the creation of a new property.
      The current models are not efficient enough to scale to millions of entities.
      The extracted relations are not categorised with respect to their semantics (e.g. reflexive/irreflexive, symmetric/antisymmetric/asymmetric, transitive, equivalence).
      The generated triples were not validated against the DBpedia ontology and may thus lead to inconsistencies in data.
      Our algorithm should be able to adapt its output not only to the DBpedia vocabulary but to any specified one (e.g., SKOS, schema.org, Wikidata, RDFS, or even a combination of many).
      Extraction examples
      The current pipeline targets relationships that are explicitly mentioned in the text. The contributor may also choose to extract complex relationships, such as:

      Causality. (Addressed during GSoC 2021, but not completed.) The direct cause-effect between events, e.g., from the text
      The Peaceful Revolution (German: Friedliche Revolution) was the process of sociopolitical change that led to the opening of East Germany’s borders with the west, the end of the Socialist Unity Party of Germany (SED) in the German Democratic Republic (GDR or East Germany) and the transition to a parliamentary democracy, which enabled the reunification of Germany in October 1990.

      extract: :Peaceful_Revolution –––dbo:effect––> :German_reunification

      Issuance. An abstract entity assigned to some agent, e.g., from the text
      Messi won the award, his second consecutive Ballon d’Or victory.

      extract: :2010_FIFA_Ballon_d'Or –––dbo:recipient––> :Lionel_Messi 1

      Material
      The contributor may use any Python deep learning framework and/or existing tool. The following resources are recommended (but not compulsory) for use in the project.

      The project repository linked above and the machine-learning models mentioned in the readme files found in each GSoC folder.
      Last year’s 9 and the 2023 blog 4 to understand the project status quo.
      Python Wikipedia 1 makes it easy to access and parse data from Wikipedia.
      Huggingface Transformers for Natural Language Inference 1 can be extremely useful to extract structured knowledge from text or perform zero-shot classification.
      DBpedia Lookup is a service available both online and offline (e.g., given a string, list all entities that may refer to it).
      DBpedia Anchor text is a dataset containing the text and the URL of all links in Wikipedia; the indexed dataset will be available to the student (e.g., given an entity, list all strings that point to it).
      An example of an excellent proposal 11 that was accepted a few years ago.
      Project size
      The size of this project can be either medium or large. Please state in your proposal the number of total project hours you intend to dedicate to it (175 or 350).

      Impact
      This project will potentially generate millions of new statements. This new information could be released by DBpedia to the public as part of a new dataset. The creation of a neural extraction framework could introduce the use of robust parsers for a more accurate extraction of Wikipedia content.

      Warm-up tasks
      Get familiar with SPARQL on the DBpedia endpoint 8.
      Understand the science behind relation extraction 4.
      Run and understand the pipeline implemented last year 8.
      Mentors
      @tsoru, @zoelevert, TBD

      ~~~~~~~~~~

      Containerized Installers for Data-centric Services using Databus Collections
      Project Description:
      This GSoC project aims to develop containerized installers for data-centric services utilizing Databus collections. Databus collections provide a framework for managing and sharing datasets across distributed systems, offering versioning, replication, and access control features.

      One exemplary application of this project is integrating Databus collections with the Virtuoso Open-Source triple store, a widely used RDF service. This integration enables seamless deployment and loading of RDF datasets into Virtuoso instances within containerized environments.

      Additionally, the project entails both designing and documenting best practices for deploying other Databus-driven services, along with implementing more deployment-ready containers. These containers will encapsulate the necessary components for pulling data from Databus collections and installing them with associated services, ensuring ease of deployment and scalability.

      Furthermore, the project may explore integration options with the Databus frontend or even metadata, enhancing discoverability and interoperability of the deployed services within the Databus ecosystem.

      Key Objectives:
      Integrate Databus collections with the Virtuoso Open-Source Triple Store as a first use case. This can be done by building upon the Virtuoso Quickstarter repository (GitHub - dbpedia/virtuoso-sparql-endpoint-quickstart: creates a docker image with Virtuoso preloaded with the latest DBpedia dataset)

      Design and document best practices for deploying Databus-driven services.

      Implement 4-5 deployment-ready containers for data-centric services utilizing Databus collections. Services could, for instance, be chosen from a list of Semantic Web applications and services here: GitHub - semantalytics/awesome-semantic-web: A curated list of various semantic web and linked data resources.

      Explore integration possibilities with the Databus frontend or metadata systems for enhanced functionality and interoperability.

      Expected Outcome:
      A well-documented Databus-driven Virtuoso Quickstarter container that focuses on ease of deployment.

      Documentation outlining best practices and guidelines for implementing, deploying and managing Databus-driven services.

      4-5 Containerized installers for deploying data-centric services leveraging Databus collections.

      Design proposal for integration of these services with the Databus frontend.

      [Optional] integration with Databus frontend or even metadata for improved discoverability and usability.

      Skills Required:
      A good understanding of SPARQL, RDF and other Semantic Web technologies

      Some proficiency in containerization technologies (e.g., Docker, Kubernetes).

      Knowledge of the core concepts of the DBpedia Databus (see Overview | Databus Gitbook 4)

      Good documentation and communication skills

      Project Size:
      Estimated anywhere between 90 to 180 hours, depending on expertise and number of tackled tasks.

      ~~~~~~~~~~

      Automatically adding Wikimedia Dumps on the Databus — GSoC 2025


      Project Description:
      Wikimedia publishes their dumps via https://dumps.wikimedia.org 6 . At the moment, these dumps are described via HTML, so the HTML serves as the metadata and it is required to parse to identify whether new dumps are available. To automate retrieval of data, the Databus (and also MOSS as its extension Databus and MOSS – Search over a flexible, multi-domain, multi-repository metadata catalog 5 ) has a metadata knowledge graph, where one can do queries like “check whether a new version of x is available”. Since DBpedia uses the dumps to create knowledge graphs, it would be good to put the download links for the dumps and the metadata on the Databus.

      Key Objectives

      Build a docker image that we can run daily on our infrastructure to crawl dumps.wikimedia.org 3 and identify all new finished dumps, then add a new record on the Databus.
      Goal is to allow checking for new dumps via SPARQL. go to OIDC Form_Post Response 2 , then example queries, then “Latest version of artifact”.
      this would help us to 1. track new releases from wikimedia, so the core team and the community can more systematically convert them to RDF as well as to 2. build more solid applications on top, i.e. DIEF or other
      process wise I would think that having an early prototype is necessary and then plan iterations from this.
      Skills
      The task is not very complex per se, but requires some experience in executing a software project. This includes a clean project setup, good code, tests and also a simple, but well-thought out process. (simple because it will be more robust and maintainable than sth. complicated). We would prefer coding in scala, but python or other would also be ok. Some devOp skills are required to produce good docker (swarm), but they can be learned during the project as well.

      Size
      120 to 180 hours to do it properly. I would estimate that the final deployment also takes a week to make it effective and thoroughly evaluate that the final result is working well.









          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/dbpedia/
    idea_list_url: https://forum.dbpedia.org/tag/gsoc2025-ideas

  

  - organization_id: 29
    organization_name: Dart
    no_of_ideas: 5
    ideas_content: |
      
      Idea: Exception testing for package:webcrypto
      Possible Mentor(s): jonasfj@google.com,
      Difficulty: Hard
      Project size: Large (350 hours)
      Skills: Dart, FFI, JS
      Description: package:webcrypto (github.com/google/webcrypto.dart) is a cross-platform implementation of the Web Cryptography API. It is important that it behaves the same way whether it's running on Windows, Linux, Mac, Android, iOS, Chrome, Firefox, or Safari. Towards that end, it has a lot of test cases. We could and should probably make more test cases. But we should also test that it throws the types of exceptions when given incorrect parameters. This probably needs a small test framework to ensure good test coverage.
      We expect a proposal for this project to include:
      A sample showing how to test exceptions for RsaPssPrivateKey.generateKey. Ideally, the sample project includes parts of a generalized framework for testing exceptions.
      An outline of what kind of exceptions should be tested?
      A design for extending TestRunner, or creating a new framework, to test exceptions thrown by all methods.
      Illustrative code for how test cases would be configured
      Pros and cons of the design (especially when multiple choices are available)
      Timeline for the project
      Good Sample Project: Write a test cases that tests the different kinds of errors and exceptions that can be thrown by RsaPssPrivateKey.generateKey, run the tests across desktop, Chrome and Firefox. Consider extending the tests to cover all members of RsaPssPrivateKey. Try to generalize these test cases to avoid repetitive code, see the existing TestRunner for inspiration.
      Expected outcome: PRs that land in package:webcrypto and increases our confidence in correctness cross-platforms.
      
      
      ~~~~~~~~~~
      Idea: Use an LLM to translate Java/Kotlin tutorial snippets into Dart JNIgen code
      Possible Mentor(s): dacoharkes@google.com, yousefi@google.com
      Difficulty: Hard
      Project size: Large (350 hours)
      Skills: Dart, FFI, Java
      Description: This project will be very exploratory. We’ll explore how much is needed to make an LLM generate Dart snippets that call JNIgen-generated code. The snippets should be the equivalent of the original native code. How much will be needed? Is a single shot prompt enough? Or do we need to teach an AI how to run JNIgen and make it generate code that is subsequently analyzed with the Dart analyzer and the errors are fed back in to the AI to improve its answer.
      If we get this working, we’ll want to explore how to make such a tool useful to users. For example, we could make a browser extension that automatically adds the generated code snippets to documentation websites.
      Inspired by this issue: dart-lang/native#1240
      Good Sample Project:
      Get a Gemini API key https://ai.google.dev/gemini-api/docs/api-key
      Follow https://developers.google.com/learn/pathways/solution-ai-gemini-getting-started-dart-flutter
      Write a Dart script that invokes the API with a prompt containing a Java snippet (for example from https://developer.android.com/media/camera/camerax/take-photo#take_a_picture) and try to come up with a prompt that will make it generate code that would work on the Dart API generated with JNIgen for this Java/Kotlin API.
      Expected outcome: A tool for translating code samples usable by users.
      
      
      ~~~~~~~~~~
      Idea: package:coverage + LLM = test generation
      Possible Mentor(s): liama@google.com
      Difficulty: Medium
      Project size: Medium (175 hours)
      Skills: Dart, LLMs
      Description: This is a very experimental project. The idea is to use package:coverage to identify uncovered code, use an LLM to decide if that code needs a test (not all code actually needs to be tested), then use an LLM to write tests that hit those cases, and then use package:coverage to verify that those lines are covered.
      Good Sample Project:
      Get a Gemini API key https://ai.google.dev/gemini-api/docs/api-key
      Follow https://developers.google.com/learn/pathways/solution-ai-gemini-getting-started-dart-flutter
      Try generating tests for any old Dart API. Don't try to integrate package:coverage yet.
      Expected outcome: A package on pub.dev for increasing test coverage.
      
      
      ~~~~~~~~~~
      Idea: Secure Paste Custom Actions on iOS
      Possible Mentor(s): huanlin@google.com, jmccandless@google.com
      Difficulty: Hard
      Project size: Large (350 hours)
      Skills: Dart, Objective-C
      Description: Support custom action items for native edit menu on iOS. It's a pretty impactful project requested by many developers (main issue here: flutter/flutter#103163). This project is one of the key milestones: flutter/flutter#140184.
      Project:
      Prepare: Learn basic git commands; Setup flutter engine dev environment; Read style guide, etc;
      Design new dart API for custom items in context menu (Related API: https://api.flutter.dev/flutter/widgets/SystemContextMenu-class.html)
      Design engine <-> framework communication API using method channel
      Implement both framework part (in Dart) and engine part (in Objective-C)
      Go through code review process and land the solution
      The final product should allow developers to add custom items to the iOS native edit menu.
      Good Sample Project: ...
      Build a sample project in Flutter with a text field that shows custom actions in the context menu. (Hint: use https://docs.flutter.dev/release/breaking-changes/context-menus).
      Build a sample project in UIKit that shows custom actions in the native edit menu (Hint: use https://developer.apple.com/documentation/uikit/uieditmenuinteraction?language=objc). You can either use ObjC or Swift, but ObjC is preferred.
      Expected outcome: A PR merged in Flutter
      
      
      ~~~~~~~~~~
      Idea: TUI framework for dart
      Possible Mentor(s): mudit.somani00@gmail.com
      Difficulty: Medium
      Project size: Medium (175 hours)
      Skills: Dart, CLIs
      Description: Dart is already used to create GUI applications through Flutter, it would be great if it can also be used to develop good looking TUI applications. Currently the language of choice for TUI development would be either Golang or Python due to their developed package ecosystems (like charm or textual) so a package that makes TUI development easier and faster on dart would increase its adoption in that space.
      Project:
      Design composable methods to render components and text on the terminal
      Include popular components like inputs, checkboxes and tables by default
      Intuitive way to create your own custom components for the terminal
      Ensure library works with popular state management libraries in dart
      Good Sample Project:
      Composable methods to style text on the terminal (kinda like libgloss).
      Component based model to render and interact with terminal based text inputs and checkboxes (kinda like bubbles).
      Expected outcome: A package on pub.dev with terminal primitives like text styling, inputs, checkboxes, tables, layouts, spinners etc.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/dart/
    idea_list_url: https://github.com/dart-lang/sdk/blob/main/docs/gsoc/Dart-GSoC-2025-Project-Ideas.md


  - organization_id: 30
    organization_name: Data for the Common Good
    no_of_ideas: 9
    ideas_content: |
      
      Title Enhancing the SMART on FHIR Backend for Patient-Controlled Data Sharing
      Description The goal of this project is to improve and extend the backend of a SMART on FHIR application that empowers patients to autonomously access, share, and manage their electronic health records (EHR). The application serves as a data interoperability layer, allowing users to seamlessly transfer their healthcare data to meet various needs, such as research participation, second opinions, or personal health tracking.
      Expected Outcomes One or both of the following: Improving the integration with diverse FHIR servers and refining data transformation capabilities. Building APIs or plugins to support additional healthcare applications and third-party services.
      Skills Java, python
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating medium


      ~~~~~~~~~~
     
      Title Enhancing the SMART on FHIR Frontend for Patient-Controlled Data Sharing
      Description This project aims to improve the frontend user interface for a SMART on FHIR application that enables patients to autonomously access, manage, and share their electronic health records (EHR). The focus is on making the UI more intuitive, accessible, and user-friendly, ensuring a seamless experience for users connecting to the backend service.
      Expected Outcomes Improved User Experience (UX)
      Skills Javascript, Node
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating medium

      ~~~~~~~~~~
     
      Title Developing a FHIR Resource Tabular Viewer for Efficient Data Exploration
      Description This project aims to build a FHIR Resource Tabular Viewer, an application that transforms complex, nested FHIR data structures into an easy-to-navigate tabular format. This tool will allow users—such as researchers, clinicians, and developers—to efficiently search, filter, and analyze FHIR resources, improving accessibility and usability of healthcare data.
      Expected Outcomes Tabular Representation of FHIR Data and Search & Filtering Capabilities.
      Skills Python, Javascript
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating medium

      ~~~~~~~~~~
     
      Title Developing Custom Jupyter Notebooks for AVRO File Processing and QA/QC Analysis
      Description This project aims to create custom Jupyter notebooks that help users efficiently unpack AVRO files, perform quality assurance (QA) and quality control (QC) checks, and run basic data analyses. The goal is to provide a user-friendly, interactive environment where users can explore, validate, and analyze AVRO-formatted data without requiring deep expertise in data engineering.
      Expected Outcomes AVRO File Handling on startup, QA/QC Checks, Basic Data Analysis.
      Skills Python, networking
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating medium

      ~~~~~~~~~~
     
      Title Extending the HAPI FHIR Server for Enhanced Functionality and Interoperability
      Description This project aims to extend the HAPI FHIR Server, a leading open-source implementation of the FHIR standard, to improve its functionality, scalability, and interoperability. The enhancements will support advanced healthcare use cases, making it easier for developers and organizations to manage and exchange FHIR-compliant health data efficiently.
      Expected Outcomes Custom FHIR Operations & Extensions
      Skills Java, FHIR
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating medium

      ~~~~~~~~~~
     
      Title Developing a Translation Service to Connect GEARBOx API with mCODE Trial Matching Service
      Description This project aims to build a translation service that connects the GEARBOx API with the mCODE (Minimal Common Oncology Data Elements) trial matching service. The goal is to enable seamless translation of oncology data between GEARBOx and mCODE, allowing healthcare providers, researchers, and clinical trial platforms to effectively match patients to relevant clinical trials based on their mCODE-compliant health data.
      Expected Outcomes Data Mapping & Transformation, Interoperability & Validation
      Skills Python, Typescript
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating medium

      ~~~~~~~~~~
     
      Title Building a Chatbot for Generating GraphQL and Custom Queries for Cohort Descriptions
      Description This project aims to develop a chatbot powered by ChatGPT or another large language model (LLM) that allows users to describe a cohort of patients and automatically generates GraphQL queries or custom queries based on the input for the PCDC. The goal is to simplify the process of building complex queries for patient data by allowing users to interact with the chatbot in natural language, rather than navigating through a UI or manually searching for filters.
      Expected Outcomes GraphQL Query Generation
      Skills LLM, Javascript
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating hard

      ~~~~~~~~~~
     
      Title Developing a Cross-Platform App for User Consent and Data Sharing from Apple Health and CommonHealth Using React Native
      Description This project focuses on creating a cross-platform mobile app (iOS and Android) using React Native that allows users to consent and share their health data from both Apple Health and CommonHealth. The app will enable users to manage their data sharing preferences, securely transmit health information, and empower them to participate in research or share data with healthcare providers.
      Expected Outcomes Initial App version
      Skills React Native, Android, iOS
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating hard

      ~~~~~~~~~~
     
      Title Enhancing the Cohort Discovery Chatbot
      Description This project aims to enhance a cohort discovery chatbot by improving its accuracy, usability, and query generation capabilities. Enhancements will focus on refining natural language understanding (NLU), improving query accuracy, supporting more complex filters, and integrating feedback mechanisms to learn from user interactions.
      Expected Outcomes Improved chatbot accuracy in understanding and generating cohort queries
      Skills LLM, Javascript
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating hard
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/data-for-the-common-good/
    idea_list_url: https://docs.pedscommons.org/GSoC/ideas
  

  - organization_id: 31
    organization_name: Debian
    no_of_ideas: 11
    ideas_content: |
          Quality assurance and continuous integration for biological and medical applications inside Debian
          Description of the project: The Debian Med Blend has packaged a lot of applications used in medicine and biology for Debian. To enhance and continuously ensure the quality of the packaged software we try to implement Continuous Integration tests for all our packages. This was accomplished thanks to several past interns. These tests are of specific importance since only a very small share of the developers inside the Debian Med project are actual users of the software and thus automated testing is required to provide our users with the quality we like to approach. Interns are also not necessarily comfortable with the topic of medicine and biology - reading documentation or publications or directly contact the authors of the software frequently gives sensible ideas how to write a test for the software.
          Confirmed Mentor: Andreas Tille
          How to contact the mentor: tille@debian.org
          Confirmed co-mentors: Emmanuel Arias <eamanu@debian.org>, Étienne Mollier <emollier@debian.org>
          Difficulty level: medium
          Project size: Depending from students availability this project can be medium or large. The advantage of the project is it can be split into small pieces
          Deliverables of the project:Continuous integration tests for Debian Med applications lacking a test, Quality Assurance review and bug fixing if issues might be uncovered
          Desirable skills: Background in bioinformatics, medical imaging could be an advantage, but interest in scientific software and reading relevant documentation and papers might be sufficient. Debian packaging skills are an extra plus but can be taught in the project run.
          What the intern will learn: Detailed insight into the software maintained by the Debian Med team, bug triaging in scientific software, Debian packaging skills, optimising bioinformatics and other scientific tools
          Application tasks: Pick bugs like 1035121, 1035175, 1035178, 1035182, 1035188, 1035200, 1035277, 1036500, 1036506 and try fixing it - asking the mentor for help is perfectly fine and actually recommended. This is on one hand proof that the student is able to understand Debian packaging and understands the actual topic at a sufficient level.
          Related projects: SummerOfCode2016/Projects/BioToolsTesting, SummerOfCode2017/Projects/QA_BiologyApps, ?Continuous_Integration_for_biological_applications_inside_Debian, SummerOfCode2019/ApprovedProjects/CIforDebianMed SummerOfCode2020/ApprovedProjects/DebianMedQAGSoC and Outreachy Project Proposal: Quality Assurance and Continuous integration for applications in life sciences and medicine
          [SummerOfCode2025/ApprovedProjects/DebianMedQA][edit]

          ~~~~~~~~~~
          Device-specific Tweaks Management
          Description of the project: A significant number of non-x86 Linux-capable devices made it to the market in the past few years, especially ARM64 laptops, mobile phones and tablets. Most of those, inheriting their design from embedded systems (and therefore lacking support for software interfaces such as ACPI/UEFI), need device-specific "tweaks" (configuration files/fragments, shell scripts...). As the number of supported devices grows rapidly, providing device-specific Debian packages containing those tweaks doesn't scale, and limits our ability to provide a generic system image/rootfs.
          This project aims at researching and implementing a more flexible way of managing those tweaks, by creating a service capable of identifying the exact device it's running on, selecting the appropriate tweaks based on its configuration file, and installing them to the system. Reaching this goal will ultimately ease supporting new devices in Debian.
          Confirmed Mentor: Arnaud Ferraris (UTC+2)
          How to contact the mentor: Matrix (a-wai on mobian-dev:matrix.org or email (aferraris@debian.org)
          Difficulty level: Mostly medium, although difficulty level is expected to increase over the project's course
          Project size: The whole project is a large (350 hours) one, although its scope could be reduced to fit either a 90 hours or a 175 hours project.
          Deliverables of the project:
          Analysis and discussion of the current state of device tweaks management in Debian and Mobian
          Proposal for a unified, run-time approach
          Initial implementation of a "tweaks management" service
          Packaging of this service and tweaks data/configuration for at least one device
          Desirable skills:
          Familiarity with ARM64 devices (RPi 3+, Pine{Book,Phone,Tab} etc)
          Basic understanding of Linux systems (common services and middleware, user/admin/distro-specific configuration...)
          Shell scripting and basic programming skills
          (optional) basic Rust knowledge
          What the intern will learn: Through this project, the intern will improve their analysis and project management skils, gain a better understanding of Linux systems from a low-level perspective along with basic embedded software skills. They will also learn about Debian development (on both technical and philosophical levels) and likely learn/improve their Rust knowledge.
          Application tasks:
          Locate current tweaks packages (in both Debian and Mobian) targeting mobile devices and their source code
          Briefly analyze one or several of those tweaks and either:
          Explain their use
          Rework them, ideally making them more generic
          Offer to remove them, explaining the reasoning
          Related projects:
          Mobian
          DebianOnMobile team
          mobile-tweaks
          tweakster
          [SummerOfCode2025/ApprovedProjects/DeviceTweaksManagement][edit]

          ~~~~~~~~~~
          Enhancing Debian packages with ROCm GPU acceleration
          Description of the project: There now exists a solid foundation of AMD ROCm components packaged within Debian, so it is time to start making use of them! This project would consist of enhancements to existing packages that have AMD GPU support available upstream but not enabled in Debian, or the packaging of new tools and libraries that would be useful for AMD GPU users. A (non-exhaustive) list of potential packages include: adios2, blaspp, cp2k, cupy, dbcsr, elpa, gloo, hpx, hypre, jax, kokkos, lammps, lapackpp, magma, mfem, mpich, onnxruntime, papi, paraview, petsc, pyfr, pytorch, slepc, spfft, sundials, superlu-dist, or trilinos. There are a lot of options of varying difficulty, so it may be possible to tune the project to the skills and time available to the contributor.
          Confirmed Mentor: Cordell Bloor
          How to contact the mentor: cgmb@slerp.xyz
          Difficulty level: Medium
          Project size: Large (350 hours) if attempting to enhance as many packages as possible, but the scope could be reduced to fit a Medium (175 hour) or Small (90 hour) project
          Deliverables of the project:
          New Debian packages with GPU support
          Enhanced GPU support within existing Debian packages
          More autopackagetests running on the Debian ROCm CI
          Desirable skills:
          Strong familiarity with Debian and/or Ubuntu
          Proficiency with CLIs
          Some experience with build systems (e.g. CMake)
          What the intern will learn:
          Debian packaging (.deb) and maintenance within the Debian ecosystem
          Interacting with a broad variety of other groups within Debian, for example the Release Team and ftp-master
          How to work with ROCm (the AMD alternative to CUDA)
          Application tasks:
          Read the Debian New Maintainer's Guide and the Developer's reference
          Analyze which packages you would target
          Try to enhance one Debian package with AMD ROCm support
          Related projects:
          AMD ROCm GitHub
          [SummerOfCode2025/ApprovedProjects/EnhancingPackagesWithROCm][edit]

          ~~~~~~~~~~
          Make Debian for Raspberry Build Again
          Description of the project: There is an available set of images for running Debian in Raspberry Pi computers (all models below the 5 series)! However, I (the maintainer) am severely lacking time to take care for them; I called for help for somebody to adopt them, but have not been successful. The image generation scripts might have bitrotted a bit, but it is mostly all done. And there is a lot of interest and use still in having the images freshly generated and decently tested! This GSoC project is about getting the [[https://raspi.debian.net/ | Raspberry Pi Debian images] site working reliably again, and ideally making it easily deployable to be run in project machines.
          Confirmed Mentor: Gunnar Wolf
          How to contact the mentor: gwolf@debian.org, IRC: gwolf on OFTC
          Difficulty level: Easy
          Project size: Medium
          Deliverables of the project:
          Refreshing the set of daily-built images
          Having the set of daily-built images become automatic again — that is, go back to the promise of having it daily-built
          Write an Ansible playbook / Chef recipe / Puppet whatsitsname to define a virtual serve and have it build daily
          Do the (very basic!) hardware testing on several Raspberry computers. Do note, naturally, this will require having access to the relevant hardware.
          Desirable skills:
          Understanding the early-boot process of a single-board computer
          Declarative configuration (for vmdb2 as well as for Ansible/Chef/Puppet)
          Writing systemd units and timers
          What the intern will learn: The Raspberry Pi family of computers are ARM-based computers, which have a boot process quite different from “traditional” UEFI-based PCs. You will get acquinted with how a different architecture (that is growing in importance!) boots, how Device Tree maps the hardware for the operating system to use it (and maybe even how to work with overlays). You will also learn how deployment of production-level code is done to servers so they run reliably.
          Application tasks:
          We try to diverge the least possible from regular Debian installs with these images, but the RPi's way of working forces us to take some decisions.
          How much do we differ?
          Do you think all of our modifications make sense, or we might be carrying over some cruft that could be removed?
          We use the vmdb2 image building system. It is not much known outside Debian. How do you compare it with other image building tools?
          Related projects: We are filling approximately the same role as our debian-installer tool, but generating for a series of computers where users often flash ready-to-use images instead of doing an explicit install. Of course, the images we provide could be compared to what Raspberry Pi OS offers, but giving the quality and free-software guarantees that Debian has.
          [SummerOfCode2025/ApprovedProjects/MakeDebianForRaspberryBuildAgain][edit]

          ~~~~~~~~~~
          Package LLM Inference Libraries
          Description of the project: Package Large Language Model (LLM) inference libraries, in particular vLLM. It is needless to explain how LLMs are important. Currently, in the Debian archive, we only have ?PyTorch, but downstream applications are still missing. One of the most promising downstream applications is LLM inference. There are already people working on llama.cpp and Ollama, but vLLM still lacks lots of dependencies to land onto Debian. For multi-GPU inference and concurrency, vLLM has its advantages over llama.cpp. The missing packages are, for instance, transformers, huggingface-hub, etc. We would like to trim the dependency tree a little bit at the beginning until we get a minimum working instance of vLLM. Such, this project involves the Debian packaging work for vLLM and its dependencies that are missing from Debian, as well as fixing issues (if there is any) in existing packages to make vLLM work.
          Confirmed Mentor: Mo Zhou
          How to contact the mentor: lumin@debian.org
          Confirmed co-mentors: Christian Kastner (ckk@debian.org), Xuanteng Huang (xuanteng.huang@outlook.com). On the other hand, Debian Deep Learning Team (debian-ai@lists.debian.org) could offer help.
          Difficulty level: Medium (There might be some hard bits. Some packages that we are going to deal with have a clearly above-average difficulty than general Debian packages.
          Project size: 350 hour (large). I get this rough estimate by looking at the pipdeptree of the vllm package. The tree is a little deep.
          Deliverables of the project: Eventually I hope we can make vLLM into Debian archive, based on which we can deliver something for LLM inference out-of-the-box. If the amount of work eventually turns to be beyond my expectation, I'm still happy to see how far we can go towards this goal. If the amount of work required for vLLM is less than I expected, we can also look at something else like SGLang, another open source LLM inference library.
          Desirable skills: Long term Linux user (familiarity with Debian family is preferred), Python, ?PyTorch, and experience of running Large Language Models locally.
          What the intern will learn: Through this project, the intern will learn about the Debian development process, and gain more experience of running LLMs locally, including the inference performance tuning.
          Application tasks: Analyze how ?PyTorch is packaged in Debian, including how the CUDA variant of ?PyTorch is prepared. Those details are very important for the whole reverse dependency tree. And, the intern also needs to setup vLLM locally using pip or uv, and run the LLM inference locally for reference.
          Related projects: The ?PyTorch packaging repository is here: https://salsa.debian.org/deeplearning-team/pytorch
          [SummerOfCode2025/ApprovedProjects/PackageLLMInferenceLibraries][edit]
          
          ~~~~~~~~~~
          Autopkgtests for the rsync package
          Description of the project: A recent series of breakages caused in the rsync package as part of CVE fixes exposed the lack of testing coverage on Debian, e.g.: https://github.com/RsyncProject/rsync/issues/702. The rsync package on Debian has no autopkgtest. This project is for adding these tests to the rsync package, covering as many usecases as possible, making impossible for regressions to go unnoticed. These tests will also be submitted to stable through the proposed-updates mechanism.
          Confirmed Mentor: SamuelHenrique
          How to contact the mentor: samueloph@d.o, @samueloph:matrix.org, samueloph @ OFTC.
          Confirmed co-mentors: N/A
          Difficulty level: Easy
          Project size: 90 hour (small project)
          Deliverables of the project: Autopkgtests for the rsync package
          Desirable skills: Debian packaging, autopkgtest, shell scripting, rsync.
          What the intern will learn: How the Debian project does CI, how to write CI tests for the rsync package.
          Application tasks: Debian packaging contributions. It is required to have a non-virtualized machine running Debian Stable or Testing (no WSL, no containers, no VMs).
          Related projects: N/A
          More Resources: https://salsa.debian.org/ci-team/autopkgtest/-/blob/master/doc/README.package-tests.rst
          [SummerOfCode2025/ApprovedProjects/RsyncAutopkgtests][edit]

          ~~~~~~~~~~
          Salsa CI in Debian
          Description of the project: Salsa CI is a custom-built continuous integration framework that is used in the Debian Gitlab instance (Salsa) and helps Debian maintainers manage roughly 9,000 projects. The Salsa CI pipeline emulates the Debian build process and runs several Debian quality tests, helping to increase the probability that packages can migrate from Debian Unstable to Testing reliably, quickly, and without issue. When new source code triggers a Salsa CI pipeline, 17 different jobs run to build and test it automatically. Salsa CI checks to see whether the to-be-uploaded packages build on multiple architectures (at the moment, amd64 and i386, and optionally on Arm), runs autopkgtest test suites to try to identify potential regressions, and checks for common errors with our custom linter, lintian, among other tests.
          Confirmed Mentor: Otto Kekäläinen
          How to contact the mentor: otto@debian.org
          Confirmed co-mentors: Emmanuel Arias <eamanu@debian.org>
          Difficulty level: Medium
          Project size: Medium sized (175 hours). Depending on the student's availability, this project can be medium or large. The advantage of the project is it can be split into small pieces.
          Deliverables of the project: Fix and discuss issues reported to Salsa CI. Specially Labels "Nice-to-have", "Accepting MRs".
          Desirable skills: Awareness of GitLab CI. Working with git. Basic knowledge of Debian packaging.
          What the intern will learn: Debian Release process, Debian package building, Debian CI process, Basic QA of Debian packages.
          Application tasks: Pick issues from here, discuss with the team and try to fix them.
          More resources:
          https://debconf20.debconf.org/talks/47-where-is-salsa-ci-right-now/
          https://about.gitlab.com/blog/2023/09/19/debian-customizes-ci-tooling-with-gitlab/
          https://debconf19.debconf.org/talks/148-salsa-ci-debian-pipeline-for-developers/
          [SummerOfCode2025/ApprovedProjects/SalsaCI][edit]

          ~~~~~~~~~~
          
          Unapproved Projects with confirmed mentors
          findutils: Finish Support
          Description of the project: Complete the Rust implementation of GNU Findutils, ensuring full compatibility with all options and passing GNU tests. This project focuses on refining and finalizing the Rust-based reimplementation of key utilities from the Findutils package, which are essential for file searching and manipulation in Unix-like systems. The goal is to achieve full feature parity with the GNU versions while maintaining performance and correctness.
          To improve your chances of being selected, please contribute a few changes to the project to demonstrate your commitment and understanding.
          Confirmed Mentor: Sylvestre Ledru
          How to contact the mentor: sylvestre@debian.org
          Confirmed co-mentors: Daniel Hofstetter <daniel.hofstetter@42dh.com>
          Difficulty level: Large
          Project size: 350 hours
          Deliverables of the project:
          A fully functional Rust implementation of the Findutils suite, including:
          /usr/bin/find - search for files in a directory hierarchy
          /usr/bin/locate - find files by name in a prebuilt index
          /usr/bin/updatedb - update the locate database
          /usr/bin/xargs - build and execute command lines from input
          Full compatibility with GNU Findutils
          Passing all relevant GNU tests
          Desirable skills:
          Rust expertise
          Knowledge of file systems and directory traversal
          Understanding of command-line utilities and Unix system interactions
          What the intern will learn:
          How file search utilities work
          Efficient directory traversal and filtering techniques
          Optimization strategies for large-scale file searches
          Application tasks:
          Implement or improve one of the Findutils utilities from the uutils/findutils project: https://github.com/uutils/findutils
          [SummerOfCode2025/PendingProjects/rust-bsdutils][edit]

          ~~~~~~~~~~
          login: Reimplementation of Login Infrastructure Tools in Rust
          Description of the project: Create Rust versions of login infrastructure tools, with a focus on full option compatibility and passing GNU tests. This project involves the Rust-based reimplementation of essential login infrastructure tools that provide functionality for logins and changing effective user or group IDs. The objective is to implement these tools as drop-in replacements for the original shadow-utils suite, ensuring full compatibility with all options and passing all relevant tests. To improve your chances to be selected, please contribute a few changes to the project to demonstrate your commitment and understanding of the project.
          Confirmed Mentor: Sylvestre Ledru
          How to contact the mentor: sylvestre@debian.org
          Confirmed co-mentors: Daniel Hofstetter <daniel.hofstetter@42dh.com>
          Difficulty level: Large
          Project size: 350 hours
          Deliverables of the project: Robust login infrastructure tools, including:
          /bin/login - the program that invokes a user shell on a virtual terminal
          /usr/bin/faillog - tool for displaying and maintaining failure records
          /usr/bin/lastlog - examine the last login record
          /usr/bin/newgrp - change to a new group
          /usr/sbin/nologin - a dummy shell for disabled user accounts
          /usr/bin/sg - execute command with different group ID
          Desirable skills: Rust expertise, knowledge of Linux authentication systems, user/group management, and security considerations.
          What the intern will learn: How login infrastructure works, system security concepts, authentication mechanisms, and privilege management.
          Application tasks: Implement or improve one of the login tools from the shadow-utils project: https://github.com/shadow-maint/shadow
          [SummerOfCode2025/PendingProjects/rust-login][edit]

          ~~~~~~~~~~
          procps: Development of System Monitoring, Statistics and Information Tools in Rust
          Description of the project: Create Rust versions of system monitoring and statistics tools, with a focus on full option compatibility and passing GNU tests. This project involves the Rust-based development of system monitoring and statistics tools: top, vmstat, tload, w, and watch. And process management and information tools: ps, pgrep, pidwait, pkill, skill, and snice. The objective is to achieve full compatibility with all options and to pass GNU tests, ensuring these tools provide accurate and reliable system insights. To improve your chances to be selected, please contribute a few changes to the project to demonstrate your commitment and understanding of the project. Debian can lead in this space with security and Rust!
          Confirmed Mentor: Sylvestre Ledru
          How to contact the mentor: sylvestre@debian.org
          Confirmed co-mentors:Daniel Hofstetter <daniel.hofstetter@42dh.com>
          Difficulty level: Large
          Project size: 350 hours
          Deliverables of the project: Robust tools for system monitoring and statistics, fully compatible with existing options and verified by GNU tests.
          Desirable skills: Rust expertise, knowledge of system performance metrics, familiarity with GNU testing frameworks.
          What the intern will learn: How the Coreutils work, the low level part of the OS
          Application tasks: Fix one or more GNU test listed on: https://uutils.github.io/coreutils/book/test_coverage.html
          [SummerOfCode2025/PendingProjects/rust-procps][edit]

          ~~~~~~~~~~
          util-linux: Development of System Utilities in Rust
          Description of the project: Create Rust versions of util-linux tools, with a focus on full option compatibility and passing GNU tests. This project involves the Rust-based reimplementation of various util-linux tools, including system information tools (dmesg, lscpu), filesystem tools (mountpoint, fsfreeze), partition management tools, process management tools, and utility tools. The objective is to achieve full compatibility with all options and to pass GNU tests, ensuring these tools function as drop-in replacements for the original util-linux suite. To improve your chances to be selected, please contribute a few changes to the project to demonstrate your commitment and understanding of the project.
          Confirmed Mentor: Sylvestre Ledru
          How to contact the mentor: sylvestre@debian.org
          Confirmed co-mentors: Daniel Hofstetter <daniel.hofstetter@42dh.com>
          Difficulty level: Large
          Project size: 350 hours
          Deliverables of the project: Robust tools for system utilities, fully compatible with existing options and verified by GNU tests.
          Desirable skills: Rust expertise, knowledge of system utilities and Linux internals, familiarity with GNU testing frameworks.
          What the intern will learn: How util-linux tools work, the low level part of the OS, system management, and filesystem operations
          Application tasks: Implement or improve one of the tools listed in the util-linux repository: https://github.com/uutils/util-linux
          [SummerOfCode2025/PendingProjects/rust-util-linux][edit]
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/debian/
    idea_list_url: https://wiki.debian.org/SummerOfCode2025/Projects

  - organization_id: 32
    organization_name: DeepChem
    no_of_ideas: 10
    ideas_content: |
      
      Length: Small (90 hours)
      Description: DeepChem has been moving towards first class layers and now has a collection of general layers. We still need to improve the documentation for existing layers to make them more useful for the community. This project should add tutorials for using existing layers to the DeepChem tutorial series, and should plan to add a few new layers that would be useful to the community.
      Educational Value: Students will learn to improve their technical communication skills and learn how to construct useful Jupyter/Colab tutorials. Layers are easier to add than full models since they are effectively functions.
      Potential Mentors: Aryan, Jose, Riya, Maithili, Nimisha, Shreyas
      Note: This was also a 2024 project, but there remains more work to be done for 2025 expanding tutorials/ideas.
      
      ~~~~~~~~~~
      Improving New Drug Modality Support
      Length: Small (90 hours)
      Description: DeepChem at present doesn’t have much tooling or support for working with emerging drug modalities. These include PROTACs, Antibody-drug-conjugates, macrocycles, oligonucleotides and more. This project would add new tutorials introducing these new drug modalities and provides examples of how to work with them with deepchem. It would also be useful to identify and process relevant datasets.
      Educational Value: New drug modalities drive many emerging startups in the space. Improving DeepChem’s support for these new modalities of therapeutics could help drive discovery of new medicine at the cutting edge. It would prepare students to potentially find jobs at these up-and-coming biotech firms as well.
      Potential Mentors: Jose, David, Bharath
      Note: This was also a 2024 project, but there remains more work to be done for 2025 expanding support for new modalities.
      
      ~~~~~~~~~~
      Improving support for drug formulations
      Length: Small (90 hours)
      Description: Drug formulations are a rich area of industrial study that is often critical for actually bringing a drug to patients. See https://drughunter.com/resource/the-modern-medicinal-chemist-s-guide-to-formulations/ 65 for example for a guide. In this project, you will build a tutorial introducing readers to the study of drug formulations along with DeepChem examples of how you can computationally help design a potential formulation.
      Educational Value: Formulations are critical for bringing drugs to patients. Improving DeepChem’s support for these new modalities of therapeutics could help drive discovery of new medicine at the cutting edge. It will prepare students to find jobs at large biotech/pharma firms as well.
      Potential Mentors: Jose, David, Bharath
      Intermediate Projects
      These projects require some degree of hacking, but likely won’t raise challenging engineering difficulties.
      
      ~~~~~~~~~~
      Improve Equivariance Support
      Length: Medium (175 hours)
      Description: DeepChem has limited support for equivariant models. This project would extend support for equivariance to DeepChem and add additional equivariant model such as tensor field networks to DeepChem
      Educational Value: Equivariance is one of the most interesting ideas in modern machine learning and underpins powerful systems like AlphaFold2. Contributors will learn more about this field and could potentially write a research paper about their work on this project.
      Potential Mentors: Aryan, Riya, Nimisha, Bharath, Shreyas
      Note: This was also a 2024 project, but this project was not taken up by a student last year.
      
      ~~~~~~~~~~
      Numpy 2.0 Upgrade
      Length: Large (175 hours)
      Description: DeepChem is currently on Numpy < 2.0. The upgrade to 2.0 is not backwards compatible. We need to fix any broken compatibilities.
      Educational Value: Complex version upgrades take a lot of sophistication and will teach students challenging debugging skills.
      Potential Mentors: Bharath
      
      ~~~~~~~~~~
      Conversion of Smiles to IUPAC and IUPAC to smiles
      Length: Large(300 hours)/Medium(175 hours)
      Description: This project focuses on developing tools within DeepChem to enable accurate, bidirectional conversion between SMILES (Simplified Molecular Input Line Entry System) strings and IUPAC (International Union of Pure and Applied Chemistry) names. The final deliverables will include user-friendly APIs, thorough documentation, and comprehensive testing to facilitate reliable molecular representation transformations.
      Educational Value: Deepening of understanding of chemical data structures, algorithm optimization for molecular conversions, and contributing to the Deepchem ecosystem.
      Potential Mentors: Shreyas, Bharath
      
      ~~~~~~~~~~
      Advanced Projects
      These projects raise considerable technical and engineering challenges. We recommend that students who want to tackle these projects have past experience working in large codebases and tackling code reviews for complex code.
      Implement a Wishlist Model
      Length: Large (300 hours)
      Description: DeepChem has an extensive wishlist of models (https://github.com/deepchem/deepchem/issues/2680 193). Pick a model from the wishlist and implement it in DeepChem. We suggest tackling a model such as Hamiltonian or Lagrangian Neural networks or Physics Inspired Neural Operators (PINO) that will improve DeepChem’s physics support.
      Educational Value: Implementing a machine learning model from scratch or from an academic reference into a production grade library like DeepChem is a challenging task. Doing so requires understanding the base model, dealing with numerical issues in implementation, and benchmarking the model correctly. Multiple past GSoC contributors have leveraged their implementations to write papers on their work and have gained skills that they have used subsequently in industry or in academia.
      Potential Mentors: Depends on model.

      ~~~~~~~~~~
      PyTorch Porting
      Length: Medium (175 hours)
      Description: DeepChem has mostly shifted to PyTorch as its primary backend, but a couple models are still implemented in TensorFlow, in particular our Chemception implementation. This project would port Chemception and do final testing to fix issues with PyTorch/DeepChem compatibility on implementations. https://github.com/deepchem/deepchem/issues/2863. 77
      Educational Value: Porting models while preserving numerical properties requires a strong understanding of deep learning implementations. It serves as a test of machine learning know-how that will serve students well in future machine learning positions in academia or industry.
      Potential Mentors: Aryan, Jose, Riya, Nimisha, Bharath, Shreyas
      
      ~~~~~~~~~~
      HuggingFace-style easy pretrained-model Load
      Length: Large (300 hours)
      Description: DeepChem requires you to know the parameters used to train a model in order to reload it from disk. This is unfriendly for distributing pretrained models. In this project, you will implement an easy 
      HuggingFace-style function call to load weights from disk without having to know training parameters. To do this, you will set a standard metadata format for saving model parameters that can be used behind the scene to autoload models from disk.
      Educational Value: This is a technically challenging project which will require understanding metadata formats and changing saving/reloading for existing models.
      Potential Mentors: Aryan, Bharath
      
      ~~~~~~~~~~
      Model-Parallel DeepChem Model Training
      Length: Large (300 hours)
      Description: DeepChem now has good support for training LLM models through huggingface. At present though, these models cannot be too large and must fit on a single GPU. In this project, you will implement basic support for model parallel training to train models with weights that don’t fit on a single GPU.
      Educational Value: This is a technically challenging project which will require understanding multi-GPU training methods. You may need to explore existing PyTorch frameworks for model-parallel training and adapt them to DeepChem.
      Potential Mentors: Aryan, Bharath
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/deepchem/
    idea_list_url: https://forum.deepchem.io/t/deepchem-gsoc-2025-project-ideas/1568

  - organization_id: 33
    organization_name: Department of Biomedical Informatics, Emory University
    no_of_ideas: 5
    ideas_content: |
      
      [1] Title: Securing Linux Storage with ACLs: An Open-Source Web Management Interface for Enhanced Data Protection
      Mentor(s): Robert Tweedy and Mahmoud Zeydabadinezhad, PhD (mzeydab -at- emory.edu)
      Overview:
      While the traditional POSIX permissions used by nearly all common Linux filesystems allow for simple data permissions management based on group membership, this can become complicated to manage in a large research environment where a project's directory tree may not be efficiently structured to permit access via the simple group management achievable via POSIX permissions, especially when a research PI would like to grant different levels of access to a file to users who are otherwise in the same group. Linux ACLs, while a de-facto standard rather than a formally defined one like POSIX, can be used to resolve these types of situations but have a higher learning curve & far fewer management tools available for a large-scale storage system than tools managing POSIX permissions, relying mainly on the command line tools "setfacl" and "getfacl" to view any details. While there is a GUI tool known as "eiciel" that can adjust Linux ACLs, its audience & feature set is aimed towards an individual user on their personal machine & thus is not suitable for large-scale storage system management. This project aims to develop an application with a web-based GUI that can be deployed on a research network's storage system to provide PIs with a graphical overview of all their research data & allow management of the Linux ACLs to grant appropriate levels of access to the PI's research team members.
      Current Status: New project
      Expected Outcomes:
      A self-contained application (ie. the application should not require external APIs/javascript/etc. to be queried by the end-user's web browser at runtime & should have any relevant scripts packaged with it; the underlying back-end should only access local network resources & not need external Internet connectivity) that allows an end-user to view and manage the access permissions of a large research storage network at a fine-grained level via a web GUI. Both the back-end logic & front-end web interface are in scope of this project.
      The application should support authentication via different modules, with a minimum of LDAP-based authentication.
      The application should support deployment behind a reverse proxy running on Apache or Nginx
      The application must be Linux distribution agnostic as much as possible, but at a minimum should support both running on both RedHat Enterprise Linux (or free derivatives like Rocky Linux) and Debian Linux (or other derivatives like Ubuntu Server) as a SystemD service.
      The application must support running under a limited service account & not as the root user; if special permissions are required for the service account (ie. AmbientCapabilities defined in the SystemD service script) these should be stated in the application's documentation.
      Documentation explaining a basic overview of application usage & installation steps for use by research network system administrators.
      The code and documentation for the application will be made publicly available on a platform such as GitHub & licensed under an Open-Source license such as GPLv3.
      Required Skills:
      Strong web application/frontend development skills using lightweight web frameworks (ie. this should not be a Java application that requires Tomcat/Glassfish/etc.). Strong backend/logic development skills in any standard language commonly available by default on Linux systems (Python, C, C++, Rust, etc.) A good understanding of POSIX and Linux ACL file permissions. A security-focused mindset to ensure that the application's coded to only permit users to view/modify permissions on their own files & not those of others. Familiarity with databases (PostgreSQL and/or MySQL) may be beneficial depending on the approach used to develop the application and track user permissions for the application itself. Familiarity with standard web servers like Apache or Nginx, especially with the concept of reverse proxies.
      Source Code: New Project
      Discussion Forum: https://github.com/NISYSLAB/Emory-BMI-GSoC/discussions
      Effort: 350 Hours
      Difficulty Level: Hard

      ~~~~~~~~~~
      [2] Title: Open-Source Framework for Advanced EEG Data Analysis Using Pre-trained Foundation Models
      Mentor(s): Babak Mahmoudi, PhD and Mahmoud Zeydabadinezhad, PhD (mzeydab -at- emory.edu)
      Overview:
      A foundation model refers to a large-scale model that is pre-trained on extensive, often unlabeled data, capturing a broad understanding of that data. Recent studies have indicated that foundation models could potentially offer enhanced robustness and versatility in the analysis of complex patterns within Electroencephalography (EEG) data. This is particularly relevant in scenarios where EEG data for specific downstream tasks is limited in quantity. This project aims to create an open-source foundation model for EEG data analysis. It will involve developing algorithms for EEG signal processing, automatic feature extraction, and implementing deep learning-based algorithms for pre-training a foundation model on publicly available EEG datasets.
      Current Status: In Progress.
      Expected Outcomes:
      Literature Review: Research and review existing open-source foundation models for medical data, specifically EEG data. Identify the current limitations and challenges in this field.
      A robust, open-source EEG foundation model.
      Documentation and examples demonstrating the model's usage.
      A report detailing the methodologies used and the performance of the model.
      The model weights and code will be made publicly available on a platform such as GitHub.
      Required Skills:
      Strong programming skills, preferably in Python.
      Experience with deep learning frameworks, preferably PyTorch.
      Knowledge of self-supervised learning and large language models
      Knowledge in signal processing, neuroscience, or related fields.
      Source Code: In Progress
      Discussion Forum: https://github.com/NISYSLAB/Emory-BMI-GSoC/discussions
      Effort: 350 Hours
      Difficulty Level: Hard

      ~~~~~~~~~~
      [3] Python Expansion of the Open Source Electrophysiological Toolbox
      Mentor(s): Reza Sameni, PhD
      Overview:
      Standardized, open-source codes are indispensable in advancing biomedical engineering and biomedical informatics. The Open-Source Electrophysiological Toolbox (OSET) [https://github.com/alphanumericslab/OSET] was conceived in 2006 with this perspective, aiming to offer researchers an open-source codebase for biomedical signal processing. The toolbox has incrementally evolved and expanded over the years. Many researchers have utilized this toolbox for their research. Notably, some modules of OSET have been translated to C/C++ and Python and integrated into medical devices and cloud-based automatic diagnostic systems for large data. It operates under a permissive open license, encouraging community-driven development. The project aims to continue the Python expansion of OSET to convert it into a standard Python package, broadening access and maintaining consistency across platforms. The planned upgrades include comprehensive cross-language unit tests (between MATLAB and Python), documentation, example codes, installation, and maintenance mechanisms, with a modern software-engineered architecture and objective microbenchmarks. Through this expansion, we aim to extend OSET's benefits to a broader community of AI researchers, also contributing to the training of the next generation of biomedical engineers in the AI era. OSET will be maintained under the 3-Clause BSD License, a permissive open-source license that allows the redistribution and use of software in any form with adequate disclaimer clauses, offering flexibility for both open-source and commercial use, while minimizing legal complexities.
      Current Status: Ongoing project.
      Expected Outcomes:
      A Python package for OSET, with standard unit tests, installation guidelines and documentation. The codebase should operate exactly identical to the current MATLAB implementation.
      Key features:
      Open-source code development for biomedical engineering and biomedical informatics.
      Identical cross-language performance
      Standardized unit tests
      Required Skills:
      Proficiency in Python and MATLAB.
      A background in signal processing
      Experience in biomedical signal processing
      Source Code: https://github.com/alphanumericslab/OSET
      Discussion Forum: https://github.com/NISYSLAB/Emory-BMI-GSoC/discussions
      Effort: 350 Hours
      Difficulty Level: Medium

      ~~~~~~~~~~
      [4] Health-AI Ethics Atlas
      Mentor(s): Selen Bozkurt, PhD
      Overview:
      This project aims to develop an interactive global map that visualizes the application and development of ethical principles in medical AI across different countries. It will highlight the diversity in ethical standards, regulatory approaches, and implementation practices in healthcare AI worldwide.##
      Key features:
      Interactive world map displaying medical AI ethics initiatives.
      Filters for different ethical principles and AI applications.
      Country-specific data on AI healthcare policies and ethics.
      Time-lapse feature to observe changes over time.
      Case studies and detailed reports linked to map locations.
      Dynamic interface allowing users to explore technological ethical dimensions.
      Current Status: New project.
      Expected Outcomes:
      A comprehensive resource for understanding global trends in medical AI ethics.
      Enhanced awareness of ethical diversity in medical AI applications.
      Tool for researchers and policymakers to identify global best practices and gaps.
      Required Skills:
      Proficiency in web development (e.g., HTML, CSS, JavaScript).
      Experience with data visualization tools and libraries (e.g., D3.js, Leaflet).
      Understanding of GIS and mapping software.
      Knowledge in data analysis and handling large datasets.
      Interest or background in AI ethics, particularly in healthcare.
      Source Code: New Project.
      Discussion Forum: https://github.com/NISYSLAB/Emory-BMI-GSoC/discussions
      Effort: 350 Hours
      Difficulty Level: Medium

      ~~~~~~~~~~
      [5] Advancing Brain Decoding and Cognitive Analysis: Leveraging Diffusion Models for Spatiotemporal Pattern Recognition in fMRI Data
      Mentor(s): Babak Mahmoudi, PhD and Ozgur Kara
      Overview:
      Functional Magnetic Resonance Imaging (fMRI) is a neuroimaging technique that measures brain activity by detecting changes in blood flow, providing high-dimensional, time-series data representing brain function. By leveraging diffusion models—probabilistic generative models originally designed for image synthesis—this project aims to learn complex spatiotemporal patterns in fMRI data, enabling downstream tasks such as brain decoding, disease prediction, and cognitive state classification.
      Current Status: New project
      Expected Outcomes:
      Data Preprocessing:
      Preprocess data using standard pipelines to normalize, denoise, and align brain scans.
      Convert the data into a structured representation suitable for diffusion training, such as voxel-wise time series or connectivity matrices.
      Model Architecture & Training:
      Adapt diffusion models to the temporal and spatial characteristics of fMRI data.
      Use a U-Net or transformer-based architecture to model the evolution of brain signals.
      Train the model with a denoising diffusion probabilistic approach, learning to reconstruct fMRI signals from noise.
      Explore conditioning techniques, such as using behavioral or task labels, to guide model learning.
      Required Skills:
      Strong programming skills, preferably in Python.
      Experience with deep learning frameworks, preferably PyTorch.
      Knowledge in signal processing, neuroscience, or related fields.
      Source Code: New Project
      Discussion Forum: https://github.com/NISYSLAB/Emory-BMI-GSoC/discussions
      Effort: 350 Hours
      Difficulty Level: Hard
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/department-of-biomedical-informatics-emory-university/
    idea_list_url: https://github.com/NISYSLAB/Emory-BMI-GSoC/?tab=readme-ov-file#list-of-ideas

  - organization_id: 34
    organization_name: Django Software Foundation
    no_of_ideas: 4
    ideas_content: |
      
      Django Templates: Bring django-template-partials into core
      Difficulty Medium
      Size 350hrs
      Potential Mentors Carlton Gibson
      Key Skills Django Template Language, template tags
      The third-party app django-template-partials allows for reusable named inline partials for the Django Template Language. These named inline partials can be used multiple times within a template or included in other templates. They are particularly useful when using libraries such as HTMX. It would be good to have support built-in to core.
      Outcome would be a PR adding this into Django. In addition there would be preparatory work on the Django-template-partials repo to smooth the migration for existing users. There is a tracking issue on the repo that can be used for guidance.
      
      ~~~~~~~~~~
      Automate processes within Django contribution workflow
      Difficulty Medium
      Size 350hrs
      Potential Mentors Lily Foote
      Key Skills GitHub actions, scripting, Jenkins
      The contribution workflow within Django has several manual processes. These are error prone and take up valuable time from contributors. This project would seek to automate these processes, such as automating releases, identifying active PRs and managing aging PR queue.
      Part of this project will involve working with the Fellows to determine which of their tasks and the community's tasks are the best candidates for automation.
      Outcome would be one to several PRs automating these workflows, depending on how many are accomplished.
      ~~~~~~~~~~
      Expand django-stubs coverage
      Difficulty Hard.
      Size Variable
      Potential Mentors 2024 mentor: Adam Johnson
      Key Skills Python typing and Django-stubs
      django-stubs is an external project that adds type hints to Django. It may be possible to work on it under GSoC if you can show experience with Python’s type hints and Mypy.
      django-stubs uses Mypy’s stubtest tool to check that its type hints align with Django’s source, per its contributing documentation. The “todo” list contains ~1600 functions and classes missing type hints. A proposal targeting a specific, significant subset of the missing types is likely to be accepted.
      
      
      ~~~~~~~~~~
      Django Admin: Add Command palette
      Difficulty Medium
      Size Variable
      Potentia mentors Tom Carrick
      Key Skills UI/UX
      Many dashboards nowadays have command palettes, often associated with the CTL+K keyboard shortcut. This allows for quicker, easier and more accessible navigation. This project is about adding such a feature to the Django admin.
      This would allow power users to e.g. very quickly find a particular object in the database to edit. The overall goal is to improve the user-experience for keyboard and keyboard-only users.
      This feature already has an accepted ticket. However, this work needs to be done carefully to ensure that all shortcuts are useful, documented in the admin, and work across browsers without shadowing browser shortcuts. In addition, shortcuts should be easily extensible by developers.
      Some initial work has been done to add keyboard shortcuts to core. The 175 hour version of this project would be to get this project finished and merged into Django. The 350 hour version would be to build this into a full command palette.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/django-software-foundation/
    idea_list_url: https://code.djangoproject.com/wiki/SummerOfCode2025

  - organization_id: 35
    organization_name: Drupal Association
    no_of_ideas: 9
    ideas_content: |
        Proposal 2025: Augmentor DALL·E 3 module
        Project Description
        This project aims to ship the Augmentor plugin with seamless integration to the DALL·E 3 service, enabling users to generate high-quality images directly from text prompts. By combining Augmentor's flexible plugin architecture with DALL·E 3’s advanced AI capabilities, the solution will empower content creators to effortlessly transform ideas into compelling visual content. The integration will focus on delivering a user-friendly interface, efficient performance, and robust error handling to cater to both technical and non-technical users.

        Project Goal
        Functional Changes:
        Integrate the DALL·E 3 API into the Augmentor plugin for real-time image generation from text inputs.
        Develop an intuitive interface for configuring image generation parameters and previewing results.
        Implement error handling and optimization strategies to ensure reliability and performance.
        Provide comprehensive documentation and usage guides to facilitate seamless adoption.
        Mentor Details
        Name: Naveen Valecha & Murrayw
        Email / Slack: @naveenvalecha, @murrayw

        Project Size
        175 hours

        Project Difficulty
        Intermediate

        Project Skills/Prerequisite
        Expertise in plugin development within the Augmentor ecosystem.
        Proficiency in JavaScript, Python, or other relevant programming languages.
        Familiarity with RESTful APIs and integrating third-party AI services.
        Experience with DALL·E 3 or similar AI image generation APIs is a plus.
        Understanding of UI/UX design principles to create an engaging and intuitive user interface.
        Project Resources
        DALL·E 3 Documentation
        Augmentor Plugin Developer Guide
        OpenAI API Reference
        Web API Documentation
        R&D Tasks
        Research the DALL·E 3 API, including authentication methods, rate limits, and usage policies.
        Design and develop a modular integration layer within the Augmentor plugin.
        Create a user-friendly interface for inputting text prompts and previewing generated images.
        Implement error handling, logging, and performance optimizations to ensure a seamless user experience.
        Document the integration process, including setup instructions and usage tutorials.

        ~~~~~~~~~~

        Proposal 2025: Open Source AI Content Generation
        
        Project Description
        This project focuses on advancing the integration of open-source AI models into existing Drupal modules, streamlining the creation of structured content based on user prompts. By embedding AI-powered content generation directly into Drupal, the solution aims to automate and simplify the content creation process. Site builders and content creators will benefit from a seamless workflow that transforms text inputs into well-organized, coherent content.

        Project Goal
        Functional Changes:
        Develop an integration layer that connects Drupal content creation modules with open-source AI models.
        Create an intuitive interface where users can input prompts or guidelines to generate structured content.
        Implement mechanisms to format and validate the generated content according to predefined templates.
        Optimize the integration for performance and reliability, including robust error handling and logging.
        Document the integration process and provide comprehensive usage guides for end users.
        Mentor Details
        Name & Slack: Gaurav & Anushri Kumari
        Email / Slack: @gauravvvv, @anushrikumari

        Project Size
        350 hours

        Project Difficulty
        Intermediate

        Project Skills/Prerequisite
        Proficiency in PHP and Symfony for backend development.
        Experience in JavaScript for front-end interface development.
        Familiarity with AI models and APIs, including experience working with open-source AI frameworks.
        Understanding of Drupal module development and integration patterns is a plus.
        Project Resources
        Drupal Documentation
        Symfony Documentation
        Hugging Face – Open Source AI Models
        JavaScript Guide
        R&D Tasks
        Research and evaluate suitable open-source AI models that can generate structured content from text prompts.
        Identify the optimal integration points within existing Drupal content creation modules.
        Develop the backend integration using PHP and Symfony, ensuring smooth communication with the AI APIs.
        Create a user-friendly front-end interface using JavaScript that allows users to input prompts and preview generated content.
        Implement error handling, logging, and performance optimizations to enhance the overall user experience.
        Document the integration process and produce detailed guides for installation, configuration, and usage.
        Issue fork gsoc-3419059
        Command icon Show commands
        About issue forks

        ~~~~~~~~~~

        Proposal 2025: Assisting Modules in Drupal 11 Compatibility


        Project Description
        Taking on a project idea from 2023. Many important Drupal modules are still not ready for Drupal 11. This makes it harder for developers and site owners to upgrade smoothly.

        This project aims to assist in making Drupal modules Drupal 11-ready by identifying top-used but outdated modules, categorizing them, and streamlining their migration process. The project will include:

        Prioritization of the top most-used yet incompatible modules.
        Categorization based on functionality (e.g., e-commerce, security, SEO).
        Automated compatibility checks and migration guides.
        By ensuring these modules are compatible, this project will significantly ease the transition to Drupal 11, benefiting developers and site owners alike.

        Project Goal
        Functional Changes:
        Analyze and prioritize high-impact modules needing Drupal 11 updates.
        Ensure code consistency and adherence to modern Drupal standards.
        Provide clear documentation for developers migrating modules.
        User Experience Improvements:
        Enhance documentation for easier adoption.
        Provide a clear roadmap for Drupal 11 compatibility efforts.
        Code & Performance Enhancements:
        Ensure PSR standards compliance.
        Mentor Details
        Name : [To be assigned]

        Email / Slack: [To be assigned]

        Project Size
        350 hours

        Project Difficulty
        Intermediate

        Project Skills/Prerequisite
        Proficiency in PHP and JavaScript
        Experience in Drupal module development
        Familiarity with upgrading Drupal modules to newer versions
        Understanding of Drupal's API and best practices
        Experience with Git and version control
        Project Resources
        Drupal Contributor Guide
        R&D Tasks
        Identify top-used modules that need compatibility updates.
        Analyze and categorize modules based on their functionality.
        Document compatibility issues and solutions for developers.
        Test migrated modules for performance and stability.

        ~~~~~~~~~~

        Proposal 2025: FAISS Vector Search Integration for Drupal

        Project Description
        Drupal currently lacks support for FAISS (Facebook AI Similarity Search), a high-performance library designed for efficient vector-based similarity search. This project aims to develop a FAISS provider module that enables advanced content discovery, documentation deduplication, and AI-powered search capabilities within Drupal.

        The solution will integrate with existing Drupal AI modules and Search API, providing a robust foundation for vector-based similarity search. By implementing FAISS as a local vector database, we can significantly improve content discovery while reducing dependency on external APIs.

        Current Scenario / Pain Points
        No native FAISS support in Drupal for vector similarity search
        External API calls causing latency in embedding generation
        Cost implications with third-party embedding services
        Growing documentation duplication without automated detection
        Performance bottlenecks in large-scale content similarity matching
        Why This Matters
        This integration will revolutionize how Drupal handles content discovery and similarity detection:

        Cost Efficiency: Local vector operations eliminate expensive API calls
        Performance: FAISS is optimized for rapid similarity search at scale
        Independence: Reduced reliance on external services
        Scalability: Handles millions of vectors efficiently
        Future Impact
        The FAISS provider will enable next-generation features in Drupal:

        Intelligent Documentation Management
        Automated duplicate detection
        Content relationship mapping
        Smart content suggestions
        Enhanced Module Discovery
        Similar module detection
        Functionality matching
        Better developer experience
        AI-Powered Search
        Semantic search capabilities
        Context-aware results
        Improved content relevance
        Project Goal
        Develop a FAISS provider module (ai_provider_faiss) for vector storage and similarity search
        Create an embedding pipeline using HuggingFace model
        Integrate with Search API for enhanced content discovery
        Implement a dashboard for visualizing similarity scores and content relationships
        Mentor Details
        Name: [To be assigned]
        Email / Slack: [To be assigned]

        Project Size
        350 Hours

        Project Difficulty
        INTERMEDIATE

        Project Skills/Prerequisites
        Strong PHP and Drupal module development experience
        Understanding of vector embeddings and similarity search concepts
        Familiarity with Search API and HuggingFace integration
        Experience with performance optimization and scalable solutions
        Project Resources
        FAISS GitHub Repository
        HuggingFace Documentation
        Original Feature Request

        ~~~~~~~~~~

        Proposal 2025: Appwrite Integration Module for Drupal

        Project Description
        Appwrite is an open-source Backend-as-a-Service (BaaS) that offers a comprehensive suite of tools—ranging from authentication and storage to databases and serverless functions—through easy-to-use APIs. This project aims to develop a Drupal module that integrates Appwrite’s services, giving Drupal developers a robust alternative for handling key backend functionalities. The module will primarily focus on connecting Drupal with Appwrite’s authentication system, object storage, and document database, while also laying the groundwork for future integrations like serverless functions, messaging, and real-time event handling.

        Many Drupal sites currently rely on local media storage or traditional cloud services, but with Appwrite’s flexible architecture, we can streamline media management and content handling. The solution will include a dedicated configuration interface within Drupal, making it simple for site administrators to set up and manage Appwrite settings.

        Project Goal
        Functional Changes:
        Develop a Drupal module that connects with Appwrite’s OAuth-based authentication system (supporting providers like Google, GitHub, Apple, etc.).
        Enable media file management by integrating with Appwrite's object storage APIs, reducing the dependency on traditional cloud storage solutions.
        Integrate Appwrite’s document database to store and retrieve structured Drupal content efficiently.
        Create an intuitive configuration interface within Drupal for managing all Appwrite-related settings.
        Mentor Details
        Name: stanzin
        Email / Slack: @stan

        Project Size
        TBD

        Project Difficulty
        INTERMEDIATE

        Project Skills/Prerequisite
        Experience with PHP and Symfony for Drupal backend development.
        Understanding of Drupal module development, including hooks, services, and dependency injection.
        Knowledge of JavaScript for interacting with the Appwrite SDK and APIs.
        Familiarity with REST APIs to facilitate seamless integration of external services with Drupal.
        Understanding of OAuth and authentication protocols for implementing secure Appwrite authentication.
        Project Resources
        Appwrite Official Website
        Drupal Module Development Guide
        R&D Tasks
        Research and evaluate the Appwrite API, focusing on authentication, storage, and document database functionalities.
        Design a modular integration approach to connect Drupal with Appwrite’s services.
        Develop and test the OAuth-based authentication workflow within Drupal using Appwrite.
        Implement media storage integration to manage file uploads and retrievals via Appwrite’s object storage.
        Integrate Appwrite’s document database to support Drupal’s content management and retrieval.
        Create a user-friendly configuration interface in Drupal to manage Appwrite settings and integrations.
        Document the integration process and provide comprehensive user guides and technical documentation.
        
        ~~~~~~~~~~

        

        Proposal 2025: AI-Powered Media Caption Generator

        Project Description
        Currently, Drupal lacks a built-in AI-powered solution for generating media captions, alt tags, and metadata. Manual captioning and tagging are time-consuming, inconsistent, and impact accessibility, SEO, and media discoverability.

        The AI-Powered Media Enhancement Module will integrate with AI APIs for NLP and computer vision to automatically generate captions, alt tags, and relevant media tags based on content analysis. This module will include:

        Adaptive feedback learning: Continuously improves caption accuracy based on user interactions.
        Batch processing: Allows handling multiple media files efficiently.
        Customizable AI model selection: Users can choose different AI services (OpenAI, Hugging Face, Google Vision, etc.).
        By automating captioning and metadata generation, this project will improve accessibility, SEO, and user engagement, reducing manual effort and making media content more discoverable.

        Project Goal
        Functional Changes:
        Develop a Drupal module capable of generating AI-powered captions, alt tags, and media metadata.
        Integrate NLP models for text-based caption generation.
        Implement computer vision models for object detection and image recognition.
        Enable an adaptive feedback loop where user edits refine AI-generated captions over time.
        Support batch processing to handle multiple media files at once.
        Allow users to choose and configure AI models based on their needs (e.g., OpenAI, Hugging Face, etc.).
        User Interface Changes:
        AI settings page: Configure AI model selection and preferences.
        Caption preview & edit section: Users can review and modify AI-generated captions.
        Bulk processing interface: Manage and process multiple media files at once.
        API Changes:
        Integration with AI APIs for NLP, image recognition, and metadata generation.
        Implement an adaptive feedback system where user corrections improve AI results.
        Data Model Changes:
        New database fields to store generated captions, alt tags, media tags, and user feedback for adaptive learning.
        Mentor Details
        Name : Binal Patel, [Senior / Experienced Drupal Developer - To be assigned]

        Email / Slack: @Binal Patel, [To be assigned]

        Project Size
        350 hours

        Project Difficulty
        Intermediate

        Project Skills/Prerequisite
        Proficiency in PHP and JavaScript
        Familiarity with Drupal module development
        Experience with AI/ML models and API integration (OpenAI, Hugging Face, Google Vision, etc.)
        Experience with Git, containerization (Docker), and RESTful APIs
        Good understanding of UI/UX principles and responsive design
        Project Resources
        Hugging Face Transformers
        OpenAI API Docs
        Google Cloud Vision API
        R&D Tasks
        Research AI models for caption generation, image recognition, and metadata extraction.
        Develop backend integration with AI APIs.
        Design and implement a user-friendly UI for media caption management.
        Ensure compliance with accessibility standards (WCAG, ARIA, etc.).
        Write module documentation and conduct testing.


        ~~~~~~~~~~

        Proposal 2025: AI-Powered Unified Accessibility Compliance Suite for Drupal

        Project Description
        This project aims to create an AI-driven Drupal module that audits and remediates accessibility issues across text, layout, and media content. Currently, Drupal administrators struggle with time-consuming manual accessibility audits that often miss context-dependent issues. The module will leverage computer vision, OCR, and NLP models to automatically scan pages for ADA/WCAG compliance issues, generate actionable remediation reports, and provide a dynamic dashboard to monitor issues, prioritize fixes based on impact severity, and implement one-click remediations where possible.

        Project Goal
        Dynamic Dashboard:
        Create a user-friendly dashboard to monitor website accessibility status and track remediation progress.
        Provide visualizations and reports for compliance documentation.
        Implement severity-based issue prioritization with configurable thresholds.
        Functional Changes / User Interface Changes:
        Integrate AI and accessibility APIs (e.g., Deque Axe) for automated scans of text, layout, and media.
        Use NLP models to suggest context-aware alt-text for media as part of remediation.
        Create an inline editor for quick fixes to identified accessibility issues.
        DB Changes / API Changes:
        Design database schema for storing accessibility audit results and remediation history.
        Create RESTful APIs for integration with external accessibility testing tools.
        Implement caching mechanisms to improve performance of repeated scans.
        Workflow Integration:
        Allow for the export of reports in common formats such as CSV, PDF, and WCAG-compatible documentation.
        Create a feedback system for users to rate AI-generated remediation suggestions.
        Integrate with Drupal's content workflow to include accessibility checks in the publishing process.
        Mentor Details
        Name: [To be assigned]
        Email / Slack: [To be assigned]

        Project Size
        350 Hours (Large)

        Project Difficulty
        Intermediate

        Project Skills/Prerequisite
        Expertise in Drupal module development and Drupal APIs.
        Proficiency in PHP, JavaScript, and Python for AI integration.
        Familiarity with AI frameworks (e.g., Hugging Face Transformers, OpenAI APIs).
        Experience with accessibility standards (WCAG 2.1/ADA) and tools like Axe.
        Understanding of semantic HTML and ARIA attributes.
        Technologies: PHP, JavaScript, Python, React, AI Frameworks, Axe Core, Drupal theme system.
        Project Resources
        Drupal Accessibility Handbook
        Deque Axe Accessibility Tools
        Drupal Module Development Guide
        GPTBot – AI Chatbot Integration for Drupal
        WCAG Guidelines and Resources
        Accessibility Checker for Drupal
        Axe Core GitHub Repository
        R&D Tasks
        Research AI models for accessibility analysis (e.g., Deque Axe, Hugging Face).
        Implement backend integrations with accessibility-focused AI providers.
        Design a UI for audit reporting and remediation, aligned with Drupal's accessibility standards.
        Evaluate existing accessibility modules like Siteimprove and Monsido for potential integration.
        Research automated testing frameworks that can validate accessibility fixes.
        Investigate machine learning approaches to recognize patterns in accessibility issues specific to Drupal sites.
        Similar Projects for Inspiration
        Editoria11y - In-CMS Accessibility Checker
        Site Audit - Framework for analyzing Drupal sites
        Microsoft Accessibility Insights
        Tota11y for Drupal

        ~~~~~~~~~~

        Proposal 2025: SARIF Integration for Error Reporting

        Project Description
        This project aims to enhance Drupal’s automated testing and error reporting ecosystem by integrating support for the Static Analysis Results Interchange Format (SARIF). SARIF is a standardized format for static analysis tool output, and by incorporating it into Drupal, developers will have a more consistent and efficient way to debug and analyze issues in both Drupal core and contributed modules. The proposed integration will enable Drupal’s CI pipeline to export error messages, linting reports, and test failures in SARIF format, making these results easily consumable by tools like GitHub Code Scanning, VS Code’s SARIF Viewer, and GitLab Security Dashboards.

        By developing a SARIF-compatible module or integration layer, the project will streamline the debugging process and facilitate better collaboration among developers, ultimately improving code quality and reducing turnaround time for fixes.

        Project Goal
        Functional Changes:
        Design and implement a conversion layer to translate Drupal’s CI output (errors, linting reports, test failures) into SARIF format.
        Develop a Drupal module or integration that automates the export of SARIF reports from the CI pipeline.
        Integrate the solution with popular CI/CD platforms such as GitHub Actions and GitLab CI for seamless workflow integration.
        Ensure compatibility with external tools including GitHub Code Scanning, VS Code’s SARIF Viewer, and GitLab Security Dashboards.
        Provide comprehensive documentation and usage guides to support adoption and future enhancements.
        Mentor Details
        Name & Slack: Royal Pinto
        Email / Slack: @royalpinto007

        Project Size
        350 hours

        Project Difficulty
        Intermediate

        Project Skills/Prerequisite
        Strong proficiency in PHP and JavaScript with hands-on experience in Drupal module development.
        Experience using Git for version control.
        Knowledge of compiler concepts and static analysis techniques, including ASTs and tokenization.
        Familiarity with CI/CD platforms, particularly GitHub Actions and GitLab CI.
        Understanding of standardized reporting formats and integration strategies.
        Project Resources
        SARIF Specification on GitHub
        Drupal Official Website
        Drupal Module Development Guide
        GitHub Actions Documentation
        GitLab CI Documentation
        R&D Tasks
        Research the SARIF specification and analyze Drupal’s existing CI output formats.
        Design a conversion layer that maps error messages, linting reports, and test failures to SARIF.
        Develop and integrate the SARIF module with Drupal’s CI pipeline to automate report generation.
        Establish integrations with GitHub Actions and GitLab CI to ensure seamless usage of SARIF reports.
        Conduct thorough testing, optimize performance, and prepare detailed documentation and tutorials for end users.


        ~~~~~~~~~~

        Proposal 2025: Entity Display Manager Module

        Project Description
        This project is focused on developing the Entity Display Manager Module for Drupal, designed to enhance field display customization by offering extended control over HTML structures, field output rewrites, and entity view mode configurations. The module addresses common development pain points by enabling site builders to manage field rendering without resorting to custom theming or complex preprocess hooks. By streamlining the display management process, the module aims to significantly speed up development workflows and improve the overall flexibility of Drupal's presentation layer.

        Project Goal
        Functional Changes:
        Introduce custom field display settings with options to enable or disable the Field HTML wrapper, Label HTML wrapper, and default field classes.
        Implement a template override mechanism for advanced customization of field output.
        Provide robust field rewrite options to allow custom text overrides, transformation of fields into clickable links, character limit trimming, HTML tag stripping, and removal of extraneous whitespace.
        Extend entity view modes by allowing bundle-specific configurations and custom display settings per view mode.
        Seamlessly integrate the new settings into Drupal’s UI under the Manage Display section, utilizing field formatters or preprocess hooks as needed.
        Mentor Details
        Name: stanzin

        Email / Slack: @stan

        Project Size
        350 hours

        Project Difficulty
        Intermediate

        Project Skills/Prerequisite
        Strong proficiency in Drupal module development and a deep understanding of Drupal's entity and field systems.
        Expertise in PHP and familiarity with Drupal’s theming system, including template overrides and preprocess hooks.
        Experience with front-end technologies such as HTML, CSS, and JavaScript for effective UI integration.
        Understanding of configurable display settings and the nuances of entity view mode configurations.
        Knowledge of best practices in module design and development to ensure maintainability and performance.
        Project Resources
        Drupal Documentation
        Understanding Drupal’s Entity API
        Drupal Theming Guide
        R&D Tasks
        Analyze current limitations in Drupal's field display customization and identify key areas for enhancement.
        Design the module architecture to introduce extended control over HTML wrappers, field classes, and output rewrites.
        Develop custom configuration settings within the Manage Display interface, including checkboxes and template override options.
        Implement comprehensive field rewrite functionalities such as custom text, link transformations, character limit trimming, HTML stripping, and whitespace normalization.
        Extend entity view mode configurations to support bundle-specific custom display settings.
        Conduct thorough testing across different Drupal environments and document configuration guidelines and usage instructions.
        Key Features
        Custom Field Display Settings:
        Enable/disable field and label HTML wrappers.
        Remove default field classes.
        Provide template override options for advanced customization.
        Field Rewrite Options:
        Override field output with custom text.
        Transform fields into custom links.
        Implement character limit trimming for field values.
        Strip HTML tags and remove unnecessary whitespace from field output.
        Entity View Mode Configuration:
        Extend entity view modes to support custom display settings.
        Allow bundle-specific configurations per entity view mode.
        Integration with UI:
        Add settings under "Manage Display" in the entity form display.
        Implement a field formatter or use preprocess hooks for modifications.















      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/drupal-association/
    idea_list_url: https://www.drupal.org/project/issues/gsoc?text=2025&status=All&priorities=All&categories=All&version=All&component=All


  - organization_id: 36
    organization_name: Eclipse Foundation
    no_of_ideas: 4
    ideas_content: |
        Agentic UI Framework for Eclipse LMOS
        Description 
        Eclipse LMOS has established a strong foundation for multi-agent backend architecture, enabling true backend agents that operate independently. However, the user interface (UI) has not yet been designed with the same agentic principles. This project aims to create an Agentic UI Framework specifically for agent builders using LMOS. The framework will provide a unified, configurable interface for deploying, managing, and configuring backend agents, allowing agent builders to efficiently oversee agent operations.

        The goal is to design a UI system where agent builders interact with their deployed agents in a natural, goal-driven manner, rather than manually configuring settings or navigating complex menus. This would involve:

        UI agents that dynamically emerge based on the context and operational needs of agent builders.
        A single, centralized interface for managing all LMOS agent deployments and configurations.
        Extensible UI components that align with agentic principles, enabling customization for different agent use cases.
        Benefits to the Community

        Empowers agent builders with an intuitive UI for configuring and managing LMOS agents.
        Simplifies interactions for non-technical users by abstracting complexity while providing advanced controls for experienced developers.
        Creates a specialized UI framework that aligns with LMOS’s multi-agent backend and enhances agent deployment workflows.
        Enables flexible, adaptive user interfaces that evolve based on agent builder requirements.
        Links to Eclipse Project
        Eclipse LMOS @ EF PMI
        Eclipse LMOS Website
        Expected outcomes 
        Initial Agentic UI Framework – A set of UI components that dynamically instantiate based on agentic needs.
        Prototype Interface for Agent Control – A single UI where users can control, configure, and observe agent activity.
        Integration with ARC View – Extending the ARC View to function as a local dev platform for UI-driven agent workflows.
        Extensibility Support – Ensuring that new agents can seamlessly introduce new UI components.
        Skills required/preferred 
        React & Modern Frontend Expertise: Strong skills in React, JavaScript, HTML, and CSS for building the UI.
        Dynamic & Adaptive UI Design: Ability to create UIs that change based on context and user needs.
        Agent System Understanding: Basic knowledge of agent concepts to build an effective agent-focused UI.
        Extensible Component Architecture: Skill in designing modular UI components that can be easily expanded.
        Project size 
        175 hours or 350 hours (scope can be adjusted)

        Possible mentors: 
        Arun Joseph
        Robert Winkler
        Patrick Whelan
        Kai Kreuzer

        ~~~~~~~~~~


        [Eclipse 4diac] Improving the Usability of the 4diac IDE's State Machine Editor


        Description 
        Over the last years, the several graphical editors in 4diac IDE were reworked to make them more usable and to reduce the number of user interactions. These are, for example, the FB network editor or the FB interface editor. One editor that didn't get this treatment is the state machine editor. With this project, we would like to explore what issues we have in this editor and how we can improve the usability of this editor. Topics of a potential project are:

        identify usability issues
        group them regarding implementation effort
        fix usability issues
        document results


        Links to Eclipse Project

        Both to the Eclipse 4diac and Project Repository.

        Expected outcomes 

        List of usability issues
        List of potential improvements
        Improved editor
        Documentation of results


        Skills required/preferred 
        Strong programming skills in Java and knowledge of Eclipse GEF Classic are required.

        Project size 
        175 hours or 350 hours (scope can be adjusted)

        Possible mentors: 
        Alois Zoitl

        Rating 
        Hard

        ~~~~~~~~~~

        GlitchWitcher: AI-assisted Bug Prediction



        Description 
        Defects exist in source code.  Some defects are easily found during code reviews, some are revealed by proper unit or integration testing.  Before code is reviewed and the code is executed during testing, there are other ways to detect where bugs may be lurking.
        The intent of this project is to trial and compare 2 approaches to predicting where defects live in source code.  There are a lot of different research papers that exist that discuss different algorithms that assist in finding defects.  This project will focus on implementation of 2 approaches.

        Approach 1: Predicting Faults from Cached History
        This first approach is a relatively simple, inexpensive technique for predicting where bugs live.  It is outlined in this research paper [1].  We would revive an earlier prototype of BugTools [2], which is a utility that applies the BugCache/FixCache algorithm to selected Github repositories to return scores against the different files in the repositories, as per the algorithm outlined in the paper.  Those with the highest hit rates are the most likely to contain defects, so are the more important to cover thoroughly with tests.
        This phase of the project is not expected to take very long, it is really to warm up to the idea of analyzing source code and integrating a new verification ‘check’ into a workflow of a Github repository.  This utility would report top 10 files that are most likely to contain defects.

        Approach 2: Reconstruction Error Probability Distribution (REPD) model
        The 2nd approach utilizes a supervised anomaly detection/classification model outlined in this research paper [3] to categorize defective and non-defective code.  This approach is much more involved.  Section 3 of the paper describes the model in use, while section 4 describes the methodology.  They train against datasets from NASA ESDS Data Metrics project [4].
        As part of this project, participants are asked to try and reproduce the REPD model described in this paper and apply it to both the data used by the researchers to see if similar results are found and then apply it to a separate C/C++ code base such as OpenJ9 [5] or OpenJDK [6] (or both).
        Ideally, one of the outcomes of this project would be to compare the results found with Approach A versus Approach B when applied against the same codebase.  A second outcome of this work would be to incorporate an interim verification check against a source code repository, perhaps on the cadence of every time a new tag is applied.

        Reference Links
        [1] https://web.cs.ucdavis.edu/~devanbu/teaching/289/Schedule_files/Kim-Predicting.pdf
        [2] https://github.com/adoptium/aqa-test-tools/tree/master/BugPredict/BugTool
        [3] https://www.sciencedirect.com/science/article/abs/pii/S0164121220301138
        [4] https://www.earthdata.nasa.gov/about/data-metrics
        [5] https://github.com/eclipse-openj9/openj9
        [6] https://github.com/adoptium/jdk

        Links to Eclipse Projects / Repositories

        https://projects.eclipse.org/projects/adoptium.aqavit
        https://projects.eclipse.org/projects/adoptium.temurin
        https://projects.eclipse.org/projects/technology.openj9
        https://github.com/adoptium/aqa-tests
        https://github.com/adoptium/aqa-test-tools
        https://github.com/eclipse-openj9/openj9
        https://github.com/adoptium/jdk (mirror of upstream repository)

        Expected outcomes 


        Trialing 2 different approaches (implemented as static analysis 'utilities’) to predict source code defects in a given source code base


        A comparison of the 2 approaches (do they identify the same files in a code base as ‘most likely’ containing bugs)


        An additional way to flag areas of code that need more scrutiny during code reviews and a greater emphasis during testing


        A verification check (or workflow, a.k.a. GlitchWitcher) that runs these static analysis utilities against pull requests in a repository



        Skills required/preferred 


        Languages & Frameworks: Python (for ML and automation), Git APIs, NLP libraries (e.g., SpaCy, BERT, GPT-based models).  Awareness of different classifiers (Gaussian Naive Bayes, logistic regression, k-nearest-neighbors, decision tree, and Hybrid SMOTE-Ensemble) and statistical analysis will be helpful.


        CI/CD Integration: GitHub Actions, Jenkins


        Database & Storage: MongoDB (or PostgreSQL/MySQL) for storing historical build data and test results.


        Deployment: integration with current development workflow and pipelines



        Project size 
        350 hours

        Possible mentors: 

        Lan Xia lan_xia@ca.ibm.com

        Longyu Zhang longyu.zhang@ibm.com

        Shelley Lambert slambert@redhat.com



        Rating 
        medium - hard


        ~~~~~~~~~~

        CommitHunter: AI-Powered Commit Debugger

        Description 
        The goal of this project is to develop an automated system that identifies problematic Git commits causing test failures in both performance and non-performance test scenarios. Given a "Good" build (where tests pass) and a "Bad" build (where tests fail), the system will analyze all intermediate commits to pinpoint the problematic commit(s). The approach will evolve from rule-based methods to AI-driven models for higher accuracy.
        Phase 1: Rule-Based Approach
        Use Rule based approach and below are some examples:

        String Matching: Identify test failure messages and correlate them with commit messages, logs, or diffs.
        Binary Search for Performance Tests: Implement a binary search approach to efficiently narrow down the commit range in performance test failures.

        Phase 2: Machine Learning Model

        Train an ML model using historical build data, commit logs, and failure reports.
        Utilize supervised learning techniques to classify commits as "Likely Problematic" or "Safe."
        Use natural language processing (NLP) to analyze commit messages and correlate them with test failures.

        Phase 3: Automation and Integration

        Integrate the approach with Git repositories (e.g., GitHub) via APIs.
        Develop a bot to automatically comment on Git issues with the identified problematic commit(s) if confidence levels meet a reliability threshold.
        Provide a dashboard for tracking identified problematic commits and their validation over time.


        Links to Eclipse Project


        https://github.com/eclipse/openj9
        https://github.com/adoptium/aqa-tests
        https://github.com/adoptium/aqa-test-tools
        https://projects.eclipse.org/projects/technology.openj9
        https://projects.eclipse.org/projects/adoptium.aqavit


        Expected outcomes 

        Reduction in manual effort needed to debug and triage test failures.
        Faster identification of problematic commits leading to improved development efficiency.
        A scalable system that can be expanded with improved AI models that can apply to other project and team.


        Skills required/preferred 

        Languages & Frameworks: Python (for ML and automation), Git APIs, NLP libraries (e.g., SpaCy, BERT, GPT-based models).
        CI/CD Integration: GitHub Workflow, Jenkins
        Database & Storage: MongoDB (or PostgreSQL/MySQL) for storing historical build data and test results.
        Deployment: integration with current development workflow and pipelines.


        Project size 
        350 hours

        Possible mentors: 

        Shelley Lambert slambert@redhat.com

        Lan Xia lan_xia@ca.ibm.com

        Longyu Zhang longyu.zhang@ibm.com



        Rating 
        Medium - hard







      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/eclipse-foundation/
    idea_list_url: https://gitlab.eclipse.org/eclipsefdn/emo-team/gsoc-at-the-ef/-/issues/?sort=due_date&state=opened&label_name%5B%5D=Project%20Idea&label_name%5B%5D=GSoC%202025&first_page_size=50


  - organization_id: 37
    organization_name: Electron
    no_of_ideas: 7
    ideas_content: |
          Electron Documentation PR Previews
          Size: 175 Hours (Medium)
          Difficulty: Medium
          Tags: JavaScript, Static Site Generators, MDX, Automation, GitHub Actions
          Scope: Electron maintains its documentation as MDX files in the main electron/electron repository, but the website lives in a separate repo that pulls in the docs as content via webhook.
          There’s a disconnect in our system between when docs get merged and when they appear on the website, so it’s easy for formatting issues to appear. This project would aim to create automation tooling that would create an ephemeral deployment of the website for each PR containing doc changes which previews the website with the changes, and link it as a comment on the PR.
          A previous version of this project idea referenced Heroku Review Apps as the technology of choice for implementation. While we still have access to Heroku deployments, the website has migrated its PR deploys to use Cloudflare Pages instead. Either technology would be available for a GSoC project.
          Success Criteria: A successful project will produce documentation PR previews and create a comment on PRs linking that preview. Ideally, previews from PRs coming from forks would still work.
          Skills:
          TypeScript/JavaScript (required)
          Resources:
          Website Repo: https://github.com/electron/website
          Heroku Review App APIs: Platform API Reference | Heroku Dev Center
          Cloudflare Preview Deployments
          Mentors:
          @dsanders11
          @erickzhao
          @yangannyx

          ~~~~~~~~~~
          Save/Restore Window State API
          Size: 175 Hours (Medium)
          Difficulty: Hard
          Tags: Electron Core, Feature, Chromium, C++, API development
          Scope: Currently Electron does not have any built-in mechanism for saving and restoring the state of BrowserWindows, but this is a very common need for apps that want to feel more native. Create an API in Electron to save, restore, and clear window state: position, size, maximized state, etc.
          Success Criteria:
          API spec is accepted by Electron’s API working group
          New window state API is added to the BrowserWindow module and merged into the main branch for a future Electron release
          Proper API documentation is added
          Skills:
          C++ (required)
          Resources:
          GitHub issue tracker discussion: https://github.com/electron/electron/issues/526
          Popular userland module for this feature: GitHub - mawie81/electron-window-state: A library to store and restore window sizes and positions for your Electron app https://github.com/mawie81/electron-window-state
          Electron’s BrowserWindow API docs
          Mentors:
          @dsanders11
          @vertedinde
          @georgexu99

          ~~~~~~~~~~
          Electron Forge CLI UX Improvements
          Size: 175 Hours (Medium)
          Difficulty: Medium
          Tags: Electron Forge, TypeScript, Node.js, Bash, CLI tools
          Scope: Electron Forge is a complete tool for building and publishing Electron applications. In 2022, Forge became the official packaging tool for Electron. However, Forge’s CLI is not as user friendly and modern as other tools in the JS ecosystem. This project would update the UX for the Forge CLI to make it easier for developers to create new Electron apps entirely from the command line.
          Success Criteria:
          The Electron Forge CLI is updated to include accurate flows from init, start, package and other major commands and expanded to allow configuring the options most commonly used by users.
          A new interactive mode to allow for a more user friendly experience.
          Tested cross-platform on Mac, Windows and Linux
          Stretch goals would include adding new features to the CLI
          Skills:
          Typescript/Javascript (required)
          Bash (recommended)
          Node.js (recommended)
          Resources:
          Electron Forge Documentation: https://www.electronforge.io/
          Forge Docs Repo: https://github.com/electron-forge/electron-forge-docs
          Mentors:
          @dsanders11
          @erickzhao
          @blackhole1

          ~~~~~~~~~~
          Electron Fiddle in VS Code
          Size: 175 Hours (Medium)
          Difficulty: Medium
          Tags: Electron Fiddle, TypeScript, Node.js, VS Code
          Scope: Electron Fiddle is a standalone tool used daily by Electron maintainers to help debug and fix issues reported in Electron, and is the best way for developers to provide minimal repro cases for their bug reports. This project would involve taking the internals of Electron Fiddle and integrating them as a VS Code extension, to allow using Fiddle’s logic without leaving the IDE, and more easily use Fiddle with a local build of Electron. This would require a reimagining of the Electron Fiddle UX to work within the constraints of the UI/UX available to VS Code extensions, rather than a 1:1 port of the UI from the standalone Electron Fiddle.
          Success Criteria:
          A working VS Code extension which integrates @electron/fiddle-core to provide an Electron Fiddle experience, with emphasis on more easily working with local builds of Electron.
          Ability to import/export GitHub Gists, integrating with VS Code’s existing GitHub auth.
          Skills:
          TypeScript/JavaScript (required)
          Node.js (preferred)
          Resources:
          Electron Fiddle: https://electronjs.org/fiddle
          fiddle-core repo, with Fiddle’s core logic: https://github.com/electron/fiddle-core
          Visual Studio Code Extension API
          Mentors:
          @dsanders11
          @blackhole1
          @georgexu99

          ~~~~~~~~~~
          Releases Working Group Calendar Website
          Size: 175 Hours (Medium)
          Difficulty: Easy/Medium
          Tags: Electron, web, APIs
          Scope: Electron’s Releases Working Group currently have several tracks of automation that help us track and communicate details about Electron’s major stable releases. However, the various tracks of automation are currently disjointed, and don’t always communicate with each other. Additionally, we depend on an upstream Chromium release schedule that we update manually, a process we would like to automate.
          Success Criteria: This project asks the contributor to 1) add new automation to allow Electron to pull dates from Chromium’s upstream API and 2) make a barebones Release calendar website that the Electron team can view, based on Chromium's alpha, beta and stable release dates.
          Going above and beyond could include:
          Creating a page on releases.electronjs.org with the information
          Setting up a bot that allows the Electron team to update the calendar automatically or add additional dates and details
          Alerting #wg-releases and updating the calendar automatically if upstream dates change
          Skills:
          TypeScript/JavaScript (required)
          Express (preferred)
          HTML/CSS (preferred)
          Resources:
          Chromium’s releases API - https://chromiumdash.appspot.com/schedule
          Releases website - https://releases.electronjs.org/
          Release website repo - https://github.com/electron/release-status
          Mentors:
          @dsanders11
          @vertedinde
          @yangannyx

          ~~~~~~~~~~
          Electron Fiddle Support for Fuses
          Size: 175 Hours (Medium)
          Difficulty: Easy/Medium
          Tags: Electron Fiddle, TypeScript, Node.js
          Scope: Electron Fiddle is a standalone tool used daily by Electron maintainers to help debug and fix issues reported in Electron, and is the best way for developers to provide minimal repro cases for their bug reports. Electron fuses are feature toggles that are set when packaging an Electron app to enable / disable certain features / restrictions. Currently Electron Fiddle has no support for setting these fuses when running a fiddle, so it cannot be used to to provide repro cases for bug reports involving specific fuse settings. This project would add support to Fiddle for setting fuses before running the fiddle, and include the fuse values in any fiddles uploaded to GitHub Gists.
          Success Criteria:
          An intuitive UI is added to Electron Fiddle which allows users to view and toggle values for Electron fuses to be set on the next run.
          Fuse values are included in fiddles uploaded to a GitHub gist, and fuse values are set when loading a fiddle from a GitHub gist.
          Skills:
          TypeScript/JavaScript (required)
          Node.js (preferred)
          React (preferred)
          HTML/CSS (preferred)
          Resources:
          Electron Fiddle: https://electronjs.org/fiddle
          fiddle-core repo, with Fiddle’s core logic: https://github.com/electron/fiddle-core
          Electron fuses repo: https://github.com/electron/fuses
          Electron’s fuses docs
          Mentors:
          @dsanders11
          @erickzhao  
          @vertedinde

          ~~~~~~~~~~
          Restore Electron Devtron Extension
          Size: 175 Hours (Medium)
          Difficulty: Medium
          Tags: JavaScript, TypeScript, Chrome Extension, IPC, Developer Tool
          Scope: Inter-process communication (IPC) is a key part of building feature-rich desktop applications in Electron. App developers getting started with Electron often struggle in understanding IPC concepts and how to work with them; multiple processes and finding where IPC is sent and received isn’t straightforward. Devtron was a Chrome extension available for Electron which brought visibility to IPC events by adding a new tab under Chrome DevTools where each IPC event was logged. It was eventually deprecated due to a lack of available maintainers, and an aging codebase. This project would modernize the existing Devtron codebase or create a new Chrome extension from scratch (many APIs in Chrome and Electron have changed in the 10 years since Devtron was created) to fill this continuing need for app developers.
          Success Criteria:
          A successful project will produce a Chrome extension that, when installed to Electron, displays IPC events sent between processes.
          Skills:
          TypeScript/JavaScript (required)
          Chrome Extensions (preferred)
          Resources:
          Deprecated Devtron: 
          Chrome Extensions: Extend DevTools
          Electron’s IPC docs
          Mentors:
          @dsanders11
          @samuelmaddock
          @yangannyx
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/electron/
    idea_list_url: https://electronhq.notion.site/Electron-Google-Summer-of-Code-2025-Ideas-List-1851459d1bd1811894dad8b48a68596d

  - organization_id: 38
    organization_name: FFmpeg
    no_of_ideas: 6
    ideas_content: |
      
      WebRTC-HTTP ingestion protocol (WHIP)
      Description: The WHIP task only requires the implementation of basic streaming capabilities as outlined in https://www.ietf.org/archive/id/draft-ietf-wish-whip-16.txt. Given that WebRTC itself is extremely large and complex, FFmpeg has no plans to fully implement WebRTC capabilities in the short term. Therefore, it will only support the most basic ICE interaction capabilities, the most basic DTLS capabilities, and minimal modifications to FFmpeg's RTP/RTCP workflow to enable WHIP support.
      Expected results: This will allow FFmpeg users to quickly utilize FFmpeg for WHIP streaming.
      Prerequisites: Good C code, basic familiarity with Git, and basic knowledge of network transport protocols.
      Difficulty: Medium to Hard
      Qualification Task: Fix a random bug in an existing muxer, demuxer or protocol.
      Mentor: Steven Liu (lingjiujianke at gmail dot com)
      Backup Mentor: Zhao Jun (barryjzhao at tencent dot com)
      Duration: 350 hours

      ~~~~~~~~~~
      ProRes Vulkan decoder
      Description: Decoding of ProRes is quite important, as its the default mezzanine codec used in production. The bandwidth and CPU requirements for 4k and 8k streams are high, therefore, having a Vulkan-based implementation would be able to speed up the workflow of users, particularly those who do editing.
      Expected results: Write a ProRes decoder in Vulkan, specifically supporting the ap4h and ap4x profiles.
      Prerequisites: Good C, GLSL, and Vulkan knowledge.
      Difficulty: Hard
      Qualification Task: Write and validate the ProRes DCT transform in GLSL.
      Mentor: Lynne (Lynne in #ffmpeg-devel on Libera.Chat IRC)
      Backup Mentor: Niklas Haas (haasn in #ffmpeg-devel on Libera.Chat IRC)
      Duration: 350 hours

      ~~~~~~~~~~
      VVC wasm simd optimization
      Description: Using WASM SIMD to optimize VVC decoding performance in WASM environment (web browser or wasi)
      Expected results: Add ALF, inter, and SAO implementation. More is better.
      Prerequisites: Good C knowledge, basic shell script skills and understanding of compilation and build processes.
      Difficulty: Medium.
      Qualification Task: Fix a random bug in FFmpeg. Build and run ffmpeg checkasm in wasm. It's easy to be done with wasi runtime like wasmtime.
      Mentor: Zhao Zhili (zhilizhao at tencent dot com)
      Backup Mentor: Nuo Mi (nuomi2021 at gmail dot com)
      Duration: 350 hours

      ~~~~~~~~~~
      VVC ARM simd optimization
      Description: Using ARM simd to optimize VVC decoding performance in arm64 environment.
      Expected results: Implement inverse transform and intra prediction using arm64 instructions.
      Prerequisites: Good C knowledge. Basic ARM assembly programming skills.
      Difficulty: Hard.
      Qualification Task: Fix a random bug in FFmpeg. Build and run ffmpeg checkasm in arm64.
      Mentor: Zhao Zhili (zhilizhao at tencent dot com)
      Backup Mentor: Nuo Mi (nuomi2021 at gmail dot com)
      Duration: 350 hours

      ~~~~~~~~~~
      VVC x86 simd optimization
      Description: Using x86 simd to optimize VVC decoding performance in x86 environment.
      Expected results: Implement inverse transform or intra prediction using x86 instructions.
      Prerequisites: Good C knowledge. Basic x86 assembly programming skills.
      Difficulty: Hard.
      Qualification Task: Any patch merged by ffmpeg
      Mentor: Nuo Mi (nuomi2021 at gmail dot com)
      Backup Mentor: Lynne (Lynne in #ffmpeg-devel on Libera.Chat IRC)
      Duration: 350 hours
      
      ~~~~~~~~~~
      VP6 encoder
      Description: Write a basic non-performant progressive VP6 encoder, starting with keys frames and adding motion compensation frames later.
      Expected results: Bitstreams produced by the encoder are decodable using FFmpeg VP6 decoder and original On2 VP6 decoder binary.
      Prerequisites: Good C knowledge, some understanding of MPEG-type video compression would be useful.
      Difficulty: Medium.
      Qualification Task: Fix a random bug in FFmpeg _or_ extend libavcodec/vpx_rac.h to support encoding
      Mentor: Peter Ross (pross at xvid dot org)
      Backup Mentor: will be choosen before project begin, the admins will serve as backup before that
      Duration: 350 hours
     
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/ffmpeg/
    idea_list_url: https://trac.ffmpeg.org/wiki/SponsoringPrograms/GSoC/2025

  - organization_id: 39
    organization_name: FLARE
    no_of_ideas: 10
    ideas_content: |
      


      capa: add Binary Ninja Explorer plugin
      size: medium, estimated 175 hours
      difficulty: medium
      mentors: @williballenthin
      link: mandiant/capa#169
      capa is the FLARE team's open-source tool to identify program capabilities using an extensible rule set.
      Binary Ninja (Binja) is a modern disassembler and reverse engineering tool with a robust Python API that facilitates plugin development. A capa Explorer plugin for Binary Ninja would significantly enhance the workflow of reverse engineers who use Binja, allowing them to seamlessly identify and analyze program capabilities within their preferred environment. This project would not only benefit Binja users but also expand the reach and adoption of capa within the reverse engineering community.
      The core functionality of the plugin would be to:
      Use capa's existing Binary Ninja backend to find capabilities in the currently open binary.
      Display the capa results in a user-friendly manner within Binary Ninja. This includes displaying matching rules, the locations of matched features, and potentially the associated source code (if debug information is available).
      Allow users to navigate from the capa results to the corresponding locations in the disassembly view. This is crucial for efficient analysis, enabling users to quickly jump to the code responsible for a detected capability.
      Deliverables:
      Results Display:
      Implement a custom dock widget (view) in Binary Ninja to display the capa results.
      Display a hierarchical tree view of matching rules, grouped by namespace (e.g., "anti-analysis", "communication").
      Show the rule name, description (short summary), and match status.
      Display the locations (addresses) of matched features within each rule.
      Implement filtering and searching capabilities within the results view. Allow users to filter rules by namespace, ATT&CK technique, or keyword.
      Highlight matched features directly in the disassembly view using Binary Ninja's highlighting API.
      Navigation:
      Enable double-clicking on a rule or feature location in the results view to navigate to the corresponding address in the Binary Ninja disassembly view. Highlight the relevant instruction(s).
      Add tags/bookmarks for the matches.
      Rule Selection:
      Basic UI for user to select a file path that contains the rulesets they'd like to use.
      Testing and Documentation:
      Write basic unit tests for the plugin's core functionality.
      Create user documentation explaining how to install and use the plugin.
      Blog Post:
      Document the development process and findings in a blog post suitable for publication on the Mandiant blog or a similar platform.
      Required Skills:
      Solid knowledge of Python 3.
      Experience with Binary Ninja's API (or strong willingness to learn).
      Basic understanding of reverse engineering concepts (disassembly, assembly language, executable file formats).
      Experience with Git and GitHub.
      Potential Challenges and Mitigation Strategies:
      Binary Ninja API Learning Curve: Binary Ninja's API is extensive, but well-documented. The contributor should allocate time for learning the API and exploring existing plugins. The mentors can provide guidance and point to relevant examples.
      Performance Optimization: Running capa on large binaries can be time-consuming. The plugin should be designed to handle large analysis results efficiently and provide progress feedback to the user. Asynchronous execution and caching strategies can be employed.
      UI Design: Provide the user an intuitive way to interact with the plugin.
      
      ~~~~~~~~~~
      capa: add Ghidra Explorer plugin
      size: medium, estimated 175 hours
      difficulty: medium
      mentors: @mike-hunhoff
      link: mandiant/capa#1980
      capa is the FLARE team's open-source tool to identify program capabilities using an extensible rule set. Currently, analysts often invoke capa as a command-line tool or via the capa Explorer plugin for IDA Pro. This project aims to bring the interactive rule exploration experience of capa Explorer to Ghidra, a powerful and extensible reverse engineering platform developed by the NSA.
      Ghidra is a free and open-source software reverse engineering (SRE) framework. It includes a suite of tools for analyzing compiled code on a variety of platforms. Ghidra's extensibility is a key feature, and recently, the PyGhidra project has provided Python bindings for the Ghidra API, enabling plugin development in Python. A capa Explorer plugin for Ghidra would greatly enhance the workflow of reverse engineers who rely on Ghidra, allowing them to seamlessly integrate capa's capability detection into their analysis process. This project would benefit both Ghidra users and expand the user base of capa.
      The core functionality of the plugin would be to:
      Use capa's existing Ghidra backend to find capabilities in the currently open binary.
      Display the capa results in a user-friendly manner within Ghidra. This includes showing matching rules, the locations of matched features (addresses, function names, etc.), and potentially linking to the relevant decompiler output.
      Allow users to navigate from the capa results to the corresponding locations in the Ghidra disassembly listing and decompiler views. This is critical for efficient analysis, enabling users to quickly jump to the code associated with a detected capability.
      Deliverables:
      Results Display:
      Implement a custom Ghidra Tool window or panel to display the capa results.
      Display a hierarchical tree view of matching rules, grouped by namespace (e.g., "anti-analysis", "communication").
      Show the rule name, description, and match status.
      Display the locations of matched features within each rule.
      Implement filtering and searching capabilities within the results view. Allow users to filter rules by namespace, ATT&CK technique, or keyword.
      Highlight matched features directly in the Ghidra listing view using Ghidra's highlighting API.
      Navigation:
      Enable double-clicking on a rule or feature location in the results view to navigate to the corresponding address in the Ghidra disassembly listing view.
      Highlight the relevant instructions.
      Rule Selection:
      Provide a basic UI for the user to select the file path containing the desired rulesets.
      Testing and Documentation:
      Write basic unit tests for the plugin's core functionality.
      Create user documentation explaining how to install and use the plugin.
      Blog Post:
      Document the development process, challenges and finding in a blog post.
      Required Skills:
      Solid knowledge of Python 3.
      Experience with Ghidra and PyGhidra (or strong willingness to learn). Familiarity with Java is a plus, but not strictly required due to PyGhidra.
      Basic understanding of reverse engineering concepts (disassembly, assembly language, executable file formats).
      Experience with Git and GitHub.
      Potential Challenges and Mitigation Strategies:
      PyGhidra Learning Curve: While PyGhidra simplifies Ghidra plugin development, the student will still need to learn the PyGhidra API and how it interacts with Ghidra's underlying Java API. The mentors can provide guidance and point to relevant examples.
      Performance Optimization: Running capa on large binaries can be time-consuming. The plugin should handle large results efficiently and provide feedback to the user. Asynchronous execution and caching can help.
      UI Design: Design the user interface to be intuitive within the Ghidra environment.

      ~~~~~~~~~~
      capa: add Frida dynamic analysis for Android
      size: large, estimated 350 hours
      difficulty: hard
      mentors: @larchchen
      capa is the FLARE team's open-source tool to identify program capabilities using an extensible rule set.
      Frida is a popular dynamic instrumentation toolkit for developers, reverse-engineers, and security researchers, allowing custom scripts injected into black box processes thus monitoring program behaviors. Frida is a particularly preferred option to analyze Android Apps by launching Apps in Android Emulator and intercepting certain function calls.
      In addition to the capa's dependencies on CAPE sandbox during dynamic capabilities detection, Frida is a more friendly alternative for mobile App analysis. With the possibilities of using existing Frida scripts and/or developing new Frida scripts, extending capa's dynamic detection upon logs generated from Frida logs would be a good start. Integrating capa rule matching engine with Frida scripts could be another bonus approach. The goal of this project is to support capa rule matching capabilities in Android via Frida instrumentation framework.
      Deliverables
      Research
      Review capa's existing support of dynamic capabilities detection
      Review Frida's instrumentation framework
      Identify Additions, Changes, and Improvements
      Suggest technical roadmaps to support Frida-capa detection
      Discuss ideas with mentors and capa user community
      Implementation
      Implement ideas aligned with finalized roadmaps
      Evaluation and Knowledge Sharing
      Test deliverables and gather feedback from users
      Write blog post about experience and project achievements
      Required Skills
      Solid knowledge of Python 3
      Solid knowledge of one of JavaScript/C/Go
      Basic understanding of reverse engineering / malware analysis
      Basic understanding of Git
      Basic understanding of Android App analysis using Android Emulator
      Basic understanding of Frida

      ~~~~~~~~~~
      capa: migrate to PyGhidra
      size: small, estimated 90 hours
      difficulty: low
      mentors: @mike-hunhoff
      link: mandiant/capa#2600
      This project aims to modernize the existing capa Ghidra backend by migrating it from the third-party Ghidrathon Python bindings to the officially supported PyGhidra bindings, released with Ghidra 11.3. Since PyGhidra is distributed with Ghidra, we expect this to have better long term support and be easier for users to access. This migration will ensure the long-term maintainability and compatibility of the capa plugin with future Ghidra releases.
      Deliverables:
      Port Existing Functionality: Migrate the existing capa Ghidra backend's code to use the PyGhidra API. This primarily involves updating API calls and adapting to any differences in how PyGhidra interacts with Ghidra.
      Testing: Thoroughly test the migrated plugin to ensure that all existing features function correctly with PyGhidra.
      Documentation Updates: Update the plugin's documentation to reflect the change to PyGhidra and provide installation instructions for users.
      Required Skills:
      Basic Python programming skills.
      Familiarity with Ghidra and its scripting capabilities, or willingness to learn.
      Experience with Git and GitHub.
      Understanding of capa is a plus, but not required for this project.

      ~~~~~~~~~~
      capa: add ARM support to IDA Pro, Ghidra, and/or Binary Ninja backends
      size: small to large
      difficulty: medium
      mentors: @mr-tz
      link: mandiant/capa#1774
      This project aims to extend capa's support for analyzing programs targeting the ARM architecture across its major analysis backends: IDA Pro, Ghidra, and Binary Ninja. While capa's core analysis engine (via the BinExport2 backend) already supports ARM, the backends for these popular disassemblers currently lack direct feature extraction for this architecture. This project will bridge that gap, enabling users to analyze ARM binaries seamlessly within their preferred reverse engineering environments.
      The core task involves extending the existing backends to extract relevant features (instructions, API calls, constants, etc.) from ARM binaries loaded in IDA Pro, Ghidra, and Binary Ninja. This will leverage the respective disassembler APIs to access the disassembled code and program information. The extracted features will then be formatted and passed to capa's core analysis engine.
      Deliverables:
      update capa IDA Pro backend (optional, pick 1-3)
      update capa Ghidra backend (optional, pick 1-3)
      update capa Binary Ninja backend (optional, pick 1-3)
      Testing: Develop test cases (ARM binaries with known capabilities) and verify that capa correctly identifies capabilities in these binaries through each of the extended plugins.
      Documentation: Update the documentation for each plugin to reflect the added ARM support.
      Required Skills:
      Solid Python programming skills.
      Familiarity with at least one of: IDA Pro, Ghidra, or Binary Ninja, and their respective plugin APIs (or willingness to learn quickly).
      Basic understanding of the ARM architecture and assembly language.
      Experience with Git and GitHub.

      ~~~~~~~~~~
      FLOSS: extract language specific strings (.NET, Swift, Zig, ...)
      size: large, estimated 350 hours
      difficulty: medium
      mentors: @mr-tz
      link: mandiant/flare-floss#718
      Various programming languages embed the constant data, like strings, used within executables in different ways. Most tools, like strings.exe, just look for printable character sequences. This doesn't work well for files compiled from Go or Rust.
      Here we propose to extend FLOSS to include a framework to extract language specific strings from executables. After identifying the language, a specific extractor can use specialized logic to pull out the strings embedded into a program by the author. When possible, the extractor should indicate library and runtime-related strings. For example, the extractor may parse debug information to recognize popular third party libraries and annotate the related strings appropriately.
      Today, FLOSS automatically deobfuscates protected strings found in malware. Better categorization of its output would make its users more efficient. Extracting language-specific strings would make FLOSS more useful and manifest success as the default tool used by security analysts.
      Deliverables
      Develop language identification module
      Initial focus on .NET
      Consider also Swift, Zig, …
      Research language string embeddings and create extractor code
      We can share existing knowledge and code to bootstrap this
      Identify strings related to runtime and library code for targeted programming languages
      Extend standard output format and render results
      Required Skills
      Medium knowledge of Python 3
      Basic understanding of reverse engineering (focus: Windows PE files)
      Experience with .NET or Swift (internals) is a plus, but not required
      Interest in malware analysis with focus on static analysis
      Basic understanding of Git

      ~~~~~~~~~~
      FLOSS: QUANTUMSTRAND
      size: large, estimated 350 hours
      difficulty: medium
      mentors: @williballenthin
      link: mandiant/flare-floss#943
      Extend FLOSS to use the rendering techniques pioneered by QUANTUMSTRAND.
      QUANTUMSTRAND is an experiment that augments traditional strings.exe output with context to aid in malware analysis and reverse engineering. For example, we show the structure of a file alongside its strings and mute/highlight entries based on their global prevalence, library association, expert rules, and more.
      FLOSS is a tool that automatically extracts obfuscated strings from malware, rendering the human-readable data in a way that enables rapid reverse engineering.
      We propose to extend FLOSS to use the techniques pioneered by QUANTUMSTRAND to highlight important information while muting common and/or analytically irrelevant noise. The project will provide an opportunity to dig into the PE, ELF, and/or Mach-O file formats, finding ways to make technical details digestible. If successful, FLOSS will continue to be the tool that malware analysts turn to when triaging unknown files.
      Deliverables
      Brand new output format released as part of FLOSS v4 in late 2025.
      Research
      Review Quantumstrand functionality
      Evaluate most useful features for integration into FLOSS
      Identify and Propose Improvements
      Suggest improvements for the user interface and experience
      Discuss ideas with mentors and FLOSS user community
      Implementation
      Implement improved functionality
      [stretch goal]: Work on a GUI to interactively display FLOSS results
      Evaluation and Knowledge Sharing
      Test improvements and gather feedback from users
      Write blog post about experience and project achievements
      Required Skills
      Solid knowledge of Python 3
      Basic understanding of reverse engineering / malware analysis
      Basic understanding of Git
      Experience or interest with file formats such as PE, ELF, and/or Mach-O
      Experience or interest in user interface and/or user experience design

      ~~~~~~~~~~
      BinDiff: rearchitect Binary Diff Server and port to PyQt
      size: large, estimated 350 hours
      difficulty: hard
      mentors: @cblichmann
      link: google/bindiff#17
      This project aims to modernize BinDiff by re-architecting it as a cross-platform "diffing service" with a unified UI layer. The core idea is to separate the diffing engine from the user interface. A "diff server," implemented (likely in C++ or Rust for performance), will handle the core diffing logic. This server will load BinExport files and perform the diffing computations. It will communicate with client plugins via a protocol like gRPC.
      Client plugins will be developed for IDA Pro and Binary Ninja, using a shared Python codebase and PyQt for the UI. Each disassembler will have a small, platform-specific module to handle tasks like symbol porting. This architecture promotes code reuse and simplifies maintenance. Keeping the diff server running in the background allows for dynamic re-diffing as binaries are modified, and opens up possibilities for improved flow graph visualization by combining data from multiple functions.
      The project scope is intentionally flexible, allowing the student and mentors to collaboratively define the specific features and implementation details. The focus will be on establishing a solid foundation for the new architecture and demonstrating its feasibility.
      Deliverables (Flexible, to be refined during the project):
      Diff Server Prototype:
      Design and implement a basic "diff server" that can load BinExport files and perform a simple diffing algorithm.
      Implement a communication protocol (e.g., gRPC) for interaction with client plugins.
      Shared UI Library (Python/PyQt):
      Develop a shared Python library using PyQt that provides the core UI components for displaying diffing results. This includes views for function lists, matched/unmatched functions, and potentially basic flow graph comparisons.
      IDA Pro and Binary Ninja Plugins:
      Create basic plugins for IDA Pro and Binary Ninja that utilize the shared UI library and communicate with the diff server.
      Implement symbol porting.
      Demonstrate basic diffing functionality within each disassembler.
      Proof of Concept:
      Demonstrate the ability to load two BinExport files, perform a diff, and display the results in both IDA Pro and Binary Ninja.
      Documentation:
      Document the design, architecture, and API of the diff server and client plugins.
      Required Skills:
      Solid knowledge of Python 3 and C++ and/or Rust.
      Experience with or willingness to learn PyQt.
      Experience with or willingness to learn gRPC.
      Basic understanding of binary diffing concepts.
      Familiarity with IDA Pro and Binary Ninja APIs (or strong willingness to learn).
      Experience with Git and GitHub.
      Potential Challenges:
      Defining the Scope: The open-ended nature of the project requires careful planning and communication between the student and mentors to define achievable goals.
      Inter-process Communication: Choosing and implementing an efficient and reliable communication protocol between the diff server and client plugins will be crucial.

      ~~~~~~~~~~
      XRefer: Build a Multi-Backend Abstraction Layer with Binary Ninja Support
      size: large, estimated 360 hours
      difficulty: medium
      mentors: @m-umairx
      XRefer is tightly coupled with IDA Pro, making it challenging to adapt for use with other popular reverse-engineering platforms like Ghidra or Binary Ninja. This project aims to refactor XRefer's core analyzer component, creating a new backend abstraction layer that standardizes how different platforms interact with the plugin's logic. Additionally, the project aims to aid support for Binary Ninja by implementing a new PoC backend.
      Note: This project focuses on creating and demonstrating an abstraction layer for XRefer's underlying analysis engine only. The user interface is not included in the project scope.
      Deliverables:
      Code Review
      Identify and document all places where IDA-specific APIs or data structures are used within the analyzer and lang components.
      Assess the feasibility and scope of decoupling those calls into a new abstraction layer.
      Design a Backend Interface
      Specify the APIs needed for core tasks (e.g., disassembly, cross-references, function discovery, flow analysis) that different backends must implement.
      Draft an interface or set of classes that each supported platform (IDA, Ghidra, Binary Ninja, etc.) can plug into with minimal friction.
      Refactor XRefer
      Migrate IDA-specific logic into a separate module or wrapper.
      Adapt XRefer's main codebase to use the newly created backend interface rather than direct IDA calls.
      Proof-of-Concept for Additional Backends
      Implement a PoC backend using Binary Ninja's API.
      Demonstrate how XRefer can run independently of IDA using the newly defined backend interface to generate a .xrefer analysis file.
      Outline best practices for future contributors to add and maintain backends.
      Required Skills
      Proficiency in Python programming language.
      Experience with (or strong willingness to learn) IDA's Python API.
      Experience with (or strong willingness to learn) Binary Ninja's API.
      Basic understanding of reverse engineering and underlying concepts (disassembly, functions, cross-references) and executable file formats.
      Basic knowledge of Git/Github.

      ~~~~~~~~~~
      XRefer: HTML Exporter and Visualizer for XRefer's Cluster Analysis
      size: medium, estimated 160 hours
      difficulty: low
      mentors: @m-umairx
      The goal of this project is to design and implement an HTML export module for XRefer. The module will convert XRefer's internal cluster analysis data into a dynamic HTML visualization. This interactive output should allow users to:
      View Cluster Graphs: Render detailed graphs illustrating the relationships between clusters.
      Read Semantic Descriptions: Provide natural language explanations for each cluster and its contained functions.
      Interact with Data: Offer interactive controls (e.g., zoom, pan, node selection, filtering) to explore and analyze clusters in depth.
      Deliverables:
      Design and Architecture
      Develop an intuitive UI/UX design that outlines how clusters and their semantic descriptions will be presented. Consider interactive elements such as zoomable graphs, clickable nodes, and filtering options.
      Evaluate and choose suitable front-end libraries or frameworks (e.g., D3.js, Cytoscape.js) for rendering graphs and managing interactivity.
      Develop the HTML Export Module
      Create a Python module to convert XRefer's cluster analysis data into a format consumable by the front-end (e.g., JSON).
      Develop a responsive HTML template that integrates the chosen visualization libraries. The template should include placeholders for cluster graphs, semantic descriptions, and interactive controls.
      Implement features such as zoom, pan, node highlighting, and tooltips to enhance the user's exploratory experience.
      Integrate the export module into the existing XRefer workflow so that a .html file is generated as part of the analysis process.
      Documentation
      Document the design decisions, data transformation process, and integration steps to help future contributors extend or maintain the module.
      Required Skills
      Proficiency in Python programming language.
      Familiarity with HTML, CSS, and JavaScript for building interactive web interfaces.
      Experience with visualization libraries (e.g., D3.js, Cytoscape.js) or willingness to learn how to implement interactive graphs.
      Ability to conceptualize and design an intuitive user interface that effectively presents complex data.
      Basic knowledge of Git/Github.
      GoReSym: project in scope
      mentors: @stevemk14ebr
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/flare/
    idea_list_url: https://github.com/mandiant/flare-gsoc/blob/2025/doc/project-ideas.md


  - organization_id: 40
    organization_name: FOSSASIA
    no_of_ideas: 15
    ideas_content: |

        1. Enhance Usability of the eventyay Badge Creator
        Description: The goal of this project is to streamline the process of generating and printing badges for eventyay. Organizers often need to print badges on the spot for attendees and speakers during check-in. The project will focus on adding a user-friendly badge customization feature in the frontend, ensuring seamless badge generation in the backend, and integrating with the check-in system to allow for on-site printing. Specifically, the tasks include:
        Badge Design and Customization
        Backend API Enhancements
        Check-In App Integration for On-Site Printing
        Print Service and Configuration
        Containerization & Deployment
        Performance and Scalability
        Documentation and Testing
        Repository URLs: 
        1. https://github.com/fossasia/eventyay-tickets
        2.https://github.com/fossasia/eventyay-tickets-exhibitors 


        Expected outcome: 
        Organizers can create custom badges for different user groups (speakers, attendees, volunteers, etc.).
        Attendees are able to check in quickly and receive a printed badge on the spot via the integrated check-in app.
        The system is fully documented and containerized, making it easy to set up for events of varying sizes.
        Comprehensive tests ensure reliability and maintainability of the new badge-related features.


        Skills required/preferred: 
        Python (Django backend)
        JavaScript (Ember.js for frontend in open-event-frontend)
        Docker & Kubernetes (containerization and deployment)
        CI/CD (to automate builds, tests, and deployments)
        Familiarity with printing workflows and/or label printing software (preferred)
        Possible mentors: hongquan, marcoag, norbusan, cweitat, DonChiaQE, shaunBoahCodes
        Expected Size: 350 hours
        Difficulty level: Intermediate

        ~~~~~~~~~~
        2. Convert eventyay-tickets VueJS implementation to Single Page application
        Description: The current eventyay-tickets system, built with VueJS, uses a traditional multi-page approach. While functional, this architecture can lead to slower page transitions, higher latency, and a less responsive user experience. The proposed project aims to refactor the existing implementation into a full Single Page Application (SPA) that leverages modern VueJS techniques for client-side routing, state management, and lazy loading.
        Key components of the project include:
        Routing and Navigation
        Integrate Vue Router to handle all in-app navigation without full page reloads.
        Design a smooth and intuitive navigation experience that includes dynamic routing for ticket details, user profiles, and event overviews.
        State Management
        Utilize Vuex (or an equivalent state management solution) to manage application-wide state.
        Ensure that ticket data, user sessions, and event information are synchronized across all components.
        Performance Optimization
        Implement code splitting and lazy loading to minimize initial load times and improve overall performance.
        Optimize API interactions to efficiently fetch and update data without redundant network requests.
        UI/UX Enhancements
        Redesign critical user interfaces to align with SPA principles, offering a more fluid and interactive experience.
        Enhance error handling, loading indicators, and overall responsiveness to create a seamless experience for users on various devices.
        Progressive Enhancement and Backward Compatibility
        Ensure that the new SPA implementation gracefully degrades for users with JavaScript disabled or limited browser support.
        Provide fallbacks and clear communication for any features that depend on modern browser capabilities.
        Testing and Documentation
        Develop a suite of unit, integration, and end-to-end tests to ensure robust functionality throughout the transition.
        Update documentation to reflect the new SPA architecture and guide future contributors in maintaining the codebase.
        Repository URL
        eventyay-tickets Repository
        Expected Outcome
        At the end of the project, the eventyay-tickets system will:
        Operate as a fully functional Single Page Application, resulting in faster navigation and a more engaging user experience.
        Offer a robust and maintainable codebase with modern state management and routing practices.
        Include comprehensive testing and clear documentation to facilitate future development and onboarding of contributors.
        Seamlessly integrate with existing eventyay services while ensuring backward compatibility where needed.
        Skills Required/Preferred
        JavaScript & VueJS: Deep understanding of VueJS, including Vue Router and Vuex (or similar state management libraries).
        Front-End Development: Strong grasp of modern front-end development best practices, including component-based architecture and performance optimization.
        Testing Frameworks: Experience with testing tools (e.g., Jest, Cypress) for ensuring code reliability and robustness.
        API Integration: Familiarity with RESTful APIs and efficient data handling in client-side applications.
        UI/UX Design: Ability to create intuitive and responsive interfaces, with attention to detail for user experience improvements.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 350 hours
        Difficulty level: Advanced

        ~~~~~~~~~~
        3. Implement eventyay features as a plugin in eventyay-talk
        Description: The goal of this project is to enhance the design and functionality of eventyay-talk and to integrate it more closely with eventyay-tickets and eventyay-video. While in the first version we already implemented some integration features, this project aims to expand on that work by decoupling the custom functionalities from the core eventyay-talk component. The approach will be to create a modular, admin-manageable plugin that provides seamless integrations without compromising upstream updates.
        Objectives:
        Modular Plugin Architecture:
        Develop an independent admin plugin that encapsulates all eventyay-specific integrations. This ensures that custom features remain separate from the core eventyay-talk codebase, facilitating easier updates and maintenance.
        Enhanced Integration with eventyay-tickets and eventyay-video:
        Integrate ticketing data to display attendee information, session details, and speaker profiles within the discussion threads of eventyay-talk.
        Integrate video content so that related event sessions or live streams are readily accessible from within the talk platform.
        Synchronize user profiles and session metadata across these services for a consistent experience.
        Improved Design and Usability:
        Enhance the overall UI/UX of eventyay-talk to match the branding and design language of the eventyay ecosystem.
        Provide a centralized admin interface where event organizers can configure and control integrations, toggle features, and manage settings without modifying core code.
        Future-Proof and Maintainable Code:
        Keep the integration functionality in-line with upstream eventyay-talk releases, ensuring compatibility and ease of updates.
        Write comprehensive documentation and tests to support long-term maintenance and community contributions.
        Repositories:
        eventyay-talk Repository
        eventyay-tickets Repository
        eventyay-video Repository
        Expected Outcome:
        At the end of the project, the eventyay-talk platform will have a standalone, well-documented plugin that:
        Integrates ticketing and video functionalities directly within the environment.
        Offers a seamless and consistent user experience across eventyay components.
        Is easily configurable through an admin interface, reducing the need to modify core eventyay-talk code.
        Maintains alignment with upstream changes, ensuring long-term compatibility and simplified maintenance.
        Includes robust testing and clear documentation to facilitate future enhancements and community contributions.
        Skills Required/Preferred:
        JavaScript & Frameworks: Strong knowledge of JavaScript and experience with the framework used in eventyay-talk using Vue.js).
        Plugin Architecture: Familiarity with creating modular plugins and extension points in a larger application ecosystem.
        API Integration: Experience with RESTful APIs and backend integrations.
        UI/UX Design: Ability to enhance user interfaces for better usability and consistency across platforms.
        DevOps: Familiarity with Docker, CI/CD, and automated testing to ensure reliable deployment and maintenance.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 175 hours
        Difficulty level: Intermediate

        ~~~~~~~~~~
        4. Upgrade eventyay-video to a Single Page Application with Dashboard, Settings, and Configuration Options for Organisers and Admins
        Description: The current eventyay-video implementation provides basic video functionalities for event streaming and management. However, it lacks an integrated, user-friendly dashboard and administrative interface. This project aims to transform eventyay-video into a modern Single Page Application (SPA) that offers comprehensive dashboards and configuration options for organisers and admins. By upgrading the UI/UX and incorporating advanced settings, the platform will allow seamless management of video content and live sessions, as well as integration with the broader eventyay ecosystem.
        Objectives:
        SPA Conversion and Modernization:
        Refactor the existing eventyay-video codebase to a Single Page VueJS Application.
        Implement client-side routing, lazy loading, and state management to ensure fast, smooth interactions and a responsive user experience.
        Dashboard and Administrative Interface:
        Develop intuitive and fully functional dashboards for organisers and admins to manage video sessions, live streams, and related content.
        Create comprehensive settings and configuration panels that allow users to customize video parameters, manage integrations, and monitor streaming analytics.
        Ensure that the dashboards are secure, scalable, and aligned with eventyay’s overall design language.
        Integration with eventyay Ecosystem:
        Seamlessly integrate with eventyay-tickets and other eventyay modules to synchronize data (e.g., event schedules, session details, user profiles).
        Enable automated configuration and updates from central eventyay administration systems, reducing manual maintenance.
        Enhanced UI/UX and Performance Optimization:
        Redesign the video interface to be more interactive and user-friendly, with emphasis on accessibility and responsiveness across devices.
        Optimize performance using code splitting, efficient API calls, and caching strategies to support large-scale live events and high traffic.
        Testing, Documentation, and Deployment:
        Write comprehensive unit, integration, and end-to-end tests to ensure reliability and performance.
        Document the new features, installation procedures, and administration guides to support future development and community onboarding.
        Leverage Docker and CI/CD pipelines to automate the build, testing, and deployment process, ensuring a robust development workflow.
        Repositories:
        eventyay-video Repository
        Expected Outcome:
        By the end of the project, eventyay-video will:
        Be transformed into a Single Page Application.
        Offer fully functional dashboards for organisers and admins, including robust settings and configuration options.
        Seamlessly integrate with the broader eventyay ecosystem to synchronize event data and manage video content efficiently.
        Include comprehensive testing and documentation, ensuring ease of maintenance and further development.
        Skills Required/Preferred:
        JavaScript & SPA Frameworks: Expertise in VueJS for SPA development, including client-side routing and state management.
        Front-End Development: Strong experience with modern UI/UX design principles and performance optimization.
        Backend Integration: Familiarity with RESTful APIs and integrating front-end applications with backend services.
        DevOps & CI/CD: Knowledge of Docker, Kubernetes, and continuous integration/deployment pipelines.
        Testing & Documentation: Experience writing comprehensive tests (unit, integration, e2e) and maintaining technical documentation.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 350 hours
        Difficulty level: Intermediate

        ~~~~~~~~~~
        5. Add New Integrations of Talks and Speakers component with eventyay Video
        Description: The goal of this project is to seamlessly integrate eventyay-talk with the eventyay-video component, ensuring a unified experience for event organisers and attendees. The project focuses on automating the synchronization between talks and video rooms, as well as enhancing speaker integration. For instance, when rooms are created in eventyay-talk, they should automatically appear in eventyay-video. Additionally, event organisers will have the ability to assign team members as MCs (Masters of Ceremonies) for different rooms, streamlining room management and improving live event coordination. This integration will reduce manual work, ensure data consistency, and provide a coherent user experience across eventyay components.
        Objectives:
        Automatic Room Synchronization:
        Develop functionality to automatically sync room creation and updates from eventyay-talk to eventyay-video.
        Ensure that any changes in the talk component (e.g., room details, schedule updates) reflect in real time on the video side.
        Speaker and Talk Data Integration:
        Integrate detailed talk and speaker information within the eventyay-video interface.
        Display session titles, descriptions, and speaker profiles alongside corresponding video rooms, providing context for viewers.
        MC Assignment Feature:
        Create an admin dashboard interface that enables organisers to assign team members as MCs for various video rooms.
        Implement notifications and role-based permissions to ensure that MCs have the tools and access needed to manage live sessions effectively.
        Unified User Experience:
        Design a consistent and intuitive UI/UX that bridges the gap between eventyay-talk and eventyay-video.
        Include visual cues and real-time status updates to help users navigate between talk sessions and their video counterparts.
        Backend Synchronization & API Enhancements:
        Enhance existing APIs or develop new endpoints to facilitate seamless data exchange between eventyay-talk and eventyay-video.
        Ensure robust error handling and data validation to maintain system reliability.
        Testing, Documentation, and Maintenance:
        Develop comprehensive unit, integration, and end-to-end tests covering all new integration functionalities.
        Provide clear documentation for developers and administrators to ensure ease of future maintenance and onboarding.
        Repositories:
        eventyay-talk Repository
        eventyay-video Repository
        Expected Outcome:
        At the end of the project, the eventyay ecosystem will benefit from:
        Automatic synchronization of rooms between eventyay-talk and eventyay-video, reducing manual intervention.
        Enhanced display of talk and speaker information in the video component.
        A dedicated admin interface for assigning MCs to rooms, ensuring better event management.
        A unified and consistent experience across the eventyay platforms, bolstered by robust API integrations, thorough testing, and clear documentation.
        Skills Required/Preferred:
        JavaScript & Front-End Frameworks: Experience with modern JavaScript frameworks (e.g., Vue.js) used in eventyay components.
        Backend Development: Experience in RESTful API design and integration.
        Integration Development: Experience in connecting disparate systems and ensuring smooth data synchronization.
        UI/UX Design: Strong skills in creating intuitive, responsive, and consistent user interfaces.
        Testing & Documentation: Ability to write comprehensive tests (unit, integration, and end-to-end) and maintain clear technical documentation.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 175 hours (medium project)
        Difficulty level: Intermediate
        
        ~~~~~~~~~~  
        6. Extend Features of the Exhibition Plugin for eventyay
        Description: eventyay currently includes an exhibition system designed to showcase exhibitors during events. This project aims to significantly enhance the existing exhibition plugin by expanding its feature set and improving its usability for both exhibitors and organizers. The new features will empower exhibitors to register and manage their own profiles, add detailed content, embed video links, and link to their social media channels. At the same time, event organizers will gain better control over exhibitor signups, payments, and the publication process. Additionally, the plugin will support integration with event sessions, allowing related sessions to be showcased on the exhibitor’s page, along with the ability to feature an exhibitor video directly on their profile.
        Objectives:
        Enhance the Exhibitor Registration & Profile Management:
        Develop a user-friendly registration process for exhibitors, allowing them to submit detailed profiles, including company information, content, and social media links.
        Allow exhibitors to edit and update their profiles through a dedicated dashboard.
        Integration of Multimedia Content:
        Enable exhibitors to embed video links (e.g., from YouTube or Vimeo) directly on their public exhibitor page.
        Support the addition of rich content (images, descriptions, documents) to provide a comprehensive overview of each exhibitor.
        Organizers’ Administrative Tools:
        Create an admin interface that enables organizers to review, approve, and manage exhibitor signups.
        Integrate payment processing options to manage exhibitor fees, if applicable, ensuring a secure and streamlined financial workflow.
        Provide tools for organizers to publish approved exhibitor profiles to the public website.
        Integration with Event Sessions:
        Implement a feature to associate related event sessions with exhibitor profiles. This will allow attendees to see relevant sessions alongside exhibitor details, fostering deeper engagement.
        Design intuitive navigation between exhibitor pages and session details.
        Responsive & Modern UI/UX:
        Redesign the exhibitor plugin interface to align with eventyay’s overall design language, ensuring a modern, accessible, and responsive user experience across all devices.
        Focus on usability for both exhibitors and event organizers through clear workflows and consistent design elements.
        Robust Testing & Documentation:
        Develop comprehensive unit, integration, and end-to-end tests to ensure reliability of all new features.
        Write detailed documentation for both developers and end-users to support future maintenance and community contributions.
        Repository:
        eventyay-tickets-exhibitors
        Expected Outcome:
        Upon completion of the project, the extended exhibition plugin will provide:
        A complete exhibitor registration system with rich profile management capabilities.
        An administrative interface for organizers to manage exhibitor applications, process payments, and publish profiles.
        Enhanced exhibitor pages that integrate multimedia content, social media links, and related event sessions.
        A modern, responsive UI that offers a seamless experience for both exhibitors and event attendees.
        Comprehensive testing and documentation that ensure maintainability and facilitate future enhancements.
        Skills Required/Preferred:
        Web Development: Strong experience with front-end technologies (JavaScript frameworks, HTML, CSS) and back-end development.
        Frameworks & Libraries: Familiarity with frameworks used in eventyay (e.g., Ember.js, Vue.js, or similar) and RESTful API integration.
        Payment Integration: Knowledge of integrating payment systems (e.g., Stripe, PayPal) for secure transaction processing.
        UI/UX Design: Ability to create intuitive and responsive interfaces.
        Testing & Documentation: Experience with writing unit, integration, and end-to-end tests as well as technical documentation.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 175 hours (medium size)
        SUSI Interpretation Project
        
        ~~~~~~~~~~
        1. SUSI Interpretation Project: Develop a Prototype for Real-Time AI Live-Interpretation of Event Videos
        Description: The SUSI AI Translator project aims to build an interpretation assistant that leverages large language models (LLMs) to enable automated, real-time live interpretation on top of the eventyay video component. The system integrates advanced speech-to-text technology with AI-powered language translation, allowing for the seamless display of interpreted text (e.g., translated subtitles) during live event video sessions. By bridging the gap between live audio streams and real-time translation, this project will significantly enhance accessibility and engagement for multilingual audiences at events.
        Scope: 
        The scope of your specific work on this project should be discussed with your mentor.
        Objectives:
        Real-Time Speech Recognition:
        Integration: Evaluate and integrate state-of-the-art speech-to-text engines (such as OpenAI’s Whisper or other open-source alternatives) to capture live audio streams from event videos with minimal latency.
        Optimization: Optimize for high accuracy and performance under varying noise and speech conditions.
        AI-Powered Translation & Interpretation:
        LLM Integration: Leverage large language models or dedicated translation APIs to interpret and translate the transcribed text in near real-time.
        Context Preservation: Ensure that the translation maintains context and clarity, offering accurate subtitles that enhance audience understanding.
        Subtitle Overlay & UI Integration:
        Eventyay Video Integration: Develop a module that overlays interpreted subtitles onto the live video stream from the eventyay video platform.
        Customization: Provide configurable options (e.g., font size, color, position, language selection, and toggle controls) to optimize subtitle display for diverse event settings.
        System Optimization and Latency Reduction:
        Pipeline Efficiency: Optimize data pipelines and processing workflows to minimize end-to-end latency, ensuring a smooth live interpretation experience.
        Caching & Asynchronous Processing: Implement techniques to handle network delays and processing loads effectively.
        Testing, Documentation, and Community Engagement:
        Comprehensive Testing: Develop unit, integration, and end-to-end tests to ensure system reliability and performance across various scenarios.
        Documentation: Create detailed guides on system setup, configuration, troubleshooting, and customization.
        Tutorials & Demos: Produce step-by-step tutorials and demo videos showcasing how to deploy and use the live interpretation feature.
        Additional Features (Exploratory):
        Admin Controls: Design an admin panel for event organizers to manage language pairs, thresholds, and real-time translation settings.
        Multi-Language Support: Expand the system to support multiple target languages and easy language switching during live events.
        Repositories:
        SUSI Translator Repository
        eventyay-video Repository
        (Additional modules or repositories may be created as the project evolves.)
        Expected Outcome:
        An improved prototype fully integrated, real-time AI live interpretation system that displays translated subtitles on the eventyay video platform.
        Enhanced accessibility and engagement for multilingual audiences through automated, low-latency speech recognition and translation.
        A robust, well-documented codebase accompanied by comprehensive tests and tutorials, fostering further community contributions and improvements.
        Skills Required/Preferred:
        Speech Recognition & Audio Processing: Familiarity with integrating and optimizing speech-to-text systems.
        AI & Machine Learning: Experience working with large language models, translation APIs, or similar AI-driven solutions.
        Programming & API Integration: Proficiency in Python and/or other relevant languages for backend processing and API development.
        Front-End Development: Skills in integrating real-time UI overlays within video platforms.
        DevOps & Testing: Experience with CI/CD pipelines and automated testing frameworks.
        Open Source Collaboration: Prior experience contributing to or managing open-source projects.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 350 hours

        ~~~~~~~~~~
        Scrum Helper
        1. Extend Features of the Scrum Helper Chrome Extension
        The Scrum Helper Chrome extension currently assists users in writing daily scrums within Google Groups by automatically fetching data from the GitHub API. It retrieves information such as pull requests, issues, and reviewed PRs based on the user’s GitHub username and pre-fills scrum reports accordingly. The proposed project aims to expand the extension's usability by:
        Adding support for popular web email clients like Gmail, Yahoo, and Outlook.
        Implementing a standalone pop-up interface that can be used independently of any email provider.
        This will allow users who do not utilize Google Groups or specific web email services to seamlessly generate and edit their scrum reports. The project focuses on extending API integrations, enhancing user interfaces, and ensuring compatibility across multiple platforms and environments.
        Objectives:
        Multi-Email Client Integration:
        Gmail, Yahoo, and Outlook Support:
        Integrate the extension with these popular web email clients by detecting the email interface and injecting necessary UI components to allow scrum report generation.
        Authentication & Permissions:
        Adapt OAuth flows or other authentication methods where necessary to securely connect to these platforms while preserving user privacy and data security.
        Standalone Pop-Up Interface:
        Development of a Standalone UI:
        Build a responsive, easy-to-use pop-up interface that operates independently of any specific email provider.
        User Experience Enhancements:
        Provide options to input GitHub username, dates, and other relevant details directly in the pop-up, pre-fill scrum data via the GitHub API, and allow users to edit the content before copying or exporting it.
        Customization Options:
        Allow users to configure which sections appear in their scrum reports and to save templates for future use.
        Enhanced GitHub Integration:
        Robust Data Fetching:
        Optimize API calls to fetch PRs, Issues, and reviewed PRs with error handling and caching mechanisms for a smoother user experience.
        User Customization:
        Offer additional filtering or sorting options for the fetched data, enabling users to fine-tune the information that populates their scrum reports.
        Cross-Platform Compatibility & Performance:
        Responsive Design:
        Ensure the extension’s UI adapts to different screen sizes and resolutions across various email clients.
        Performance Optimization:
        Optimize the extension for minimal load times and resource usage, ensuring a smooth experience even when processing large amounts of data.
        Testing, Documentation, and Community Engagement:
        Comprehensive Testing:
        Write unit, integration, and end-to-end tests to cover new functionalities, ensuring robustness and ease of maintenance.
        Documentation:
        Update technical and user documentation to guide future contributors and end users.
        Community Feedback:
        Engage with the community to gather feedback and iterate on the features, ensuring that the extension meets the evolving needs of its users.
        Repository:
        Scrum Helper Repository
        Expected Outcome:
        By the end of the project, the Scrum Helper Chrome extension will:
        Support integration with Gmail, Yahoo, and Outlook, enabling users to generate and send scrum reports directly from these platforms.
        Include a fully functional standalone pop-up interface for users who prefer not to rely on specific email providers.
        Enhance GitHub integration to provide robust, customizable data fetching and pre-filling of scrum reports.
        Feature an intuitive, responsive, and optimized UI that works seamlessly across different platforms.
        Be accompanied by comprehensive testing and detailed documentation, facilitating future contributions and maintenance.
        Skills Required/Preferred:
        Chrome Extension Development: Experience building and maintaining Chrome extensions.
        Front-End Development: Experience in HTML, CSS, JavaScript (and frameworks/libraries as needed) for building responsive UIs.
        API Integration: Knowledge of integrating third-party APIs (especially GitHub and web email clients) and handling OAuth authentication.
        Back-End Integration & Optimization: Ability to design robust data-fetching mechanisms and implement caching/error handling strategies.
        Testing & Documentation: Experience with writing automated tests and maintaining clear technical documentation.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 90 hours (small project)
        Difficulty level: Easy

        ~~~~~~~~~~
        FOSSASIA.ORG
        1. Revamp FOSSASIA.org with WordPress for a Modern, Maintainable Website
        Description: The goal of this project is to develop a new version of the FOSSASIA.org website using WordPress. The new website will adhere to the existing FOSSASIA brand guidelines, utilizing the core colors of red, gray, and white to maintain brand identity. By leveraging standard WordPress plugins and best practices, the project aims to create a website that is easy to update and maintain, ensuring a future-proof and scalable online presence for the community. The revamped site will showcase FOSSASIA's projects, events, news, and community initiatives in an engaging, responsive, and user-friendly manner.
        Objectives:
        Design & Branding:
        Develop a modern, responsive design for FOSSASIA.org that respects the current color scheme (red, gray, white).
        Create custom layouts and a theme that reflect the FOSSASIA identity, ensuring visual consistency across all pages.
        Plugin & Functionality Integration:
        Utilize standard, well-supported WordPress plugins to handle essential functionalities such as:
        Blog and news feeds.
        Contact forms and newsletter sign-ups.
        Social media integration and sharing.
        Keep customization minimal to simplify future updates and maintenance.
        Content & Information Architecture:
        Structure the site to clearly present FOSSASIA’s projects, events, community news, and resources following the current structure.
        Ensure easy navigation and a seamless user experience across devices.
        Performance, SEO, and Security:
        Optimize the site for speed and responsiveness.
        Implement SEO best practices and integrate tools for analytics.
        Ensure the website adheres to current security standards and best practices for WordPress.
        Documentation & Future-Proofing:
        Provide comprehensive documentation on theme customization, plugin management, and content updates.
        Create guidelines for future developers and maintainers to ensure the website remains current and easy to update.
        Expected Outcome:
        By the end of the project, the new FOSSASIA.org website will:
        Feature a fresh, modern design that maintains brand consistency with red, gray, and white as the primary colors.
        Leverage standard WordPress plugins to deliver a robust, feature-rich experience including event management, blog updates, contact forms, and social media integration.
        Be optimized for performance, SEO, and security, providing a seamless experience across all devices.
        Include detailed documentation to facilitate ongoing maintenance and future enhancements, ensuring longevity and scalability.
        Skills Required/Preferred:
        WordPress Development: Proficiency in WordPress theme development, PHP, and customizing plugins.
        Front-End Technologies: Experience with HTML, CSS, JavaScript, and responsive design principles.
        UI/UX Design: Ability to translate branding guidelines into a modern, user-friendly design.
        SEO & Performance Optimization: Understanding of web performance best practices and SEO fundamentals.
        Documentation: Strong technical writing skills for creating comprehensive developer and user guides.
        Repository:
        A new repository for the FOSSASIA.org WordPress theme and related assets will be maintained under the FOSSASIA GitHub organization.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 175 hours (intermediate project)
        Difficulty level: Intermediate

        ~~~~~~~~~~  
        LED Badge Magic
        The Badge Magic Android app lets you create moving text and draw clipart for LED name badges. The app provides options to portray names, cliparts, and simple animations on the badges. For the data transfer from the smartphone to the LED badge it uses Bluetooth.
        Project Ideas
        1. Enhance the feature set of the Flutter Badge Magic Application 
        Description: Badge Magic is a Flutter-based application that controls LED name badges via Bluetooth, allowing users to display names, graphics, and simple animations. Currently available on GitHub and major app stores, the app provides basic functionalities to customize LED displays. The goal of this project is to significantly expand its feature set to offer a richer, more customizable experience. New features include support for various fonts, games, and additional LED badge screen sizes and color options. Users will also benefit from advanced badge configuration options (such as Bluetooth always-on mode) and the ability to manage up to 8 storage slots for text and animations, including making animations editable and storable. Additionally, the project will streamline deployment by integrating automated support for additional app stores (e.g., Aptoide, App Gallery) and extend the app’s availability across all platforms supported by Flutter (Windows, Linux, MacOS, and Websites). Furthermore, existing bugs should be solved and feature enhancements made to ensure robust functionality and an improved user experience.
        Objectives:
        Multi-Font, Color, and Content Support:
        Integrate a diverse range of fonts and color palettes to allow users to customize the appearance of text, graphics, and animations on their LED badges.
        Enhance content management by enabling editable storage for animations—allowing users to store, edit, and reapply animations to 8 storage slots of the badge.
        Enable Interactive Games Integration:
        Provide an option to integrate simple, engaging mini-games that can be displayed on the LED badges.
        Support for Multiple LED Badge Screen Sizes:
        Enhance the app to automatically adapt content for various LED badge screen sizes and resolutions.
        Advanced Badge Configuration Options supported by the firmware:
        Implement detailed configuration settings, such as enabling/disabling Bluetooth always-on mode, and other badge-specific options to provide greater control over the device behavior.
        Solve existing bugs and improve feature enhancements to refine overall functionality.
        Automated Multi-Platform Deployment:
        Improve the automated deployment pipeline that facilitates the submission of the app to additional app stores (e.g., Aptoide, App Gallery) as well as all platforms supported by Flutter.
        Ensure that installation files for Windows, Linux, MacOS, and Websites are autogenerated and maintained in the project's app branch.
        Enhanced UI/UX Improvements:
        Provide clear visual feedback and customization options across all supported platforms.
        Comprehensive Testing and Documentation:
        Implement unit, integration, and end-to-end tests to ensure all new features work as expected and existing bugs are resolved.
        Update technical and user documentation to assist future contributors and end users, ensuring long-term maintainability.
        Repository:
        https://github.com/fossasia/badgemagic-app 
        Expected Outcome:
        At the end of the project, the Flutter Badge Magic Application will:
        Support a wide range of fonts, colors, and display options for highly customizable badge presentations.
        Feature interactive games and advanced configuration settings, including a “Bluetooth always on” mode.
        Allow users to store, edit, and manage animations in up to 8 dedicated storage slots.
        Automatically adapt to various LED badge screen sizes, ensuring optimal content display.
        Support automated multi-platform deployment, generating installation files for Windows, Linux, MacOS, and Websites on the app branch.
        Provide a robust, bug-free experience with a modern, user-friendly interface and comprehensive documentation.
        Skills Required/Preferred:
        Flutter/Dart: Advanced knowledge in Flutter development and Dart programming.
        Bluetooth Communication: Experience with Bluetooth integration in mobile applications.
        UI/UX Design: Strong design skills for building intuitive and responsive mobile interfaces.
        Mobile and Multi-Platform App Development: Proven experience in Android, iOS, and cross-platform development (Windows, Linux, MacOS, and Web).
        CI/CD & Deployment: Familiarity with automated deployment pipelines and multi-app store submissions.
        Testing & Documentation: Experience in writing unit, integration, and end-to-end tests, as well as maintaining detailed project documentation.
        Possible mentors: Aditya, MarioB, cweitat
        Expected Size: 175 hours (median project)
        Difficulty level: Easy
        
        ~~~~~~~~~~
        Magic ePaper Badge
        1. Improve the Magic ePaper Badge app into a User friendly Functional App
        Description: The Magic ePaper Badge is a unique hardware platform featuring a tri-color ePaper display, NFC capabilities, and battery-free operation. The goal of this project is to build an open source Flutter application that allows users to interact with and control the badge with rich, customizable content. The app will enable users to create and edit content through drawing tools, text inputs, emojis, and image import functionalities—with various effects (none, semi-transparent, block, portrait). Additional features include adjusting contrast, colors, image rotation, and text customization (font and size). Finally, the app will support transferring the composed content to the badge via NFC. This project is especially suited for contributors with an electronics background who are also interested in modern mobile app development using Flutter.
        Objectives:
        User Interface & Drawing Tools:
        Develop an intuitive Flutter UI for creating badge content.
        Implement drawing functionalities, text input, and emoji insertion.
        Integrate a color picker to easily change colors by tapping on a color button.
        Image Import and Editing:
        Enable users to import images from their devices.
        Support multiple image display effects: none, semi-transparent, block, and portrait.
        Provide features for rotating images and adjusting brightness, contrast, and overall color balance.
        Text Customization:
        Allow users to change fonts and text sizes to match their design needs.
        Ensure text overlays are compatible with the tri-color ePaper display.
        NFC-Based Content Transfer:
        Integrate NFC functionalities to enable the transfer of created content from an NFC-enabled phone directly to the Magic ePaper Badge.
        Ensure a smooth, secure, and reliable connection between the mobile device and the badge hardware.
        Support for Tri-Color ePaper Displays:
        Ensure that all drawing, text, image, and animation functionalities are fully optimized for the unique constraints of tri-color ePaper displays.
        Testing, Bug Fixes & Feature Enhancements:
        Identify and resolve existing bugs, particularly issues around storing and editing animations.
        Continuously refine and enhance features based on user feedback and testing results.
        Multi-Platform Deployment & Automation:
        Adapt the app to run on all platforms supported by Flutter (Android, iOS, Windows, Linux, MacOS, and Web).
        Set up an automated deployment pipeline to generate installation files in the app branch for all target platforms.
        Ensure that the deployment process is smooth and maintainable for future updates.
        Documentation & Community Engagement:
        Produce comprehensive documentation covering installation, usage, and NFC transfer processes.
        Provide guidelines for future contributions and ensure robust testing strategies are in place.
        Repository:
        Magic ePaper App Repository
        Resources:
        Waveshare ePaper Sample App
        Expected Outcome:
        By the end of the project, the Magic ePaper Badge Flutter App will:
        Offer a complete suite of content creation tools (drawing, text, emoji, image editing) tailored for the tri-color ePaper display.
        Provide robust customization options including color adjustments, image effects, and text formatting.
        Seamlessly transfer content to the badge via NFC.
        Run across all major platforms supported by Flutter, with autogenerated installation files maintained in the app branch.
        Include comprehensive documentation, a solid testing framework, and a refined UI/UX for an engaging user experience.
        Skills Required/Preferred:
        Flutter & Dart Development: Knowledge in building cross-platform apps with Flutter.
        Mobile & Multi-Platform App Development: Experience in deploying applications on Android, iOS, Windows, Linux, MacOS, and Web.
        NFC Integration: Understanding of NFC communication and its implementation on mobile devices.
        UI/UX Design: Skills in creating intuitive and responsive user interfaces.
        Image Processing & Drawing: Experience with image editing, drawing functionalities, and handling various display effects.
        Electronics & ePaper Displays: Basic knowledge of ePaper technology and hardware integration is a plus.
        Testing & Documentation: Proven ability to write comprehensive tests and maintain clear, detailed documentation. 
        Possible mentors: Aditya, MarioB, cweitat
        Expected Size: 350 hours (large project)
        Difficulty level: Intermediate
        
        ~~~~~~~~~~
        2. Enhance the Firmware of the Magic epaper Badge 
        Description: The Magic Epaper Firmware is a fully customizable and efficient firmware designed to control FOSSASIA's ePaper displays. It serves as the backbone for smart signage, dashboards, IoT devices, and various applications that require low-power, high-performance e-ink display control. The firmware is optimized for FOSSASIA ePaper displays, ensuring smooth rendering while consuming minimal power, and features a modular codebase that allows easy adaptation to different e-paper sizes and types. With flexible connectivity options supporting SPI, I2C, or UART interfaces, and compatibility with various microcontrollers, the firmware is capable of rich content rendering including text, images, and custom graphics—with support for grayscale and partial refresh (depending on display capabilities). Fully open-source under the Apache2 license, the firmware invites contributors to extend its capabilities and enhance its reliability.
        Objectives:
        Reliability and Stability Enhancements:
        Audit the current firmware codebase to identify and resolve bugs affecting rendering, connectivity, and power consumption.
        Optimize the code for smoother rendering and enhanced stability across various hardware configurations.
        Modular Codebase Improvements:
        Refactor and document the modular components to simplify customization for different e-paper display sizes and types.
        Enhance configurability to allow easier integration with new microcontrollers and communication protocols (SPI, I2C, UART).
        Low-Power Optimization:
        Fine-tune power management routines to further reduce energy consumption, making the firmware even more suitable for battery-powered devices.
        Implement advanced sleep and wake-up cycles tailored for e-ink display operations.
        Advanced Content Rendering:
        Improve support for rich content rendering including text, images, and custom graphics.
        Enhance grayscale rendering capabilities and optimize partial refresh functionality to reduce ghosting and improve update speed.
        Connectivity and Integration Enhancements:
        Ensure robust communication over SPI, I2C, or UART, adding diagnostics or fallback mechanisms to handle connection interruptions.
        Develop test cases and debugging tools to facilitate easier firmware integration with different hardware setups.
        Documentation and Community Support:
        Update and expand technical documentation, providing detailed guides on customizing and extending the firmware.
        Create a set of example projects and usage scenarios for smart signage, dashboards, and IoT devices to encourage community contributions.
        Repository:
        Magic ePaper Firmware Repository
        Expected Outcome:
        By the end of the project, the enhanced Magic Epaper Firmware will:
        Deliver a more stable and reliable performance with optimized rendering and low-power operation.
        Feature a thoroughly documented and modular codebase that simplifies customization for various e-paper displays and microcontrollers.
        Offer improved content rendering capabilities, including refined support for grayscale and partial refresh.
        Provide robust connectivity with diagnostics and enhanced support for SPI, I2C, and UART interfaces.
        Include comprehensive documentation and example projects, fostering further development and community engagement.
        Skills Required/Preferred:
        Embedded Systems & Firmware Development: C/C++ or similar languages used in microcontroller programming.
        Electronics & Hardware Integration: Experience with ePaper displays, low-power device design, and understanding of communication protocols (SPI, I2C, UART).
        Optimization & Debugging: Skills in debugging firmware and optimizing performance for resource-constrained devices.
        Documentation & Open-Source Collaboration: Ability to write clear technical documentation and collaborate with a global open-source community.
        Possible mentors: fcartegnie, Benjamin Henrion, Simon Budig, danielm
        Expected Size: 350 hours
        Difficulty level: Difficult

        ~~~~~~~~~~
        Pocket Science Lab
        In the Pocket Science Lab Project we create phone and desktop applications to collect measurements and data to solve global problems with science and build a sustainable world. With the PSLab mobile and desktop apps it is possible to use sensors of a phone or desktop PC to collect measurements and data. The app comes with a built-in Oscilloscope, Multimeter, Wave Generator, Logic Analyzer, Power Source, and we are constantly adding more digital instruments or even robotic controls. With PSLab applications your phone or PC becomes like many devices in one. 
        Project Ideas
        1. Complete the Port of the PSLab app to Flutter
        The Pocket Science Lab (PSLab) project has empowered countless students to explore science hands-on with affordable, versatile instruments. Currently, the PSLab mobile app is available only for Android, limiting its accessibility. In response to feedback from educational institutions and schools, this project aims to develop a cross-platform Flutter application that works seamlessly on Android, iOS, desktop (Windows, macOS, Linux), and web. The new app will provide support for popular scientific instruments such as the Oscilloscope, Logic Analyzer, Multimeter, and robot controls. Additionally, due to Apple's restrictions on USB connections, the project will include robust configuration options and WiFi connectivity to enable data transmission on Apple devices.
        Objectives:
        Cross-Platform Development:
        Porting/Implementation: Rebuild the existing Android app using Flutter to support iOS, desktop, and web platforms.
        Optimization: Ensure the app performs smoothly across different devices and screen sizes.
        Core Instrument Functionality:
        Oscilloscope, Logic Analyzer, Multimeter, and Robot Controls: Implement and integrate these instrument features with consistent behavior and accuracy across all platforms.
        Data Visualization: Develop clear, interactive visualizations and controls for each instrument, enabling real-time monitoring and analysis.
        Enhanced Connectivity:
        USB and WiFi Support:
        Retain USB connectivity for Android while implementing configuration options for WiFi-based data transmission.
        Address Apple’s limitations by enabling WiFi connectivity, ensuring seamless communication between the PSLab hardware and the app on iOS devices.
        Robust Communication Protocols: Ensure secure and reliable data transfer through efficient connection management.
        User Interface & Experience:
        Responsive UI: Design an intuitive, responsive interface that adapts to mobile, desktop, and web environments.
        User-Centric Design: Prioritize ease of use, especially for educational settings, with clear navigation and instrument control layouts.
        Testing, Documentation, and Deployment:
        Comprehensive Testing: Develop unit, integration, and end-to-end tests to validate functionality across all supported platforms.
        Automated Deployment: Set up CI/CD pipelines to automate building and deployment for mobile (App Store/Google Play), desktop installers, and a web version.
        Documentation: Create detailed user and developer documentation, including setup guides and usage examples, to foster community engagement and future contributions.
        Repository:
        PSLab Android Repository (Check the flutter branch)
        Expected Outcome:
        By the end of the project, PSLab will have a robust, cross-platform Flutter application that:
        Runs seamlessly on Android, iOS, desktop (Windows, macOS, Linux), and web.
        Provides essential scientific instrument functionalities (Oscilloscope, Logic Analyzer, Multimeter, Robot Controls) with intuitive, real-time visualizations.
        Supports both USB (for Android) and WiFi connectivity (for iOS and other platforms) to overcome hardware limitations.
        Offers a user-friendly interface tailored for educational use, complete with comprehensive testing, documentation, and automated multi-platform deployment.
        Skills Required/Preferred:
        Flutter/Dart Development: Knowledge in building cross-platform applications.
        Mobile, Desktop & Web Development: Experience in deploying apps across various platforms.
        Hardware & IoT Integration: Understanding of connectivity protocols (USB, WiFi) and interfacing with scientific instruments.
        UI/UX Design: Ability to design responsive and intuitive interfaces.
        Testing & CI/CD: Experience with automated testing frameworks and deployment pipelines.
        Open Source Collaboration: Familiarity with contributing to and managing open-source projects.
        Possible mentors: padmal, bessman
        Expected Size: 350 hours
        Difficulty level: Difficult

        ~~~~~~~~~~

        2. Advanced Robot Control and Python Integration for the PSLab Android App
        Description: The PSLab Android app currently allows users to control a robotic manipulator with 4 degrees of freedom via connected servo motors. In parallel, similar control functionalities are available using Python, offering flexibility for custom automation and scripting. This project aims to enhance the robot control features within the PSLab Android app while seamlessly bridging the gap between mobile and Python environments. Key enhancements include advanced control options, import/export capabilities for Python scripts, and storage of user-defined robot controls. Additionally, comprehensive documentation and a web-based UI guide will be developed to showcase how to transfer control data and operate the robot through a web interface.
        Objectives:
        Enhanced Robot Control Features:
        Upgrade the existing robot control module within the PSLab Android app to support advanced manipulation options.
        Improve the user interface for intuitive control over the 4 degrees of freedom, including real-time feedback and fine-tuning capabilities.
        Implement additional control modes, presets, and customizable parameters for servo motor movements.
        Python Script Integration:
        Develop functionality for exporting the current robot control configurations and commands from the Android app as a Python script.
        Implement an import feature that allows users to load Python scripts into the Android app, enabling them to execute predefined control sequences.
        Ensure that the Python integration maintains consistency with the PSLab Python library and adheres to best practices.
        Data Storage & Management:
        Introduce a storage mechanism for users to save and manage their custom robot control profiles and scripts within the app.
        Provide a clear and accessible user interface to review, edit, and organize stored controls.
        Documentation & Web UI Integration:
        Create comprehensive, step-by-step documentation detailing the transfer of control data between the Android app and Python scripts.
        Develop a web-based UI guide that demonstrates how to control the robot via a browser, highlighting the integration process and potential use cases.
        Include troubleshooting guides and best practices to help users optimize their control setups.
        Repository:
        PSLab Android App
        PSLab Python
        Expected Outcome:
        At the end of the project, the PSLab Android app will feature:
        Enhanced and more intuitive robot control capabilities with advanced options.
        Seamless import and export functionalities for Python scripts, allowing bi-directional control and integration.
        Robust storage of user-defined control profiles for quick access and customization.
        Comprehensive documentation and a web UI guide that illustrate the control data transfer process and provide additional insights on operating the robot.
        Skills Required/Preferred:
        Android Development: Android app development with a strong understanding of Java/Kotlin and Flutter (if applicable).
        Python Programming: Experience with Python scripting and integrating Python functionalities within mobile applications.
        Robotics & IoT: Familiarity with robotic control systems, servo motors, and interfacing with hardware.
        UI/UX Design: Ability to design intuitive user interfaces that enhance user interaction and control.
        Documentation & Testing: Experience with writing clear documentation and performing robust testing to ensure a stable release.
        Possible mentors: padmal, orangecms, bessman
        Expected Size: 90 hours
        Difficulty level: Intermediate

        ~~~~~~~~~~
        3. Create a Firmware Prototype for PSLab Mini: A Compact Oscilloscope & Multimeter
        The PSLab Mini aims to be a streamlined, cost-effective version of the Pocket Science Lab, specifically designed to offer dedicated Oscilloscope and Multimeter functionalities in a compact form factor. This project involves developing a firmware prototype based on the existing PSLab firmware. The prototype will be optimized to run on resource-constrained hardware while delivering precise data acquisition, processing, and visualization for oscilloscope and multimeter measurements. As an alternative, if a dedicated PSLab Mini hardware is not available, an ARM development board can be used to simulate the target environment. This project is ideal for students with embedded systems and firmware development experience, and it will help extend PSLab’s reach into classrooms and educational settings.
        Objectives:
        Firmware Analysis and Requirements Definition:
        Review the existing PSLab firmware to understand its architecture and core functionalities.
        Identify the essential modules for Oscilloscope and Multimeter operations.
        Define the performance and resource requirements for the PSLab Mini.
        Prototype Development:
        Refactor and streamline the current firmware to create a lightweight version that focuses on Oscilloscope and Multimeter features.
        Implement core functionalities such as high-speed data acquisition, signal processing, and measurement display.
        Integrate a basic user interface for real-time visualization of measurements (using an onboard display or external interface).
        Hardware Optimization & Alternative Platform Integration:
        Optimize the firmware for low-power consumption and efficient operation on minimal hardware.
        If a dedicated PSLab Mini device is unavailable, port and test the firmware on an ARM development board as a substitute platform.
        Testing and Validation:
        Develop comprehensive test cases to ensure the accuracy and reliability of oscilloscope and multimeter functions.
        Benchmark the firmware’s performance against standard measurement devices.
        Iterate based on testing feedback to fine-tune responsiveness and accuracy.
        Documentation and Community Engagement:
        Document the firmware architecture, development process, and hardware requirements.
        Provide step-by-step guides for setting up the firmware on the PSLab Mini (or ARM development board).
        Engage with the community for feedback and further enhancements.
        Repository:
        PSLab Firmware Repository: [Insert Repository URL here]
        (If a dedicated repository for the PSLab Mini firmware prototype is created, it will be added to the FOSSASIA GitHub organization.)
        Expected Outcome:
        A fully functional firmware prototype for the PSLab Mini that supports oscilloscope and multimeter features.
        Optimized firmware tailored for resource-limited hardware with low power consumption and reliable performance.
        Comprehensive documentation and test suites for further development and community contributions.
        Optionally, a demonstration of the firmware running on an ARM development board if dedicated hardware is unavailable.
        Skills Required/Preferred:
        Embedded Systems & Firmware Development: Proficiency in C/C++ and experience with ARM Cortex or similar microcontrollers.
        Hardware Interfacing: Familiarity with analog-to-digital conversion, sensor interfacing, and low-level hardware communication protocols.
        Optimization Techniques: Ability to optimize firmware for performance and low power consumption on resource-constrained devices.
        Testing & Debugging: Experience in developing unit tests and debugging firmware in embedded environments.
        Documentation: Strong technical writing skills to produce clear, comprehensive documentation.
        Possible mentors: bessman
        Expected size: 350 h (large project)
        Difficulty level: Intermediate

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/fossasia/
    idea_list_url: https://docs.google.com/document/d/1Tz1KxYefreKzBr98C4vbCv9UwnchZoyTwO8rBrz_lmg/edit?tab=t.0#heading=h.9sjk3ie7l2o2
  

  - organization_id: 41
    organization_name: FOSSology
    no_of_ideas: 13
    ideas_content: |
      
      Data pipelining for safaa project
      Goal: Automate the process of model training using pipelining.
      Currently in Safaa Project data was manually curated And we see that most of the things are manual here. the project should concentrate on creating a pipeline, Utilizing LLMS if required to increase the accuracy, use deep learning techniques to improve.
      Scripts to copy copyright data automatically(group's data or some users data) from fossology instance to train the model.
      
      Test cases needs to be provided as well.
      Category Rating
      Low Hanging Fruit **
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development *
      Project Infrastructure **
      Project size Large
      Preferred contributor Student/professional
      Skills needed Python, ML And Data
      Contact @Kaushl2208 @GMishx @shaheemazmalmmd

      ~~~~~~~~~~
      License Detection Using Large Language Models
      Goal: To automate license detection using license dataset and ensure accurate and up-to-date results by leveraging a Retrieval-Augmented Generation (RAG) approach.
      We have previously tried semantic similarity approach for license detection #104-Atarashi. Which used text processing and prompt engineering. We have tried multiple LLM models for license statement types. Visit Weekly Reports for more performance details
      What we want to achieve?
      Utilize SPDX or SAFAA Database for licenses.
      To create RAG knowledge Base, For model to understand specifics of licenses.
      High Accuracy on Random license texts(Input provided need not to be a full fledged statement). Confidence score if necessary
      Needs to be a Language Agnostic Solution.
      Pipeline to Fetch New License Data (If available) from SPDX Database or SAFAA so RAG Knowledge Base should always be up to date.
      Category Rating
      Low Hanging Fruit **
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development *
      Project Infrastructure **
      Project size Medium/Large
      Preferred contributor Student/professional
      Skills needed Python, LLMs, Fine-tuning, Documentation
      Contact @Kaushl2208 @GMishx @shaheemazmalmmd

      ~~~~~~~~~~
      Transforming Nirjas into a Technical Documentation tool Using Large Language Models (LLMs)
      Goal: To transform Nirjas into a comprehensive technical documentation tool using LLMs by automatically generating, improving, and structuring documentation for source code files. This will include comments, function documentation, and metadata extracted using Nirjas, ensuring consistency, clarity, and quality in technical documentation.
      We have previously worked on extracting metadata and comments using regex-based approaches in Nirjas. While this method provided structured results, it can also be used to generate high-quality documentation. Leveraging LLMs with metadata extraction from Nirjas.
      What we want to achieve?
      Integrate LLMs for Documentation Generation
      Use Existing Knowledge Sources for Training
      Implement a Retrieval-Augmented Generation (RAG) Approach
      Automatic Summarization and Quality Scoring
      Seamless Integration with Existing Tools
      Category Rating
      Low Hanging Fruit **
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development **
      Project Infrastructure **
      Project Size Medium/Large
      Preferred Contributor Student/Professional
      Skills Needed Python, LLMs, Fine-tuning, Data Engineering, Documentation Standards
      Contact @hastagAB @GMishx @Kaushl2208

      ~~~~~~~~~~
      Overhauling scheduler design
      Goal: Improving FOSSology scheduler or replacing with OTS solution
      The existing scheduler design is causing new issues which need to be addressed. Moreover, existing scheduler design is not touched in years.
      Concerning points
      The scheduler is written in C which makes it next to impossible to find cause of a failure.
      The C language does not support exception handling out of the box. It makes code less readable and prone to errors.
      The linear queue design causes issue when there should be only one instance of an agent running for an upload, but overall the agent is not mutually exclusive.
      For example, if the monkbulk has a limit set to 1, it should be implied for only single upload. But with linear queue, this monkbulk job will block all other agents from executing even when they are not effected by the results of monkbulk.
      This essentially makes the agent mutually exclusive even though, there is a special flag EXCLUSIVE for the very same purpose: https://github.com/fossology/fossology/wiki/Job-Scheduler#agentconfs
      One idea on redesigning the queue, it can be broken into buckets per upload each maintaining its own priority queue. There can be another queue for global operations like maintenance, delagent, etc.
      Doing so, each bucket can be traversed in round-robin and pick first pending job and check against host limit. This will eliminate the scenario mentioned in point 3. Also, exclusive agents can be sent to global queue.
        upload specific queue
      |-<upload_2> -> nomos, copyright, ojo, keyword
      |-<upload_3> -> monkbulk, decider, monkbulk, decider
      |-<upload_4> -> reuser, decider
      
      global queue
      -> delagent,
      Since the FOSSology is released, there can be number of new scheduling libraries being released which needs to be explored. They can be a nice addition to the project.
      There have been some work already done in GSoC 2024, Can be visited here
      Category Rating
      Low Hanging Fruit -
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development ***
      Project Infrastructure *
      Project size Large
      Preferred contributor Professional
      Skills needed Go
      Contact @GMishx @Kaushl2208 @avinal @shaheemazmalmmd

      ~~~~~~~~~~
      Debian packaging for Debian repository
      Goal: Improve Debian packaging and make it acceptable for APT
      The existing effort to put FOSSology under Debian packaging list needs to be taken forward. A repository under Debian Salsa was setup initially but not maintained any more: https://salsa.debian.org/fossology-team/fossology It is configured to use gbp.
      Blockers
      The Debian building mechanism does not allow installation from sources other than apt. The Composer packages need to be packed as Debian packages and shipped with FOSSology.
      Packaging and shipping other tools needs to satisfy their licensing terms.
      The versions of packages in APT and actual versions used are different.
      APT also provides JS libraries like JQuery and DataTables but RHL does not.
      See also
      https://github.com/fossology/fossology/pull/2075
      https://wiki.debian.org/PackagingWithGit
      https://wiki.debian.org/SimplePackagingTutorial
      https://wiki.debian.org/Diagrams
      https://wiki.debian.org/PHP
      https://peertube.debian.social/videos/watch/0fb2dbc4-f43d-477e-8b14-20c426f970de
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure ***
      Project size Small
      Preferred contributor Student/Professional
      Skills needed Debian, APT, CMake
      Contact @GMishx @shaheemazmalmmd @Kaushl2208

      ~~~~~~~~~~
      User & Developer Assistant Chatbot using Large Language Models
      Goal: To develop an intelligent assistant chatbot that leverages Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) techniques to provide comprehensive support for both end-users and developers of our tool. The assistant will bridge the gap between users, documentation, and the codebase to ensure an interactive and efficient problem-solving experience.
      The chatbot will be designed to interactively assist new and existing users with various aspects of the tool, including:
      Feature Discovery:
      Answer questions about available features, their functionalities, and usage.
      Provide contextual information derived from the tool's wiki and feature documentation.
      Problem Resolution and Recommendations:
      Assist users during the project setup phase by identifying common setup errors.
      Provide troubleshooting steps for known issues by integrating knowledge from GitHub issues.
      Developer Support:
      Answer codebase-related queries by identifying relevant classes, methods, or functions.
      Enhance developers' understanding of the project by linking features to the corresponding implementation in the code.
      The chatbot will utilize LangChain, RAG, and a Vector Database for retrieval, enabling contextual conversations. A seamless pipeline will integrate multiple data sources, including documentation, GitHub issues, and the codebase.
      What We Want to Achieve:
      For End-Users:
      Improved Onboarding:
      Enable new users to quickly understand the tool's features and capabilities through interactive conversations.
      Efficient Problem Resolution:
      Provide real-time recommendations for known issues encountered during project setup.
      Reduce reliance on manual troubleshooting by surfacing relevant GitHub issues.
      Enhanced User Engagement:
      Increase user satisfaction by offering a conversational interface that adapts to their queries and knowledge level.
      For Developers:
      Codebase Exploration:
      Allow developers to query the codebase for insights into specific classes or functions, fostering faster understanding and debugging.
      Knowledge Consolidation:
      Create a unified interface where feature descriptions, documentation, and implementation details converge.
      Broader Objectives:
      Reduce the time spent on documentation searches.
      PS: There are some features which aligns with the goal but not be possible in short time interval. Topics like: Knowledge Consolidation & Codebase Exploration but the development should be done by taking all this in mind
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory *
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure **
      Project size Large
      Preferred contributor Student/professional
      Skills needed Python, LLMs, Documentation Standards
      Contact @Kaushl2208 @GMishx @shaheemazmalmmd
      
      ~~~~~~~~~~
      Support text phrases and bulk based scanning for MONK a like agent
      Goal: Adding text phrases from UI to database and use existing bulk phrases and provide ability to scan them using MONK and identify files if the match is 100%
      FLOW :
      Create a UI Where user can add multiple text phrases associated with license(FROM FOSSology License Database).
      Use existing bulk phrases table from database.
      Create a new agent like existing MONK agent which not only identifies the matches but also decides the files.
      Test cases needs to be provided as well.
      Category Rating
      Low Hanging Fruit **
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development *
      Project Infrastructure **
      Project size Medium
      Preferred contributor Student/professional
      Skills needed PHP, C++
      Contact @GMishx @shaheemazmalmmd
      
      ~~~~~~~~~~
      Enhance atarashi ability
      Goal: Improve license identification of atarashi
      Improve existing model which have 80 % accuracy.
      Use some model to identify the license-possibility using keywords.
      Once there is some license possibility pass this to existing trained model to identify the accurate license.
      If the trained model miss to find the license then add license-possibility to file so that users checks the file and clarify.
      Work on the existing branch(https://github.com/fossology/fossology/pull/1634) and make sure that this gets merged.
      Know more about atarashi.
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure ***
      Project size Small
      Preferred contributor Student/Professional
      Skills needed Python, ML , CMake
      Contact @GMishx @shaheemazmalmmd @Kaushl2208 @hastagAB
      
      ~~~~~~~~~~
      Integrating Open Source Review Toolkit
      Goal: Using ORT to fetch dependencies and generate SBOM
      Build systems fetch the required dependencies (library/artifact) for a project while building the project. Its important to get an insight of these dependencies for license compliance check.
      The OSS Review Toolkit is an open source project helps to find dependencies in a project.
      The goal of this project is to render the project dependencies created by ort and display those in the fossology-UI. Dependencies can be scheduled directly from the UI and scan with fossology.
      Also vice versa integrate FOSSology to ORT to scan the opensource dependencies.
      Category Rating
      Low Hanging Fruit -
      Risk/Exploratory -
      Fun/Peripheral **
      Core Development ***
      Project Infrastructure *
      Project size Large
      Preferred contributor Student/Professional
      Skills Needed PHP, Cmake, Kotlin
      Contact @GMishx @shaheemazmalmmd @Kaushl2208
      
      ~~~~~~~~~~
      Complete microservices infrastructure for FOSSology
      Goal: Continue the work from previous GSoC and bring FOSSology to a working state on Kubernetes
      As part of GSoC 2021, a large portion of work was done to bring FOSSology to work on Kubernetes. Since then, there have been countless changes to the codebase and the build system. Here are a few objectives we expect to be achieved:
      Go through the changes in the codebase and devise strategies for integrating them
      Inspect the changes in #2086 and complete the work
      By the end, we should have a fully working FOSSology installation on Kubernetes
      Create documentation for setting up FOSSology on a cluster and all the options available
      Stretch goal: Create an all-in-one script for easy Kubernetes setup with FOSSology
      Stretch goal: Add mechanism for health checks of the installation
      Stretch goal: Expose usage and performance metrics
      References
      #2086
      #2075
      https://summerofcode.withgoogle.com/archive/2021/projects/4661860250419200
      Category Rating
      Low Hanging Fruit -
      Risk/Exploratory ***
      Fun/Peripheral *
      Core Development *
      Project Infrastructure ***
      Project Size Medium/Large
      Preferred Contributor Professional
      Skills Needed Kubernetes, Docker/Podman, CMake, Bash
      Contact @avinal @GMishx @shaheemazmalmmd @Kaushl2208
      
      ~~~~~~~~~~
      Rewrite FOSSology UI using React
      Goal: Rewrite FOSSologyUI using react.
      Existing code is old. and needs a fix.
      Implementation of new API'S to existing code.
      Implementation designed templates.
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure ***
      Project size Small
      Preferred contributor Student/Professional
      Skills needed php, react, CMake
      Contact @GMishx @shaheemazmalmmd @Kaushl2208 @deo002
      
      ~~~~~~~~~~
      FOSSology UX and UI design
      Goal: Redesign the FOSSology UX and UI to modernize its interface and enhance user-friendliness.
      Understand the Primary Users
      Identify user personas: Determine who the key users of FOSSology are, such as developers, compliance officers, or open-source contributors.
      Analyze pain points: Conduct surveys, interviews, or user studies to understand the challenges users face while using the current system.
      Analyze the Current Interface
      Evaluate usability issues: Identify areas where the current interface is difficult to use or navigate.
      Highlight outdated design elements: Assess visual components and workflows that no longer align with modern design standards or user expectations.
      Identify Redesign Requirements
      Define goals: Establish clear objectives for the redesign, such as improving efficiency, accessibility, or ease of use.
      Prioritize features: Focus on addressing critical pain points and implementing high-impact improvements.
      Design Reusable Components
      Catalog interface elements: List existing components and determine which can be updated or replaced.
      Ensure consistency: Create reusable design components to maintain a cohesive user experience and simplify scalability.
      Draft Layouts and Workflows
      Streamline user journeys: Map out key workflows to reduce complexity and improve navigation.
      Prototype layouts: Create wireframes or mockups to visualize potential improvements and gather early feedback.
      Establish a Cohesive Design System
      Define visual guidelines: Standardize elements such as colors, typography, and spacing for a unified aesthetic.
      Componentize the UI: Build a library of modular components for easier development and maintenance.
      Gather Feedback and Refine
      Conduct usability testing: Engage users to validate the new designs and identify areas for improvement.
      Iterate based on feedback: Refine layouts, workflows, and components to ensure the redesign meets user needs effectively.
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure ***
      Project size Medium/Large
      Preferred contributor Student/Professional
      Skills needed wireframe and other design techniques
      Contact @EttingerK @GMishx @shaheemazmalmmd @Kaushl2208
      
      ~~~~~~~~~~
      New single file view page to accommodate license + copyright clearing
      Goal: To Redesign & develop new single file view page accommodate all the clearings.
      Have a folder tree with blue & red buttons to indicate the clearing.
      Integrate drag and drop functionality to copy the clearing decisions from one file to another.
      Have a histogram feature to accommodate license groups in the current upload.
      Have a file view page with highlights of all the findings (licenses + copyrights + keywords + ECC).
      Refer the screenshot of the design.
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure ***
      Project size Small
      Preferred contributor Student/Professional
      Skills needed wireframe and other design techniques
      Contact @EttingerK @GMishx @shaheemazmalmmd @Kaushl2208
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/fossology/
    idea_list_url: https://fossology.github.io/gsoc/docs/2025/GSoC-projects

  - organization_id: 42
    organization_name: Fedora Project
    no_of_ideas: 2
    ideas_content: |
     
      AI-Powered Log Triage and Security Alert Aggregator for Fedora
      Difficulty : Easy
      Type : 1 person full time 350hrs (12 weeks)
      Technology : python, bash, scikit-learn, pytorch, tensorflow, security, AI, LLMs
      Mentor : Huzaifa Sidhpurwala
      Email : huzaifas@redhat.com
      Description
      This project aims to automatically parse, classify, and prioritize security-related logs on a Fedora system. The tool will aggregate logs from multiple sources (e.g., SELinux, systemd journal, audit logs) and apply basic machine learning (ML) or natural language processing (NLP) techniques to identify and prioritize potential security events. It will help administrators quickly spot critical alerts while reducing noise from routine messages.
      Deliverables
      As a GSoC intern, you will be responsible for the following :
      Source Code Repository: A publicly accessible GitHub/GitLab project containing all scripts, models, and integration logic.
      Packaged RPM: A Fedora-compliant RPM package that users can install to deploy the log triage tool.
      Documentation: Concise instructions covering installation, usage, configuration, and development/contribution guidelines.
      Demonstration/Prototype: A working setup (CLI or basic UI) showcasing how logs are collected, classified, and prioritized in real time.
      Testing & Evaluation Results: A set of tests (unit/integration) plus any benchmarking or evaluation reports on model performance and accuracy.

      ~~~~~~~~~~
      Create a service to get a new project to Fedora more easily
      Difficulty : Easy
      Type : 1 person full time 350hrs (12 weeks)
      Technology : Python, Git, git-forges knowledge and Linux
      Mentor : František Lachman
      Email : flachman@redhat.com
      Description
      This project aims to help people with less experience add a project (=package) to Fedora Linux by using pull-request workflow to be able to get feedback both from tools and more experienced packagers.
      Deliverables
      Source Code Repository: Either a contribution to existing tools (e.g. FedoraReview, Fedora review service and/or Packit) and/or another publicly accessible GitHub/GitLab project containing all the code and scripts.
      Documentation: Concise instructions covering the service and its deployment, testing and development but also usage.
      Demonstration/Prototype: A working setup showcasing how this service works and integrating at least a single automatic feedback.
      Testing & Evaluation Results: A set of tests (unit/integration) of the new code.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/fedora-project/
    idea_list_url: https://docs.fedoraproject.org/en-US/mentored-projects/gsoc/2025/ideas/

  - organization_id: 43
    organization_name: Fortran-lang
    no_of_ideas: 26
    ideas_content: |
      
      Version Constraint Resolution (fpm)
      The current decentralized package system in fpm allows dependencies to be fetched via a git repository URL. As part of this, a git tag or commit can be given to require a specific version of a dependency. There is however no way of specifying version compatibility requirements (e.g. >= 1.0.0, <2.0.0) and no way to resolve such requirements across a dependency tree.
      This project will involve:
      Defining a manifest syntax for version compatibility matching
      Implementing support in fpm for solving a set of version compatibility constraints
      A possible approach would be to interface with an existing satisfiability solver such as:
      libsolv: interface via iso_c_binding as a separate fpm package
      See also: existing options for version matching syntax:
      conda
      npm
      cargo
      Expected outcomes: Implemented a working version constraint mechanism in fpm
      Skills preferred: Fortran programming, experience with one or more build systems
      Difficulty: Intermediate, 350 hours
      Mentors: Brad Richardson (@everythingfunctional), Sebastian Ehlert (@awvwgk), Umashankar Sivakumar (@usivakum)
      
      ~~~~~~~~~~
      Build Process Enhancements (fpm)
      Fortran Package Manager (fpm) is pivotal for long-term Fortran success. This GSoC project aims to improve fpm’s build process by improving dependency detection, optimizing linking, implementing shared libraries, ensuring safe concurrent builds, and introducing external Makefile generation.
      The project will address the following tasks:
      Custom flags and configurations
      Implement custom and compiler-dependent flags, and configurations
      External build system Generation:
      Enable generation of external Makefiles akin to cmake -G for advanced project configuration.
      Linking Optimization:
      Replace one-liner linking with static libraries to prevent line buffer overflow in Windows builds.
      Shared Library Implementation:
      Introduce support for shared library targets for project flexibility.
      Dependency Detection:
      Enhance fpm’s dependency detection to minimize rebuilds by parsing or hashing module/submodule files or parsing procedure interfaces in module files. fpm should not rebuild dependencies to a module whose public interface has not changed.
      Expected Outcomes:
      Enhanced dependency tracking and reduced rebuild times.
      Improved reliability in linking, particularly in Windows.
      Increased project versatility with shared library support.
      Safer concurrent builds through file locking.
      Greater project configuration flexibility with external Makefile generation.
      Difficulty: Intermediate, 175 hours.
      Skills preferred: Fortran programming, experience with one or more build systems
      Mentors: Federico Perini (@perazz), José Alves (@jalvesz), Henil Panchal (@henilp105)
      
      ~~~~~~~~~~
      Extended Testing Support (fpm)
      The aim of this project is to create a manifest specification to provide defaults to executable targets in fpm projects. Information can be passed as environment variables, command-line arguments or as a runner. Desired features include:
      Programs should have a way to find resources of which the relative position within the project source directory is known.
      The current binary directory to access other targets within a project.
      Default runners like mpirun/cafrun or scripts from test frameworks should be usable to launch programs.
      A general syntax to define environment variables and command-line arguments should be defined.
      Some features should be implemented directly in fpm, while more elaborated functionality could be implemented in a separate fpm package as an official Fortran-lang fpm package.
      Related issues:
      fpm#179: Testing with fpm test
      Related discussions:
      fpm#328: Example which requires external data
      Expected outcomes: fpm has broader and deeper testing functionality
      Skills preferred: Fortran programming and writing unit tests
      Difficulty: Easy, 175 hours
      Mentors: Sebastian Ehlert (@awvwgk), Brad Richardson (@everythingfunctional)
      
      ~~~~~~~~~~
      Export build order and compile_commands.json (fpm)
      fpm has the ability to automatically determine the build order of a project's source files. This information is valuable to third party tools such as language servers and code analysis tools. The goal of this project is to export the build order of a project's source files in the compile_commands.json.
      The second leg of this project is to implement the full syntax of compile_commands.json as described in the Clang documentation. This would bring fpm a step closer to being compatible with other build tools.
      Expected outcomes: fpm will export a complete compile_commands.json file.
      Skills preferred: Fortran programming, experience with one or more build systems
      Difficulty: Hard, 350 hours
      Mentors: Giannis Nikiteas (@gnikit)
      
      ~~~~~~~~~~
      Support of external third-party preprocessors
      Adding support for external third-party preprocessors is important for fpm due to the additional flexibility they provide when building complex packages. In particular, the Fortran-lang stdlib project exploits the powerful fypp preprocessor for code generation and the support of fypp by fpm is required for stdlib to eventually be compatible as an fpm package.
      This project will require to:
      Modify fpm to optionally invoke a third-party preprocessor before compiling sources;
      Extend the current manifest syntax of fpm for defining preprocessor variables in a preprocessor-independent manner, if necessary;
      Extend the current manifest syntax of fpm for specifying a third-party preprocessor and the corresponding file suffixes, if necessary;
      Passe defined preprocessor variables to built-in preprocessors if necessary;
      Third-party preprocessors should be specified on a per-project basis, i.e. multiple preprocessors might be required, and fpm should be able to report useful errors for missing third-party preprocessors.
      Related issues:
      fpm#78: support for third-party preprocessors (e.g. fypp)
      fpm#308: Fortran-based smart code generation in fpm
      fpm#469: Source pre-processing prior to determining dependencies
      Expected outcomes: fpm has a working preprocessing capability
      Skills preferred: Fortran, C, or Python programming, experience using one or more preprocessors
      Difficulty: easy, 175 hours
      Mentors: Laurence Kedward (@lkedward), Milan Curcic (@milancurcic), Federico Perini (@perazz), Jeremie Vandenplas (@jvdp1)

      ~~~~~~~~~~
      File system library (stdlib)
      Currently, file system operations such as listing contents of directories, traversing directories, and similar, are restricted to 3rd party libraries and compiler extensions that are platform-specific and not portable. This project will entail designing and implementing a cross-platform solution for file system operations.
      Related issues:
      stdlib#201: File system operations
      stdlib#220: API for file system operations, directory manipulation
      WIP implementation:
      stdlib_os
      Expected outcomes: Implemented an stdlib module that provides cross-platform file-system utilities
      Skills preferred: Fortran and C programming, experience using Linux, macOS, and Windows
      Difficulty: Intermediate, 350 hours
      Mentors: Arjen Markus (@arjenmarkus), Milan Curcic (@milancurcic)

      ~~~~~~~~~~
      Library to work with OS processes (stdlib)
      Cross-platform solution to abstract POSIX and Windows API for creating subprocesses.
      Related issues:
      stdlib#22: Interface to POSIX I/O API
      stdlib#308: Subprocesses and Multiprocessing
      Discourse thread:
      Ideas for command module
      Skills preferred: Fortran and C programming, experience using Linux, macOS, and Windows
      Difficulty: Intermediate, 350 hours
      Mentors: Sebastian Ehlert (@awvwgk)

      ~~~~~~~~~~
      Linear algebra and sparse matrices (stdlib)
      Improve dense and sparse linear algebra APIs in the Fortran Standard Library.
      The API development should closely follow the developements on dense linear algebra in order to keep a coherent interface for sparse and dense matrices.
      Related issue: #931 #930 #910 #898 #891 #763 #934
      WIP implementations: #915 #844 FSPARSE
      Expected outcomes: Improved linear algebra and sparse matrix functionality in the stdlib_linalg module
      Skills preferred: Fortran programming, understanding of linear algebra
      Difficulty: Hard, 350 hours
      Mentors: Ondřej Čertík (@certik), Ivan Pribec (@ivan-pi), Jeremie Vandenplas (@jvdp1), Jose Alves (@jalvesz), Federico Perini (@perazz)
      
      ~~~~~~~~~~
      String to number conversion (stdlib)
      This project will enhance stdlib's string handling capabilities for fast number parsing in Fortran.
      Recently, a new module was added to stdlib called stdlib_str2num which implements fast routines for converting strings to numerical types. The participant would get familiar with these implementations and subsequently:
      Create a full benchmark suite for the string to number conversion, across compiler vendors, operating systems, and CPU architectures.
      Explore ways to improve robustness and efficiency, e.g. error handling.
      Propose a shallow interface for the string_type facility in stdlib.
      Propose an enhancement to the loadtxt facility function to speed-up file reading.
      Depending on the advancement, the participant is also encouraged to include a roadmap for inclusion of the inverse conversion by following the intitiative in this thread ryu-based to_string function
      Relevant thread on Fortran Discrouse: Faster string to double
      Expected outcomes: Enhancement of stdlib fast string to number conversion
      Skills preferred: Fortran and C programming, understanding of floating-point arithmetic
      Difficulty: Hard, 350 hours
      Mentors: Jose Alves (@jalvesz), Carl Burkert (@carltoffel) Brad Richardson (@everythingfunctional), Ivan Pribec (@ivan-pi)
      
      ~~~~~~~~~~  
      Compile benchmarking code written in Fortran with LFortran and improving LFortran's performance on these benchmarks (LFortran)
      https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/fortran.html contains all the benchmark codes written for various problems such as n-body, sepctral norm, mandelbrot. The workflow would involve first doing bug fixes to compile the code (modifying the input code would be okay) with LFortran and producing correct outputs. Then, improving LFortran to perform better or equivalent to other Fortran compilers such as GFortran.
      n-body already compiles with workarounds with LFortran main. See, https://github.com/lfortran/lfortran/pull/1213. More work needs to be done for other benchmark codes.
      Expected outcomes: LFortran can compile as many benchmark codes as possible. Performing better than other compilers would be an additional plus.
      Skills preferred: Fortran and C++ programming
      Difficulty: intermediate/hard, 350 hours
      Mentors - Gagandeep Singh (Github - @czgdp1807)
      
      ~~~~~~~~~~
      Compile any Fortran code (LFortran)
      The primary goal is to compile as many codes as possible. We have identified and listed those at label:code-to-be-compiled.
      This project aims to pick up a code and get it compiled to ASR, then to LLVM, binary and assure that values align with GFortran (or other Fortran compilers). We can have several of these projects at the same time.
      Expected outcomes: LFortran can compile chosen code.
      Skills preferred: Fortran and C++ programming
      Difficulty: intermediate/hard, 350 hours
      Mentors - Pranav Goswami
      
      ~~~~~~~~~~
      Compiling SciPy with LFortran (LFortran)
      Currently LFortran compiles about 60% of all SciPy Fortran packages and can parse all the Fortran source code in SciPy. The goal of this project is to compile the rest of them. This project involves implementing the rest of the semantics that is needed to compile the Fortran files with LFortran.
      Being able to compile SciPy with LFortran would make a huge impact on both LFortran and SciPy.
      Expected outcomes: LFortran can compile all Fortran code in SciPy.
      Skills preferred: Fortran and C++ programming
      Difficulty: intermediate, 350 hours
      Mentors - Ondřej Čertík, Pranav Goswami
      
      ~~~~~~~~~~
      Compiling LAPACK with LFortran (LFortran)
      Progressing towards beta we need to compile as much of the LAPACK routines as possible. The goal of this project is to compile LAPACK Fortran codes. It involves implementing the rest of the semantics that is needed to compile the Fortran files with LFortran.
      Expected outcomes: LFortran can compile all code in LAPACK.
      Skills preferred: Fortran and C++ programming
      Difficulty: intermediate, 350 hours
      Mentors - Ondřej Čertík, Pranav Goswami
      
      ~~~~~~~~~~
      Allow running Fortran in the browser (LFortran)
      We have LFortran running in the browser using WASM here: https://dev.lfortran.org/, the goal of this project would be to improve the user interface. Here is a list of issues that the project can work on fixing: https://github.com/lfortran/lcompilers_frontend/issues
      This project would entail working with LFortran, LLVM, Emscripten, and Webassembly to allow running Fortran in the browser.
      Skills preferred: Fortran and C++ programming
      Difficulty: intermediate, 350 hours
      Mentors - Ondřej Čertík
      
      ~~~~~~~~~~
      Implementation of features on the ASR and LLVM level (LFortran)
      The roadmap https://gitlab.com/lfortran/lfortran/-/issues/272 issue contains a list of Fortran features that we want implemented. Each feature should be implemented at the ASR level and in the LLVM backend to be complete. If AST is missing for a given feature, then it has to be implemented also.
      Here you can pick a feature or a set of features from the list and propose it as a GSoC project. In other words, this project idea can accommodate multiple student projects.
      List of resources for more information and background:
      ASR.asdl, the comment at the top explains the design motivation
      asr_to_llvm.cpp is the LLVM backend
      ast_to_asr.cpp is the AST -> ASR conversion where all semantics checks are being done and compiler errors reported to the user
      Developer Tutorial
      If you have any questions, please do not hesitate to ask, we can discuss or provide more details.
      Mentors: Ondrej Certik (@certik)
      
      
      
      ~~~~~~~~~~
      MPI support (fortls)
      fortls has support for Fortran intrinsics, Standard modules and OpenMP. It does not however support MPI. The goal of this project is to add full support for completions, hover and signature help for MPI variables, subroutines and functions.
      Due to the size of the MPI standard, the process of extracting the necessary information from the standard such as names, interfaces and documentation will be automated. The student will be responsible for creating a scraper/parser to fetch the necessary information from the MPI standard and then create the serialised data (JSON) to be used by fortls.
      Discourse thread: MPI documentation and interfaces
      Expected outcomes: fortls will have completion and hover support for MPI.
      Skills preferred: Python programming and understanding of Fortran
      Difficulty: Intermediate, 175 hours
      Mentors: Giannis Nikiteas (@gnikit)
      
      
      ~~~~~~~~~~
      Semantic highlighting and collapsable scopes (fortls)
      As part of this project the student will add support to fortls for the Semantics Tokens request, which is used to provide improved syntax highlighting and the Folding Range request, which is used to provide collapsable scopes.
      Related Issues:
      fortls#56
      Expected outcomes: fortls will serve for semantic highlighting and collapsable scopes requests.
      Skills preferred: Python programming and understanding of Fortran
      Difficulty: Intermediate, 175 hours
      Mentors: Giannis Nikiteas (@gnikit)
      
      ~~~~~~~~~~
      Replace explicit LSP interface with pygls (fortls)
      fortls uses explicit interfaces to the Language Server Protocol (LSP). To decrease code duplication and increase maintainability, the work of maintaining the explicit interfaces should be replaced with the use of pygls' module.
      Related Issues:
      fortls#96
      Expected outcomes: fortls uses pygls' to define LSP interfaces, types and requests.
      Skills preferred: Python programming and understanding of the Language Server Protocol
      Difficulty: Hard, 350 hours
      Mentors: Giannis Nikiteas (@gnikit)
      
      
      ~~~~~~~~~~
      Python environment manager (vscode-fortran-support)
      In the Modern Fortran for VS Code extension, the use of Python as a means to install third party tools is essential. The goal of this project is to create a robust Python environment manager for installing and running third party tools such as fortls, fpm, findent, etc., taking into account the user's setup (venv, conda, system Python, etc.).
      Expected outcomes: Modern Fortran for VS Code will have a robust Python environment manager for installing and running third party tools.
      Skills preferred: Typescript, Python programming
      Difficulty: Hard, 175 hours
      Mentors: Giannis Nikiteas (@gnikit)
      
      
      ~~~~~~~~~~
      vscode integration with fpm (vscode-fortran-support)
      The goal of this project is to allow fpm integration with the Modern Fortran extension for Visual Studio Code, similar to how CMake and Meson are integrated in VS Code.
      Using an Activity bar icon, the user will be able to build and run projects, tests and examples. The student will be responsible for creating the GUI integration and the necessary backend to communicate with fpm.
      Expected outcomes: Modern Fortran for VS Code will have a GUI integration with fpm to build and run projects, tests and examples.
      Skills preferred: Typescript, Fortran programming
      Difficulty: Hard, 350 hours
      Mentors: Giannis Nikiteas (@gnikit)
      
      ~~~~~~~~~~
      Standard Conformance Suite
      Fortran compilers' support for ISO Fortran standards generally lag the publication of the standard by several years or longer. Fortran consultants Ian Chivers and Jane Sleightholme periodically publish a paper containing a table detailing the standard features supported by 10 compilers. Gathering the tabulated data requires a considerable amount of effort on the part of the authors and the compiler developers. The chosen venue for publishing the table also puts it behind a paywall: access requires a subscription to ACM SIGPLAN Fortran Forum. The project will automate the generation of the table, make it more detailed and empower the community to contribute to by submitting small tests to an open-source conformance test suite.
      Prior work:
      fortran-compiler-tests
      flibs chkfeatures
      Defunct
      Fortran Testsuite Proposal
      Expected outcomes: A comprehensive test suite that generates a report of standard conformance for any Fortran compiler. The suite is not expected to be 100% complete by the end of the project, but should be significant in terms of standard coverage.
      Skills preferred: Fortran programming, experience reading and interpreting the Fortran Standard, and writing tests
      Difficulty: Hard, 350 hours
      Mentors: Damian Rouson (@rouson), Arjen Markus (@arjenmarkus), Ondřej Čertík (@certik)
      
      ~~~~~~~~~~
      Coarray Fortran Framework of Efficient Interfaces to Network Environments (Caffeine)
      This project would add support for grouping images (parallel processes) into teams that allow submodes to execute independently. Caffeine 0.1.0 uses the GASNet-EX networking middleware software as a back end for supporting most of the non-coarray parallel features of Fortran 2018 except for the intrinsic derived team_type and related features. Work is underway to support the coarray features that most applications will need for expressing custom parallel algorithms. The teams feature set is the one significant non-coarray parallel group of features not yet implemented in Caffeine.
      Expected outcomes: Caffeine can be used to create images groups in execution parallel programs
      Skills preferred: Fortran and C programming
      Difficulty: Intermediate, 175 hours
      Mentors: Damian Rouson (@rouson)
      
      ~~~~~~~~~~
      Get fortran-lang/minpack to be used in SciPy
      fortran-lang/minpack #14
      The participant would work with Fortran-lang and SciPy teams toward implementing fortran-lang/minpack in SciPy.
      Expected outcomes: fortran-lang/minpack is incorporated into SciPy.
      Skills preferred: Fortran-C interop, Python programming
      Difficulty: Easy, 175 hours
      Mentors: Sebastian Ehlert (@awvwgk)
      
      ~~~~~~~~~~
      Improving fastGPT: Making it Faster, Easier to Use, and More General
      The fastGPT project is a Fortran implementation of GPT-2 that is comparable in speed to PyTorch. Although it is already very fast on CPUs, there is still room for improvement in terms of usability and performance on CPU and other architectures, such as GPUs.
      This project aims to explore various aspects of fastGPT to improve its usability and performance. Some potential areas of exploration include:
      Parallelism: Investigate the use of parallelism in fastGPT, including MPI and coarrays, to potentially make it even faster. Given that GPT inference is dominated by large matrix-matrix multiplications over a few layers, we will carefully investigate which parallel approach is the best (whether MPI, coarrays, OpenMP or just parallel BLAS that we already have).
      Reduced precision models: Experiment with using reduced precision models (e.g., 16-bit or 8-bit floats) instead of the default 32-bit to potentially speed up inference.
      GPU acceleration: Explore how to optimize fastGPT for GPU architectures to potentially make it even faster.
      UI improvements: Add a chat mode (similar to chatGPT). Explore how to make it easier to use as a grammar checker, or creating summaries, or other areas where GPT-2 is strong. Make it a nice Fortran library, installable using fpm, usable in other projects. Investigate how to use it with the neural-fortran project.
      Expected outcomes: Create an improved fastGPT implementation that is faster, easier to use, and more general.
      Skills preferred: Fortran, linear algebra
      Difficulty: Intermediate, 175 hours
      Mentors: Ondřej Čertík (@certik), Milan Curcic (@milancurcic)
      
      ~~~~~~~~~~
      Fortran Graphics Library
      Fortran does not have native graphics handling capabilities. While several bindings interfacing Fortran to graphics and plotting libraries are available (e.g., f03gl, sdl, pyplot, dislin, plplot ), no up-to-date open-source graphics package with a pure, modern Fortran API is available.
      The aim of this project is to lay out the basics of an object-oriented "canvas" representation in object-oriented Fortran. The contributor would implement, document, and test basic graphics classes (2d points, lines, brushes, etc.), an abstract graphics canvas API with backends to both file and graphics devices (i.e., bitmap, PNG, OpenGL, SVG, etc.) The outcome of this project would be a contribution to the development of a platform-agnostic graphics library for Fortran.
      Expected outcomes: Design and implement classes for 2d graphics primitives, a unified graphics canvas API, and several backend implementations.
      Skills preferred: Fortran, C, 2D graphics basics
      Difficulty: Intermediate, 350 hours
      Mentors: Federico Perini (@perazz)*
      
      
      ~~~~~~~~~~
      Improved generation of Fortran interfaces for PETSc
      PETSc, the Portable, Extensible Toolkit for Scientific Computation, pronounced PET-see, is for the scalable (parallel) solution of scientific applications modeled by partial differential equations (PDEs). It has bindings for C, Fortran, and Python (via petsc4py). PETSc also contains TAO, the Toolkit for Advanced Optimization, software library. It supports MPI, and GPUs through CUDA, HIP, Kokkos, or OpenCL, as well as hybrid MPI-GPU parallelism; it also supports the NEC-SX Tsubasa Vector Engine.
      Currently, only a part of the Fortran interfaces can be generated automatically using bfort. Since the manual generation of the remaining interfaces is tedious and error prone, this project is about an improved generation of Fortran interfaces from PETSc's C code.
      The main tasks of this project are
      Definition of a robust and future-proof structure for the Fortran interfaces
      Selection and/or development of a tool that creates the interfaces automatically
      More specifically, the first task is about finding a suitable structure of the C-to-Fortran interface that reduces the need of 'stubs' on the C and Fortran side making use of modern Fortran features where appropriate. This task will involve evaluating different approaches found in other projects taking into account the object-oriented approach of PETSc. Prototypes will be implemented manually and evaluated with the help of the PETSc community. The second task is then the automated generation of the Fortran interfaces using the approach selected in the first task. To this end, it will be evaluated whether an extension of bfort, the use of another existing tool, or the development of a completely new tool (probably in Python) is the most suitable approach.
      Links:
      PETSc
      bfort
      Fortran Wiki: Generating C Interfaces
      Fortran Discourse: ISO_C_binding
      Expected outcomes: Stable and robust autogeneration of Fortran interfaces for PETSc that works for almost all routines
      Skills preferred: Programming experience in multiple languages, ideally C and/or Fortran
      Difficulty: Intermediate, 350 hours
      Mentors: Martin Diehl (@MarDiehl)
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/fortran-lang/
    idea_list_url: https://github.com/fortran-lang/webpage/wiki/GSoC-2025-Project-ideas

  - organization_id: 44
    organization_name: Free and Open Source Silicon Foundation
    no_of_ideas: 19
    ideas_content: |
      
      ZynqParrot RISC-V Tracer
      ZynqParrot (https://github.com/black-parrot-hdk/zynq-parrot) is a framework for doing self-contained, FPGA-based "hostless" ASIC accelerator development. It is designed to be extremely general and has been used to prototype IP from individual ASIC/FPGA cores to full multicore processors. In addition, ZynqParrot has been used to bringup N=1 ASIC silicon in the lab.
      RISC-V provides a trace format specification (https://github.com/riscv-non-isa/riscv-trace-spec) which can be used for diagnostic performance and debugging. This project will design and integrate a RISC-V Trace implementation into the ZynqParrot environment, requiring SystemVerilog implementation + testing, Block Diagram (Vivado IPI) design and well as writing C++ driver to work in both Co-Simulation and Co-Emulation.
      Skill level: intermediate
      Project length: medium (175 hours)
      Mentors: Dan Petrisko
      Language/Tools: SystemVerilog, C++, some knowledge of computer architecture. RISC-V knowledge preferred but not required. FPGA tools such as Vivado strongly encouraged but not required.
      
      ~~~~~~~~~~
      Surfer memory and wide array support
      Surfer (https://surfer-project.org) is an open source waveform viewer designed to be snappy and extensible. Waveform viewers work well for visualizing individual signals, but for large arrays or memories users are often more interested in changes to individual elements rather than the whole array.
      For this, a separate UI element where memory content can be visualized as a table would be much more useful. Beyond just visualizing the content, also having the ability to highlights elements that have changed between timestamps or around the cursor would be extra useful.
      Skill level: intermediate
      Project Length: medium (175 hours)
      Mentors: Frans Skarman Oscar Gustafsson
      Languages/Tools: Rust. Familiarity with hardware design is helpful to have some context of what the tool is used for is helpful, but the project itself is pure software. Some familiarity with egui is also helpful though certainly not required.
      
      ~~~~~~~~~~
      cocotb v2 Code Migration Helper
      The upcoming cocotb v2.x release will have quite some breaking changes (see https://docs.cocotb.org/en/latest/release_notes.html), so users and extension developers will have to actively migrate existing code.
      A code migration helper tool would be helpful, even if it is not perfect.
      Some links:
      https://libcst.readthedocs.io/
      https://lukeplant.me.uk/blog/posts/tools-for-rewriting-python-code/
      Skill level: Intermediate/Advanced
      Duration: medium (175 hours)
      Language/Tools: Python, cocotb
      Mentor: Kaleb Barrett

      ~~~~~~~~~~
      Generate Counter Examples for Bounded Model Checks in CIRCT
      The CIRCT project has its own bounded model checking tool, circt-bmc. It takes a hardware design described in CIRCT's MLIR dialects and translates it into a program that uses the Z3 SMT solver to formally prove assertions. If it finds a way how assertions can be violated, it simply terminates with an error message. This is not very useful for a user that is trying to debug a hardware design that they have written. Instead, we would like circt-bmc to produce a counter-example, essentially a signal trace that shows and example of how the assertions can be violated. The Z3 SMT solver actually provides a counter-example as part of its checking, circt-bmc just does not use that yet.
      We would love you to extend circt-bmc with a counter-example feature that produces a signal trace for violated assertions, ideally a VCD waveform as a starting point. This will require you to modify the lowering pass that translates a hardware design to Z3 solver calls: in addition to the asserts that need to be checked, you will also want to translate any named ports, wires, registers into the corresponding Z3 solver expressions. The bounded model check can then take a snapshot of all these expressions in every time step. When Z3 finds a counter-example, you can go through every time step, evaluate all the solver expression for all user-visible names, and write them to a waveform.
      This may also be an excellent opportunity to introduce a waveform writing library for CIRCT. Eventually, we'd want different tools in CIRCT to be able to write various waveform formats such as VCD, FST, etc. It would be great if there is a common interface for waveform writers, and if CIRCT could then provide various implementations for different waveform formats. Tools like Arcilator, circt-bmc, and circt-lec would then use this library to produce signal traces.
      CIRCT is based on MLIR and LLVM, and are implemented in C++. So you'll definitely want to have some experience writing C++ code, since LLVM-based projects often follow a fairly peculiar and performance-conscious style of C++. You may also benefit from knowing a little bit about SAT and SMT solvers, and how bounded model checks can be implemented incrementally using these solvers.
      Skill Level: Medium
      Duration: 175 hours or 350 hours
      Language/Tools: C++, CIRCT, MLIR, LLVM
      Mentor: Fabian Schuiki,  Martin Erhart, and others in the CIRCT community

      ~~~~~~~~~~
      Spike + Sim-X
      The project is to interface Spike with Sim-X. Spike is a functional RISC-V ISA simulator and Sim-X is a high-level simulator for the Vortex GPGPU.
      Existing work allowed us to integrate the Vortex GPGPU RTL in the OpenPiton multi-core research platform (https://cea.hal.science/cea-04772235/document). To ease programming though, we would like to test software correctness using a high-level simulator. It would be faster than relying on RTL simulation. Interfacing Spike with Sim-X would allow us to simulate functionaly our heterogeneous CPUs+GPU shared-memory architecture, hence allowing us to ease future software development.
      Skill level: Intermediate
      Duration: medium (175 hours)
      Language/Tools: C++, RISC-V GNU Cross-compiler, Vortex LLVM compiler
      Mentor: Davy Million

      ~~~~~~~~~~
      OpenRISC Linux Feature Development
      The OpenRISC Linux kernel support is under constant development but there are certain Linux facilities that are not yet used or available on the OpenRISC platform.
      This project will have the student developing, testing and sending patches up to the Linux kernel. This includes:
      Use the cacheinfo API for reporting CPU details in OpenRISC Linux.
      Add tracing facilities to OpenRISC Linux including: jump_label, ftrace, kprobes, eBPF etc.
      Skill level: Advanced
      Project Length: large
      Language/Tools: Linux, C, Assembly, OpenRISC architecture
      Mentor: Stafford Horne
      
      ~~~~~~~~~~
      Generic MinimumLinuxBoot for RTL Simulations
      This project consists of booting Linux in Qemu, save the memory state, thencontinue the simulation in an RTL Simulation of OpenPiton. The first part of the project consists of understanding what states need to be saved, probably a combination of the TLB and MMU states as an starting point could be enough. Then, this state needs to be saved in a file format that the checkpoint mechanism of Verilator understand or create a synthetic benchmark that makes the proper MMU configuration. The second part of the project is adding the necessary support in OpenPiton Simulation infrastructure to continue the simulation and being able to launch some applications.
      OpenPiton uses different languages like Verilog, Python, Perl, and C. Verilator C++. Additionally, some background in hardware design is useful.
      Skill Level: Medium/Advanced
      Duration: 350 hours
      Language/Tools: Verilog, C++, SystemVerilog
      Mentors: Guillem López Paradís and Jonathan Balkind
      
      ~~~~~~~~~~
      Using AI to Improve Open-Source IP
      What if we could instantly improve all the existing open-source Verilog by reducing its size, improving its maintainability, making it more configurable, identifying bugs, and creating visualization for it? How could you possibly do all those things over one summer as a student? Well, you can't. But you could help to make significant strides in that direction.
      Transaction-Level Verilog (TL-Verilog) models are smaller, cleaner, and less bug-prone than their Verilog counterparts. But there's not much TL-Verilog in the wild yet. If you ask ChatGPT to convert your code today, you won't be happy with the results. But with careful coaching, AI models can be trained for the job.
      Since LLMs understand Verilog better than TL-Verilog, we do as much as possible with the Verilog to prepare it for conversion to TL-Verilog. An initial flow has been put in place for this. A Python program iterates through a recipe of prompts, each performing an incremental refactoring step. After each step, formal equivalence verification (FEV) is used to ensure functional correctness. Human intervention is possible and is currently needed at almost every step.
      Your project will be to use and enhance this flow to refactor an open-source Verilog project like SERV. In the process, you'll contribute to the automation, and your work will become training data to improve future LLMs for this task.
      Skill level: Intermediate/Advanced
      Duration: 350 hours
      Language/Tools: Verilog, Python, TL-Verilog
      Repo: https://github.com/stevehoover/conversion-to-TLV
      Mentor: Steve Hoover

      ~~~~~~~~~~
      Metro-MPI++
      Metro-MPI is a generic methodology to distribute RTL simulation and unlock SoCs’ inherent parallelism. We partition well-defined blocks within designs into isolated simulation processes that communicate via MPI message passing. Metro-MPI works particularly well with replicated blocks of comparable size, such as manycores with NoCs. Verilator is an open-source Verilog simulator and linting tool that translates Verilog HDL code into optimized C++ or SystemC code, allowing for fast, cycle-accurate simulation of digital circuits.
      Automatic partitions with Metro-MPI We want to add the automatic support of metro-MPI inside other tools, like Verilator or Essent. The idea would be to detect the top modules that are suitable to be interfaced with metro-MPI. An automatic partition algorithm would be ideal although we can start with a user-guided approach like pragmas. The project will be divided into two big milestones: the initial task is to use the methodology from Metro-MPI to speed up the simulation (e.g. using messages with MPI to communicate between partitions); the second task would be to influence the partitions of the design to ease the usage of MPI between them.
      Metro-MPI @FPGA We would like to explore the same methodology that Metro-MPI introduces but to connect multiple FPGAs with MPI.
      We are also open to other improvements on metro-MPI:
      Explore the support of OpenMP instead of openMPI
      Explore making the simulations faster with statistical analysis: predict values that will take the MPI messages on a certain simulation, making checkpoints and rolling back in case of predicting wrong.
      Improve current Verilator support from v4 to v5.
      Scale Simulations up to 10K cores (currently we support up to 1024 cores)
      Metro-MPI uses Verilog and C++. Additionally, some background in hardware design is useful.
      Skill Level: Medium/Advanced
      Duration: 350 hours
      Language/Tools: C++, MPI, SystemVerilog
      Mentors: Guillem López Paradís and Jonathan Balkind

      ~~~~~~~~~~  
      OpenLane Web-based Graphical User Interface
      Details: OpenLane is the premier open source RTL-to-GDSII flow. Versions 2.0 or higher's modular architecture allows for constructing complex flows using nodes called "steps," Users who are adept in Python can create many such complex flows, including flows that are parallel. A web-based GUI of some kind (based on a library such as ReactFlow https://reactflow.dev) would greatly enhance the ability of novice users to create custom OpenLane-based flows with ease.
      Skill level: Beginner or Intermediate
      Duration: 175 hrs.
      Language/Tools:: TypeScript (React), Python
      Mentor: Mohamed Gaber, Mohamed Shalan
      ~~~~~~~~~~
      LiteX SMP SoC for OpenRISC
      The LiteX project makes creating FPGA-based SoCs easy. LiteX supports creating SoCs containing OpenRISC CPU cores. Up until now however, there have been no LiteX SoCs that support running OpenRISC multicore/SMP Linux. The linux-on-litex-vexrisc project provides a good example of how to develop and document getting Linux up and running on a LiteX SoC; including multicore.
      Using linux-on-litex-vexrisc as an example, this project will have the student creating a project to help people get up and running with OpenRISC. The final goal shall be to have a documented multicore OpenRISC LiteX SoC running Linux SMP.
      Skill level: Advanced
      Project Length: large
      Language/Tools: Verilog, LiteX, Linux, Python, OpenRISC architecture
      Mentor: Stafford Horne

      ~~~~~~~~~~
      Improve CIRCT's Verilog Frontend
      The CIRCT project uses the Slang frontend to parse the SystemVerilog hardware description language. The sv-tests project runs many SystemVerilog frontends on a benchmark suite of input files to test their quality. We would love you to use the sv-tests results as a starting point to find key missing features that you can add to circt-verilog and fix failing tests. Tests often fail for similar reasons, and fixing small things can cause large numbers of tests to start passing.
      SystemVerilog is a complicated language and CIRCT builds a deep stack of intermediate representations using MLIR to process it. The Slang frontend produces an Abstract Syntax Tree which the ImportVerilog pass converts into the Moore dialect, the first IR level in circt-verilog. Various optimizations are already performed at this level. Then the MooreToCore conversion pass lowers the Moore dialect to the HW, Comb, Seq, and LLHD dialects for further processing. Finally, several optimization passed implemented on the LLHD dialect analyze the hardware design and detect common structures. If you want to sink your teeth into compiler and IR design, this is the perfect project for you!
      Slang and CIRCT are based on MLIR and LLVM, and are implemented in C++. So you'll definitely want to have some experience writing C++ code, since LLVM-based projects often follow a fairly peculiar and performance-conscious style of C++.
      Skill Level: Advanced
      Duration: 175 hours or 350 hours
      Language/Tools: C++, CIRCT, MLIR, LLVM
      Mentor: Fabian Schuiki, Martin Erhart, and others in the CIRCT community

      ~~~~~~~~~~
      Architectural Improvements to OpenPiton+Ariane for RISC-V Profile Compliance
      OpenPiton+Ariane is a permissively-licensed RISC-V manycore processor, built as a collaboration between the PULP Platform from ETH Zürich and the OpenPiton Platform from Princeton University. We would like to co-optimise OpenPiton and Ariane/CVA6 in their combined platform, to improve performance of the processor both in FPGA emulation systems and for eventual silicon chips. We are particularly interested in moving the platform toward RISC-V RVA23 profile compliance and so developing any new extension support needed for this purpose would be a great GSoC opportunity!
      Skill level: Intermediate
      Duration: 175 or 350 hours
      Language/Tools: Verilog, SystemVerilog, RISC-V
      Mentor: Jonathan Balkind, Nils Wistoff
      
      ~~~~~~~~~~
      Cohort++
      Cohort is a framework designed to integrate hardware accelerators into software systems while maximizing efficiency seamlessly. It introduces Software-Oriented Acceleration (SOA), a paradigm that simplifies and optimizes interactions between software and hardware accelerators. By leveraging existing software abstractions—such as shared-memory queues—Cohort enables a streamlined, high-performance communication channel between software components and accelerators.
      This project consists of improving the performance of OpenPiton memory hierarchy to better suit Cohort. For example, there is prior work on supporting wider NoCs, and cachelines in OpenPiton; we changing the Cohort engine's interaction with the coherence protocol; multiple MMU outstanding requests for higher performance.
      We have other ideas to work more on Cohort software support and we are also open to new proposals. Some examples:
      Support for other data structures instead of only queues
      Connect the openMP and/or openMPI runtime library to use Cohort queues
      Add the support for PRGA to be used with Cohort
      Skill Level: Medium/Advanced
      Duration: 350 hours
      Language/Tools: C++, SystemVerilog
      Mentors: Guillem López Paradís , Davy Million and Jonathan Balkind
      
      ~~~~~~~~~~
      Seamless multi-frontend support for OpenLane
      Details: OpenLane is the premier open source RTL-to-GDSII flow. Versions 2.0+ currently support handling multiple frontends for compilation:
      Yosys Default - Verilog
      Synlig - SystemVerilog
      GHDL - VHDL (x86-64-only)
      However, in the cases of VHDL and Verilog specifically– there is no way to mix and match Verilog and VHDL in one design, for example, which is common when reusing IPs.
      This task proposes a retool to OpenLane synthesis to, instead of having two different flows (Classic and VHDLClassic), have one flow accepting a heterogeneous list of files, which can then be inspected to determine the proper frontend to be used.
      The project may involve enhancements to one or more of the C++-based Yosys frontends, as well as the addition of more frontends for languages such as Chisel and Amaranth.
      Skill level: Intermediate
      Duration: 175 hrs.
      Language/Tools: Python, Verilog, C++, Nix
      Mentor: Kareem Farid, Mohamed Shalan

      ~~~~~~~~~~
      OpenRISC Benchmarking and Performance improvements
      The OpenRISC CPU architecture has multiple CPU implementations including the mor1kx and marocchino. Recent testing has shown that memory access on the marocchino is slightly slower compared to the mor1kx.
      This project will have the student:
      Continue from where the 2024 GSoC student left off.
      Use tools like the Embench modern benchmark suite to measure OpenRISC processor and compiler toolchain performance.
      Document the OpenRISC performance at Embench IoT results to be able to compare OpenRISC vs other popular CPUs.
      Track down and improve OpenRISC CPU performance by finding and fixing deficiencies in the verilog designed cores.
      Skill level: Advanced
      Project Length: large
      Language/Tools: Verilog, Shell scripting, C, Assembly, Python
      Mentor: Stafford Horne

      ~~~~~~~~~~
      OpenLane Flow Declaration GUI
      Details: OpenLane is the premier open source RTL-to-GDSII flow. Versions 2.0 or higher's modular architecture allows for constructing complex flows using nodes called "steps."
      Users who are adept in Python can create many such complex flows, including flows that may run multiple steps in parallel, but those who are not may face difficulty doing so.
      A web-based GUI of some kind (based on a library such as ReactFlow https://reactflow.dev) would greatly enhance the ability of novice users to create custom OpenLane-based flows with ease.
      Skill level: Beginner to Intermediate
      Duration: 175 hrs.
      Language/Tools:: TypeScript (React), Python
      Mentor: Mohamed Gaber, Mohamed Shalan
      
      ~~~~~~~~~~
      Adding TL-Verilog Support to Surfer
      Details: Surfer is a modern open-source waveform viewer that evolved alongside the Spade HDL. It has gained broader popularity beyond the Spade ecosystem, and adding support for other emerging HDL capabilities will benefit the community.
      TL-Verilog models have higher-level knowledge that can be reflected in a waveform viewer to enhance the debugging experience. Most notably, TL-Verilog signals can be "invalid". Invalidity is, in some respects, similar to dont-care state. One distinction is that validity is compatible with two-state simulators, like Verilator.
      This project will focus on two main features to enhance TL-Verilog waveforms in Surfer:
      Displaying TL-Verilog-style signal and hierarchy names in TL-Verilog standard colors.
      Reflecting validity on signal values.
      These two features can currently be seen in the Makerchip IDE's waveform viewer.
      Skill level: Medium/advanced
      Language/Tools: Rust
      Duration: 350 hrs
      Repo: https://gitlab.com/surfer-project/surfer
      Mentors: Frans Skarman (creator of Surfer and Spade), Oscar Gustafsson, Steve Hoover (creator of TL-Verilog & Makerchip)
      
      ~~~~~~~~~~
      Device-Under-Test Python Typing Stub Generator for cocotb tests
      cocotb tests manipulate the signals of the Device-Under-Test (DUT) to verify the design, but what was the name of that signal I needed to wiggle???
      If we had a Python typing stub for the DUT, we could get the Pylance VS Code extension to help us by listing the signals in the DUT in an autocomplete pop-up; we could use Python static type checkers like mypy to ensure we didn't fat-finger the name of some module; or use generated typing stubs to create abstract bus definitions that users could "mock out" when needed.
      cocotb has existing DUT introspection capabilities that could be leveraged to generate Python typing stubs. However, existing features may not be enough, and additional features may need to be added, in addition to the generator itself. Perhaps even, this code could be set up for future use by a language server, like slang, to generate even more informative typing stubs.
      See more information here.
      Skill level: Beginner to Intermediate
      Duration: medium (175 hours)
      Language/Tools: Python, cocotb
      Mentor: Kaleb Barrett
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/free-and-open-source-silicon-foundation/
    idea_list_url: https://fossi-foundation.org/gsoc/gsoc25-ideas

  - organization_id: 45
    organization_name: FreeCAD
    no_of_ideas: 38
    ideas_content: |

      Improve FreeCAD Hidden Line Removal
      Outline
      FreeCAD's Technical Drawing module (TechDraw) relies heavily on the OpenCascade Hidden Line Removal algorithms. These algorithms can be very slow, do not provide progress reporting and do not provide any linkage between the input shape and the output.

      Details
      The TechDraw module provides projections, section views and detail views of 3D model components and assemblies developed in FreeCAD modules such as Part, PartDesign and Draft.

      Expected Outcome
      a) develop new code for projecting shapes and creating the geometry for technical drawings.
      -or-
      b) modify the existing OpenCascade code as an enhancement.

      Project Properties
      Both OpenCascade and TechDraw are written in C++.

      Skills
      The student should have a good knowledge of C++ and be familar with graphics topics such as the painters algorithm, face detection and hidden line removal.
      Knowledge of technical drawing standards and previous exposure to Qt will be helpful. Familiarity with OpenCascade is a definite plus.

      Difficulty
      Hard

      Size
      long

      Additional Information
      Potential mentor(s): wandererfan
      Organization website: https://freecadweb.org
      Communication channels: https://forum.freecadweb.org

      ~~~~~~~~~~
      Create visual programming nodes for generating BIM data with IfcSverchok

      Outline
      Blender allows visual node programming, similar to Grasshopper in Rhino. Grasshopper has a really neat extension called GeometryGym which allows users to use visual node programming to generate building geometry and data using the "IFC" international standard. It's super awesome, and something like that doesn't exist yet in the open source world with only free software. So, let's create it!

      Some of this is already started, so the basics are already coded, but now it needs to be tested, debugged, and a whole bunch more nodes written and tested out in experiments in generating buildings with visual nodes.

      https://github.com/IfcOpenShell/IfcOpenShell/tree/v0.7.0/src/ifcsverchok is the source code, take a look, install it, and play around!

      Expected Outcome
      A whole bunch more nodes, and little examples of generating buildings via nodes, and getting an IFC output.

      Future Possibilities
      If we code it right, in the future, these nodes can be made agnostic of Blender and also work in FreeCAD (e.g. through PyFlow). So this allows multiple authoring apps to benefit from visual programming.

      Project Properties
      Skills
      Python
      Knowledge of visual programming (knowledge with Grasshopper / Sverchok super useful!), if not, get ready to watch tutorials on them!
      Basic Blender knowledge
      Difficulty
      Medium

      Size
      Medium (175h)
      The IfcOpenShell API is exposed as visual nodes, and basic geometry creation nodes are related to IFC.

      Long (350h)
      Proof of concept of simple visual node programming tasks are recreated with Sverchok and IFC nodes.

      Additional Information
      Potential mentor(s): Dion Moult
      Organization website: https://ifcopenshell.org
      Communication channels: https://community.osarch.org , ##architect on Freenode , and https://github.com/IfcOpenShell/IfcOpenShell/issues
      
      ~~~~~~~~~~

      Scripts for generating simple animations (e.g. appear / disappear, bounce, appear left to right, fade in from above, etc)



      Outline
      Often, construction firms need to visualise animations of construction sequencing. A project timeline will be created, and related to individual model elements. For example, when a concrete slab is poured, it is linked to a 3D object called a slab. We need the ability to automatically generate animations from Blender where objects appear / disappear in various different ways when they start / end their task in the project timeline. The systems for describing project timelines is already in place, so now we need a little animation generator!

      Details
      Expected Outcome
      A series of small scripts that take objects and can automatically animate the visibility, locations, or staggered appearances of building elements, as well as sub elements, and basic scripts that correlate real world time to animation frames, and frames per second, and generate an animated timeline bar in various styles.

      Future Possibilities
      This animation system can be then used from BIM models either in Blender, FreeCAD, or via other software altogether, so it has quite a large impact on the ecosystem.

      Skills
      Basic knowledge of the principles of animation (keyframing)
      Basic Blender animation (you can do some tutorials and get up to speed pretty quick)
      Python
      Artistic sense! We should offer beautiful and elegant animations!
      Difficulty
      Easy

      Additional Information
      Potential mentor(s): Dion Moult
      Organization website: https://ifcopenshell.org
      Communication channels: https://community.osarch.org , ##architect on Freenode , and https://github.com/IfcOpenShell/IfcOpenShell/issues

      ~~~~~~~~~~

 
      Create a 2D nesting tool	C++/Python, CAM/BIM, OpenCasCade	350h	Medium/Hard
      Open
      Feature
      Open
      Create a 2D nesting tool
      #19576
      Feature
      @yorikvanhavre
      Description
      yorikvanhavre
      opened last month · edited by yorikvanhavre
      Problem description
      Nesting is the process of arranging different shapes inside one bigger container shape. This is often used in CNC or laser cutting operations, to try to figure out how to cut several shapes out of a piece of material, while wasting as little as possible of the material.

      FreeCAD currently has a nesting tool, but it is very inefficient and fails often.

      This project should:

      Explore and assess the current tool, where it works and where it fails
      Investigate existing, open-source nesting solutions
      Find out if any is usable in FreeCAD, both technically (code-wise) and legally (compatible license)
      Research possible algorithms, or ways to better the current algorithm
      Decide either to use an external solution, or build or refactor our own algorithm
      Adapt the current tool to use it
      Difficulty
      Medium/Hard

      Workbenches/Technologies
      CAM/BIM, OpenCasCade, C++/Python

      Project size
      350h

      ~~~~~~~~~~

      Create fillets between 2 arcs in Sketcher	C++, Sketcher	175h	Medium/Hard
      Open
      Feature
      @KrisCouvreur
      Description
      KrisCouvreur
      opened on Feb 8 · edited by yorikvanhavre
      Problem description
      Fillet between 2 arcs in Sketcher workbench : can someone write the Python code for this ?
      In attachment the math behind this.
      Pull request was not allowed.

      Fillet between 2 arcs.pdf

      Difficulty
      Medium/Hard

      Technology/workbenches
      Sketcher, OpenCasCade

      Project size
      175h

      ~~~~~~~~~~

      Allow to place windows and doors with different insertion points	Python, Qt, BIM, Coin3D, OpenCasCade	175h	Medium
      Open
      Feature
      Open
      [BIM] Add the "Window/Door Alignment" property
      #19552
      Feature
      @kaiwas
      Description
      kaiwas
      opened last month · edited by yorikvanhavre
      Gsoc idea summary
      See below

      Is there an existing issue for this?

      I have searched the existing issues
      Problem description
      Currently, all windows and doors are built relative to the lower left edge (origin).
      If you add the "Alignment" property, windows and doors can be placed in a more convenient way. For example, with the "Right" alignment, the origin is shifted by minus width and we can place the window relative to the end of the wall.
      If the alignment is "Center", the origin is shifted by minus half the width and we can snap to the center point of the wall.

      I have put together an approximate version using expressions, but this feature should be at the program level without using expressions.
      Video demonstration.

      vokoscreenNG-2025-02-12_09-14-56.mp4 
      Image

      The test file is attached. Remove the Zip extension.

      Win_align.FCStd.zip

      Full version info
      OS: Manjaro Linux (KDE/plasma/xcb)
      Architecture: x86_64
      Version: 1.1.0dev.40176 (Git) Conda AppImage
      Build type: Release
      Branch: main
      Hash: 2745f436026b6f1fb84dbaaf89ea22b5fb4c2295
      Python 3.11.9, Qt 5.15.13, Coin 4.0.3, Vtk 9.2.6, IfcOpenShell 0.7.0, OCC 7.7.2
      Locale: Russian/Russia (ru_RU)
      Stylesheet/Theme/QtStyle: OpenLight.qss/OpenLight/Fusion
      Logical/physical DPI: 96/91.7938
      Installed mods: 
        * FreeCAD_SketchArch
        * PitchedRoof
        * Road 2025.2.6
        * addFC 1.3.0
        * freecad.gears 1.3.0
        * sheetmetal 0.7.10
        * OpenTheme 2024.9.1
      Subproject(s) affected?
      BIM

      Anything else?
      No response

      Code of Conduct

      I agree to follow this project's Code of Conduct

      ~~~~~~~~~~

      Improve FreeCAD Hidden Line Removal	C++, OpenCasCade, Part, TechDraw	350h	Hard
      Open
      Feature
      Open
      [Part] Improve FreeCAD Hidden Line Removal
      #19442
      Feature
      @yorikvanhavre
      Description
      yorikvanhavre
      opened on Feb 6 · edited by yorikvanhavre
      Outline
      FreeCAD's Technical Drawing module (TechDraw) relies heavily on the OpenCascade Hidden Line Removal algorithms. These algorithms can be very slow, do not provide progress reporting and do not provide any linkage between the input shape and the output.

      Details
      The TechDraw module provides projections, section views and detail views of 3D model components and assemblies developed in FreeCAD modules such as Part, PartDesign and Draft.

      Expected Outcome
      a) develop new code for projecting shapes and creating the geometry for technical drawings.
      -or-
      b) modify the existing OpenCascade code as an enhancement.

      Project Properties
      Both OpenCascade and TechDraw are written in C++.

      Skills
      The student should have a good knowledge of C++ and be familar with graphics topics such as the painters algorithm, face detection and hidden line removal.
      Knowledge of technical drawing standards and previous exposure to Qt will be helpful. Familiarity with OpenCascade is a definite plus.

      Difficulty
      Hard

      Size
      long

      Additional Information
      Potential mentor(s): wandererfan
      Organization website: https://freecadweb.org
      Communication channels: https://forum.freecadweb.org
      Migrated from opencax/GSoC#69 (comment)

      ~~~~~~~~~~

      Improve API of the user preferences system	C++, Preferences, User Interface	175h	Medium
      Open
      Feature
      Open
      No way to reset individual preferences / display which setting was changed by the user or theme
      #19171
      Feature
      @maxwxyz
      Description
      maxwxyz
      opened on Jan 21 · edited by maxwxyz
      Is there an existing issue for this?

      I have searched the existing issues
      Problem description
      Currently, the user can only reset all preferences, the preferences from the tab or the group. There is no way to reset individual preferences.
      There is also no way to see, which preferences were changed in comparison to the default value.

      I propose a similar I as in existing apps, where any changed preference is displayed in bold with a reset button next to it. Hovering the reset button would show the default value, clicking it would only reset this preference field.

      UI Example from Prusa Slicer:

      Image

      Image

      Similar UI in Firefox:

      Image

      It would be great to have some sort of information on changes based on a different setting: For example, many TechDraw preferences changes when you switch from ASME to ISO. This relation, why a preference changed and because of which setting it has been changed (and the default when choosing the parent setting) would be great.

      Full version info
      OS: Windows 10 build 19045
      Architecture: x86_64
      Version: 1.1.0dev.39896 (Git) Conda
      Build type: Release
      Branch: main
      Hash: a977fade2de741c94c9efa59b1c2c26df18eb631
      Python 3.11.11, Qt 5.15.15, Coin 4.0.3, Vtk 9.3.0, OCC 7.8.1
      Locale: German/Germany (de_DE)
      Stylesheet/Theme/QtStyle: FreeCAD Light.qss/FreeCAD Light/Fusion
      Installed mods: 
        * Curves 0.6.51
        * fasteners 0.5.32
        * freecad.gears 1.2.0
        * Manipulator 1.5.7
      Subproject(s) affected?
      Core

      Anything else?
      No response

      Code of Conduct

      I agree to follow this project's Code of Conduct


      ~~~~~~~~~~

      Design a finer way to copy/paste object attributes	C++/Python, BIM, Part, Addons, User Interface	175h	Medium
      Open
      Feature
      Open
      Part: No way to copy / paste object properties or attributes
      #17749
      Feature
      @maxwxyz
      Description
      maxwxyz
      opened on Nov 8, 2024 · edited by maxwxyz
      Is there an existing issue for this?

      I have searched the existing issues
      Problem description
      There is currently no way to copy properties from one object to a different object, e.g. placement values.

      For example: Copying one object's placement properties and selecting a different object and pasting them so the placement property is transformed to the new object.
      The workflow could look like this:

      Right click an object --> copy placement
      Right click a different object --> paste placement
      In the case of placement there is a workaround: Open the placement editor while the old part is selected, select the new object and hit apply.

      This could be extended for other properties, e.g. material/appearance, display modes, ...
      Maybe the object can just be copied and then there is a Paste special command where the user can choose what to paste (everything = as today, or a selection of properties).

      Full version info
      OS: Windows 11 build 26100
      Architecture: x86_64
      Version: 1.1.0dev.39100 (Git)
      Build type: Release
      Branch: main
      Hash: 8865450a3e14220925e0e449c0f1f79056b4fb89
      Python 3.11.10, Qt 5.15.15, Coin 4.0.3, Vtk 9.3.0, OCC 7.8.1
      Locale: German/Germany (de_DE)
      Stylesheet/Theme/QtStyle: OpenDark.qss/OpenDark/Fusion
      Installed mods: 
        * CfdOF 1.27.13
        * Curves 0.6.51
        * dodo 1.0.1
        * fasteners 0.5.29
        * freecad.gears 1.3.0
        * Manipulator 1.5.7
        * OpenTheme 2024.9.1
        * OpticsWorkbench 1.0.25
        * Rocket 4.0.0
        * sheetmetal 0.5.3
        * Silk 0.1.5
      Subproject(s) affected?
      Part

      Anything else?
      No response

      Code of Conduct

      I agree to follow this project's Code of Conduct

      ~~~~~~~~~~

      Diagnose and explore solutions to performance issues with large files	C++, Core, Performance, User Interface	350h	Hard

      Performance issues with large files (hover/preselection/navigation) #17185
      Open
      Bug
      0 / 2
      0 of 2 issues completed
      Open
      Performance issues with large files (hover/preselection/navigation)
      #17185
      Bug
      0 / 2
      0 of 2 issues completed
      @maxwxyz
      Description
      maxwxyz
      opened on Oct 11, 2024 · edited by maxwxyz
      Is there an existing issue for this?

      I have searched the existing issues
      Problem description
      When working in large files selecting/preselection is super slow which leads to lagging when starting to orbit or move the camera.
      I guess that is also the case why moving around in the scene is so hard because it takes about 5 seconds where nothing happens, then I can rotate without performance issues

      It seems to be related that the app checks what is under the cursor. Just scrolling for zooming in and out takes 2 seconds until it starts. when it's started I can zoom in and out without issues when holding the mouse at the same position. Moving the mouse freezes again for 2 seconds then it works normally.

      The app behaves normally until the cursor is over geometry.
      When the mouse is moved without clicks over the geometry the preselection highlight of faces or edges lags behind significantly, it also takes a few seconds when clicking that the element gets selected.
      When the mouse cursor is not over geometry (just over the background) the navigation and orbiting starts instantly, so no issues.

      PC should be able to handle this without issues:
      11th Gen Intel i7-11850H @2,5GHz; 32 GB RAM; NVIDIA T1200.

      @Rexbas @kadet1090 FYI
      The file itself is around 190 mb and has a lot of nested bodies in parts in other part containers. I cannot provide the file.

      Full version info
      OS: Windows 10 build 19045
      Word size of FreeCAD: 64-bit
      Version: 1.1.0dev.38923 (Git)
      Build type: Release
      Branch: main
      Hash: d20cb9e6ee198beb2bfd7e72d3dec0a575e3f28c
      Python 3.11.9, Qt 5.15.13, Coin 4.0.3, Vtk 9.2.6, OCC 7.7.2
      Locale: German/Germany (de_DE)
      Stylesheet/Theme/QtStyle: unset/FreeCAD Classic/Qt default
      Installed mods: 
        * Curves 0.6.50
        * fasteners 0.5.29
        * freecad.gears 1.2.0
        * Manipulator 1.5.7
      Subproject(s) affected?
      Core

      Anything else?
      No response

      Code of Conduct

      I agree to follow this project's Code of Conduct


      ~~~~~~~~~~

      Implement Draft Analysis in Part Design	C++, Part Design	350h/175h	Medium
      Open
      Feature
      Open
      PartDesign: Draft Analysis not available
      #16099
      Feature
      @maxwxyz
      Description
      maxwxyz
      opened on Aug 28, 2024
      Is there an existing issue for this?

      I have searched the existing issues
      Problem description
      Currently there is no option to perform a draft analysis to inspect the model to be able to analyze whether the part model is manufacturable based on the draft condition applied.
      It is necessary that the part can be removed easily from the panel dies (in case of Sheet metal part) or Mold (in case of casting).

      Implementation in CATIA:
      https://skill-lync.com/blogs/all-about-draft-analysis-using-catia

      original

      grafik

      Full version info
      OS: Windows 10 build 19045
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.38553 (Git)
      Build type: Release
      Branch: main
      Hash: 59c1ccec3e6b70f56eeee8f94d361019b84bd850
      Python 3.11.9, Qt 5.15.13, Coin 4.0.2, Vtk 9.2.6, OCC 7.7.2
      Locale: German/Germany (de_DE)
      Installed mods: 
        * Curves 0.6.42
        * fasteners 0.5.25
        * freecad.gears 1.2.0
        * Manipulator 1.5.7
      Subproject(s) affected?
      PartDesign

      Anything else?
      Maybe related to the implementation of
      #15028

      @pierreporte FYI

      Code of Conduct

      I agree to follow this project's Code of Conduct


      ~~~~~~~~~~

      TechDraw: Export layered PDF File format	C++, PDF, TechDraw	175h	Medium

      Is there an existing issue for this?

      I have searched the existing issues
      Problem description
      All commercial CAD software usually export drawing in a layered PDF format. This allows the user to hide certain layers when viewing the PDF later or extract certain layers only.

      Usually they provide the following layers in this order:

      pixelated image rendering (colors/shades)
      hatching
      visible lines (of the model)
      symbols (balloons, tables, finishes,...)
      section view lines (cutting lines and name)
      Cosmetic geometry (incl. page drawing frame)
      title block template
      title block content (text/images)
      dimensions (values and lines/arrows)
      Demo:
      image

      With only one layer active:
      image

      Full version info
      OS: Windows 11 build 22631
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.37213 (Git)
      Build type: Release
      Branch: main
      Hash: 20e7deb86a8c6c2cd2378f09f8313760933f3a5c
      Python 3.11.9, Qt 5.15.13, Coin 4.0.2, Vtk 9.2.6, OCC 7.7.2
      Locale: German/Germany (de_DE)
      Installed mods: 
        * CfdOF 1.25.12
        * Curves 0.6.36
        * dodo 1.0.1
        * fasteners 0.5.20
        * freecad.gears 1.2.0
        * OpenTheme 2024.5.3
        * OpticsWorkbench 1.0.17
        * sheetmetal 0.4.13
      Subproject(s) affected?
      Techdraw

      Anything else?
      No response

      Code of Conduct

      I agree to follow this project's Code of Conduct

      ~~~~~~~~~~

      Support radius/diameter, also for cylindrical surfaces in measurement tools	C++, Measurement	175h	Medium

      Problem description
      Currently the unified measurement type cannot get results of the type radius or diameter when selecting a cylindrical surface. If a surface is selected, the area is chosen automatically. Switching manually to radius gives no result. There is no type to measure the diameter at all.
      The tool should support the measurement of the radius and diameter, when a cylindrical / arc surface and also curve is selected.

      Additionally, the annotation of radius/diameter should be attached and displayed at the center of the radius. Currently it is on a starting point of the selected curve.

      Full version info
      OS: Windows 10 build 19045
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.37063 (Git)
      Build type: Release
      Branch: main
      Hash: 680792030fd664c94829e2c1b78b21788e8d9879
      Python 3.11.9, Qt 5.15.13, Coin 4.0.2, Vtk 9.2.6, OCC 7.7.2
      Locale: German/Germany (de_DE)
      Installed mods: 
        * BIM 2021.12.0
        * CurvedShapes 1.0.9
        * Curves 0.6.35
        * fasteners 0.5.20
        * OpenTheme 2024.4.20
        * OpticsWorkbench 1.0.17
        * sheetmetal 0.4.13
      Subproject(s) affected?
      Core

      Anything else?
      No response

      Code of Conduct

      I agree to follow this project's Code of Conduct

      ~~~~~~~~~~  

      Measure inertia with material and coordinate system in measurement tools	C++, Measurement	175h	Medium

      Problem description
      With the material of the object the measurement tool should also support the measurement of inertia. The whole matrix should be displayed, plus the principal moments of inertia and its associated coordinate system, possibly different than the base one, with the origin at the center of gravity.

      Several implementations are possible and all are desirable:


      Most basic: use only the base coordinate system.

      Use a point as the origin. The coordinate system is then a translation of the base one.

      Use a local coordinate system.

      Use a single line to compute the inertia around it.
      Full version info
      0.22
      Subproject(s) affected?
      Core

      Anything else?
      Needs mass calculation, see #13715.

      Code of Conduct

      I agree to follow this project's Code of Conduct

      ~~~~~~~~~~

      Add attachment support to annotation labels	C++, Core	175h	Easy

      Problem description
      The AnnotationLabel when created has no attachment support for the origin of the annotation line(s).
      It is not possible to set the position and keep it updated when the annotation is placed at a selected geometry or object.

      Full version info
      OS: Windows 11 build 22631
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.36729 (Git)
      Build type: Release
      Branch: main
      Hash: 6ca35709ddc7f95fb84eef4c24973dc489e5acde
      Python 3.11.8, Qt 5.15.8, Coin 4.0.2, Vtk 9.2.6, OCC 7.7.2
      Locale: English/United States (en_US)
      Installed mods: 
        * BIM 2021.12.0
        * CfdOF 1.25.11
        * Curves 0.6.35
        * dodo 1.0.1
        * fasteners 0.5.20
        * fcVM-WB
        * freecad.gears 1.2.0
        * OpenTheme 2024.4.20
        * sheetmetal 0.4.13

      ~~~~~~~~~~
      
      Add snapping to measurements / picking points	C++, Measurement	175h/350h	Medium

      Currently when selecting two circles or cylinders, the measurement is displayed between the enveloped circle curve or between the mantle surfaces.
      It would be great if the unified measurement facility could support snapping like in the Draft WB to snap to circle midpoints, intersections, and so on.
      This would also allow to measure distances and angles of axes between shafts and holes.
      grafik

      Full version info
      OS: Windows 10 build 19045
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.37063 (Git)
      Build type: Release
      Branch: main
      Hash: 680792030fd664c94829e2c1b78b21788e8d9879
      Python 3.11.9, Qt 5.15.13, Coin 4.0.2, Vtk 9.2.6, OCC 7.7.2
      Locale: German/Germany (de_DE)
      Installed mods: 
        * BIM 2021.12.0
        * CurvedShapes 1.0.9
        * Curves 0.6.35
        * fasteners 0.5.20
        * OpenTheme 2024.4.20
        * OpticsWorkbench 1.0.17
        * sheetmetal 0.4.13

      ~~~~~~~~~~

      Unify DXF importers and exporters	C++/Python, DXF, Draft, Import	350h	Medium/Hard

      DXF import/export is a hot topic. There have been many issues with it and it seems that there are still some problems left. Apparently, the legacy importer/exporter should be used in most cases. But ideally, there should be only a single importer/exporter (with all the benefits and features of the current two implementations) or at least the better/recommended one should be the default to avoid the confusion. Are there any plans for that? I guess that it won't happen before the next release but it's something that should be resolved as soon as possible, in my opinion.

      Full version info
      OS: Windows 10 build 19045
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.36958 (Git)
      Build type: Release
      Branch: main
      Hash: a041129090b8dcbb8367636840d3c668ef30a933
      Python 3.11.9, Qt 5.15.13, Coin 4.0.2, Vtk 9.2.6, OCC 7.7.2
      Locale: Polish/Poland (pl_PL)

      ~~~~~~~~~~

      Allow adding text to the sketcher	C++, Sketcher, Qt	350h	Medium

      Currently the only way of adding text to FreeCAD is StringShape which doesn't play nicely with parametric design (e.g. font cannot be specified as function, neither can size as far as I can tell) and it's painful to use with Part Design.

      It would be good if user could just type string inside sketcher and extrude it if they use Part Design workflow.

      Full version info
      [code]
      OS: NixOS 24.05 (Uakari) (GNOME/gnome)
      Word size of FreeCAD: 64-bit
      Version: 0.21.2.Unknown
      Build type: Release
      Python 3.11.8, Qt 5.15.12, Coin 4.0.1, Vtk 9.2.6, OCC 7.6.2
      Locale: English/United States (en_US)
      Installed mods: 
        * kicadStepUpMod 10.22.9
        * Assembly4 0.50.6
        * fasteners 0.5.0
      [/code]

      ~~~~~~~~~~
      Export 3D PDF File format	C++, Core, PDF	350h	Hard

      There is no way to directly export into a 3D PDF and keep tree structure, materials and custom views.
      https://helpx.adobe.com/acrobat/using/adding-3d-models-pdfs-acrobat.html

      3D related file types to be used in 3D PDF are Universal 3D (.U3D) files (https://en.wikipedia.org/wiki/Universal_3D)

      Related issue for import of these files:

      import PRC file or 3D PDF into FreeCAD #6090

      OS: Windows 11 build 22631
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.36277 (Git)
      Build type: Release
      Branch: main
      Hash: 9e1903d46112b3660bf10c6a4537d728101d560b
      Python 3.10.13, Qt 5.15.8, Coin 4.0.2, Vtk 9.2.6, OCC 7.6.3
      Locale: German/Germany (de_DE)
      Installed mods: 
        * 3DfindIT 1.2.0
        * BIM 2021.12.0
        * CfdOF 1.25.2
        * CurvedShapes 1.0.5
        * Curves 0.6.23
        * Defeaturing 1.2.2
        * fasteners 0.5.12
        * FEMbyGEN 2.1.0
        * freecad.gears 1.2.0
        * freecad_metal_workbench 0.0.1
        * OpenDark 2023.12.17
        * sheetmetal 0.4.2

      ~~~~~~~~~~  

      Use only selected parts of a sketch / Features with different profiles of a master sketch	C++, Sketcher, Core	175h	Hard

      Currently it is not possible to create a master sketch with multiple, overlapping islands of wires and use the individual parts of the sketch in the 3D view for features. Always the entire sketch has to be used to create features. If there are open loops / wires or not one single closed profile, most PartDesign features fail.
      The idea is to create a sketch and use a a single loop / closed profile or combinations of the enclosed sketch for features in FreeCAD, for example PartDesign WB (Pad, Pocket, Revolve,...), Part WB (Extrude,...) or elsewhere.

      In other CAD software, when activating a sketch based feature (e.g. Pad) the user can select the parts of the sketch which should be included in the profile to be extruded. When hovering the sketch, the different - closed - profiles of overlapping sketch geometry are highlighted and can be selected individually to be added or removed from the final group of profiles which will be used for that feature.

      Example from Fusion360:
      extrude-shape

      Example from Onshape:

      onshape-profiles
      onshape-sketch-profiles

      This also lets the user create a single sketch (sometimes referred to as master sketch) and referencing different parts for different features, without the need to copy the sketch, redraw the sketch, recreate dimensions or create external geometry references and redrawing or constraining with regard to them.

      This was also mentioned as issue at the FreeCAD Day 2024 Complaint Session:
      Unable to easily apply operations to selected parts of a sketch

      Full version info
      OS: Windows 11 build 22631
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.36277 (Git)
      Build type: Release
      Branch: main
      Hash: 9e1903d46112b3660bf10c6a4537d728101d560b
      Python 3.10.13, Qt 5.15.8, Coin 4.0.2, Vtk 9.2.6, OCC 7.6.3
      Locale: German/Germany (de_DE)
      Installed mods: 
        * 3DfindIT 1.2.0
        * BIM 2021.12.0
        * CfdOF 1.25.2
        * CurvedShapes 1.0.5
        * Curves 0.6.23
        * Defeaturing 1.2.2
        * fasteners 0.5.12
        * FEMbyGEN 2.1.0
        * freecad.gears 1.2.0
        * freecad_metal_workbench 0.0.1
        * OpenDark 2023.12.17
        * sheetmetal 0.4.2

      ~~~~~~~~~~

      Improve the FreeCAD API documentation	C++/Python, Doxygen	175h	Easy

      Outline
      Work on the FreeCAD doxygen-generated documentation: Propose a better plan, document the modules better, make it clearer to read, etc.

      Details
      The API documentaiton of FreeCAD is generated with doxygen from the docstrings contained in the source code. It is hosted on https://github.com/FreeCAD/SourceDoc . It is currently not easily readable, the modules structure doesn't list classes and functions, python functionality is not well distinguishable from C++ functionality, and many other problems.

      Expected Outcome
      Identify problems and possible solutions, and propose changes to the docstrings and in-source doxygen instructions to build better docs, and possibly do some css work to produce a cleaner HTML result

      Project Properties
      Skills
      The student should have or build a good knowledge of doxygen, optionally be ready to do some css work too

      Difficulty
      Medium

      Additional Information
      Potential mentor(s): Yorik
      Organization website: https://freecad.org
      Communication channels: https://https://forum.freecad.org

      ~~~~~~~~~~
      
      Compare multiple parts / bodies (CAD versions and 3D Scan to Original CAD Model)	C++, OpenCasCade, Part	175h	Medium

      There is currently no feature to compare two parts or bodies. This would be helpful to analyze different parts or versions of the same body.
      Differences (more or less material/features) should be highlighted as an analysis report.
      The feature would also be helpful to inspect 3D scans (meshes) and compare them to the actual CAD model (quality inspection).

      In CATIA there are two option
      Example from CATIA:
      How-to-compare-2-Parts-in-CATIA-V5-2
      Demo Video: https://youtu.be/kb_iyLEO18Y?t=73&feature=shared

      In CATIA there are two options, to make a visual comparison (se image above) and a geometric comparison which shows results with added or removed material on both models in a linked view:
      6a0115711b8d26970b0240a4b4ac12200c-800wi

      Demo in Siemens NX: https://www.youtube.com/watch?app=desktop&v=DNx2AdKI7zg

      Demo with 3D scan comparison in SolidWorks: https://www.youtube.com/watch?v=06B6YcoNuoI

      I've tagged the PartDesign WB as this would be the most useful WB for such features but it would also be beneficial to compare meshes or assemblies and as mentioned above, scanned 3D meshes to actual CAD geometry.

      Full version info
      0.22



      ~~~~~~~~~~  

      Assembly: Possibility to Inspect the Assembly	C++, Assembly, Part	175h	Hard

      There should be some possibilities to inspect the assembly:

      display degrees of freedom (DoF) for the parts (maybe in the property view, maybe in an inspection dialog, maybe display them directly in the 3D view (e.g. arrows)
      alternatively an option to wiggle/animate the assembly in all open degrees of freedom, to see if the assembly is working correctly and all joints were made.
      Check for intersection of parts / collision (clash) detection. But also allow a maximum/minimum distance input and analyze if no parts have a closer or larger distance to each other
      Assembly Hierarchy and Structure: Displaying the organization of components within the assembly hierarchy is crucial for managing complex assemblies. The WB should provide tools for displaying the relation of all components, maybe like the dependency graph
      To add from the FreeCAD Day 2024 Complaint Session:
      No way to get the mass of a sub assembly. Material properties are not handled properly assemblies, you cant get aggregate properties

      Full version info
      OS: Windows 11 build 22631
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.35966 (Git)
      Build type: Release
      Branch: main
      Hash: 7f5d89fa1942fec79222e4d173655744037164dc
      Python 3.10.13, Qt 5.15.8, Coin 4.0.2, Vtk 9.2.6, OCC 7.6.3
      Locale: German/Germany (de_DE)
      Installed mods: 
        * 3DfindIT 1.2.0
        * BIM 2021.12.0
        * CfdOF 1.25.1
        * CurvedShapes 1.0.5
        * Curves 0.6.23
        * Defeaturing 1.2.2
        * fasteners 0.5.2
        * FEMbyGEN 2.1.0
        * freecad.gears 1.0.0
        * freecad_metal_workbench 0.0.1
        * OpenDark 2023.12.17
        * sheetmetal 0.4.0
        * woodworking 0.21.2.33771

      ~~~~~~~~~~

      Sketcher: Improve Dimension between Circle/Arc (Distance Constraints)	C++, Sketcher	175h	Hard

      Currently, it is only possible to constrain the minimum distance between two circles/arcs with the dimension tool:
      grafik

      The tool should be improved to behave like the distance tools on lines, depending on the cursor position of the mouse

      Minimum distance between circle/arcs, already implemented
      Maximum distance between circles/arcs
      Minimum horizontal distance between circles/arcs
      Maximum horizontal distance between circles/arcs
      Minimum vertical distance between circles/arcs
      Maximum vertical distance between circles/arcs
      What is meant:
      grafik
      grafik

      Building on top of @FlachyJoe #9166
      This FR is includes #11412 but includes additional cases to support all distances.
      Also includes #5864

      When implemented, the Dimension tool should be updated to include these different constraint cases and suggest the best case, depending on the cursor position.

      Full version info
      0.22

      ~~~~~~~~~~
      
      Edit multiple documents at a time (AKA make tabs independent editors)	C++, Core	350h	Hard

      freeCAD has been designed to edit one document at a time only. When two files are opened and an edition is occurring in one of them (for example a sketch is opened), the program stays in this edit mode when switching to the other document (the task panel is still the same). If this second document has a sketch that is also opened, it closes the one opened in the other document. In other words, tabs are not independent editor.

      This behavior is a limitation. It makes working on several documents in parallel difficult. A workaround is to open as much as FreeCAD sessions as needed, but it is impossible to detach a tab into its own FreeCAD session.

      This would be a big change because the architecture would be altered. Though it would make FreeCAD more predictable as basically all software with tabs make them independent editors.

      Full version info
      OS: Ubuntu 23.10 (KDE/plasma)
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.35510 (Git) AppImage
      Build type: Release
      Branch: main
      Hash: da05f7c8e8b25ff783cc6c4eb3b73b640f134519
      Python 3.10.13, Qt 5.15.8, Coin 4.0.2, Vtk 9.2.6, OCC 7.6.3
      Locale: French/France (fr_FR)
      Installed mods: 
        * OpenDark 2023.12.1

      ~~~~~~~~~~  

      Improvement of Light Sources Preferences: Appearance, Multiple Lights in the Scene, Background Illumination	C++, Coin 3D, User Inteface	350h	Medium

      To extend the functionality of #11113 implemented by #11146 it would be great to add, adjust, and remove lights in the preference dialog of FreeCAD.
      The arrows could indicate a light each.
      grafik

      The direction of the lights should be editable as well as the intensity. If possible, even the color could be adjusted and all saved in the preferences. The current light which is edited could be highlighted in the view, maybe even represent color and intensity on the ball (like a real time preview). It should be possible to add new lights as well as to remove them again.
      Maybe themes could provide settings of the default lightning.

      There should be a setting to set the ambientColor and ambientIntensity with a default white ambient environment light in the scene, so no completely black areas on the model are visible.

      If possible default light settings e.g. three spot, default, ... could be provided and chosen via a dropdown menu and a custom entry could be saved.

      Full version info
      0.22





      ~~~~~~~~~~

      PartDesign: Design a good way to create walls / thin extrusions / ribs	C++, Part Design	350h	Hard

      Currently there is no good way to create "Thin" elements in the FreeCAD. Because of that creating wall-like elements in the Part Design is really hard and requires a lot of effort. Possible uses:

      Creating walls
      Creating ribs
      Creating reinforcements
      To illustrate this feature in OnShape:
      image

      It'd be nice to implement this in a way that would allow this feature to be easily used in most (all?) features without code duplication, so It probably should be implemented as separate "thicken" feature, that then can be: padded, pocketed, revolved, etc.

      This potential feature should also allow control on:

      Offset (One way, symmetric, Two Distances)
      Cap type (Round / Butt)
      Join type (Round / Tangent)
      If possible, there should be a way to create "Thicken" feature using for example "Pad" dialog, to simplify user workflow and make it more user friendly.

      Workarounds
      Using SheetMetal add base: https://wiki.freecad.org/SheetMetal_AddBase
      Creating SubShape binder to sketch with filled offset applied - it works, but it is not intended use of binder, and it has a lot of quirks
      Using Part workbench with 2d offset
      Sketch Offset tool will help a lot with many cases when (if) merged, but again it's not correct tool for the job
      Using Arch_Wall ?
      Full version info
      FreeCAD 0.21

      ~~~~~~~~~~
      
      Implement selection order priority	C++, Coin, User Interface	350h	Hard

      Recently we have a new tool which appeared called 'selection filter'. This also exist in Assembly4 as a toolbar. (introduced in core following #10243)

      This was in part introduced to fix an annoying issue that it is hard/impossible to select some points or lines.

      The technical reason for that issue (I think) is that the selection mechanism use pointOnRay function, but it uses the overload that returns only the 1st object found. So if you try to select a point but a face is closer to the camera, then the face is going to be selected.

      The selection mechanism should not behave like this. Instead it should use the pointOnRay that return ALL the objects found. Then these objects should be sorted by priority by the following order :

      Points
      Edges
      Faces
      Then the selection should take the item with the higher priority.
      @wwmayer Do you have any insight on the matter? Or can confirm if my analysis is correct?

      @Syres916 @FEA-eng you might be interested to follow this.

      Edited following @FEA-eng comments

      ~~~~~~~~~~  

      Sketcher: Implement automatic projection of external geometry for dimensions	C++, Sketcher	180h	Hard

      I would like to propose an easy improvement in the Sketcher module that can make it easier to use and faster.

      While using the following button commands: "Constrain horizontal distance" & "Constrain vertical distance"

      It would be great to run highlight edges from "Create external geometry" when the mouse hovers above external geometries and in case the user clicks, to create the external geometry automatically.

      I think all the functionality is existing already.

      This way the user can create constraints directly to the edges of the body without additional clicks

      ~~~~~~~~~~

      Design a compatibility system for different Assembly Workbenches	C++/Python, Assembly	350h	Hard

      ne of the key findings of the Ondsel Assembly workbench blog series was the need for a common data format for the interchange of assembly information.

      The creation of a data standard should be an early priority to allow the various addon assembly workbenches time to adapt and/or build migration scripts.

      This issue is for continued discussion about the requirements for a common data standard.

      ~~~~~~~~~~
      
      On-machine inspection for CAM	C++/Python, CAM	180h	Medium

      On-Machine Inspection
      Background
      In commercial manufacturing using CNC, the part is inspected to ensure that the resulting part matches the required tolerance. Tool wear, backlash, and other environmental factors can affect machining accuracy.

      Traditionally the part is removed from the machine after completion and placed and a Coordinate Measuring Machine (CMM) which probes the part and compares to the probe results to the required specifications. The problem with this approach is that the placement of the part is lost when it is removed from the machine. If re-work is necessary, the setup time to reestablish accurate placement can be very high.

      On-machine Inspection uses a touch probe in the CNC machine to replace the CMM. The part is left in place and a toolpath is executed.

      In manual mode, the machine probes the part and indicates to the operator if a probe point is out of tolerance.

      In automatic mode, the probe points are gathered and saved to an inspection report

      The CAM workbench in FreeCAD (Path) lacks any capability for generating an On Machine Inspection toolpath.

      Details
      Understand the basic workflow for creating a Path Job and generating tool paths for CNC machining operatoins. Understand the two main workflows for On-machine Inspection.
      Propose a Path operation and workflow for generating a toolpath, storing and displaying inspection results.
      Design the operation, task panels, and core logic.
      Implement unit tests for the core logic
      Implement the feature and demonstrate practical application
      Create a wiki page describing how on-machine inspection is used
      Expected Outcome
      Mergable code for an OMI feature
      Unit tests for the core logic
      A Wiki page describing the procedure for the user to create tests and the developer to create new comparators
      Future Possibilities
      There are numerous other places in the CAM workflow where Integration of touch probes and other sensing equipment would reduce errors and increase cycle time. These are valuable features to implement. They make FreeCAD more attractive to commercial use.

      Project Properties
      Skills
      Programming language mainly Python. Familiarity with or willingness to learn G-code.
      Familiarity or willingness to learn basic CNC / machining concepts
      Difficulty
      Medium

      Project size
      175h

      ~~~~~~~~~~  

      Advanced FreeCAD test system	C++/Python, Core	350h	Medium

      Advanced FreeCAD test system
      This page is dedicated to the Google Summer of Code project regarding the enhancement of FreeCAD's test system.

      Outline
      FreeCAD as a CAE application has a high level of complexity, both in its source code and also in its user interaction. To ensure a certain level of quality automatic testing is essential. However, as an open source application with spare time coders only this part of the project has not seen very much attention. One of the major reasons is the low-level handling required to write test cases. All actions to trigger, every result fetching and every single comparison needs to be hand coded. This makes it cumbersome to provide a test for every created functionality and possibly impossible to do so if deep document comparisons are needed. For example the Part and PartDesign workbench: An automated test for document objects require the resulting topology shape to be analysed. This is a tremendous part and cannot be handled on a per test basis.

      This project aims at reducing the work required to write meaningful tests. This should be accomplished by providing a infrastructure for result file storage and special "comparators" which compare the stored result files with the test result for equality.

      Details
      Create a result file infrastructure for the test system. It should allow to save an arbitrary number of files together with the test itself where the expected results are stored. It is intended to have one result file for each comparator used. The infrastructure should make the storage (file structure), loading and handling easy. It furthermore should define a specification for the generic file content, e.g. which comparator to use for it etc.
      Create a infrastructure for comparators and provide a few important ones. The comparators should be able to read in a result file and compare the available test output with it. As every workbench requires different types of comparisons the comparators need to be provided by the workbench itself, as well as possible top-level ones. The test infrastructure needs to be adopted to work with such workbench specific types. Furthermore there needs to be a way to generate result files for comparators. this can be done either by themselves or by a different class.
      a. Implement a global comparator for the document structure: It stores the Document object structure with all properties in a result file and compares the available document after a test run with it
      b. Implement a Part workbench comparator for shapes: It stores data about a certain TopoShape in a result file suitable for comparison, e.g. number of edges/vertices/faces, properties like area, mass, center of gravity.
      c. Advanced: Create a global comparator for the 3D output based on picture comparison. This is marked as advanced as this comparator needs to be tolerant to slight changes due to driver differences (see VTK for example) and also needs to somehow ensure the same display settings used for the comparators every time
      Create a wizard or GUI for test creation in the Test workbench. This would work like macro recording: the user starts the test recording, and everything plotted in the python console would be the test procedure. When hitting stop the user gets a dialog where he can choose which comparators to apply. The wizard than creates the appropriate test structure with the test itself, all needed result files etc.
      Create a Wiki page describing the working of the test system and how to create tests and new comparators
      Expected Outcome
      Mergable code for a result file based comparator system
      A GUI for simplified test generation based on macro recording
      A Wiki page describing the procedure for the user to create tests and the developer to create new comparators
      Tests which utilize the created comparators and show their use
      Future Possibilities
      Future contributions can include new comparators, e.g. for meshes. Also creating tests for existing functionality has a high priority and can be achieved with the new system. Futhermore a GUI based system can be created, where a test is defined by recorded UI events, see Record and replay events. This could also be a new GSoC project.

      Project Properties
      Skills
      Programming language mainly Python, some comparators may need C++ code.
      Understand and use APIs from FreeCAD and external libraries (OCC for Part comparator)
      Difficulty
      Medium

      Project size
      175h

      ~~~~~~~~~~

      FEM: Extend Z88 Solver	C++/Python, FEM, Z99	350h	Medium

      GSoC FEM Solver Z88
      This page is dedicated to the description of the Google Summer of Code project idea regarding extending FEM solver Z88OS.

      Outline
      FreeCAD is not only a traditional CAD platform but also aims at providing general engeneering functionality. One of the most valuable design tools for modern product development is the finite element method. It provides advanced means for design analysis, stress tests and optimisation. Over the last two years a FEM workbench in FreeCAD has been developed based on the CalculiX solver and already reached a usable state in the 0.16 release. However, since CalculiX has neither real Shell nor real Beam elements, CalculiX has limitations in the regard of these element types. This was the main reason to start an implementation of an additional solver for the FreeCAD FEM workbench. Z88OS was choosen, since it is OpenSource and thus runs on all major plattforms and has real Beam and Shell elements. The solver Z88OS has been integrated in FreeCAD FEM already. But only very limited parameter are supported at the moment. Only fixed constraints in main axis directions and simple node loads are supported on the pre processing side. On the contrary the post processing only the displacements are read into FreeCAD FEM. To really be able to use Z88 as an additional solver more of his capabilities need to be supported by FreeCAD.

      The GSoC project aims to exactly do this. On pre processing side of FreeCAD a lot of constraints and boundary conditions are supported by FEM and CalculiX solver. Most of them should be ported to Z88 too. On post processing side the FreeCAD FEM result object supports a wide range of result types as well as viewing them by the use of sophisticated VTK post processing tools. An implementation should be made to read more Z88 results into FreeCAD result object. Furthermore most Z88 solver adjustments are hard coded into FreeCAD FEM. They should be changed in a way they could be changed during run time of FreeCAD FEM.

      Details
      Get familiar with FreeCAD FEM workbench its capabilities and its architecture. Furthermore get familiar with Z88OS and its interface text files for pre- and post processing. It is important to have a good understanding of all involved components to be able to make the needed extensions.
      Post processing: Extend the importZ88result module to read stress and strains from Z88 result files and add them to the FreeCAD result object.
      Pre processing: Implement Z88 input file writing for all three element dimensions (beam, shell, volume) for the following constraints of FreeCAD FEM: fixed, force, pressure, self weight, displacement.
      Solver: extend the FreeCAD FEM solver object by FreeCAD properties to hold the the attributes which could be used to make the needed adjustments at Z88 solver binary.
      Advanced: add the free-ware solver Z88Aurora (not OpenSource, but free of license fee) as another possibility in FreeCAD FEM in addition to Z88OS. Z88Aurora supports much more constraints and analysis types than Z88OS
      Expected Outcome
      Fully functional advanced postprocessing in FreeCAD based on VTK
      Unit tests ensuring the functionality
      Documentation and tutorials for post processing
      Future Possibilities
      If this project is finished successfully futher work on the FEM workbench can be done. Advancing the preprocessing with better control over the meshing process come to mind, or integrating different solvers for other analysis types. Also calulix implementation can be advanced, for example allowing nonelinear calculations.

      Project Properties
      Skills
      Programming language Python
      Deep understanding and use of APIs from FreeCAD and Z88OS
      Knowledge of FEM pre- and postprocessing workflows and needs
      Difficulty
      Easy-Medium

      Project size
      175h



      ~~~~~~~~~~
      
      Upgrade the documentation system	C++/Python, Doxygen, Mediawiki, Markdown	350h	Easy  

      Upgrade the documentation system
      This page is dedicated to the description of the Google Summer of Code 2023 project idea of upgrading the documentation system of FreeCAD.

      Outline
      FreeCAD already possesses a vast documentation, written by its users and hosted on the FreeCAD wiki. On each FreeCAD release, the contents of the wiki get packed into a offline documentation package which is bundled with FreeCAD. When using the "what's this?" feature, FreeCAD users can quickly get documentation about a specific tool

      Additionally, this same documentation also has several translations, hosted on the same wiki and managed by a mediawiki plugin, and also counts on the source code structure and comments, automatically extracted by the doxygen tool, and hosted on https://www.freecadweb.org/api/

      However there are several problems:

      The mediawiki software is a dinosaur to maintain, and complicated to maintain up-to-date
      The mediawiki data is hard to back up. We are constantly at risk of loosing data
      The mediawiki search feature is notoriously weak
      The mediawiki is complicated to theme and make look good
      Our doc has become as important as FreeCAD itself. It would benefit from having the same level of decentralisation
      The current translation system is always at risk of becoming obsoleted, like many mediawiki plugins. It is not used anymore by the MediaWiki project
      A simpler, file-based system would allow much more automation, scripting and integrations. Python/C++ API documentation can be built on-the-fly and integrated
      A Git-based system would allow branching/tagging/versions of the documentation corresponding to FreeCAD versions and maintaining a more up-to-date documentation
      A markdown-based system would allow to produce many kinds of outputs such as online/HTML like the current wiki, but also better integrate into the FreeCAD Help system, or produce e-book formats or even printed books
      A markdown + Git based system would be easy to integrate into online translation platforms, and therefore free us from one more part of maintainance and unify with other translation systems of FreeCAD
      This project proposes to remedy to these problems by:

      switch the FreeCAD documentation, currently managed by a MediaWiki instance hosted on the FreeCAD website to a file-based, versioned system, preferably based on Git and markdown
      offer a nice web-based experience
      allowing the FreeCAD user to switch between online and offline documentation, and choose between different available languages
      extending and better integrating the autogenerated documentation, with special care for the python API
      enabling different e-book outputs (pdf, e-pub, etc)
      implement a good search system
      The above proposal also introduces a new problem: The ease-of-use of the Mediawiki platform would be lost. That ease-of-use is important because most of the edits done to the wiki are small edits, like corrrecting an info or fixing a typo. Many people who currently work on the wiki would probably do it less often if it required a complex Pull Request-based system. A wiki system, that allows easy and small edits, is therefore fundamental to keep.

      The solution to that problem could be found in using a wiki system that is based on files, markdown and git. As part of this project, available file-based wiki solutions should be researched.

      Details
      have a good knowledge of the markdown format, including how to work with yaml data
      be able to write scripts, preferably in Python, to automate some aspects of the migration or maintaining
      be able and ready to explore and work with the API of online platforms such as MediaWiki, GitHub or Crowdin
      be able to work with doxygen and autogenerated documentation systems
      be ready to document everything you do so others can take the work further
      Expected Outcome
      A better documentation system for FreeCAD, based on the proposed workflow below

      What's there to test already
      An automatic translation of the mediawiki content to markdown is already available on https://github.com/FreeCAD/FreeCAD-documentation . It is done automatically by the help of a python script at https://github.com/FreeCAD/FreeCAD-documentation/blob/main/migrate.py . The translated documentation can be read online, by browsing through the markdown pages, or from within FreeCAD's Help system. Both the Help addon and the markdown documentation form the core of what we want to develop.

      The goal of this project is to migrate for good to the markdown version, retire the migrate script, and shut down the wiki.

      Proposed workflow
      Research available file-based wiki solutions
      Write article explaining the migration to the community: why, what are the advantages, what are the issues
      Write a migration plan or adapt this one
      Define a directory / category structure that reflects the current documentation categories
      Define a tags / yaml system to allow further and finer classification of documentation pages
      Define a language switching system that allows user to use the documentation in their language
      Define a search system
      Define a sequence system so some pages can be assembled like a book
      Design an online HTML-based output
      Design a FreeCAD online output
      Design a FreeCAD offline output
      Design a multi-formats e-book output
      Design a printed book output
      Research and help choose a translation platform, investigate available plans (see below)
      Define what contributors should do while the wiki is in read-only mode
      Set the wiki in read-only mode
      Transfer all the contents from wiki to markdown files
      Verify that all the contents have been transferred
      Manually check each and fix each and every page for style errors
      Verify all the links
      Create a structure for translations and relocate all pages
      Setup the translation platform
      Tie the translation platform into the git repo
      Document the steps needed to setup the translation platform
      Document the process to adopt for translators
      Document the process to adopt for maintainers
      Define how dynamic contents such as FreeCAD API documentation can be extracted and added automatically to the documentation
      Write an article announcing the change
      Design a system to handle and redirect wiki.freecad.org links
      Remove the mediawiki installation
      Possible translation platforms, to be checked again
      Research which translation platform to use (transifex, crowdin?) based on:
      are they free for FOSS projects, or what are the costs
      how good they handle markdown files
      how already translated pages can be fed back into the translation platform
      automatic integration with github
      Crowdin - https://crowdin.com
      Free for FOSS projects
      Incomplete markdown support (looses images) (12/2020)
      Allows to upload a translated file as translation
      Integration with github
      Advantage: FreeCAD users know it
      Transifex - https://transifex.com
      Free for FOSS projects
      Incomplete markdown support (looses images) (12/2020)
      Allows to upload a translated page (git push)
      Integration with github
      Weblate - https://weblate.org
      Free for FOSS projects
      No markdown support (12/2020)
      Project Properties
      Skills
      Programming language: C++, but understanding some Python will be necessary
      Readiness to work with documentation, reasonably good english writing skills
      Difficulty
      Medium

      Project size
      175h or 350h

      ~~~~~~~~~~  

      FreeCAD ↔ BRLCAD integration	C++, BRL-CAD, OpenCasCade, Core	350h	Hard

      FreeCAD-BRLCAD integration
      This page is dedicated to the description of the Google Summer of Code 2023 project idea of integrating FreeCAD and BRL-CAD.

      Outline
      Is there an existing request for this?

      Details
      FreeCAD and BRL-CAD are very complementary applications: BRL-CAD is a powerful engine which could do with a better modelling UI, and FreeCAD has an increasingly vast modelling UI but could make great use of the support for large models that BRL-CAD can offer.

      FreeCAD being highly modular, and BRL-CAD having a C+ API, building a BRL-CAD module for FreeCAD is totally possible. This way, it would be possible to open BRL-CAD models (that are usually called databases, because they are often made of a collection of models) in FreeCAD, and it would also be possible to use FreeCAD as a modelling tool for BRL-CAD.

      This project idea will require a reasonable knowledge of C++, and, since it involves two different applications, a versatile mind able to learn quickly and navigate between many different concepts, as they are implemented differently in both applications.

      This project would be mentored commonly by both FreeCAD and BRL-CAD developers.
      https://wiki.freecad.org/FreeCAD-BRLCAD_integration

      Expected Outcome
      Documentation. Since this is a large task, that might not fit in a single GSOC project, other people (or yourself) will likely work on this project after the GSOC period ends. They must be able to take on the work where it has been stopped. Also, the first steps of this project will involve a lot of research, that should be made as available as possible to others.
      A basic prototype, that allows to open and visualize BRL-CAD databases in FreeCAD, and shows how modelling and saving BRL-CAD objects can work in FreeCAD
      Future Possibilities
      Such an integration could go a very long way, as both applications are very complex, and if the "wedding" works well, new possible fields of use could emerge. Also, we think this kind of inter-project integration could pave the way for more, so the possibilities are vast.
      Project Properties
      Skills
      Programming language: C++
      Good understanding and use of APIs from FreeCAD and BRL-CAD
      Knowledge of 3D modeling, topology and computational geometry is a plus
      Difficulty
      High, mostly because you have two different applications to learn and work with

      Project Size
      350h

      ~~~~~~~~~~

      Design a set of interactive controls in the 3D view for tools that have numeric values/inputs (drag to edit)	C++, Coin, Core, User Interface	350h	Hard

      Added from the FreeCAD Day 2024 Complaint Session:
      When you have done an operation, such as extrude, it’s impossible to visually edit that parameter via click and drag

      Currently all inputs for value/parameter based tools are handled. via the task dialog or the property view. It would be great to input data in the 3D view (widget/overlay) and also click and drag interactively in the 3d view to manipulate the feature. Also the direction of a feature could be indicated by arrows in the 3D view for an overall better UX and easier onboarding for new users.

      Applicable features would be:

      Pad feature: display direction with an arrow, click and drag arrow to define the length. (Double)click the arrow to reverse direction. Typing would insert a value in a widget right in the 3D view (like OVP in Sketcher WB).
      Revolve feature: display the direction and angle, dragging changes the angle
      Sheet metal flange: display direction, angle and length
      Pattern feature: define direction, offset, remove single copies
      and so on...
      Example of other software:

      fusion360-interactive-extrude

      solidworks-interactive-flange

      catia-interactive pattern

      fusion360-interactive-revolve

      Issue imported from https://tracker.freecad.org/view.php?id=4640

      Reporter: nukeRomancer
      Date submitted: 4/21/2021
      FreeCAD version: 0.2
      Category: Feature
      Status: new
      Tags:
      Original report text
      interactive controls in the viewport for all / most ( where applicable ) tools that have numeric values / inputs

      this would be a MASSIVE improvement to the general workflow

      https://forum.freecadweb.org/viewtopic.php?p=496292#p496292

      Other bug information
      Priority: immediate
      Severity: feature
      Category: Feature
      Updated: 4/22/2021
      Discussion from Mantis ticket
      Comment by Pauvres_honteux 2021-04-22 14:51
      Some good examples of how user interacting stuff can be made, begins at 28 minutes

      ~~~~~~~~~~
      
      Direct modeling tools	C++/Python, BIM, Core	350h	Medium

      Issue imported from https://tracker.freecad.org/view.php?id=3353

      Reporter: yorik
      Date submitted: 2/22/2018
      Original report text
      FreeCADs is a feature-based parametric modeling system, hence different modeling steps depend on one or multiple previous steps. Each step is at the same time a tool/operation, and a geometrical object, resulting from that operation. This mix of operation and object is called a feature. Direct modeling, often presented as the opposite of parametric modeling, allows to graphically move vertices, push or pull faces and edges to modify the geometry of an object.

      This issue is a GSOC idea https://www.freecadweb.org/wiki/Direct_modeling_tools

      and also as a test for bountysource...

      Other bug information
      Priority: normal
      Severity: minor
      Category: Feature
      OS: Debian Testing 64bit
      Platform: PC
      Updated: 2/6/2021
      Discussion from Mantis ticket
      Comment by Kunda1 2021-01-31 11:21
      Several attempts have already begun to tackle this issue:

      carlopav in https://forum.freecadweb.org/viewtopic.php?t=49837
      https://github.com/MariwanJ/Design456

      ~~~~~~~~~~
      Integrate a client for the buildingSMART Data Dictionary web service	Python, BIM	175h	Easy  

      The situation
      The BuildingSmarth Data Dictionary (BSDD) is an onlne service provided by BuildingSMART, the non-profit body that maintains the IFC file format, an universal and open file format for BIM.

      BSDD allows a user to query for terms and receive a series of records of where that term is used in different standards such as IFC itself, but also other classification systems used in the world. The final aim is to help BIM users, when they define something, for example a wall, to query the BSDD service to help them find what classes of what classification systems are applicable to that wall, and which one they should use. This can be used not only for objects, like a wall, but also materials (concrete, brick...) or even properties of an object (for ex the height of a wall).

      Classification systems are huge standards that define each and every item in a construction project. The aim is to have things defined as precisely as possible, so there is no ambiguity over what is what. Additionally, having a classification tag attached to an object also helps to overcome translation problems, as it's the same reference number across different languages.

      A BSDD client in FreeCAD
      Currently, assigning a class to an object works like this:

      A user designs a wall
      The user wishes to add a classification entry to that wall
      They can, in the BIM workbench, open the classification manager, choose a classification system, and search for the term "wall" in that system
      The user then picks the class they find most appropriate
      A BSDD workflow in FreeCAD could look like this:

      When opening the classification manager in the BIM workbench, a third panel could open
      That panel could already present a series of suggestions based on the current selected object
      The panel should also allow the user to see what have been search for automatically, and change that if that's not correct
      The user could click on one of the suggestions
      The appropriate classification would be used
      Expected Outcome
      Build a detailed plan of the workflow: What you imagine the user would need to do, and how that would happen
      Design a system to connect to the BSDD service. Beware, it requires authentication, one should carefully read the docs
      Extend the classification manager in the BIM workbench to add BSDD functionality
      Project Properties
      Skills
      The student should have reasonable coding skills in Python. The student should also get familiar with:

      All the details and requirements on https://wiki.freecad.org/Google_Summer_of_Code_2024
      Work with GIT, GitHub and pull requests
      The BuildingSMART Data Dictionary
      The BIM workbench
      The classification manager
      How BlenderBIM implements BSDD (see comments by Dion Moult below) and see how close we can match what they did
      Difficulty
      Medium

      Duration
      350h

      Additional Information
      Main FreeCAD GSoC page: https://wiki.freecad.org/Google_Summer_of_Code_2024
      Potential mentor(s): Yorik
      Organization website: https://freecad.org
      Communication channels: GSoC section on the FreeCAD forum and this issue
      
      
      
      

























      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/freecad/
    idea_list_url: https://wiki.freecad.org/Google_Summer_of_Code_2025


  - organization_id: 46
    organization_name: GNOME Foundation
    no_of_ideas: 5
    ideas_content: |
      
      Add eBPF profiling capabilities to Sysprof
      Papers: Proof of Concept for backend isolation
      Vala: Researching/Designing/Implementing xml/json/yaml/... integration
      Add printing support to GNOME Crosswords
      Add Wordlist Scoring to GNOME Crosswords Editor
      Project proposals will be listed here.
      Add eBPF profiling capabilities to Sysprof
      Currently, Sysprof works by recording stack traces from the Linux Perf subsystem using perf_event_open(). It also can record various system statistics using data from /proc such as CPU, memory, networking, and disk statistics.
      eBPF provides an existing new direction for tooling of this nature by uploading small programs into the kernel to extract the data you want without the parsing overhead. That data can be delivered to an application like Sysprof for recording into the capture files.
      This internship would involve creating the tooling within libsysprof to setup new eBPF programs by compiling, linking, and uploading them into the kernel along with necessary components to get data from the kernel back to Sysprof.
      This would then be used to port some collectors such as CPU or memory trackers to use eBPF instead of /proc files.
      Requirements
      Knowledge of C, preferably using GLib/GObject but that can be learned
      Minimal experience performance profiling software
      Minimal experience with the Linux kernel
      Learning how eBPF works and how to integrate that with the kernel can be learned on the job
      Communication
      Chat, email, video chat. Christian Hergert @chergert or hergertme on IRC/Matrix or @chergert at gnome.org
      Mentor(s): Christian Hergert
      Difficulty: Hard
      Mentor availability: ~350 hours
      More information
      https://gitlab.gnome.org/Teams/Engagement/internship-project-ideas/-/issues/51

      ~~~~~~~~~~
      Papers: Proof of Concept for backend isolation
      This project will mostly require work on Papers' libraries: ppsview and ppsdocument. The former contains an abstraction (PpsJob) to run (potentially slow) backend code in threads. The later is basically a common abstraction over different backends: PDF, DJVU, Tiff, etc. The idea is to create a component that will start a new process per-document (similar to web-browsers having one process per tab!). That side-car process will take care of all the calls to the backends (so embedded in ppsdocument), and be managed by PpsJobs. Further details are available in https://gitlab.gnome.org/GNOME/Incubator/papers/-/issues/104
      The idea for the GSoC will be for the Intern to prototype a solution to this problem, and investigate potential solutions and foot-guns. The intern will need quite a good knowledge on C, and have motivation to do some investigate work (e.g: look into solutions implemented by other projects like WebKit). I don't expect a full implementation or solution, even if that would be welcomed. A failed attempt at this might already gives us extremely valuable input.
      This will benefit Papers as the future Document Viewer in GNOME in two ways:
      By isolating documents from each other, we improve the overall security situation. Even CVEs that might allow somebody to gain access to execution code from rendering a PDF would not have access to the other documents.
      By isolating documents from the UI we improve the resilience of Papers. A document crashing during rendering (for which CVEs happen regularly (last one CVE-2024-6239) will not bring down with itself the complete application. This has been so far the main blocker to implement the Document Viewer tabbed view, which has been a feature request for Evince since 2005
      Requirements
      Good skill and experience in the C programming language. Both be able to write and read it
      The ability to investigate previous approaches to solve the same issue. We will guide the Intern on where to look
      Motivation to try different approaches. We know a big part of this project will be checking the feasibility of different solutions
      Communication
      Our preferred communication channel is Matrix (https://matrix.to/#/#papers:gnome.org), but we will also do video-calls to get onboarded and if deemed useful and necessary for the mentoring process
      Mentor(s): Pablo Correa Gomez, Qiu and Markus
      Difficulty: Hard
      Mentor availability: ~350 hours
      More information
      https://gitlab.gnome.org/Teams/Engagement/internship-project-ideas/-/issues/58

      ~~~~~~~~~~
      Vala: Researching/Designing/Implementing xml/json/yaml/... integration
      The goal of this project is to add xml, json and/or yaml format language integration to Vala. Other integrations already exist for DBus, GTK builder format, or GModule (https://gnome.pages.gitlab.gnome.org/vala/manual/attributes.html#dbus-attribute). Examples can be found here.
      Currently, parsing and emitting files in Vala with formats like xml, json, or yaml are relatively tedious, need a lot of boilerplate code, and are much more complicated than in other programming languages. But these file formats are very commonly used in modern software, and many internet protocols and existing standards depend on them. Improving their handling would allow more efficient development, as well as lower the barrier for newcomers to Vala.
      First, research is necessary, to find out how other programming languages have done the integrations. Also wanted features will need to be evaluated. For that also different example projects need to be looked into or created, to find the different use cases and related challenges and how to address them. For proposing designs of the new Syntax, "code mock-ups" are going to be written. These can later also serve as test cases for the vala test suite. Then the community will discuss and give feedback to iterate on the syntax design. As the last step (and probably the one taking the longest time), the proposed syntax('s) will be prototyped inside the Vala compiler. Also test cases for the new features, documentation and example code snippets should be developed at the end of the project. If time is left at the end, also other projects that benefit from the new features can be updated to use the new syntax, for example the Vala Language Server.
      Requirements
      Experience with programming in general, as well as a good understanding of object orientation
      Ready to learn the Vala language, and to understand and investigate the syntax of other programming languages for research purposes
      Being open to reach out to the Vala community, and to contributors of other projects written in Vala, to collect feedback about the current situation and the new syntax
      Ability to grow familiar with a relatively large codebase, to find solutions to problems you encounter (There will be a lot of guidance of course)
      Communication
      Main communication channel: Matrix: https://matrix.to/#/#vala:gnome.org Calls are possible for onboarding and mentoring whenever there is a need. (And when enough time)
      Mentor(s): Lorenz Wildberg
      Difficulty: Medium
      Mentor availability
      TBD
      More information
      https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/61

      ~~~~~~~~~~
      Add printing support to GNOME Crosswords
      GNOME Crosswords has some cursory svg code, but doesn't support printing. It is relatively straightforward to extend the svg code to produce printable puzzles. This project consists of multiple sequential stages, with some simple initial milestones and some stretch goals as well. In particular:
      Initial design and planning
      Refactor the svg code to make it handle the existing board and thumbnail usecases, as well as printable puzzles
      Add clues to the generated svg, and make it look good
      Bring the printing dialog to both the game and the editor
      Add crossword-specific options to the printing flow
      As stretch goals, it would be good to support additional puzzle types, as well as add an ipuz2pdf utility to the app.
      Requirements
      Knowledge of C, especially glib-style C programming. Ability to understand a complex codebase and issues.
      Familiarity with svg a plus
      A physical printer is not necessary
      Communication
      Primarily matrix. The main crosswords channel can be found at https://matrix.to/#/#crosswords:gnome.org
      We also will use gitlab issues and email as appropriate. Video conferencing occasionally when necessary.
      Mentor(s): Jonathan Blandford, Federico Mena Quintero, tanmayp@gnome.org
      Difficulty: Medium
      Mentor availability: ~350 hours (Could be ~175 hours if necessary, with fewer milestones reached
      More information
      https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/62

      ~~~~~~~~~~
      Add Wordlist Scoring to GNOME Crosswords Editor
      GNOME Crosswords Editor uses some lists of words in order to produce crosswords. These lists lack the metadata to make more interesting puzzles. We'd like to find, gather, and encode that metadata with the lists in order to choose appropriate words when working with the editor.
      For more information on the problem, please read this design doc.
      This project will involve finding ways to calculate, measure, and encode values for each of the five traits listed. We will then use it when creating a puzzle to try and create more interesting grids.
      Requirements
      The biggest requirement for this project is a love of words, and a certain amount of comfort with uncertainty. I will expect the intern to do some independent research and exploration
      This project will mostly be in python, and will involve a fair amount of data analysis as well as codings
      Some low-level C programming knowledge is a strong plus, as well as the ability to use a hex-editor. The current wordlist is stored in a custom data structure
      This project will involve working with some large data sets — possibly as big as 20 GB. A relatively fast machine with sufficient disk space will be required, as well as the ability to download large files.
      Communication
      Primarily matrix. The main crosswords channel can be found at https://matrix.to/#/#crosswords:gnome.org
      We also will use gitlab issues and email as appropriate. Video conferencing occasionally when necessary.
      Mentor(s): Jonathan Blandford, Federico Mena Quintero, tanmayp@gnome.org
      Difficulty: Medium
      Mentor availability: ~350 hours (Could be ~175 hours if necessary, with fewer milestones reached
      More information
      https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/63
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gnome-foundation/
    idea_list_url: https://gsoc.gnome.org/2025/


  - organization_id: 47
    organization_name: GNSS-SDR
    no_of_ideas: 4
    ideas_content: |
     
      Project Title: WAAS
      Description:
      Large-sized project (350 h)
      This Google Summer of Code (GSoC) project focuses on advancing the functionalities of GNSS-SDR receivers related to WAAS.
      The primary goal for the summer is to provide a working implementation of a GNSS-SDR receiver working with WAAS signals: Signal acquisition and tracking algorithms for their specific signals. The outcome should be a robust GNSS receiver capable of delivering RINEX-B files and real-time navigation solutions including SBAS information.
      Implement acquisition and tracking algorithms for WAAS signals, following the examples already implemented for other GNSS signals. This would facilitate research on precise positioning, safety positioning and drone-related activities working with real signals. Demodulation of the navigation message, opening the door to open innovation in multi-constellation receivers.
      Required skills:
      Basic knowledge of digital signal processing and proficiency in C++ programming are essential. Familiarity with the GNU Radio framework or GNSS-SDR is considered a valuable plus.
      Potential mentor(s):
      Miguel Ángel Gómez, Luis Esteve, Javier Arribas.


      ~~~~~~~~~~
          Project Title: Sensor Fusion
      Description:
      Large-sized project (350 h)
      This Google Summer of Code initiative aims to enhance sensor fusion capabilities between GNSS (Global Navigation Satellite System) and other sensors. The goal is to develop a functional GNSS receiver capable of integrating additional sensor data into its architecture, generating RINEX files, and enabling real-time navigation solutions—providing on-the-fly computation of position, velocity, and time. The fusion of GNSS signals with data from new sensors will leverage state-of-the-art AI techniques, such as Bayesian filters (e.g., Kalman filters and particle filters), graph neural networks (GNNs), and transformers for spatiotemporal data modeling. These methods will enhance research on sensor fusion, precise positioning, and urban canyon navigation using real-world signals.
      Integrating additional sensors into GNSS receivers is a key step in advancing next-generation multi-constellation systems. This innovation fosters open research and development while addressing critical challenges such as integrity, reliability, robustness, extended coverage, and high-accuracy positioning.
      Required skills:
      Applicants should possess a fundamental understanding of digital signal processing and demonstrate proficiency in C++ programming. Knowledge of GNSS principles and prior experience with sensor fusion, particularly between GNSS and INS, will be advantageous.
      Potential mentor(s):
      Miguel Ángel Gómez.

      ~~~~~~~~~~
          Project Title: Vector Tracking
      Description:
      Large-sized project (350 h)
      This Google Summer of Code initiative aims to enhance vector tracking capabilities between GNSS (Global Navigation Satellite System). The goal is to develop a functional GNSS-SDR receiver capable of performing Vector Tracking. It is well-known that the use of Vector Tracking Loops (VTL) in GNSS receivers can result in improved tracking performance and sensitivity, faster acquisition, and improved interference robustness. This project leads to a real-time SDR GNSS VTL receiver capable of working with different COTS front-ends. These methods will enhance research on sensor fusion, precise positioning, and urban canyon navigation using real-world signals.
      Required skills:
      Applicants should possess a fundamental understanding of digital signal processing and demonstrate proficiency in C++ programming. Knowledge of GNSS principles and prior experience with sensor fusion, particularly between GNSS and INS, will be advantageous.
      Potential mentor(s):
      Miguel Ángel Gómez.

      ~~~~~~~~~~
          Project Title: Improving the volk-gnsssdr library
      Description:
      Medium project (175 h)
      This project aims to improve volk-gnsssdr, the Vector-Optimized Library of Kernels for GNSS-SDR. This library provides SIMD-optimized implementations of essential signal processing functions (named kernels in this context) for efficient execution on modern processors.
      Objectives: During the summer, the focus will be on:
      Identifying performance-critical kernels that significantly impact GNSS-SDR execution speed.
      Implementing missing SIMD optimizations by adding NEON (for ARM architectures) and RISC-V vector extensions to existing kernels.
      Benchmarking and validating improvements to ensure enhanced performance and correctness across different hardware platforms. No physical access to those hardware platforms is required.
      Expected outcomes: By the end of the project, volk-gnsssdr will have broader SIMD coverage, improving the efficiency of GNSS-SDR on ARM and RISC-V architectures, making it more portable and performant for diverse GNSS applications.
      Required skills:
      Applicants should have a solid understanding of numerical computations and be proficient in C programming.
      Potential mentor(s):
      Carles Fernández-Prades.
         
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gnss-sdr/
    idea_list_url: https://gnss-sdr.org/google-summer-code-2025-ideas-list/

  - organization_id: 48
    organization_name: GNU Compiler Collection (GCC)
    no_of_ideas: 9
    ideas_content: |
      
      Rust Front-End. a new compiler front-end for Rust is in development please see: https://github.com/Rust-GCC/gccrs. A number of projects are available, you can choose one of the following. Required skills include C/C++ and finding a way through a large code-base, some knowledge of Rust would of course also be highly beneficial.
      Rewrite Rust lints to operate on our frontend's HIR instead of using GCC's existing infrastructure
      Our frontend has mutliple lint passes (mark-live, scanning for dead code, unused variables...) which are currently implemented by making use of existing GCC middle-end passes. However, this approach poses certain issues for our frontend, and we would like to instead implement these passes using our frontend's internal representation, and more specifically our HIR.
      To facilitate writing these lints, you will first need to introduce a new base HIR visitor class which will allow you to avoid repeating yourself with boilerplate visitor pattern code. Once this is done, you will need to reimplement existing lints to work using this new base visitor class. If time permits, it would be helpful to rewrite other HIR passes to make use of the new visitor framework you will introduce.
      This can be both a medium-sized or large project.
      Complete name resolution pass rewrite
      In order to handle complex imports and exports in the Rust programming language, we have started a rewrite of our name-resolution pass with a new data-structure and a new algorithm for resolving uses. We are planning to get the new algorithm to a working state by Spring 2025, but this rewrite will still be missing some of the features of the old name-resolver. Your goal will be to take care of these features and help us get the name-resolution rewrite to feature-parity with our old algorithm.
      This project should be medium-sized.
      Improving match expressions and pattern matching
      Our frontend is currently lacking support for important Rust patterns such as struct rebinding patterns (destructuring a structure instance's fields and binding them to new names) which prevents us from completing certain compiler milestones, as well as handle existing Rust code within the Rust standard library and Rust-for-Linux project. You will be tasked with improving multiple areas of the compiler in order to improve our handling of match expressions and pattern matching.
      This project can be medium-sized or large.
      
      ~~~~~~~~~~
      
      Fortran – DO CONCURRENT – see GFortranStandards for language links (Fortran standard and what's new documents for 2018 and 202x). Project would be mentored by Tobias Burnus. Required skills include C/C++; some knowledge of Fortran helps, but is not needed. Difficulty medium, size: 175 hours (medium)
      "DO CONCURRENT" is a special way to write loops such that each iteration is independent of another (except for reductions), permitting to run it concurrently.
      Goal is to execute the loops actually in parallel, namely:
      Handling do-concurrent loops in the generic OpenMP code, possibly starting without MASK support and only for those annotated by '!$omp loop'
      Extending it for MASK support / or optimizing the loop count for it.
      Handling parallelization without '!$omp loop' using the command line flag -fdo-concurrent= (like: no parallelization, OpenMP loop, etc.), "parallel" (pthread parallelization similar to (based on?) -ftree-parallelize-loops=n).
      For some experiments and results, see also https://arxiv.org/pdf/2110.10151.pdf or experiments by other compiler vendors (search the internet)
      As of Feb 2025, local/local_init for Fortran loops isn't fully implemented, PR101602, this does not affect the OpenMP implementation but just scalar code, but should eventually be fixed. (Hopefully, it will be fixed by the time this project starts. If not, it could be a first task.)
      
      ~~~~~~~~~~
      Fortran – 2018/202x – Several Fortran 2018 and all Fortran 202x features are unimplemented. See GFortranStandards for language links (Fortran standard and what's new documents for 2018 and 202x).
      Project would be mentored by Tobias Burnus. Required skills include C/C++; some knowledge of Fortran helps, but is not needed.
      The size and difficulty of the project depends on its agreed scope, i.e. it can be both a 175-hour (medium-sized) or a 350 hour (large) project, can be both medium difficulty or hard.
      Effort depends on which new feature(s) are implemented; requires some research about what's missing and about the effort. If interested, please ask via the fortran@ mailing list, https://gcc.gnu.org/lists.html
      For instance, the "Extracting tokens from string", "Interoperability with C", and "Trig functions changes" documented in "what's new in 202x" document would be a medium sized project.
      
      ~~~~~~~~~~

      Fortran – run-time argument checking. – In particular older Fortran code, which does not use modules, but also code which uses implicit-size or explicit-size arrays is prone to argument mismatches. The goal of this item is to add an optional run-time test which works by storing the argument-type/size data before the call in a global variable – and check against it in the callee. (A pointer to the called function is stored alongside to permit calls from uninstrumented code to instrumented code.) This project would/could be mentored by Tobias Burnus. Required skills include C/C++; some knowledge of Fortran helps, but is not needed. Difficulty medium, size: 175 hours (medium).
      
      ~~~~~~~~~~

      Fortran – improved argument compile-time checking – The compiler does check for the arguments in the same file – but it could do better in some cases, i.e. checking better the interface data or updating the expected input better from the use. This project would/could be mentored by Tobias Burnus. Required skills include C/C++; some knowledge of Fortran helps, but is not needed. Difficulty medium, size: 175 hours (medium).
      
      ~~~~~~~~~~

      Enhance OpenACC support. OpenACC is parallel programming model for heterogeneous HPC hardware. GCC currently supports most but not all of OpenACC 2.6. The project idea here is to fill some of the gaps, for example, implement:
      OpenACC acc_memcpy_device runtime API routine
      OpenACC init, shutdown, set directives
      These complement the corresponding acc_init etc. runtime API routines, which are already implemented.
      Make the OpenACC cache directive actually do something
      It's currently only parsed, but we're not actually using it for optimization purposes: prefetch data, move data to low-latency memory.
      OpenACC bind clause
      OpenACC device_type clause
      To work on these items, it's definitely very helpful to have available a GNU/Linux system with an AMD or Nvidia GPU supported by GCC Offloading, but it's not strictly necessary. Mentors: Thomas Schwinge, Tobias Burnus. The size and difficulty of the project depends on the agreed number of items to be implemented, i.e. it can be both a 175-hour (medium-sized) or a 350 hour (large) project, can be both medium difficulty or hard.
      
      Notes on OpenACC init, shutdown, set directives:
      Certain functionality in OpenACC exists both in a directive variant and a runtime API routine variant. For example, OpenACC 2.6 has 2.16.3. "Wait Directive" (directive variant) and 3.2.11. "acc_wait" etc. (runtime API routine variants). In GCC, the front ends map the directive variant to gcc/omp-builtins.def:BUILT_IN_GOACC_WAIT (see git grep --cached BUILT_IN_GOACC_WAIT\\\|c_finish_oacc_wait -- gcc/). This eventually gets translated to a regular function call to libgomp/oacc-async.c:GOACC_wait, which uses the same building blocks as do acc_wait etc., which are also implemented in libgomp/oacc-async.c. (libgomp is the GCC runtime library for OpenMP originally, but then also OpenACC, implementing both the user-level OpenACC "Runtime Library Routines" and the compiler-used GOACC_[...] etc. routines.) Similar for #pragma acc enter data create(var) vs. acc_create, and others. Some users like to use one of directive vs. runtime API routine variants over the other; generally some prefer using the directive variants instead of C/C++ #include <openacc.h> or Fortran use openacc module. Corresponding to the acc_init, acc_shutdown, acc_set_device_num/acc_set_device_type runtime API routine variants implemented in GCC, in OpenACC 2.5, "New init, shutdown, set directives were added", which are not yet implemented in GCC. Implementation of those is assumed to be very much similar as the OpenACC wait directive is via BUILT_IN_GOACC_WAIT, for example, so would enhance the GCC code along these lines, plus proper testsuite coverage.
      
      ~~~~~~~~~~
      Simple file system for use during Nvidia and AMD GPU code generation testing. GCC supports code offloading from a host system to a device: Nvidia and AMD GPUs, via the OpenACC and OpenMP target programming models for heterogeneous HPC hardware. In order to test Nvidia PTX and AMD GCN (etc.) code generation, bare of the OpenACC/OpenMP code offloading infrastructure, we run GCC's make check in configurations where the GPU is treated similar to an embedded device: generate (single-threaded) GPU code, use a run tool to load it to the device and execute it (Nvidia, AMD), and return success status. Other than simple malloc and printf implementations, these device kernels don't have any "access to the outside world". In particular, they have no way to read/write files -- which a number of GCC test cases like to do, which thus currently FAIL to execute. The idea of this GSoC project is either (a) to implement a simple "in-memory" file system (volatile), which is either (a.1) initially empty or (a.2) initially contains files as determined by the test harness (dg-additional-files directives used in test cases), and may grow additional files that the respective test case writes, and then is able to read back, or (b) to implement an RPC mechanism from the device to the host, so that device kernels may access host files. (The latter is implemented by LLVM, for example.) Either variant is to be implemented in the run tools mentioned above, and newlib, which provides a libc for the devices. In order to execute this project, you have to have a system with a GPU that is supported with GCC code offloading (a laptop with Nvidia GPU should work, for example), and some prior experience with low-level GPU or embedded programming is highly desirable, as well as understanding of low-level file access: how are open, write, etc. typically implemented. For variant (a), how to implement a simple "in-memory" file system; for variant (b), how to implement an RPC mechanism between device and host? Performance is not a big concern in this context. Mentor: Thomas Schwinge. The size and difficulty of the project depends on the agreed number of items to be implemented, i.e. it can be both a 175-hour (medium-sized) or a 350 hour (large) project, can be both medium difficulty or hard.
      
      ~~~~~~~~~~
      
      Extend the static analysis pass GCC has gained an experimental static analysis pass which performs some rudimentary checking of malloc/free and the stdio FILE stream API. There is plenty of scope for extending this pass in ways that may interest a contributor, such as
      Add format-string support to -fanalyzer. We currently have two different implementations of warnings for format strings (e.g. printf) in GCC; gcc/c-family/c-format.cc implements -Wformat in the C/C++ frontends, doing type-checking on format strings against their arguments, and gcc/gimple-ssa-sprintf.cc implements parts of -Wformat_overflow=, -Wformat_truncation=, and -Wrestrict in the middle-end). Now that the analyzer has -Wanalyzer-out-of-bounds, it might be good to refactor and generalize this format-string parsing to share more code, and so that the analyzer can reuse it, and do similar range analysis (but with the analyzer's more precise path-sensitive interprocedural approach; see https://gcc.gnu.org/bugzilla/show_bug.cgi?id=107017)
      Add a checker for some API or project of interest to the contributor (e.g. the Linux kernel, a POSIX API that we're not yet checking, or something else), either as a plugin, or as part of the analyzer core for e.g. POSIX.
      Extending the analyzer's support for C++. See https://gcc.gnu.org/bugzilla/showdependencytree.cgi?id=97110.
      Extend the plugin to add checking for usage of the CPython API (e.g. reference-counting); see https://gcc.gnu.org/bugzilla/show_bug.cgi?id=107646
      This project would be mentored by David Malcolm. Required skills include C/C++ and finding a way through a large code-base. The size of the project depends on its agreed scope, i.e. it can be both a 175-hour (medium-sized) or a 350 hour (large) project but it is probably easier to define a large one. Difficulty also depends on scope but is likely to be hard.
      One more project idea, co-mentored by Thomas Schwinge:
      e. add checks for programs using OpenACC (parallel programming model for heterogeneous HPC hardware), for example: extend the analyzer's existing malloc/free-like checks to understand OpenACC host vs. device memory, and OpenACC runtime API memory allocator and mapper routines (acc_malloc vs. acc_create vs. acc_map_data etc.; see also here). Depending on the number of checks to be implemented, this can also be both a 175-hour (medium-sized) or a 350 hour (large) project. As the suggested checks only concern host-side code, having an AMD or Nvidia GPU supported by GCC Offloading is not necessary for this project.
      
      ~~~~~~~~~~
      
      Tooling for running BPF GCC tests on a live kernel. eBPF is a technology for injecting code into, for example, a running Linux kernel, in a safe way. GCC contains a back end for eBPF code generation. There is a target specific testsuite with many compile-time tests, and a lot of the other compiler testsuites can also be tested. However, the BPF backend doesn't have any execution tests. Other backends rely on a simulator in order to run target GCC tests. However, BPF programs are not like userland programs. They have no main function. Instead every compiled object may feature several entry points, which are designed to be invoked by a kernel. These entry points are of different kinds, and the context provided via a pointer argument to each entry point is different depending on the kind of entry point. For example, a BPF entry point for a kprobe gets passed an argument that points to a description of the probed task. Due to this, it would be very difficult to have a simulator actually emulating a running kernel with all its complexities. We do have a simulator, but it is designed just to emulate simple instructions in combination with GDB. The goal of this project is to:
      Write a test tool (probably within the contrib/ directory in the GCC sources) to launch a suitable kernel in some sort of virtual environment (like qemu) and load and execute a given BPF program object. This is similar to what the kernel BPF sefltests infrastructure does. This also requires to write some glue infrastructure for the BPF tests, in order to communicate the result of execution of tests etc.
      Once we have the test tool, the next step will be to integrate it in the Dejagnu based testing infrastructure in GCC.
      Finally, using the integrated infrastructure, a new testsuite for the BPF target shall be added to the GCC testsuite, containing an initial set of well choosen tests.
      Note that the BPF, by its own nature, will really benefit from having execution tests in the compiler testsuite, because in practice every compiler change (not just in the BPF backend) has the potential of causing the compiler to generate programs that are not verifiable by the kernel BPF verifier. This is thus an important project. Prior knowledge of eBPF specifically is not necessary but useful; some prior knowledge of (virtual) instruction set architectures is desirable. Knowledge on building the kernel and virtualization environments would also be very useful. Mentors: David Faust, Jose E. Marchesi, Thomas Schwinge. The difficulty of this project is medium, and the size is large: 350 hours. However, if only the point 1 and 2 are implemented then it could be medium-sized: 175 hours.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gnu-compiler-collection-(gcc)/
    idea_list_url: https://gcc.gnu.org/wiki/SummerOfCode

  - organization_id: 49
    organization_name: GNU Image Manipulation Program
    no_of_ideas: 14
    ideas_content: |
      
      Implement In-Painting Tool
      Category
      User Interface, Core, Tools, GEGL
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, CmykStudent
      Difficulty
      Intermediate
      Outcome
      implementation of the tool in GIMP codebase
      GIMP has had support for in-painting (filling in an area based on the surrounding image) for many years with the third-party Resythesizer plug-in. There have been many requests to implement the feature as a tool directly in core GIMP. In addition to this algorithm, there is also the GEGL operation alpha-inpaint which works similarly.
      Relevant discussions that would assist with implementing this feature can be found here and here.
      Study the Resynthesizer plug-in, gegl:alpha-inpaint operation, and other implementations
      Design a potential implementation and UI
      Improve the implementation of the algorithms as needed
      Implement the tool

      ~~~~~~~~~~
      Image Segmentation Improvements
      Category
      Core, Tools
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, CmykStudent
      Difficulty
      Intermediate
      Outcome
      New and/or improved algorithms for selecting parts of images
      GIMP has many different tools and algorithms for selecting specific sections of an image - from the standard Rectangle and Ellipse Select tools to the more advanced Paint Select and Foreground Select tools. Yet there are always new algorithms and methods for segmenting images.
      Find an existing algorithm or propose a new one
      Implement, optimize and test for real image processing work on a variety of images
      Design how it should be used in GIMP
      An additional mode in an existing tool
      A new tool entirely

      ~~~~~~~~~~
      Improving unit testing
      Category
      Unit testing
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, Jacob
      Difficulty
      Intermediate
      Outcome
      Improved unit testing infrastructure and new unit tests
      Currently GIMP unit testing framework is really outdated, adding new tests is complex and therefore never happens. We should specify and code a proper framework for testing GIMP features.
      This implies automated tests we can run in our Continuous Integration in Gitlab and not interactive tools (though such tools can be interesting too, as additional process, if someone has something nice to propose).
      Port existing tests to the new framework;
      Testing all libgimp functions;
      Testing GEGL operations implemented within GIMP codebase;
      Testing plug-ins (in priority the file import/export ones, but not only);
      Testing core code;
      Testing GUI code if possible;
      Writing down the procedure to add unit tests to make it a mandatory process in future development.

      ~~~~~~~~~~
      Fuzz testing integration
      Category
      Unit testing, Security
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, Jacob
      Difficulty
      Intermediate
      In addition to unit testing, we would also like to build a robust automated fuzz testing suite. Integrating a fuzzer would help us better detect when new code could lead to a security vulnerability or incorrect behavior in GIMP. This project would cover many aspects of GIMP, from core code to plug-ins to public API.
      Study GIMP and determine what areas to cover in initial implementation
      Review fuzzing techniques and tools
      Design a test suite and process
      Implement fuzz testing suite

      ~~~~~~~~~~
      Implement sandboxing for plug-ins
      Category
      Security, Plug-ins
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, Jacob
      Difficulty
      Complicated
      Many features of GIMP such as image import and export are implemented with separate plug-ins. For this project, we would like to run them in a sandbox environment for safety and security.
      This is a complex project, and requires knowledge of both GIMP’s architecture as well as extensive research into security. Mentors would be learning alongside the student, so any interested individual would need to be able to work well independently. Please contact us to discuss your proposal for this project.

      ~~~~~~~~~~
      Improving the text tool
      Category
      GEGL, color science
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Liam Quin
      Difficulty
      Intermediate
      Outcome
      Improvement of the text tool
      This is a project following up a few previous GSoC projects, which deserves further work as this is a complicated topic.
      Our text tool is a bit of a UI and UX mess and deserves a proper rewrite/enhancement project:
      Re-specify text editing and formating as well as the tool option, for existing features, but also adding new features for modern text editing (see also this draft);
      Add OpenType support.
      Continue previous years experiments on a new text layout library.

      ~~~~~~~~~~
      Implement GEGL operations for GIMP
      Category
      GEGL, image processing
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, Øyvind
      Difficulty
      Intermediate
      Outcome
      implementation or improvements of GEGL operations in GIMP or GEGL codebase
      The migration of GIMP to use GEGL has accelerated - for some GIMP functionality the main hurdle to migrate is having GEGL ops that can act as drop in replacement for the core processing functionality (some ops would be desired directly in GIMP others could likely go directly into GEGL).
      For most code involved, porting to GEGL involves understanding what the current code does; and port or reimplement it as a floating point processing operation (floating point math often ends up shorter and more readable than the 8bit equivalents.
      There are also some filters which were ported to GEGL, but some people prefer the old one (e.g. the Sharpen filter). It would be worth investigating the difference and either implement the old one or improve the new one.
      Talk to us for specifics on which operations would be a good project`.

      ~~~~~~~~~~
      Implement OpenColorIO Color Management
      Category
      User Interface, Core, Tools, GEGL
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      drc, CmykStudent
      Difficulty
      Intermediate
      Outcome
      implementation of the OCIO color management system in GIMP codebase
      GIMP uses industry standard ICC Color profiles to allow users to match and maintain colors for image editing and printing. The film industry utilizes a separate standard, OpenColorIO, which focuses more on manipulating colors in a space rather than trying to keep them consistent across multiple devices.
      This project would involve adding support for OCIO color management in addition to the existing system. This addition would improve user workflows for motion picture and animation work, as well as improve compatibility with other OCIO-supporting software like Blender and Krita. The project would involve the following:
      Research OCIO and color management systems in general
      The Krita manual has an excellent overview of the subject
      Design and test a user interface
      Implement the code
      
      ~~~~~~~~~~
      Implement GEGL Filter Browser
      Category
      GEGL, User Interface
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan
      Difficulty
      Intermediate
      Outcome
      implementation of the feature in GIMP codebase
      During the 3.0 development process, a new filter API was created that allows script and plug-in developers to apply any valid GEGL filter they have installed. However, GIMP doesn’t not currently have a built-in browser to easily find the name, descriptions, and properties of these filters.
      For this project, you would design and develop a GEGL Browser, similar to the existing Plug-in and Procedure Browsers. This will involve both code development and UX/UI Design.
      
      ~~~~~~~~~~
      
      Improve Non-Destructive Editing
      Category
      GEGL, User Interface
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, CmykStudent
      Difficulty
      Intermediate
      Outcome
      implementation of the feature in GIMP codebase
      As of version 3.0, GIMP now has initial support for non-destructive editing with layer effects. Yet there is much more work to be done. Our roadmap provides some ideas for the next areas to improve, or you can propose your own:
      Studying the current implementation
      Design improvements to UI or functionality
      Implement the improvements
      
      ~~~~~~~~~~
      Improving off-canvas editing
      Category
      User Interface, Core
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan
      Difficulty
      Intermediate
      Outcome
      implementation of the feature in GIMP codebase
      GIMP recently got the ability to view the image out of the canvas. This is still incomplete. Among the many possible improvements:
      Being able to select off-canvas.
      Being able to see off-canvas but with an effect (e.g. dimming).
      Having various tools and features working differently when “Show All” is enabled.
      
      ~~~~~~~~~~
      Improve Metadata Editor and Viewer
      Category
      Metadata, Plug-in, User Interface
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, Jacob
      Difficulty
      Intermediate
      Outcome
      Improved metadata UI and codebase
      Our image metadata viewer and editor could use some code review and improvements. It currently supports only a subset of all valid metadata, and the UI could be improved to allow easier editing and viewing of metadata.
      Additionally, some image formats such as HEIC, FITs, and DICOM have custom metadata. Another aspect of this project might be considering how to handle these in a way that is easily extensible and maintainable.
      For further inspiration, you can review open issues tagged with the Metadata label in our tracker.
      Review metadata related issues and develop a plan
      Design user interface and code structure
      Implement planned changes in the metadata plug-in
      
      ~~~~~~~~~~
      Extension website
      Category
      Web
      Project size (GSoC)
      Large (350 hours)
      Skills
      Python, HTML, Javascript and other web technologies
      Possible mentors
      Jehan
      Difficulty
      Intermediate
      Outcome
      New website and build scripts for continuous integration
      We would want a website for our future extension platform, with very specific criteria. Apart from some necessary dynamic parts, we want a website as static as possible, with generated pages when possible. GIMP is a software project, which relies on community. We don’t want to spend all our time having to maintain and manage a website with a lot of moving parts. So we need simplicity first, security first, with just the right amount of dynamicity. The static website framework which we seem to want to go with the most in our project right now is Hugo.
      Even though it has a “web” component, this project is also about building a proper backend, which includes processing XML metadata (AppStream) in a secure way (considering third-party received data as unsafe and possibly malicious), generic static web and repository data from these repositories, and more.
      See this document for an early overview of what we are looking for.
      
      ~~~~~~~~~~
      Convert gimp-help build system from autotools to meson
      Category
      gimp-help, build system
      Project size (GSoC)
      Large (350 hours)
      Skills
      Python, some understanding of autotools and Makefiles
      Possible mentors
      Jacob
      Difficulty
      Intermediate
      Outcome
      The gimp-help repository can be built using meson
      More and more projects move from autotools to meson for building. GIMP itself already uses meson as main build system. We would want all targets in our autotools build converted to meson. The main ones being able to build html for all languages, validate the xml files, create the distribution packages, making pdf quickreference guides, etc.
      Some guidelines for porting from autotools to meson can be found here, and more Gnome specific here.
      The build system needs to function on Linux, Windows and Mac. This would need to be integrated in our CI builds. There is an almost 2 year old repository where some work was done, but we ran into some problems due to the more strict directory and other requirements of meson. However, there have been improvements to meson which may make it easier now.
      It is possible that you may have to write a meson module like the gnome one, which has functions for handling yelp, gtkdoc, etc. Don’t forget to check out the i18n module, you may be able to use that too.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gnu-image-manipulation-program/
    idea_list_url: https://developer.gimp.org/core/internship/ideas/


  - organization_id: 50
    organization_name: GNU Octave
    no_of_ideas: 3
    ideas_content: |
      
      
      Adding clustering *Searcher classes in statistics package
      Although the statistics package already has knnsearch and rangesearch functions, it misses classdefs for extending their functionality. Furthermore, the KDTree method in the aforementioned functions is currently disabled, because it is very slow and poorly implemented (see GitHub issue #151). The goal of this project if to implement KDTreeSearcher, ExhaustiveSearcher, and hnswSearcher classes (including their knnsearch and rangesearch methods) along with the createns helper function. Beyond MATLAB compatibility, the KDTree implementation should ideally utilize a compiled oct library for faster construction and queries of points.
      Project size [?] and Difficulty
      ~350 hours (hard)
      Required skills
      Octave, classdef, C++, good knowledge of clustering methods
      Potential mentors
      Andreas Bertsatos

      ~~~~~~~~~~



      Custom re-implementation of the texi2html (v.1.82) command line tool
      Implement a compiled .oct function to relax the dependency of the pkg-octave-doc package on texi2html (v.1.82) command line tool, which is no longer maintained or further developed but also not readily available to all linux distributions. The idea is to have a `texi2html` function within the pkg-octave-doc package that will replace the functionality of the texi2html (v.1.82) command line tool. This will also help improve the speed of pkg-octave-doc processing large packages, which contain specific tags (such as @math) which are currently handled within Octave code.
      Project size [?] and Difficulty
      ~350 hours (hard)
      Required skills
      Perl, C++, Octave, Texinfo, HTML
      Potential mentors
      Andreas Bertsatos

      ~~~~~~~~~~
      
      Port Chebfun to Octave and improve classdef support
      Chebfun uses interpolation to approximate functions to very high accuracy, giving numerical computing that feels like symbolic computing. The software is implemented as collection of "classdef" classes and is Free and Open Source Software. However, Chebfun does not yet work with Octave, largely due to differences and issues with Octave's classdef implementation. This project has two aims: (1) make changes to the Chebfun code to make it work on Octave and (2) improve Octave's classdef functionality. Some initial steps toward to first goal can be found on this octave_dev branch. The second goal will likely involve a collaborative effort because classdef is a priority on | Octave's Development Roadmap and because other proposed projects also involve classdef.
      Project size [?] and Difficulty
      ~350 hours (hard)
      Required skills
      Octave, object-oriented programming, polynomial interpolation and approximation theory, C++.
      Potential mentors
      Colin B. Macdonald

    
      
      
      
      
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gnu-octave/
    idea_list_url: https://wiki.octave.org/Summer_of_Code_-_Getting_Started#Suggested_projects


  - organization_id: 51
    organization_name: GNU Radio
    no_of_ideas: 8
    ideas_content: |
      
      FM Broadcast Radio application
      GNU Radio has built-in capabilities to receive, decode and play FM broadcast radio stations. With additional projects https://github.com/bastibl/gr-rds we are able to decode RDS data alongside. The project does not (yet) have a fully fledged demo application which would allow potential users and beginners to see how to build a production-grade application (almost). The goal for this project is to build an application which works plug&play with many SDRs and automatically scans (all) potential FM broadcast frequencies, gives a channel list and allows users to tune/select a radio station they would like to listen to.
      Therefore one part of the project is to focus on a polished user experience in the frontend application. Since this should be a good demo the other part of the project should focus on developing a well-functioning flowgraph with the existing signal processing blocks and potentially also porting gr-rds to a newer GNU Radio and/or integrating it in the GNU Radio source tree. This flowgraph should then be started/halted on demand of the frontend application. Potentially multiple streams could be recorded at the same time or decoded and some of the signal processing signals can be shown in a debug view so potential beginners and users can perform introspection on the application.
      
      Prerequisites
      Programming skills in Python
      Interest in designing a functional and polished graphical user interface
      Preferred: Familiarity with basic signal processing libraries in Python (e.g., SciPy).
      Interest working with real radio signals
      Expected Outcome
      Fully fledged FM broadcast receiver application with integrated RDS and spectrum scanning
      A clean example application which shows how the signal processing can be combined well with a GUI
      Project Length
      Small (100 hours) – Medium (200 hours)
      Difficulty'
      Easy
      Mentor(s)
      Andrej Rode

      ~~~~~~~~~~
      5G Cell Scanner
      Cell scanning by passively observing the RF environment using an SDR and decoding received signals based on the waveforms defined in the 2G/3G/4G/5G standards is a well-established approach for assessing cellular connectivity in the surrounding environment. While multiple cell scanners are publicly available, they often employ opaque signal processing methods and frequently cease analysis prematurely, failing to provide detailed information about the cells. This includes not decoding the Master Information Block (MIB) and the System Information Block (SIB1) to extract cell properties and signal quality metrics. Our objective is to develop a high-quality cell scanner using GNU Radio in a transparent way that delivers the most information possible (depending on the cells’ signal levels) in a trustable manner. The general procedure will be based on the initial synchronization and cell identification process on the user-equipment side of 5G (see further reads). Depending on the student’s experience, we can also go a step further and parallelize the cell scanning process by observing multiple frequency bands simultaneously by applying channelization and parallel processing techniques to the signal.
      Prerequisites
      Proficiency with GNU Radio.
      Basic programming skills in Python.
      Preferred: Familiarity with basic signal processing libraries in Python (e.g., SciPy).
      Preferred: General understanding of the 5G waveform and experience with 5G processing libraries in Python.
      Expected Outcome
      Development of an Out-Of-Tree (OOT) module or flowgraphs capable of interacting with SDR input streams and automatically generating detailed visualizations of cell search results.
      Capability to export results as a function of time and SDR location to enable the creation of coverage maps.
      Further Reads
      https://de.mathworks.com/help/5g/ug/nr-cell-search-and-mib-and-sib1-recovery.html
      https://de.mathworks.com/help/5g/gs/synchronization-signal-blocks-and-bursts.html
      Project Length
      Small (100 hours) – Medium (200 hours)
      Difficulty'
      Medium
      Mentor(s)
      Michael Petry
      Andrej Rode

      ~~~~~~~~~~
      
      Expanding the GNU Radio 4.0 Block Set
      GNU Radio 4.0 has reached a stage where real signal processing applications can achieve performance improvements over GNU Radio 3.x. To maximize its adoption, we aim to expand the set of available blocks, making it easier for the community to build applications with readily available components. The goal of this project is to migrate existing GR 3.x blocks (e.g. gr-digital, gr-analog, gr-audio ...) into GR 4.0. A good list of blocks in GR3 that should be ports has been maintained here: [1]
      Prerequisites
      Knowledge of modern C++
      Signal processing understanding
      Outcome
      GR4 OOT module with a substantial number of blocks
      Each block should have CI tests and an example flowgraph
      Document the process so that other block developers can be guided
      
      Project length
      Long (350 hours)
      Difficulty
      Medium
      Mentor(s)
      John Sallay, Josh Morman

      ~~~~~~~~~~
      
      Graphical interoperability between CyberEther and GNU Radio
      The CyberEther project comes with some neat graphical sinks that would be great to have access to in GNU Radio. This project entails creating a new CyberEther GUI workflow much like the gr-bokehgui project, such that users can create flowgraphs with CyberEther sinks. This would allow the user to visualize GNU Radio data streams in one of the high-performance CyberEther plots (lineplot, waterfall, spectrogram, etc).
      Prerequisites
      Knowledge of C++ and some Python
      Familiarity with graphical APIs (OpenGL, Vulkan, Metal)
      Basic Qt understanding
      Outcome
      OOT module with CyberEther sinks
      Support for both GNU Radio main branch and 3.10?
      Project length
      Long (350 hours)
      Difficulty
      Medium
      Mentor(s)
      Luigi Cruz, Håkon Vågsether

      ~~~~~~~~~~
      GPU Accelerated Signal Processing Blocks
      GPUs offer incredible capability for accelerating a number of signal processing routines when the calculations can be done in parallel. Also, GNU Radio 3.10 brought in a "custom buffers" feature which provides support generally for accelerator devices by allowing blocks to have direct access to device memory, finally making accelerator processing feasible through a flowgraph (see FOSDEM 2022 Presentation.
      One piece that is missing for GNU Radio is a library of blocks that accelerate common DSP routines. There are several interesting libraries of GPU accelerated signal processing - primarily using CUDA because of its accessible programming paradigm and the ubiquity of NVIDIA hardware:
      Matx
      cuSignal (Python signal processing)
      CUSP
      Integration of any of this functionality, along with additional kernels for signal processing would need to be predicated on using gr-cuda custom buffers, and expanding this module as needed
      This project can be broken into several subprojects:
      Create gr-matx OOT
      Add Matx Custom Buffer Type (after gr-cuda)
      Create blocks wrapping Matx operations
      Expand gr-cuda
      Additional custom buffer types - pinned, unified
      Create python custom buffers allowing zero copy into python blocks
      Create gr-cuSignal
      Wrap cuSignal functionality (dependent on python zero copy)
      Replicate existing GR blocks as CUDA accelerated (things not in cuSignal or Matx)
      Target for extensions to Matx, cuSignal, or CUSP (within our control)
      FIR Filters
      Polyphase Resampler
      Signal Source
      Moving Average
      Polyphase Clock Sync
      Stream Operators
      ...
      Prerequisites
      Knowledge of C++ and Python.
      Familiarity with CUDA programming
      
      Outcome
      Depends on chosen subprojects (see above).
      Project length
      350 hours
      Difficulty
      Medium
      Mentor(s)
      Josh Morman, Andrej Rode

      ~~~~~~~~~~
      GRC and GR 4.0
      Development of GR 4.0 is progressing quickly. In the current runtime prototype a plugin architecture is used to properly register blocks with the runtime. This allows a more dynamic construction of flowgraphs and introspection into the blocks. But this means the current way of assembling a flowgraph by generating a Python or C++ file needs updates.
      The idea is to port and change necessary parts of GRC (Qt development version) to use the block registry in the new GNU Radio runtime https://github.com/gnuradio/gnuradio4/ and assemble some of the example flowgraphs defined in GRC files and make them run. The design for this is not finalized and therefore you will have freedom to propose your ideas.
      Prerequisites
      Good Knowledge of C++ and Python
      Experience with inter-language bindings (not necessarily C++ & Python) is useful
      Basic Qt understanding
      Outcome
      Prototype integration of GRC with the new plugin architecture of GR 4.0
      Project length
      Long (350 hours)
      Difficulty
      Challenging
      Mentor(s)
      Andrej Rode, Josh Morman


      ~~~~~~~~~~
      
      
      
      Revitalize in-tree and out-of-tree (OOT) modules
      A lot has changed since version 3.7, and GNU Radio has made great technical strides the last few years. However, some OOT modules haven't been updated to support the latest versions of GNU Radio, and these modules currently require the user to install an older version of the framework. This is unfortunate, and lowers the useability of GNU Radio as a whole. Some of these modules have been superseded by others, but might still have some blocks or flowgraphs that are useful, and these could be updated and moved in-tree. Some in-tree modules are also in need of attention, like gr-wavelet, which does not have any examples.
      Prerequisites
      Knowledge of C++, Python and DSP.
      Outcome
      More example code, tests and flowgraphs for various in-tree modules
      Porting various OOT modules to support recent versions of GNU Radio
      Possibly blocks/flowgraphs from old OOT modules moved in-tree
      Project length
      Small (90 hours) - Medium (175 hours)
      Difficulty
      Easy - Medium
      Mentor(s)
      Andrej Rode, Håkon Vågsether

      ~~~~~~~~~~
      
      CI for maintenance branches and select OOT modules
      It would be useful to have nightly builds for GNU Radio's maintenance branches (3.8, 3.9, 3.10) and some select OOTs.
      Prerequisites
      Experience with Docker?
      ?
      Outcome
      Automated PPAs, Snaps, Flatpak apps
      Project length
      175 hours
      Difficulty
      Easy
      Mentor(s)
      Håkon Vågsether, ?
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gnu-radio/
    idea_list_url: https://wiki.gnuradio.org/index.php?title=GSoCIdeas

  - organization_id: 52
    organization_name: GRAME
    no_of_ideas:
    ideas_content: |
      
      Integrated Faust Language Server and Formatting Extension for VS Code
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      Description: A language server, sometimes called an LSP, is a code analysis tool that allows programming environments to get information about projects. This lets them display information like code completions, inline errors, locations of function definitions, reference official documentation, and more. Many programming languages have their own language server (see https://langserver.org/ for a list), but Faust does not. If there was a Faust language server, it would make it easier to write Faust code using any IDE that supports LSP. This would make it easier for beginners to get started writing Faust using programming tools they're already familiar with, and it would make it easier for experts to navigate large codebases. The tree-sitter-faust project could be helpful in doing any parsing required for a language server.
      We propose to create a Visual Studio Code extension that integrates the Faust Language Server with a dedicated Faust code formatter. Leveraging the vscode-languageclient package, the extension will launch the Faust Language Server to provide robust features (code completion, diagnostics, navigation) while also offering context-aware formatting tailored to Faust DSP syntax.
      Integrate the Faust Language Server:
      Use vscode-languageclient to launch and manage the server, ensuring features like auto-completion and error checking are available for .dsp files.
      Develop a Faust Code Formatter:
      Implement a formatter that understands Faust’s constructs, providing commands and auto-format-on-save functionality to improve readability and enforce best practices.
      Expected outcomes:
      A fully functional VS Code extension that combines the Faust Language Server with a dedicated code formatter.
      Enhanced developer productivity through improved code intelligence and formatting.
      Comprehensive documentation and user-friendly configuration options, making it easier for the Faust community to adopt best practices.
      Skills required: Faust programming, TypeScript and Web programming.
      An easy, medium or hard difficulty rating of each project: medium
      
      ~~~~~~~~~~
      Extending the Faust DSP Testbench
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      Description: The Faust DSP Testbench, a fork of the DSP-Testbench project, is designed to help developers using the JUCE framework to analyse their Faust DSP. This project will focus on extending the Testbench’s functionality to make it a more comprehensive and user-friendly tool for developers and researchers working with Faust.
      The proposed extensions aim to:
      Extend and improve the visualisation tools.
      Enable better visualization of DSP performance and behavior.
      Expected outcomes:
      A robust, user-friendly Faust DSP Testbench with automated testing, benchmarking, and visualization capabilities.
      Comprehensive documentation and tutorials for using the Testbench effectively.
      Skills required: Faust programming, DSP theory, C++, knowledge of the JUCE framework.
      An easy, medium or hard difficulty rating of each project: medium
      
      ~~~~~~~~~~
      Backend for MOJO
      Mentors: Stéphane Letz and Yann Orlarey
      Expected size of project: 175 hours
      Mojo is a new programming language that bridges the gap between research and production by combining the best of Python syntax with systems programming and metaprogramming. Mojo combines the usability of Python with the performance of C, unlocking unparalleled programmability of AI hardware and extensibility of AI models. With Mojo, you can write portable code that’s faster than C and seamlessly inter-op with the Python ecosystem. Having autodifferentiation inside the language is not yet ready but is regularly discussed on Mojo Discord.
      The primary objective of the project is to develop a backend for this new language, add architecture files, and measure how the generated code behaves doing various benchmarks.
      Expected outcomes:
      a new backend to generate MOJO code
      development of MOJO architecture files to create benchmarks and measure the speed of the generated code
      Skills required/preferred: C++ and basic Python programming, Faust programming
      An easy, medium or hard difficulty rating of each project: medium
      
      ~~~~~~~~~~
      Differentiable DSP in Faust [Taken in 2024]
      Mentors: Thomas Rushton, David Braun, Stéphane Letz, and Yann Orlarey
      Expected size of project: 175 hours
      Differentiable programming is a technique whereby a program can be differentiated with respect to its inputs, permitting the computation of the sensitivity of the program's outputs to changes in its inputs.
      Partial derivatives of a program can be found analytically via automatic differentiation and, coupled with an appropriate loss function, used to perform gradient descent. Differentiable programming has consequently become a key tool in solving machine learning problems.
      Differentiable digital signal processing (DDSP) is the specific application of differentiable programming to audio tasks. DDSP has emerged as a key component in machine learning approaches to problems such as source separation, timbre transfer, parameter estimation, etc. DDSP is reliant on a programming language with a supporting framework for automatic differentiation. In Python, this is provided by libraries such as TensorFlow and JAX; other languages, Swift for example, may feature native support.
      We would like to explore the possibility of implementing automatic differentiation in Faust; the successful implementation of a Faust library for differentiable programming would permit the application of Faust to DDSP problems. Exploratory work on such a library has begun; one aim is to turn this into a comprehensive package of support for differentiable Faust programs.
      Related work, concerned with adding automatic differentiation capabilities to the Faust compiler, was conducted for a previous edition of GSoC. Also consult David Braun's DawDreamer project, which uses Faust's JAX backend.
      Expected outcomes:
      creation of an automatic differentiation library describing derivatives for all of Faust's operators, helper functions for generalising the creation of differentiable Faust programs, a variety of time- and frequency-domain loss functions, etc.;
      development of a series of practical applications of the new library;
      a new autodiff (or machine learning) architecture file, to support the training of machine learning models and the generation of parameter weights;
      a means to use the generated weights for real-time inference.
      Skills required/preferred: Faust programming, machine learning
      An easy, medium or hard difficulty rating of each project: medium
      Support for CLAP format
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      CLAP is an Audio Plugin format (as pure C api), liberally licensed (MIT), entirely developers in the open (GitHub), with support from commercial developers (u-he, Bitwig, more). CLAP has many design goals, but a primary one was to allow developers to build their base plugin layer using a properly open clean C standard, to replace the VST2 API which most folks base their plugin model on, and then project into other systems. An extensive discussion can be accessed here.
      The project is to develop:
      a faust2clap tool (see faust2xx Tools and Developing a faust2xx Script) to statically compile Faust DSP code in a CLAP plugin.
      and a CLAP pluging embedding the libfaust based dynamic compilation chain, so that DSP programs can be written and recompiled on the fly
      new C++ architecture files will have to be developed.
      Look at additional CLAP projects.
      Expected outcomes: The result will be a faust2clap script to compile a DSP program in a CLAP plugin, and a CLAP pluging embedding libfaust.
      Skills required/preferred: C++ programming, audio and Faust programming.
      An easy, medium or hard difficulty rating of each project: medium
      Integration in Surge
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      The Surge Synth Team is a group of musicians, developers, testers, documenters, and general volunteer open source enthusiasts who randomly assembled to work on the Surge Synthesizer. Use the Discord channel to connect to their community.
      The project is to develop a faust2surge tool (see faust2xx Tools and Developing a faust2xx Script) to statically compile Faust DSP code in a Surge plugin. This is currently discussed here. You'll probably have to develop or adapt C++ architecture files.
      Expected outcomes: The result will be a faust2surge script to compile a DSP program in a Surge plugin.
      Skills required/preferred: C++ programming, audio and Faust programming, knowledge of the JUCE framework.
      An easy, medium or hard difficulty rating of each project: medium
      Integration in Bespoke
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      More detailed description of the project: Bespoke is a modular DAW for Mac, Windows, and Linux. It contains a bunch of modules, which you can connect together to create sounds. Use the Discord channel to connect to their community. The integration could follow the two steps:
      develop a faust2bespoke tool (see faust2xx Tools and Developing a faust2xx Script) to statically compile Faust DSP code in Bespoke modules
      a complementary approach is to directly embed the Faust compiler (using libfaust + LLVM JIT), allowing DSP programs to be edited, dynamically compiled, and run in the platform
      This is currently discussed here. You'll probably have to develop or adapt C++ architecture files. A recent Faust integration in TouchDesigner can be studied as an example.
      Expected outcomes: The result will be:
      afaust2bespoke tool to compile Faust DSP code in Bespoke modules
      a Bespoke plugin embedding the libfaust + LLVM library, and allowing DSP programs to be edited, dynamically compiled, and run in the platform
      Skills required/preferred: C++ programming, graphical programming, audio and Faust programming.
      An easy, medium or hard difficulty rating of each project: medium to hard
      References:
      Bespoke Anywhere
      Integration in Godot [Taken as an internship in 2025]
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      More detailed description of the project: Godot Engine is a feature-packed, cross-platform game engine to create 2D and 3D games from a unified interface. It provides a comprehensive set of common tools, so that users can focus on making games without having to reinvent the wheel. The integration could follow the two steps:
      develop a faust2godot tool (see faust2xx Tools and Developing a faust2xx Script) to statically compile Faust DSP code in Godot modules
      a complementatry approach is to directly embed the Faust compiler (using libfaust + LLVM JIT), allowing DSP programs to be edited, dynamically compiled, and run in the platform
      You'll probably have to develop or adapt C++ architecture files. A recent Faust integration in TouchDesigner can be studied as an example.
      Expected outcomes: The result will be:
      afaust2godot tool to compile Faust DSP code in Godot modules
      a Godot plugin embedding the libfaust + LLVM library, and allowing DSP programs to be edited, dynamically compiled, and run in the platform
      Skills required/preferred: C++ programming, audio and Faust programming.
      An easy, medium or hard difficulty rating of each project: medium to hard
      Integration in Cables.gl [Taken in 2024]
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      More detailed description of the project: Cables.gl is a tool for creating beautiful interactive content. With an easy to navigate interface and real time visuals, it allows for rapid prototyping and fast adjustments. You are provided with a set of operators, such as mathematical functions, shapes, materials and post processing effects. Connect these to each other with virtual cables to create the experience you have in mind. Easily export your piece of work at any time. Embed it into your website or use it for any kind of creative installation. Use the Discord channel to connect to their community.
      The project would be to integrate the Faust Web Audio Library to dynamically compile and run Faust DSP programs in Cables.gl.
      Expected outcomes: The result will be a Cable.gl plugin embedding the libfaust WASM library, and allowing DSP programs to be edited, dynamically compiled, and controlled with an adapted Graphical User Interface.
      Skills required/preferred: TypeScript/JavaScript programming, Web technologies, audio and Faust programming.
      An easy, medium or hard difficulty rating of each project: medium
      PluginGuiMagic architecture
      Mentor: Stéphane Letz and Daniel Walz
      Expected size of project: 175 hours
      More detailed description of the project: PluginGuiMagic is a WYSWYG runtime design system for JUCE plugins. The foleys_plugin_magic module allows to have a generated UI, that can be edited at runtime using advanced layout and styling options. It also adds visualisers to display signals, levels and spectral with no extra coding involved. The project is to develop new C++ architecture files to ease the use of PGM in the faust2juce tool. Another faust_juce_pgm_skeleton project to look at.
      Expected outcomes: The result will be set of C++ architecture files and an improved faust2juce tool.
      Skills required/preferred: C++ programming, knowledge of the JUCE framework, knowledge of the foleys_plugin_magic module, audio and Faust programming.
      An easy, medium or hard difficulty rating of each project: medium
      VST plugin embedding the dynamic compiler [Taken in 2024]
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      More detailed description of the project: A VST plugin using the libfaust + LLVM JIT to do DSP live coding in any VST aware host. FX and monophonic or polyphonic synthesizers can be written. The source code can be edited and recompiled on the fly. The GUI has to be automatically created. The pMix and Amati projects can be used as starting points. An integration with the PluginGuiMagic architecture could possibly be added.
      Expected outcomes: The result will be a VST plugin developed with the JUCE framework .
      Skills required/preferred: C++ programming, audio and Faust programming, knowledge of the JUCE framework.
      An easy, medium or hard difficulty rating of each project: medium
      Integration in Audiokinetic Wwise
      Mentor: Stéphane Letz
      Expected size of project: 350 hours
      More detailed description of the project: Audiokinetic is the leading global provider of the most advanced and scalable cross platform interactive audio solutions. A trusted technology partner to the world’s largest developers, OEMs, and audio production companies, its flagship product Wwise is the gold standard interactive audio engine on the market. Wwise features a complete suite of design and development tools, making it easy to prototype and bring to life your creative vision for audio, no matter the scale of your project. The integration could follow the two steps:
      develop a faust2wwise tool (see faust2xx Tools and Developing a faust2xx Script) to statically compile Faust DSP code in Wwise modules
      a complementatry approach is to directly embed the Faust compiler (using libfaust + LLVM JIT), allowing DSP programs to be edited, dynamically compiled, and run in the platform
      Look at the faust2wwise preliminary work. You'll probably have to develop or adapt C++ architecture files.
      Expected outcomes: The result will be:
      a new faust2wwise tool with the associated C++ architecture files to compile a DSP project in a ready to use Wwise plugin
      a plugin embedding the libfaust + LLVM JIT dynamic compiler technology to allow Faust DSP live-coding
      Skills required/preferred: C++ programming, audio and Faust programming, knowledge of the Audiokinetic Wwise architecture.
      An easy, medium or hard difficulty rating of each project: hard
      Integration in BELA
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      More detailed description of the project: BELA is a maker platform for creating beautiful interaction. Designed for artists, musicians, researchers and makers, Bela brings the power of ultra-low latency interactive audio and sensors to your digital projects. A Faust/BELA integration has already been done in a faust2bela tool and some preliminary work on the dynamic compilation chain have been done.
      Expected outcomes: The result will be:
      an improved faust2bela tool
      a fully integrated Faust/BELA IDE that would allow to design and experiment Faust code in the Web plaform (using the dynamic WebAssembly based compilation chain), then compile it in C++ and deploy it on the BELA board. Monophonic DSP and MIDI controllable polyphonic instruments should be supported.
      a finished dynamic compilation chain integration.
      Integration in openFramework
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      More detailed description of the project: openFrameworks is an open source C++ toolkit designed to assist the creative process by providing a simple and intuitive framework for experimentation. It allows to access a lot of additional extensions and libraries in the form of addons. The project is to explore how Faust can be integated in the framework as an ofxFaust addon, either statically (using the C++ generated code from a DSP program), or possibly embedding the libfaust compiler. Adapted architecture files will have to be developed.
      Expected outcomes: The result will be a new ofxFaust and openFrameworks demo examples explaining how to use it.
      
      ~~~~~~~~~~
      
      Integration in the Heavy Compiler Collection
      Mentor: Alexander Chalikiopoulos
      Expected size of project: 175 hours
      More detailed description of the project: HVCC is a python-based dataflow audio programming language compiler that generates C/C++ code and a variety of specific framework wrappers. It's main focus is in parsing Pure Data DSP patch files, statically interprets them, and converts them to C/C++. The project is to explore how Faust can be integrated into the compiler toolchain. Likely starting from pd-faustgen external and then internally calling faustdoctor to wrap the resulting C into separate header and implementation files. A crude proof of concept integration between faust generated code and a heavy DSP graph was done to explore the feasibility of this integration.
      Expected outcomes: The result will be:
      extending hvcc compiler steps pd2hv, hv2ir and ir2c
      jinja2 templates that create Heavy compatible C header and implementation files, based on Faust code
      successfully create DSP prototypes using PD and Faust that can be compiled to C/C++ projects based on Heavy
      Skills required/preferred: Python, C, Pure Data, audio and Faust programming.
      An easy, medium or hard difficulty rating of each project: medium
      Packaging system for Faust libraries [Taken in 2024]
      Mentors: Yann Orlarey and Stéphane Letz
      Expected size of project: 350 hours
      More detailed description of the project: The idea is to develop a packaging system to facilitate the integration of Faust libraries in a DSP project. The inspiration comes from the Julia language with the JuliaHub project and/or the Rust language with the Cargo package manager.
      Requirements
      load packages containing Faust sources, either in .dsp or in .lib format
      be able to load sets of files (typically a library that is written as several .lib files)
      isolate packages in different environments, to avoid name conflicts
      notion of a centralized directory on GitHub, where contributions can be made in the form of Pull Requests. Publishing tool (with search by content) of this directory, general, like fausthub (inspired for example by Juliahub https://juliahub.com/lp/).
      at each PR, test of the syntax of the code with GitHub actions
      cache management: typically 1) the package is loaded the 1st time and kept in a cache, 2) then the compiler uses the version in the cache. Work on the question of new version management.
      automatic generation of the documentation from the lib files (starting from the existing tools and possibly adapting them), automatic deployment
      preservation semantic: we want to be able to keep a project as a DSP file with all its needed libraries with specific version numbers
      Syntax proposal
      Simple version
      package("foo") ⇒ syntactic sugar for library("https://faustpackages.grame.fr, "path/to/actual/library.lib")
      Version with constraint on version number
      package("foo", "3.4") ⇒ syntactic sugar for library("https://faustpackages.grame.fr, "path/to/actual/3.4/library.lib")
      package("foo").bar
      or else:
      foo = package("foo") and foo.bar in the DSP code
      Tools to describe packages
      look at the package format of Rust or Julia: .toml file, src folders, tests
      look at the TOML format (https://toml.io/en/), used by Rust and Julia
      Expected outcomes:
      a working insfrastructure with a server hosting the published packages
      an extended Faust compiler able to access the server
      Skills required/preferred: C++ programming, server/client technology.
      An easy, medium or hard difficulty rating of each project: hard
      Faust programming by examples
      Mentors: Yann Orlarey and Stéphane Letz
      Expected size of project: 350 hours
      More detailed description of the project: The objective is to develop a new approach to Faust programming, not textual or graphical, but based on DAW-like examples. This programming principle is analogue to the one described in the article Real time Composition in Elody. This approach is based on the idea of manipulating and editing virtual "audio files" which represent the real time audio inputs and outputs.
      To take a simple monophonic example, let's call these two virtual audio files INPUT and OUTPUT. Let's note t:file the fact of placing in the DAW a file fileat time t in seconds and t:file*0.75 the fact of placing in the DAW a file at time t but also controlling its sound level. So the DAW construction {0:INPUT, 1:OUTPUT*0.75} corresponds to a realtime echo whose Faust translation is process = + ~ (@(ma.SR):*(0.75));.
      Expected outcomes: The project consists in exploring this model and see how standard DAW editing actions can be translated in Faust DSP programs. A prototype coded in TypeScript, JavaScript or any other scripting languages will be developed.
      Skills required/preferred: C++ programming, possibly TypeScript + JavaScript or other scripting languages.
      An easy, medium or hard difficulty rating of each project: hard
      Languages built on top of the signal API
      Mentors: Yann Orlarey and Stéphane Letz
      Expected size of project: 350 hours
      More detailed description of the project: The signal API opens an intermediate access inside the Faust compilation chain. Generating complex expressions by directly using it can quickly become really tricky and unpracticable. So a language created on top of the signal API is usually needed. This is exactly what the Block Diagram Algebra is all about, and the entire Faust language itself.
      But some other approaches can possibly be tested. The Elementary audio language for instance is built over a similar signal language and uses JavaScript as the upper layer language to help create complex signal graphs programmatically.
      Expected outcomes: The project consits in exploring various approaches to build a language on top of the signal API. It could be a textual one (like JavaScript, Haskell or scripting languages...) or a purely graphical tool.
      Skills required/preferred: C++ programming, possibly TypeScript + JavaScript, Haskell or other functional languages.
      An easy, medium or hard difficulty rating of each project: hard
      Developing modular synthesis using widget modulation
      Mentors: Yann Orlarey and Stéphane Letz
      Widget modulation acts on the widgets of an existing Faust expression, but without requiring any manual modifications of the expression's code. This operation is done directly by the compiler, according to a list of target widgets and associated modulators. Target widgets are specified by their label, as used in the graphical user interface. Modulators are Faust expressions that describe how to transform the signal produced by widgets.
      The project would be to develop a set of modular synthesizers, typically by choosing and adapting existing functions in the Faust Libraries, each of them with a pretty GUI, to be combined in a patch like model. The widget modulation syntax will be used to prepare the widgets to be modulable. The implementation will be done using web technologies, and in particular FaustWasm, a high-level API that wraps around Faust compiler. Here is a list of possible steps:
      choose and adapt existing functions in the Faust Libraries and add a pretty GUI with User Interface Primitives to create modules including oscillators (which generate sound), filters (which modify sound by frequency), amplifiers (which control the volume), and modulators (like LFOs and envelopes, which affect other parameters over time)
      create sequencing modules, vital for composition in modular synthesis. It allows users to create a series of notes (a sequence) that can be sent to an oscillator to produce rhythmic patterns or melodies
      define a library of modulation circuits, using the lowest/highest primitives of the language, and define adapted signal mappings
      create a global GUI to rack all used modules as in VCV Rack, using Web technologies, and develop the connection logic needed between all considered modules, compiled and connected as separated Faust Web Audio nodes
      Expected size of project: 350 hours
      Expected outcomes: The project aims in developing new libraries for modular synthesis and a prototype Web application.
      Skills required/preferred: Faust programming, Web programming
      An easy, medium or hard difficulty rating of each project: medium
      Past GSoC editions
      2024: FaustNet - DDSP, Faust in Cables.gl, Amati++, a VST/CLAP Plugin embedding the dynamic compiler and Faust Package Manager
      FaustNet - DDSP aimed to continue the work done on adding automatic differentiation in Faust (started in a GSOC 2023 project), to leverage machine learning for audio processing tasks directly within the familiar Faust environment. It was worked on by Advik Raj Basani and contributed as a Pull Request on Thomas Rushton faust-ddsp library.
      Faust in Cables.gl aimed to develop a Cables.gl plugin that compiles Faust DSP code into a WASM AudioWorklet in real-time. It was worked on by Fay Carsons and contributed as a separated Faust Cables plugin project.
      Amati++, a VST/CLAP Plugin embedding the dynamic compiler, inspired by the pMix and Amati projects, this plugin has been built using the JUCE framework for the interface and libfaust with LLVM and interpreter backend API to compile Faust code. It was worked on by Tyler Li and is still a work-in-progress.
      Faust Package Manager aimed to add a packaging system to facilitate the integration of Faust libraries in a DSP project. It was worked on by Shehab Khaled Roshdy and a was contributed as a Pull Request that is still in test in a master-dev-pacman branch.
      2023: Automatic Differentiation in the Faust Compiler and Better Faust on the Web
      Automatic Differentiation in the Faust Compiler aimed at adding Automatic differentiation directly in the compiler, so that gradient calculation can be carried out natively in Faust, with applications in Machine Learning algorithms. The project was worked by Thomas Rushton and completed with this Pull Request, and finally integrated in the Faust master-branch.
      Better Faust on the Web aimed at enhancing Faust’s support for the web platform, and was worked on by Ian Clester. Transitioning the Faust web tools to a rewritten TypeScript version has been completed and deployed in updated versions of the Faust editor and Faust playground and soon in the Faust Web IDE with this Pull Request. A Faust web component embedding the libfaust JS/WebAssembly compiler has been developed and will be used soon in the Faust documentation. The development is fully detailed in this blog post.
      2022: Integration in HISE
      Faust Integration in HISE aimed at integrating support for the Faust audio programming language into HISE, an extensive framework for the creation of sample-based virtual musical instruments. The project has been completed by Roman Sommer with the help of Christoph Hart as mentor, and announced here.
      Faust ideas
      This repository hosts the "TODO/ideas list" for the Faust programming language.
      Conventions
      Items are placed at the bottom of the file and separated by ---.
      Items can have a person associated to them by declaring * Currently addressed by: xxx. If no-one is currently working on the item, replace xxx by nil.
      Items are ordered by priority and are also listed in the List section below.
      Items can be commented by adding subsections, pictures, etc.
      List
      Implement Jonathan Abel's Modal Reverb
      Improved UI Declarations
      Improved Linear Algebra Support
      Finish the DX7 Implementation
      Trigonometric simplifications
      WebAssembly specific optimisations
      Improve faust2audiokit
      Improve faust2vcvrack
      Testing tools on the Web
      Progressive Web applications for iOS and Android
      A tool to generate Faust web components as NPM packages
      PFFT like wrapper for Faust DSP code
      Hot reloadable soundfiles
      WebGPU audio architecture
      Invertible functions
      faust2nih tool
      Implement Jonathan Abel's Modal Reverb
      Currently addressed by: Romain and Yann
      This should be done as part of the Longyou grottoes project. The "final goal" would be to create an interactive website where users can process the sound of their microphone to apply the acoustics of this ancient space. Modal reverb would allow to interpolate between IRs and change some of the parameters of the space in real-time. It'd be nice if this could be reproducible so we need to think about a way to nicely generate these reverbs from an impulse response. This tool could be similar to mesh2faust or could come as part of a toolkit in matlab/octave/pyhton, etc.
      Improved UI Declarations
      Currently addressed by: Romain and Yann
      Essentially allow for specific UI elements to have metadatas associated to them outside of their declaration. As part of that, we want to implement a system to further customize UI elements.
      Potential Implementation
      Several approaches are being considered to further customize UI elements. The first one would consist of being able to declare a "CSS" allowing for the use of CSS code. Another approach (more generic and not limited to the web) would allow for the declaration of UI-specific metadata inspired by CSS.
      declare UI "
        synth{
          background-color: blue;
        }
        synth/freq{
          tooltip: Frequency parameter of the synth;
          width: 70%;
        }
        synth/gain{
          style: knob;
          tooltip: Gain parameter of the synth;
          width: 70%;
        }
      ";
      
      f = hslider("freq",400,50,1000,0.1);
      g = hslider("gain",0.5,0,1,0.01);
      process = hgroup("synth",os.sawtooth(f)*g);
      Of course, it would still be possible to declare metadatas within the UI declaration (this system would be fully backward compatible). Internally, we'd have to parse the metadata and create a corpus of supported CSS metadatas knowing that interfaces would be based on a specific kind of layout (e.g., grid layout). Once again, another option would be to allow to specify "pure CSS" giving access to all the CSS features without having to do some reformatting.
      Improved Linear Algebra Support
      Currently addressed by: nil
      Linear algebra operations are currently poorly supported in Faust. Having a way to conveniently express matrices would improvement. As part of that, linear algebra/matrix operations (e.g., inversion, multiplication, determinant, etc.) primitives could be added to the language.
      Potential Implementation
      Matrices could be expressed using the Faust-multirate vectorize primitives by creating vectors of vectors.
      It would be interesting to try to implement matrix operations from scratch in Faust. Although it might be hard and not so optimized, thus a more pragmatic solution would be to implement them as primitives. That would be a fair amount of work as this would imply that the corresponding code for each language supported by Faust would have to be supported.
      Finish the DX7 Implementation
      Currently addressed by: nil
      Essentially, finish dx7.lib. It might be worth looking at these elements to make this happen:
      https://webaudiomodules.org/demos/wasm/dx7.html
      https://github.com/everythingwillbetakenaway/DX7-Supercollider
      Trigonometric simplifications
      Currently addressed by: nil (suggested by Pierre Lecomte)
      For some applications, trigonometric functions (spherical harmonics) are used, and depending on the algorithm, the output formula could be very complicated. However, in a lot of cases, trigonometric identities could help to drastically simplify the expressions.
      WebAssembly specific optimisations
      Currently addressed by: Stéphane and Yann
      To run as fast as possible and approch native code performances as much as possible, WebAssembly code requires some specific optimisations, like: memory access (index precomputation as much as possible...), delay lines handling, struct/stack variables access...etc. We have started an informal collaboration with Mozilla engineers (Benjamin Bouvier) to work on this subject.
      Improve faust2audiokit
      Currently addressed by: nil
      The faust2audiokit tool transforms a Faust DSP program into a fully working AudioKit node. The result can be a monophonic DSP or a MIDI controllable polyphonic one (when the DSP describes an instrument, following the freq, gain, gate parameter naming convention).
      The project consists in improving and finishing the tool.
      Improve faust2vcvrack
      Currently addressed by: nil
      The faust2vcvrack The faust2vcvrack tool compiles a Faust DSP program in a folder containing the VCV Rack plugin C++ source code and a Makefile to compile it. By default the resulting C++ code is compiled and installed in the VCV Rack application:
      The project consists in improving the tool, particulary the automatically created graphical user interface which is ugly for now.
      Testing tools on the Web
      Currently addressed by: nil
      Faust distribution already contains some testing tools, like faust2plot or faust2octave.etc. It would be great to have them running in a Web page (or some extension of the same idea). For signal generators/processors, several output formats (oscilloscope, spectrogramme...), and for processors several calibrated input signals (dirac impulse, ramp, sinusoide..) would be available.
      Progressive Web applications for iOS and Android
      Faust code can easily be distributed as self-contained Web pages containing the Faust DSP code as a statically compiled Web Audio node. The project is to improve the current model to deploy the pages as Progressive Web applications. The faustwasm package will be improved to allow this new kind of deployment model. The use of movement sensors will be added in the architecture to keep the same capability currently found in the native applications. Deployment on iOS and Android machines will be tested.
      Done, see faustpwa.
      A tool to generate Faust web components as NPM packages
      Faust code can easily be distributed as self-contained Web pages containing the Faust DSP code as a statically compiled Web Audio node. The project is to improve the current model to deploy the pages as ready-to-use NPM packages. The faustwasm package will be improved to allow this new kind of deployment model. A faust2webnpm tool to compile a Faust DSP program will be developed, with polyphonic and polyphonic with global effect support.
      PFFT like wrapper for Faust DSP code
      The Max/MSP pfft~ object is designed to simplify spectral audio processing using the Fast Fourier Transform (FFT). In addition to performing the FFT and the Inverse Fast Fourier Transform (IFFT), pfft~ (with the help of its companion fftin~ and fftout~ objects) manages the necessary signal windowing, overlapping and adding needed to create a real-time Short Term Fourier Transform (STFT) analysis/resynthesis system.
      This model has been tested and implemented by Shihong Ren for Faust and can be tested on a customized version of the Faust IDE. The FFT input part process the temporal signal, delivers a tripplet of signals (real, imaginary, and current bin index), uses regular Faust DSP code working on this tripplet of signals, and finally do the iFFT process to produce temporal signals.
      Here is a noise reduction algorithm using this model written by Shihong.
      It is actually a simplified version of the commonly used spectral denoise (10.1109/TASSP.1979.1163209). When the user hits the button, the algorithm learns the current spectrum as a reference of the background noise. Then, subtract from every input spectrum, the power of this background noise spectrum (for each FFT bin).
      The Faust FFT DSP has 3 inputs: real part/imaginary part/current bin (as in pfft~ in Max). Each input gets sequentially a complex number as information about each FFT bin. The first part of the code gets the current FFT setup and defines necessary functions for calculating FFT info:
      import("stdfaust.lib");
      
      fftSize = hslider("fftSize", 1024, 2, 16384, 1);       // global variable set by the processor itself
      fftHopSize = hslider("fftHopSize", 1024, 2, 16384, 1); // global variable set by the processor itself
      bufferSize = fftSize / 2 + 1; // Bins from 0Hz to Nyquist freq
      freqPerBin = ma.SR / fftSize;
      binToFreq = *(freqPerBin);
      freqToBin = /(freqPerBin);
      
      cartopol(x, y) = x * x + y * y : sqrt, atan2(y, x);  // cartesian to polar
      poltocar(r, theta) = r * cos(theta), r * sin(theta); // polar to cartesian
      then UI components:
      freezeBtn = checkbox("Capture");
      reduceSld = hslider("Reduce", 0, 0, 2, 0.01);
      Here is a function to freeze the last spectrum, when the checkbox is on, instead of bypassing the input, it puts the last received full spectrum buffer into a feedback loop:
      freeze(rIn, iIn, bin) = out with { // 3 inputs for each audio channel: real, imaginary, current bin
          freezeSignal(sig, frz) = orig + freezed with {
              orig = sig * (1 - frz);
              freezed = orig : @(bufferSize) : + ~ (*(frz) : @(bufferSize - 1)) * frz;
          };
          out = freezeSignal(rIn, freezeBtn), freezeSignal(iIn, freezeBtn);
      };
      Finally the main processor, getting the current magnitude value and subtract the freezed spectrum's corresponding magnitude, then output the resulting spectrum for IFFT.
      fftproc(rIn, iIn, bin) = out, out with { // 3 inputs for each audio channel: real, imaginary, current bin
          pol = cartopol(rIn, iIn);
          mag = pol : _, !;
          phase = pol : !, _;
          pol_freezed = freeze(rIn, iIn, bin) : cartopol;
          mag_freezed = pol_freezed : _, !;
          phase_freezed = pol_freezed : !, _;
      
          out = poltocar(mag * (1 - freezeBtn) + (mag - mag_freezed * reduceSld) * freezeBtn : max(0), phase);
      };
      process = fftproc;
      The goal of the project is to use the same model for Faust code by writing a C++ wrapper that would add FFT and iFFT processing around the Faust DSP code. This can possibly be done by extending the ffunction primitive to a mode general version that would deliver a list of output values (instead of a single one), or if not possible, develop a dsp wrapper architecture file that would add the FFT/iFFT process around the Faust DSP code.
      Hot reloadable soundfiles
      The soundfile primitive currently provides access to a predefined list of external sound resources. These soundfiles are loaded once during the application's initialization and cannot be modified dynamically during runtime.
      The primary objective of the project is to enable hot reloadability for soundfiles, allowing users to change them on the fly while the DSP code is actively running. To achieve this, two key aspects need enhancement:
      code generation improvement: the code generation process should be refined to facilitate an atomic switch to the new soundfile while the DSP code is in execution. This ensures a seamless transition between different sound resources without interrupting the ongoing processing.
      soundfile loader architecture enhancement: the architecture of the soundfile loader, detailed in SoundUI.h, needs to be upgraded. This upgrade should introduce the capability for users to interactively change the loaded soundfile, potentially through a graphical user interface (GUI) element.
      For instance, integrating a GUI item within the application can empower users to select and switch soundfiles effortlessly during runtime.
      Additionally, a possible solution involves implementing a purely memory-based loader. This loader would emulate soundfiles as audio buffers in memory, allowing for dynamic changes to the loaded soundfiles without requiring a complete reload of resources. This approach enhances flexibility and responsiveness by enabling real-time alterations to the sound resource being processed.
      By addressing these aspects, the project aims to elevate the functionality of the soundfile primitive, providing users with the ability to seamlessly modify soundfiles while the DSP application is actively running.
      WebGPU audio architecture
      The WebGPU audio architecture represents an innovative model to use the WebGL language to compute and render audio on the Web platform: audio Synthesis uses rough streaming architecture to get chunks out of WebGPU and send control buffers to control a WebGPU compute shader.
      The primary objective of the project is to develop a WebGSL backend for Faust, and an customized architecture file to render the computed audio using the Web Audio API, as demonstrated in the current demonstration. To validate the efficacy of this model, benchmarks are planned. These will assess the performance of the WebGPU audio architecture, comparing it against the existing standards of AudioWorklet and WebAssembly solutions.
      Invertible functions
      Currently addressed by: nil
      There could be a new primitive to automatically compute the inverse of a function. If the function can't be inverted at compile-time, then an error should be raised. Having access to the inverse would be useful when a user writes a custom scale function and wants to know its inverse. For example, the user might have an hslider whose visible range is [0-1], but the effective value is scaled:
      scale = pow(_,5)*32*1000; // take [0-1] (unitless) and remap into [0-32000] milliseconds
      scaleInverse = inverse(scale);
      h = hslider("attack", scaleInverse(50), 0, 1, .01);
      process = h : scale;
      In the code above, we achieve three things:
      The attack parameter is "normalized" between 0 and 1, which is useful for modular synthesis.
      We have a custom scale function that remaps from [0-1] to a meaningful milliseconds unit.
      We set 50 milliseconds as the default attack.
      Note that scaleInverse will effectively be scaleInverse = _/(32*1000) : pow(_,1./5); However, some functions are not invertible, or require assumptions. For example, the inverse of pow(_,2) is plus or minus sqrt(_).
      Other use cases could involve automatically inverting custom scales that use ba.midikey2hz.
      In a more advanced example, it might be possible to invert a function that takes multiple arguments, while only inverting over the last argument.
      Example:
      func(a, b, c, x) = a+2*b+3*c+x;
      funcInverse = inverse(func);
      // funcInverse(a, b, c, y) now solves for x in y=func(a, b, c, x)
      process = _ : funcInverse(1, 1, 1) : _;
      This would be useful for numerical integration methods (see en.adsr_bias).
      faust2nihplug tool
      NIH-plug is an API-agnostic audio plugin framework written in Rust. The primary objective of the project is to develop a faust2nihplug tool to convert a Faust DSP program in a ready-to-compile NIH-plug project. Those lowpass-lr4-faust-nih-plug and lamb-rs projects can be used as starting points. Monophonic DSP and MIDI controllable polyphonic instruments should be supported.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/grame/
    idea_list_url: https://github.com/grame-cncm/faustideas

  - organization_id: 53
    organization_name: GeomScale
    no_of_ideas:
    ideas_content: |
      ⚠️ NOTE
      This year contributors will have to choose between a ~90 hours small-sized project, ~175 hours medium-sized project or ~350 hours large project. For more information please read the official gsoc website as well as GeomScale's introductory wiki for GSoC 2025.
      GeomScale hosts a few projects in different github repositories. The most mature one is volesti written in C++. Then there are two repositories that act as interfaces of volesti (i) Rvolesti in R that also contains utilities for financial applications and (ii) and dingo written in Python (uses C++ functions of volesti via Cython) and contains utilities for biological applications. Finally, there is PorQua a Python package for index replication in finance.
      Proposed projects are related to those repositories. There are two types of coding projects: research and development (marked as R&D in the table below) and pure development (marked as Dev in the table below). R&D projects needs a deep understanding of the mathematical background in addition to the implementation details that are needed by the Dev projects. Typically the former is more demanding than the later but this also depends on the background of the contributor.
      Mentors, please edit this wiki page, and add your ideas to the table below.
      Contributors, please look for a project that interests you in the table below. Before emailing project mentors, please do at least one project test and post a link to your solution on the proposal's wiki page.
      Proposal Type Languages Size Hours
      Randomized SDP solver R&D C++/R Large 350
      Non-convex sampling in dingo R&D C++ /Python Large 350
      Exclude Lpsolve from R and C++ interfaces of volesti Dev C++/R Medium 175
      Counting linear extensions with volume computation and applications in AI R&D C++ Large 350
      Expose sampling and volume on spectrahedra to R interface of volesti Dev R/Rcpp Medium 175
      Expose autodiff to R interface of volesti Dev R/Rcpp Medium 175
      Enhancing Rvolesti: Integration of Advanced Rounding Routines Dev R/Rcpp Small 90
      Supporting Sparse Matrix Representation for H‐Polytopes in Rvolesti Dev R/Rcpp Small 90
      Developing a Comprehensive Unit Test Framework for PorQua Dev Python Small 90
      General Sampling and Volume Computation in Dingo Dev Python Medium 175
      Interactive Web API for PorQua Dev Python Medium 175
      PorQua – A Framework for Constructing and Backtesting Investment Strategies Dev Python Large 350
      Shake and Bake ‐ Sampling from the boundary of convex polytopes R&D C++ Large 350
      All contributor applications will be discussed by the GeomScale mentor community, and proposals will be ranked considering factors such as quality, contributor's ability to successfully finish the project, and impact for the GeomScale project. A finite number of slots will be granted to GeomScale by Google, thus, only the best proposals will get chosen. This implies that it is possible that some ideas will not become GSoC projects even if they are supported by a good contributor application.
      Contributors, if you are interested in a coding project related to GeomScale that is not listed above, please try to find mentors by posting a description of your project idea on the gitter. If you find mentors, feel free to add your project idea to this wiki and write an application.
      Information Candidates Should Supply
      The application process has several steps. Before contacting anybody verifies that you are eligible. The next step is to contact the mentor of the project you are interested in. You have to convince them that you are the right person to get the job done. The next step is to work out more details and to contact the mentors or the GeomScale org by providing the following information by email or by gitter.
      Project:
      Select a project in the list and provide your personal and detailed description. If you wish to work on another idea of your own, we are pretty open as long as this serves the goal of consolidating GeomScale as a whole.
      Provide a proposal of a technical solution with your envisioned methodology. The more detailed the better.
      Explain how the solution will be available to the user, in which form. Do not forget the documentation, unitary tests, and cross-platform aspects.
      Provide a realistic schedule with objectives (one every two weeks for example) and deadlines. Focus on mid-term objectives as well as on the final evaluation.
      Personal data:
      First name, last name, affiliation, and geographical location.
      A brief list of the main studies and programming courses attended, with ranking.
      List of the most important software projects contributed and success.
      Which are your best skills in terms of programming and scientific computing?
      In general what is your taste in terms of programming? language, methodology, teamwork, etc.
      Is there anything that prevents you from working full time on the project during the program period?
      How do you see your involvement after the program ends? Do you see yourself pushing the project further, or do you see yourself contributing to other GeomScale projects?
      Are you more interested in the theory/scientific aspect of GeomScale, or do you feel more like a hacker?
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/geomscale/
    idea_list_url: https://github.com/GeomScale/gsoc25/wiki/table-of-proposed-coding-projects

  - organization_id: 54
    organization_name: Git
    no_of_ideas:
    ideas_content: |
      Home
      About Git Rev News
      Git Rev News Sources
      Git Rev News
      Git Rev News Archive
      SoC 2025 Applicant Microprojects
      SoC 2025 Ideas
      SoC 2022 Organization Application
      Mentoring Program Guide
      Historical Summer of Code and Outreachy Materials
      Hacking Git
      General Microproject Information
      General Application Information
      GSoC participants
      This is the idea page for Summer of Code 2025 for Git.
      Please completely read the general application information page before reading the idea list below.
      Summer of code main project ideas
      Students: Please consider these ideas as starting points for generating proposals. We are also more than happy to receive proposals for other ideas related to Git. Make sure you have read the “Note about refactoring projects versus projects that implement new features” in the general application information page though.
      Note about limit of project selection
      Kindly note that considering the bandwidth of available mentors, the Git project would only mentor up to 3 contributors this year.
      This is not a hard and fast rule. It may change if more community members are willing to mentor in the coming days. For instance, this may happen when a new project is proposed and some community member volunteers to mentor the same.
      Consolidate ref-related functionality into git-refs
      This project aims to streamline Git’s reference management into the existing git-refs command by consolidating functionality currently spread across multiple commands. The new command will provide subcommands for listing, getting, checking existence, writing, and optimizing references, replacing the functionality currently handled by git-update-ref(1), git-for-each-ref(1), git-show-ref(1), and git-pack-refs(1).
      The consolidation work should ensure backward compatibility with existing commands. The work involves C programming in Git’s codebase, creating comprehensive tests, and updating documentation.
      Required skills include C programming, familiarity with Git’s codebase, and experience with command-line tool development. The project is expected to take 12 weeks, with existing commands being maintained for backward compatibility while development focuses on the new unified interface.
      Getting started: Build Git from source, study the existing ref-related commands, and submit a micro-patch to demonstrate familiarity with the codebase.
      Expected Project Size: 175 hours or 350 hours
      Difficulty: Medium
      Languages: C, shell(bash)
      Possible mentors:
      Patrick Steinhardt < ps@pks.im >
      Jialuo She < shejialuo@gmail.com >
      Christian Couder < christian.couder@gmail.com >
      Ghanshyam Thakkar < shyamthakkar001@gmail.com >
      Refactoring in order to reduce Git’s global state
      This project focuses on modernizing Git’s environment handling by refactoring the environment.c code to reduce global state. The goal is to move environment variables and configuration from global scope into more appropriate local contexts, primarily into the struct repository / struct repository_settings structure. This architectural improvement will make the codebase more maintainable and potentially enable better multi-repository handling in the future. The project involves careful refactoring of Git’s core environment handling code, requiring strong C programming skills and attention to detail.
      The student will identify global variables that can be moved to local scope, implement the necessary structural changes, and ensure all affected code paths continue to work correctly. This includes updating tests, fixing any regressions, and documenting the architectural changes.
      Expected Project Size: 90 or 175 hours or 350 hours
      Difficulty: Medium
      Languages: C, shell(bash)
      Possible mentors:
      Patrick Steinhardt < ps@pks.im >
      Karthik Nayak < karthik.188@gmail.com >
      Jialuo She < shejialuo@gmail.com >
      Christian Couder < christian.couder@gmail.com >
      Ghanshyam Thakkar < shyamthakkar001@gmail.com >
      Machine-Readable Repository Information Query Tool
      This project aims to create a new Git command dedicated to querying repository metadata and configuration in a structured, machine-readable format. Currently, much of this functionality exists within git-rev-parse(1), which has evolved beyond its original purpose. The new command will provide a cleaner, more focused interface for programmatically accessing repository information using JSON output.
      The student will design and implement this new command, focusing on identifying what repository information should be exposed, designing a consistent JSON schema, and implementing the necessary interfaces to Git’s internal APIs. Key challenges include determining which subset of information from git-rev-parse to expose via this new command, ensuring backward compatibility, and creating a clean, well-documented command interface that’s useful for scripts and tools.
      While this is an exploratory project that hasn’t been extensively discussed in the Git community, it addresses a real need for better programmatic access to repository information.
      Expected Project Size: 175 hours or 350 hours
      Difficulty: Medium
      Languages: C, shell(bash)
      Possible mentors:
      Patrick Steinhardt < ps@pks.im >
      Karthik Nayak < karthik.188@gmail.com >
      Ghanshyam Thakkar < shyamthakkar001@gmail.com >
      Implement support for reftables in “dumb” HTTP transport
      Fetching Git repositories uses one of two major protocols:
      The “dumb” protocol works without requiring any kind of interactive negotiation like a CGI module. It can thus be served by a static web server.
      The “smart” protocol works by having the client and server exchange multiple messages with each other. It is more efficient, but requires support for Git in the server.
      While almost all servers nowadays use the “smart” protocol, there are still some that use the “dumb” protocol.
      The “dumb” protocol cannot serve repositories which use the “reftable” backend though. While there exists a “info/refs” file that is supposed to be backend-agnostic, this file does not contain information about the default branch. Instead, clients are expected to download the “HEAD” file and derive the default branch like that. This file is a mere stub in the “reftable” backend though, which breaks this protocol.
      The goal of this project is to implement “reftable” support for “dumb” fetches.
      See:
      https://git-scm.com/docs/reftable
      Note: While both ideas are valuable, we prioritize the ‘Consolidate ref-related functionality into git-refs’ proposal over support for reftables in “dumb” HTTP transport. If we receive applications for both projects, preference will be given to applications focusing on the git-refs consolidation work.
      Expected Project Size: 175 hours or 350 hours
      Difficulty: Medium
      Languages: C, shell(bash)
      Possible mentors:
      Patrick Steinhardt < ps@pks.im >
      Karthik Nayak < karthik.188@gmail.com >
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/git/
    idea_list_url: https://git.github.io/SoC-2025-Ideas/

  - organization_id: 55
    organization_name: GitLab
    no_of_ideas:
    ideas_content: |
      Open
      13
      Closed
      0
      All
      13
      New issue
      Actions
      Toggle history
      Created date
      Issue
      [Workspaces] Allow users to use Workspaces without having to build a custom image 1 of 6 checklist items completed
      #14 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      1
      updated 3 days ago
      Issue
      [Workspaces] Inject JetBrains Editors into a workspace 1 of 6 checklist items completed
      #13 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      3
      updated 5 days ago
      Issue
      [Web IDE] Add additional source control operations to the Web IDE 0 of 6 checklist items completed
      #12 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      1
      updated 1 week ago
      Issue
      [Vulnerability Management] Expand Vulnerability GraphQL Offering 1 of 6 checklist items completed
      #11 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      2
      updated 4 days ago
      Issue
      [Release Orchestration] Resource Groups 1 of 6 checklist items completed
      #10 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      2
      updated 1 week ago
      Issue
      [Portfolio Management] Epics can have Assignees 1 of 6 checklist items completed
      #9 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 2 days ago
      Issue
      [Package Registry] Simplify the packages list by consolidating versions of the package into the detail page 1 of 6 checklist items completed
      #8 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 1 week ago
      Issue
      [Navigation] Personalized Home Page 1 of 6 checklist items completed
      #7 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 23 hours ago
      Issue
      [Issue Tracking] Team Velocity and volatility 1 of 6 checklist items completed
      #6 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 1 week ago
      Issue
      [Infrastructure as Code] Protected Terraform States 1 of 6 checklist items completed
      #5 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 3 days ago
      Issue
      [Design System] Use improved hide heuristics when using GlDisclosureDropdown and GlCollapsibleListbox 1 of 6 checklist items completed
      #3 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 2 days ago
      Issue
      [Design System] Remove any CSS classes that are unused 1 of 6 checklist items completed
      #2 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 2 days ago
      Issue
      [Deployment Management] Add Notification for expiring Deploy Tokens: E-mail and Webhook 1 of 6 checklist items completed
      #1 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      1
      updated 2 days ago
      Show 20 items
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gitlab/
    idea_list_url: https://gitlab.com/gitlab-org/developer-relations/contributor-success/google-summer-of-code-2025/-/issues


  - organization_id: 56
    organization_name: Google DeepMind
    no_of_ideas:
    ideas_content: |
      Instantly share code, notes, and snippets.
      dynamicwebpaige/gdm-gsoc-projects-2025.md Secret
      Last active 2 hours agoMarch 14, 2025 11:58
      Show Gist options
      Star
      134
      ()
      You must be signed in to star a gist
      Fork
      38
      ()
      You must be signed in to fork a gist
      Save dynamicwebpaige/92f7739ad69d2863ac7e2032fe52fbad to your computer and use it in GitHub Desktop.
      Code
      Revisions
      15
      Stars
      134
      Forks
      38
      Embed
      Clone this repository at &lt;script src=&quot;https://gist.github.com/dynamicwebpaige/92f7739ad69d2863ac7e2032fe52fbad.js&quot;&gt;&lt;/script&gt;
      Save dynamicwebpaige/92f7739ad69d2863ac7e2032fe52fbad to your computer and use it in GitHub Desktop.
      Download ZIP
      Google Summer of Code: 2025 Google DeepMind Project List
      Raw
      gdm-gsoc-projects-2025.md
      Shovel-Ready AI Developer Projects
      ☀️ Google Summer of Code
      Author: Google DeepMind GSoC Team
      Created: Aug 30, 2024
      Self Link: goo.gle/deepmind-gsoc-projects-2025
      TL;DR: This document outlines concise, open-source engineering projects to enhance the functionality and developer experience of AI Developer products (Gemini APIs, AI Studio, Colab, Gemma). Projects focus on addressing user pain points, unlocking new capabilities, and increasing developer adoption for Google DeepMind's tools. These are ideal for Google Summer of Code (GSoC) contributors! If you don't see a project on the list that you feel should be included, feel free to propose a new idea.
      Project List
      1. Develop a Gemini Workspace in Postman 📭
      Objective: Create a Postman Workspace for interacting with Google's Gemini APIs, providing a central hub for exploration, integration, and troubleshooting. This should streamline the process for developers to get started with Gemini and reduce the initial learning curve.
      Key Features:
      Pre-built Collections: Example API requests for various Gemini features (text generation, chat, image generation, code generation). These collections should cover all major API endpoints and include variations for different parameters (e.g., temperature, top_p, top_k). Each request should be well-documented with comments explaining its purpose and expected behavior. 🚀
      Environments: Pre-configured environments with API keys, authentication tokens, and project IDs. Include separate environments for testing and production, with clear instructions on how to obtain and configure the necessary credentials. ⚙️
      Documentation and Tutorials: Integrated documentation and guides for API endpoints, parameters, and use cases. This should be linked directly within the Postman Workspace, potentially using Postman's built-in documentation features. Tutorials should cover common tasks and scenarios, such as setting up a basic chatbot or generating images from text prompts. 📖
      Testing and Mocking: Example test scripts and mock servers for validating API responses and local development. Test scripts should cover success and error cases, checking for expected response formats and values. Mock servers (using Postman's mocking capabilities) allow developers to test their code without making actual API calls, saving on costs and avoiding rate limits. 🧪
      Note: Long-term maintenance via a GitHub Action is desirable. This action would automatically update the Postman Workspace with the latest Gemini API changes and documentation, ensuring it remains accurate and up-to-date. 🤖
      Complexity: Medium. Requires familiarity with Postman, REST APIs, and potentially GitHub Actions for automation. The project involves organizing existing information and creating helpful examples, rather than developing complex new features.
      Expected Size: 175-350 hours.
      Skills: REST API interaction, Postman, JSON, (optional) JavaScript for GitHub Actions.
      2. Improve Evals Documentation for the Gemini APIs 📝
      Objective: Expand and improve promptfoo, wandb, and other evals platforms' documentation for Gemini APIs, achieving parity with other open-source model providers' documentation. This will make it easier for researchers and developers to evaluate the performance of Gemini models and compare them to alternatives.
      Key Improvements:
      Model Format Documentation: Detailed explanations for each supported Gemini model (e.g., google:gemini-2.0-flash, google:gemini-2.0-flash-lite, etc.). This should include information on model capabilities, limitations, and intended use cases. Specify input/output formats for each model, including any special tokens or formatting requirements. 🤖
      Configuration Options: Documentation for all configuration options (e.g., safetySettings, stopSequences, temperature). Explain the purpose of each parameter and provide guidance on how to choose appropriate values. Include examples of how different parameter settings affect the model's output. ⚙️
      Environment Variables: Guidance on using environment variables (e.g., GOOGLE_API_KEY). Clearly explain how to set these variables in different environments (e.g., local development, cloud deployment) and emphasize the importance of keeping API keys secure. 🔑
      Advanced Features: Document advanced features like image and video handling, tools use/function calling, and error handling/rate limiting. Provide code examples and best practices for using these features effectively. Explain how to handle different error codes and how to implement retry mechanisms to mitigate rate limiting. ✨
      Code Examples: Comprehensive code examples for various use cases. These should be clear, concise, and well-documented. Include examples for different programming languages (e.g., Python, JavaScript) and different evaluation frameworks. Show how to integrate Gemini models into existing evaluation pipelines. 💻
      Complexity: Medium. This project primarily involves writing documentation and creating code examples. It requires a good understanding of the Gemini APIs and evaluation frameworks.
      Expected Size: 175-350 hours.
      Skills: Technical writing, Python, JavaScript, understanding of LLM evaluation methodologies.
      3. Enhance Gemini API Integrations in OSS Agents Tools 🤖🛠️
      Objective: Expand and improve Gemini API integration in agent/workflow tools (e.g., Composio, CrewAI, LangChain, LlamaIndex, etc.) and improve related documentation. Include code examples, make improvements to those libraries, etc. This will enable developers to seamlessly build AI agents and workflows that leverage the capabilities of Gemini models.
      Key Tasks:
      Identify Gaps: Analyze the existing integrations in each target tool and identify areas where Gemini support is lacking or could be improved.
      Implement Missing Features: Add support for missing Gemini features, such as multimodal inputs, function calling, and specific model configurations.
      Improve Existing Features: Optimize existing integrations for performance and reliability. Address any known bugs or limitations.
      Documentation Updates: Update the documentation for each tool to clearly explain how to use Gemini models. Include code examples and best practices.
      Community Engagement: Interact with the maintainers and users of the target tools to gather feedback and ensure the integrations meet their needs.
      Code Examples: Create multiple, distinct use-case examples of agent/workflow tools, making use of Gemini.
      Complexity: Medium to High. Requires familiarity with the Gemini APIs and the target agent/workflow tools. The complexity will depend on the specific gaps and improvements identified.
      Expected Size: 175-350 hours.
      Skills: Python, understanding of AI agents and workflows, experience with libraries like LangChain, LlamaIndex, etc.
      4. Batch Prediction with Long Context and Context Caching Code Sample 🚀🧠
      Objective: Develop a code sample demonstrating batch prediction with Gemini APIs, leveraging long context and context caching for efficiently answering questions about a single video. This addresses a common use case of extracting information from large content sources.
      Scenario: Extracting information from a video lecture/documentary by asking multiple, potentially interconnected, questions.
      Code Sample Features:
      Batch Prediction: Design and optimization for submitting a batch of questions. This should minimize API calls and improve efficiency. Consider using techniques like dividing the questions into smaller batches to avoid exceeding API limits. 📦
      Long Context Handling: Demonstrate use of Gemini's long context capabilities. Show how to provide the entire video transcript (or relevant segments) as context. Consider strategies for handling transcripts that exceed the maximum context length. 📏
      Context Caching: Implement context caching to store and reuse previous interactions. This can significantly reduce the amount of data sent to the API and improve response times, especially for interconnected questions. Use a suitable caching mechanism (e.g., in-memory cache, persistent storage). 💾
      Interconnected Questions: Handle questions that build upon previous answers. The code should maintain the conversation history and use it to provide more accurate and relevant responses. 🔗
      Output Formatting: Clear and user-friendly output. Present the answers in a structured format, possibly with links to the relevant timestamps in the video. ✨
      Code Documentation: Detailed comments, setup instructions, and usage guidelines. Explain the different components of the code and how they work together. Include instructions on how to obtain and configure an API key. Provide example questions and expected outputs. 📖
      Error Handling: Implement robust error handling to gracefully handle API errors, network issues, and invalid inputs.
      Complexity: Medium. Requires understanding of API interaction, data structures, and potentially asynchronous programming for batch processing.
      Expected Size: 175 hours.
      Skills: Python, API interaction, asynchronous programming, data structures.
      5. Enhance Gemini Support in Open-Source Extensions (Continue.dev/Aider-like) 💻✨
      Objective: Improve Gemini API integration within open-source coding extensions, similar to Continue.dev or Aider, addressing bugs, adding features (long context, context caching), and enhancing the user experience. This aims to provide developers with a seamless and powerful coding experience powered by Gemini.
      Key Focus Areas:
      API Key Authorization: Bug fixes, secure key management, and error handling. Ensure that API keys are stored securely and that the extension handles authentication failures gracefully. Provide clear error messages to the user. 🔑
      Long Context Support: Context window expansion and segmentation. Allow the extension to handle large codebases by dividing them into manageable chunks and sending them to the Gemini API. Implement strategies for maintaining context across multiple chunks. ↔️
      Context Caching: Caching mechanism and retrieval. Cache previous interactions with the Gemini API to improve performance and reduce costs. Implement a strategy for invalidating the cache when the code changes. 💾
      User Interface Enhancements: Model selection, parameter customization, and output formatting. Allow users to easily switch between different Gemini models and adjust parameters like temperature and top_p. Provide clear and concise output that is integrated into the coding environment. 🖥️
      Documentation & Examples: Gemini integration guide and code examples. Provide clear instructions on how to configure and use the Gemini integration. Include examples of common tasks, such as code completion, refactoring, and bug detection. 📖
      Code Summarization/Explanation: Add features to summarize or explain blocks of code using Gemini.
      Complexity: Medium to High. Requires understanding of IDE extensions, API integration, and potentially UI development.
      Expected Size: 175-350 hours.
      Skills: TypeScript/JavaScript, IDE extension development, API integration, UI/UX design.
      6. Open-source Gemini Example Apps
      Objective: Upgrade existing tutorials and content to support the new unified Gemini SDKs for JavaScript/TypeScript and Python. This could include migrating examples in the Gemini Cookbook from Python to JS/TS, building new end-to-end tutorials and examples, or upgrading examples for other open-source libraries that use dated versions of the Gemini APIs. This project increases adoption by providing up-to-date and diverse learning resources.
      Specific Tasks:
      Cookbook Migration: Migrate existing Python examples in the Gemini Cookbook to JavaScript/TypeScript. Ensure the code is idiomatic and well-documented.
      New Tutorials: Develop new end-to-end tutorials demonstrating various Gemini use cases, such as building a chatbot, creating a text summarization tool, or generating images from text prompts.
      Library Updates: Identify open-source libraries that use outdated versions of the Gemini APIs and update their examples to use the latest SDKs.
      Documentation: Ensure all examples are well-documented, with clear explanations of the code and the underlying Gemini concepts.
      Variety of Use Cases: Cover a wide range of Gemini capabilities, including text generation, code generation, image generation, and multimodal interactions.
      Complexity: Medium. Requires familiarity with Python and JavaScript/TypeScript, and the Gemini SDKs.
      Expected Size: 175-350 hours.
      Skills: Python, JavaScript/TypeScript, Gemini SDKs, technical writing.
      7. Evaluate Gemini on an Open-Source Benchmark
      Objective: Create a real-world multimodal benchmark or eval, and evaluate the Gemini models on it. If you don't want to create a benchmark yourself, you could also propose adding Gemini 2.0 to an existing external open-source benchmark. This contributes to the broader understanding of Gemini's capabilities and helps identify areas for improvement.
      Options:
      Create a New Benchmark: Design a new benchmark that focuses on a specific real-world task or scenario, incorporating multiple modalities (text, image, video, audio). This could involve:
      Defining a task and evaluation metrics.
      Collecting or generating a dataset.
      Developing evaluation scripts.
      Documenting the benchmark and making it publicly available.
      Extend an Existing Benchmark: Identify an existing open-source benchmark (e.g., on platforms like Hugging Face) and add support for Gemini 2.0. This involves:
      Understanding the benchmark's structure and evaluation methodology.
      Implementing the necessary code to run Gemini 2.0 on the benchmark.
      Reporting the results and comparing them to other models.
      Complexity: High. Requires strong understanding of evaluation methodologies, benchmarking, and potentially data collection/generation.
      Expected Size: 350 hours.
      Skills: Python, data analysis, machine learning evaluation, (optional) data collection/annotation.
      8. Self-Contained OSS-Fuzz Module for Researchers 🔬📦
      Objective: Develop a standalone Python module to provide researchers with APIs to query OSS-Fuzz project details, access historical fuzzing results, and experiment with custom fuzz targets.
      Expected Outcomes (Functionalities):
      Project Information Retrieval ℹ️:
      API to list all projects currently fuzzed by OSS-Fuzz.
      API to retrieve details for a specific project (e.g., language, build system, fuzzer engines used).
      Ability to filter projects based on criteria (e.g., language, library).
      Historical Fuzzing Results 📜:
      API to access historical coverage reports for a specific project and fuzzer.
      API to retrieve crash reports and statistics.
      Ability to specify a date range for the results.
      Data should be returned in a structured format (e.g., JSON).
      Custom Fuzzing Execution ⚙️:
      API to define and submit custom fuzz targets for a specific project.
      Ability to specify fuzzer engine, configuration options, and resources (e.g., CPU, memory).
      API to monitor the status of custom fuzzing runs.
      API to retrieve results from custom fuzzing runs (coverage, crashes).
      Modular Design 🧱:
      The module should be well-structured and easy to extend.
      It should be installable via pip.
      It should have clear documentation and usage examples.
      Required Skills: Python, Bash, understanding of fuzzing, familiarity with GCP.
      Mentor: Dongge Liu
      Expected Size: 350 hours
      Complexity: High. Requires significant programming experience and a deep understanding of fuzzing and the OSS-Fuzz infrastructure.
      9. Streamlined Experiment Execution and Improved Report UI (OSS-Fuzz-Gen) 🧪📈
      Objective: Enhance the experiment execution process and improve report readability in OSS-Fuzz-Gen.
      Expected Outcomes (Enhancements):
      Search Functionality 🔍: Implement a search feature to allow users to easily find specific experiments, projects, or fuzzers within the reports. This could include searching by name, date, or configuration parameters.
      Aggregated Metrics 📊: Provide aggregated metrics across multiple experiments, such as average coverage, number of crashes, and execution time. This will allow users to quickly compare the performance of different fuzzing strategies.
      Improved Navigation 🧭: Enhance the navigation within the reports to make it easier to find and access specific sections and data. This could include adding a table of contents, breadcrumbs, or interactive filters.
      Experiment Configuration ⚙️: Provide a clear and user-friendly interface for configuring experiments. This should include options for selecting the project, fuzzer, configuration parameters, and resources.
      Improved Readability & UI ✨: Improve the overall readability and visual appeal of the reports. This could include using charts and graphs to visualize data, improving the layout and formatting, and using a consistent color scheme.
      General UI/Feature Improvements 👍: Address any other UI or feature requests from users to improve the overall usability of OSS-Fuzz-Gen. This could include adding features like exporting reports in different formats, comparing results across different time periods, or customizing the display of data.
      Required Skills: Python, Bash, Web Development, understanding of fuzzing, familiarity with GCP.
      Mentor: Dongge Liu
      Expected Size: 350 hours
      Difficulty: Medium
      Complexity: Medium. Requires a mix of programming (Python, Bash) and web development skills. The focus is on improving usability and data presentation.
      10. Integrating Research Innovations into OSS-Fuzz-Gen 💡🔬
      Objective: Explore advancements from related research works and integrate them into OSS-Fuzz-Gen.
      Expected Outcomes:
      Identify at least 5 relevant research projects. 🤔: Research recent advancements in fuzzing, particularly those related to LLMs or improved fuzzing techniques. Select projects with potential for integration into OSS-Fuzz-Gen.
      Successfully integrate at least one research-driven technique. ✅: Choose one or more of the identified techniques and implement them within OSS-Fuzz-Gen. This will require adapting the research code and integrating it into the existing codebase.
      Demonstrate measurable improvements. 📈: Evaluate the impact of the integrated technique on fuzzing performance. This could involve measuring improvements in coverage, crash detection rate, or other relevant metrics. Provide clear evidence of the benefits of the integration.
      Required Skills: Python, Bash, C/C++, research experience in fuzzing, experience with LLM applications.
      Mentor: Dongge Liu
      Expected Size: 350 Hours
      Difficulty: Hard
      Complexity: High. Requires strong research skills, programming expertise, and a deep understanding of fuzzing.
      11. Gemma Model Projects 💎
      Objective: Contribute to the Gemma ecosystem by developing tools, tutorials, and integrations. Gemma is Google's family of open models.
      Project Ideas:
      Gemma Model Fine-tuning UI: Develop a user-friendly web interface (using Streamlit, Gradio, or similar) that allows users to fine-tune Gemma models on their own datasets. This should include:
      Dataset Uploading: Support various data formats (CSV, JSONL, text files) and handle data validation and preprocessing. Consider providing options for data augmentation.
      Hyperparameter Configuration: Allow users to easily adjust key hyperparameters (learning rate, batch size, epochs, etc.). Provide sensible defaults and tooltips explaining each parameter.
      Training Progress Visualization: Display real-time training progress, including loss curves, evaluation metrics (e.g., accuracy, F1-score), and potentially examples of generated text.
      Model Download/Export Options: Allow users to download the fine-tuned model in various formats (e.g., TensorFlow SavedModel, PyTorch, GGUF for local inference).
      Integration with Google Cloud Storage/Vertex AI: (Optional) Provide options for users to train at scale using Google Cloud resources. This would involve integrating with GCS for data storage and Vertex AI for training.
      Clear Documentation and Examples: Provide comprehensive documentation and step-by-step examples for using the UI.
      Complexity: Medium to High. Requires web development skills, familiarity with machine learning frameworks (TensorFlow/PyTorch), and potentially cloud integration.
      Expected Size: 175-350 hours.
      Skills: Python, Streamlit/Gradio, TensorFlow/PyTorch, (optional) Google Cloud Platform.
      Gemma <> Hugging Face Spaces Demo: Create an interactive demo for the Hugging Face Spaces platform using a Gemma model. This should showcase a specific capability of Gemma (e.g., text generation, question answering, code completion).
      Build a Gradio or Streamlit Application: Create a user-friendly web application that allows users to interact with the Gemma model.
      Integrate with the Hugging Face Hub: Load the Gemma model directly from the Hugging Face Hub.
      Provide Clear Instructions and Examples: Make it easy for users to understand how to use the demo and what to expect.
      Make the Demo Visually Appealing and Engaging: Use interactive elements, clear formatting, and potentially visualizations to make the demo engaging and informative.
      Complexity: Medium. Requires web development skills and familiarity with Hugging Face Spaces.
      Expected Size: 175 hours.
      Skills: Python, Streamlit/Gradio, Hugging Face Hub.
      Benchmark Gemma Models: Develop a comprehensive benchmark suite to test Gemma models on a range of tasks and datasets (academic benchmarks like MMLU, GSM8K, etc., and custom datasets).
      Create scripts for automation. Automate the benchmarking process for various tasks.
      Compare performance of various Gemma model families. Run the benchmarks on different Gemma model sizes and variants.
      Compare performance against other open models. Include other popular open models (e.g., Llama 2, Mistral) in the benchmark for comparison.
      Create informative summaries of benchmark results. Generate reports and visualizations summarizing the results. This should include tables, charts, and potentially a leaderboard.
      Regular Updates: Design the benchmark to be easily updated with new Gemma models and datasets.
      Reproducibility: Provide clear instructions and scripts to allow others to reproduce the benchmark results.
      Complexity: Medium to High. Requires understanding of benchmarking methodologies, machine learning evaluation, and scripting.
      Expected Size: 175-350 hours.
      Skills: Python, machine learning evaluation, scripting, data analysis.
      Gemma Model Function Calling Exploration:
      Investigate and document best practices for using Gemma with function calling, similar to other models' function calling capabilities. This capability allows the model to call external functions to retrieve information or perform actions.
      Create detailed tutorials, and comprehensive code examples. Provide step-by-step instructions and code examples demonstrating how to implement function calling with Gemma.
      Develop use case scenarios. Showcase various use cases where function calling can be beneficial, such as interacting with APIs, databases, or other external tools.
      Define clear specifications: Document how to define the functions that Gemma can call, including input/output formats and error handling.
      Explore Different Approaches: Investigate different approaches for implementing function calling, such as using existing libraries or developing custom solutions.
      Complexity: Medium. Requires understanding of LLM capabilities, API design, and potentially creating custom integrations.
      Expected Size: 175-350 hours
      Skills: Python, API design, LLM interaction.
      Comments are disabled for this gist.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/google-deepmind/
    idea_list_url: https://goo.gle/deepmind-gsoc-projects-2025


  - organization_id: 57
    organization_name: Graphite
    no_of_ideas:
    ideas_content: |
      Contributor guide
      » Project setup
      » Codebase overview
      » Debugging tips
      » Starting a task
      » Code quality guidelines
      » Submitting a contribution
      » Student projects
      » Graphene
      » Networks and nodes
      Student projects
      Graphite offers a number of opportunities for students to contribute by building a self-contained project as part of a structured format. These projects are designed to be completed over several months and are ideal for Google Summer of Code or similar internship programs, solo or group university capstone projects, and other arrangements. Each project has a distinct focus and is a great way to make a meaningful contribution to open source over the length of the program while receiving mentorship and guidance from the Graphite team.
      Student projects require adherence to a set schedule with regular check-ins, milestones, and evaluations. The structured setting is designed to provide a supportive environment for students to learn and grow as developers while gaining real-world industry experience from collaborating on a sizable software product and remaining accountable to stakeholders. It's our goal to make sure you succeed!
      Use this contributor guide to start out with the code. Then when you're ready, reach out through Discord and use the #🎓student-projects channel to discuss and work towards proposing a project with the Graphite core team.
      Google Summer of Code
      GSoC is a program offering students a stipend for successful completion of an internship-style experience with an open source organization. Read about how it works.
      Graphite is participating again in GSoC 2025. Getting involved early is a great way to have a head start and stand out in your application. The proposal formulation period is open now until the April 8 deadline (see the full timeline).
      Writing a proposal
      Writing a good proposal is an important first step that demonstrates your understanding of the project and your ability to plan and execute it. A well-defined proposal will set you up for success throughout the rest of the program.
      You are encouraged to reference the project idea list below to find several potential projects suited to your experience, interest, and choice of scope. Then, you must reach out to a core team member through Discord to discuss your plan in detail before writing a proposal. This will help you understand the project's scope and requirements and develop a detailed timeline for your expected summer-long work schedule. Importantly, it will also help us understand your background and capabilities to offer you feedback and suggestions for the best outcome in the competitive applicant selection process.
      When it comes to writing the proposal, which you will submit to the GSoC application website, we offer some guidelines below:
      Proposal structure: Please consult the Blender GSoC application template as reference for our desired format. For project ideas already listed below, omit the "Benefits" section. Remember: don't waste your—and our—time restating information that we already know, like background info about Graphite or our tech stack; we just want to hear your thoughts and plans about what you uniquely bring to the table and how you'll execute the project. Proposals should be utilitarian, not formal, while also demonstrating your professional communication skills. Using an LLM to write your proposal won't be to your advantage.
      Experience: We're especially interested in your background and work experience, so attaching a résumé or CV is an optional but recommended way to help us understand your capabilities. If able, please also include links to past open source contributions or personal projects in the bio section. Our goal is to provide an environment for you to learn and grow as a productive software engineer and team collaborator, not to help you learn the basics of coding, so any included work examples will help us understand your potential as a self-motivated contributor to the open source community.
      Work timeline: Your goal is to write a proposal that inspires confidence in your ability to successfully complete the project, which means understanding in detail what's involved at a technical level and how you plan to tackle it. A detailed work timeline is the most important written part of your proposal. It should be broken into weekly or bi-weekly milestones with a couple sentences of technical detail. The summary in the project idea list below doesn't give enough information to develop a timeline, so you'll need to discuss this with the core team on Discord.
      Prior PRs: The largest factor in our selection decision will be the quality and extent of your prior contributions to Graphite made during the proposal formulation period (or before, if applicable). Include a link to https://github.com/GraphiteEditor/Graphite/commits?author=YOUR_GITHUB_USERNAME in your proposal and feel free to write up a summary of what you've contributed and learned from the process. You may also keep contributing during the month after applications close, before we've finalized our selections, for those additional PRs to be considered.
      Project idea list
      Compilers, graphics, and theory
      These projects are more advanced but are highest priority for Graphite's development. We will be aiming to find standout candidates for at least one of these projects this year. If your background suits the projects listed in this section, you are likely to have better odds applying to these compared to the more general projects further below.
      Graphene language/compiler development
      Check back shortly for a full project description, or ask on Discord right now for more details.
      See the GitHub issue.
      Best for someone with an aptitude or focus on programming languages, compilers, and type system theory.
      GPU-accelerated rendering pipeline within the compiler/runtime/engine
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Build out infrastructure in the language/compiler/runtime/engine using rust-gpu and/or CubeCL.
      See the GitHub issue.
      Best for someone with both an aptitude for low-level graphics programming (experience in one of WGPU, Vulkan, OpenGL, etc.) and an interest in compilers and programming languages.
      Node equivalence rewriting
      Check back shortly for a full project description, or ask on Discord right now for more details.
      See the GitHub issue.
      Best for someone with an interest towards graph theory and compiler optimization topics like E-graphs.
      Machine learning architecture
      Generative AI and vision ML models will need to run in Graphite's node graph with a Rust-centric, modular, portable, deployable, scalable environment.
      Possible Mentors: Oliver
      Needed Skills: Machine learning (and potentially: Rust, Python, ONNX, Candle, Burn)
      Project Size: Large (GSoC: 350 hours)
      Difficulty: Hard
      Expected Outcomes: Specifics will vary by proposal. In general, a useful end-to-end integration of at least one GenAI or vision model into Graphite's node graph which can run both locally and deployed to a hosting provider server.
      AI/ML is filling a rapidly growing role as a tool in the creative process. Graphite's procedural node-based workflow is uniquely suited to leveraging the power and flexibility of AI nodes.
      Segment Anything 2 (object segmentation), Depth Anything (depth estimation), and Stable Diffusion (image generation, generative fill, style transfer, etc.) are currently the three models we are most interested in integrating. The challenge is settling on an architecture and tech stack which is well suited for Graphite's requirements.
      For additional technical details: click here
      Rendering and graphics
      Several of these require a good understanding of computer graphics rendering techniques and algorithms. Experience in game development and writing your own rendering engines is a plus.
      Mesh vector rendering
      Check back shortly for a full project description, or ask on Discord right now for more details.
      See the GitHub issues: fills and strokes.
      Support paints for strokes and fills
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Refactor and upgrade our renderer to cleanly handle paints for fills and strokes.
      This includes gradient rendering polyfills
      May include other rendering features like stroke alignment polyfills
      Advanced text layout and typography
      Check back shortly for a full project description, or ask on Discord right now for more details.
      See the GitHub issue.
      PDF and/or DXF import/export
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Scope and viability depends on the state of available libraries.
      Traditional brush engine
      Check back shortly for a full project description, or ask on Discord right now for more details.
      See the GitHub issue.
      Procedural brush engine
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Read this thesis for background, chapter 3 onwards.
      Advanced color management
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Add support for HDR/WCG and/or CMYK and alternate color spaces/models
      Requires an experienced understanding of color science
      Image processing algorithms for photography
      Check back shortly for a full project description, or ask on Discord right now for more details.
      New graphics nodes
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Research and implement image processing (raster) or geometry (vector) nodes that you propose or we suggest in our discussions with you.
      Example of one such node: Text on path.
      SVG with raster effects
      Check back shortly for a full project description, or ask on Discord right now for more details.
      The SVG spec supports a number of filters and other raster effects, and we currently only implement a small subset.
      Add support for the rest of the SVG spec, including filters, masks, and other raster effects.
      Allow roundtrip import and export of SVG files with these features.
      Editor tooling
      Snapping system overhaul
      Check back shortly for a full project description, or ask on Discord right now for more details.
      See the GitHub issue.
      Advanced vector editing tool modes
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Add modes for segment editing, mesh vector, and more. Discuss with us on Discord to decide on the scope of the project.
      Tooling polishing and gizmo additions
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Marquee selection masking
      Graphite's raster editing features requires the implementation of Select mode, where users can draw a mask which becomes a marquee (marching ants) selection.
      Possible Mentors: Keavon, Hypercube
      Needed Skills: Rust, computer graphics
      Project Size: Large (GSoC: 350 hours)
      Difficulty: Medium
      Expected Outcomes: Complete implementation of Mask mode and its marquee selection. Marching ants visualization shader effect. Integration of selection mask with the node graph and raster editing tools. Useful raster editing workflow.
      A central part of the workflow in raster image editors is the selection of portions of the image to constrain manipulations just to the masked areas. Tools such as the circular and rectangular marquee, lasso, and magic wand are used to create masks. Instead of using dedicated tools, Graphite's design reuses the existing vector and raster drawing tools (like Rectangle, Ellipse, Pen, and Fill) to create masks in a dedicated Mask mode. Returning from Mask mode reveals the marching ants selection that constrains further editing operations.
      This is a key feature in Graphite's evolution to a fully-featured raster editor.
      Refactors and infrastructure
      Complex widget layout system
      Graphite's UI needs an upgraded layout system to support more complex and dynamic widget arrangements defined from the backend.
      Possible Mentors: Keavon
      Needed Skills: Rust, web (Svelte, CSS, TypeScript)
      Project Size: Small (GSoC: 90 hours) or Medium (GSoC: 175 hours)
      Difficulty: Medium
      Expected Outcomes: An improved system for defining widget layouts with better control and flexibility over arrangement and dynamic data binding. Reduction in boilerplate and plumbing required to define each new layout. Better control of styling between rows.
      The current system for defining the arrangement of widget layouts from the backend, created during a previous student project, has served us well thus far but has limitations. This project aims to extend the system to better model our evolved requirements.
      Students should have a good level of familiarity with Rust design patterns to envision, prototype, propose, and robustly implement a new system that can handle the complexity of Graphite's use cases. The size of this project can vary depending on the proposal's scope and extent of refactoring to these and adjacent systems.
      For additional technical details: click here
      Testing and performance instrumentation
      Graphite has many areas that could benefit from better automated testing for bugs and performance regressions.
      Possible Mentors: Dennis, Hypercube
      Needed Skills: Rust, unit testing
      Project Size: Small (GSoC: 90 hours) or larger if proposed
      Difficulty: Easy
      Expected Outcomes: Specific focus and scope may vary by the student's interests and proposal. In general, a significant increase in the coverage of tests in useful code areas (such as document loading, tool manipulation, and rendering) and attention towards systems which measure performance metrics and identify bottlenecks and regressions.
      Graphite could benefit from better testing coverage in a number of areas, especially end-to-end testing in the tool, document, and node graph systems. This project is about identifying and addressing areas that are lacking and most vulnerable to suffering from regressions. The student will be responsible for identifying areas that could benefit from better testing.
      Architecture visualization
      Infrastructure to generate visualizations of Graphite's system architecture would be a valuable addition to the project's documentation and debugging tools.
      Possible Mentors: Keavon, Dennis
      Needed Skills: Rust (especially proc macros)
      Project Size: Small (GSoC: 90 hours) or larger if proposed
      Difficulty: Medium
      Expected Outcomes: A system built from proc macros which can generate useful visualizations of Graphite's system architecture. Depending on proposal scope, this can include static visualizations added to the documentation, dynamic message flow visualizations for debugging, and tools to help identify redundant message traffic.
      Graphite's editor architecture, based around a message-passing processing queue, is structured as a hierarchical system of message handlers. Each handler stores its own state, and references to the state data may be passed along to its child handlers that need it.
      It is challenging to document the hierarchy of this system as a tree in the documentation because the code is often changing. Generating a visualization would ensure it remains up to date. Additional visualizations could also be generated with greater detail, such as message flow diagrams for each message.
      For additional technical details: click here
      Other
      Your own idea
      If you have an idea for a project that you think would be a good fit, we'd love to hear it!
      Possible Mentors: Varies
      Needed Skills: Varies
      Project Size: Varies
      Difficulty: Varies
      Expected Outcomes: Stated in your proposal.
      If none of the projects above suit your interests or experience, we are very open to discussing your own project ideas that could benefit Graphite. You may consult our task board and roadmap to get a feel for what our current priorities are.
      As is the case with all projects, please discuss this with us on Discord to flesh out your idea. Unsolicited proposals that have not been discussed with us will almost certainly be rejected.
      Successful past projects
      2024: Interactive node graph auto-layout
      Graphite's graph UI needs a system to automatically arrange layers and nodes given incremental changes to the graph contents.
      Affiliation: GSoC 2024
      Duration: 3 months
      Student: Adam Gerhant
      Program project listing
      Report and weekly updates
      Outcomes: A system that manages the placement of nodes based on a set of layout constraint rules and incremental updates to the graph topology. It should run efficiently, even with large graphs. It should be robust enough to handle a variety of graph topologies and user interactions, producing organized, useful, and stable layouts.
      Background: The Graphite concept is built around a node graph representation of layer stacks, while tools automatically generate and manipulate nodes. When a layer or node is inserted, deleted, moved, or referenced, the graph needs to be reorganized to maintain a clear and useful layout. Users can also interactively expand and collapse groups of nodes which occupies or frees up graph real estate.
      Unlike other node editors that are centered around manual graph editing, where users are fully in charge of node placements within one large node network, Graphite's node UI is more oriented towards automatic layout management and viewing just parts of the graph at one time. This means the shown graph topology is constantly changing and the layout system needs to cooperatively organize the graph in concert with user actions.
      While general graph layout algorithms are complex and struggle to produce good results in other node editors, Graphite's graph topology is more constrained and predictable, which makes it possible to design a layout system that can produce good results. Nodes tend to be organized into rows, and layers into columns. This turns the problem into more of a constraint-based, axis-aligned packing problem.
      2024: Rendering performance infrastructure improvements
      Graphite performance is bottlenecked by limitations in the new node graph rendering architecture that needs improvements.
      Affiliation: GSoC 2024
      Duration: 4 months
      Student: Dennis Kobert
      Program project listing
      Report and weekly updates
      Outcomes: A holistic, metrics-driven focus on fixing the many unoptimized areas of Graphite's node graph compilation, execution, and rendering systems. Integration of Vello as an integrated rendering backend. A significant improvement in the performance of the editor, especially in the node graph, and a more stable and predictable performance profile. Benchmarking and profiling tools to measure and visualize performance improvements and regressions.
      Background: Graphite's node graph system is the backbone of the editor, but it has many performance problems that need to be addressed because the system is relatively immature and performance-impacting shortcuts were taken during its initial development. This project is all about making the node graph system more robust and optimized, which will have a direct impact on the user experience and the editor's overall performance. By the end of the project, the editor should finally feel usable in the majority of user workflows. Vello should be enabled as an alternate render engine that will fully replace the existing SVG-based one in the future, once browser support arrives across major platforms.
      2024: Raw photograph decoding in Rust
      For Graphite to support editing photos from professional digital cameras, it needs a raw decoding/processing library.
      Affiliation: GSoC 2024
      Duration: 5 months
      Student: Elbert Ronnie
      Program project listing
      Report and weekly updates
      Rawkit library
      Outcomes: A Rust library that implements raw photo decoding functionality to native Rust. A clean, well-structured codebase and API. At a minimum, demonstrate the successful end-to-end decoding, debayering, and color space handling of Sony ARW format photos in Graphite. Publish the library to crates.io.
      Background: For Graphite to work as a photo editing app, it needs to import raw photos. These contain compressed sensor imagery and metadata in a variety of formats. Sony ARW is the first target and additional camera brands are stretch goals. Graphite needs a library written in pure Rust with a suitable (non-GPL) license, which does not currently exist in the ecosystem, so we need to create one ourselves.
      2023: Bezier-rs library
      Graphite's vector editing features require the implementation of Bezier curve and path manipulation computational geometry algorithms.
      Affiliation: University of Waterloo, Ontario, Canada
      Duration: 9 months
      Students: Hannah Li, Rob Nadal, Thomas Cheng, Linda Zheng, Jackie Chen
      Bezier-rs library
      Interactive web demo
      Outcomes: The student group designed an API for representing and manipulating Bezier curves and paths as a standalone Rust library which was published to crates.io. It now serves as the underlying vector data format used in Graphite, and acts as a testbed for new computational geometry algorithms. The team also built an interactive web demo catalog to showcase many of the algorithms, which are also handily embedded in the library's documentation.
      2022: Backend layout system
      Graphite's UI needs a system to define and manage layouts for widgets from the backend.
      Affiliation: California Polytechnic State University, San Luis Obispo, USA
      Duration: 3 months
      Student: Max Fisher
      Outcomes: The student designed and implemented a new system across the editor's frontend and backend which made it possible to define and manage layouts for widgets from the backend and receive input data from those widgets. Previously, all layouts were statically defined in the frontend and extensive plumbing was required to pass data back and forth.
      2022: Path boolean operations
      Graphite's vector editing features require the implementation of boolean operations on paths, such as union, intersection, and difference.
      Affiliation: California Polytechnic State University, San Luis Obispo, USA
      Duration: 3 months
      Student: Caleb Dennis
      Outcomes: The student devised and prototyped algorithms for performing boolean operations on paths, such as union, intersection, and difference. These were used as a stopgap during 2022 and 2023 to provide users with a rudimentary boolean operation feature set.
      Submitting a contribution
      Graphene
      Contents
      Google Summer of Code
      Writing a proposal
      Project idea list
      Compilers, graphics, and theory
      Graphene language/compiler development
      GPU-accelerated rendering pipeline within the compiler/runtime/engine
      Node equivalence rewriting
      Machine learning architecture
      Rendering and graphics
      Mesh vector rendering
      Support paints for strokes and fills
      Advanced text layout and typography
      PDF and/or DXF import/export
      Traditional brush engine
      Procedural brush engine
      Advanced color management
      Image processing algorithms for photography
      New graphics nodes
      SVG with raster effects
      Editor tooling
      Snapping system overhaul
      Advanced vector editing tool modes
      Tooling polishing and gizmo additions
      Marquee selection masking
      Refactors and infrastructure
      Complex widget layout system
      Testing and performance instrumentation
      Architecture visualization
      Other
      Your own idea
      Successful past projects
      2024: Interactive node graph auto-layout
      2024: Rendering performance infrastructure improvements
      2024: Raw photograph decoding in Rust
      2023: Bezier-rs library
      2022: Backend layout system
      2022: Path boolean operations
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/graphite/
    idea_list_url: https://graphite.rs/volunteer/guide/student-projects/

  - organization_id: 58
    organization_name: Haskell.org
    no_of_ideas:
    ideas_content: |
      GSoC 2025 Ideas
      This is a list of ideas for contributors who are considering to apply to Google Summer of Code 2025 for Haskell.org
      For project maintainers
      Are you working on a Haskell project and you could use the help of a contributor during the summer? Consider adding it as an idea here! You can contribute ideas by sending a pull request to our github repository (example from 2024). If you just want to discuss a possible idea, please contact us.
      What is a good idea? Anything that improves the Haskell ecosystem is valid. The GSoC rules state that it must involve writing code primarily (as opposed to docs).
      Projects should be concrete and small enough in scope such that they can be finished by the contributor. Past experience has shown that keeping projects “small” is almost always a good idea.
      Important changes since 2021/2022: In the past, GSoC projects were expected to take up the equivalent of full time employment for a student. In 2021, this was reduced to half time positions: students were expected to work around 175 hours in a 10 week period. Since 2022, contributors now have the choice between a larger (around 350 hours) or a smaller project. Ideas should indicate in which category they fall.
      Projects should benefit as many people as possible – e.g. an improvement to GHC will benefit more people than an update to a specific library or tool, but both are acceptable. New libraries and applications written in Haskell, rather than improvements to existing ones, are also welcome.
      For students/contributors
      We have added some tips on writing a proposal here. Please be aware that:
      This is not an all-inclusive list, so you can apply for projects not in this list and we will try our best to match you with a mentor.
      You can apply for up to two ideas (but only one can be accepted).
      Table of Contents
      CodeWorld GHC Update
      Language Server support for cabal.project files
      Qualified aliases in Liquid Haskell
      CodeWorld GHC Update
      CodeWorld is a web-based educational environment for learning computer science using Haskell. It is based on GHCJS, an old project to compile Haskell to JavaScript with a modified GHC compiler.
      GHCJS is no longer a good choice, as it is difficult to keep up to date with the latest GHC versions. However, modern versions of GHC have built-in backends for both JavaScript and WebAssembly, which are more reliable and easier to maintain, and kept up to date as part of the main line of GHC development. This project would involve updating CodeWorld to use one of the new GHC backends for JavaScript or WebAssembly.
      This would involve updating the build system, and making any necessary changes to the CodeWorld runtime to work with the new backends.
      The scope of the project can be adjusted based on the desired time frame and experience of the mentee. Some questions include:
      Is the goal to get a proof of concept, or a deployable replacement?
      Will the rule-based requirements checker also be updated to newer GHC versions?
      This requires updating the GHC API usage.
      This feature is, to my knowledge, not currently used by anyone.
      Will the educational dialect be updated?
      If so, how do we handle unconstrained universal equality? Note that this likely requires development of a non-trivial GHC plugin.
      If not, how do we deploy both versions simultaneously (if a deployable replacement is the goal)?
      What additional improvements are enabled by newer GHC versions and the new backends?
      Mentorship
      Chris Smith (cdsmith)
      Ideally, a second mentor with experience in one or both of GHC JS/WASM backends
      Difficulty and size
      The difficulty of this project is medium, as there are significant infrastructure and build system challenges to address. Depending on choices made, this may become hard.
      The minimum size of this project is 175 hours, but there is likely more work depending on the mentee’s desired scope and ideas.
      Language Server support for cabal.project files
      Goals
      Introduce a new Haskell Language Server plugin, which provides IDE-features for cabal.project files.
      Some possible features include: * Diagnostics * Completions of * keywords * filepaths * enum values * Syntax Highlighting
      The scope of the project can be adjusted based on the desired time frame and experience of the mentee. Some of these implementations can draw inspiration from the corresponding implementation in the hls-cabal-plugin.
      Background
      cabal.project files are often needed to configure how your project should be built. Haskell developers will often write and edit these files during their development process but as of yet, Haskell Language Server (HLS) provides no IDE support for them.
      Since HLS already provides IDE features for .cabal files it seems a natural next step to add a similar cabal.project plugin to HLS which provides IDE support for cabal.project files.
      Outcomes
      The main outcomes are pull requests with the implementation, tests, and code documentation of the implemented features.
      A secondary outcome is a blogpost describing the experience and the results of the project.
      Difficulty and Size
      The difficulty of this project is medium, as there are two rather big existing projects that developers need to understand in order to provide improvements.
      The minimum size of this project is 90 hours, but this can easily be extended to 175 as there is likely more work depending on the mentee’s desired scope and ideas.
      Required Skills
      Read and write technical English
      Haskell programming basics
      Project Mentor
      Jana Chadt (VeryMilkyJoe)
      Co-Mentor: Fendor
      Qualified aliases in Liquid Haskell
      Goals
      Update the implementation of Liquid Haskell to allow referring to type and predicate aliases in qualified form.
      Background
      Liquid Haskell is a verification tool for Haskell programs. The programmer writes specifications for these programs, and Liquid Haskell checks if the programs actually meet the specifications.
      Recently, the Liquid Haskell implementation went through a refactoring to improve name resolution. Much of the names in the specification language can be qualified now, in order to dissambiguate equal names that come from different modules. There is an exception though, when it comes to type and predicate aliases. For technical reasons, this constructs have been left behind in the refactoring.
      As the reference documentation explains, type aliases can be used to shorten specifications. Instead of writing a spec like:
      {-@ length :: [a] -> {v:Int | v >= 0} @-}
      one can write
      {-@ type INat = {v:Int | v >= 0} @-}
      {-@ length :: [a] -> INat @-}
      Unfortunately, if there are multiple INat aliases in scope, Liquid Haskell does not allow to qualify the name to disambiguate. For instance, the following specification is rejected with a message that says that SomeImport.INat is not in scope.
      {-@ length :: [a] -> SomeImport.INat @-}
      This project is to analyze the implementation and to design and implement a solution both for type and predicate aliases. There is a corresponding issue in the Liquid Haskell repo.
      Outcomes
      The main outcomes are a pull request with the implementation, tests, and code documentation, and a discussion of the analysis and the design in the corresponding issue.
      A secondary outcome is a blogpost describing the experience and the results of the project.
      Size
      Project size should be near 175 hours. The project will require a fair amount of reading of existing Haskell code, and building an understanding of how it works. Familiarity with the verification mechanisms is not necessary a priori, though some user-level understanding of Liquid Haskell is going to be needed to write tests.
      Required Skills
      Read and write technical English
      Haskell programming basics
      Project Mentor
      Facundo Domínguez, Tweag engineer and comaintainer of Liquid Haskell
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/haskell.org/
    idea_list_url: https://summer.haskell.org/ideas.html

  - organization_id: 59
    organization_name: HumanAI
    no_of_ideas:
    ideas_content: |
      HumanAI
      Activities
      
      HumanAI is dedicated to integrating Artificial Intelligence with various fields in the Arts and Humanities. Our mission is to enhance the analytical potential of Arts and Humanities by combining humanist interests with machine learning initiatives.
      HumanAI in GSoC 2025
      The HumanAI open source umbrella organization plans to participate in the 2025 Google Summer of Code. If you are a student interested in our projects please check our ideas page. HumanAI is an umbrella organization that welcomes other projects and organizations related to machine-learning in Arts and Humanities. Please contact the admins at human-ai@cern.ch if you are interested in participating as a project.
      Please take a look at our GSoC Page for more details.
      You can also find us on Gitter.
      Latest update: evaluation tests to be published on 2/27.
      Organization administrators:
      Prof. Sergei Gleyzer, AI
      Prof. Xabier Granja, Modern Languages
      Prof. Emanuele Usai, AI
      Prof. Despina Stavrinos, Social Sciences, Psychology
      
      
      Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/humanai/
    idea_list_url: https://humanai.foundation/


  - organization_id: 60
    organization_name: INCF
    no_of_ideas:
    ideas_content: |
      GSoC 2025 Project Descriptions
       Request edit access
      +6
       Share
      Sign in
      FileEditViewToolsHelp
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/incf/
    idea_list_url: https://docs.google.com/document/d/1T7U4nYFbVbZuIUw_2bB89YASj-ra26hRNtG2a20Gjlw/edit?tab=t.0
  

  - organization_id: 61
    organization_name: IOOS
    no_of_ideas:
    ideas_content: |
      Project Ideas for 2025
      IOOS DMAC community's project ideas list for Google Summer of Code 2025.
      Deadline for mentoring organization application: Feb 11, 2025.
      Project Title Project Idea Link Description Hours
      Build web UI versions using pyodide/pyscript for IOOS tools ioos/gsoc#64 The idea for this project is to build interfaces for ioos-qc and compliance-checker. A user should be able to load datasets, select data and the checks they want to apply. 350 hours
      Prometheus server- graphs and monitoring for ERDDAP™ ioos/gsoc#72 We recently started adding Prometheus metrics to ERDDAP™. The main goal of this project is to build an example Prometheus Server which can monitor one or more ERDDAP™ instances. 175 hours
      Update ERDDAP™ page rendering to use a template framework ioos/gsoc#73 The project is to migrate existing ERDDAP™ pages to use a templating framework. 175 hours
      IOOS Cloud Sandbox - model validation and verification tools ioos/gsoc#84 Add model validation and verification tools to https://github.com/ioos/Cloud-Sandbox. Model validation and verification can include comparing model results to observations, previously validated data, other model data, etc. 175 hours
      Code separation and build management for cloudflow ioos/gsoc#85 Move Cloudflow's code to a poetry or uv build, with well-established and externalized dependency, and allow deployment to pypi. 90 hours
      Increased logging for Cloudflow ioos/gsoc#86 Having AWS logging increased within the codebase of cloudflow would greatly increase our capacity to support multiple users on the coastal sandbox. 90 hours
      Combined DwCA/Croissant JSON-LD examples and tools ioos/gsoc#70 The project would primarily consist of python tools to convert existing DwC metadata (in XML format) into JSON-LD format, example metadata for datasets that employ both standards, and a proof-of-concept pipeline that uses a combined DwC/Croissant-described dataset to train an AI model that predicts DwC categories from images 175 hours
      NOAA trawl survey database ioos/gsoc#74 The primary objective of this project is to create an accessible international database of transboundary marine survey data across the Northeast Pacific Ocean. 175 hours
      Extend CrocoLake's available datasets ioos/gsoc#75 This project consists in taking an existing dataset that is not yet included in CrocoLake and developing or adapting existing modules to convert it to CrocoLake's format. 175 hours
      Autoval Improvement ioos/gsoc#76 This project aims to enhance the capabilities of the Autoval package, which was developed for STOFS auto validation. STOFS stands for the Surge and Tide Operational Forecast System. 175 hours
      OCSMesh Parallelization ioos/gsoc#77 OCSMesh is a Python package that automates the generation of unstructured continuous (creek-to-ocean) meshes using the jigsaw-python library and triangles. The goal of this project is to increase OCSMesh’s efficiency by parallelizing the most time consuming steps, including DEM processing and jigsaw mesh generation. 350 hours
      STOFS dashboard ioos/gsoc#78 This project aims to advance and improve our STOFS event dashboard (github repo). This tool allows a user to select events (e.g., tropical cyclones, winter storms, major incidents in coastal areas) and compare STOFS model results with observations for those events. 175 hours
      Probabilistic Surge Model Performance Assessment ioos/gsoc#79 The storm surge modeling team at the Office of Coast Survey (OCS) have developed a framework called (ondemand-storm-workflow) to develop probabilistic hurricane storm surge models. The goal of this project is to improve the post-prossessing and model evaluation capabilities of the workflow. 175 hours
      Land Cover Integration for Parametric Hurricane Model (PaHM) ioos/gsoc#80 This project aims to enhance the Generalized Asymmetric Holland Model (GAHM) within the Parametric Hurricane Modeling System (PaHM) framework by incorporating land cover effects on wind speeds during tropical cyclones. 350 hours
      Expand the Google Test suite for the Fisheries Integrated Modeling System ioos/gsoc#81 The Fisheries Integrated Modeling System (FIMS) is a framework to create statistical models, written in C++ and R, to assess the status of marine resources. This project will add tests for uncovered code and suggest places where the tests, especially the Google tests, can be enhanced. 175 hours
      Fix clang-tidy for the Fisheries Integrated Modeling System ioos/gsoc#82 The project follows a modified Google style guide for the The Fisheries Integrated Modeling System (FIMS) C++ standards and relies on GitHub action using clang-tidy to ensure that code pushed to the GitHub repository conforms to these standards. 90 hours
      Complete the integration of the logging system in the Fisheries Integrated Modeling System ioos/gsoc#83 This project would take examples already in the source code for the The Fisheries Integrated Modeling System (FIMS) and use pattern matching to insert new logging entries into the code where it seems that they are needed. 90 hours
      phytoclass for the masses ioos/gsoc#90 This project will improve usability and accuracy of phytoclass R library for conversion of HPLC pigment data to phytoplankton abundance estimations. 90 hours
      pyOBIS for stakeholders ioos/gsoc#91 This project will make use of the pyOBIS python library to create a series of jupyter notebooks to address research questions of natural resource managers. 90 hours
      Add MQTT support to ERDDAP™ #93 Add support for MQTT to ERDDAP™. MQTT is a message protocol which was in particular designed to be lightweight and used by remote/IoT devices. 350 hours
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/ioos/
    idea_list_url: https://github.com/ioos/gsoc/blob/main/2025/ideas-list.md

  - organization_id: 62
    organization_name: Inkscape
    no_of_ideas:
    ideas_content: |
      master
      inkscape
      doc
      gsoc
      summerofcode.md
      summerofcode.md
      Find file
      Blame
      Permalink
      Clean doc folder, add GSoC instructions
      Jonathan Neuhauser authored 4 months ago
      1d7e5d29
      History
      Code owners
      Assign users and groups as approvers for specific file changes. Learn more.
      summerofcode.md
      18.99 KiB
      Edit
      Welcome to Inkscape!
      For quite a few years Inkscape has been successfully participating in Google Summer of Code.
      Google has opened up the program to students AND beginners to Open Source who are 18 years are older. Projects can be small (~90 hours), medium size (~175 hours) or large size (~350 hours). Finish times are flexible, 12 to 22 weeks (with agreement of mentor).
      For more information, checkout Google's guide.
      GSoC is a program where Google funds the development of specific features in open source software by university students and others new to open source. Projects to be developed are picked by Inkscape administrators from the pool of proposals submitted by applicants.
      We've mentored about 4-6 students a year since GSoC started. Many students enjoyed their work and continue to be involved; perhaps your mentor will be a past GSoC student! A lot of exiting new features have been originally developed by GSoC students in the past several releases.
      You're interested in joining us for the next round as a student? Great! Scroll through the ideas list below to get inspired and when the time comes, talk to us and select a project of your choosing.
      You can select a proposal from the list below or come up with one of your own. In either either case, you must give us a detailed outline of what you plan to do. It is highly recommended that you discuss your idea as early as possible with Inkscape developers. They not only can give you guidance as you flesh out your proposal but ultimately you must convince them that you can do the work planned in the time allotted. If you have not discussed your proposal with Inkscape developers before you apply, your application will be rejected!
      Candidate Applications {#candidate_applications}
      Google program information:
      Home page.
      Summer of Code Application form. Applications open at 18:00 UTC on March 18th, 2024. https://developers.google.com/open-source/gsoc/timeline
      Inkscape-specific information:
      SOC Application Template.
      Candidate Applications for GSoC 2024 must be submitted to the GSoC site by 18:00 UTC on April 2nd 2024.
      The "two patches" rule
      We require two relevant previous contributions from each potential GSoC student at the time of the application deadline before accepting the student for GSoC participation.
      The reason for this requirement is that you can show us that you have
      succeeded in building Inkscape or set up the development environment for the subproject you intend to work on on your PC
      have understood a little piece of the code relevant for your project and are able to improve it.
      Inkscape is a large project, and you really should not try to understand all the code. Many (all?) developers know only parts of the program code! You can join our or chat and ask developers for help.
      Suggested "easy" bug fixes or improvements
      To get you started on Inkscape development, you can find (probably) easy-to-fix bugs or small improvements that require very little knowledge of the whole program by searching our bug-tracker for bugs tagged with 'easy-fix'.
      Note that for projects outside of the core repository (such as extensions, website, infrastructure or documentation / translation infrastructure) related projects, your two patches should be in the appropriate subprojects and programming language.
      Performance Evaluation
      See also the official guide.
      GSoC has two formal evaluation points, at the mid-term and at the end. These evaluations determine if you receive the stipend from Google. In order to receive a pass for the evaluations you will need to show adequate progress toward your project's goals.
      To help you meet your goals and so that your mentor can better evaluate your progress you should:
      Have frequent, public discussions of your progress. (Don't rely on just your mentor for advice)
      Have a public branch for your code to which you commit regularly. Ideally, an open merge request invites discussion from other experienced contributors.
      Give regular (typically weekly) status reports to the entire project.
      For the final pass, the code doesn't need to be merged yet, but as a general guideline, there should be a clear pathway to get it production-ready (in particular, remarks from core contributors should have been addressed).
      Remember: we want you to succeed!
      Suggested Project Ideas
      The following is a list of formal project suggestions, but do not feel limited to only these - some of our best contributions have been unique ideas that students had in mind from other sources! That's how most developers start contributing - an "itch to scratch" is the best motivation to stay on track!
      General inspiration may be taken from
      highly requested features
      UX bugtracker
      Older, possibly outdated project lists (definitely ask on chat before spending any time on investigating them):
      Development Project Ideas
      Projects
      Launchpad blueprints
      C++ projects
      UI-Free Inkscape
      Estimation of difficulty: Difficult - Long (350h)
      Potential mentors: Marc Jeanmougin
      Programming skills: C++, CMake
      Prerequisites: Minimal knowledge of build systems. Experience with GtkMM helpful.
      Detailed Description: Inkscape currently builds with X11 and gtk and a lot of graphical dependencies. But since it is allowed to run in commandline, and there are controlled environments (servers) that use it to convert svg to png and to perform actions, there should be no need to force it to build with those. The main goal of this project is to add a WITH_GUI compilation flag that when OFF, does not link Inkscape with any graphical dependency. While much work has been done towards this goal, much remains to be done. More work needs to be done to separate out hidden GUI dependencies that remain since the Verb to Action transition.
      Use cases: Server installs, scripts
      Rework Live (Path) Effect system
      Estimation of difficulty: Hard - Long (350h)
      Potential mentors: mikekov
      Programming skills: C++
      Prerequisites: experience with raster images
      Detailed Description: Live Path Effects (LPEs) are non-destructive effects applied to paths and shapes standalone or inside a group. This is done by keeping a reference to the original data to recompute when needed. Currently, they don't work on text and image elements, and the underlying code needs to be refactored to support this and make LPEs more robust.
      Use cases: Enable non-destructive editing for more object types, even groups with mixed element types.
      Path Library Improvements
      Estimation of difficulty: Hard - Long (350h)
      Potential mentors: Tavmjong Bah, KK
      Programming skills: C++
      Prerequisites: Strong math skills, specifically in (computational) geometry.
      Detailed Description: Inkscape relies on two geometry libraries for path manipulations: lib2geom and livarot. lib2geom is a generic modern library written specifically with Inkscape in mind. lib2geom is missing some functionality that Inkscape requires and that is found in livarot. This project is to move that functionality into lib2geom (or into separate files) using lib2geom path descriptions. A 2020 GSoC student did a significant amount of work understanding and documenting the issues involved. This project would be to build on his work.
      Specifically, the functionality needed is
      Path offset/inset functions.
      Path simplify.
      Stroke to path function.
      Line scanning (used for flowing text into a shape).
      Improvements to Paint Server Dialog
      Estimation of difficulty: Easy to Medium (175h)
      Potential mentors: Tavmjong
      Programming skills: C++
      Prerequisites: Some knowledge of GTK and CSS.
      Detailed Description: The Paint Server Dialog allows a user to visually select a pattern or hatch to use in painting the fill or stroke of an object. This project would be to expand the dialog to cover gradients, meshes, and solid colors as well as make other improvements to the dialog. Interaction with the Inkscape's UX team will be required.
      Improving UI of Live path effects
      Estimation of difficulty: Medium-Hard, Medium or Long depending on scope (175h or 350h)
      Potential mentors: Mike
      Programming skills: GTK 4, C++
      Prerequisites: Front end UI, familiarity with Live path effects
      Detailed Description: This project should implement the proposed UI clean up of controls. LPE controls should be more user friendly and predictive. Full Proposed designs
      Corners LPE Rotate copies LPE
      Recolor Artwork
      Estimation of difficulty: Variable - Short to Medium (90h or 175h)
      Potential mentors: Adam Belis ?
      Programming skills: C++
      Prerequisites:
      Detailed Description: An easy and convenient way how to change any color from the selection. Useful for experimenting and tweaking colors.
      Full proposal Here
      Use cases
      fast editing of color in whole project without the need for swatches
      easier way to make colors harmonize in a project
      Faster iteration and visioning of designs
      Python projects
      Import and Export extensions
      Estimation of difficulty: Flexible, usually easy to medium, Medium or Long depending on scope (175h or 350h)
      Potential mentors: Jonathan
      Programming skills: Python, Ability to read technical documents, depending on the format: some reverse engineering
      Prerequisites: minimal knowledge of test-driven development
      Detailed Description: Inkscape is alway looking to improve compatibility! Some ideas of relevant file formats - each of them more than enough for one GSoC:
      Refactor our DXF input and output extensions, and improve their test coverage / correctness
      Rewrite the XAML importer in Python (currenly XSLT) to match the capabilities of the new XAML exporter (i.e. support for different target frameworks, better text support...) - would have to select carefully what to support (drawing primitives) and what not (control elements) - the boundary is not as clear-cut as it seems.
      Update the Synfig export to support the latest Synfig developments
      Import or export of TikZ. There are a few abandoned extensions out there (from which we can borrow), but it's very widely used in science - both import and export could serve an important function in the scientific workflow. Related, import / export to Typst.
      Import of the proprietary fileformats of Vectornator (now Linearity Curve), Vectorstyler, Canva (users at some point will sit on a bunch of files that they can't open anymore because).
      Python based EMF / WMF importer - the current (core Inkscape) C extension is unmaintained and Python would probably be the right way to get more collaboration on it. A lot of public archives sit on mountains of EMF files. Note that the Document Foundation recently did a lot of work properly importing those files, so we can learn from them / maybe even join forces ...
      your favorite file format? - also have a look here: https://office.inkscape.org/nextcloud/index.php/s/Tq6cdDDGay6taCw
      Gcodetools refactoring and documentation
      Estimation of difficulty: Easy- Medium or Long depending on scope (175h or 350h)
      Potential mentors: Jonathan
      Programming skills: Python
      Prerequisites: Maker background / familiarity with the Maker community
      Detailed Description: Gcodetools is a set of Inkscape extensions that deal with reading and creating Gcode files, mostly for use in laser cutters or plotters. For this project, ideally someone with a Makerspace background will
      query maker spaces on their needs regarding gcodetools,
      implement those needs together with unit tests,
      improve the test coverage of Gcodetools,
      write proper documentation for it. (doesn't really exist at the moment).
      Packing / Nesting as an Inkscape extension
      Estimation of difficulty: Medium, Short or Long depending on scope (175h or 350h)
      Potential mentors: Jonathan
      Programming skills: Python
      Prerequisites: Computational geometry
      Detailed Description: In this project, a set of packing / nesting algorithms will be implemented:
      Linear nesting is not too useful in SVG, but might be a good place to get acquainted with the problem. 2D cutting stock problem would be very interesting to have and would work great with the new multipage functionality.
      For efficient packing of free form objects, we might just re-implement SVGNest in Python. There are probably some more recent research papers which would be interesting to implement as a comparison.
      Other
      Your project
      Estimation of difficulty: Variable - Variable (90h to 350h)
      Potential mentors: ask us!
      Programming skills: C++ or Python
      Prerequisites: good ideas
      Detailed Description: The most successful GSoC we had in the past were students coming with their own past, use cases and ideas for Inkscape. Many basic tools like 3d cubes or connectors you can see in Inkscape now have been brought by brilliant people (like you) with ideas. If we think that your project fits with Inkscape (ie: has its place with a vector graphic editor), we can help you refining your ideas and help bring shiny new stuff to life!
      Use cases
      Amaze us!
      Successful SOC Projects from Previous Years
      2005
      Connectors
      Inkboard
      Open Clip Art Library (OCAL) Interface
      DXF Import / Export
      2006
      Support for SVG Filters
      Filter Effects
      PDF export
      Inkboard Protocol Spec / Lib Conversion
      2007
      Text Style Improvements
      PDF import
      Live Path Effects
      3D Box Tool
      UI for SVG Filter Effects
      Raster Functionality
      Importing from, and Exporting to, a remote ccHost instance
      2008
      SVG Fonts support
      2Geom refactoring project - port most geometry code to 2Geom
      lib2geom: interactive applications showing off the power of lib2geom
      Tech drawing abilities
      A test suite
      2009
      Node tool rewrite
      D-Bus scripting API
      Connector tool improvements
      ICC/CMYK workflow
      2010
      Cairo-based rendering
      C++ification of SP Layer
      2011
      Rendering caching
      Javascript support improvements
      CSS support improvements
      2012
      Usibility Improvements for Guides
      On-canvas support for Tessellations
      Creating python bindings for lib2geom
      2013
      Recolor Tool
      Improved Units Support
      Electronics CAD Support
      New From Templates Dialog
      New Raster to Vector Algorithm
      2014
      Better Support for SVG Paints
      Robust Boolean and Stroking Operations for 2Geom
      2016
      Better data structure for selections, see also wiki page
      CSS Style Sheet Editor, see also wiki page
      2017
      SVG 2 Text Support
      Better CSS Style Sheet Support
      2019
      Mesh gradient and hatches polyfills
      2020
      New dialog system
      Command palette dialog
      Path operations documentation
      2021
      On-canvas marker editing
      Verbs to Gio::Actions conversion
      On canvas alignment snapping
      On-canvas interactive boolean operations - basis for the Shape builder Tool of Inkscape 1.2
      Website update to Django 2.x
      Rework of Export dialog, shipped in Inkscape 1.2
      2022
      Tab Structure
      Font Selections Improvement
      OCR Support
      2023
      GTK4 toolbar port preparation
      Customizable Appearance of Canvas Controls - shipped in Inkscape 1.4
      2024
      Support for .afdesign files, shipped in Inkscape 1.4
      Improving UX of Node and Bezier tools
      Node-based filter editing
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/inkscape/
    idea_list_url: https://gitlab.com/inkscape/inkscape/-/blob/master/doc/gsoc/summerofcode.md

  - organization_id: 63
    organization_name: International Catrobat Association
    no_of_ideas:
    ideas_content: |
      Ideas Page for Google Summer of Code 2025
      We are thrilled to share our carefully curated project ideas for this year’s Google Summer of Code.
      General Information
      These ideas are just some topics we came up with, where currently nobody is working on. However, Catrobat is a project with a wide range of possibilities and we’re aware of our blindspots: So let’s live the spirit of Open Source and come up with improvements (e.g., new features, extensions, …) that are related to the project and in which you’re interested in. We do have many senior contributors who would be happy to mentor such a project. Don’t be shy and check out the last point on the list: Your idea!
      General Knowledge Prerequisites for all Projects
      Knowledge in the usage of Git and GitHub
      Basic knowledge in the concepts of software testing (e.g., test doubles) and test-driven development
      Basic knowledge in app development (for Android and iOS projects)
      Java, JUnit, Mockito, Robotium and Espresso for Android development
      Swift and Objective C for iOS development
      Also please check that you have the proper hardware for the development (e.g., an Android/iOS smartphone for testing some of the projects, Mac for iOS development etc)
      Idea Overview
      Pocket Paint Flutter
      AI Mentor for PocketCode Students
      AI-Generated 3D Models from Marine Animals
      AR-Based Interactive Marine Ecosystem Simulation
      AI-Driven Adaptive Learning Module for Marine Biology
      Mobile Application for Marine Biology AR Learning
      Open-Source AR Toolkit for STEM Education
      Awesome Demo Game Project on Marine Biology
      Your own Project Ideas …
      Project Descriptions
      Pocket Paint Flutter
      350 HOURS
      Required Skills: Flutter, Dart, Android-Development, Agile Development
      Possible Mentors: Abdulbaki Celebi, Mario Kaurin, Julia Herold, Thorsten Bandel
      Expected Outcome: Features from Kotlin/Java version of Paintroid ported to new Flutter-based version
      Difficulty level: Medium to advanced
      The developer should have knowledge of Flutter. Develop and implement missing tools in Flutter that exist in our old Android app built with Android Native.
      AI Mentor for PocketCode Students
      350 HOURS
      Required Skills: Kotlin, Python, Android AI and ML Tools, Android-Development, Agile Development, Test Driven Development, Clean Code
      Possible Mentors: Paul Spiesberger, Patrick Ratschiller
      Expected Outcome: An integrated proof of concept AI mentor within PocketCode
      Difficulty level: Advanced
      AI is now capable of sophisticated programming and can automate many coding tasks. More importantly, it excels at explaining code to students, making learning more engaging and accessible. Our goal is to integrate an AI-powered mentor into PocketCode that understands a student’s programming context and offers real-time guidance to enhance learning and coding skills.
      The AI mentor could:
      Explain programming concepts, from variables and loops to software design patterns and testing strategies
      Suggest code from text prompts, help debug issues, and propose project ideas
      Assist in code architecture, naming conventions, and writing Catrobat language tests
      Explain and translate downloaded projects from other users
      You won’t need to implement everything—just focus on a part that excites you most! The Catrobat team will provide the initial prompt and necessary API access or local LLMs for support.
      AI-Generated 3D Models from Marine Animals
      350 HOURS
      Preferred Skills: Generative AI (Stable Diffusion, GANs, Autoencoders), 3D Modeling (Blender, Unreal Engine), Marine Biology Data Sources
      Possible Mentors: Krishan Mohan Patel, Himanshu Kumar
      Expected Outcome: Functionally coded 3D models
      Difficulty level: Medium
      This year’s focus of Catrobat includes topics around marine biology as an application area, and we have several projects around the general topic. This project will focus on developing AI-powered 3D models of marine species using generative AI techniques. By training machine learning models on marine biology datasets, realistic and interactive 3D assets of octopus, fish, corals, and other underwater species will be created for use in AR applications for teaching marine biology in high schools, where teachers and pupils will be able to “program” the simulated marine animals for learning purposes integrated into biology curricula. These models will adapt dynamically based on environmental conditions like depth, temperature, and biodiversity levels.
      AR-Based Interactive Marine Ecosystem Simulation
      350 HOURS
      Preferred Skills: AR Development (Unity, ARKit, ARCore), Physics-Based Ecosystem Simulations, AI-Powered Content Adaptation
      Possible Mentors: Himanshu Kumar, Aryavardhan Sharma
      Expected Outcome: AR simulation code
      Difficulty level: Advanced
      This year’s focus of Catrobat includes topics around marine biology as an application area, and we have several projects around the general topic. This project will develop an immersive AR simulation that allows users to explore marine ecosystems and understand ecological interactions. Students will be able to visualize food chains, coral reef dynamics, and the effects of pollution through real-time AR simulations. This project aims to provide an engaging, hands-on learning experience for STEM education.
      AI-Driven Adaptive Learning Module for Marine Biology
      350 HOURS
      Preferred Skills: AI for Adaptive Learning (Reinforcement Learning, NLP), Educational Gamification Techniques, Data Analytics for User Behavior Tracking
      Possible Mentors: Aryavardhan Sharma, Supreeth M Kumar
      Expected Outcome: AI-based machine learning module
      Difficulty level: Advanced
      This year’s focus of Catrobat includes topics around marine biology as an application area, and we have several projects around the general topic. This project will implement an AI-driven adaptive learning system that customizes educational content based on student engagement and progress. The system will analyze user interactions, quizzes, and exploration patterns to personalize the learning path, ensuring a more effective and engaging experience. We will provide remote access to hardware on which the learning algorithms can be executed.
      Mobile Application for Marine Biology AR Learning
      350 HOURS
      Preferred Skills: Mobile AR Development (Flutter, React Native), UI/UX Design for Interactive Learning, Voice & Gesture Recognition
      Possible Mentors: Supreeth M Kumar, Paul Spiesberger
      Expected Outcome: Mobile AR app
      Difficulty level: Advanced
      This year’s focus of Catrobat includes topics around marine biology as an application area, and we have several projects around the general topic. This project will focus on developing a mobile AR application that allows students to access interactive marine biology lessons anywhere. The app will support gesture-based interaction, voice commands, and real-time exploration of AI-generated underwater environments, making STEM education more accessible.
      Open-Source AR Toolkit for STEM Education
      350 HOURS
      Required Skills: Open-Source Development (GitHub, API Integrations), Modular AR Content Framework, Cross-STEM Applications (Physics, Chemistry, Earth Science).
      Possible Mentors: Wolfgang Slany, Krishan Mohan Patel
      Expected Outcome: AR toolkit / STEM
      Difficulty level: Medium
      This year’s focus of Catrobat includes topics around marine biology as an application area, and we have several projects around the general topic. This project will create a modular, open-source AR framework that educators and developers can use to extend AR-based learning into other STEM domains. The toolkit will include pre-built 3D models, AI-based interactive features, and an easy-to-use interface for educators to integrate AR content into their curriculum.
      Awesome Demo Game Project on Marine Biology
      350 HOURS
      Required Skills: Coding Basics
      Possible Mentors: Selina Ernst, Wolfgang Slany
      Expected Outcome: Catrobat Demo Game on Marine Biology
      Difficulty level: Beginner
      Spend the whole GSoC time developing and designing a demo game. This year’s focus of Catrobat includes topics around marine biology as an application area, and we have several projects around the general topic. The present project aims at inspiring young people to become aware of topics related to the protection of marine habits by creating related video games of their own. If you have your own original idea about a game around this topic, please feel free to suggest it. Please note that the demo game will be published under Catrobat’s free open source license, and that the game will thus become part of the Catrobat FLOSS project’s source code. Thus, all artwork, sounds, character names etc must be compatible with our licenses, i.e., freely publishable under our licenses, the AGPL version 3 and CC BY-SA 4.0, or under a compatible, possibly even freer license such as CC0.
      Your own Project Ideas …
      90, 175 OR 350 HOURS
      Required Skills: Kotlin, Java, Android-Development, iOS-Development, Agile Development
      Requirement: self-organized work
      Difficulty level: advanced
      In the last years we found that you have many great ideas and knowledge! We’re aware that there are many ways how to improve performance, reduce memory usage, make our services more stable and of course the code easier to maintain. We’re sure you do have ideas how to achieve this, although we may have never heard of this approach before -> that’s the great thing about Open Source! And well, that’s also the experience we made at last year’s GSoC - and we liked it!
      Also new features or extensions for iOS and Android are welcome to be introduced to us. Help us to spread coding and Open Source!
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/international-catrobat-association/
    idea_list_url: https://developer.catrobat.org/pages/development/google-summer-of-code/2025/

  - organization_id: 64
    organization_name: Internet Archive
    no_of_ideas:
    ideas_content: |
      Internet Archive - Google Summer of Code 2025 - Call For Proposals (CFP)
       Request edit access
       Share
      Sign in
      FileEditViewToolsHelp
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/internet-archive/
    idea_list_url: https://docs.google.com/document/d/1oHNwPNYmHV5q3puBfv6IQFs-4gTe9XLN2iz2Lgse-1k/edit?tab=t.0

  - organization_id: 65
    organization_name: Internet Health Report
    no_of_ideas:
    ideas_content: |
      List of ideas for projects
      Information for Students
      Make sure you have read the IHR contributor handbook
      The below ideas were contributed by current IHR contributors. They are sometimes vague or incomplete. Questions related to these ideas should be asked on the related GitHub discussion thread.
      Becoming accepted as a Google Summer of Code student is quite competitive. Accepted students typically have thoroughly researched the topic of their proposed project and have been active in the discussions. Simply copying and pasting an idea here will not work. On the other hand, creating a completely new idea without first consulting potential mentors also rarely works.
      Also keep in mind that these are just proposals, we are open to new ideas you might have! Do you have an awesome idea you want to work on for IHR, but that is not among the ideas below? That's cool. We love that! Please get in touch with a mentor early on and make sure your project is realistic and within the scope of IHR.
      If there is no specific contact given you can ask questions on github, slack, or at admin@ihr.live.
      List of ideas
      IHR Status Page
      Brief explanation: Things breaks easily, so we need a status page that tells us which services are running as usual and which one are not. This page could also provide a machine-readable JSON object so that we can automate email alerts when something is not running as usual. It would also be nice to keep historical availability data.
      We provide datasets in different formats (e.g., RUST API, files on an FTP server), which need to be monitored. Thus, there can be different liveness checks, e.g., that an API responds (and also gives results), that a file exists, etc.
      The project should use, or build on top of, an existing monitoring solution, should be maintainable, and extendable if we add new datasets in the future.
      Expected results:
      Find a suitable monitoring tool that can be used as a base for this project
      Implement a status page for all API endpoints and results, websites (ihr, ihr-archive, iyp), and the IYP database
      Add a machine-readable format of the page
      Automatic email notification when something is down
      Github discussion: https://github.com/orgs/InternetHealthReport/discussions/51
      Knowledge Prerequisite:
      Overview of the IHR ecosystem, see Resources below
      Docker
      Web development experience
      Resources:
      https://github.com/InternetHealthReport/
      IHR API
      IHR Archive
      IYP website
      IYP database
      Project size: 90 hours
      Difficulty: Easy
      Contact: Dimitrios Giakatos (dimitrios@iij.ad.jp), Malte Tashiro (malte@iij.ad.jp), Romain Fontugne (romain@iij.ad.jp)
      Migrate IHR API
      Brief explanation: All results displayed on the Internet Health Report website are accessible via the IHR REST API. The current codebase is developed on an outdated version of Django (2.2.27), which is no longer supported, and we are not utilizing all of Django's features. Therefore, instead of just upgrading the Django version, we plan to migrate the codebase from the complex Django framework to a simpler framework, such as FastAPI. Additionally, the current Django framework includes code for initializing/managing the database. This time, we want to implement Bash scripts for initializing/managing the database, which will result in better maintenance.
      Expected results:
      Migrate all Django endpoints to FastAPI
      Convert the database code from Django to Bash scripts
      Dockerize the application (excluding the Bash scripts, which will be run as is)
      Github discussion: https://github.com/orgs/InternetHealthReport/discussions/58
      Knowledge Prerequisite:
      Django (to understand the current codebase)
      FastAPI
      SQL
      Docker
      Resources:
      https://github.com/InternetHealthReport/ihr-django
      https://docs.djangoproject.com/en/2.2/
      https://fastapi.tiangolo.com/
      https://learnscripting.org/streamlining-database-operations-running-sql-queries-from-a-shell-script/
      Project size: 175 hours
      Difficulty: Medium
      Contact: Romain Fontugne (romain@iij.ad.jp), Dimitrios Giakatos (dimitrios@iij.ad.jp)
      Improve the IHR Website Codebase
      Brief explanation: The IHR website provides outputs from IHR research projects through a simple and user-friendly web interface. Its current codebase is large and contains many features. This time, instead of adding new features, we will focus on improving the existing ones. The goal of this project is to refactor certain components to enhance reusability.
      Expected results:
      Refactor the codebase
      Improve reusability
      Github discussion: https://github.com/orgs/InternetHealthReport/discussions/47
      Knowledge Prerequisite:
      VueJS
      JavaScript
      CSS
      HTML
      Resources:
      https://github.com/InternetHealthReport/ihr-website
      Project size: 175 hours
      Difficulty: Medium
      Contact: Dimitrios Giakatos (dimitrios@iij.ad.jp)
      IYP Browser
      Brief explanation: The Internet Yellow Pages (IYP) is a knowledge database that aggregates information about various Internet resources, such as ASNs, IP prefixes, and domain names. Currently, we use the Neo4J browser to query the graph, which returns results in four formats: an interactive graph, a table, a raw table, and a JSON object. To enhance the user experience, especially for those unfamiliar with Cypher, we have developed an LLM model and will provide an API to simplify the querying process. Our goal is to develop a new browser that allows users to input either a Cypher query (using the Neo4J API) or an English description (using our LLM API) of the results they wish to obtain from the database. Additionally, we aim to continue providing the default four output formats along with explanations generated by our LLM API.
      Expected results:
      Design a user-friendly, maintainable browser that connects to both the Neo4J API and our LLM API (frontend only, no backend)
      Implement a graph visualizer similar to that of the Neo4J browser
      Implement a data table viewer similar to that of the Neo4J browser
      Allow users to input either a Cypher query or a natural language description
      Provide the LLM-generated explanation text (from our LLM API) alongside the graph visualizer and/or data table viewer
      Github discussion: https://github.com/orgs/InternetHealthReport/discussions/50
      Knowledge Prerequisite:
      Neo4J
      Javascript
      VueJS
      NVL (Neo4j Visualization Library)
      Quasar
      Resources:
      https://github.com/InternetHealthReport/internet-yellow-pages
      http://iyp.iijlab.net/
      https://neo4j.com/docs/nvl/current/
      https://www.npmjs.com/package/@neo4j-nvl/base
      https://neo4j.com/docs/getting-started/graph-visualization/graph-visualization/
      Project size: 175 hours or 350 hours
      Difficulty: Medium
      Contact: Dimitrios Giakatos (dimitrios@iij.ad.jp), Malte Tashiro (malte@iij.ad.jp), Romain Fontugne (romain@iij.ad.jp)
      Traceroute visualization (continuation of GSoC'24)
      Brief explanation: Operators would like to have a better way to visualize latency increases in upstream networks. We have a lot of traceroute data from RIPE Atlas but we miss a good visualization to show traceroute details. The goal of this project is to design and implement a page on IHR to visualize traceroute results from RIPE Atlas. There is some good tools to get inspired from (tracemon and thousand eyes path visualization, having our own would be great so we can integrate it with other tools (e.g. IYP, AS Hegemony).
      Expected results:
      Create a VueJS component that fetch traceroute results from RIPE Atlas
      Display the results in intuitive graphs, showing the IP paths and corresponding RTT values
      Integrate with IYP data
      Github discussion: https://github.com/orgs/InternetHealthReport/discussions/59
      Knowledge Prerequisite:
      Be familiar with existing traceroute code
      Good understanding of traceroute
      Javascript
      VueJS
      Visualization library (i.e. Plotly or D3.js)
      Resources:
      https://www.ihr.live/en/traceroute-monitor
      https://github.com/InternetHealthReport/ihr-website/blob/master/src/views/TracerouteVisualizationTool.vue
      https://atlas.ripe.net/
      https://labs.ripe.net/author/massimo_candela/tracemon-network-debugging-made-easy/
      Project size: 350 hours
      Difficulty: Hard
      Contact: Romain Fontugne (romain@iij.ad.jp), Malte Tashiro (malte@iij.ad.jp), Dimitrios Giakatos (dimitrios@iij.ad.jp)
      Proposal template
      Project
      If appropriate, screenshot or another image
      Brief explanation:
      Expected results:
      Github discussion: https://github.com/orgs/InternetHealthReport/discussions/
      Knowledge Prerequisite:
      Resources:
      https://github.com/InternetHealthReport/
      Project size: 175 hours or 350 hours
      Difficulty: Easy / Medium / Hard
      Contact: (your name and email address for contact)
      Content based on https://community.kde.org/GSoC and available under Creative Commons License SA 4.0
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/internet-health-report/
    idea_list_url: https://github.com/InternetHealthReport/gsoc/blob/main/ideas.md


  - organization_id: 66
    organization_name: Invesalius
    no_of_ideas:
    ideas_content: |
      GSoC 2025 Ideas for InVesalius
      See also the instructions for applying here.
      All the current ideas for GSoC 2025 are listed bellow:
      Add unit tests to InVesalius to ease the process of adding new features
      Use tools like unittest or pytest to add tests to InVesalius code. That way, when adding new features or bug fixes, you can verify that no previous code has been affected. Also run this code when committing and sending pull requests on Github.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies.
      Deliverables:
      Unit tests in InVesalius code
      Github-CI action for running tests when committing or posting a pull-request
      Programming Languages: Python and YAML
      Duration: 175h
      Difficulty level: Intermediate
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com
      References: invesalius/invesalius3#496 and https://realpython.com/python-testing/
      Add type information to functions, methods and classes in InVesalius
      Since python 3.5 it is possible to add type information to the parameters of functions, methods and classes. With this information it is possible to use tools like Mypy to catch calls made with the wrong type. This way you can avoid errors and make your code easier to maintain and grow
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies.
      Deliverables:
      Type information added to InVesalius functions, methods and classes.
      Github-CI action for catching type errors using tools like Mypy
      Programming Languages: Python and YAML
      Duration: 175h
      Difficulty level: Intermediate
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com
      References: invesalius/invesalius3#497, https://docs.python.org/3/library/typing.html and https://mypy-lang.org/
      Add logging and error catching tool
      Tool that allows the user to activate the capture of logs and errors. It should be possible to save the sequence of events in a text file. It will be necessary to add logging capture to all functions and functionalities and their respective levels (debug, info, warn, error or critical).
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies.
      Deliverables:
      Graphic interface integrated to InVesalius that allows the user to activate the tool and save the logs.
      Log support to all InVesalius functions and functionalities.
      Programming Languages: Python
      Duration: 350h
      Difficulty level: Hard
      Mentor: Paulo Henrique Junqueira Amorim - paulojamorim@gmail.com
      References: invesalius/invesalius3#498, https://docs.python.org/3/library/logging.html and https://realpython.com/python-logging/
      Implement UX principles to improve InVesalius usability
      The neuronavigation feature of InVesalius currently does not follow user experience (UX) principles in the user interface and workflow design. The software usability can be significantly improved by applying the basic UX design principles.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies.
      Deliverables:
      Description and documentation of the neuronavigation workflow
      Refactored neuronavigation user controls and settings
      Programming Languages: Python
      Duration: 350h
      Difficulty level: Hard
      Mentor: Victor Hugo Souza - vhosouza@gmail.com
      References: invesalius/invesalius3#506
      Performance optimization of real-time neuronavigation
      The real-time neuronavigation feature of InVesalius currently works based on multi-threading using Queues, Events, and Jobs (look at #242). Optimization (utilizing the least memory, minimizing its CPU time, and offering high speed) is needed to improve neuronavigation performance.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of computer graphics.
      Deliverables:
      Characterize step-by-step code execution time for neuronavigation
      Improve threads’ sleep times
      Investigate: WX GUI becomes slower when navigation is on
      Optimize 3D rendering/updating scene
      Programming Languages: Python
      Duration: 350h
      Difficulty level: Hard
      Mentor: Victor Hugo Souza - vhosouza@gmail.com
      References: invesalius/invesalius3#529 and invesalius/invesalius3#242
      3D edition of masks
      User can edit a mask in InVesalius slice by slice. That is a very repetitive and error prone job. Since InVesalius has 3D visualizations, it's possible to draw over the rendering area and remove the voxels projected in the painted areas.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of computer graphics.
      Deliverables:
      Tool to edit masks using projections.
      Programming Languages: Python
      Duration: 350h
      Difficulty level: Hard
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com
      References: invesalius/invesalius3#91 and https://en.wikipedia.org/wiki/3D_projection
      Harmonize and revamp the cross-platform user interface over MacOS, Linux, and Windows
      Currently, the InVesalius interface is not properly designed for different modes (Light and Dark) mode, especially on MacOS, for example.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of computer graphics.
      Deliverables:
      Unify the color scheme to different modes (light and dark)
      Apply standard and default colors to UI components
      Adjust component sizing that are disrupted across platforms
      Introduce modern icons
      Programming Languages: Python
      Duration: 175h
      Difficulty level: Intermediate
      Mentor: Petrus Kirsten - petrus.kirsten@gmail.com / Victor Malheiro - victorhugomalheiro@gmail.com
      Surface texture
      Add texture to a surface based on the image tissue.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of computer graphics.
      Deliverables:
      Tool to set a texture to a surface.
      Programming Languages: Python
      Duration: 350h
      Difficulty level: Hard
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com
      References: https://en.wikipedia.org/wiki/Texture_mapping
      Extract surface using Dual contouring
      InVesalius uses Marching Cubes to extract surface from volumetric images. It's interesting to have other methods like Marching Tetrahedra and Dual Contouring.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of computer graphics.
      Deliverables:
      Tool to generate surfaces using other methods than Marching Cubes.
      Programming Languages: Python and Cython
      Duration: 350h
      Difficulty level: Hard
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com
      References: https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/ https://en.wikipedia.org/wiki/Marching_tetrahedra https://en.wikipedia.org/wiki/Isosurface
      Improvements in user response (loading and saving files)
      When saving or loading files (except DICOM), InVesalius does not provide any feedback to the user. The goal of this task is to implement a window that displays the progress when loading or saving the different types of files that InVesalius handles. This task also includes replacing the progress bar of the volume rendering functionality.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background in GUI.
      Deliverables:
      Windows with progress bar for the functionalities specified in the referenced issues (references).
      Programming Languages: Python
      Duration: 90h
      Difficulty level: Easy
      Mentor: Paulo Henrique Junqueira Amorim - paulojamorim@gmail.com
      Use Github Actions to create installers for macOS
      Github Actions is used for various softwares to run tests when a commit or pull request is submitted. Also, it can be used to compile software and create binaries ready to be used by the users. The idea in this task is to use Github Actions to create nightly and release InVesalius installers for macOS.
      Requirements: Computer with Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies.
      Deliverables:
      Github action to create nightly and release installers for InVesalius for macOS.
      Programming Languages: Python
      Duration: 175h
      Difficulty level: Intermediate
      Mentor: Paulo Henrique Junqueira Amorim - paulojamorim@gmail.com and Thiago Franco de Moraes - totonixsame@gmail.com
      References: https://docs.github.com/en/actions https://pyinstaller.org/en/stable/
      Convert from Pytorch to ONNX or Tinygrad
      InVesalius uses Pytorch framework to create machine learning based segmentation. The problem is Pytorch is a very large library which makes InVesalius installer and packages very large too. Also, Pytorch has some features not used by InVesalius. ONNX is a format to export machine learning models and a library too. Tinygrad is simple library alternative to Pytorch. Both ONNX and Tinygrad are smaller and enough to InVesalius use.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of Machine Learning and AI.
      Deliverables:
      Conversion of tool using Pytorch to ONNX or Tinygrad.
      Programming Languages: Python
      Duration: 175h
      Difficulty level: Intermediate
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com and Paulo Henrique Junqueira Amorim - paulojamorim@gmail.com
      References: https://github.com/tinygrad/tinygrad and https://onnx.ai/
      Convert from Pip and Conda to UV
      InVesalius uses Pip with requirements.txt. There is also a Conda environment. UV is a fast modern alternative that uses pyproject.toml and other modern Python standards and also can manage Python versions.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies.
      Deliverables:
      Conversion to UV and using documentation
      Conversion of Cython compilation to use pyproject.toml
      Programming Languages: Python
      Duration: 90h
      Difficulty level: Easy
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com and Paulo Henrique Junqueira Amorim - paulojamorim@gmail.com
      References: https://github.com/astral-sh/uv
      Segment brain in its subparts
      Use Machine Learning (like https://deep-mi.org/research/fastsurfer/) or an atlas (like https://yalebrainatlas.github.io/YaleBrainAtlas/) or both to segment brain subparts in MRI images. Segmentation of brain subparts in MRIs is crucial for precise targeting in Transcranial Magnetic Stimulation (TMS). It enables accurate identification of specific brain regions, ensuring stimulation is applied to the correct areas for optimal effectiveness. Proper placement of the TMS coil is essential, and with segmented MRI data, the coil’s position can be precisely aligned with the target brain regions.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of Machine Learning and AI.
      Deliverables:
      Tool to segment brain in its subparts.
      Model weights (if used AI).
      Programming Languages: Python
      Duration: 350h
      Difficulty level: hard
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com and Paulo Henrique Junqueira Amorim - paulojamorim@gmail.com and Renan Matsuda – renan_hiroshi@hotmail.com
      References: https://yalebrainatlas.github.io/YaleBrainAtlas/ and https://deep-mi.org/research/fastsurfer/
      Simultaneous visualization and control of Two Robots for Dual Transcranial Magnetic Stimulation
      Development and integration of the functionality for simultaneous control of two robots, aimed at applying dual-site Transcranial Magnetic Stimulation (TMS) in InVesalius (currently, support is provided for only one TMS coil attached to one robot). This feature is based on the existing implementation for the use of two or more coils, adapting it for multiple robots. The inclusion of this feature not only improves the speed, accuracy, and safety of the stimulatory process, but also enables the scientific exploration of interactive brain networks, by allowing concurrent, targeted TMS pulses to multiple brain areas.
      Requirements: Computer with Windows, Linux, or Mac OS installed. Python programming language and InVesalius library dependencies. A source code editor.
      Deliverables:
      Visualization interface showing the robots' movements integrated into the InVesalius neuronavigation system.
      Coordinate communication between the websocket data receiver, InVesalius brain targets, and GUI.
      Software module for control and synchronization of the two robots.
      Programming Languages: Python
      Duration: 350h
      Difficulty Level: Hard
      Mentor: Renan Matsuda - renan_hiroshi@hotmail.com and Thais Marchetti - thaismarchetti123@gmail.com and Lucas Betioli - lucasantoniobetioli@gmail.com and Victor Malheiro - victorhugomalheiro@gmail.com
      References:
      Neuronavigation: Track multiple coils simultaneously and show stylus/probe #827
      Robot control: https://github.com/biomaglab/tms-robot-control
      Implement neuronavigation capability for transcranial focused ultrasound (tFUS)
      Development and integration of the functionality for neuronavigation of transcranial focused ultrasound transducers (tFUS). InVesalius currently supports only neuronavigation for Transcranial Magnetic Stimulation (TMS) coils. We aim at extending the support to tFUS, which is becoming an important neuromodulation tool to study and and interact with brain function non-invasively. This new feature will significantly extend the user based on InVesalius to support accurate and reproducible neuroscience.
      Requirements: Computer with Windows, Linux, or Mac OS installed. Python programming language and InVesalius library dependencies. A source code editor.
      Deliverables:
      Visualization interface for coregistration of tFUS transducers.
      Targeting and guiding interface for tFUS.
      Minor adjustment to UI/UX considering the tFUS user requirements.
      Programming Languages: Python
      Duration: 350h
      Difficulty Level: Hard
      Mentor: Victor H. Souza - vhosouza@gmail.com and Renan Matsuda - renan_hiroshi@hotmail.com and Victor Malheiro - victorhugomalheiro@gmail.com
      References:
      Neuronavigation: Track multiple coils simultaneously and show stylus/probe #827
      tFUS: tFUS Basics
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/invesalius/
    idea_list_url: https://github.com/invesalius/gsoc/blob/main/gsoc_2025_ideas.md


  - organization_id: 67
    organization_name: JAX and Keras
    no_of_ideas:
    ideas_content: |
      Summer of Code 2025: JAX & Keras Project Ideas
       Request edit access
      +2
       Share
      Sign in
      FileEditViewToolsHelp
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/jax-and-keras/
    idea_list_url: https://docs.google.com/document/d/16uAZEldrXUBHjrszSO22Hr81OmVSjzVXza0szZl6Fxw/edit?usp=sharing

  - organization_id: 68
    organization_name: JSON Schema
    no_of_ideas:
    ideas_content: |
      Welcome to Google Summer of Code 2025 with JSON Schema!
      We are thrilled to announce that JSON Schema will be applying as a mentoring organization for the 2025 Google Summer of Code (GSoC). If accepted, we look forward to collaborating with talented contributors from around the world to advance the field of JSON Schema and open-source technology.
      Timeline and Project Ideas
      The official GSoC 2025 timeline is now live, and our project ideas are on the way! Stay tuned for updates and get ready to explore exciting opportunities to contribute to meaningful, real-world projects.
      Full timeline
      Important dates Deadline
      Organization Applications Open January 27, 2025
      Organization Application Deadline February 11, 2025
      Organizations Announced February 27, 2025
      Potential GSoC contributors discuss application ideas with mentoring organizations February 27 - March 24, 2025
      GSoC contributor application period March 24 - April 8, 2025
      Accepted GSoC Contributor projects announced May 8, 2025
      Contributors work on their Google Summer of Code projects June 2, 2025 - August 25, 2025
      Mentors submit final GSoC contributor evaluations (standard coding period) September 1, 2025 - September 8, 2025
      Initial results of Google Summer of Code 2024 announced September 3, 2025
      Project Ideas
      Here is the list of our 2025 project ideas:
      #874: GSOC 2025 : Build a Java wrapper library for sourcemeta/blaze
      #870: GSoC 2025: Better JSON Schema Errors
      #857: GSoC 2025: Investigating Schema Normalization
      #856: GSoC 2025: Comprehensive JSON Schema linting for encouraging best practices and catching anti-patterns early
      #872: GSOC 2025 : Automated Badge Issuance System For Tour
      #859: GSoC 2025: Adaption of component library in JSON Schema website
      Looking for mentors:
      #868: GSOC 2025 : JSON Schema Visualization Tool - Interactive Graphical Viewer
      Why Choose a JSON Schema Project?
      JSON Schema is a widely adopted and powerful tool in the developer ecosystem. Some of the most active members today joined because of their participation in past GSoC editions, which is a clear evidence of how positive the experience has been for them. Our mentors have extensive mentoring experience, you will have the best support before, during and after the program.
      Contributing to a JSON Schema project offers:
      Real-World Impact: Your work will influence the global developer community.
      Skill Development: Gain hands-on experience with cutting-edge technology and improve your software development skills.
      Collaborative Learning: Work closely with experienced mentors and a welcoming community.
      Professional Growth: Build your network, receive guidance, and showcase your contributions at community events.
      Financial Support: Participants receive a stipend from Google for their contributions.
      How to Apply
      Details about our projects, qualification tasks, and application guidelines will be shared soon. In the meantime, prepare by:
      Familiarizing yourself with JSON Schema.
      Engaging with the community via GitHub and Slack.
      Exploring past GSoC projects to understand the process.
      Getting in Contact
      GitHub: Please use Issues to comment on project ideas, ask questions and collaborate.
      Slack: Please join us in our slack workspace. All GSoC discussions are are hapenning in the #gsoc channel.
      Please see our Code of Conduct
      Getting Help
      Got a problem? Reach out to mentors or the community for assistance. Remember, mentors are listed, but other community members can also lend a hand. When talking to non-mentors:
      Introduce yourself.
      Discuss tasks based on personal interest, not just the contest.
      Explain technical decisions independently.
      Consult mentors for guidance on task evaluation.
      🫶 How to get involved before GSoC?
      If you join our organization before GSoC, we invite you to join us contributing to JSON Schema as a great way to start engaging with the Team, learn about the JSON Schema specification and get to know some of our projects.
      Please check out our Contribution guidelines to know more about how to contribute in each area.
      🏗 GSoC Contributor Guidance
      Please, check-out the GSoC Contributior Guidance
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/json-schema/
    idea_list_url: https://github.com/json-schema-org/community/blob/main/programs/mentoring/gsoc/gsoc-2025.md


  - organization_id: 69
    organization_name: JabRef e.V.
    no_of_ideas:
    ideas_content: |
      JabRef in Google Summer of Code 2025
      JabRef is a powerful, open-source, cross-platform citation and reference management tool designed to help researchers stay organized and efficient. With JabRef, you can effortlessly collect, organize, and manage your literature sources, giving you more time to focus on what truly matters: your research.
      By contributing to JabRef, you contribute to advancing global research. Trusted by over 10,000 researchers worldwide, JabRef plays a vital role in shaping the future of academic and scientific discovery. Your skills and creativity can help push the boundaries of what JabRef can achieve.
      Built in Java, JabRef is designed with a strong emphasis on high-quality, modern, and maintainable code. As a contributor, you’ll have the opportunity to enhance your technical skills, deepen your understanding of Java development, and learn best practices in open source collaboration. Whether you're a beginner or an experienced developer, working on JabRef will help you grow as a programmer while making a meaningful impact on a tool that supports researchers around the globe.
      We are passionate about open source and pride ourselves on fostering collaboration within a diverse and inclusive community. JabRef is dedicated to providing a welcoming environment for newcomers to open source, making it an ideal starting point for anyone eager to contribute. With four successful years of Google Summer of Code (GSoC) participation, we’ve achieved significant milestones in enhancing JabRef as a user-friendly research tool. Each project has been a meaningful step toward empowering researchers worldwide. As a GSoC participant with JabRef, you'll have the opportunity to grow your technical skills, coding expertise, and open source experience. Beyond the invaluable learning, participants receive a stipend from Google and gain access to a global professional network that can open doors for their future.
      Below, you’ll find some project ideas to inspire your contributions to JabRef through GSoC. We’ve also included links to provide more background information and context.
      Links
      What is Google Summer of Code?
      GSoC timeline
      latest proposal deadline: TBA
      coding until: TBA 18:00 UTC (can be extended under conditions)
      GSoC stipends: starting at 750 USD, depending on the country.
      Google's guide on making first contact
      Checklist for items contained in the proposal
      Google's guide on wrting a good proposal
      (All summarized information is tentative. The definitive information is on the linked pages.)
      Projects
      This page lists a number of ideas for potential projects to be carried out by the persons participating in Google Summer of Code 2025. This is by no means a closed list, so the possible contributors can feel free to propose alternative activities related to the project (the list of feature requests and the GitHub issue tracker might serve as an additional source of inspiration). Students are strongly encouraged to discuss their ideas with the developers and the community to improve their proposal until submission (e.g., using the Gitter Channel or the forum). It's also a good idea to start working on one of the smaller issues to make yourself familiar with the contribution process. Successful pull requests increase the chance of being accepted as a mentee.
      Improve handling of ancient documents by OCR and AI
      JabRef, a comprehensive literature management software, currently supports both handling metadata and text-based PDF documents. However, a significant limitation arises with scanned PDFs, particularly historical articles, which are not text-searchable due to their image-based format. This project aims to bridge this gap by integrating advanced OCR (Optical Character Recognition) technology, enabling full-text search in scanned PDFs.
      Useful links:
      A Document AI Package: https://github.com/deepdoctection/deepdoctection
      Hand-written text recognition in historical documents: https://github.com/githubharald/SimpleHTR#handwritten-text-recognition-with-tensorflow
      Java OCR with Tesseract: Baeldung Guide
      OCRmyPDF Installation and Usage: GitHub Repository
      ChatOCR and ChatGPT Integration: Blog Article
      AI-Powered OCR: Addepto Blog
      Tika OCR Integration: Apache Tika Wiki
      Tesseract OCR Library: Official Documentation
      Surya AI powered SOTA OCR, better than Tesseract but coded in python https://github.com/VikParuchuri/surya
      Some aspects:
      Add an option to call an OCR engine from JabRef, e.g., cloud based or local installs
      Define a common interface to support multiple OCR engines
      Provide a good default set of settings for the OCR engines
      Support expert configuration of the settings
      Add the extracted text as a layer to the pdf so that Apache Lucene can parse it
      Add an option to further process the text with Grobid for training and metadata extraction
      Expected outcome:
      A) Develop a common interface within JabRef to accommodate multiple OCR engines, ensuring flexibility and expandability. B) Enable expert users to fine-tune OCR settings, catering to specific needs or document formats.
      C) Incorporate the OCR-extracted text as a searchable layer in PDFs, allowing Apache Lucene to index and look for the content.
      Skills required:
      Proficiency in Java programming.
      A keen interest and curiosity in document processing and AI technologies.
      Possible mentors:
      @Siedlerchr, @InAnYan, @calixtus
      Project size:
      175h (medium)
      Integrating JabRef's Integrity Check with VS Code via Language Server Protocol (LSP)
      Synopsis
      JabRef is a widely used open-source reference manager supporting BibTeX and BibLaTeX. One of its features is the Integrity Check, which helps users identify potential issues in their bibliographic entries. This project aims to leverage JabRef's Integrity Check to provide real-time feedback in Visual Studio Code (VS Code) by implementing a Language Server Protocol (LSP)-based extension.
      Benefits to the Community
      Currently, users rely on JabRef’s graphical interface to run integrity checks manually. By integrating these checks into VS Code, users can receive immediate feedback while editing BibTeX/BibLaTeX files, improving the quality of bibliographic data and ensuring compliance with best practices. The integration will also make JabRef’s functionality more accessible to users who prefer VS Code for LaTeX editing.
      Deliverables
      A VS Code extension that communicates with an LSP server to analyze BibTeX/BibLaTeX files.
      An LSP server that integrates JabRef’s Integrity Check and returns structured diagnostics (e.g., warnings and errors).
      Real-time feedback in VS Code’s Problems panel, highlighting issues in bibliography files.
      Unit tests and documentation to ensure maintainability and ease of use.
      Technical Details
      The LSP server will be implemented in Java, leveraging JabRef’s existing Integrity Check logic.
      The VS Code extension will be written in TypeScript and communicate with the LSP server.
      Diagnostics will be provided in real-time as users edit .bib files.
      Optional: Quick fixes for common integrity issues.
      Related work: https://plugins.jetbrains.com/plugin/9473-texify-idea offers BibTeX error reporting in IntelliJ idea.
      Expected Outcomes
      By the end of GSoC, the VS Code extension should be functional and capable of detecting integrity issues in .bib files. The project will enhance the JabRef ecosystem by expanding its usability in modern LaTeX workflows.
      First steps
      Get to know to Check Integrity
      Try to convert the result of the check integrity to errorformat: file:col:line: message
      Serve the error format file using efm-langserver
      Then, you have an initial skilset on the JabRef API and language servers. then, you can include an LSP into JabRef.
      Skills Required
      Java (for LSP server and integration with JabRef)
      TypeScript (for VS Code extension development)
      Experience with Language Server Protocol (LSP) is a plus
      Familiarity with LaTeX/BibTeX/BibLaTeX is beneficial
      Possible mentors:
      @koppor, @calixtus
      Project size:
      175h (medium)
      Welcome Walkthrough
      This project aims to create an engaging and informative first start screen for JabRef, enhancing the initial user experience and showcasing the best features of the software. This screen will differ from the standard interface displayed when no database is open, providing a tailored introduction for new users.
      Moreover, this project aims for adding various walkthrouhgs through JabRef's features: Users should be guided to the interesting features of JabRef (instead of having to read the the documentation)
      For walkthroughts, read on at https://www.appcues.com/blog/the-5-best-walkthrough-examples.
      Hints on the welcome tab
      Configuration of Paper Directory:
      Implement a feature allowing users to easily set up and manage their paper directory.
      This should include a dialog asking for a directory if none is set.
      Integration of Online Services:
      Include options for update checks, connecting with online services like Grobid, fetchers, and full-text search capabilities.
      Incorporate telemetry features with a clear and concise privacy statement.
      Creation of Example Library:
      Develop a feature to create an example library, helping new users quickly understand JabRef's functionality.
      Community Engagement Tools -> https://github.com/JabRef/jabref/pull/12461#issuecomment-2708900164
      Add links to the JabRef forum for support and Mastodon for community interaction.
      Donation Prompt:
      Encourage support for JabRef through a tastefully integrated donation option.
      User Group-Specific Defaults:
      Offer pre-configured default preferences catering to different user groups, such as "relaxed users" wanting all features, and "pro-users" who prefer managing BibTeX files without additional features
      (These are just ideas, during the pro, this needs to be refined )
      Expected Outcome:
      A welcome dialog with nice and welcoming UX.
      Multiple walkthroughs through JabRef's features.
      Examples:
      The welcome dialog should ask for: Configuration of Paper Direction, Integration of Online Services (Grobid, Telemetry), Creation of Example Library, Community Engagement Tool, Link to Donation page
      The welcome dialog should offer some sensitive User Group-Specific Defaults: Offer pre-configured default preferences catering to different user groups, such as "relaxed users" wanting all features, and "pro-users" who prefer managing BibTeX files without additional features (as per Issue #9491).
      Walk through: Guide through collecting papers and refining the bibliography data - until the publication of data on an HTML page
      Skills required:
      Java, JavaFX
      Understanding of (potential) JabRef users
      Possible Mentors:
      @koppor, @tobiasdiez
      Project size:
      90h (small) - if only welcome tab is improved (and some more minor JabRef fixes are made)
      175h (medium) - if walkthroughs are made
      The GSoC proposal should include one initial idea of a walk through
      Issue: https://github.com/JabRef/jabref/issues/12664
      Using PostgreSQL as full backend for JabRef
      Currently, JabRef holds all entries in memory. It even converts LaTeX to Unicode and vice versa to support better search. While this is a great UX, this leads to a huge memory consumption. The more "proper" way is to use a database (such as PostgreSQL) to store the entries. Then, not all entries need to be loaded in memory. The first step is to introduce a data-access layer: The maintable should read from SQL database, not from all in-memory. Possible future work may be: https://www.zotero.org/support/dev/client_coding/direct_sqlite_database_access and https://github.com/zotero/zotero/blob/main/resource/schema/userdata.sql.
      There can be an initial phase to evluate whether PostgreSQL is the right DBMS as backend for JabRef. For instance, DuckDB and SQLite were also discussed. Currently, PostgeSQL turned out best (especially for handling regular expression search on the database itself), but things may have changed in 2025.
      This is issue https://github.com/JabRef/jabref/issues/12708
      Skills required:
      PostgreSQL, Java, JavaFX
      Possible Mentors:
      @koppor, @InAnYan, @calixtus
      Project size:
      175h (medium)
      Improved LibreOffice-JabRef integration
      Description:
      JabRef can connect to LibreOffice to offer premier reference management by allowing users to cite library entries directly into the document, and then generate bibliographies based on the cited entries. See JabRef LibreOffice Integration.
      We have a collection of independent projects available for the LibreOffice/OpenOffice integration feature of JabRef.
      BST style support: Currently, custom styles (JStyles) and CSL styles are supported. In the LaTeX-world, BST styles (specified via .bst files) are still popular. JabRef already has BST support, but it is currently not accessible via the UI.
      Expected deliverable: It should be possible to select a .bst file, which is then used for rendering into the LibreOffice document. [Details: #624]
      Improved support for CSL styles: Support for CSL styles in the LibreOffice integration has been a popular new feature in JabRef that users look forward to. This project aims to enhance the integration further by introducing:
      a) Footnote-based citation support for CSL styles: Currently, using CSL styles in footnotes of the LibreOffice document causes unexpected behavior, especially for numeric styles. There should be a proper definition of the "global order" of the citations so that they can be used in footnotes. This problem is already solved for JStyles (see a high-level overview here), so the solution needs to be extended/adapted for CSL styles (and BST styles, if project 1 is also undertaken).
      Expected deliverable: It is possible to use CSL styles in the footnotes of the documents, without any unexpected/broken ordering in the bibliography or numeric citations. [Tracking issue: #12484]
      b) Support for custom CSL styles: Sometimes, users wish to use external (or their own custom designed) CSL style files with JabRef that have not been (or not yet been) officially accepted by the Zotero-CSL community. There are plenty of websites/tools available that enable users to create custom CSL styles, enabling full flexibility in terms of how they want to style their citations. Adding support for using external CSL style files would thus be beneficial for such users.
      Expected deliverable: It is possible to load an external CSL style file in JabRef and use it for citing. [Tracking issue: #12337]
      Cross-compatibility with other reference management software: In case of CSL styles, reference management software like Zotero and Mendeley can read each other's citations in LibreOffice. This is made possible by following a specific format of document annotations, embedding information in CSL JSON. In JabRef, the internal format of references is currently a JabRef-custom format. It should be changed to a format used by Zotero, so that cross-compatibility can be ensured. See the discussion at https://github.com/JabRef/jabref/issues/2146#issuecomment-891432507 for details. This includes: i) Implementation of that format, ii) Implementation of a converter from the "old" JabRef-Format to the new one. The converter could be implemented within OpenOffice (similar to JabRef_LibreOffice_Converter).
      Expected deliverable: One can seamlessly switch working with LibreOffice documents having citations from Zotero and JabRef.
      Seamless citation style type switching: JabRef in LibreOffice should support auto-updation of references when switching from CSL-based formats to JStyle (or BST)-based formats and back. Currently, if the user messes up and realizes that they had to use another style family, the workaround is to re-cite all entries again with the new style, then refresh the bibliography. This may not be very user-friendly when citation styles need to be updated when submitting papers to different journals (one use-case), or simply because of last-minute change in decisions. For this project, the starting step will be unifying the "reference mark" (document annotation) format for all these style types, so that the entry information can be parsed across styles. This project thus goes very well coupled with Project 1.
      Expected deliverable: On changing style type (CSL/BST/JStyle), all references in the documents should seamlessly adapt to the new style.
      Skills required:
      Java, JavaFX
      Possible Mentors:
      @Siedlerchr, @subhramit
      Project size:
      350h (large): If (Project 1 + Project 2 + Project 3 + Project 4)
      175h (medium): If (Project 1 + Project 2) OR (Project 2 + Project 3) OR (Project 1 + Project 3)
      90h (small): If Project 1 OR Project 2 OR Project 3
      Improved SLR Support
      Description:
      With the ever-growing number of publications in computer science and other fields of research, conducting secondary studies becomes necessary to summarize the current state of the art. For software engineering research, Kitchenham popularized the systematic literature review (SLR) method to address this issue. The main idea is to systematically identify and analyze the majority of relevant publications on a specific topic. This is usually an activity that takes extensive manual effort. Some tool support does exist, but the full potential of tools has not been exploited yet. JabRef also offers basic functionality for systematic literature reviews that is used by a number of researchers to systematically "harvest" related work based on the fetching capabilities of JabRef. While using the feature, various additional feature requests came up. For instance, created search queries are currently transformed internally by JabRef to the query format of the publisher. It should also be possible to directly input a query at the publisher site, e.g., for IEEE or ACM.
      More background information: Paper: Systematic Literature Tools: Are we there yet?; Presentation.
      One key aspect would be the improvement of the fetcher infrastructure in JabRef to better adapt to new and changing Publisher/Journal websites and to offer a more direct integration. As an inspiration, see BibDesk.
      Expected outcome:
      An advanced SLR functionality, where a researcher is supported to execute a systematic-literature-review.
      We did an initial project organization at https://github.com/users/koppor/projects/2.
      Skills required:
      Java, JavaFX
      Possible mentors:
      @koppor, @calixtus
      Project size:
      175h (medium)
      Improved Journal Abbreviations
      Currently, JabRef has a single list of journal abbreviations. This list is a combined list of the .csv files at https://github.com/JabRef/abbrv.jabref.org/tree/main/journals. Instead of the dropdown of JabRef should not show a single "JabRef built in list", but should show the various lists we offer: built-in lists, external lists, custom lists. Then, one can enable and disable with a click. This eases the users to find issues in abbreviation lists and allows users to customize the lists according to their field (e.g., physics, information science, ...).
      Fore more context, see: https://github.com/JabRef/jabref/issues/12364
      Skills required:
      Java, JavaFX
      Possible Mentors:
      @calixtus, @koppor
      Project size:
      90h (small)
      Expected Outcome:
      A UI view which allows selecting/including journal abbreviations by category.
      {Your own project}
      You can propose another projects. JabRef offers various places where it can be improved. Think as a user or talk to other users. The following places are a good start:
      Switch to Apache Velocity: https://github.com/JabRef/jabref/issues/12418
      Big projects: https://github.com/JabRef/jabref/issues?q=sort%3Aupdated-desc+state%3Aopen+label%3A%22size%3A+big%22
      Feature requests prioritized: https://github.com/orgs/JabRef/projects/6
      General list of feature requests: http://discourse.jabref.org/c/features
      Candidates of university projects, the large ones: https://github.com/orgs/JabRef/projects/3/views/3?filterQuery=status%3A%22free+to+take%22+size-of-project%3Alarge&sortedBy%5Bdirection%5D=desc&sortedBy%5BcolumnId%5D=8246261
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/jabref-e.v./
    idea_list_url: https://github.com/JabRef/jabref/wiki/GSoC-2025-ideas-list


  - organization_id: 70
    organization_name: JdeRobot
    no_of_ideas:
    ideas_content: |
      GSoC 2025
      TOC GSoC-2025
      Ideas list
      Project #1: Robotics-Academy: support for solutions directly using ROS2 topics
      Project #2: Robotics-Academy: CI & Testing
      Project #3: Robotics-Academy: improve Computer Vision exercises, including with real cameras
      Project #4: Robotics-Academy: new exercise on End-to-End Visual Control of an Autonomous Vehicle using DeepLearning
      Project #5: VisualCircuit: Improving Functionality & Expanding the Block Library
      Project #6: Robotics Academy: using the Open3DEngine as robotics simulator
      Project #7: Robotics Academy: improvement of Gazebo scenarios and robot models
      Project #8: Robotics Academy: improvement of industrial robotics exercises with MoveIt2 and ROS2
      Project #9: BT-Studio: a tool for programming robots with Behavior Trees
      Project #10: Extend DetectionMetrics: GUI, CI Workflow, and Object Detection
      Application instructions for GSoC-2025
      Requirements
      Programming tests
      Send us your information
      Previous GSoC students
      How to increase your chances of being selected in GSoC-2025
      RTFM
      Robotics applications are typically distributed, made up of a collection of concurrent asynchronous components which communicate using some middleware (ROS messages, DDS…). Building robotics applications is a complex task. Integrating existing nodes or libraries that provide already solved functionality, and using several tools may increase the software robustness and shorten the development time. JdeRobot provides several tools, libraries and reusable nodes. They have been written in C++, Python or JavaScript. They are ROS-friendly and full compatible with ROS2-Humble (and Gazebo Harmonic).
      Our community mainly works on three development areas:
      Education in Robotics. RoboticsAcademy is our main project. It is a ROS-based framework to learn robotics and computer vision with drones, autonomous cars…. It is a collection of Python programmed exercises and challenges for engineering students.
      Robot Programming Tools. For instance, BT-Studio, for robot programming with Behavior Trees; VisualCircuit for robot programming with connected blocks, as in electronic circuits, in a visual way.
      Machine Learning in Robotics. For instance, the BehaviorMetrics tool for assessment of neural networks in end-to-end autonomous driving. Another example is DetectionMetrics tool for evaluation of visual detection neural networks and algorithms.
      Ideas list
      This open source organization welcomes contributors in these topics:
      Project #1: Robotics-Academy: support for solutions directly using ROS2 topics
      Brief explanation: Robotics-Academy is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS 2 or OpenCV.
      Nowadays, Robotics Academy offers the student up to 26 exercises, and another 11 prototype exercises. All of them come ready to use in the RoboticsAcademy docker image (RADI). The only requirement for the students its to download the docker image, all the dependencies are installed inside the RADI.
      Currently, exercises can be solved using Python without any knowledge of ROS 2 thank to our Hardware Abstraction Layer (HAL). However, some students asked for the possibility to use (and learn) ROS 2 interfaces (topics and services) while coding the solution. Project #2 will explore new ways of coding the exercise solution, where a few changes like ROS 2 spin control or editor autocompletions are required.
      Skills required/preferred: React, Python, ROS2.
      Difficulty rating: medium
      Expected results: New way of coding your solutions in RoboticsAcademy using ROS 2 topics
      Expected size: 90h
      Mentors: Pedro Arias (pedro.ariasp AT upm.es) and Apoorv Garg (apoorvgarg.ms AT gmail.com)
      Project #2: Robotics-Academy: CI & Testing
      Brief explanation: Robotics-Academy is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision.
      Project #2 seeks to identify and address potential issues early on, fostering the maintainability and reliability of its software. This commitment to improving the quality of the software will be achieved through the implementation of automated testing and continuous integration (CI) processes. The project will also include the development of a testing strategy and the implementation of a CI pipeline.
      Skills required/preferred: Docker, GitHub actions, Python, JavaScript, pytest, Selenium
      Difficulty rating: medium
      Expected results: Tests on RAM, RI and RA
      Expected size: 350h
      Mentors: Pedro Arias (pedro.ariasp AT upm.es), Pawan Wadhwani (pawanw17 AT gmail.com) and Miguel Fernandez (miguel.fernandez.cortizas AT upm.es)
      Project #3: Robotics-Academy: improve Computer Vision exercises, including with real cameras
      Brief explanation: As of now, Robotics-Academy includes two deprecated Computer Vision exercises: ColorFilter and OpticalFlow Teleoperator. These exercises allow users to learn de foundations of image processing using OpenCV library. A Work-In-Progress from the JdeRobot Computer Vision Working Group is the multiplatform support of real cameras in RoboticsAcademy exercises (it works on Linux, Windows and MacOS machines), using WebRTC.
      The main objective of this project is to prepare several exercises in RoboticsAcademy about Computer Vision (including the update of the previous two) which can be performed with real camera from the browser.
      Skills required/preferred: ComputerVision, OpenCV, React, Python
      Difficulty rating: easy
      Expected results: new exercises on ComputerVision in Robotics-Academy, including with real cameras.
      Expected size: 90h
      Mentors: David Pascual (d.pascualhe AT gmail.com) and David Pérez (david.perez.saura AT upm.es)
      Project #4: Robotics-Academy: new exercise on End-to-End Visual Control of an Autonomous Vehicle using DeepLearning
      Brief explanation: The goal of this project is to develop a new deep learning exercise focused on visual robotic control in the context of Robotics-Academy. We will create a web-based interface that allows users to upload a trained model, which will take camera input from a drone or car and output the linear speed and angular velocity of the vehicle. The controlled robot and its environment will be simulated using Gazebo. The objectives of this project include:
      Updating the web interface to accept models trained with PyTorch/TensorFlow.
      Building new widgets to monitor exercise results.
      Preparing a simulated environment.
      Coding the core application that feeds input data to the trained model and returns the results.
      Training a naive model to demonstrate how the exercise can be solved.
      This new exercise may utilize the infrastructure developed for the “Human detection” Deep Learning exercise. The following videos showcase one of our current web-based exercises and a visual control task solved using deep learning:
      Skills required/preferred: Python, Deep Learning, Gazebo, React, ROS2
      Difficulty rating: medium
      Expected results: a web-based exercise for robotic visual control using deep learning
      Expected size: 350h
      Mentors: David Pascual ( d.pascualhe AT gmail.com ) and Pankhuri Vanjani (pankhurivanjani AT gmail.com)
      Project #5: VisualCircuit: Improving Functionality & Expanding the Block Library
      Brief explanation: VisualCircuit allows users to program robotic intelligence using a visual language similar to electronic circuits, simplifying the creation of code for robotics applications such as Deep Learning, ROS, and more.
      Over the past few years, we have focused on making VisualCircuit more robust by resolving Nested Blocks (multi-level blocks) with the Block Composition feature, developing a working prototype for dockerized execution of robotics applications directly from the browser, migrating the old POSIX IPC implementation to a cross-platform compatible Python Shared Memory implementation, and more.
      Now, for GSoC 2025, the goal of the project is to further refine VisualCircuit by improving Shared Memory, Block Composition, and other features, developing more real-world robotics applications utilizing the latest functionalities of VC, expanding the block library to cater to a larger audience, and enhancing automated testing. Additionally, we aim to address other issues such as implementing Undo and Redo functionality, adding more keyboard shortcuts for faster circuit creation, and making various other improvements. You can read further about the tool on the website.
      Skills required/preferred: ROS2, Gazebo, Python, TypeScript
      Difficulty rating: medium
      Expected results: Expanding Block library for VisualCircuit, improving automated testing using GitHub Actions and creating real world robotics applications developed with latest functionalities of VC and resolving other major issues.
      Expected size: 175h
      Mentors: Toshan Luktuke (toshan1603 AT gmail.com), Pankaj Borade (borade.pankaj825 AT gmail.com) and Suhas Gopal.
      Project #6: Robotics Academy: using the Open3DEngine as robotics simulator
      Brief explanation: Open 3D Engine (O3DE) is an Apache 2.0-licensed multi-platform 3D engine that enables developers and content creators to build AAA games, cinema-quality 3D worlds, and high-fidelity simulations. It supports also simulation of most common robot sensors and actuators. The idea of this project is to integrate Open3DEngine into the RoboticsAcademy framework, with at least one exercise using it instead of Gazebo.
      Skills required/preferred: C++ programming, ROS
      Difficulty rating: Medium
      Expected results: A new robotics exercise in RoboticsAcademy using the Open3DEngine
      Expected size: 175h
      Repository Link - Open 3D Engine, RoboticsAcademy, RoboticsInfrastructure
      Mentors: José M. Cañas (josemaria.plaza AT gmail.com) and Jan Hanca ( jan.hanca AT googlemail.com )
      Project #7: Robotics Academy: improvement of Gazebo scenarios and robot models
      Brief Explanation: Currently Robotics Academy offers the student up to 26 exercises, and another 11 prototype exercises. The main goal of this project is to improve the current Gazebo scenarios and robot models for many the exercises making them more appealing and realistic without increasing too much the required computing power for rendering. For instance the world model of the FollowLine exercise will be enhanced in order to have a 3D race circuit and several models will be reviewed to be low poly (= faster to simulate).
      Skills required/preferred: experience with Gazebo, SDF, URDF, ROS2 and Python
      Difficulty rating: easy
      Expected results: New Gazebo scenarios
      Expected size: small (~90h)
      Mentors: Pedro Arias (pedro.ariasp AT upm.es) and Shashwat Dalakoti (shash.dal623 AT gmail.com)
      Project #8: Robotics Academy: improvement of industrial robotics exercises with MoveIt2 and ROS2
      Brief explanation: A few years ago we developed some exercises on industrial robots using MoveIt1 and ROS1-Noetic. A Work-In-Progress from the JdeRobot Industrial Robotics Working Group is the support in RoboticsAcademy to MoveIt2 and ROS2. A proof of concept has already been developed and it opens the door to new applications with manipulators (pick-and-place, palletizing…). Developing an easy API for the programming of industrial robots, similar to other solutions such as RAPID from ABB is an open topic. The main goal of this project is to integrate, refine this support and develop a new exercise regarding manipulation.
      Skills required/preferred: Gazebo, URDF, ROS2, MoveIt2
      Difficulty rating: medium
      Expected results: updated and operating new exercise on industrial robot manipulation
      Expected size: medium (~175h)
      Mentors: Diego Martín (diego.martin.martin AT gmail.com) and Pankhuri Vanjani (pankhurivanjani AT gmail.com)
      Project #9: BT-Studio: a tool for programming robots with Behavior Trees
      Brief explanation: Behavior Trees is a recent paradigm for organizing robot deliberation. There are brilliant open source projects such as BehaviorTrees.CPP and PyTrees. Our BT-Studio has been created to provide a web based graphical editor of Behavior Trees. It also includes a conversor to Python language, the dockerized execution of the generated robotics application from the browser and supports subtrees (a feature created along a previous GSoC-2024 project).
      The goal of this GSoC proposed project is to develop a Behavior Tree library, a collection of example robotics applications and further refine the tool.
      Skills required/preferred: Python, ROS, Gazebo
      Difficulty rating: medium
      Expected results: Behavior Trees library for BT-Studio and several example robotics applications developed with them.
      Expected size: 175h
      Mentors: José M. Cañas (josemaria.plaza AT gmail.com) and Oscar Martínez (oscar.robotics AT tutanota.com)
      Project #10: Extend DetectionMetrics: GUI, CI Workflow, and Object Detection
      Brief explanation: DetectionMetrics is a toolkit for evaluating perception models across frameworks and datasets. Past GSoC projects (Vinay Sharma, Jeevan Kumar) contributed to its first stable release, published in Sensors (Paniego et al., 2022). Recently, we revamped the tool to improve usability and installation—check it out here! Currently, DetectionMetrics functions as both a Python library and CLI, focusing on the quantitative evaluation of image and LiDAR segmentation models, with plans to expand into object detection. It supports PyTorch and TensorFlow models, along with multiple public datasets. Its modular design allows easy integration of new models and datasets. While redesigning the core functionality, some useful features were lost. This project aims to bring them back and enhance DetectionMetrics by:
      Recovering object detection evaluation support, including metrics like mAP and IoU. This involves restoring compatibility with COCO-style and Pascal VOC-style datasets and implementing necessary pipeline adjustments.
      Building a GUI for visualizing dataset samples (images, point clouds) and evaluation results (IoU, confusion matrices, etc.). Ideally, it will also provide an interactive interface for launching batched evaluation jobs. Possible tools: Streamlit, Gradio.
      Setting up a Continuous Integration (CI) workflow to automate testing, documentation generation, and versioning using Sphinx, pytest, and GitHub Actions.
      Since this new version of DetectionMetrics is still in its early stages, your contributions will have a lasting impact on a tool already featured in a scientific journal!
      Skills required/preferred: Python, GitHub Actions, PyTorch, Deep Learning
      Difficulty rating: Medium
      Expected results: A brand-new GUI and CI workflow for DetectionMetrics
      Expected size: Long (~350h)
      Mentors: David Pascual Hernández (d.pascualhe AT gmail.com), Sergio Paniego (sergiopaniegoblanco AT gmail.com), Santiago Montiel Marín (santiago.montiel AT uah.es)
      Application instructions for GSoC-2025
      We welcome students to contact relevant mentors before submitting their application into GSoC official website. If in doubt for which project(s) to contact, send a message to jderobot AT gmail.com We recommend browsing previous GSoC student pages to look for ready-to-use projects, and to get an idea of the expected amount of work for a valid GSoC proposal.
      Requirements
      Git experience
      C++ and Python programming experience (depending on the project)
      Programming tests
      Project #1 #2 #3 #4 #5 #6 #7 #8 #9 #10
      Academy (A) X X X X X X X X X X
      Python (B) X X X X X X X X X X
      ROS2 (C) X X O X X X X X X X
      React (D) X O X X O O * * O O
      
      Where:  
      * Not applicable
      X Mandatory
      O Optative
      Before accepting any proposal all candidates have to do these programming challenges:
      Note: Python Programming test for GSoC 25 will be updated soon.
      (A) RoboticsAcademy challenge
      (B) Python challenge (To be updated soon)
      (C) ROS2 challenge
      (D) React challenge
      Send us your information
      AFTER doing the programming tests, fill this web form with your information and challenge results. Then you are invited to ask the project mentors about the project details. Maybe we will require more information from you like this:
      Contact details
      Name and surname:
      Country:
      Email:
      Public repository/ies:
      Personal blog (optional):
      Twitter/Identica/LinkedIn/others:
      Timeline
      Now split your project idea in smaller tasks. Quantify the time you think each task needs. Finally, draw a tentative project plan (timeline) including the dates covering all period of GSoC. Don’t forget to include also the days in which you don’t plan to code, because of exams, holidays etc.
      Do you understand this is a serious commitment, equivalent to a full-time paid summer internship or summer job?
      Do you have any known time conflicts during the official coding period?
      Studies
      What is your School and degree?
      Would your application contribute to your ongoing studies/degree? If so, how?
      Programming background
      Computing experience: operating systems you use on a daily basis, known programming languages, hardware, etc.
      Robot or Computer Vision programming experience:
      Other software programming:
      GSoC participation
      Have you participated to GSoC before?
      How many times, which year, which project?
      Have you applied but were not selected? When?
      Have you submitted/will you submit another proposal for GSoC 2025 to a different org?
      Previous GSoC students
      Prajyot Jadhav (GSoC-2024) Robotics-Academy: migration to Gazebo Fortress
      Mihir Gore (GSoC-2024) Robotics-Academy: improve Deep Learning based exercises
      Pankaj Borade (GSoC-2024) VisualCircuit: block library
      Óscar Martínez (GSoC-2024) BT-Studio: a tool for programming robots with Behavior Trees
      Zebin Huang (GSoC-2024) End-to-end autonomous vehicle driving based on text-based instructions: research project regarding Autonomous Driving + LLMs
      Pawan Wadhwani (GSoC-2023) Robotics Academy: migration to ROS2 Humble
      Meiqi Zhao (GSoC 2023) Obstacle Avoidance for Autonomous Driving in CARLA Using Segmentation Deep Learning Models
      Siddheshsingh Tanwar (GSoC 2023) Dockerization of Visual Circuit
      Prakhar Bansal (GSoC 2023) RoboticsAcademy: Cross-Platform Desktop Application using ElectronJS
      Apoorv Garg (GSoC-2022) Improvement of Web Templates of Robotics Academy exercises
      Toshan Luktuke (GSoC-2022) Improvement of VisualCircuit web service
      Nikhil Paliwal(GSoC-2022) Optimization of Deep Learning models for autonomous driving
      Akshay Narisetti(GSoC-2022) Robotics Academy: improvement of autonomous driving exercises
      Prakarsh Kaushik(GSoC-2022) Robotics Academy: consolidation of drone based exercises
      Bhavesh Misra (GSoC-2022) Robotics Academy: improve Deep Learning based Human Detection exercise
      Suhas Gopal (GSoC-2021) Shifting VisualCircuit to a web server
      Utkarsh Mishra (GSoC-2021) Autonomous Driving drone with Gazebo using Deep Learning techniques
      Siddharth Saha (GSoC-2021) Robotics Academy: multirobot version of the Amazon warehouse exercise in ROS2
      Shashwat Dalakoti (GSoC-2021) Robotics-Academy: exercise using Deep Learning for Visual Detection
      Arkajyoti Basak (GSoC-2021) Robotics Academy: new drone based exercises
      Chandan Kumar (GSoC-2021) Robotics Academy: Migrating industrial robot manipulation exercises to web server
      Muhammad Taha (GSoC-2020) VisualCircuit tool, digital electronics language for robot behaviors.
      Sakshay Mahna (GSoC-2020) Robotics-Academy exercises on Evolutionary Robotics.
      Shreyas Gokhale (GSoC-2020) Multi-Robot exercises for Robotics Academy In ROS2.
      Yijia Wu (GSoC-2020) Vision-based Industrial Robot Manipulation with MoveIt.
      Diego Charrez (GSoC-2020) Reinforcement Learning for Autonomous Driving with Gazebo and OpenAI gym.
      Nikhil Khedekar (GSoC-2019) Migration to ROS of drones exercises on JdeRobot Academy
      Shyngyskhan Abilkassov (GSoC-2019) Amazon warehouse exercise on JdeRobot Academy
      Jeevan Kumar (GSoC-2019) Improving DetectionSuite DeepLearning tool
      Baidyanath Kundu (GSoC-2019) A parameterized automata Library for VisualStates tool
      Srinivasan Vijayraghavan (GSoC-2019) Running Python code on the web browser
      Pankhuri Vanjani (GSoC-2019) Migration of JdeRobot tools to ROS 2
      Pushkal Katara (GSoC-2018) VisualStates tool
      Arsalan Akhter (GSoC-2018) Robotics-Academy
      Hanqing Xie (GSoC-2018) Robotics-Academy
      Sergio Paniego (GSoC-2018) PyOnArduino tool
      Jianxiong Cai (GSoC-2018) Creating realistic 3D map from online SLAM result
      Vinay Sharma (GSoC-2018) DeepLearning, DetectionSuite tool
      Nigel Fernandez GSoC-2017
      Okan Asik GSoC-2017, VisualStates tool
      S.Mehdi Mohaimanian GSoC-2017
      Raúl Pérula GSoC-2017, Scratch2JdeRobot tool
      Lihang Li: GSoC-2015, Visual SLAM, RGBD, 3D Reconstruction
      Andrei Militaru GSoC-2015, interoperation of ROS and JdeRobot
      Satyaki Chakraborty GSoC-2015, Interconnection with Android Wear
      How to increase your chances of being selected in GSoC-2025
      If you put yourself in the shoes of the mentor that should select the student, you’ll immediately realize that there are some behaviors that are usually rewarded. Here’s some examples.
      Be proactive: Mentors are more likely to select students that openly discuss the existing ideas and / or propose their own. It is a bad idea to just submit your idea only in the Google web site without discussing it, because it won’t be noticed.
      Demonstrate your skills: Consider that mentors are being contacted by several students that apply for the same project. A way to show that you are the best candidate, is to demonstrate that you are familiar with the software and you can code. How? Browse the bug tracker (issues in github of JdeRobot project), fix some bugs and propose your patch submitting your PullRequest, and/or ask mentors to challenge you! Moreover, bug fixes are a great way to get familiar with the code.
      Demonstrate your intention to stay: Students that are likely to disappear after GSoC are less likely to be selected. This is because there is no point in developing something that won’t be maintained. And moreover, one scope of GSoC is to bring new developers to the community.
      RTFM
      Read the relevant information about GSoC in the wiki / web pages before asking. Most FAQs have been answered already!
      Full documentation about GSoC on official website.
      FAQ from GSoC web site.
      If you are new to JdeRobot, take the time to familiarize with the JdeRobot.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/jderobot/
    idea_list_url: https://jderobot.github.io/activities/gsoc/2025#ideas-list
  

  - organization_id: 71
    organization_name: Jenkins
    no_of_ideas: 11
    ideas_content: |
      
      AI-Powered Chatbot for Quick Access to Jenkins Resources
      Develop an AI-based chatbot to provide users with quick and intuitive access to Jenkins documentation, plugins, and community resources..
      Potential Mentor(s):
      Vutukuri Sreenivas
      Kris Stern
      Ashutosh Singh
      
      Plugins Natural Language Processing (NLP), Python, JavaScript/TypeScript, Jenkins Plugin Development, Machine Learning
      AI-Powered Chatbot for Quick Access to Jenkins Resources 
      Project goal: Develop an AI-based chatbot to provide users with quick and intuitive access to Jenkins documentation, plugins, and community resources.

      Skills to study/improve: Natural Language Processing (NLP), Python, JavaScript/TypeScript, Jenkins Plugin Development, Machine Learning

      Details 
      As Jenkins continues to evolve, users often seek efficient ways to navigate its extensive documentation, plugins, and community discussions. This project proposes the development of an AI-powered chatbot integrated into the Jenkins interface, enabling users to retrieve information swiftly through natural language queries.

      Project Description

      The aim is to create a Jenkins plugin that embeds a chatbot capable of understanding and responding to user inquiries about Jenkins. Leveraging Natural Language Processing (NLP) and Machine Learning (ML) techniques, the chatbot will interpret user questions and provide relevant information from official documentation, plugin repositories, and community forums.

      Benefits to the Community

      Enhanced User Experience: Users can obtain information quickly without leaving the Jenkins environment.

      Improved Accessibility: Simplifies the learning curve for newcomers by providing instant answers to common questions.

      Increased Productivity: Reduces the time spent searching for resources, allowing users to focus on development and deployment tasks.

      Comparable Solutions

      While there are existing AI chatbots in various domains, an AI assistant tailored specifically for Jenkins is limited. A community discussion highlighted interest in developing a Jenkins Assistant plugin, indicating a demand for such a tool. This project aims to fill that gap by offering a specialized solution within the Jenkins ecosystem.

      Project Scope

      Chatbot Development: Implement NLP models to process and understand user queries related to Jenkins.

      Integration: Develop a Jenkins plugin to host the chatbot, ensuring seamless interaction within the Jenkins user interface.

      Data Sources: Configure the chatbot to access and retrieve information from Jenkins documentation, plugin directories, and community forums.

      User Interface: Design an intuitive chat interface within Jenkins for user interactions.

      Quickstart

      To get started:

      Familiarize Yourself with Jenkins Plugin Development: Review the Jenkins Plugin Tutorial.

      Explore Relevant AI Libraries: Investigate NLP frameworks such as NLTK, spaCy, PyTorch, LlamaIndex, etc., that can be integrated into Python applications.

      Understand Existing Chatbot Implementations: Study existing chatbot plugins or tools to gather insights into design and functionality.

      Links

      Jenkins Plugin Tutorial

      NLTK

      spaCy

      PyTorch Chatbot Tutorial

      Project Size

      175 - 350 Hours

      Project Difficulty Level

      Beginner to Intermediate

      Newbie-friendly Issues

      Potential applicants can explore the following tasks to prepare:

      Jenkins Plugin Development: Start by creating a simple plugin to understand the basics of Jenkins plugin architecture.

      NLP Model Training: Experiment with training NLP models on sample datasets to grasp the fundamentals of natural language understanding.

      Community Engagement: Participate in Jenkins forums and Gitter channels to understand common user queries and challenges.

      By undertaking these preliminary tasks, contributors can build a solid foundation for developing an AI-powered chatbot that enhances the Jenkins user experience.

      Potential Mentors 
      Vutukuri Sreenivas
      Kris Stern
      Kris Stern
      Ashutosh Singh
      Ashutosh Singh
      Project Links 
      Gitter
      Meetings
      Forum
      Organization Links 
      Jenkins GSoC page - documentation, application guidelines
      Participate and contribute to Jenkins - landing page for newcomer contributors
      Newbie-friendly issues - list of organization-wide newbie-friendly issues (use them if there is no links in the project idea)
      ~~~~~~~~~~
      Backend code refactoring for Infra Statistics
      To significantly refactor backend code for the Infra Statistics.
      Potential Mentor(s):
      Kris Stern
      Bervianto Leo Pratama
      Phillipp Glanz
      Infra Groovy, Backend-frontend Integration, Code Refactoring, Infra / DevOps Processes

      Project goal: To significantly refactor backend code for the Infra Statistics

      Skills to study/improve: Groovy, Backend-frontend Integration, Code Refactoring, Infra / DevOps Processes

      Details 
      Background
      The project aims to refactor the code at https://github.com/jenkins-infra/infra-statistics as well as to audit and improve the infra processes used for collecting the infra statistics data.

      Project Size
      175 hours

      Project Difficulty
      Beginner to Intermediate

      Expected Outcomes
      Details to be clarified interactively, together with the mentors, during the Contributor Application drafting phase.

      Potential Mentors 
      Kris Stern
      Kris Stern
      Bervianto Leo Pratama
      Bervianto Leo Pratama
      Phillipp Glanz
      Phillipp Glanz
      Project Links 
      Gitter
      Meetings
      Organization Links 
      Jenkins GSoC page - documentation, application guidelines
      Participate and contribute to Jenkins - landing page for newcomer contributors
      Newbie-friendly issues - list of organization-wide newbie-friendly issues (use them if there is no links in the project idea)
      
      
      ~~~~~~~~~~
      Complete build retooling of jenkins.io
      Using alternative tooling with Gatsby and Antora to build the Jenkins static site and provide versioned Jenkins documentation.
      Potential Mentor(s):
      Kris Stern
      Bruno Verachten
      Kevin Martens
      Rajiv Ranjan Singh
      Tools Web development, AsciiDoc, Static website tooling, Documentation, Website retooling

      Background
      The jenkins.io website is generated as a static website using Awestruct from AsciiDoc sources, YAML data files, and HAML templates stored in GitHub. One of the drawbacks of the current build method is that the technical documentation is not product version bound. It is thus not possible to view the documentation for a given Jenkins version. Only the latest can be viewed. This can lead to unnecessary confusion and is a worse experience than many other documentation sites like the git site, FreeBSD, and others…​

      The preferred tool to replace Awestruct is Antora.

      The potential GSoC project would be to build a working site generator to demonstrate the existing site. Once the existing site is generated with Antora, the site should be extended to add version specific documentation.

      The project has been discussed extensively at GitHub issue #5474, where some existing proof-of-concept code can be found referenced there.

      We have already begun work on this project in GSoC 2023 as "Building Jenkins.io with alternative tools". However, we were only able to complete most of the groundwork for the Antora part of the versioned docs and some of the groundwork for the Gatsby part, mostly for the non-versioned part. An initial audit is required to find out what needs to be refactored and perhaps redesigned for a success transition from the old tooling to the new one. We expect the applicant to include the result of such an audit in their GSoC proposal.

      So now the core work left will be to update the outdated contents of both the Antora versioned docs and the Gatsby backbone at the project at jenkins-infra/docs.jenkins.io repo.

      The outcome of this project is expected to produce a visible impact they can showcase in their portfolio of the jenkins.io website, as the GSoC contributor is also expected to contribute via UI/UX improvements beyond the basic tooling required.

      This selected GSoC contributor is expected to work very diligently to play catch up with the transition from the current jenkins.io repo and the new jenkins-infra/docs.jenkins.io repo. So we will only shortlist candidates who do not have competing commitments in order for this project to have a successful outcome.

      Please note that for the UI/UX improvement portion we may need to deal with the jenkins-io-components repo, where the code for components shared by various Jenkins websites (jenkins.io, plugins.jenkins.io, etc.) is currently hosted.

      Quick Start
      Documentation quick start steps include:

      Build the current documentation site locally

      Become familiar with the current site, including:

      Page types and how they are generated

      Changelogs

      Roadmap

      User handbook

      Developer handbook

      Artwork

      Security advisories

      Version specific content in tutorials (like "Improve a plugin")

      Page content sources

      Asciidoc

      HAML / Ruby

      Web components

      Build process

      Makefile

      Docker containers

      Syntax and spelling checks

      Fix several "good first issues"

      Explore jenkins-io-components repo

      Explore Antora

      Review version specific documentation techniques (some of them are Antora sites)

      CloudBees documentation site

      Git reference pages

      Python (sphinx is the generator)

      PyTorch

      TensorFlow

      Skills to Study and Improve
      Web development

      AsciiDoc

      Static website tooling

      HAML templates

      YAML data files

      Documentation

      Project Difficulty Level
      Beginner to Intermediate

      Project Size
      175 to 350 hours

      Expected Outcomes
      The deliverables of the project would be:

      Iterative and incremental improvements to the site throughout the project

      Demonstration that all the existing pages are rendered in an equivalent way

      Suggestions of improved page design(s)

      A list of all automation that are difficult/impossible to port to the new tool

      Suggestions and demos of alternative ways to solve this

      Demonstration of the versioned documentation automated tooling

      Description of the publication process (how does one contribute to document a new or modified feature)

      Successful migration of revamped jenkins.io website to replace website using old tooling

      Details to be clarified interactively, together with the mentors, during the Contributor Application drafting phase.

      New Features
      Improved layout of the existing site and its pages. New jenkins.io website.

      Newbie Friendly Issues
      Basically any good-first-issue listed in the jenkins.io GitHub repo would do. These can be accessed at the GitHub repo issues tracker with the "good first issue" label.

      Potential Mentors 
      Kris Stern
      Kris Stern
      Bruno Verachten
      Bruno Verachten
      Kevin Martens
      Kevin Martens
      Rajiv Ranjan Singh
      Rajiv Ranjan Singh
      Project Links 
      Gitter
      Meetings
      Organization Links 
      Jenkins GSoC page - documentation, application guidelines
      Participate and contribute to Jenkins - landing page for newcomer contributors
      Newbie-friendly issues - list of organization-wide newbie-friendly issues (use them if there is no links in the project idea)
      
      ~~~~~~~~~~
      Domain-specific LLM based on actual Jenkins usage using ci.jenkins.io data
      To develop a web app using an existing open-source LLM model with Jenkins usage data collected for domain-specific Jenkins knowledge to be fine-tuned.
      Potential Mentor(s):
      Kris Stern
      Harsh Pratap Singh
      Shivay Lamba
      Vutukuri Sreenivas
      Infra Python, JavaScript/TypeScript, React.js, LLM, AI/ML, Jenkins, Ollama, LangChain, UI, Infra statistics, Data Analytics
      Background
      This full-stack project focuses on a proof-of-concept (PoC) idea to fine-tune an existing open-source LLM model (such as Llama 2) with domain-specific Jenkins data to be compiled, wrangled, and processed by the contributor as a part of an AI-driven application, to develop a minimalistic UI for the user to interact with the LLM as a complete end-to-end product. The main source of raw data will be the publicly available ci.jenkins.io datasets. It is expected that there will be two parts of the project: the first part which is to analyze the ci.jenkins.io data using machine learning techniques, and the second part which is to "ingest" the knowledge gained via part one to fine-tune an existing LLM model to help with any infra-related troubleshooting tasks. The contributor will get to be involved in every step of the application development process, from data collection, wrangling, and processing to fine-tuning the model and developing the UI. Unlike the very similar GSoC 2024 LLM counterpart, this project is very research-focused and data-driven, and will be a lot more difficult to achieve a successful outcome. We will build on the completed work available via GitHub at https://github.com/jenkins-infra/Enhancing-LLM-with-Jenkins-Knowledge/. It is expected that some benchmarking will be conducted by the GSoC contributor selected towards the end of the project to gauge the effectiveness of the work completed, which will also serve as a basis for future similar projects.

      Summary
      Strategy: Test failure analysis based on the test data from ci.jenkins.io

      Help the user with failure diagnosis

      Is the failure due to infra?

      Is the failure due to a code change?

      Is the failure due to an unreliable test (“flaky test”)?

      Sample repositories and use cases

      Jenkins core

      Jenkins acceptance test harness

      Jenkins plugin BOM

      Expected Outcomes
      Details to be clarified interactively, together with the mentors, during the Contributor Application drafting phase.

      Project Size
      175 - 350 hours

      Project Difficulty
      Intermediate to Advanced

      Quick Start
      Become familiarized with the flow of the GSoC 2024 LLM project. We will reference the source code from the GSoC 2024 LLM project at its official repo on GitHub.

      Potential Mentors 
      Kris Stern
      Kris Stern
      Harsh Pratap Singh
      Harsh Pratap Singh
      Shivay Lamba
      Shivay Lamba
      Vutukuri Sreenivas
      Project Links 
      Gitter
      Meetings
      Organization Links 
      Jenkins GSoC page - documentation, application guidelines
      Participate and contribute to Jenkins - landing page for newcomer contributors
      Newbie-friendly issues - list of organization-wide newbie-friendly issues (use them if there is no links in the project idea)
      
      ~~~~~~~~~~
      Improving Tekton Client Plugin for Jenkins
      Enhance the Jenkins Tekton Client Plugin to improve cloud-native CI/CD interoperability and user experience.
      Potential Mentor(s):
      Vibhav Bobade
      Kris Stern
      Plugins Java, Kubernetes, Tekton, Jenkins

      Project goal: Enhance the Jenkins Tekton Client Plugin to improve cloud-native CI/CD interoperability and user experience

      Skills to study/improve: Java, Kubernetes, Tekton, Jenkins

      Details 
      Background
      The Tekton Client Plugin enables Jenkins to interact with Tekton, a powerful and flexible cloud-native CI/CD framework. This project aims to enhance the plugin’s capabilities, improve its integration with the Jenkins ecosystem, and provide a better user experience for cloud-native CI/CD workflows.

      Key areas for improvement include:

      Support any version of Tekton Pipeline by dynamically loading the appropriate Tekton client version

      Support for other Tekton resources such as Tekton Chains, Triggers, and EventListener

      Stretch goals:

      Convert existing Jenkins Pipeline steps to use the Tekton Client Plugin (translating the DSL to the Tekton Pipeline YAML)

      Skills to Study and Improve
      Java development

      Jenkins plugin development

      Kubernetes and cloud-native technologies

      Tekton Pipelines and Custom Resources

      REST API integration

      Testing frameworks (JUnit, MockK)

      Technical documentation

      Project Size
      175 - 350 hours

      Project Difficulty Level
      Intermediate

      Expected Outcomes
      Enhanced Tekton Client Plugin with improved features and stability

      Better integration with Jenkins Pipeline and Configuration as Code

      Comprehensive documentation and examples

      Improved test coverage

      Regular releases with new features and bug fixes

      Details to be clarified interactively, together with the mentors, during the Contributor Application drafting phase.

      Potential Mentors 
      Vibhav Bobade
      Kris Stern
      Kris Stern
      Project Links 
      Gitter
      Meetings
      Organization Links 
      Jenkins GSoC page - documentation, application guidelines
      Participate and contribute to Jenkins - landing page for newcomer contributors
      Newbie-friendly issues - list of organization-wide newbie-friendly issues (use them if there is no links in the project idea)
      
      
      ~~~~~~~~~~
      Improving Plugin Modernizer
      Improving the Jenkins Plugin Modernizer tool and provide integrations with Jenkins ecosystem.
      Potential Mentor(s):
      Bruno Verachten
      Valentin Delaye
      Sridhar Sivakumar
      Phillipp Glanz
      Tools OpenRewrite, Data structure (Trees) and visitor pattern, Java, Plugin hygiene and migration
      Project goal: Improving the Jenkins Plugin Modernizer tool and provide integrations with Jenkins ecosystem

      Skills to study/improve: OpenRewrite, Data structure (Trees) and visitor pattern, Java, Plugin hygiene and migration

      Details 
      Background
      This project idea is a continuation of the GSoC 2024 Using OpenRewrite Recipes for Plugin Modernization. The current Plugin Modernizer will need to be enhanced to support more modernization recipes and provide integrations with the Jenkins ecosystem.

      Improvements and integration could include:

      Store metadata about the modernization process on Jenkins reports site

      Provide APIs to access the modernization metadata in addition to the existing CLI module (or even run the modernization recipes as a service)

      Generate metadata regularly (using Jenkins infrastructure or GitHub Actions depending on the research done during the project)

      Better integration with the Plugin Health Score to automatically run modernization recipes on plugins with low scores

      Visualize the modernization metadata on Jenkins statistics site

      Any recipe improvements or new recipes that could be added to the tool to improve plugins health

      …​

      Skills to Study and Improve
      Java

      OpenRewrite

      Plugin refactoring and ecosystem

      Jenkins modernization

      Project Size
      175 - 350 hours

      Project Difficulty Level
      Intermediate to Advanced

      Expected Outcomes
      Details to be clarified interactively, together with the mentors, during the Contributor Application drafting phase.

      Potential Mentors 
      Bruno Verachten
      Bruno Verachten
      Valentin Delaye
      Valentin Delaye
      Sridhar Sivakumar
      Sridhar Sivakumar
      Phillipp Glanz
      Phillipp Glanz
      Project Links 
      Gitter
      Meetings
      Organization Links 
      Jenkins GSoC page - documentation, application guidelines
      Participate and contribute to Jenkins - landing page for newcomer contributors
      Newbie-friendly issues - list of organization-wide newbie-friendly issues (use them if there is no links in the project idea)
      ~~~~~~~~~~
      Revamping jenkins.io website Success Stories feature
      To revamp jenkins.io website's Success Stories feature to update both tooling and UI/UX experience with new design.
      Potential Mentor(s):
      Kris Stern
      Bervianto Leo Pratama
      UI/UX Website development, UI/UX design, Geospatial data visualization, Gatsby.js and React.js
      Project goal: To revamp jenkins.io website's Success Stories feature to update both tooling and UI/UX experience with new design

      Skills to study/improve: Website development, UI/UX design, Geospatial data visualization, Gatsby.js and React.js

      Details 
      Background
      The current jenkins.io "Success Stories" feature at https://stories.jenkins.io/ is in need of a revamp to keep it looking sharp and relevant. The project at https://github.com/jenkins-infra/stories/ is in need of modernization tech-stack wise, as we will need to upgrade the React version used to the latest possible (ideally v19) as well as upgrade the versions of most of the dependencies used. Besides, we will need to redesign the layout of its UI/UX including but not limited to the landing page, the story page, the map, etc.

      Moreover, the workflow for users to submit new stories may need to be redesigned and reimplemented, given the context of the Infra Helpdesk issue at https://github.com/jenkins-infra/helpdesk/issues/4392/.

      Skills to Study and Improve
      Website development

      UI/UX design

      Geospatial data visualization

      Gatsby.js and React.js

      Project Size
      175 hours

      Project Difficulty Level
      Beginner to Intermediate

      Expected Outcomes
      Details to be clarified interactively, together with the mentors, during the Contributor Application drafting phase.

      Potential Mentors 
      Kris Stern
      Kris Stern
      Bervianto Leo Pratama
      Bervianto Leo Pratama
      Project Links 
      Gitter
      Meetings
      Organization Links 
      Jenkins GSoC page - documentation, application guidelines
      Participate and contribute to Jenkins - landing page for newcomer contributors
      Newbie-friendly issues - list of organization-wide newbie-friendly issues (use them if there is no links in the project idea)
      
      
      ~~~~~~~~~~
      Swagger / OpenAPI standardization for Jenkins REST API
      Standardizing Jenkins REST API documentation using Swagger or the OpenAPI specifications.
      Potential Mentor(s):
      Kris Stern
      Bruno Verachten
      Rajiv Ranjan Singh
      Bervianto Leo Pratama
      Phillipp Glanz
      Tools Swagger / OpenAPI standardization, REST API, Documentation, Automation, Java

      Project goal: Standardizing Jenkins REST API documentation using Swagger or the OpenAPI specifications

      Skills to study/improve: Swagger / OpenAPI standardization, REST API, Documentation, Automation, Java

      Details 
      Background
      Developers need to know what to expect in terms of responses for each REST API endpoint, so external tools like jenkins-rest can be developed with confidence, and possibly with the help of some REST specification automation. For example, this could be done using the OpenAPI Specification (formerly known as Swagger Specification). Users of the REST API most often want:

      HTTP responses and codes

      Body of message and its format (e.g. JSON, html, etc.)

      Jenkins does not have automated REST API documentation at all at this time. A lot of APIs are contributed from extensions, so there are multiple REST APIs (core and plugins) of varying versions. The goal of this project is to find and implement the extraction of the REST APIs from the sources and generate and publish the REST APIs' respective documentation.

      Project Details
      Generating the expected HTTP responses is a difficult task. The student is expected to study Jenkins core to identify ways to extract them. For example, they could be extracted from Javadocs and annotations.

      As part of the community bonding and student project proposal phase, the student is expected to make a few proposals on how to specify and generate the REST API for the Jenkins core and for the plugins. In the case the student finds that it is not possible to generate the REST API from a specification, the student should identify why this is not possible. We also ask the student to explore and propose a way to have REST API of plugins generated from a REST API specification. For example, some auto-code could populate what the javadoc would look like in an empty-plugin used by the maven plugin generator.

      The student is also expected to study and propose how the REST API documentation generation could be part of the REST API generator.

      It might be helpful to automatically generate some code for the REST API when the plugin developer creates a plugin for the first time using the plugin skeleton generator. Any methodology created to handle the REST API should be built into the skeleton generator.

      The jenkins core REST API and the plugins own REST API need to be versioned separately. It is suggested to focus first on generating the specification, then later look at the versioning of the REST API. Nested objects make versioning challenging.

      Jenkins users should be easily able to see the REST APIs available for their installed Jenkins. For Jenkins core, this could be done with a URL like: http://localhost/rest/api/1.0. The plugins would have their own REST API path with a version number like: http://localhost/plugin/rest/api/1.0. Plugins and the core would thus have their own version number, and an additional REST API version number. Automated API documentation using the OpenAPI 3.0 specification is part of identifying the API specs.

      More details are in the draft project idea.

      Links
      There are many examples of such documentation on the web:

      Bitbucket REST API (link to Bitbucket documentation)

      Artifactory REST API (link to Artifactory documentation)

      OpenAPI3 description of the Jenkins REST API: swaggy jenkins (note: the swaggy-jenkins author now recommends OpenAPI (explanation).

      This stackoverflow question talks briefly about generating a REST API spec in WADL format

      A blog post that talks about swagger and WADL

      Making Stapler more declarative discussion leading to a comment on swagger.

      A google group discussion on seeking help on clarifying this proposal

      Plugin skeleton generator

      Jira ticket JENKINS-35808 on generating spec for Jenkins REST API from 2016

      Quick-start
      Watch the project discussion meeting recording. It summarizes the project and the first possible steps

      Study the Open API specification, go through examples for other services

      Explore ways to index the REST API endpoints in Jenkins and Stapler. It includes @Exported and @ExportedBean annotations, and other methods from the Stapler framework. See the video for the links.

      Newbie-friendly issues
      Jira Query

      Create an Open API specification for a Jenkins plugin with REST API, add it to the respective plugin repository

      Contribute to documentation of Jenkins REST API, e.g. see the _api.jelly files in the Jenkins Core and plugins

      Javadoc Landing Page — While Javadoc isn’t Rest API, user experience concerns described in INFRA-1717 for Javadoc Landing Page could be re-considered when determining where to publish Rest API accordingly

      Skills to improve/study
      Java

      REST API

      OpenAPI specification details and automatic generators

      Stapler (more info:https://github.com/jenkins-infra/jenkins.io/pull/2157#issuecomment-471230609)

      Project Difficulty Level
      Intermediate

      Project Size
      175 to 350 hours

      Expected Outcomes
      Details to be clarified interactively, together with the mentors, during the Contributor Application drafting phase.

      Potential Mentors 
      Kris Stern
      Kris Stern
      Bruno Verachten
      Bruno Verachten
      Rajiv Ranjan Singh
      Rajiv Ranjan Singh
      Bervianto Leo Pratama
      Bervianto Leo Pratama
      Phillipp Glanz
      Phillipp Glanz
      Project Links 
      Gitter
      Meetings
      Project idea draft
      Organization Links 
      Jenkins GSoC page - documentation, application guidelines
      Participate and contribute to Jenkins - landing page for newcomer contributors
      Newbie-friendly issues - list of organization-wide newbie-friendly issues (use them if there is no links in the project idea)
      

      ~~~~~~~~~~
      Android and/or iOS tutorials in official documentation
      Adding Android and/or iOS tutorials for Jenkins in the official documentation.
      Potential Mentor(s):
      Bruno Verachten
      Kris Stern
      Documentation Documentation, Java, YAML, Android / iOS development, Command line tools

      Project goal: Adding Android and/or iOS tutorials for Jenkins in the official documentation

      Skills to study/improve: Documentation, Java, YAML, Android / iOS development, Command line tools

      NOTE: This idea is published as a draft under active discussion, but it is confirmed in principle. It is FINE to apply to it. The scope and the suggested implementation may change significantly before the final version is published. Sections like quickstart guide and newbie-friendly issues may be also missing. As a contributor, you are welcome to request additional information and to join the discussions using channels linked on this page.
      Details 
      Background
      Topics such as how to proceed, what are the successful patterns, and what are the pitfalls are poorly documented. It very often requires potential users and Jenkins Administrators to "reinvent the wheel".

      iOS
      The project idea is to have a clear status of what can be done with Jenkins for iOS app builds now. There are only a few articles here and there about iOS.

      Android
      For Android development, some experiments are available and were presented publicly.

      The proof of concept could be docker-compose based. It would work under Windows, Linux, Vagrant, macOS (x86 and ARM), and mostly on Gitpod. It should be easily transposable to a production environment. The demo/proof-of-concept would be composed of a Jenkins controller (configured with JCasc), an Android agent, a generic Docker agent, an Android emulator, and an Android device farm (STF).

      The idea is to have a more precise status of what can be done now with Jenkins. We could then amend the existing Android documentation and describe architectures for:

      Standalone Android projects

      Android apps building farms

      Android distro building (customized AOSP)

      Skills to Study and Improve
      Jenkins technical architecture

      iOS application development

      CI principle and practice

      Android application development

      Docker

      Project Size
      175 - 350 hours

      Project Difficulty Level
      Intermediate

      Expected Outcomes
      Details to be clarified interactively, together with the mentors, during the Contributor Application drafting phase.

      Potential Mentors 
      Bruno Verachten
      Bruno Verachten
      Kris Stern
      Kris Stern
      Project Links 
      Gitter
      Meetings
      Organization Links 
      Jenkins GSoC page - documentation, application guidelines
      Participate and contribute to Jenkins - landing page for newcomer contributors
      Newbie-friendly issues - list of organization-wide newbie-friendly issues (use them if there is no links in the project idea)

      ~~~~~~~~~~
      Pipeline documentation improvements - Phase 2 and Phase 3
      Improving the navigation and implementation of the Pipeline Steps Reference.
      Potential Mentor(s):
      Kris Stern
      Bervianto Leo Pratama
      Documentation Documentation, Web development, Jenkins plugins

      Pipeline documentation improvements - Phase 2 and Phase 3 
      Project goal: Improving the navigation and implementation of the Pipeline Steps Reference

      Skills to study/improve: Documentation, Web development, Jenkins plugins

      NOTE: This idea is published as a draft under active discussion, but it is confirmed in principle. It is FINE to apply to it. The scope and the suggested implementation may change significantly before the final version is published. Sections like quickstart guide and newbie-friendly issues may be also missing. As a contributor, you are welcome to request additional information and to join the discussions using channels linked on this page.
      Details 
      Background
      Continuing from the GSoC 2022 Pipeline Step Documentation Generator project as Phase 2 of that project. More to do during this Phase 2 and the next Phase 3, as we will need to include both the refinement of the detailing and the navigation design. The project will involve the adopting of multiple plugins and improving their Pipeline Steps documentation. The selected contributor is expected to do lots of writing, exploring, testing, but not lots of coding.

      Quick Start
      Studying all materials relevant to the GSoC 2022 Pipeline Step Documentation Generator project and become familiar with them.

      Skills to Study and Improve
      Jenkins plugin development life cycle

      Documentation

      Web UI/UX design for documentation

      Testing Jenkins plugins

      Project Difficulty Level
      Beginner to Intermediate

      Project Size
      175 to 350 hours (depending on the scope)

      Expected Outcomes
      Details to be clarified interactively, together with the mentors, during the Contributor Application drafting phase.

      Potential Mentors 
      Kris Stern
      Kris Stern
      Bervianto Leo Pratama
      Bervianto Leo Pratama
      Project Links 
      Gitter
      Meetings
      Organization Links 
      Jenkins GSoC page - documentation, application guidelines
      Participate and contribute to Jenkins - landing page for newcomer contributors
      Newbie-friendly issues - list of organization-wide newbie-friendly issues (use them if there is no links in the project idea)

      ~~~~~~~~~~
      Improving Jenkinsfile Runner abilities and GitHub Actions
      To investigate the current state of the Jenkinsfile Runner project and to improve its abilities as well as those of GitHub Actions when used in conjunction.
      Potential Mentor(s):
      Valentin Delaye
      Kris Stern
      Bervianto Leo Pratama
      Tools Java, Jenkinsfile Runner, Docker, GitHub Actions

      Project goal: To investigate the current state of the Jenkinsfile Runner project and to improve its abilities as well as those of GitHub Actions when used in conjunction

      Skills to study/improve: Java, Jenkinsfile Runner, Docker, GitHub Actions

      NOTE: This idea is published as a draft under active discussion, but it is confirmed in principle. It is FINE to apply to it. The scope and the suggested implementation may change significantly before the final version is published. Sections like quickstart guide and newbie-friendly issues may be also missing. As a contributor, you are welcome to request additional information and to join the discussions using channels linked on this page.
      Details 
      Background
      This project idea is a continuation of the GSoC 2022 Jenkinsfile Runner Action for GitHub Actions project. The current Jenkninsfile Runner project will need to switch to Spring Security 6, Jetty 12, as well as Jakarta EE 9 as part of its modernization. We would like to encourage more adoption and compatibility with the latest Jenkins version. There are many open issues within this project. We will also need to work on reporting on GitHub checks.

      Skills to Study and Improve
      Java

      To run Jenkinsfile Runner (an incubating project) to create an action inside Docker

      Docker configuration

      GitHub Actions configuration

      Jenkins modernization

      Project Size
      175 - 350 hours

      Project Difficulty Level
      Intermediate to Advanced

      Expected Outcomes
      Details to be clarified interactively, together with the mentors, during the Contributor Application drafting phase.

      Potential Mentors 
      Valentin Delaye
      Valentin Delaye
      Kris Stern
      Kris Stern
      Bervianto Leo Pratama
      Bervianto Leo Pratama
      Project Links 
      Gitter
      Meetings
      Organization Links 
      Jenkins GSoC page - documentation, application guidelines
      Participate and contribute to Jenkins - landing page for newcomer contributors
      Newbie-friendly issues - list of organization-wide newbie-friendly issues (use them if there is no links in the project idea)
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/jenkins/
    idea_list_url: https://www.jenkins.io/projects/gsoc/2025/project-ideas/

  - organization_id: 72
    organization_name: Jitsi
    no_of_ideas: 11
    ideas_content: |

      Chat Moderation & Editing

   
      Overview
      Enhance chat functionality with advanced moderation and editing features.

      Description
      Improve Jitsi's basic chat by adding moderation tools and editing capabilities. Currently, moderators have limited control, as the chat lacks features like message editing, deletion, and reporting. This project aims to improve usability and moderation.

      Expected outcomes
      Cover features such as the following:

      Message Control for Moderators – Ability to delete and redact messages, mute and remove participants directly from the chat interface.
      User Moderation Tools – Moderators can ban users from messaging, issue warnings, shadow ban, and remove participants from the chat.
      User Reporting System – Allow users to report messages or participants for review.
      User Message Editing – Users can edit their own messages with version history.
      Message Search – Enable users to search chat history efficiently.
      Extra points for a challenge:

      Threaded Replies – Improve conversation structure with message threading.
      Skills / Technologies
      JavaScript, React, React Native, Prosody

      Possible mentors
      Saúl Ibarra Corretgé, Mihaela Dumitru

      Expected project size
      Medium (175 hours) or Large (350 hours)

      Difficulty
      Medium

      ~~~~~~~~~~
      Whiteboard Improvements

      Overview
      Further develop whiteboard capabilities

      Description
      The current Jitsi whiteboard integration is a fork of Excalidraw. Participants can only share smart objects during collaboration and there is a limit in place to limit memory overload.

      Expected outcomes
      File Upload Support – Enable users to upload and share files within the whiteboard.
      Upgrade to Socket.IO 4 – Improve performance and compatibility by updating the underlying real-time communication library.
      Migrate to a Newer Excalidraw – Upgrade to the latest version for better features and stability.
      Improve WebSocket Connections – Optimize packet size during real-time collaboration.
      Skills / Technologies
      JavaScript, React, Node

      Possible mentors
      Saúl Ibarra Corretgé, Mihaela Dumitru

      Expected project size
      Medium (175 hours)

      Difficulty
      Medium

      ~~~~~~~~~~
      Advanced Audio Settings

      Overview
      Provide in-meeting settings for advanced audio controls such as Acoustic Echo Cancellation (AEC), Noise Suppression (NS), Gain Control (AGC) and Stereo.

      Description
      In Jitsi Meet there is a possibility to configure a given deployment to provide no audio filtering at all by disabling AEC, AGC and NS, and even enable stereo audio. It is not possible, however, to do this easily from the web UI.

      This project aims at makint it easier for those who need there to tweak the settings from an advanced section in the user interface available to the user.

      Expected outcomes
      New advanced section in the audio settings dialog with all the aforementioned settings
      Skills / Technologies
      JavaScript, TypeScript, WebRTC (not strictly necessary)

      Possible mentors
      Saúl Ibarra Corretgé, Jaya Allamsetty

      Expected project size
      Medium (175 hours)

      Difficulty
      Medium



      ~~~~~~~~~~
      Picture-in-Picture for iOS
      Overview
      Jitsi Meet is available for mobile platforms on Android and iOS. Android already has a native Picture-in-Picture (PiP) implementation; this project aims to provide equivalent functionality on iOS.

      Description
      The Android and iOS Jitsi Meet apps have feature parity, but sometimes due to platform differences features are not available on one of the platforms. This is the case of PiP in iOS. Thanksfully support for it was added to react-native-webrtc, so this project is about integrating that support into the Jitsi Meet iOS app.

      Expected outcomes
      iOS app with support for PiP
      Background camera support for iOS
      Skills / Technologies
      JavaScript, TypeScript, React, React Native, iOS

      Possible mentors
      Saúl Ibarra Corretgé, Calin-Teodor Chitu

      Expected project size
      Medium (175 hours) or Large (350 hours)

      Difficulty
      Medium



      ~~~~~~~~~~
      Jitsi Videobridge JavaScript client

      Overview
      JavaScript library for communicating with the Jitsi Videobridge.

      Description
      The JVB is the heart of Jitsi Meet. It's the entity responsible for video routing.

      Jitsi Meet uses many more components than the JVB, connecting them via XMPP. This setup may not be desirable for everyone so a low level library that can connect to the JVB directly would give developers the ultimate flexibility to use our video router, without having to buy into the entire ecosystem.

      Expected outcomes
      TypeScript library which can communicate with the JVB and negotiate media sessions
      Sample "meetings app" using the previously built library and socket.io for signalling
      Skills / Technologies
      JavaScript, TypeScript, socket.io (not strictly necessary)

      Possible mentors
      Saúl Ibarra Corretgé, Boris Grozev

      Expected project size
      Medium (175 hours) or Large (350 hours)

      Difficulty
      Medium

      ~~~~~~~~~~
      lib-jitsi-meet in TypeScript

      Overview
      lib-jitsi-meet is the low level JavaScript library that takes care of all signalling and media negotiation for Jitsi Meet. It's partially written in TypeScript and now is a good time to make that 100%!

      Description
      lib-jitsi-meet (LJM) is the low level library that was spun off the Jitsi Meet project so it can also be consumed standalone. Over time parts of it were migrated to TS but it's not 100% there.

      We'd like to fully move to TS so we can better document its public API and typings, and get a better development experience by using the generated type information.

      Expected outcomes
      lib-jitsi-meet in TypeScript
      Automated typings package generation and publication
      Skills / Technologies
      JavaScript, TypeScript

      Possible mentors
      Saúl Ibarra Corretgé, Jaya Allamsetty, Hristo Terezov

      Expected project size
      Medium (175 hours) or Large (350 hours)

      Difficulty
      Medium

      ~~~~~~~~~~
      Virtual Backgrounds, take 2

      Overview
      Improve the virtual backgrounds in Jitsi Meet so they perform as good as possible.

      Description
      The current implementation for virtual backgrounds relies on a WASM build of Tensor Flow Lite (tflite) which predates the release of MediaPipe.

      This project consists of migrating away from this package to MediaPipe and making performance oriented changes to make sure the quality is a good as it can be. A non exhaustive list of potential improvements: use WebGL for rendering, use requestVideoFrameCallback for driving the render, use insertable streams.

      Expected outcomes
      A do-over of the feature, with higher quality than today
      Skills / Technologies
      JavaScript, TypeScript

      Possible mentors
      Saúl Ibarra Corretgé

      Expected project size
      Medium (175 hours)

      Difficulty
      Medium



      ~~~~~~~~~~
      Integrated AI services with Skynet

      Overview
      Provide an integrated experience across Jitsi Meet, Jigasi and Skynet for an integrated AI services approach that includes meeting transcriptions and summaries.

      Description
      Jitsi Meet already has support for AI assisted transcriptions and summaries by combining Jigasi and Skynet. There is, however no out-of-the-box way to set it up. This project aims to provide that experience with some Docker configuration and a new small full-stack solution to glue all the services together.

      Expected outcomes
      New Docker configuration to run Skynet
      New backend service to store and process transcriptions
      New frontend service to browse past meetings history
      Skills / Technologies
      JavaScript, TypeScript, Python, Docker

      Possible mentors
      Saúl Ibarra Corretgé, Razvan Purdel, Tudor Avram

      Expected project size
      Medium (175 hours)

      Difficulty
      Medium



      ~~~~~~~~~~
      Meeting stats with rtcstats

      Overview
      Provide an integrated way for people self-hosting Jitsi Meet to have an insight into their meeting stats with rtcstats.

      Description
      With rtcstats one can get lots of information about meeting quality, logs, etc. It's what we've been using in production for quite a while. The project is fully open source, but there is no simple way for self-hosters to deploy in their own premises. This project aims to make that job easier by providing an integrated approach.

      Expected outcomes
      New MongoDB connector for rtcstats
      Integration with the Docker setup
      Skills / Technologies
      JavaScript, TypeScript, MongoDB (not necessary), Docker

      Possible mentors
      Saúl Ibarra Corretgé, Andrei Gavrilescu

      Expected project size
      Medium (175 hours)

      Difficulty
      Medium

      ~~~~~~~~~~
      Audio Switchboard API
      Overview
      Design and implement a protocol and an API to allow participants in a Jitsi Meet conference to use different audio channels.

      Description
      Jitsi Meet clients use a very flexible constraints API to select which video streams in a conference they want to receive. However, audio is not configurable: endpoints always receive all audio streams (optionally filtered by loudness).

      The goal of this project is to build the lower level functionality to allow endpoints more control over what they receive. This would allow various exciting features to be implemented on top of it: live translation layers, lightweight breakout rooms, whispering, etc.

      Expected outcomes
      A protocol between a client and Jitsi Videobridge to publish/subscribe audio channels
      Audio filtering in Jitsi Videobridge based on channels
      [Optional: A javascript API that allows clients to change the audio channels they receive/send]
      Skills / Technologies
      Kotlin, Java, JavaScript

      Possible mentors
      Boris Grozev, Saúl Ibarra Corretgé

      Expected project size
      Large (350 hours)

      Difficulty
      Hard

      ~~~~~~~~~~
      Removing "ghost" participants on reconnections

      Overview
      Detect reconnections due to failure and kick out the "ghost" participant from the previous connection.

      Description
      Jitsi Meet is subject to network connection problems, variance. A particularly annoying problem happens when a user reconnects after a connection failure. A new tile will appear, but the previous one, for the (now dead) connection will remain there for 1-3 minutes, until the connection is presumed fully dead and it gets kicked. We refer to these user tiles as "ghosts". This situation can be optimized if we detect a user is reconnecting and can automatically replace the ghost tile with the new real one.

      Expected outcomes
      TypeScript code handling this problem
      Skills / Technologies
      JavaScript, TypeScript

      Possible mentors
      Saúl Ibarra Corretgé, Damyan Minkov

      Expected project size
      Medium (175 hours)

      Difficulty
      Medium

    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/jitsi/
    idea_list_url: https://github.com/jitsi/gsoc-ideas/blob/master/2025/README.md

  - organization_id: 73
    organization_name: Joomla!
    no_of_ideas: 4
    ideas_content: |
     
      Project I: API Improvements[edit]
      #SECURITY
      Project Description[edit]
      To exchange information between different Content Management Systems, for integration or migration purposes, many ad hoc solutions have been created. A more universally applicable approach would be establishing a common, shared model for content. This would enable the creation of specific models tailored to individual CMSs, facilitating model-to-model transformations. A standardized content model would provide a more versatile and efficient solution for handling information exchange across diverse CMS platforms.
      There was a standard for content integration, CMIS [1], but it is hardly used nowadays, mainly because it is not up to date with modern web content management.
      
      Knowledge Prerequisite[edit]
      Language Requisitions: PHP, JavaScript
      Besides that, a must have: REST API
      Nice to have: API Protocols
      Expected Outcome[edit]
      Work towards a gradually more general (formal) content model, usable in multiple CMSs.
      Gradually adding more CMSs. Adjusting the general model and defining the specificities per CMS. Start with Joomla and 1 other.
      Export content from those CMSs to the general model using the API.
      Import content from the general model using the API.
      Increase the coverage for API
      Go through the components to add missing calls
      Auth & Error
      Enhancement to authentication (OAuth 2.0)
      Improve Error handling
      Difficulty[edit]
      Hard
      Project Hours[edit]
      [350 Hrs]
      Mentors[edit]

      ~~~~~~~~~~
      Project II: Workflow enhancements[edit]
      Project Description[edit]
      With Joomla! 4.0 a workflow extension was implemented. It supports a powerful workflow mechanism to manage articles in Joomla! This project should help to improve the user experience of the workflow by checking other solutions, what is “the state of the arts” today and implement a proper UI solution for Joomla!
      
      Knowledge Prerequisite[edit]
      Language Requisitions: PHP, JavaScript
      Expected Outcome[edit]
      A graphical workflow interface (drag & drop + graphs)
      Different default workflows which are shipped with the system
      Improved documentation & help page
      Difficulty[edit]
      Hard
      Project Hours[edit]
      [350 Hrs]
      Mentors[edit]

      ~~~~~~~~~~
      Project III: Weblinks enhancements[edit]
      Project Description[edit]
      A few years ago the weblink extension was extracted from the core and maintained in an extra repository. Over time the code was not kept up-to-date and does not cover all the standards.
      Knowledge Prerequisite[edit]
      Language Requisitions: PHP, JavaScript
      Nice to have: Joomla! 5 template creation
      Expected Outcome[edit]
      Bring the code to the latest standard of Joomla! Programming
      Implement the workflow into weblinks
      Suggest and implement new features which improve the extension itself
      
      Difficulty[edit]
      Medium
      Project Hours[edit]
      [175 Hrs]
      Mentors[edit]

      ~~~~~~~~~~
      Project IV: Joomla! AI framework[edit]
      Project Description[edit]
      AI is here, so Joomla! should start offering a framework to get AI support into Joomla! The task of this project is to check out best practice examples on the internet and come up with a proposal for a basic AI framework.
      
      Knowledge Prerequisite[edit]
      Language Requisitions: AI knowledge, API, PHP
      
      Expected Outcome[edit]
      Basic best practices framework which can be extended in the future
      An Example implementation of one or more state-of-the-art AI providers
      
      Difficulty[edit]
      Medium
      Project Hours[edit]
      [175 Hrs]
      Mentors[edit]
      Categories: Google Summer of Code 2025Google Summer of Code
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/joomla!/
    idea_list_url: https://docs.joomla.org/GSoC_2025_Project_Ideas

  - organization_id: 74
    organization_name: KDE Community
    no_of_ideas: 23
    ideas_content: |
      
      
      Cantor
      Project: Python virtual environments in Cantor
      Brief explanation: Cantor is a graphical frontend for different computer algebra systems and programming languages (https://cantor.kde.org/). For the Python backend, it lacks the support for Python virtual environments. The purpose of this project is to implement this missing functionality.
      Expected results: Cantor can work with multiple Python virtual environment similarly to how it's possible in other IDEs like Spider-IDE, PyCharm, etc.
      Knowledge Prerequisite: C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentors: Alexander Semke, Israel Galadima, https://matrix.to/#/#cantor:kde.org
      ~~~~~~~~~~
      
      Merkuro
      Project: Port account management to QML
      Brief explanation: Currently Merkuro makes use of QtWidgets dialog for managing the type of resources (accounts), the goal is to port all (or at least a some) of the dialogs to QML
      Expected results: Making Merkuro a step closer to be fully usable on mobile
      Knowledge Prerequisite: QML and C++
      Duration: ~350 hours, but we can discuss to reduce the scopes
      Difficulty: Difficult
      Mentors: Carl Schwan and Aakarsh MJ. Please contact us on #merkuro:kde.org (Matrix) and not via DM
      ~~~~~~~~~~
      KArchive
      Project: Rewrite Zip backend to use libzip
      Brief explanation: Currently karchive uses home grown code to handle zip files. The code is not very good since it gets confused when it finds token markers in what it is actual compressed data. See https://bugs.kde.org/show_bug.cgi?id=450597
      Expected results: KArchive uses libzip for handling zip files (and there's no regressions)
      Knowledge Prerequisite: C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Albert Astals Cid <aacid@kde.org>

      ~~~~~~~~~~
      
      Internationalization
      Project: Move translation files to git
      Brief explanation: Translation files currently live in SVN, they are one of the last things in SVN, and the sysadmin team would welcome if we stop using it so they can shut down the server (also some folks have trouble using SVN since it's now starting to become old). The plan is to move files to GIT but we need to make sure the history is preserved and the associated scripts are adapted. See more at https://invent.kde.org/teams/localization/issues/-/issues/1
      Expected results: Most/All of what is described above is done.
      Knowledge Prerequisite: git/bash/python
      Duration: ~350 hours
      Difficulty: Medium
      Mentor: Albert Astals Cid/Luigi Toscano, talk to us at https://matrix.to/#/#kde-i18n:kde.org

      ~~~~~~~~~~
      
      Plasma
      Project: Make KWin aware of game controllers
      Brief explanation: Plasma could do a lot to improve support for game controllers: gamepads, fight sticks, flight sticks, and more. But before we can work on advanced features like button mapping or mouse emulation, Plasma's Wayland compositor KWin first needs to take control of controller input. The task is to modify KWin so it reads game controller input events and provides it back to games/applications unmodified. Once that's in place, the sky's the limit.
      Expected results: KWin has access to game controller input events, games still work, and Plasma does not suspend the system as long as you use the controller (one of our oldest bugs)
      Knowledge Prerequisite: C++, a little Qt, patience to dive into KWin and Wayland protocols
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Xaver Hugl. Introduce yourself on #kde-input:kde.org (Matrix) and tag user @zamundaaa
      
      ~~~~~~~~~~
      Project: Make Plasma Virtual Keyboard production-ready
      Brief explanation: Evolve the current proof of concept into a solution that can be shipped with Plasma by default. Currently it's based on the Qt Virtual Keyboard API [1] [2]. It still needs lots of work and polish first though. That's where you come in!
      Expected results: A virtual keyboard that works well for different languages and can be shipped with Plasma. It should be usable on phones, tablets and the likes.
      Knowledge Prerequisite: C++, a little Qt, understanding of how Wayland works.
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Aleix Pol. Introduce yourself on #kde-input:kde.org (Matrix) and tag user @apol:kde.org
      
      ~~~~~~~~~~
      Project: Select & use more than one input method
      Brief explanation: Different users require different ways to input text. Some will need an on-screen keyboard for their tablet, phone, or laptop touchscreen. Some use fcitx5 or IBus to enter complex characters with their keyboard. Some would like to dictate or generate text with the help of an AI model. Some would like all of the above depending on the situation. Plasma on Wayland currently lets you select one input method as "Virtual Keyboard" in System Settings, but ideally we want many input methods to co-exist peacefully.
      Expected results: On the less ambitious end, Plasma and KWin will let you switch between input methods / virtual keyboard on the fly. On the more ambitious end, multiple input methods can be active at the same time so you can e.g. use fcitx5 for physical keyboard input and Maliit or plasma-keyboard as on-screen keyboard.
      Knowledge Prerequisite: C++, a little Qt, understanding of how Wayland works
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Eike Hein. Introduce yourself on #kde-input:kde.org (Matrix) and tag user @hein:kde.org
      
      ~~~~~~~~~~
      Project: Improve input handling in ways that you're totally excited about
      Brief explanation: Input handling is one of the elected KDE Goals and we're looking for all the help we can get. If you have an itch that needs scratching, and none of the other ideas on this page look quite right to you, we're still interested in your contributions. Drop by on our Matrix channel (see below) and let's discuss what your project could look like.
      Expected results: An input-related GSoC application drafted with community input but including many of your own ideas, opinions and planned milestones. Once selected, actually delivering on those plans.
      Knowledge Prerequisite: Depends on the project, but probably C++, Qt, and a basic understanding of Wayland
      Duration: 90, 175 or 350 hours, depending on what you sign up for
      Difficulty: also depends on the project
      Mentor: Jakob Petsovits (@jpetso:kde.org) and/or other interested KDE people in the #kde-input:kde.org (Matrix) chatroom. Say hi and let's chat!
      
      
      ~~~~~~~~~~
      Plasma Mobile
      Make network related KCMs feature complete with desktop equivalent
      Brief explanation: Currently, Plasma Mobile has its own Wi-Fi, cellular networking and hotspot settings modules. They are very basic, and lack some features compared to their desktop equivalents (ex. enterprise Wi-Fi security). The desktop has a very functional networking settings module, but it has a large codebase and complex UI that is not easy to adapt to mobile usage.
      The aim of the project is to improve the mobile networking settings so that it is functionally equivalent to the desktop experience. This includes support for enterprise Wi-Fi networks, VPN configuration, and etc. The tasks involves exposing configuration values from C++ to QML and writing some UI code around it (working heavily with NetworkManager and ModemManager). Developing a shared base with the desktop implementation and consolidating code is also a key goal.
      Expected results: Mobile network KCMs can share more code with the desktop one and are more featureful
      Knowledge Prerequisite: QML and C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Carl Schwan and rest of Plasma mobile team. https://matrix.to/#/#plasmamobile:kde.org

      ~~~~~~~~~~
      KDE Linux
      Kirigami ISO Image Writer
      Brief explanation: Create a GUI in Kirigami for ISO Image Writer: https://invent.kde.org/kde-linux/kde-linux/-/issues/132
      Expected results: ISO Image Writer GUI rewrite using Kirigami.
      Knowledge Prerequisite: QML and C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org

      ~~~~~~~~~~
      Backup Prototype
      Brief explanation: Backuping its data is important to not lose them. Whether it's duplicating locally, on the same network or on an external server to be able to retrieve them in case of bad manipulation or incident. The tool should also be robust and trustable (when it says it copied, it really copied). The projects aims to create a prototype which satisfies these conditions: https://invent.kde.org/kde-linux/kde-linux/-/issues/131
      Expected results: A prototype for a local backup solution that is robust
      Knowledge Prerequisite: QML and C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org

      ~~~~~~~~~~
      CVE/Security Tracker
      Brief explanation: Security is one of the core values that matters to people. When we install software, we should know if the version has known vulnerabilities and if we can update it to a version that have it fixed. This project aims to create a solution that will allow to track them: https://invent.kde.org/kde-linux/kde-linux/-/issues/134
      Expected results: A system that can track security advisories. Ideally a web based solution.
      Knowledge Prerequisite: Any programming language
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org

      ~~~~~~~~~~
      Recovery Infrastructure
      Brief explanation: When your computer crash or do not start, you'd like to recover as much as you can. The aim of the task is to create a tool that would allow to recover this data: https://invent.kde.org/kde-linux/kde-linux/-/issues/135
      Expected results: A prototype of a system/application to help users and OEMs recover a broken system, or at least its data.
      Knowledge Prerequisite: QML and C++, possibly others
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org

      ~~~~~~~~~~
      Replication Infrastructure
      Brief explanation: When you change computer, you may want to keep some data: installed applications, configuration files, personal data... The aim of the project is to create a tool that will allow to synchronise data between two machines: https://invent.kde.org/kde-linux/kde-linux/-/issues/136
      Expected results: A prototype of a system/application to help users replicate (or move) from one system to another.
      Knowledge Prerequisite: QML and C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org

      ~~~~~~~~~~
      Karton
      Brief explanation: KDE has developed its own virtual machine application. The aim of the project is to create a Kirigami graphical interface to the tool: https://invent.kde.org/kde-linux/kde-linux/-/issues/133
      Expected results: A polished Kirigami-based virtual machine application that can replace virt-manager and virtualbox for most users.
      Knowledge Prerequisite: QML and C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org

      ~~~~~~~~~~
      Automatic Testing
      Brief explanation: The goal of this project is to develop automated tests which will allow to detect regressions before pushing new features/tools to the user: https://invent.kde.org/kde-linux/kde-linux/-/issues/79.
      Expected results: Fully automated tests to detect regressions in KDE Linux
      Knowledge Prerequisite: Bash, Python, Perl
      Duration: ~350 hours
      Difficulty: Medium
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org

      ~~~~~~~~~~
      Website
      Brief explanation: KDE Linux needs to have a website. There are already some websites in KDE done with Hugo. The aim of the task is to create a website for KDE Linux, including multiple infos such as Downloads links, Community links... More details can be found at https://invent.kde.org/kde-linux/kde-linux/-/issues/92
      Expected results: A swanky website for KDE Linux using Hugo
      Knowledge Prerequisite: Web development, ideally using Hugo
      Duration: ~90 hours
      Difficulty: Easy
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org

      ~~~~~~~~~~
      KDE Games
      Mankala: Bao La Kiswahili
      Brief explanation: Add Bao La Kiswahili and create a computerized opponent with various levels of difficulty for it. Explore the use of machine learning algorithms in creating a computerized opponent. Code can be found at https://invent.kde.org/joaotgouveia/mankala.
      Expected results: An additional game in Mankala
      Knowledge Prerequisite: C++, Qt, QML
      Duration: ~175 hours
      Difficulty: Medium
      Mentor: Benson Muite, João Gouveia contact through https://matrix.to/#/#mancala:kde.org

      ~~~~~~~~~~
      Misc
      Project: Add more fuzzed libraries to oss-fuzz
      Brief explanation: oss-fuzz is a SAS for fuzzying code. We have a few libraries there (karchive, kimagefomats, kcodecs), but we should add more since we have quite some code that processes file formats.
      Expected results: As many projects/libraries as possible have been added to oss-fuzz
      Knowledge Prerequisite: docker/compiling
      Duration: ~350 hours
      Difficulty: Medium
      Mentor: Albert Astals Cid <aacid@kde.org>

      ~~~~~~~~~~
      GCompris
      Project: Enhancing GCompris Server with GUI Sub-Programs for Dataset Creation
      Project Overview: This project aims to enhance the GCompris server by integrating a set of GUI-based sub-programs specifically designed for teachers. These tools will facilitate the creation of new datasets for various educational applications.The applications targeted for dataset expansion include:
         Grammar Analyses
         Graduated Lines
         Decimal Numbers
         Share
         Fractions Create
      By implementing these sub-programs, educators will be able to customize learning materials more effectively to fit their pupils needs.
      Resources Required:
         Developers with experience in Qt/QML, Gitlab.
         Being able to compile GCompris on QT6 and use it.
      Development resources:
      The server source code is available here : https://invent.kde.org/education/gcompris/-/tree/work/server_qt6?ref_type=heads The development guide is here: https://invent.kde.org/education/gcompris/-/wikis/Developers-corner/Development-process
      Duration: ~175 hours
      Difficulty: Middle
      Mentor: Emmanuel Charruau, Johnny Jazeix (contact on Matrix KDE Webchat)

      ~~~~~~~~~~
      Kdenlive
      Project: Improving Kdenlive timeline markers
      Brief explanation: Kdenlive already allows the user to add markers to the timeline and inside clips. The idea is to update the current code to add a duration attribute to the markers. With this change, markers will be able to represent a time range with a start and an end time, which will unlock some nice new features. See this issue for more technical details.
      Expected results: An nice display of the time range markers in the timeline and monitors. The marker's time range should also be connected to existing features and extend them, like render a marker's range, or improved searching.
      Knowledge Prerequisite: C++, Qt, will also involve some Qml
      Duration: ~175 hours
      Difficulty: Medium
      Mentor: Jean-Baptiste Mardelle (https://matrix.to/#/@j-b-m:matrix.org)
      Marknote

      ~~~~~~~~~~
      Project: Implement block editor
      Brief explanation: Implement a basic block editor where each elements from markdown is transformed into a block which can be drag-and-dropped.
      Inspiration can be taken from https://rubymamistvalove.com/block-editor
      Expected results: A nice rich text editor which can then be also reused in other apps like Merkuro Mail.
      Knowledge Prerequisite: C++, Qt, will also involve some Qml
      Duration: ~350 hours
      Difficulty: Medium
      Mentor: Carl Schwan (https://matrix.to/#/#marknote:kde.org)

      ~~~~~~~~~~
      digiKam
      Project: Interface the database search engine to an AI based LLM
      Brief explanation: The digiKam photo management program already allows the user to search items over the collections using a database. Many powerful search tools can find items by many criteria such as metadata, aesthetic contents, face, place, date, hierarchical keywords, etc. The idea is to add a new top-level interface where users can enter a human phrase which describes the contents to search. With this change, the searches can be user-friendly to use without having to pass plenty of settings used to tune the engine. The LLM must be included in the application, without using an external web-service, as it's not permitted to share data over the Internet. All the new implementations must be written in C++, not Python.
      Relevant entries in bugzilla: - wish 497938 - wish 367700
      Expected results: A nice and simple view where users type a human comprehensive phrase to search items over the photo collections.
      Knowledge Prerequisite: C++, Qt, OpenCV, AI modeling, Large Language Model
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Michael Miller (michael_miller@msn.com), Maik Qualmann (metzpinguin@gmail.com), and Gilles Caulier (caulier.gilles@gmail.com)
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kde-community/
    idea_list_url: https://community.kde.org/GSoC/2025/Ideas

  - organization_id: 75
    organization_name: Keploy
    no_of_ideas: 6
    ideas_content: |
      
      1. AI-Powered Open-Source Code Review Agent (Using any CI/CD workflow)
      Mentors: Hermione, Gourav, Yash, Shubham
      Develop an AI-driven, open-source code review agent that integrates with version control platforms and CI/CD pipelines to provide automated feedback on coding style, security vulnerabilities, and best practices. Use any CI/CD runners and open-source static analysis tools to improve the developer experience in open-source projects.
      Description: The objective of this project is to enhance the Keploy Playground by introducing new functionalities, improving user experience, and expanding its capabilities. This includes:
      Expanding Language Support: Adding robust support for multiple programming languages such as Java and Python.
      Integrating Test & Mock Support: Providing comprehensive functionalities to generate tests and simulate mocks seamlessly.
      Improving User Onboarding: Redesigning the user experience, especially the onboarding process, to ensure a smooth introduction to Keploy’s capabilities.
      Tasks:
      Explore the architecture and workflows of various open-source code review systems to understand their impact and areas for improvement and build a matrix comparing them based on features such as accuracy, language support, ease of integration, and performance
      Build a modular webhook-based system to allow easy integration with various platforms.
      Integrate OWASP Dependency-Check or Google’s Open Source Insights (deps.dev API) to detect vulnerable dependencies.
      Export review results in JSON, Markdown, or PDF formats for offline analysis.
      Skills Required:
      CI/CD workflows & automation
      REST APIs & Webhooks
      Golang
      JavaScript/TypeScript, Node.js
      Static Code Analysis Tools (ESLint, GolangCI-Lint)
      AI/ML for automated code review - Vertex AI (Optional but beneficial)
      Refs
      ESLint: Pluggable JavaScript Linter
      GolangCI-Lint
      Time Estimate : 350 hours
      Difficulty : Hard

      ~~~~~~~~~~
      2. OSS Code Indexer for Efficient Retrieval
      Mentors: Shivam, Charan, Sarthak, Shubham Jain
      Goals & Ideas Develop an efficient code indexing system that enables fast and scalable code search and retrieval. The system will integrate open source unit test geneartion with a Retrieval-Augmented Generation (RAG) indexer, utilizing vector and graph databases to improve query efficiency and relevance. The goal is to create a robust and scalable solution that can handle large open-source codebases and enable better code discovery, navigation, and reuse.
      Integrate the existing RAG bot with a vector database.
      Explore dynamic indexing techniques to improve efficiency.
      Research methodologies for leveraging GRAGs to enhance retrieval.
      Test OSS UTG with OSS Repos.
      Integrate Gemini with UTG.
      Skills Required
      Experience with RAG (Retrieval Augmented Generation) architectures.
      Knowledge of vector databases (e.g., Pinecone, FAISS, Weaviate, etc.).
      Understanding of graph databases and their integration with AI systems.
      Familiarity with indexing strategies for efficient code retrieval.
      Proficiency in Python/Golang for backend development.
      Refs
      Research papers on RAG and GRAG models.
      Documentation for vector and graph databases.
      Tasks
      Integrate the existing RAG bot with a Milvus.
      Modify the existing RAG bot to store code snippets as vector embeddings in Milvus.
      Explore dynamic indexing techniques to improve efficiency.
      Research and compare different indexing techniques (HNSW, IVF, PQ, Flat Index) for faster retrieval.
      Research methodologies for leveraging GRAGs to enhance retrieval.
      Implement a prototype that combines vector search with graph-based retrieval to improve accuracy.
      Test Open-Source UTG (Unit Test Generation) with OSS Repositories.
      Run Keploy’s OSS Unit Test Generator (UTG) on real-world repositories and suggest optimizations for the UTG model based on results.
      Use Gemini AI (Google’s LLM) to generate better test cases from indexed OSS codebases.
      Time Estimate : 350 hours
      Difficulty : Medium

      ~~~~~~~~~~
      3. TestSuite Idempotency Checker
      Mentors: Animesh, Sarthak Shyngle, Neha Gupta
      Description: Ensuring idempotency in test suites is crucial for reliable and repeatable testing. This project focuses on analyzing test cases to identify operations that should be idempotent, it will help in detecting noisy parameters and inconsistencies which may lead to flaky tests.
      Goals & Ideas
      Identify Noisy Parameters – Automatically detect parameters in test cases that cause unnecessary variations, leading to non-idempotent behavior.
      Validate CRUD Operations – Ensure that CRUD requests in test cases conform to idempotency rules by verifying their consistency across multiple executions.
      HTML-based Test Verification – Check test cases that interact with HTML responses to ensure stable outputs and prevent unintended failures.
      Automated Idempotency Reporting – Develop a reporting mechanism that flags test cases violating idempotency, with insights into potential fixes.
      Tasks
      Implement Idempotency Check for GET Requests in Postman
      Denoise the un-expected Parameters (timestamp, headers, token's, change in body response) from Keploy Testcases
      Create a basic report template using Allure or Extent Reports.
      Handling noisy parameters of big payloads(10k or more lines) in the cli-diff viewer.
      Skills Required
      Scripting Languages such as Python, Bash.
      Golang
      Logical Reasoning + DSA
      Ref
      idempotency and safety in REST APIs
      How Idempotent REST APIs Boost Reliability and Error Handling
      Idempotent Message Validator
      Time Estimate : 350 hours
      Difficulty : Medium

      ~~~~~~~~~~
      4. Improve Keploy Open-Source Playground console
      Mentors: Aditya Sharma, Shivam Jha, Tvisha Raji, Manas, Neha Gupta
      Description
      The goal of this project is to elevate the open-source Keploy Playground for the contributors to understand record-replay. Few of the features requests b community includes:
      Expanding Language Support: Adding support for more languages such as Java, Python, Node.
      Integrating Test & Mock Support: Adding support to fetch generated tests from the keploy server and simulated mocks which can be editable on the playground.
      Improving User Onboarding: Currently the playground lags if the payload is big, or in case of AI/ML genrated tests, the idea is to improve performance of the react console so that other community members can experience it well.
      Goals & Ideas
      Currently Loading Structure Loading is Fragile: Improve the user experience by fixing the performance issues and handling edge cases.
      Interactive Demo Environment: Build a dynamic playground console where users can interact with live demos, generate tests, and see real-time results.
      Automated Test Generation from URL Input: Allow users to provide a URL, then automatically scrape the frontend to generate a sitemap, identify API calls, and create tests based on the discovered endpoints using ATG
      Multi-Language Testing Support: Implement a flexible backend architecture that supports testing across multiple languages, making Keploy a versatile tool for a diverse range of applications.
      Skills Required
      Next.js, React, typescript
      API call handling
      Golang, Java, Python
      [optional] AI/ML
      Refs
      [source code] - https://github.com/keploy/website/tree/main/app/(default)
      Meshery Playground
      Time Estimate : 350 hours
      Difficulty : Medium

      ~~~~~~~~~~
      5. API contract matching - Adding Features and Platform support
      Mentors: Gourav Kumar, Charan Kamarapu, Ahmed Lotfy, Shubham Jain
      Description: The goal of this project is to enhance the functionality of contract testing by adding new features and improving existing capabilities. This includes better schema storage, consolidation, and validation, along with exploring a provider-driven approach as a future enhancement.
      Goals & Ideas
      Schema Storage Enhancement: Implement local storage support for schemas, functioning as a mock public registry (e.g., S3).
      Unified Schema Management: Merge individual test/mock schemas into a comprehensive single schema for each service, consolidating all APIs
      Advanced Schema Comparison: Design and improve schema validation between interconnected services to ensure consistency.
      Provider-Driven Architecture: Develop and integrate a provider-driven contract testing model into Keploy, allowing service providers to define and manage contracts efficiently.
      Skills Required
      Golang
      REST APIs
      Refs
      What is Contract Testing?
      Keploy Documentation
      What is a REST API? - IBM
      A Tour of Go
      Tasks
      Implement Microservices Architecture with HTTP APIs & Validate Keploy Contract Testing
      Identify and Resolve Issues in Keploy Contract Testing Implementation
      Time Estimate : 350 hours
      Difficulty : medium

      ~~~~~~~~~~
      6. App Dashboard with Metrics and Chart
      Mentors: Manas Manohar, Tvisha Raji, Hermione Dadheech, Neha Gupta
      Description
      The objective of this project is to create a console that provides interactive visualizations, metrics, and insights for code merges and test activities.
      The console should support dynamic updates and be powered by a Go web server that processes and serves data.
      It should be structured for easy extensibility, making it straightforward to add new metrics or charts in the future.
      Goals & Ideas
      Dynamic Dashboard: Develop a frontend that aggregates and displays real-time test reports using visual elements such as graphs and charts
      Template-Based PR Insights: Allow users to create and utilize templates for code analysis, offering customizable views for different teams and workflows.
      Scalable & Modular Design: Ensure the system’s architecture is modular and can accommodate new metrics, charts, or data sources with minimal effort.
      Tasks:
      Build a web app that tracks multiple repositories and user activities, offering a customizable feed of test outcomes and analytics.
      Research techniques for building modular dashboards, data processing, and integration with various version control or repository hosting services.
      Skills Required
      Next.js, Charting Libraries(e.g., Chart.js, Recharts, D3.js)
      Golang
      MongoDB
      Refs
      Grafana – For inspiration on dashboard design and real-time data visualization.
      Golang Documentation – For best practices in building scalable Go services.
      Time Estimate : 350 Hours
      Difficulty : Medium
     
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/keploy/
    idea_list_url: https://github.com/keploy/gsoc/tree/main/2025


  - organization_id: 76
    organization_name: Kiwix
    no_of_ideas: 6
    ideas_content: |
      
      What it is: WP1 is the bot and website that provides tables like this one on English Wikipedia. The tables help editors determine which articles they should focus on in their WikiProjects. The website also provides tools for creating a Wikipedia “selection”, ie a list of articles, so that they can create a ZIM file and have a subsetted offline version of Wikipedia.
      Project A, Combinator Builder: There are currently multiple ways to build a selection, from simple article lists to SPARQL queries. We wish to create a “combinator” builder, which allows a user to combine existing or future builders to create a final selection.
      Deliverables:
      Provide a data model for a combinator builder that integrates with the rest of the WP1 site
      Provide a UI frontend for users to create combinator builders
      Sufficient backend and frontend tests
      Skills required:
      Good understanding of Python
      Understanding of Javascript
      Understanding of Vue.js or willingness to learn
      Difficulty: Medium
      Scope: Small (about 90 hours of work)

      ~~~~~~~~~~
      Project B, Scheduled selections/ZIMs: Currently, users create their selections and then manually request/create their ZIM files. However, for certain classes of selections, such as those based on WikiProjects or SPARQL queries, it is possible that the results are stale and there are more recent results available.
      We should provide a way for a user to schedule their selection being processed into a ZIM file (1 month, 3 months, 6 months, 1 year). As part of this process, the user should provide us with an email where we can notify them that their ZIM has been created. We should also remove ZIMs from the schedule if the user doesn’t “claim” them, ie come to the website and download them.
      Deliverables:
      Scheduling system for running ZIM creation tasks on set intervals
      Method for collecting email addresses, and publication of privacy policy for handling of PII
      Frontend UI for scheduling ZIM files, including handling required input and error cases
      Sufficient backend and frontend tests
      Skills required:
      Good understanding of Python
      Understanding of Javascript
      Understanding of Vue.js or willingness to learn
      Difficulty: Medium-Easy
      Scope: medium (about 120-150 hours of work)
      Interested? Check out the repo.

      ~~~~~~~~~~
      Kolibri UI Revamp
      Some of the content we offer is actually harvested by our friends at Learning Equality. Kolibri2zim is the tool that allows us to package it to the ZIM format. The UI rendition isn’t great and we’d like to fix that.
      Objective: Redo the menu UIs based on a new design. Foundations have already been laid in a Git branch, but some features have not yet been implemented or are missing.
      Technologies: Vue.js + a bit of Python
      Key Deliverables:
      Finalised code changes for creating beautiful Vue.js UIs inside Kolibri ZIMs
      Skills required:
      Good understanding of JavaScript, HTML, and CSS
      Familiarity with at least one modern JS Framework (React, Vue.JS, Angular, …)
      Knowledge of web development and user interface design.
      Difficulty: Medium, but short (90 hours) project
      Interested? Check out the repo!

      ~~~~~~~~~~
      Gutenberg Library UI Revamp
      We provide a ZIM copy of the Gutenberg library but saying that its layout and design is not optimal would be an understatement.
      Objective and deliverable:
      suggest and implement a new UI for this zim
      Difficulty:
      Medium (mostly because good developers suck at design, and good designers suck at coding), probably 175 hours.
      Skills required: vue.js
      Look around the gutenberg repository here.

      ~~~~~~~~~~
      TED Talks UI Revamp
      We also provide a ZIM copy of the TED talks, and although it’s not as bad as Gutenberg, it could do better.
      Objective and deliverable:
      Suggest and implement a new UI for this zim
      Difficulty:
      Medium, probably 175 hours.
      Skills required: vue.js
      Check out the TED repository here.

      ~~~~~~~~~~
      Hotspot Companion
      The Kiwix-hotspot is a neat adaption of the Raspberry pi microserver into a local hotspot that entire classrooms can connect to without having to download anything onto their devices. The hotpost owner downloads content from our library onto a microSD card running the Raspbian OS, and off they go, the hotspot is fully autonomous with Kiwix-server working as a regular http daemon. The problem arises when users want to update the available content, or download usage metrics collected by the hotspot.
      Objective and deliverable: Develop a mobile application prototype serving as a bridge between internet connectivity and the offline mode of a Raspberry Pi-based hotspot. The primary goal is to facilitate efficient data synchronization, allowing users to leverage internet benefits when available while ensuring a seamless offline experience. The application will have a very simple interface enabling users to manage the transfer of data between the remote server and the Raspberry Pi.
      Difficulty: Hard (it touches on many different techs but the good news is we don’t expect more than a working prototype), 350 hours.
      Skills required: mobile, flutter
      
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kiwix/
    idea_list_url: https://kiwix.org/en/google-summer-of-code/


  - organization_id: 77
    organization_name: Kornia
    no_of_ideas: 7
    ideas_content: |
      
      Implement efficient Smol VLM
      Description: The aim of this project is to bring State of the Art methods for lightweight Visual Language models into Kornia in Rust. Recently, Hugging Face released a family of small visual language models (SmolVLM) which can be a game changer for the industry to build applications in embedded devices using such AI models.
      Expected Outcomes: The expectation is to implement an API in Rust to integrate the latest SmolVLM model. Evaluate which NN engine suits better for this task, either onnxruntime (via ORT-Pyke) or Candle. It’s expected also to evaluate a native Rust implementation of the model and its feasibility. Tests and benchmarks in both desktop and nvidia jetson are also mandatory as part of the final delivery.
      Resources:
      Rust Book: https://doc.rust-lang.org/book/
      ORT: https://ort.pyke.io/
      Candle: https://github.com/huggingface/candle
      SmolVLM: https://huggingface.co/HuggingFaceTB/SmolLM-1.7B-Instruct
      Possible Mentors: Miquel Farre
      Difficulty: Medium
      Duration: 350 hours

      ~~~~~~~~~~
      Apriltag and calibration detectors
      Description: This project aims to implement in Kornia Rust curated detection algorithms useful for localization and calibration purposes. It’s very common to use April tags for camera calibration applications; or corners detectors for more advanced machine vision applications. In the area of visual localization, common algorithms are FAST (because it is really fast), or ORB. With such methods kornia-rs could be used in many robotics applications together with existing foundational libraries such sophus-rs.
      Expected Outcomes: Implement efficient CPU versions of the above detectors with proper testing and benchmarking against common libraries such OpenCV or VPI. It’s expected also as part of the delivery to work together with the author of sophus-rs to show an integration of a calibration system using e.g the april tag detector and/or using FAST features for a Visual SLAM implementation.
      Resources:
      Rust Book: https://doc.rust-lang.org/book/
      Nvidia VPI: https://docs.nvidia.com/vpi/index.html
      Opencv-rs: https://docs.rs/opencv/latest/opencv/
      Aprilgrid-rs: https://github.com/powei-lin/aprilgrid-rs
      Sophus-rs: https://github.com/sophus-vision/sophus-rs
      Possible Mentors: Edgar Riba
      Difficulty: Hard
      Duration: 350 hours

      ~~~~~~~~~~
      Pointcloud registration algorithms
      Description: This project aims to provide 3D registration capabilities to kornia-rs through pointcloud processing via implement local or global methods such as expanding the family of ICP algorithms with newer state of the art KISS family.
      Improve existing Iterative Closest Point (ICP) for point cloud alignment by adding Point to Normal loss, or evaluate again KISS-ICP.
      Optional, implement Truncated Signed Distance Function (TSDF).
      The implementations should be optimised to use for near real-time systems
      Resources:
      Rust Book: https://doc.rust-lang.org/book/
      ICP: https://manipulation.csail.mit.edu/Fall2020/pset2/pset2_ICP.html
      KISS-ICP: https://arxiv.org/abs/2209.15397
      TSDF: https://www.open3d.org/docs/0.14.1/tutorial/t_reconstruction_system/integration.html
      Possible Mentors: Sergey
      Difficulty: Hard
      Duration: 350 hours

      ~~~~~~~~~~
      Camera Pose Estimation algorithms
      Description: This project aims to enhance kornia-rs's capabilities in 3D registration and pose estimation by implementing and optimizing key algorithms, including:
      Perspective-n-Point (PnP) and Efficient PnP (EPnP) for camera pose estimation
      Affine and similarity transformations (e.g., cv2.AffineTransform3D) for rigid and non-rigid transformations
      Potential optimizations for near real-time performance and robustness
      Expected Outcomes:
      A set of efficient, well-tested Rust implementations of the above algorithms
      Integration with kornia-rs for seamless use in robotics, AR, and SLAM applications
      Benchmarking and comparison with existing implementations for accuracy and performance such as Open3D
      Comprehensive documentation and examples
      Expected Outcomes:
      A set of efficient, well-tested Rust implementations of the above algorithms
      Integration with kornia-rs for seamless use in robotics, AR, and SLAM applications
      Benchmarking and comparison with existing implementations for accuracy and performance such as OpenCV
      Comprehensive documentation and examples
      Resources:
      Rust Book: https://doc.rust-lang.org/book/
      PNP : https://medium.com/@rashik.shrestha/perspective-n-point-pnp-f2c7dd4ef1ed
      KISS-ICP: https://arxiv.org/abs/2209.15397
      TSDF: https://www.open3d.org/docs/0.14.1/tutorial/t_reconstruction_system/integration.html
      Possible Mentors: Dmytro Mishkin, Daniel Barath
      Difficulty: Hard
      Duration: 350 hours

      ~~~~~~~~~~
      Implement GPU image transforms
      Description: This project has the main objective to improve the existing image transformations in the kornia-imgproc crate which are currently implemented in native CPU to be upgraded to GPU. Ideally, propose a plan to upgrade the functionality in this crate into efficient GPU implementations via CubeCL or similar that can support WGP in native Rust. An example would be geometric sampling transformations like resize, or warp_affine/warp_perspective. Additionally, color transformations and Distance Transform would be very welcomed.
      Expected Outcomes: Finished implementations of the functions with proper documentation, testing and benchmarking against existing libraries such OpenCV or Nvidia VPI. Examples and tutorials are expected as part of the end of the project delivery as testing in Nvidia Jetsons.
      Resources:
      Rust Book: https://doc.rust-lang.org/book/
      Kornia Imgproc Crate: https://github.com/kornia/kornia-rs/tree/main/crates/kornia-imgproc
      CubeCL: https://github.com/tracel-ai/cubecl
      Nvidia VPI: https://docs.nvidia.com/vpi/index.html
      Opencv-rs: https://docs.rs/opencv/latest/opencv/
      Possible Mentors: Edgar Riba; Guillaume (tracel-ai)
      Difficulty: Hard
      Duration: 350 hours

      ~~~~~~~~~~
      Depth Estimation on Android Using Rust
      Description: This project aims to develop an Android application using Rust to perform real-time depth estimation with ONNX Runtime via Rust bindings for ONNX Runtime. By leveraging Rust’s performance efficiency and memory safety, the application will enable on-device AI processing for applications in robotics, augmented reality (AR), SLAM, and 3D scene reconstruction.
      Expected Outcomes:
      A fully functional Rust-based Android application capable of real-time depth estimation.
      Integration of ONNX Runtime via Pyke’s Rust bindings for optimized AI inference.
      Utilization of Android’s official Rust build system for compatibility and performance.
      A lightweight, user-friendly UI for depth visualization.
      Performance benchmarking to compare execution efficiency.
      Comprehensive documentation and a demo video showcasing real-world applications.
      Resources:
      Android’s Official Build System for Rust Modules: Overview
      ONNX Runtime with Rust Bindings: ORT
      Depth Estimation Models: [Depth-Anything, MiDaS, etc.]
      Possible Mentors: Christie Jacob
      Difficulty: Medium
      Duration: 350 hours

      ~~~~~~~~~~
      Implementation of VO Slam API
      Description: This project aims to build a Visual Odometry (VO) SLAM API in Rust for the Kornia-rs ecosystem, focusing first on an RGB-D pipeline (e.g., iPhone LiDAR data + Prompt DepthAnything for high-resolution, accurate depth) and subsequently extending it to monocular-only VO. The implementation should be efficient, dependency-light, and well-suited for real-time or near–real-time robotics and AR/VR use cases.
      Expected Outcomes: A VO SLAM crate in Rust that is straightforward to integrate with Kornia-rs, starting first with the simpler RGB-D visual odometry pipeline and making progress towards robust monocular visual odometry pipeline in rust.
      Resources:
      RGB-D Odometry Open3D
      Monocular Visual Odometry
      Visual Odometry From Scratch
      Global Registration Open3D
      MadPose - Relative Pose Estimation through Affine Corrections of Monocular Depth Priors
      PromptDA - Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation
      Possible Mentors: Pablo Vela
      Difficulty: Hard
      Duration: 350 hours
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kornia/
    idea_list_url: https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025

  - organization_id: 78
    organization_name: Kotlin Foundation
    no_of_ideas: 11
    ideas_content: |
     
     
      Build Server Protocol: add Kotlin support [Hard, 350 hrs]
      The Kotlin team wants to expand official Kotlin support not only for Gradle and Maven build systems, but any other build system as well and support them natively in JetBrains IDE with minimal effort. On the other hand, we also want to provide basic Kotlin support in non-JetBrains IDE – one part of such support is to be able to get Kotlin specific information from any build system supporting Kotlin.
      The solution to these requirements could be a Build Server Protocol (BSP) that provides an abstraction layer between build system and IDE.
      The goal of this project would be implementing a prototype which uses the BSP protocol to get all required for IDEA information from a user project to be able to work with Kotlin code in the project. To limit the scope of this prototype – user project will be using Gradle to build itself.
      Skills required (preferred)
      Kotlin
      Understanding how to write Gradle plugins
      Bonus: understanding how to write IntelliJ IDEA plugins
      Possible mentors
      Yahor Berdnikau, Bálint Hegyi, and Reinhold Degenfellner
      Tasks for applicants
      Task #1. Why are you interested in this project?
      Task #2. Practice assignment: create a Gradle plugin which exposes a specific task. This task should on the presence of Kotlin Gradle Plugin get all the Kotlin sources structure and output to the file. Having tests is a bonus
      
      ~~~~~~~~~~
      Support Android and iOS targets in Kotlin Multiplatform for an existing Google service [Medium, 175 hrs]
      This project aims to create an open-source Kotlin Multiplatform (KMP) library that supports an existing Google service on at least Android and iOS. This project will showcase best practices in creating KMP libraries for existing services, with a focus on appropriate production implementation (for example, proper API key management, allowing user-managed API keys, client throttling).
      Expected outcomes
      A new Kotlin Multiplatform library with support for an existing Google service
      Sample code and documentation
      Skills required (preferred)
      Kotlin
      Kotlin Multiplatform
      Mobile development (Android and iOS)
      Possible mentor
      Matt Dyor, and the Google team

      ~~~~~~~~~~
      Add Kotlin Multiplatform support in Bazel [Hard, 350 hrs]
      Bazel's support for Kotlin is evolving, but proper Kotlin Multiplatform (KMP) integration remains a challenge. This project aims to improve Bazel's KMP support by addressing dependency resolution issues, enhancing rules_kotlin and rules_jvm_external compatibility, and enabling cross-platform builds.
      Key improvements will focus on handling platform-specific dependencies (expect/actual mechanisms), improving Gradle metadata support, and ensuring a smoother developer experience for KMP in Bazel.
      Expected outcomes
      Enhanced dependency resolution for Kotlin Multiplatform in Bazel
      Improved integration with rules_kotlin and rules_jvm_external
      A working KMP build setup in Bazel for seamless multiplatform development
      Skills required (preferred)
      Kotlin Multiplatform and Gradle
      Bazel build system
      Dependency resolution strategies
      Possible mentor
      Shauvik Roy Choudhary, and the Uber team
      
      ~~~~~~~~~~
      Kotlin Language Server (LSP) [Hard, 350 hrs]
      The Language Server Protocol (LSP) is a widely adopted standard that enables code intelligence features such as autocompletion, go-to definition, and refactoring across different editors and IDEs. There is currently no official Kotlin LSP server. Uber has developed an internal Kotlin LSP, but a publicly maintained, community-driven implementation can support broader use cases, including code migration, AI-powered code assistance, and seamless integration into various development environments.
      This project aims to develop a Kotlin LSP implementation, ensuring compatibility with key LSP features and broadening Kotlin's accessibility across development environments.
      Expected outcomes
      Develop a Kotlin LSP implementation
      Skills required (preferred)
      Kotlin
      Language Server Protocol (LSP)
      Plugin or extension development for IDEs
      Possible mentor
      Shauvik Roy Choudhary, and the Uber team
      Maven Central publishing plugin for Gradle with new APIs [Medium, 175 hrs]
      Maven Central is one of the most popular Maven repositories for publishing JVM-focused libraries and projects. It is actively used by Apache Maven or Gradle-based open-source projects, and based on Sonatype Nexus v2, pending migration to a newer version. There is ongoing migration of open source projects to a new Maven Central Instance, which has a very different API implementation and needs special support in the build tool plugins. Developing a Gradle plugin that is compatible with the new Maven Central publication APIs would help the library authors building with Gradle to have a smooth experience with the new process.
      Currently, there are multiple implementations of Maven Central publishing plugins in Gradle, for example, the Maven Publish Plugin or the New Maven Central Publishing, which already tries to adopt the new APIs. A potential contributor, during the application or the community bonding phase, would need to review the implementations and suggest a plugin to be updated, or decide to build a new plugin or fork. The deliverables would include either a new version of an existing plugin for Maven Central publishing or a new plugin for Gradle. We anticipate the implementation to be in Kotlin or Java and to have proper test coverage and documentation. Additional deliverables may include Kotlin DSL extensions to simplify the use of the plugins and Declarative Gradle extensions.
      Expected outcomes
      Updated Maven Central publishing plugin or a new plugin
      Skills required (preferred)
      Kotlin
      Gradle
      Maven Repositories
      Possible mentor
      Oleg Nenashev, and the Gradle team
      
      
      ~~~~~~~~~~
      Improving Configuration Cache and lock contention in key Gradle plugins [Easy to Hard, 90 hrs to 350 hrs]
      Gradle is working on Isolated Projects – a new feature that greatly extends the configuration cache to further improve performance, particularly the performance of Android Studio and IntelliJ IDEA sync. From the developer experience standpoint, it is one of the most expected features in Gradle.
      One of the problems for Isolated projects is the lock contention in the Gradle core and plugins sometimes getting in the way of parallel execution. We would like to reduce the lock contention, especially in the key Gradle Build Tool plugins for Java, Kotlin, Android, and Kotlin Multiplatform ecosystems. Contributors are welcome to choose the deliverables, based on their interest and the desired project size.
      Potential deliverables include but not limited to:
      Embed the Configuration Cache Report tool into the Gradle Profiler (or implement a GitHub Action for it)
      Profile Gradle and a few popular Gradle plugins in various projects, with automation of the test suite on GHA
      Determine potential areas and plugins where lock contention can be reduced, with or without Configuration Cache
      While around, contribute to other areas of Configuration Cache compatibility in the target plugins
      Implement some of the discovered improvements
      Expected outcomes
      Implementing extensibility features in the Kotlin DSL for Gradle and improving support for common project integrations
      Skills required (preferred)
      Kotlin
      Gradle
      Java
      Performance analysis
      Profiling
      Possible mentor
      Oleg Nenashev, Laura Kassovic

      ~~~~~~~~~~
      Gradle convention plugin for developing Jenkins plugins [Easy to Hard, 90 hrs to 350 hrs]
      There are more than 50 Jenkins plugins that are implemented with Gradle. There is a Gradle JPI plugin, but it is not fully compliant with Jenkins hosting requirements, and needs an update. In this project idea, the aim would be to recover the Gradle developer flow for Jenkins, reach feature parity with the Apache Maven flow (Parent POM, Plugin Compatibility Tester, Jenkins Bill of Materials, and others), and to improve the developer experience for those who develop Jenkins plugins with Gradle.
      Contributors are welcome to choose the deliverables, based on their interest and the desired project size.
      Potential deliverables include but not limited to:
      Refreshing the Gradle JPI plugin and making it compliant with hosting best practices
      Migrating the Gradle JPI plugin codebase from Groovy to Kotlin
      Implementing a new convention plugin for Jenkins Plugins that would cover the main features of Jenkins plugin Parent POM, with Kotlin and Kotlin DSL. This would include not just building the plugin, but also testing and static analysis according to Jenkins' best practices
      Adopting the refreshed plugin and/or the convention plugin in the most popular Gradle plugin, including the Gradle Plugin itself
      Integrating Gradle Plugins into Plugin Compatibility Tester and Bill of Materials
      Documenting the updated Gradle development flow for Jenkins plugins
      Expected outcomes
      Updated Gradle JPI Plugin AND/OR new convention plugin for Jenkins, published on Jenkins Update Center and Gradle Plugin Portal
      Skills required (preferred)
      Kotlin DSL
      Kotlin
      Gradle
      Jenkins
      Java
      Possible mentor
      Oleg Nenashev, Stefan Wolf

      ~~~~~~~~~~
      Kotlin DSL and Declarative Gradle documentation samples test framework [Easy to Medium, 90 hrs to 175 hrs]
      Many projects, including Gradle, have a lot of Kotlin DSL samples and code snippets (see the Gradle Docs for examples). Testing them against multiple versions poses certain challenges because the snippets often represent incomplete code for the sake of brevity. We would like to build a test framework that simplifies the verification of those samples within a unit test framework (Kotest or JUnit 5) on GitHub Actions or Teamcity. Later we would be interested in doing the same for Declarative Gradle samples.
      Expected outcomes
      Implementing extensibility features in the Kotlin DSL for Gradle and improving support for common project integrations
      Skills required (preferred)
      Kotlin
      Gradle
      Java
      Static analysis
      Possible mentor
      Oleg Nenashev, Laura Kassovic

      ~~~~~~~~~~
      IntelliJ Platform Gradle Plugin – Gradle Reporting and Parallel Verifications [Medium, 175 hrs]
      The IntelliJ Platform Gradle Plugin, a plugin for the Gradle build system, simplifies configuring your environment for building, testing, verifying, and publishing plugins for IntelliJ-based IDEs. The plugin manages the build, test, and verification steps while keeping up with the constant changes introduced in the IntelliJ Platform. The IntelliJ Platform Gradle Plugin is used by JetBrains, third-party developers, and external companies to integrate their workflows with JetBrains tools.
      Expected outcomes
      Introduce Gradle Reporting to provide detailed, configurable verification task reports.
      Utilize Gradle Worker API to enable parallel execution of the verifyPlugin task against multiple IntelliJ Platform versions, reducing the task execution time.
      Explore additional Gradle enhancements to further improve plugin development workflows.
      Skills required (preferred)
      Kotlin
      Gradle
      IntelliJ Platform
      Possible mentor
      Jakub Chrzanowski, JetBrains

      ~~~~~~~~~~
      Add More Kotlin OpenRewrite Recipes [Medium, 175 hrs]
      OpenRewrite is a powerful framework for automating code migrations and refactorings in a structured manner. While OpenRewrite has strong support for Java, the Kotlin ecosystem would benefit from a more comprehensive set of OpenRewrite recipes to help developers seamlessly migrate their codebases.
      Expected outcomes
      Development of new OpenRewrite recipes for Kotlin code migrations
      Skills required (preferred)
      Kotlin
      OpenRewrite framework
      Java-to-Kotlin migration strategies
      Possible mentor
      Shauvik Roy Choudhary, and the Uber team

      ~~~~~~~~~~
      Add BOM Support to Bazel rules_jvm_external [Hard, 350 hrs]
      Bazel's rules_jvm_external provides a structured way to declare external Java dependencies, but it currently lacks proper support for Bill of Materials (BOM) files. BOM files are widely used in Maven and Gradle to manage dependencies in a consistent manner without requiring developers to specify individual versions. This project aims to enhance rules_jvm_external by adding BOM support, allowing developers to use BOM-based dependency resolution within Bazel. The project may involve contributing to an existing open-source effort or implementing BOM support directly in rules_jvm_external, ensuring compatibility with widely used dependency management approaches.
      Expected outcomes
      Implementation of BOM support in Bazel rules_jvm_external
      Improved dependency resolution and usability for Bazel users
      Documentation and examples for using BOM support in Bazel
      Skills required (preferred)
      Starlark (Bazel's scripting language)
      Bazel build system
      Dependency resolution strategies
      Possible mentor
      Shauvik Roy Choudhary, and the Uber team

      ~~~~~~~~~~
      Clean and actionable reporting for Gradle code quality plugins for Kotlin [Easy to Medium, 90 hrs to 175 hrs]
      Gradle recently introduced a new Problems API that allows Gradle and third-party plugins to propagate issues and warnings in a unified way. This API provides clean and actionable error reporting and more insights into the console output, dedicated HTML reports, and connected observability tools. IDEs, such as IntelliJ IDEA or Android Studio, also have access to the details via Gradle's tool integration API, and can show warnings right in the code editorI. Several core features and plugins have already adopted the Problems API: Java compilation, dependency resolution errors, deprecation warnings, etc. We want the code quality plugins for Kotlin to adopt this API, too; it would greatly improve the developer experience for 100,000+ Kotlin developers using Gradle.
      In this project, we invite contributors to choose a number of Kotlin code quality plugins, such as Ktlint, Detekt, Diktat, ArchUnit, or Checkstyle for Kotlin, and integrate them with Problems API. You can also work on integrating a similar analysis for Gradle builds defined with KotlinDSL.
      Expected outcomes
      Implement Problems API integration in the mentioned plugins
      Skills required (preferred)
      Kotlin
      Gradle
      Possible mentors
      Oleg Nenashev, Balint Hegyi, Reinhold Degenfellner

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kotlin-foundation/
    idea_list_url: https://kotlinlang.org/docs/gsoc-2025.html


  - organization_id: 79
    organization_name: KubeVirt
    no_of_ideas: 4
    ideas_content: |

      1. Dynamic attachment and removal of filesystem volumes
      GitHub issue: https://github.com/kubevirt/community/issues/384
      Description
      Direct directory sharing between a virtual machine and the host is made possible by filesystem devices. Pods and virtual machines can share the same Persistent Volume Claim thanks to this virtiofs. For instance, the capability to hotplugging an extra directory might be utilized to obtain diagnostic information from the VM and thereafter examine it.
      While attaching a disk to a running virtual machine dynamically is standard for VMs, it is an uncommon operation for pods. KubeVirt has already implemented the capability for hotplugging disks and LUNs, but it does not yet have the functionality to add or remove filesystems from a virtual machine. The volume hotplug/unplug feature isn’t supported natively by Kubernetes. KubeVirt mechanism relies on an additional pod known as the attachment pod to schedule and attach storage to the specific node where the VM is operating. Then, the storage is hotplug through Libvirt api.
      In addition, virtiofs is deployed in a separate container which is usually started together with the pod. However, in the case of hotplug, the pod cannot be dynamically modified with extra containers. This is a further challenge which needs to be taken into account during the design proposal.
      Expected outcomes
      The project goal is to propose and develop a solution based on the current approach of the attachment pod which supports filesystem volume types.
      Project requirements
      Project size: 350 hours
      Difficult: Hard
      Required skills: Kubernetes knowledge and GoLang programming skills
      Mentors: Alice Frosi: afrosi@redhat.com, German Maglione: gmaglion@redhat.com, Javier Cano Cano jcanocan@redhat.com
      See the GitHub issue for more information on the project, how to get started, and to ask questions.
      
      ~~~~~~~~~~
      
      2. Adding emulated BMC support to KubeVirt (KubeVirtBMC)
      GitHub issue: https://github.com/kubevirt/community/issues/386
      Description
      KubeVirt is a virtualization API for Kubernetes, that allows to run virtual machine-based workloads on Kubernetes. [1]
      Often times, developers require the ability to deploy applications or systems in local virtual environments like bare-metal ones. Existing solutions involve libvirt domains or QEMU VMs with Basedband Management Controller (BMC) emulators, which are not directly compatible with KubeVirt, necessitating a Kubernetes-native solution. The original RFE [2] was followed up by an implementation of a BMC emulator for KubeVirt named KubeVirtBMC [3].
      KubeVirtBMC facilitates the deployment of software/applications/platforms such as OpenShift and OpenStack - whose installers typically require communication with bare-metal out-of-band management protocols like IPMI and Redfish - in KubeVirt VMs for development, testing, and debugging purposes, similar to the functionality provided by VirtualBMC [4] and sushy-emulator [5] but within a Kubernetes context.
      As a result, a KubeVirt feature proposal was created and accepted [6], which now needs to be implemented. The proposal is divided into four phases, with work on phase one having already begun.
      Expected outcomes
      The project goal is to transfer KubeVirtBMC into the KubeVirt organization and to continue the development of a native BMC emulator for KubeVirt as laid out in the accepted proposal. Phases one to three of the proposal should be completed, while phase four is optional.
      Project requirements
      Project size: 350 hours
      Difficult: Hard
      Required skills: Kubernetes knowledge, GoLang programming skills, possibly experience with BMCs and the IPMI/Redfish protocols
      Mentors: Felix Matouschek fmatouschek@redhat.com, Zespre Chang starbops@zespre.com
      See the GitHub issue for more information on the project, how to get started, and to ask questions.
      
      ~~~~~~~~~~
      3. Self-sufficient virt-handler
      GitHub issue: https://github.com/kubevirt/community/issues/388
      Description
      Kubevirt is a Kubernetes extension to run vVirtual machines on Kubernetes clusters leveraging Libvirt + Qemu & KVM stack. It does this by exposing a custom resource called VirtualMachine which is then translated into a Pod. This Pod is treated as any other application Pods, and includes a monitoring process, virt-launcher, that manages the Libvirt+Qemu processes. The virt-launcher exposes a command grpc server for managing the virtual machine and has a notify client (see below notify server) through which it sends domain (virtual machine state) events and Kubernetes events.
      Each node in the cluster is running a node agent, called virt-handler. The virt-handler is using the command servers of virt-launchers to manage virtual machines. It is also providing a notify server that collects domain and Kubernetes events from launchers in order to obtain internal state of virtual machines.
      The hard dependencies on OS, file system, presence of virt-launcher Pod and GRPC servers make it hard to run virt-handler independently inside unprivileged Pod without the presence of virt-launcher. The goal of this project is to run virt-handler inside an unprivileged Pod and simulate a virt-launcher so that no Pod for virt-launcher needs to exist.
      Expected outcomes
      The main goal of this project is to create a proof of concept to run virt-handler in an unprivileged Pod without virt-launcher Pods to be running on the same host. This will enable scalability testing with significantly less resources required.
      Project requirements
      Project size: 350 hours
      Difficulty: Hard
      Required skills: Golang
      Desirable skills: Kubernetes, GRPC, Unix
      Mentor: Ľuboslav Pivarč lpivarc@redhat.com, Co-mentor: Victor Toso victortoso@redhat.com
      See the GitHub issue for more information on the project, how to get started, and to ask questions.
      
      
      ~~~~~~~~~~
      4. Early enablement of CBOR
      GitHub issue: https://github.com/kubevirt/community/issues/389
      Description
      Kubevirt is a Kubernetes extension to run Virtual machines on Kubernetes clusters leveraging Libvirt + Qemu & KVM stack. It does this by exposing custom resources (defined by Custom Resource Definition, also known as CRD) called VirtualMachine, VirtualMachineInstance, as well as resources for backpups and other features.
      From the beginning, Kubernetes supported only json or yaml format for custom resources, in fact that was a default for core API types as well. Support for Protocol Buffers (protobuf) was introduced for core API types while CRDs were left with json/yaml because they required a schema. The protobuf helped to scale Kubernetes beyond limitations presented in the past. Kubernetes 1.32 introduced Alpha support of CBOR (Concise Binary Object Representation) for CRDs, promising a more compact format and further aiding scalability of Kubernetes and related projects.
      The goal of this project is to build a proof of concept, integrating CBOR for our client-go, as well as enabling SIG-scale testing, paving the way for adoption once the feature graduates in Kubernetes.
      Expected outcomes
      The main goal of this project is to create a proof of concept, integrating CBOR into Kubevirt in a way that can be used to run our scalability jobs. This integration will need to be guarded as the feature is not widely available, and should include a comparison of CBOR and json, visual aids and a presentation for the community about the work and findings.
      For the future, we expect guidance for enabling the feature as well summarizing the benefits from this adoption.
      Project requirements
      Project size: 350 hours
      Difficulty: Medium
      Required skills: Golang
      Desirable skills: Kubernetes
      Mentor: Ľuboslav Pivarč lpivarc@redhat.com, Co-mentor: Pending
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kubevirt/
    idea_list_url: https://github.com/kubevirt/community/wiki/Google-Summer-of-Code-2025


  - organization_id: 80
    organization_name: Kubeflow
    no_of_ideas: 12
    ideas_content: |
     
      Project 1: Kubeflow Platform Enhancements
      Components: Kubeflow Manifests, Kubeflow Dashboard, Kubeflow Notebooks, Kubeflow Pipelines
      Possible Mentors: @juliusvonkohout, @thesuperzapper
      Difficulty: Hard
      Size: 350 hours
      Possible Projects:
      Pipelines: productionize the SeaweedFS PoC as secure minio replacement
      Pipelines: isolate artifacts per namespace/profile/user using only one bucket (kubeflow/pipelines#4649)
      Notebooks/Dashboard: migrate code to kubeflow/dashboard and kubeflow/notebooks (kubeflow/kubeflow#7549)
      Dashboard: work on the Central Dashboard angular rewrite (kubeflow/dashboard#38)
      Dashboard: support using groups for auth (kubeflow/manifests#2910)
      Manifests: improve scripts and CI/CD in kubeflow/manifests, including matrix calls to test multiple Kubernetes versions simultaneously
      Skills Required/Preferred:
      GitHub and GitHub Actions
      containers and Kubernetes knowledge
      Experience with Python, Go and JavaScript frameworks

      ~~~~~~~~~~
      Project 2: Kserve Models Web App
      Components: KServe
      Possible Mentors: @juliusvonkohout, @varodrig, @Griffin-Sullivan
      Difficulty: Medium
      Size: 175 hours
      Goals:
      Reviving and updating the kserve/kserve-models-web application.
      Clean up and merge the open issues and PRs
      Implement a better CI/CD pipeline.
      Potentially migrate the application to kubeflow/kserve-model-ui
      Add features for editing, regression testing, and monitoring/metrics support.
      Synchronize with kserve 0.14+ changes.
      Skills Required/Preferred:
      GitHub Actions
      containers and Kubernetes knowledge
      JavaScript frameworks

      ~~~~~~~~~~
      Project 3: Istio CNI and Ambient Mesh
      Components: Kubeflow Manifests
      Possible Mentors: @juliusvonkohout, @kimwnasptd
      Difficulty: Medium
      Size: 175 hours
      Goals:
      Secure our service mesh with istio-cni by default (kubeflow/manifests#2907)
      Provide an out-of-box option for istio-ambient mesh (kubeflow/manifests#2676)
      Controllers to create HTTPRoute and AuthorizationPolicies, that align with way-point proxies
      Manifests to also have a flavour of HTTPRoute and updated AuthorizationPolicies
      Secure Kserve by default (kubeflow/manifests#2811)
      Rootless Kubeflow (kubeflow/manifests#2528)
      Skills Required/Preferred:
      GitHub and GitHub Actions
      Kubernetes and networking
      Istio, Kustomize

      ~~~~~~~~~~
      Project 4: Deploying Kubeflow with Helm
      Components: Kubeflow Manifests, Kubeflow Pipelines, Kubeflow Trainer, Kubeflow Katib, Kubeflow Spark Operator, Kubeflow Model Registry
      Possible Mentors: @chasecadet, @varodrig, @juliusvonkohout
      Difficulty: Medium
      Size: 350 hours
      Goals:
      To extend our userbase and satisfy the requirement for a helm chart that many users and companies have voiced, a community-driven Helm chart is being developed for Kubeflow v1.10.x.
      Work with Kubeflow components maintainers and kubeflow/manifests to support the creation of Helm charts for a full Kubeflow deployment with similar functionality as the current kustomize manifests for the Kubeflow 1.10.x release.
      Investigate possible systems to automatically generate or maintain charts based on the existing kustomize manifests, such that we have a single source of truth.
      Skills Required/Preferred:
      Container and Kubernetes knowledge
      Helm (especially templating and chart creation)
      Kustomize (not strictly required, but a plus)

      ~~~~~~~~~~
      Project 5: JupyterLab Plugin for Kubeflow
      Components: Kubeflow Notebooks, Kubeflow Pipelines
      Possible Mentors: @ederign, @StefanoFioravanzo
      Difficulty: Medium
      Size: 350 hours
      Goals:
      Work with the new IDE Working Group (name pending - kubeflow/community#808) to create a JupyterLab plugin for Kubeflow
      Modernizing and/or consolidating Elyra, Kale, and Jupyter Scheduler into a single plugin for Kubeflow
      Eventually, the plugin will likely integrate with:
      Kubeflow Pipelines (priority)
      Kubeflow Notebooks
      Kubeflow Model Registry
      Kubeflow Training Operator
      and more
      Skills Required/Preferred:
      Python for backend development and API integration
      JavaScript/TypeScript for frontend development
      Modern UI frameworks (e.g., React, Jupyter widgets) is a plus
      Familiarity with Jupyter Notebook, JupyterLab
      Jupyter extension development experience is a plus

      ~~~~~~~~~~
      Project 6: Batch Processing Gateway Integration
      Components: Kubeflow Spark Operator
      Possible Mentors: @Shekharrajak, @lresende, @yuchaoran2011, @andreyvelich
      Difficulty: Hard
      Size: 350 hours
      Goals:
      Integrating the Batch Processing Gateway (BPG) with Kubeflow for submitting, monitoring, and managing Spark applications across multiple clusters (kubeflow/spark-operator#2422)
      Analyse, Design, Plan, and Execute Spark Job Execution Strategies:
      Evaluate the trade-offs between running a Spark kernel directly within a Kubeflow Notebook versus leveraging the Batch Processing Gateway for job submission.
      Assess the cloud-native design of Kubeflow SDK and Notebook environments to determine the optimal approach for Spark integration that maximizes efficiency, scalability, and usability.
      Make a well-informed decision on whether to support Spark kernels within notebooks, use BPG, or implement a hybrid approach for an enhanced user experience.
      Automated Job Routing and Scalable Execution:
      Implement dynamic workload routing using BPG to automatically distribute Spark jobs based on cluster load, resource availability, and workload priority.
      Integrate with the Spark Operator to optimize resource allocation, minimize execution delays, and ensure efficient scaling for petabyte-scale machine learning and data processing workloads.
      Enhanced User API and Notebook Integration:
      Develop a Python SDK for Kubeflow notebooks, enabling users to submit, manage, and monitor Spark jobs via BPG REST APIs for a lightweight, scalable solution.
      Ensure a seamless user experience by providing intuitive APIs that abstract complex job management operations, making it easier for data scientists and ML engineers to experiment and iterate on workflows within
      Comprehensive Debugging and Performance Monitoring:
      Enable full debugging capabilities by integrating Spark UI, logging, and monitoring tools into Kubeflow, allowing users to visualize Spark DAGs, tasks, and execution stages.
      Implement centralized logging and Prometheus-based monitoring to provide real-time insights into Spark job performance across clusters.
      Ensure users can efficiently analyze job execution, detect bottlenecks, and optimize data processing and ML workflows within Kubeflow.
      Note: Most of the logging APIs must be leveraged out of the box from either BPG or Spark - but we need to document, showcase examples to user.
      Comprehensive documentation and user guides to assist users in leveraging the new features effectively.
      Skills Required/Preferred:
      Proficiency in Python, Java and familiarity with developing SDKs.
      Experience with Kubernetes and managing containerized applications.
      Understanding of Apache Spark and its deployment on Kubernetes clusters.
      Familiarity with RESTful API development and integration.
      Experience with monitoring tools and logging frameworks is a plus.

      ~~~~~~~~~~
      Project 7: GPU Testing for LLM Blueprints
      Components: Kubeflow Trainer (Training Operator)
      Possible Mentors: @andreyvelich, @varodrig
      Difficulty: Medium
      Size: 350 hours
      Goals:
      Explore using Self-Hosted Runners for GPU testing in Kubeflow Trainer (kubeflow/trainer#2432)
      Skills Required/Preferred:
      GitHub Actions
      Kubernetes
      PyTorch
      Python

      ~~~~~~~~~~
      Project 8: Support JAX and TensorFlow Training Runtimes
      Components: Kubeflow Trainer (Training Operator)
      Possible Mentors: @Electronic-Waste, @XshubhamX, @andreyvelich
      Difficulty: Hard
      Size: 350 hours
      Goals:
      Add support TensorFlow as a training runtime in Kubeflow Trainer (kubeflow/trainer#2443)
      Add support JAX as a training runtime in Kubeflow Trainer (kubeflow/trainer#2442)
      Skills Required/Preferred:
      Go
      Kubernetes
      JAX
      TensorFlow

      ~~~~~~~~~~
      Project 9: Export Kubeflow Trainer Models to Kubeflow Model Registry
      Components: Kubeflow Trainer (Training Operator), Kubeflow Model Registry
      Possible Mentors: @tarilabs, @franciscojavierarceo
      Difficulty: Hard
      Size: 350 hours
      Goals:
      Integrate Kubeflow Trainer with Kubeflow Model Registry (kubeflow/trainer#2438)
      Trainer has implemented initializers for model and dataset, and will support model exporter in the future.
      By supporting the model registry as one of the destinations of the exporter, Trainer will integrate with Kubeflow ecosystem more deeply.
      Skills Required/Preferred:
      Kubernetes
      Go
      YAML
      Python

      ~~~~~~~~~~
      Project 10: Support Volcano Scheduler in Kubeflow Trainer
      Components: Kubeflow Trainer (Training Operator)
      Possible Mentors: @Electronic-Waste, @rudeigerc
      Difficulty: Hard
      Size: 350 hours
      Goals:
      Integrate Volcano Scheduler with Kubeflow Trainer (kubeflow/trainer#2437)
      Currently, Trainer does not support Volcano for scheduling.
      Since Volcano is a widely adopted scheduler for AI workloads, it could provide Trainer with more AI-specific scheduling capabilities if we integrate Volcano into Trainer
      Skills Required/Preferred:
      Kubernetes
      Go
      Volcano

      ~~~~~~~~~~
      Project 11: Support Postgres for Kubeflow Pipelines backend
      Components: Kubeflow Pipelines
      Possible Mentors: @rimolive, @shivaylamba
      Difficulty: Medium
      Size: 175 hours
      Goals:
      Implement support for PostgreSQL as an alternative to MySQL/MariaDB in Kubeflow Pipelines (kubeflow/pipelines#9813)
      Kubeflow Pipelines must store information about pipelines, experiments, runs, and artifacts in a database. Currently, the only database it supports is MySQL/MariaDB.
      We plan to support PostgreSQL as an alternative to MySQL/MariaDB so users will be able to reuse existing databases, and PostgreSQL will be a good use case for supporting multiple databases.
      Skills Required/Preferred:
      Kubernetes
      Python
      Go
      YAML

      ~~~~~~~~~~
      Project 12: Empowering Kubeflow Documentation with LLMs
      Components: Kubeflow Website
      Possible Mentors: @franciscojavierarceo, @chasecadet, @shravan-achar, @Shekharrajak, @varodrig
      Difficulty: Hard
      Size: 350 hours
      Goals:
      Leverage LLMs to improve Kubeflow documentation: (kubeflow/website#4025).
      Explore how other OSS communities leverage LLMs with the user documentation.
      Explore possibilities to use LLMs to improve existing Kubeflow documentation or use LLMs to help with user questions.
      Skills Required/Preferred:
      JavaScript
      Python
      HTML
      Netlify
      Hugo
     
      
      Last modified March 5, 2025: fix: SeaweedFS PoC link in GSoC project (#4031) (56f27bf)
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kubeflow/
    idea_list_url: https://www.kubeflow.org/events/gsoc-2025/
  

  - organization_id: 81
    organization_name: LLVM Compiler Infrastructure
    no_of_ideas: 14
    ideas_content: |
      

     
      Bfloat16 in LLVM libc
      Description:
      Bfloat16 is a recently developed floating point format tailored to machine learning and AI, and in the latest C++23 standard, it is officially standardized as std::bfloat16_t. Its support could be found in many modern hardware, ranging from CPUs of all the major vendors including Intel, AMD, Apple, and Amazon, to GPUs (nVidia and AMD GPUs) and Google TPUs. On the software side, it is supported in all major accelerator libraries, such as CUDA, ROCm, oneAPI, PyTorch, and Tensorflow. The goal for this project is to implement bfloat16 math functions in the LLVM libc library.
      Expected result:
      Setup the generated headers properly so that the type and the functions can be used with various compilers (+versions) and architectures.
      Implement generic basic math operations supporting bfloat16 data types that work on supported architectures: x86_64, arm (32 + 64), risc-v (32 + 64), and GPUs.
      Implement specializations using compiler builtins or special hardware instructions to improve their performance whenever possible.
      If time permits, we can start investigating higher math functions for bfloat16.
      Skills:
      Basic C & C++ skills + Interest in knowing / learning more about the delicacy of floating point formats.
      Project size: Large
      Difficulty: Easy/Medium
      Confirmed Mentors: Tue Ly, Nicolas Celik,
      Discourse: URL

      ~~~~~~~~~~
      Direct I/O from the GPU with io_uring
      Description:
      Modern GPUs are capable of unified addressing with the host. We currently use this to provide I/O support using the RPC interface. However, this requires a dedicated user thread on the CPU to handle the server code. We want to explore alternatives to providing I/O from the GPU using the Linux io_uring interface.
      This interface is a ring buffer designed to accelerate syscalls. However, it provides a polling mode that allows the kernel to flush the ring buffer without the user initiating a system call. We should be able to register mmap() memory with the GPU using AMD and NVIDIA API calls. This interface should allow us to implement a rudimentary read/write interface which can be thought of as the same as the syscall on the CPU. That can then be used to implement a whole file interface.
      Expected result:
      An implementation of pwrite and pread that runs on the GPU.
      Support for printf by forwarding snprintf into pwrite.
      If time permits, exploring GPU file APIs.
      Skills:
      Basic C & C++ skills + access to a GPU, Linux kernel knowledge, GPU knowledge.
      Project size: Small
      Difficulty: Hard
      Confirmed Mentors: Joseph Huber, Tian Shilei
      Discourse: URL

      ~~~~~~~~~~
      Profiling and testing the LLVM libc GPU math
      Description:
      The LLVM C library provides implementations of math functions. We want to profile these against existing implementations, such as CUDA's libdevice, ROCm's device libs, and OpenCL's libclc. Last year we worked on some interfaces to support these tests, now they need to be refined and filled out for the interesting functions.
      Additionally, we want to verify the accuracy of these functions when run on the GPU via brute force testing. The goal is to verify that the implementations are correct and at least conformant to the error ranges in the OpenCL standard. This will require a set of unit tests written in the offload/ project, ideally using the new API that @callumfare is working on.
      Expected result:
      Final performance results similar to Old results but with the more optimized functions and higher accuracy.
      A test suite that can do brute force testing to confirm that the implementations are conformant.
      Skills:
      Basic C & C++ skills + access to a GPU, some math knowledge
      Project size: Small
      Difficulty: Easy / Medium
      Confirmed Mentors: Joseph Huber, Tue Ly
      Discourse: URL

      ~~~~~~~~~~
      Validate existing Clang CodeGen test coverage with ClangIR
      Description: The ClangIR (CIR) project aims to establish a new intermediate representation (IR) for Clang. Built on top of MLIR, it provides a dialect for C/C++ based languages in Clang, and the necessary infrastructure to emit it from the Clang AST, as well as a lowering path to the LLVM-IR dialect. ClangIR upstreaming is currently in progress.
      In order to give community more frequent updates it'd be great if we can report ClangIR progress by measuring the coverage of existing Clang's CodeGen tests in face of a ClangIR enabled pipeline. By collecting information on crashing, passing or failing tests we can come up with a metric that is easier to report and understand, provide entry points for newcomers looking for tasks and help the project by classifying existing issues. Existing Clang CodeGen tests live in clang/test/CodeGen* and can be found in different states regarding ClangIR support:
      FileCheck fails. LLVM IR builds but FileCheck fails to match output
      LLVM IR differs because ClangIR pipeline is emitting different IR (e.g. different instructions are used, missing attributes). Issues need to be created and ClangIR needs to be fixed.
      LLVM IR differs because CHECK lines need be made more flexible (LLVM-IR dialect output is different, SSA value names, order of attributes, etc). It's possible a tool like llvm-canon might be of good use here.
      Test crash / error. ClangIR doesn't support some C/C++ construct or LLVM lowering hasn't been implemented.
      Test pass. Yay!
      In order to retrieve the information above, the student needs to make changes to Clang's testing infra (LIT configs, scripts, tests, ???) such that it's easier to replay the same invocations with ClangIR enabled, compare against traditional pipeline result or retrieve special directives from tests.
      It's not clear what is the best methodology just yet, but it's expected that submitted proposals that want to be taken seriously should present few possible ideas on how to achieve this, prior discussion with other members of the community is encouraged. The student is also expected to interact with the ClangIR community, file github issues, investigate and/or make changes to failing codegen tests.
      Expected result:
      Build the infrastructure to run tests and collect results.
      Present the results in a way that can be placed on a webpage.
      File issues or change check lines for 50% of the "FileCheck fails" category above. The only subdirectories that need consideration for the moment are:
          clang/test/CodeGen
          clang/test/CodeGenCXX
          clang/test/CodeGenOpenCL
          clang/test/CodeGenCUDA
          
      Bonus point: find ways to automate/facilitate changes to tests, put PRs to fix problems in ClangIR.
      Skills: Python, intermediate C++ programming skills and familiarity with basic compiler design concepts are required. Prior experience with LLVM IR, MLIR, Clang or ClangIR programming is a big plus, but willingness to learn is also a possibility.
      Project size: Large
      Difficulty:Medium
      Potential Mentors: Bruno Cardoso Lopes Andy Kaylor
      Discourse: URL

      ~~~~~~~~~~
      Participate in ClangIR Upstreaming
      Description: ClangIR is a new, MLIR_based intermediate representation of C and C++ code. It has been developed in an LLVM incubator project, but work is now underway to migrate the code from the incubator to the main LLVM repository. As the code is moved, it must be updated to align with LLVM coding standards and quality expectations. The goal for this project is to participate in the ClangIR upstreaming process and help improve both the code and the upstreaming process.
      The ClangIR project intends to unlock the possibility of better optimization, analysis, and diagnostics for C and C++ code by adding new abstractions that more closely model the source constructs, preserving more details than are available in standard LLVM IR. The ClangIR dialect is already being used to solve real-world problems using the implementation available in the ClangIR incubator, but we need to move this into the main LLVM repository in order to make this functionality available to a larger audience.
      This project will be an opportunity to gain hands-on experience with MLIR development with a focus on day-to-day software engineering discipline. Participants will work side-by-side with other LLVM contributors to achieve a common goal, and in the process will gain a deep understanding of the ClangIR dialect.
      Expected result:
      Migrate ClangIR support for C and C++ language features into the main LLVM repository
      Improve the quality of code as it is being migrated
      Suggest ways to improve the migration process
      Skills: Proficiency with modern C++ programming and familiarity with basic compiler design concepts are required. Prior experience with LLVM IR, MLIR, Clang or ClangIR programming is a big plus, but since the goal of this project is to gain such experience, it is not a prerequisite.
      Project size: Medium to Large
      Difficulty:Medium
      Potential Mentors: Andy Kaylor Bruno Cardoso Lopes
      Discourse: URL

      ~~~~~~~~~~
      Teach the Clang Static Analyzer to understand lifetime annotations
      Description: The Clang Static Analyzer (CSA) can already find a wide range of temporal memory errors. These checks often have hardcoded knowledge about the behavior of some APIs. For example, the cplusplus.InnerPointer checker knows the semantics of std::string::data. The Clang community introduced some lifetime annotations including [[clang::lifetimebound]] and [[clang::lifetime_capture_by(X)]] and made many improvements to Clang's default warnings. Unfortunately, the compiler's warnings only do statement local analysis. The CSA is capable of advanced inter-procedural analysis. Generalizing the existing checks like cplusplus.InnerPointer could enable the analyzer to find even more errors in annotated code. This can become even more impactful once the standard library gets annotated.
      Expected result:
      Identify the checks that can benefit from the [[clang::lifetimebound]] and [[clang::lifetime_capture_by(X)]] annotations.
      Extend those checks to support these annotations.
      Make sure the generated bug reports are high quality, the diagnostics properly explain how the analyzer took these annotations into account.
      Validate the results on real world projects.
      Potentially warn about faulty annotations (stretch goal).
      Skills: Intermediate C++ programming skills and familiarity with basic compiler design concepts are required. Prior experience with Clang or CSA programming is a big plus, but willingness to learn is also a possibility.
      Project size: Large
      Difficulty:Hard
      Potential Mentors: Gabor Horvath Balazs Benics Daniel Domjan
      Discourse: URL

      ~~~~~~~~~~
      Simple C++20 modules without a build system
      Description
      Currently there is no easy way to take a collection of source files using C++20 modules and build an executable from them. This makes it hard to create simple tests or tiny programs using C++20 modules without first setting up a build system. This project's goal is to extend the extremely simple build system in Clang's driver to handle these cases.
      This can be done by using Clang's existing support for scanning for C++20 modules to discover the dependencies between the source files that have been passed in, and then build them in that order, passing in the right PCM files where needed. This may also be extended to support explicitly building Clang modules discovered via module map files too.
      Expected outcomes
      Invoking clang similarly to
      clang -o program -std=c++20 main.cpp A.cppm B.cppm
      should compile successfully where each translation-unit only imports modules defined in other source files on the command line, or the standard library. This should add no overhead to cases where modules are not used.
      Confirmed mentors and their contacts
      Michael Spencer
      Required skills
      Intermediate knowledge of C++; familiarity with how C++ code is built. Familiarity with C++20 modules is an asset, but not required.
      Size of the project:
      medium (~175h)
      Project difficulty:
      medium
      Discourse: URL

      ~~~~~~~~~~
      Usability Improvements for trapping Undefined Behavior Sanitizer (UBSan)
      Description
      Undefined Behavior Sanitizer (UBSan) is a useful compilation mode in Clang for finding uses of undefined behavior (e.g. signed integer overflow) and problematic C/C++ code (e.g. unsigned integer overflow). The default version of UBSan uses a compiler runtime that only works in userspace (e.g. it won’t work in the kernel or for embedded applications) and is not considered secure enough for use in production environments. To handle these other environments UBSan provides a trapping mode that emits trap instructions that immediately halts the application rather than calling into the UBSan runtime which normally diagnoses the problem and then carries on execution.
      Unfortunately trapping UBSan has some deficiencies which make it hard to use. In particular:
      Clang silently ignores the -fsanitize-trap=undefined flag when it's passed without -fsanitize=undefined. This project would fix this as a “warm up task” to get familiar with the Clang codebase.
      When a UBSan trap is hit with the debugger attached it is not convenient to figure out the reason UBSan trapped. For x86_64 and arm64 some information is encoded in the instruction but decoding this is very inconvenient. While LLDB could be taught to look at the instruction and decode the meaning this is brittle because it depends on undocumented compiler ABI. Instead we can build upon the __builtin_verbose_trap work to encode the reason for trapping ("trap reasons") inside the debug information. If time permits we can also investigate emitting more precise trap reasons
      Expected outcomes
      When the -fsanitize-trap=undefined flag is passed on its own the compiler silently ignores it. Currently Clang requires that the -fsanitize-trap= flag is also passed. Clang should be taught to warn about this.
      Teach Clang to emit the UBSan trap reasons in debug information on UBSan trap instructions similar to how __builtin_verbose_trap works.
      Confirm LLDB is able to recognize the UBSan trap reasons and add tests for this.
      If time permits we should investigate emitting more precise trap reasons by using information available in the compiler. We may want to implement a "Sema Diagnostic" like approach where trap reason strings can easily be constructed inside the compiler. This task is more open-ended and has potentially uses outside of UBSan (e.g. -fbounds-safety).
      Confirmed mentors and their contacts
      Dan Liew
      Michael Buch
      Required skills
      Good understanding of C++
      Desirable skills
      Familiarity with UBSan
      Familiarity with LLDB
      Size of the project:
      small (~90h). but can be extended if time allows
      Project difficulty:
      Easy. This project would be good for a beginner to LLVM. Note the "emitting more precise trap reasons" portion is more open ended and so the difficulty of this is entirely down to direction the applicant chooses.
      Discourse: URL


      ~~~~~~~~~~
      Improve documentation parsing in Clang
      Description of the project: Clang-Doc is a C/C++ documentation generation tool created as an alternative for Doxygen and built on top of LibTooling. This effort started in 2018 and critical mass has landed in 2019, but the development has been largely stagnant mostly due to a lack of resources until last year when the development restarted as a successful Google Summer of Code project.
      
      The tool is built on top of LibTooling and leverages Clang parsers which supports parsing of Doxygen commands in documentation comments (this support is also used in the implementation of Clang’s
      -Wdocumentation
      which can be used to validate the content of documentation comments during compilation).
      
      Unfortunately, Clang’s documentation parser is incomplete and has several issues:
      Not all Doxygen commands are supported, limiting the Clang-Doc’s usability.
      Not all C/C++ constructs are currently handled, most notably C++20 features such as concepts.
      Markdown support in documentation comments introduced in Doxygen version 1.8.0 is missing.
      Expected result: The goal of this project is to implement the missing features in Clang’s documentation parser as well as their handling in Clang-Doc to improve the quality of the generated documentation. The eventual goal is for the LLVM project to start using Clang-Doc for generating its reference documentation, but before we can do that we need to ensure that all required features are implemented.
      
      Successful proposals should focus not only on addressing the existing limitations, but also draw inspiration for other potential improvements from other documentation tools such as hdoc, standardese, subdoc or cppdocgen.
      
      Over the course of the project, the candidate will have an opportunity to gain significant experience with LLVM and Clang internals (including lexer and parser) and C/C++ language.
      Skills: Intermediate knowledge of C++; interest in compilers and parsers. Previous experience with Clang/LibTooling is a bonus but not required.
      Project size: Either medium or large.
      Difficulty: Medium
      Confirmed Mentor: Petr Hosek, Paul Kirth
      Discourse: URL

      ~~~~~~~~~~
      Advanced symbol resolution and reoptimization for clang-repl
      Description of the project: The Clang compiler is part of the LLVM compiler infrastructure and supports various languages such as C, C++, ObjC and ObjC++. The design of LLVM and Clang enables them to be used as libraries, and has led to the creation of an entire compiler-assisted ecosystem of tools. The relatively friendly codebase of Clang and advancements in the JIT infrastructure in LLVM further enable research into different methods for processing C++ by blurring the boundary between compile time and runtime. Challenges include incremental compilation and fitting compile/link time optimizations into a more dynamic environment. Incremental compilation pipelines process code chunk-by-chunk by building an ever-growing translation unit. Code is then lowered into the LLVM IR and subsequently run by the LLVM JIT. Such a pipeline allows creation of efficient interpreters. The interpreter enables interactive exploration and makes the C++ language more user friendly. Clang-Repl is one example.
      Expected result: The project aims to develop a robust mechanism for resolving missing symbols by dynamically identifying and loading the appropriate shared objects or static archives. Additionally, it will explore use cases where adapting symbols based on execution profiles leads to measurable performance improvements, optimizing the efficiency of just-in-time compilation and dynamic execution environments.
      Skills: Intermediate knowledge of C++, Understanding of LLVM and the LLVM JIT in particular
      Project size:Either medium or large.
      Difficulty: Medium
      Confirmed Mentor: Vassil Vassilev
      Discourse: URL

      ~~~~~~~~~~
      Improve Enzyme reliability and compile times for Rust
      Description
      Enzyme requires good information about the memory layout of types. LLVM-IR is intentionally opaque, e.g. `&f32` and `&f64` both have the LLVM-IR type `ptr`. Enzyme is generally able to infer the underlying type (e.g. f32 vs f64) through usage analysis, but that process is slow and can in some cases fail. To make autodiff more robust, we should lower either MIR or THIR type information into LLVM-IR metadata. This analysis is recursive, for example `&[T]` is a fat pointer and therefore will be represented as a (ptr, int) pair in LLVM-IR. In this case the algorithm should recursively also analyze `T` and generate metadata for it.
      The function here can be extended to generate metadata from rusts Mid-level IR (MIR). A prototype of the parser was implemented here and can be used for inspiration. Various LLVM-IR examples for the metadata which we want to generate can be found in this test folder. Look for annotations in the style of ` {[-1]:Pointer, [-1,0]:Float@float}`.
      The online compiler Explorer fork can be used to trigger related bugs, starting with "can not deduce type of X".
      Expected outcomes
      The participant should find and select some interesting testcases, in which Enzyme either fails to differentiate an example due to inssuficient Type Information, or takes unreasonable long times (e.g. > 20x slower than compiling the code without autodiff). In the second case, a profiler should be used to verify that Enzyme causes a long compile time due to type analysis. The participant should then write (or later extend) the Type parser to generate the correct metadata, such that Enzyme can handle the new testcases. The LIT testcases should be added to the rust compiler, to avoid further regressions.
      Examples for code that currently is not handled correctly can be discussed in the project proposal phase.
      Confirmed mentors and their contacts
      Manuel Drehwald
      Oli Scherer
      Johannes Doerfert
      Required skills
      Intermediate knowledge of Rust and C++; Familiarity with profilers or LLVM metadata is an asset, but not required.
      Size of the project:
      medium (~175h)
      Project difficulty:
      medium
      Discourse: URL



      ~~~~~~~~~~
      Introduce an ABI lowering library
      Description: Currently, every LLVM-based frontend that wants to support calling into C code (FFI) needs to re-implement a substantial amount of complex call ABI handling. The goal of this project is to introduce an LLVM ABI library, which can be reused across different frontends, including Clang. More details on the motivation and a broad outline of the design are available in the corresponding RFC.
      The initial phase of the project will be to implement a prototype that can handle at least the x86_64 System V ABI. This will involve implementing the ABI type system, mapping of Clang types to ABI types and moving at least part of the X86 ABIInfo implementation from Clang to the new ABI library. This is to demonstrate general feasibility, figure out design questions and analyze compilation-time impact.
      Assuming the results from the prototype are positive, the next step would be to upstream the implementation by splitting it into smaller PRs. Finally, the implementation can be expanded to cover additional targets, ultimately removing Clang's ABI handling code entirely.
      Expected result: The minimum result is a prototype for the x86_64 ABI. The maximum result is fully upstreamed support for all targets. The expected result is somewhere in the middle between those two.
      Skills: Intermediate C++. Some familiarity with LLVM is a plus, but not required.
      Project size: Large
      Difficulty: Hard
      Confirmed mentors: Nikita Popov
      Discourse: URL

      ~~~~~~~~~~
      Byte type
      Description: LLVM IR can't represent implementations of memcpy, memcmp, etc correctly due to the lack of a way to represent raw memory. This project aims to add a new 'byte' type to the LLVM IR to represent raw memory.
      In addition to adding the new type, the project involves changing clang to lower chars to the new b8 type instead of i8, fixing incorrect lowerings of memory intrinsics, and tracking down the performance regressions.
      There is already a prototype implementation of the byte type for an older version of LLVM. More information here.
      Expected result: The minimum result is a port of the existing prototype to the current LLVM, fixing all known incorrect optimizations, add support for the byte type to Alive2, and a performance analysis.
      Skills: Intermediate C++, familiarity with LLVM, profiling.
      Project size: Large
      Difficulty: Hard
      Confirmed mentors: Nuno Lopes
      Discourse: URL


      ~~~~~~~~~~
      LLVM Compiler Remarks Visualization Tool for Offload Proposal
      Description: LLVM offers different information via remarks, profiling, or runtime debug annotations (e.g., LIBOMPTARGET_INFO=-1). However, as projects increase, dissecting this information becomes difficult for users. For example, it is difficult to collect all this data, visualize it, and learn from it when building large projects.
      Currently, some of this information—for example, compilation remarks—can be exported in JSON format. We want to create a tool to visualize, aggregate, and summarize the information. To aid accelerator development, we will start with the offload project as the primary candidate.
      Similar tools, such as opt-viewer, can be used as references and starting points.
      Expected outcomes: The expected outcome is a tool (e.g., in the form of a compiler wrapper such as ccache) that will allow the dump of all the compiler-generated information in JSON format and organize it in a project structure.
      The tool should generate an HTML-based report to help visualize the remarks. We envision a small client-server application using Python to spawn a local server as the visualization's front end. The server will expose the different reports and perform early analysis and aggregation.
      Additionally, the tool should be designed so that, in the future, the analysis of the remarks can provide generalized guidelines for the developer (e.g., show the most common remark, use LLM models to explain actions, etc.). The client (HTML viewer) will display the aggregated data, in-line remarks, profile information, etc. We do not expect the project to have all the features at the end of the GSoC but to serve as a placeholder for growth in the future.
      In particular, the outcomes of this project should be:
      Together with the mentors, help the design of the compiler wrapper, data storage layer, and client/server infrastructure. This includes the server API. The outcome of this task is a design document (similar to an RFC).
      Create a compiler wrapper that will dump different information in JSON format into the data storage layer (e.g., folders).
      Create a simple server layer that exposes the backend API to the front end. Python is the right way to do this, but we welcome other suggestions that align with the LLVM project. We would like to avoid relying on external projects (e.g., Flask) to avoid adding more dependencies to the LLVM project.
      Create a simple client-side visualization tool that can be extended in the future to show more reports.
      Mentors: @shiltian, @jdoerfert, @josemonsalve2
      Required/desired skills:
      Basic understanding of the LLVM Compiler to be able to generate compiler remarks, profiling data, and other information from the compiler.
      Proficiency in Python and C++.
      Full-stack web development.
      Project size: Large
      Difficulty: Easy
      Discourse Link: [GSoC][Offload]LLVM Compiler Remarks Visualization Tool for Offload Proposal
      Google Summer of Code 2024
      Google Summer of Code 2024 was yet another successful one for LLVM project. For the list of accepted and completed projects, please take a look into Google Summer of Code website.
      Welcome prospective Google Summer of Code 2024 Students! This document is your starting point to finding interesting and important projects for LLVM, Clang, and other related sub-projects. This list of projects is not only developed for Google Summer of Code, but open projects that really need developers to work on and are very beneficial for the LLVM community.
      We encourage you to look through this list and see which projects excite you and match well with your skill set. We also invite proposals not on this list. More information and discussion about GSoC can be found in discourse . If you have questions about a particular project please find the relevant entry in discourse, check previous discussion and ask. If there is no such entry or you would like to propose an idea please create a new entry. Feedback from the community is a requirement for your proposal to be considered and hopefully accepted.
      The LLVM project has participated in Google Summer of Code for several years and has had some very successful projects. We hope that this year is no different and look forward to hearing your proposals. For information on how to submit a proposal, please visit the Google Summer of Code main website.
      Remove undefined behavior from tests
      Description of the project: Many of LLVM's unit tests have been reduced automatically from larger tests. Previous-generation reduction tools used undef and poison as placeholders everywhere, as well as introduced undefined behavior (UB). Tests with UB are not desirable because 1) they are fragile since in the future the compiler may start optimizing more aggressively and break the test, and 2) it breaks translation validation tools such as Alive2 (since it's correct to translate a fuction that is always UB into anything).
      The major steps include:
      Replace known patterns such as branch on undef/poison, memory accesses with invalid pointers, etc with non-UB patterns.
      Use Alive2 to detect further patterns (by searching for tests that are always UB).
      Report any LLVM bug found by Alive2 that is exposed when removing UB.
      Expected result: The majority of LLVM's unit tests will be free of UB.
      Skills: Experience with scripting (Python or PHP) is required. Experience with regular expressions is encouraged.
      Project size: Either medium or large.
      Difficulty: Medium
      Confirmed Mentor: Nuno Lopes
      Discourse: URL

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/llvm-compiler-infrastructure/
    idea_list_url: https://llvm.org/OpenProjects.html

  - organization_id: 82
    organization_name: LabLua
    no_of_ideas: 8
    ideas_content: |
      Documentation generator tool for the Teal language
      The goal of this project is to create a "tealdoc" tool that generates documentation from comments embedded in Teal source code. Teal is a statically typed language that compiles to Lua (Teal is to Lua somewhat like TypeScript is to JavaScript). Since Teal is essentially a superset of Lua, this tool should be useful for Lua as well. There is prior art for Lua (LuaDoc, LDoc), but the community would benefit from a Teal-specific tool that is able to make use of its type annotations as possibly integrate better with language servers in modern editors.
      Expected results
      a CLI tool that generates Markdown from Teal or Lua comments and Teal type annotations
      support for generating HTML, possibly using templating systems (possibly reusing LDoc code)
      stretch goal: integration with other existing tooling such as the vscode-teal plugin and LuaRocks
      stretch goal: extensibility for supporting more languages in the Lua ecosystem
      Tools
      Teal
      any Lua libraries needed
      LuaRocks
      Skill level
      Intermediate
      Project size
      Large (350 hours)
      Mentor
      Hisham Muhammad

      ~~~~~~~~~~
      Lunatik binding for Human Interface Devices (HID) drivers
      Lunatik is a framework for scripting the Linux kernel with Lua. For example, Lunatik can be used for scripting the Linux networking subsystem (as presented at Netdev 0x14 and 0x17) among other examples.
      The purpose of this project is to create a Lunatik library for binding the Linux HID APIs to allow developers to write new HID drivers using Lua. This project might leverage the Lunatik device library, which allows the creation of character device drivers using Lua. Moreover, this project should also port at least one HID driver to Lua.
      Expected results
      Lunatik HID library
      HID driver examples in Lua
      Benchmark comparison between the original HID drivers and their Lua implementation
      Prerequisites
      Lua and C programming languages
      Experience with the Lua-C API (highly desirable)
      Experience with Linux kernel (highly desirable)
      Skill level
      Intermediate
      Project size
      Medium (175 hours) or Large (350 hours)
      Mentors
      Lourival Vieira Neto
      Matrix room
      #lunatik

      ~~~~~~~~~~
      Port Lua Test Suite to Lunatik
      Lunatik is a framework for scripting the Linux kernel with Lua. For example, Lunatik can be used for scripting the Linux networking subsystem (as presented at Netdev 0x14 and 0x17) among other examples.
      The purpose of this project is to port the Lua Test Suite to Lunatik. That is, to adapt scripts from the Lua Test Suite and develop a Linux loadable kernel module containing its C portion. This project might leverage the GSoC 2015 project developed by Guilherme Salazar, which ported the Lua Test Suite to the NetBSD kernel.
      The main difference between the kernel Lua and regular user-level Lua is that kernel Lua doesn't have support for standard libraries that depend on operating system (e.g., io and os) and for floating-point numbers.
      Expected results
      Adapted test scripts for Lunatik
      Lunatik library for testing the Lua C API
      Test Report at least for x86_64 and ARM64
      Prerequisites
      Lua and C programming languages
      Experience with the Lua-C API (nice to have)
      Experience with Linux kernel (nice to have)
      Skill level
      Intermediate
      Project size
      Medium (175 hours)
      Mentors
      Guilherme Salazar
      Lourival Vieira Neto
      Matrix room
      #lunatik

      ~~~~~~~~~~
      Lunatik package for Linux distros
      Lunatik is a framework for scripting the Linux kernel with Lua. For example, Lunatik can be used for scripting the Linux networking subsystem (as presented at Netdev 0x14 and 0x17) among other examples.
      The purpose of this project is to create Lunatik packages for some Linux distributions including, at least, Ubuntu, OpenWRT and VyOS. This project should also provide the documentation and templates for creating packages for new Lunatik libraries.
      Expected results
      Lunatik packages for Linux distros (at least, Ubuntu, OpenWRT, VyOS)
      Submit packages to upstream repositories
      Documentation and templates
      Prerequisites
      Lua and C programming languages
      Experience with build tools and package managers (highly desirable)
      Experience with the Lua-C API (nice to have)
      Experience with Linux kernel (nice to have)
      Skill level
      Intermediate
      Project size
      Small (90 hours)
      Mentors
      Marcel Moura
      Lourival Vieira Neto
      Matrix room
      #lunatik

      ~~~~~~~~~~
      Terminal UI library for Lua
      Lua has several core libraries that work across platforms; luasocket (networking), luafilesystem (file system), and luasystem (time, random, terminal). The latter library, luasystem, provides the primitives to handle terminal operations, albeit they are fundamentally different on Posix and Windows based systems.
      The purpose of this project is to shape the new terminal.lua library that builds on luasystems terminal primitives to build basic UI elements for user interaction in a cross-platform way. This should not be anything like curses, but the simpler user interactions like;
      progress indicators/bars
      prompts; yes/no, ok/cancel
      reading line inputs; reading a filename or other strings
      hidden inputs; for secrets
      headers and footers (basics for full-screen apps)
      More complex full screen app support (panels, drawing/re-drawing)
      etc.
      Things to consider
      The library should be general purpose, adhering the the Lua principle of 'mechanisms over policies'. This means for example that it should be possible to use it sync as well as async (coroutines), and it shouldn't force control over the main application loop, etc. A developer using the library should be able to make his/her own choice.
      Besides that terminals are challenging to work with. There are many control codes to control the terminal, however querying the terminal is very limited. There is no way to request current color status or cursor visibility for example.
      Some explorations to get started:
      what are terminals to begin with? a great explanation part 1, and part 2
      read up on terminals and streams; stdin, stdout, and stder; especially the latter two, when to use what?
      what does LuaSystem offer for platform compatibility, see LuaSystem terminal docs
      check the existing code base
      Expected results
      API that makes it easy to work around terminal limitations
      API design with consistency across platforms
      updated terminal.lua build on top of LuaSystem, ready for a first release
      works on Windows and Posix
      including tests, documentation and examples
      Prerequisites
      Lua programming language
      Experience with terminals (nice to have)
      Skill level
      Beginner
      Project size
      Medium (175 hours)
      Mentors
      Thijs Schreijer
      Matrix room
      #lunarmodules

      ~~~~~~~~~~
      Conntrack and NAT support for Lunatik
      Connection tracking (conntrack) is a fundamental component of the Linux kernel's networking stack. It is part of the Netfilter framework and is responsible for monitoring active network connections passing through the system. Conntrack maintains a state table, allowing the kernel to track packets as part of a flow and apply connection-oriented filtering, NAT (Network Address Translation), and stateful firewalling.
      NAT is used to modify IP addresses and ports in packet headers to facilitate address translation, load balancing, and security enforcement. The Linux kernel provides APIs to manipulate NAT and connection tracking through the Netfilter framework.
      The purpose of this project is to port conntrack and NAT data structures and kernel APIs to lunatik. These are present under:
      net/netfilter/conntrack.h
      net/netfilter/nf_conntrack_common.h
      net/netfilter/conntrack_tuple.h
      net/netfilter/nf_conntrack_core.h
      net/netfilter/nf_nat.h
      This projects builds upon the GSoC 2024 Project 'Lunatik binding for Netfilter'. For complete reference on the relevant kernel headers and data structures, refer to the following gist.
      Expected results
      Allow fetching the conntrack entries and connection information
      Ability to conntrack add entries from lua programs that need to perform NAT. Example use case - L7 load balancing using netfilter in lua
      Ability to perform NAT for atleast inet protocols
      Prerequisites
      Lua and C programming languages
      Linux Networking
      Experience with Linux Kernel (highly desirable)
      Experience with Netfilter subsystem (good to have)
      Skill level
      Challenging
      Project size
      Medium (175 hours) or Large (350 hours)
      Mentors
      Lourival Vieira Neto
      Mohammad Shehar Yaar Tausif
      Matrix room
      #lunatik

      ~~~~~~~~~~
      Add support for prepared statements for LuaSQL
      'LuaSQL' is a generic interface from Lua to a DBMS. It aims at portability over performance, but it allows extensions to suit the particularities of each DBMS.
      The inclusion of support for prepared statements in LuaSQL has been discussed thoroughly some time ago, but since each DBMS offers very different APIs there is no standard that could be defined to assure portability between them. Anyway the demand persists.
      This project proposes the addition of a minimal API that would allow each driver to offer prepared statements according to its DBMS restrictions and mechanisms.
      Expected results
      Propose a new API that would be flexibly enough to cover the main features of each database respecting each different mechanisms of defining prepared statements
      Implement the new API into one or more drivers
      Test and document everything
      Prerequisites
      C programming languages
      Experience with any database C API (highly desirable)
      Experience with Lua-C API (highly desirable)
      Experience with Lua (good to have)
      Skill level
      Challenging
      Project size
      Large (350 hours)
      Mentors
      Tomás Guisasola
      Matrix room
      #lunarmodules

      ~~~~~~~~~~
      Lunatik Binding for Linux Traffic Control (TC) and eBPF Maps
      This project aims to create Lunatik bindings for the Linux Traffic Control (TC) subsystem and eBPF maps to enable efficient and programmable network traffic control. These bindings will allow Lua scripts to manipulate TC and interact with eBPF maps, providing a flexible interface for traffic shaping, filtering, and monitoring.
      This work is heavily inspired by the luaxdp binding, which integrates Lua with XDP (eXpress Data Path) using eBPF. Given that TC and XDP both utilize eBPF, this new binding (luatc) will reuse and adapt parts of the luaxdp codebase, ensuring consistency and maintainability.
      Linux Traffic Control (TC) is a subsystem of the Linux kernel that allows administrators to manage network packet transmission, enabling features like traffic shaping, queuing, scheduling, and policing. It is widely used for bandwidth control, Quality of Service (QoS), and network performance optimization.
      Configuring TC using traditional tools can be complex and static, making it difficult to implement custom traffic processing logic. Lunatik, a Lua-based kernel scripting interface, can simplify this process by allowing users to write Lua scripts that dynamically interact with TC queuing disciplines (qdiscs), classes, and filters.
      Additionally, this project will introduce support for eBPF maps within Lunatik. eBPF maps are a key component of eBPF, providing efficient storage and retrieval of structured data between user space and kernel space. This functionality will not be restricted to the TC binding (luatc), but will be implemented as a general feature in Lunatik, enabling other kernel extensions to leverage eBPF maps.
      Expected results
      A fully functional Lunatik binding for the TC subsystem, allowing Lua scripts to configure and manipulate network traffic.
      Support for eBPF maps in Lunatik, enabling efficient data sharing between Lua scripts and eBPF programs.
      Integration with the existing luaxdp codebase, reusing and adapting components where possible.
      Clear documentation and examples, demonstrating how to use luatc for network traffic control and eBPF maps for data storage.
      Prerequisites
      Lua and C programming languages
      Linux Networking
      Experience with Linux Kernel (highly desirable)
      Experience with Traffic Control (TC) subsystem (good to have)
      Experience with eBPF maps (good to have)
      Skill level
      Challenging
      Project size
      Large (350 hours)
      Mentors
      Lourival Vieira Neto
      Savio Sena
      Matrix room
      #lunatik
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/lablua/
    idea_list_url: https://github.com/labluapucrio/gsoc

  - organization_id: 83
    organization_name: Learning Equality
    no_of_ideas: 5
    ideas_content: |
      
      
      
      
      Create Robust Windows App
      Background
      The current deployment of Kolibri involves platform-specific applications for Windows, macOS, and Linux (Gnome), each requiring a separate Python environment setup on the host system. This approach presents significant challenges in terms of maintainability, user experience, and cross-platform compatibility.
      
      Needs
      Change our installer to use https://pyinstaller.org/ so we can use the same app we have in MacOs  and make it independent of the status of Python in the system where Kolibri is installed.
      Adapt current Kolibri app, https://github.com/learningequality/kolibri-app to be fully compatible with Windows, integrating native features such as taskbar icon functionality and system-specific menus.
      Outcome
      The primary goal of this project is to streamline the deployment and operation of Kolibri by developing a unified application framework that is independent of the host system's Python environment.
      
      Mentors
      Richard Tibbles and Prathamesh Desai
      
      Skills
      WxPython
      Windows taskbar API
      Windows installation, configuration and services
      Duration
      175 hours in 12 weeks
      
      Difficulty level
      Medium

      ~~~~~~~~~~
      
      
      Implement a prototype of a Rich Text Editor
      Background
      Kolibri Studio currently uses a very old version of Toast UI’s text editor. It is desirable to have an up to date Rich Text editor for use in both the Kolibri Learning Platform and Kolibri Studio, to generate Rich Text content in a way that can be scoped for the specific use case, and also extended to allow insertion of specific toolbar elements under specific circumstances.
      
      Needs
      Create a prototype Vue.js based text editor component using a well maintained and robust text editing library
      Have feature parity for the existing text editor in Kolibri Studio
      Add underline and list formatting options to the text editor
      Outcome
      A prototype Rich Text Editor, implemented within Kolibri Studio, that allows inlining of a range of rich text elements. Taking an HTML document as a reactive input/output for the Vue component.
      
      Mentors
      Marcella Maki and Jacob Pierce
      
      Skills
      Javascript
      Vue.js
      HTML/CSS
      Duration
      175 hours in 12 weeks
      
      Difficulty level
      Medium

      ~~~~~~~~~~
      
      
      Create a new user onboarding experience for Kolibri
      Background
      Although Kolibri has user documentation, within Kolibri there is not yet an in-app onboarding experience. This project would be to create that onboarding experience that introduces users to Kolibri's user interface Key features within the Learn plugin will be highlighted through informative pop-up elements containing tips after the user has completed the device setup process. It's designed to enhance user understanding and engagement with Kolibri UI.
      
      With inclusivity at the heart of Learning Equality’s mission, building accessible products is an essential part of our day-to-day work. Approaching this frontend work with accessibility at the center will be critical for success.
      
      Needs
      Research and evaluate the pros and cons of existing  libraries like popper.js or tippy.js  and how those can be used as reference for a custom approach that we could maintain ourselves
      Create an accessible, flexible popover component that can be associated with a variety of interactive elements on the page, such as links, buttons, or menu items
      Integrate the component into an onboarding workflow for new users
      Outcome
      Implement a guided introduction to Kolibri for new users that helps orient users to features and navigation, and understand the product's value through experience.
      
      Mentors
      Liana Harris and Marcella Maki
      
      Skills
      HTML, Javascript, Vue.js
      Inclusive design principles, familiarity with WCAG specification
      Duration
      175 hours in 12 weeks
      
      Difficulty level
      Medium

      ~~~~~~~~~~
      
      HTML5 Article Renderer
      Background
      Currently Kolibri allows for sandboxed HTML5 applications that are able to implement arbitrary styling, Javascript, HTML etc, all presented inside a sandboxed iframe. However, this puts a large burden on the content creator to have knowledge of HTML and CSS if all they want is to produce rich text content. In order to allow this, we wish to be able to render HTML5 documents outside of an iframe, and with carefully crafted styling to create a responsive article experience.
      
      This will be building on previous technical work that handles taking an HTML5 document and applying sanitization to it to remove disallowed HTML tags.
      
      Needs
      To create consistent styling to this Figma spec
      Ensure responsive behaviours
      Ensure accessibility conformance as close as possible to WCAG 2.1 level AA.
      Outcome
      A Kolibri content renderer that can take an ‘article’ format that consists either of an HTML5 document with all assets inlined, or an HTML5 article zip file, and render to spec. Stretch goals would include integration of existing renderers to handle audio, video, and other multimedia content for better rendering experiences than simple HTML5 elements.
      
      Mentors
      Samson Akol, Allan Otodi Opeto, and Radina Matic
      
      Skills
      Javascript
      Vue.js
      HTML/CSS
      Mobile responsiveness testing
      Accessibility testing
      Duration
      175 hours in 12 weeks
      
      Difficulty level
      Medium
      

      ~~~~~~~~~~
      Easy sharing of community channels
      Background
      In many places, Kolibri is used to support the teaching of  local, regional, or national curricula. Aligning of open educational resources (OERs) to curricular standards can be done through Kolibri Studio, but is time consuming and requires expertise. Many organizations using Kolibri in their projects have already done the work to create sets of aligned channels.
      
      While it is currently possible to share channels and collections of channels within the Kolibri ecosystem, it is not user friendly. This project would update and add to that experience to improve the ease of sharing community curated libraries of resources for use within their projects and also for easier sharing with others.
      
      Needs
      Implement a new “Community Library” feature (name is provisional) within Kolibri Studio, using the existing “Collections” backend functionality.
      Allow a way to make these “Community Libraries” publicly discoverable on Kolibri Studio so that users can choose to make their Community Libraries publicly discoverable for use by others.
      Implement a license audit feature, so that prior to making a community library publicly discoverable, the owner can assert and correct licensing to ensure that it is accurate and appropriate to be publicly shared.
      Implement the new add community library workflow in Kolibri, which will permanently record the token for the library so any time new resources are imported from Studio, the community libraries that have been added are displayed.
      Outcome
      An updated feature implemented within both Kolibri Studio and Kolibri that allows users to more easily share collections with aligned channels.
      
      Mentors
      Alex Velez and Richard Tibbles
      
      Skills
      Javascript
      Vue.js
      HTML/CSS
      Python
      Fullstack development
      Duration
      175 hours in 12 weeks
      
      Difficulty level
      Medium
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/learning-equality/
    idea_list_url: https://docs.google.com/document/d/e/2PACX-1vT49WKgbsAIUoJ0jJS8LTWWm7UTByM0Pw3qt0KgyU_BShB1oGtZBkrEWuannFsRMVvGd0QBytZt8blh/pub

  - organization_id: 84
    organization_name: LibreOffice
    no_of_ideas: 15
    ideas_content: |
      
      Variable units on numerical input
      LibreOffice allows to change the unit from cm to inch or point, etc. but only globally. Some workflows make it necessary to deal with different units at the same time. For instance the page size in inch, positioning of objects in centimeter, and size in points. The proposal is to allow switching the unit on the control.
      Mockup: https://bug-attachments.documentfoundation.org/attachment.cgi?id=130628
      Enhancement request on Bugzilla (and the various See Also tickets)
      Goals:
      derive a new control from spin edit that allows switching the unit
      ideally but optionally remember the unit per control
      consider solutions to change the precision per adding decimal places
      replace the existing numerical spin edit controls
      Required skills / knowledge
      (C++, Reading other's code)?
      Size
      350 hours
      Difficulty
      (Medium)?
      Potential mentors
      Andreas Heinisch, mail: andreas.heinischyahoo.de
      Heiko Tietze, IRC: htietze, Mail: heiko.tietzedocumentfoundation.org

      ~~~~~~~~~~


      Remember window size per document
      LibreOffice remembers the window size per module and it's possible to have, for example, a Writer document in landscape next to a portrait sized Calc sheet. However, closing the modules brings you back to the start center which overwrites the module size. And the size/position is not stored per document, which is a major problem for many users.
      Ticket on Bugzilla.
      Goal:
      Restore the window size per module from the document
      Required skills / knowledge
      (C++, Reading other's code)?
      Size
      175 hours
      Difficulty
      (Medium)?
      Potential mentors
      Andreas Heinisch, mail: andreas.heinischyahoo.de
      Heiko Tietze, IRC: htietze, Mail: heiko.tietzedocumentfoundation.org

      ~~~~~~~~~~
      Improve snapping and object selection
      Snapping in LibreOffice is a bit awkward, and doesn't work as expected in some cases. There is also no advanced snapping supported (taking into account multiple object positions and distances), which would make object position and sizing much easier for the user. This idea involves investigating the existing implementation for snapping in the svx module and work on it.
      Goal:
      Make snapping and object selection pleasant to use.
      Extended goal for this idea is to look into object selection and handles rendering, consistency and UX. In some cases the selection and selection handles aren't properly rotated with the object, sometimes an outline of the selection isn't rendered or rendering could be improved.
      Required skills / knowledge
      (C++, Reading other's code)?
      Size
      350 hours
      Difficulty
      Hard
      Potential mentors
      Tomaž Vajngerl, IRC: quikee, mail: quikeegmail.com
      

      ~~~~~~~~~~
      Re-design Notebookbar using Native Toolkit Widgets
      The task here is to redesign the Notebookbar to use vcl weld mechanism instead of custom widgets. The issue is filed as tdf#163988 in Bugzilla.
      Currently, although Notebookbar uses Glade UI files, it uses custom widgets, and most of the logic is done in C++ code.
      Although the result looks nice with GTK3 and some other UI plugins, it has some drawbacks as described in tdf#163988. Specially in GTK4, the result is not interesting. Also, changing the Notebookbar in the Glade interface designer is not easy/possible with this approach.
      The task here is to re-design the Notebookbar, using native toolkit widgets and make sure that is usable with VCL weld mechanism. Doing modifications in the C++ code to make it usable in LibreOffice UI is not part of this task, so that people who only know how to design, but are not familiar with C++ can also do the task. To make the result usable with LibreOffice, additional coding/refactoring is needed which does not fit into this project.
      One can start by creating a dialog box with GtkNotebook, and then add appropriate icons and other GTK widgets to reach to a reasonable UI, comparable to what is available with the custom widgets.
      Please note that not each and every GTK widget is supported by VCL weld, so you have to go step by step to make sure that the result works well with VCL weld mechanism.
      A preview can be generated by both glade-previewer -f notebook.ui and also by using the ui file with minweld example. One may test the result, after putting the UI file in instdir/share/config/soffice.cfg/ and changing the minweld example to reflect the name of the UI and the ID of the dialog.
      ./bin/run minweld
      Goal:
      Re-design Notebookbar using native widgets.
      Required skills / knowledge
      UI Design, Glade UI designer, Reading other's code
      Size
      175 hours
      Difficulty
      Medium
      Potential mentors
      Hossein Nourikhah, IRC: hossein, mail: hosseinlibreoffice.org

      ~~~~~~~~~~
      New dialog to edit Table Styles
      LibreOffice Writer and Calc have a set of built-in table styles. For instance, in Writer, when the user inserts a new table, they can go to Table - AutoFormat Styles to select which style to apply to the table.
      To create a new style, the user can first insert a table to the document, format it manually and then go to Table ▸ AutoFormat Styles and click Add. This will extract the table formatting properties and create the new style.
      However, LibreOffice does not offer a dialog to Edit existing table styles.
      The objective of this project is to create a new dialog to edit all the properties of existing table styles.
      The UX team has already devised a proposal for the new Edit Table Styles dialog.
      As a stretch goal, it would be nice to have this dialog be used in Impress as well. See the Table Design entry in Impress's Properties sidebar when a table is selected.
      Required skills / knowledge
      UI Design, C++, Reading other's code, Debugging
      Size
      350 hours
      Difficulty
      Medium
      Potential mentors
      Rafael Lima, mail: rafael.palma.limagmail.com

      ~~~~~~~~~~
      Base
      Implement report builder in C++
      Designing and generating reports in LibreOffice is an important feature of LibreOffice BASE. The current report builder implementation uses Java and Pentaho Reporting Flow Engine of Pentaho BI for creating the output, which is an ODT file. Dependence on Java and Pentaho creates issues for packaging LibreOffice in different distributions, and also makes development harder.
      The file format used for storing the reports is in itself and XML file, and the resulting ODT file is also an XML document conforming to ODF standard. In order to implement report builder in C++, one should look into the import/export filters in LibreOffice, like the FODF which use XSLT. The resulting code should be able to do the export to ODT without the help of Pentaho library and/or Java.
      LibreOffice uses libxslt as an external library that provides the required tool to XSL tranfromations in C++ code. One can find some of the existing XSL transformation files used in import/export filters with:
      $ git ls-files "filter/*.xsl"
      Defining appropriate XSL transformation file alongside writing C++ code is needed to implement the reportgenerator.
      The other parts of the reporting workflow are already in C++. The reportdesign is in C++, and also other parts of the LibreOffice BASE that the report designer relies on are written in C++. This project can also improve report generating performance of LibreOffice.
      Help page for the current implementation.
      Base guide chapter for the current implementation.
      Goal
      Implementing report builder in C++, and removing the Java / Pentaho dependency
      Required skills / knowledge
      C++, XML, XSLT, Reading other's code
      Size
      350 hours
      Difficulty
      Hard
      Potential mentors
      Hossein Nourikhah, IRC: hossein, mail: hosseinlibreoffice.org

      ~~~~~~~~~~
      Basic


      BASIC IDE code auto-completion
      LibreOffice BASIC has a built-in code completion feature, that while useful, is very limited, and is not really helpful in practice.

      The current feature is available via "Tools > Options > LibreOffice > Code Completion". Then, you may write something like this:

      Sub Main
        Dim aPicker As com.sun.star.ui.dialogs.XFilePicker
              aPicker.
      End Sub
      After typing aPicker and then . (dot), you should be able to see the code completion popup.

      The task here is to provide better code complete feature. These are some of the required features:

      Add an object browser, as described in tdf#66185
      Be able to handle various types of objects, and not only UNO objects in certain conditions. tdf#165786 describes the need for ctrl+space code completion, alongside "." dot code completion which is described in tdf#66185.
      Add the "Quick Info" and "Parameter Info" functionality
      Make BASIC IDE code completion enabled by default
      Goal
      Implementing better code completion for LibreOffice BASIC IDE editor.

      Required skills / knowledge
      C++, UNO, BASIC, Reading other's code
      Size
      350 hours
      Difficulty
      Hard
      Potential mentors
      Hossein Nourikhah, IRC: hossein, mail: hossein@libreoffice.org

      ~~~~~~~~~~
      Draw
      Impress
      Attach animations to styles
      Currently, Impress styles control most of the visual shape appearance, but not the slideshow animation effect. Which is a pity, as the styles concept is pretty powerful inside LibreOffice, and provides a nice way to change animation settings and type for a great number of objects simultaneously. For a slightly different view onto the same problem, see this bug report, and this one from the LibreOffice side.
      Original patch from GSoC 2010: https://cgit.freedesktop.org/libreoffice/build/tree/patches/dev300/sd_effects_styles.diff?h=master-backup
      Goal:
      Make styles animatable.
      Required skills / knowledge
      C++, Reading other's code
      Size
      350 hours
      Difficulty
      Hard
      Potential mentors
      Thorsten Behrens, IRC: thorsten, mail: thorsten.behrensallotropia.de
      Katarina Behrens, IRC: bubli, mail: bublibubli.org

      ~~~~~~~~~~
      Rework Impress slideshow to use DrawingLayer primitives
      The Impress slideshow, while being designed to only interact with Impress via interfaces, had to resort to an ugly hack to be able to render all Impress content. That was ok back in the day, but is becoming a liability these days. Nowadays, what one want to use is the DrawingLayer Primitives (https://wiki.openoffice.org/wiki/DrawingPrimitives), which means porting over slideshow/source/engine/shapes/* to use this kind of abstraction, instead of the StarView Metafile previously in use.
      Goal:
      Get rid of ugly hack for rendering Impress content in slideshows by porting code to use DrawingLayer primitives.
      Required skills / knowledge
      C++, Reading other's code.
      Size
      350 hours
      Difficulty
      Hard
      Potential mentors
      Thorsten Behrens, IRC: thorsten, mail: thorsten.behrensallotropia.de

      ~~~~~~~~~~
      Calc
      Common
      Accessibility checker for Impress and Calc
      We have an accessibility checker sidebar in Writer, but not in Impress and Calc. The accessibility checker triggers a check of the document for accessibility issues and displays those in the sidebar, with helpful hints how to resolve those issues. Accessibility issues include checks of the document metadata (name, description), document structure, objects in the document, as well as check of contrast (font color vs. background color). A lot of issues apply for Impress and Calc too, but some are Writer specific and there as some that are unique to Impress and Calc.
      Goal:
      Add accessibility sidebar to impress (move code from writer to common code into svx or sfx2), implement a trigger to re-run a check when an object changes, go through the accessibility checks for writer and investigate which check also applies to Impress, add the accessibility check to common code and adapt if necessary (for example to work in editeng and not writer model). If there is still time, repeat the same for Calc.
      Required skills / knowledge
      C++, Reading other's code, Debugging,
      Size
      350 hours
      Difficulty
      Medium to Hard
      Potential mentors
      Tomaž Vajngerl, IRC: quikee, mail: quikeegmail.com

      ~~~~~~~~~~
      Extend support for document theme colors
      Support for theme colors is already implemented for Writer, Impress/Draw and Calc, however some colors weren't extended to support theme colors properly. Also when we define gradients we don't support theme colors there so support for theme color gradients would need to be added.
      Goal:
      Search for properties or parts of properties where we use colors, but we don't support to set a ComplexColor (used for theme colors). Implement a property that works with a ComplexColor for that property, add support to change the color in ThemeColorChanger, write a round-trip test and adapt the import/export filters (for ODF and OOXML) to support saving the theme color for the property. Repeat.
      Required skills / knowledge
      C++, Reading other's code, Debugging
      Size
      350 hours
      Difficulty
      Hard
      Potential mentors
      Tomaž Vajngerl, IRC: quikee, mail: quikeegmail.com

      ~~~~~~~~~~
      Filters
      Import Markdown files into LibreOffice Writer
      This project is meant to deliver a first working version of Markdown import into LibreOffice Writer, optionally using a document template (OTT) to provide decorative content, and custom styles. Participants are encouraged to research available import libraries, as well as means to get content inserted programmatically into a Writer document (e.g. via UNO, or via DLP's librevenge).
      Related report: tdf#162153.
      Goal:
      Make it possible to import Markdown files compliant to the CommonMark specification into Writer.
      As a stretch goal, adding experimental support for Paste-special-as-Markdown can be implemented for Writer.
      Required skills / knowledge
      C++, working with libraries
      Size
      350 hours
      Difficulty
      Medium
      Potential mentors
      Thorsten Behrens, IRC: thorsten, mail: thorsten.behrensallotropia.de

      ~~~~~~~~~~
      UNO
      UNO is the LibreOffice component model, cross-language and intra- as well as inter-process. It is somewhat similar to Corba and COM. It is used to extend LibreOffice via document-related scripts and more general extension packages, as well as to use LibreOffice functionality remotely from another process.
      UNO's cross-language abilities are implemented by bridging between various language-specific environments and a binary runtime representation (with a C API). Next to C++, Java, and Python, it would be great to have such a bridge also for a great language like Rust and a lightweight scripting language like LUA and latest version of .NET, which is cross-platform.
      Rust UNO Language Binding
      One aspect is to use Rust FFI to interface with the binary UNO C API. Another is to design the Rust representations of the various UNO constructs (its data types; objects with their multiple interfaces and methods; services and singletons), so that this language binding can not only be used to interact with existing LibreOffice services written in other languages, but also to create new services in Rust. A third aspect could be to create a pure Rust implementation of the UNO remote bridge protocol.
      Some documentation pointers are:
      UNO Type System
      UNO Object Life Cycle Model
      Uno Remote Protocol
      Some code pointers are:
      bridges/source/jni_uno as an example of an in-process UNO bridge (for Java, via JNI)
      binaryurp as an example of a remote UNO bridge (in C++)
      Goal:
      Make it possible to use LibreOffice's UNO API with Rust.
      Required skills/knowledge
      Rust, interfacing to low-level C/C++, working against formal specifications
      Size
      350 hours
      Difficulty
      Medium to hard
      Potential mentors
      Stephan Bergmann, IRC: sberg, mail: stephan.bergmannallotropia.de
      Michael Stahl, IRC: mst___, mail: mstlibreoffice.org
      Bjoern Michaelsen, IRC: Sweetshark, mail: bjoern.michaelsenlibreoffice.org

      ~~~~~~~~~~
      Python code auto-completion
      While it has been years since LibreOffice (and before that, OpenOffice) support Python binding, there were difficulties for the Python script developers to use it efficiently. One of the obstacles is the lack of Python auto-completion. The reason why this was not possible was that the Python objects are created at runtime, and therefore an IDE can not know about the structure of the classes when a developer writes the code.
      The solution for that is to generate Python stubs from IDL specifications. This is done in many other languages in the module codemaker. The task here is to create a similar tool for Python, which can be named pythonmaker.
      To get an idea of the needed code, you may look into codemaker/source/, and there you will see:
      cppumaker: stub generator for C++
      javamaker: stub generator for Java
      netmaker: stub generator for Python
      Goal:
      Make it possible to do Python code auto-completion by generating Python stubs from IDL specifications.
      Required skills/knowledge
      C++, Python, reading other people's code
      Size
      350 hours
      Difficulty
      Medium to hard
      Potential mentors
      Hossein Nourikhah, IRC: hossein, mail: hosseinlibreoffice.org

      ~~~~~~~~~~

      
      Tests
      Improve word processor test coverage
      LibreOffice Writer is the foremost Free and Open Source word processing program. During our 39 year development history, we're proud to have added comprehensive support for world languages, word processor use cases, and interoperability with other office suites. However, offering so many features has a cost in source code size and complexity. One of our greatest challenges today is managing this complexity.

      The goal for this project is to develop automated tests for LibreOffice Writer features that currently do not have tests.

      Use a test coverage report and C++ skills to identify features that require more tests.
      Use C++ debugging skills to create LibreOffice Writer documents that exercise target code.
      Use C++ to develop automated tests that assert the correct program behavior.
      File bug reports with detailed instructions and example documents, as needed.
      Required skills / knowledge
      C++, Reading code written by others
      Size
      175 hours
      Difficulty
      Medium
      Potential mentors
      Jonathan Clark, IRC: jonclark, mail: jonathan@libreoffice.org
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/libreoffice/
    idea_list_url: https://wiki.documentfoundation.org/Development/GSoC/Ideas

  - organization_id: 85
    organization_name: Liquid Galaxy project
    no_of_ideas: 21
    ideas_content: |

        Catastrophe Visualizer application for Liquid Galaxy

        Duration and difficulty
        175h/ Medium

        Introduction
        A platform that visualizes various catastrophes, from natural disasters like earthquakes and hurricanes in real-time.

        Development
        The project is to make a Catastrophe Visualizer for Liquid Galaxy that shows information for disasters in real-time, and for this, we’ll use some free and open-source API (like the  SGS Earthquake Hazards Program API), along with good knowledge of Flutter and Figma (optional) for creating stunning interfaces and good User Experience.
        The contributor will have to find APIs or downloadable resources to draw over the LG rig, and have to include plenty of KML data (numbers, points, lines, text, and photo) to be shown on the screens' previous selection of the user.
        Those will be researched and accorded previous the GSoC starting with the mentor.

        Deliverables
        - The new App published on the Play Store under the Liquid Galaxy LAB account.
        - Proper User Testing of the application and ensuring the data can be stored in the app as well as updated to show real-time data to the user.
        - Full documentation and code on our Github.

        Programming languages
        Android, Flutter, UX

        References
        USGS Earthquake Hazards Program API
        National Weather Service (NWS) API
        NASA Earth Observatory API
        Global Disaster Alert and Coordination System (GDACS) API  


        ~~~~~~~~~~       


        Flutter AirMashup for Liquid Galaxy 

        Duration and difficulty
        350h / Medium

        Introduction
        We want to create a port to Dart and Flutter of our great AirMashup 2019 Python-based airspace visualization, developed by contributor Albert Morea.

        Development
        Review the old app, prepare a list of functionalities to be ported, and implement a rich Flutter/Dart based port for a 6.3”” smartphone.
        Be careful with the data availability, check it with the same API used, or search for another one.

        Deliverables
        - The new App published on the Play Store under the Liquid Galaxy LAB account.
        - Full documentation and code on our Github.

        Programming languages
        Dart/Flutter

        References
        https://www.youtube.com/watch?v=dM5WLLFpf3Y
        https://github.com/LiquidGalaxyLAB/AirMashup 
        https://opensky-network.org/ 
         










        ~~~~~~~~~~
        Project Tapestry - Illuminating the Electric Grid

        Technology: Web Based
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h

        Introduction
        Project Tapestry by X (The Moonshot Factory) focuses on building a better understanding of the electric grid. This GSoC proposal aims to integrate power grid data visualizations into Google Earth using KML layers. The project will allow users to visualize real-time and historical electric grid information, fostering insights into energy usage, renewable integrations, and grid stability. Keywords: Visualization, KML, Mapping, Environmental Data.

        Requirements
        Liquid Galaxy setup
        Familiarity with KML and Google Earth engine
        Understanding of electric grid data

        Deliverables
        - Full documentation and code on our Github.
        - A dynamic KML-powered visualization of electric grids 

        Programming languages
        HTML, CSS, JavaScript, KML, UX, Google Earth

        References
        Tapestry Project Overview

         






        ~~~~~~~~~~
        Google Labs - Generative AI Data Visualization

        Technology: Web Based
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h

        Introduction
        This project merges Generative AI with Google Earth to create an innovative multimedia visualization tool. Users can input text, KML data, or even voice commands to generate immersive visualizations that combine geospatial data, AI-generated sounds, and rich text narratives. The aim is to offer dynamic, creative, and context-aware data presentations, with experiments to be submitted for review at Google Labs. Keywords: Generative AI, Multimedia Visualization, Mapping, Creative AI and Data Integration.


        Requirements
        Liquid Galaxy setup
        Understanding of AI tools and APIs (e.g., Vertex AI)
        Experience with KML and audio-visual integrations
        Deliverables
        - Full documentation and code on our Github.
        - Fully interactive AI data visualization
        - Submission to Google Labs
        Programming languages
        HTML, CSS, JavaScript, KML, UX, Google Earth

        References
        Google Labs Overview

                                                                                                                                                                   


        ~~~~~~~~~~
        Google Research - Open Buildings Data Visualization


        Technology: Flutter Based
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h

        Introduction
        The Open Buildings Dataset by Google Research offers rich geospatial building data for regions worldwide. This project aims to create an interactive map using Google Earth, where users can explore buildings by continent and country through KML visualizations. The approach emphasizes accessibility by ensuring the interface is screen-reader friendly and adheres to accessibility standards. Keywords: Data Visualization, Interactive Mapping, Accessibility, Geospatial Data 

        Requirements
        Liquid Galaxy setup
        Familiarity with Google Maps and Google Earth tools
        Understanding of accessibility best practices
        Deliverables
        - Full documentation and code on our Github.
        - A clickable, interactive map with building data integrated via KML on Google Earth

        Programming languages
        Dart, KML, UX, Google Earth

        References
        Open Buildings Dataset Overview
                                                                                                     


        ~~~~~~~~~~
        Climate change - ESA Copernicus visualization for Liquid Galaxy 

        Duration and difficulty
        175/ Medium

        Introduction
        Thinking about the planet’s sustainability and our past work around forest fires with project Dronecoria, we want to create a new tool based on the information from Copernicus, the specific satellite network of the European Space Agency for Earth Observation. The tool specifically will have to get images and other information available on the Copernicus Open Access Hub and visualize the images overlaid to actual Google Earth terrain, with data in KML-HTML on bubbles.

        Development
        Review the old app, prepare a list of contents available from the API on the forest theme, and implement a rich Flutter/Dart based port for a 6.3” smartphone.

        Deliverables
        - The new App published on the Play Store under the Liquid Galaxy LAB account.
        - Full documentation and code on our Github.

        Programming languages
        Dart/Flutter

        References
        API Copernicus Data Space Ecosystem
        https://dataspace.copernicus.eu/
                                                                                                                   







        ~~~~~~~~~~
        Google’s GEMINI LIVE voice controller

        Technology: Flutter based
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h 


        Introduction
        We want an app that users query the GEMINI LIVE API for places or data and create a nice KML in real time, sending it to the rig.
        The app should have only a single button, to allow the user to start talking or stop.
        The app should have a minimum of twenty ready-tested queries (or prompts)
        Example: What’s the London population?
        Deliverable: a kml showing the great London area with a balloon with statistical data about london population.



        Requirements

        Deliverables
        - APK compiled in your GitHUB ready to be tested at Liquid Galaxy LAB HQ.
        - Full documentation and code on our Github.

        Programming languages
        Android and Dart/Flutter

        References
        https://support.google.com/gemini/answer/15274899?hl=en 
        https://developers.google.com/kml/documentation/kmlreference
        https://aistudio.google.com/u/1/prompts/new_chat

                                                                                                       








        ~~~~~~~~~~
        LG AI Tour Agent

        Technology: Flutter based
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h 


        Introduction
        We want an AI agentic mobile app capable of taking actions based on voice commands. These voice commands can be natural and require external geographical information.
        From ‘Zoom in’, ‘Take me to Spain’ to ‘Let’s tour 10 places in Paris’. And possibly also add audio capabilities for reading any information related to the places. 

        Requirements
        Research on agentic and voice AI models and APIs.

        Deliverables
        - APK compiled in your GitHUB ready to be tested at Liquid Galaxy LAB HQ.
        - Full documentation and code on our Github.

        Programming languages
        Dart, KML, Google Earth

        References

                                                                                                       

















        
        ~~~~~~~~~~
        LG Panoramic data dashboard

        
        Technology: Web based
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h 


        Introduction
        We want a web app that allows users to upload spreadsheets or connect to their databases, and allow them to prompt or randomly generate charts and visualize them on the connected LG rig display. The LG Rig display would allow the users to adjust the charts, more or less like Kanban, so that they can have a better look from afar and extract valuable insights from it.

        Requirements
        Understanding of AI tools, models, and APIs

        Deliverables
        - APK compiled in your GitHUB ready to be tested at Liquid Galaxy LAB HQ.
        - Full documentation and code on our Github.

        Programming languages
        HTML, CSS, JavaScript, KML, Google Earth

        References
        https://brewit.ai/
        https://www.zeit-ai.com/                                                                              
















        ~~~~~~~~~~
        Environment Monitoring Data Dashboard

        Technology: Flutter based
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h 


        Introduction
        We want an app that showcases environmental changes (like pollution, AQI, deforestation, etc). Users can explore different locations and see the impact of environmental or weather metrics. Text data is necessary either on the device or the LG Rig and visualisation is also necessary in this project.

        Requirements
        Understanding of AI tools, models, and APIs

        Deliverables
        - APK compiled in your GitHUB ready to be tested at Liquid Galaxy LAB HQ.
        - Full documentation and code on our Github.

        Programming languages
        Dart, KML, Google Earth

        References
        https://eyes.nasa.gov/apps/earth/#/ 

                                                                                                                   















        
        ~~~~~~~~~~
        Cognitive Behavioral Therapy (CBT) Visualizer

        Technology: Flutter based
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h 


        Introduction
        We want a flutter app that combines panoramic visuals on LG Rig with audio and also provides CBT exercises(possibly via audio) to enhance mental health treatment.
        A good example would be the LG Rig displaying a calming environment while conducting a deep breathing exercise via audio, while also playing a calming background audio.
        An additional feature would be to add an AI voice therapist to allow the users to get treated in a calming environment.

        Requirements
        Familiarity with audio-visual integrations.

        Deliverables
        - APK compiled in your GitHUB ready to be tested at Liquid Galaxy LAB HQ.
        - Full documentation and code on our Github.

        Programming languages
        Dart

        References
        https://livekit.io/
                                                                                                   














        ~~~~~~~~~~
        Intelligent RPI glasses based navigation for LG


        Technology: Raspberry PI, VIAM
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h 

        Introduction
        We’ve developed in the past several projects to drive the LG with hand and body gestures using Posenet and Gameface. We want this year to develop a project based on a first person view instead.

        Requirements
        A Raspberry PI Zero 2, a 3d printed glasses structure

        Deliverables
        - An application based on RPI Zero 2 that will interpret hands gestures for basic Liquid Galaxy navigation.

        - Full documentation and code on our Github.

        Programming languages
        VIAM

        References
        Based on this project:
        https://www.hackster.io/coderscafe/sign-language-translator-b7fab5
        https://www.youtube.com/watch?v=ByrtJx1cG8o 
                                                                                                                 















        ~~~~~~~~~~
        Port old apps from tablet to smartphone, pack one   

        Technology: Flutter based
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h 


        Introduction
        We want two contributors to port to the right UX (Smartphone 6.x “ and vertical) old LG applications.
        Each contributor will port one of these packages of apps:

        Pack one, controllers:
        Liquid Galaxy for Education
        Super Liquid Galaxy Controller
        Simply CMS



        Requirements
        Adapt the same application to Smartphone UX

        Deliverables
        - APKs compiled in your GitHUB ready to be tested at Liquid Galaxy LAB HQ.
        - Full documentation and code on our Github.

        Programming languages
        Android and Dart/Flutter

        References
        https://github.com/LiquidGalaxyLAB/


        ~~~~~~~~~~


         











        Port old apps from tablet to smartphone, pack two  

        Technology: Flutter based
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h 


        Introduction
        We want two contributors to port to the right UX (Smartphone 6.x “ and vertical) old LG applications.
        Each contributor will port one of these packages of apps:

        Pack two, general apps:
        AirMashup for Liquid Galaxy
        Smart City Dashboard for Liquid Galaxy
        La Palma Volcano Eruption tracking tool


        Requirements
        Adapt the same application to Smartphone UX

        Deliverables
        - APKs compiled in your GitHUB ready to be tested at Liquid Galaxy LAB HQ.
        - Full documentation and code on our Github.

        Programming languages
        Android and Dart/Flutter

        References
        https://github.com/LiquidGalaxyLAB/


        ~~~~~~~~~~


         













        Robotics for LG: Gazebo visualization


        Technology: Flutter based
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h 


        Introduction
        We want to have a visualization across our lg rig screens of robotics Gazebo simulation.
        The use case to showcase the implementation will be around Unitree’s robots line, dog and humanoid.  

        Requirements
        Implement a set of Gazebo’s libraries in to a LG visualization, developing a showcase with the robotic dog or humanoid from Unitree.

        Deliverables
        - APKs compiled in your GitHUB ready to be tested at Liquid Galaxy LAB HQ.
        - Full documentation and code on our Github.

        Programming languages
        Android and Dart/Flutter

        References
        https://gazebosim.org/about
        https://www.unitree.com/ 


                                                                                                            











        ~~~~~~~~~~
        Data spaces Open Data visualization for LG


        Technology: Flutter based
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h 

        Introduction
        We want to have a visualization of data from FIWARE backend.  

        Requirements
        Implement a set of visualizations from FIWARE based on the samples we provide below and API open end points to be found on the internet. 

        Deliverables
        - APKs compiled in your GitHUB ready to be tested at Liquid Galaxy LAB HQ.
        - Full documentation and code on our Github.

        Programming languages
        - Android and Dart/Flutter, WEB STACK

        References
        https://www.fiware.org/wp-content/uploads/FF_PositionPaper_FIWARE4DataSpaces.pdf 
        https://www.fiware.org/wp-content/directories/marketing-toolbox/material/FIWAREBrochure_SmartIndustry.pdf 


        
















        ~~~~~~~~~~
        Webrcade porting to Liquid Galaxy



        Duration and difficulty
        350h / Hard

        Introduction
        Continuing our large project of developing under an HTML canvas across our screens, we have ported in the past several of the most classic videogames to the Liquid Galaxy rig.

        Development
        A port of the Webrcade that runs across a number of Liquid Galaxy screens, with a controller developed in Flutter/Dart. 

        Deliverables
        - The new App published on the Play Store under the Liquid Galaxy LAB account.
        If web create a wrapper and publish it this way.
        - Full documentation and code on our Github.

        Programming languages
        HTML5, Javascript, NodeJS, Flutter, Android

        References
        https://www.webrcade.com/ 
        https://github.com/webrcade 
        












        ~~~~~~~~~~
        nerfstudio visualization on Liquid Galaxy 




        Duration and difficulty
        350h / Hard

        Introduction
        The idea is to port the web-based viewer of nerfstudio to the Liquid Galaxy, and have ready some of his cool demos, like the Waymo’s ones. 

        Development
        A port of the viewer that has a minimum UI to handle navigation and choose the demo from the available ones.

        Deliverables
        - The new App published on the Play Store under the Liquid Galaxy LAB account.
        If web create a wrapper and publish it this way.
        - Full documentation and code on our Github.

        Programming languages
        HTML5, Javascript, NodeJS

        References
        https://docs.nerf.studio/ 
        https://www.youtube.com/watch?v=nSFsugarWzk
        https://www.youtube.com/watch?v=6lGMCAzBzOQ
        https://waymo.com/intl/es/research/block-nerf/
        








        ~~~~~~~~~~
        Kennedy Approach porting to Liquid Galaxy



        Duration and difficulty
        350h / Hard

        Introduction
        Continuing our large project of developing under an HTML canvas across our screens, we have ported in the past several of the most classic videogames to the Liquid Galaxy rig.
        This year we want to create a port of the old Commodore 64 game Kennedy Approach
        The project needs the implementation of an AI VOICE to reproduce air controller commands.

        Requirements
        A port of the Kennedy Approach that runs across a number of Liquid Galaxy screens, with a controller developed in Flutter/Dart 

        Deliverables
        - The new App published on the Play Store under the Liquid Galaxy LAB account.
        If web create a wrapper and publish it this way.
        - Full documentation and code on our Github.

        Programming languages
        HTML5, Javascript, NodeJS, Flutter

        References
        Google it for info
        You can get a port for windows here
        








        ~~~~~~~~~~
        Geoguesser like Earth game 

        Technology: Flutter based
        Theme: Liquid Galaxy project specific 

        Duration 
        350 h 


        Introduction
        Similar to Geo Guesser, but fully adapted to an LG, we want to develop a similar game for education and entertainment.

        Requirements
        Analysis of functionalities, research of other possible methods and games, code.

        Deliverables
        - APK compiled in your GitHUB ready to be tested at Liquid Galaxy LAB HQ.
        - Full documentation and code on our Github.

        Programming languages
        Android and Dart/Flutter

        References
        https://developers.google.com/kml/documentation/kmlreference
        https://www.geoguessr.com/ 


         








        ~~~~~~~~~~
        Space Invaders for Liquid Galaxy


        Duration and difficulty
        350h / Hard

        Introduction
        Space Invaders is another game that achieved tremendous popularity during the 70' and 80'. As other pixel games created for the Liquid Galaxy, the aim of this project is to make it multiplayer allowing various users to be connected against the machines. An application will work as a controller for moving and shooting the different enemies that appear in the game. 

        Development
        Take a look at our many great HTML based games developed by our Liquid Galaxy LAB Facens and mimic the Space Invaders game with multiple screens.

        Deliverables
        - The new App published on the Play Store under the Liquid Galaxy LAB account.
        If web create a wrapper and publish it this way.
        - Full documentation and code on our GitHub.

        Programming languages
        Dart/Flutter, HTML 5, node js, other

        References
        https://github.com/LiquidGalaxyLAB/galaxy-pacman 

         




       
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/liquid-galaxy-project/
    idea_list_url: https://docs.google.com/document/d/1tuTqs_v0jwBBBlMNvyjtt9imXMEjW0xLwEnH8D4Lvlo/edit?tab=t.0


  - organization_id: 86
    organization_name: MBDyn
    no_of_ideas: 7
    ideas_content: |
  
      Python Preprocessor development
      The MBDyn Python Preprocessor is a tool that is intended to support and speed up the generation of input files, integrating the standard MBDyn input syntax with Python code.
      The preprocessor can parse an input file searching for Python code wrapped by #beginpreprocess and #endpreprocess tags, and processes it generating portions of the final input file. See the examples in contrib/PythonPreprocessor/examples.
      After the 2024 GSoC project of Shimul Baidya, pre Preprocessor is now able to generate an entire MBDyn model using only Python code. This makes it suitable for integration in other software providing a Python API, to define a GUI-based method for MBDyn model generation. It also makes it easy to define higher-order preprocessing methods, like meshing flexible elements and automatically generating models for complex systems (for example, aeroelastic models of rotary-wing aircraft).
      In this context, many possibilities for GSoC projects can be devised. A non-comprehensive list of ideas that can be taken alone or combined to form a GSoC project:
      Integration of the Preprocessor in Blendyn, so that Blender can become a pre- and post-processor for MBDyn.
      Integration of the Preprocessor in FreeCAD
      Addition of classes that handle the generation of rotary-wing aircraft components (like HingelessRotor, FullyArticulatedRotor, Wing, etc...)
      Addition of classes to handle flexible element meshing
      This project can be scoped at 175 or 350 hours.
      Category: User Interface
      Programming Languages: Python
      Difficulty: Low/Intermediate
      Mentors: Andrea Zanoni, Marek Lukasiewicz
      ENTRY TEST: Complete step 1 of standard MBDyn GSoC entry test, compiling MBDyn from the preprocess branch, then write a simple parametric input file leveraging the Python Preprocessor. If you can, try to add support for a new MBDyn entity (e.g. a Drive Caller, see Section 2.6 of the Input Manual).
      
      
      ~~~~~~~~~~
      Modeling Capabilities
      Genetic Optimization Module
      The purpose of this project is to develop and MBDyn module which implements a genetic algorithm (GA) which will solve optimization problems inside an MBDyn simulation run.
      The module will implement a super-element, i.e. an element that will take inputs from a series of drives (which, in turn, can expose other entities private data) and output one or more optimized variables to another set of drives. The main structure will be similar to the one of the hfelem module.
      In their basic form, GAs are extremely simple to implement, therefore the preferred way in this GSoC project will be to develop one from scratch and keep external dependencies to a minimum. Linking of external GA optimization libraries will be considered only after a satisfactory level of functionality is reached with the in-house code.
      Implementing the baseline GA solver, with the minimum required flexibility to be usable, is a 175 hours project.
      Developing a fully-featured GA solver, plus structuring the module so that also external GA optimization libraries can be linked is a 350 hours project.
      Category: Modeling Capabilities
      Programming Languages: C++
      Keywords: Optimization, Genetic Algorithms
      Difficulty: Intermediate/Advanced
      Mentors: Andrea Zanoni

      ~~~~~~~~~~
      
      
      Post-Process
      Blendyn development
      MBDyn is a multibody dynamics solver which comes without any default graphical user interface for pre- and post-processing. There exist a few standalone post-processing tools based on EasyAnim, OpenDx and Blender.
      However, Blendyn, based on Blender, is the most up-to-date.
      See some example videos of its output and the tutorials to understand better what Blendyn is about.
      It is simple to use and generates 3D animations that represent the exact model movement and joints. Blendyn has got a great push in the development in the 2017 edition of the GSoC by the work of Reddy Janga and the 2022 edition by Do Tieng Dung, but some desirable features are still missing and several other need completion of fixing. For example:
      only fixed timestep simulation output is currently supported, variable timestep should be allowed also
      support the live plotting of MBDyn signals, for example leveraging the NetCDF output sync feature
      support the plotting of signals derived from arbitrary compositions of MBDyn signals (e.g. the sum of two signals) (up to here, this is a 90 hours project)
      support for the visualization of specific models, like for example aeroelastic models of rotary wing aircraft, biomechanical models of the human body, ecc... (getting here will require 175 or 350 hours, depending on how many possibilities for specific models are introduced)
      Category: User Interface
      Programming Languages: Python
      Keywords: Blender, UI, post-process
      Difficulty: Low/Intermediate
      Mentors: Andrea Zanoni
      ENTRY TEST: Complete step 1 of standard MBDyn GSoC entry test, then use the Blender Python API (or console) to create a simple Blender model
      
      ~~~~~~~~~~
      Complete NetCDF output implementation
      MBDyn can output simulation results in NetCDF format, speeding up significantly the manipulation of output data for visualization and processing. Currently, the support for binary output is still not complete among all the MBDyn entities. For example, drives are currently not supported, nor are numerous user-defined elements contained in modules.
      The aim of this project is to add the support for binary output to all the missing entities. A vast library of examples can be obtained simply looking at the current implementation for the supported entities.
      The roadmap can be the following one:
      complete the binary output of 'standard' elements (e.g. plates are currently missing)
      add the binary output of reference frames
      add the binary output of drives (up to here, this is a 90 hours project)
      complete the binary output of elements defined in modules
      enable the user to output to NetCDF also solver diagnostics (e.g. residuals, iterations, jacobians) (up to here, this is a 175 hours project)
      Category: Post-process
      Programming Languages: C++
      Keywords: post-process, NetCDF
      Difficulty: Low
      Mentors: Andrea Zanoni

      ~~~~~~~~~~
      IPC/RT
      Introduce MAVLink support
      MBDyn offers several possibilities to communicate with external processes: UNIX sockets, RTAI mailboxes or standard TCP/UDP sockets can be used to exchange data.
      The purpose of this project is to add the support to the MAVLink, a lightweight messaging protocol born for communicating with drones.
      The desired output is a module similar to module-flightgear, in which a new mode of operation of the file drivers of type stream and of the output elements of type stream is defined, allowing the user to select which MBDyn signal put into which MAVLink fields.
      Depending on the amount of flexibility/implemented features, this project can be scoped at 90 hours or 175 hours.
      Category: Modeling Capabilities
      Programming Languages: C/C++
      Keywords: Inter-Process Communication, Sockets
      Difficulty: Low
      Mentors: Andrea Zanoni, Marek Lukasiewicz

      ~~~~~~~~~~
      MBDyn-DUST Module
      MBDyn can be coupled with external software, allowing it to be inserted into co-simulation pipelines. The most common application is Fluid-Structure Interaction (FSI), which is the field for which MBDyn was initially developed.
      DUST is a mid-fidelity aerodynamic solver, designed to provide fast estimated good enough for aircraft conceptual design. It is based on an integral boundary element formulation of the aerodynamic problem and vortex-particle modelling of the wakes.
      MBDyn is currently typically coupled with DUST using preCICE. However, for most applications, this is a rather unnecessary complication, since all is requested from preCICE is to make the two software exchange data at each timestep and give each other the OK to go to to the next step at convergence.
      This project aims at developing an in-house solution for the coupling, in the form of a MBDyn module. It will follow a similar pattern as the one from the 2020 GSoC edition from Runsen Zhang, who created a template module for the co-simulation of MBDyn and Chrono.
      This is a 350 hours project.
      Category: Modeling Capabilities
      Programming Languages: C/C++
      Keywords: Inter-Process Communication, Co-Simulation
      Difficulty: Intermediate/Advanced
      Mentors: Andrea Zanoni, Alberto Savino, Alessandro Cocco

      ~~~~~~~~~~
      Utility
      Packaging MBDyn
      MBDyn is currently distributed only through publicly available source code, that the user is then expected to compile themselves. This has been identified as a barrier to entry for new users, especially ones not used to Linux environment. Even the latest documentation needs to be compiled by the end user.
      The purpose of this project is to simplify the installation process for a new user of MBDyn coming from a mechanical or aerospace engineering background. The resulting process should be portable to many Linux distributions, independent of the end user's local setup, include MBDyn's documentation and be well-documented itself.
      The first part of the contribution should be a review of available formats. Then the contributor should package MBDyn using the best solution(s) identified, and test it on a variety of systems.
      Additional goals, dependent on the scope and progress, would be to incorporate the packaging process into Continuous Integration (CI) and setup infrastructure to allow easy downloading of the premade binary.
      This work can have a positive impact on many fellow students, as the software is regularly used in teaching. Additionally, the skills developed by the contributor will be applicable not just to MBDyn, but to many open source projects with an involved build step.
      Depending on the amount of flexibility/implemented features, this project can be scoped at 90 hours or 175 hours.
      Category: Utility
      Programming Languages: C/C++ (mostly build systems)
      Keywords: Packaging, Maintenance
      Difficulty: Intermediate
      Mentors: Andrea Zanoni, Marek Lukasiewicz
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/mbdyn/
    idea_list_url: https://public.gitlab.polimi.it/DAER/mbdyn/-/wikis/GSoc-Project-Ideas


  - organization_id: 87
    organization_name: MDAnalysis
    no_of_ideas: 9
    ideas_content: |
      
      
      
      Project 1: Integrating MDAnalysis streaming analysis within WESTPA propagators
      Summary
      This project aims to integrate MDAnalysis with WESTPA to exploit MDAnalysis’s ability to analyze streamed trajectory data generated by WESTPA. This integration will reduce I/O bottlenecks and minimize the runtime needed to analyze a WESTPA simulation before intermittent restarting of the short, completed MD simulations.
      Detailed Description
      MDAnalysis is currently an option for extracting and analyzing simulation data for WESTPA simulations. This project aims to expand those capabilities by integrating streaming directly into WESTPA’s propagator executables and work managers for analysis, reducing the need for users to configure the networking. This will include stress testing MDAnalysis’s streaming capabilities, as analysis might involve using networking configurations such as streaming data from many-nodes-to-many-nodes and many-nodes-to-one-nodes.
      Expected Outcomes
      Stress-testing MDAnalysis streaming
      Additional propagator executables for integrating MDAnalysis streaming within WESTPA
      Relevant Skills
      Python (multiprocessing)
      Networking (TCP/IP)
      MD Engines
      Related issues/PRs/etc.:
      https://github.com/jeremyleung521/westpa/pull/28
      Possible Mentors
      @jeremyleung521
      @ltchong
      @fiona-naughton
      @orbeckst
      Expected Size of Project
      Large (175 hours)
      Difficulty Rating
      Medium

      ~~~~~~~~~~


      Project 2: Dashboard for tracking WESTPA simulation progress
      Summary
      WESTPA simulations involve running multiple MD trajectories in parallel, which makes it hard to track progress. This project aims to create a graphical user interface that exploits MDAnalysis’s streaming ability and WESTPA’s work managers to monitor the progress of a WESTPA simulation.
      Detailed Description
      While WESTPA simulations report status at regular intervals, these iterations could last minutes to hours, leaving users unsure of the intermediate progress or time estimate. The task here will involve creating a graphical user interface reporting trajectory progress and completion time estimates through MDAnalysis’s streaming abilities and extracting relevant information from WESTPA’s work managers (ZMQ, python multiprocessing) and data managers.
      Expected Outcomes
      New CLI tool for WESTPA tracking simulation progress
      MDAnalysis module for aggregating/tracking multiple simulations
      Relevant Skills
      Python (frontend UI, multiprocessing)
      Networking (TCP/IP)
      Related issues/PRs/etc.:
      Not applicable
      Possible Mentors
      @jeremyleung521
      @ltchong
      @fiona-naughton
      @talagayev
      Expected Size of Project
      Small (90 hours)
      Difficulty Rating
      Easy

      ~~~~~~~~~~
      Project 3: Lazy trajectory analysis with Dask and a Lazy Timeseries API
      Summary
      This project aims to improve MDAnalysis’s viability in high-performance clusters and high-throughput environments by building out a lazy (rather than eager) reader and timestep interface along with a sample H5MD implementation and basic analysis classes.
      Detailed Description
      MDAnalysis’s core data structure for holding trajectory data, the timestep, is extremely useful for providing a highly uniform interface for various readers, however, its eager approach to memory management, where trajectory frames are loaded into the object one step at a time, constrains analysis speed compared to the increasingly popular lazily-loaded paradigm used in recent packages like Dask and Polars. In HPC or cloud computing environments where minimizing analysis time is a necessity for making MDAnalysis viable at scale, having a lazy interface for new readers to target and existing ones to adapt to along with a sample implementation with H5MD and basic analysis classes that build on it would provide immediate benefits for HPC MDAnalysis users and a future platform for ensuring MDAnalysis is a tool that can scale with its users’ projects.
      MDAnalysis already has a timeseries API for readers which provides a natural starting place for a similar lazy_timeseries interface which would include an additional argument to select between coordinates, velocities, and forces. Existing readers can implement lazy_timeseries by first simply passing the numpy.ndarray result of calling timeseries into a Dask array, but certain readers like the H5MDReader or ZarrH5MDReader can receive a proper lazy implementation.
      Expected Outcomes
      MDAKit with lazy reader and timeseries interface code
      A working H5MD implementation of the interface
      A lazy timeseries analysis base
      Implementation of at least one basic analysis algorithm using the interface (like RMSD)
      Relevant Skills
      Experience with dask or lazy computation paradigm
      Knowledge of object-oriented programming
      Experience writing analysis code classes/scripts
      Any experience with a numpy-like-interface is useful
      Related issues/PRs/etc.:
      https://github.com/MDAnalysis/mdanalysis/issues/4713
      https://github.com/MDAnalysis/mdanalysis/issues/4598
      https://github.com/MDAnalysis/mdanalysis/issues/4561
      https://github.com/MDAnalysis/mdanalysis/issues/2865
      Possible Mentors
      @ljwoods2
      @orbeckst
      @yuxuanzhuang
      Expected Size of Project
      Medium (175 hours)
      Difficulty Rating
      Medium

      ~~~~~~~~~~
      Project 4: Better interfacing of Blender and MDAnalysis
      Summary
      Improvements to how Blender and Molecular Nodes interface with MDAnalysis which powers the import and animation of MD trajectories inside of Blender. Simple import is currently available when using the GUI in Blender, but there is still a lot of potential for improvements in scriptability, automated rendering, and using Blender as an analysis tool for MD trajectories.
      Detailed Description
      Blender is industry-leading 3D modeling and animation software. Through the add-on Molecular Nodes, MDAnalysis universes are able to be imported into the 3D scene, enabling advanced rendering of molecular dynamics trajectories that is not possible inside of any other molecule viewer. The ability to script and automate this rendering is possible but limited with lots of room for improvement for visualizing many common MD datasets. Blender also provides a great platform for implementing a potential GUI, to enable interactive analysis of MD trajectories with stunning visuals, all powered by MDAnalysis under the hood.
      Expected Outcomes
      Prototype improved API for scripting and working with Molecular Nodes from Jupyter Notebooks or other similar environments
      Prototyping common analysis and visualization tasks that could be performed from within Blender via the GUI
      Relevant Skills
      Proficiency with Python
      Working knowledge of MDAnalysis
      Familiarity with Blender and programming via its Python API
      Related issues/PRs/etc.:
      https://github.com/MDAnalysis/mdanalysis/discussions/4862
      https://github.com/yuxuanzhuang/ggmolvis
      https://github.com/yuxuanzhuang/ggmolvis/issues/11
      https://www.mdanalysis.org/2024/12/12/sdg_molecularnodes/
      https://github.com/BradyAJohnston/MolecularNodes/pull/719
      Possible Mentors
      @yuxuanzhuang
      @bradyajohnston
      Expected Size of Project
      Large (350 hours)
      Difficulty Rating
      Medium

      ~~~~~~~~~~
      Project 5: HBond interactions from implicit hydrogens
      Summary
      This project makes interaction fingerprints analysis with ProLIF (an MDAKit) more accessible and faster to run from PDB files for machine-learning (ML) practitioner.
      Detailed Description
      Interaction fingerprints (IFPs) are a common strategy to filter docking poses that aren't able to recapitulate known interactions in molecular complexes, but their use require explicit hydrogens to model hydrogen bonds. While ML-based docking and cofolding tools have seen increased usage other the recent years, the files that these methods generate only contain heavy atoms. While it's possible to add hydrogens to a complex and optimize its hydrogen-bond network, this significantly slows down and ultimately hampers the use of IFPs to evaluate the quality of ML-based molecular complexes. By adding to ProLIF the ability to evaluate hydrogen bond interactions solely based on heavy atom positions (and with the assumptions that hydrogens are positioned ideally for such interactions), it would be possible to directly compare co-crystallized complexes (e.g., from the PDB) with ML-based poses without requiring the intermediate use of protonation tools (PDB2PQR, reduce...etc.).
      Expected Outcomes
      New set of hydrogen-bond interaction classes available using implicit hydrogens
      Helper function to load PDBs with heavy atoms only and common non-standard residues (HSD, HSE, HID…etc.) appropriately
      Relevant Skills
      Python
      RDKit
      SMARTS
      Computational Chemistry
      Related issues/PRs/etc.:
      Not applicable
      Possible Mentors
      @cbouy
      @talagayev
      Expected Size of Project
      Medium/Large (175/350 hours)
      Difficulty Rating
      Medium

      ~~~~~~~~~~
      Project 6: Continuous (i.e., non-binary) interaction fingerprints (IFPs)
      Summary
      IFPs use cutoff values for defining the different expected distances and angles that interactions must follow, leading to cases slightly outside of these thresholds to not be detected at all. This project aims to bring an alternative (continuous) encoding for interactions in ProLIF (an MDAKit) so that such cases may still be accounted for in subsequent analysis.
      Detailed Description
      IFPs are inherently binary and based on distance and angles thresholds that can be hard to define robustly across the wide diversity of use cases. The idea here would be to define "ideal" and "suboptimal" thresholds for distances and angles, and for interacting atoms that satisfy the ideal thresholds encode them as 1 (as would be with a "traditional" IFPs), for those that don't satisfy the suboptimal thresholds encode them as 0, and for anything in between encode them through a sigmoid function that outputs a real value between 0 and 1. This would allow to deal more gracefully with cases that follow non-ideal geometries for interacting atoms. Note that the sigmoid function that transforms the input distances and angles into a real value will have to be determined during the project.
      Expected Outcomes
      The interaction classes have the ability to specify multiple thresholds for distances and angles, and additional metadata is returned when these classes are used to detect interactions
      The conversion of the resulting IFPs to a pandas DataFrame outputs continuous values between 0 and 1 instead of being binary
      From a user perspective, they should only have to toggle on a new parameter in the Fingerprint object initialization to enable this analysis
      Relevant Skills
      Python
      RDKit
      Computational Chemistry
      Related issues/PRs/etc.:
      Not applicable
      Possible Mentors
      @cbouy
      @talagayev
      Expected Size of Project
      Large (350 hours)
      Difficulty Rating
      Hard

      ~~~~~~~~~~
      Project 7: Improving ProLIF's 2D interaction visualizations
      Summary
      This project involves improvements to the current “LigNetwork” plot produced by ProLIF to make it easier to use and more publication-ready, and leaves some room to add other 2D visualizations that can help summarize the information contained in interaction fingerprints.
      Detailed Description
      When creating a "LigNetwork" plot with ProLIF, the protein residues are placed randomly and left for the user to drag and drop to make the figure readable. It would be beneficial to automate the placement of residues on the plot in a way that minimizes the overlap between residues and the ligand, and minimizes crossing between interaction edges.
      Depending on the size of the project, additional visualizations could be added, such as: a "heatmap" of ligand atoms involved in different interactions by highlighting such atoms with a bivariate Gaussian distribution based on an atomic interaction-aware weighting (see doi.org/10.1186/1758-2946-5-43 for reference). Another one could be to generate a figure similar to the LigNetwork with InteractionDrawer, converting the ProLIF metadata to follow their JSON schema. For protein-protein systems and residue network analysis, Flareplot would be very beneficial.
      Expected Outcomes
      The placement of residues on the LigNetwork plot is made to be readable out of the box
      If time allows, additional kinds of plots are added to further improve ProLIF’s visualization capabilities
      Relevant Skills
      Python
      JavaScript
      Related issues/PRs/etc.:
      Not applicable
      Possible Mentors
      @cbouy
      @talagayev
      Expected Size of Project
      Small/Medium (90/175 hours)
      Difficulty Rating
      Medium

      ~~~~~~~~~~
      Project 8: Benchmarking and performance optimization
      Summary
      The goal of this project is to increase the performance assessment coverage (using the existing ASV framework), identify code that should be improved, and optimize code.
      Detailed Description
      The MDAnalysis Roadmap emphasizes performance improvement. The performance of the MDAnalysis library is assessed by automated nightly benchmarks with ASV (see https://github.com/MDAnalysis/benchmarks/wiki) but coverage of the code base is low. The goal of this project is to substantially increase the performance assessment coverage, identify code that should be improved, and possibly implement performance optimizations.
      Expected Outcomes
      Write ASV benchmark cases for all major functionality in the core library
      Write ASV benchmark cases for often-used analysis tools
      Analyze performance history and generate a priority list of code that should be improved
      Document writing benchmarks with a short tutorial
      Optional: Optimize performance for at least one discovered performance bottleneck
      Relevant Skills
      Python/ASV
      Cython
      Related issues/PRs/etc.:
      https://github.com/MDAnalysis/mdanalysis/issues/1023
      https://github.com/MDAnalysis/mdanalysis/issues/1721
      https://github.com/MDAnalysis/mdanalysis/issues/4577
      Possible Mentors
      @orbeckst
      @ljwoods2
      Expected Size of Project
      Medium/Large (175/350 hours)
      Difficulty Rating
      Easy/Medium

      ~~~~~~~~~~
      Project 9: Integrating OpenFolds’ structural prediction confidence metrics into the topology system
      Summary
      The goal of this project is to expose per-molecule and inter-molecular structural prediction confidence metrics to users via the MDAnalysis topology system.
      Detailed Description
      Structural prediction tools like OpenFold are increasingly important for in-silico estimations of protein structure and of binding probability between molecules. However, working with the raw output of prediction tools is challenging and often requires bespoke tools made by researchers prone to inefficiency and errors. MDAnalysis’s topology system provides a robust, natural interface for working with per-residue (like pLDDT) and between-residue/chain metrics (like a contact probabilities matrix). This project seeks to build the foundation for working with structural prediction confidence metrics in MDAnalysis.
      After this project is complete, users will be able to access confidence metrics via Numpy arrays associated with (or between) each AtomGroup in a way that is consistent with current MDA atom selection
      Expected Outcomes
      Modifications of the PDBParser to associate confidence metrics with and between each AtomGroup
      Relevant Skills
      OpenFold experience or structural prediction tools more generally
      Python
      Experience solving parsing problems
      Related issues/PRs/etc.:
      https://github.com/MDAnalysis/mdanalysis/issues/4134
      Possible Mentors
      @ljwoods2
      @orbeckst
      Expected Size of Project
      Small (90 hours)
      Difficulty Rating
      Easy/Medium
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/mdanalysis/
    idea_list_url: https://github.com/MDAnalysis/mdanalysis/wiki/GSoC-2025-Project-Ideas

  - organization_id: 88
    organization_name: MIT App Inventor
    no_of_ideas: 10
    ideas_content: |
      
      Artificial Intelligence Projects
      Trainable ChatBot interface and AI component
      Brief Explanation: App Inventor has a growing offering of artificial intelligence features and is looking to add more cutting-edge AI learning experiences. We are looking to build a tool to create a trainable and customizable ChatBot that can be imported into an App Inventor app. This would be a similar experience to our Personal Image Classifer (PIC) and Personal Audio Classifer (PAC) extensions wherein there are external websites to build and train models, and these models are then exported and imported into App Inventor.
      PIC: https://classifier.appinventor.mit.edu/
      PAC: https://c1.appinventor.mit.edu/
      Familiarity with RAG implementations and SLMs will be helpful.
      Technical Difficulty: Hard
      Estimated Time Commitment: 350 hours
      Knowledge Prerequisites: Java, GWT, Javascript.
      Potential Mentors: Natalie Lao

      ~~~~~~~~~~
      Property editor for creating transfer-learning ML models
      Brief Explanation: Our Personal Image Classifer (PIC) and Personal Audio Classifer (PAC) components use external websites to build and train models. Those models then have to be exported and imported into App Inventor. It's a cumbersome process.
      PIC: https://classifier.appinventor.mit.edu/
      PAC: https://c1.appinventor.mit.edu/
      Build these sites as property editors in core App Inventor.
      Technical Difficulty: Hard
      Estimated Time Commitment: 350 hours
      Knowledge Prerequisites: Java, GWT, Javascript.
      Potential Mentors: Jeff Schiller

      ~~~~~~~~~~
      Component Projects
      ListView Component Update
      Brief Explanation: The ListView component offers a sophisticated set of behavior options. It supports both the addition of simple list elements by comma-delimited string and complex items by an interactive editor in the web designer. It supports several different layouts of list elements that include strings and images. Lists elements can display in a scrolling list style or a "swipe left" single element card style. Several parts of this need to be enhanced or refactored.
      Expected Results: Add features: New layout matching a swipe-left browser with a large central image with text below as captions; refactor of web designer list item editor to use UIBinder layout template, be more user-friendly, and be keyboard navigable; multi-select support. Update some iOS features that do not work properly.
      Knowledge Prerequisites: Java, GWT, swift
      Technical Difficulty: Medium
      Estimated Time: 175 hours
      Potential Mentors: Susan Rati Lane

      ~~~~~~~~~~
      iOS Implementation of Menu Component
      Brief Explanation: A previous GSoC project created a set of menu components for Android apps. We were never able to release it because by the time PR review was complete, we were fully supporting iOS, and these components were not implemented in iOS.
      Expected Results: Implement Menu, Sidebar, and Floating Action components in iOS to match the functionality in this PR: https://github.com/mit-cml/appinventor-sources/pull/2299. It is not up-to-date with master, but it should compile and run in a development environment.
      Knowledge Prerequisites: swift
      Technical Difficulty: Hard
      Estimated Time: 350
      Potential Mentors: Susan Rati Lane

      ~~~~~~~~~~
      Designer Projects
      Improvements for the Designer view. This part of the system is built mainly with Java using the Google Web Toolkit.
      Responsive (Mobile phone) layout
      Brief Explanation: In 2023, App Inventor rolled out an extensive refactor of our user interface to support GWT's UiBinder framework. This allows us to provide multiple user interface layouts based on device or user preferences. We see a growing number of users accessing App Inventor with mobile phones, and handheld devices are globally more accessible than desktops or laptops. We would like to provide a user interface option that makes App Inventor a more practical option for small screens.
      Technical Difficulty: Medium
      Estimated Time Commitment: 350 hours
      Knowledge Prerequisites: Java, GWT, UiBinder.
      Potential Mentors: Susan Lane

      ~~~~~~~~~~
      Better behavior for unimplemented components
      Currently, when an Android-only component is added to a project and loaded into the iOS Companion, the app just crashes. We would like our iOS Companion to be able to detect that it is trying to load an unimplemented component and present the user with useful information about it. We would also like the app to run if it is possible without the unimplemented component.
      Technical Difficulty: Medium
      Estimated Time: 175
      Knowledge Prerequisite: Swift
      Potential Mentors: Evan Patton, Susan Lane

      ~~~~~~~~~~
      Assets Library
      Brief Explanation: Allow users to upload sets of assets to be imported easily into different projects.
      Expected Results: An interface that allows for uploading and organizing assets (images and sounds) to be used within App Inventor apps through the Designer.
      Knowledge Prerequisites: JavaScript and Java
      Technical Difficulty: Medium
      Estimated Time: 175 hours
      Potential Mentors: Evan Patton, Jose Dominguez or Jeff Schiller

      ~~~~~~~~~~
      Learning Management System (LMS) Integrations
      Brief Explanation: Integrate App Inventor with one or more LMS systems such as Google Classroom and Canvas.
      Expected Results: An interface that allows course organisers to assign course work and manage submissions and grading of App Inventor projects through an existing LMS.
      Knowledge Prerequisites: JavaScript and Java
      Technical Difficulty: Medium
      Estimated Time: 175 hours
      Potential Mentors: Jose Dominguez or Jeff Schiller
      ~~~~~~~~~~
      User defined components/extensions
      Brief Explanation: Add the ability to create user-defined components (or extensions). By which we mean an App Inventor user could take a set of App Inventor components (and blocks using those components) and wrap them up together in a single reusable unit which exposed a set of properties, methods and events. In the initial implementation, perhaps, those units could only be used in the project in which they are defined, but ultimately you'd like for them to be exportable/importable, so that they could be used by other users (or that same user in other projects).
      Expected Results: App Inventor users can create reusable components.
      Knowledge Prerequisites: App Inventor, Java, GWT, UIBinder
      Technical Difficulty: Hard
      Estimated Time: 350 hours
      Potential Mentors: Mark Friedman

      ~~~~~~~~~~
      Additional Projects
      Github workflow hooks
      Brief Explanation: The appinventor-sources repository behaves differently from the Github workflow expectations. In particular, we have two branches that function as master: master and ucr (Upcoming Component Release). Changes that must be installed on devices (Android or iOS Companion) need to be released at specific times of the year, so that work is branched from and merged into ucr. Changes that affect the web designer can be released at any time and are branched into/merged into master. Github does not recognize ucr for the purpose of updating linked issues and other features. We also would like to manage other issue labels, like updating when PRs need additional review, etc.
      Expected Results: Write Github hooks to match our dual-master workflow.
      Knowledge Prerequisites: Python, Git, Github
      Technical Difficulty: Medium
      Estimated Time: 175 hours
      Potential Mentors: Evan Patton, Jeff Schiller, or Susan Rati Lane
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/mit-app-inventor/
    idea_list_url: https://github.com/mit-cml/appinventor-sources/wiki/Google-Summer-of-Code-2025

  - organization_id: 89
    organization_name: Machine Learning for Science (ML4SCI)
    no_of_ideas: 50
    ideas_content: |
    
        URL: https://ml4sci.org/gsoc/2025/proposal_NeuroDyad1.html
        TITLE: CEBRA-Based Data Processing Pipeline for Mapping Time-Locked EEG Paired Sets in Interacting Participants
        CONTENT:
        Machine Learning for Science
        Activities
        CEBRA-Based Data Processing Pipeline for Mapping Time-Locked EEG Paired Sets in Interacting Participants
        Description
        This project aims to develop a computational pipeline using the Contrastive Embedding for Behavioral and Neural Analysis (CEBRA) method to analyze time-locked EEG data from interacting participants. The goal is to map neural dynamics within dyads, particularly in Speaker-Listener interactions, and to identify parameters that distinguish neurotypical participants from those with clinical diagnoses. The project will use CEBRA algorithm for low-dimensional, interpretable latent embeddings for:

        Mapping EEG signals from interacting dyads to uncover neural patterns underlying communication (speaking vs. listening).
        Exploring differences in feature spaces (e.g., neural synchrony, boundary conditions, or latent manifold properties) that characterize clinical versus neurotypical interactions. This research is relevant for understanding how neural dynamics in social interaction are shaped by neurotype differences, such as those in Autism Spectrum Disorder (ASD). While CEBRA was originally designed for linking neural and behavioral data, the project aims to adapt it for clinical population comparison in a clinically relevant machine learning application.
        Duration
        Total project length: 175/350 hours.

        Task ideas
        Preprocess EEG recordings and format data to be compatible with CEBRA’s embedding architecture.
        Implement a pipeline for CEBRA-based mapping of time-locked EEG data from dyads (64-channel EEG).
        Train the model on neurotypical and clinical dyads, analyzing how latent embeddings encode neural interactions.
        Identify differentiating features (e.g., variance in manifold structure, neural synchrony, connectivity patterns) that may characterize clinical interactions.
        Test
        Please use this link to access the test for this project.

        Requirements
        MATLAB, Python; solid understanding of linear algebra, topology, signal processing. Interest in clinical neuroscience and computational methods.

        Expected results
        A functional pipeline for mapping time-locked EEG hyperscans from interacting participants using CEBRA.
        Identified neural parameters that differentiate clinical from neurotypical populations.
        Difficulty Level
        Intermediate/Advanced

        Mentors
        Evie Malaia (University of Alabama)
        Brendan Ames (University of Southampton, UK)
        Links
        CEBRA Pipeline Docs
        Paper 1 (Schneider et al., 2023 (CEBRA Paper))
        Paper 2
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        NEURODYAD
        Participating Organizations
        Alabama


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_ML4DQM1.html
        TITLE: Continuous learning for high-energy physics data quality monitoring
        CONTENT:
        Machine Learning for Science
        Activities
        Continuous learning for high-energy physics data quality monitoring
        Description
        A key challenge in data quality monitoring in high-energy physics is the need for online monitoring and control of the experiment with the data that is sensitive to underlying conditions and the constantly evolving state of the detector components. Machine learning models can be useful in identifying anomalies in the data and monitoring the quality of the data. At the same time, continuous learning techniques may be necessary to avoid machine learning model sensitivity to changing data inputs, avoiding the need to frequently re-train models. This proposal seeks to address this challenge by exploring continuous learning models capable of adapting to changing detector conditions and systems over time.

        Duration
        Total project length: 175 hours.

        Task ideas
        Develop continuous machine learning models.
        Evaluate and Benchmark model performance and robustness to changing detector conditions.
        Expected results
        Build a continuous machine learning model pipeline
        Evaluate and Benchmark the models with realistic datasets
        Requirements
        C++, Python, PyTorch, Tensorflow, previous experience in Deep Learning.

        Project difficulty level
        Medium

        Mentors
        Emanuele Usai (University of Alabama)
        Sergei Gleyzer (University of Alabama)
        Dale Julson (Cerium Labs)
        Resham Sohal (University of Alabama)
        Test
        Solve the evaluation tasks at this link. Please send us your CV and a link to all your completed work (github repo, Jupyter notebook + pdf of Jupyter notebook with output) to ml4-sci@cern.ch with Evaluation Test: ML4DQM in the title.

        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        ML4DQM
        Participating Organizations
        Alabama
        Cerium


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_DEEPLENSE6.html
        TITLE: Data Processing Pipeline for the LSST
        CONTENT:
        Machine Learning for Science
        Activities
        Data Processing Pipeline for the LSST
        Description
        The Rubin Observatory will provide an unprecedented volume of astronomical data, accessible via a dedicated open-source software suite consisting of data reduction pipelines and tools for interacting with calibrated images and catalogs. In order to prepare for the application of DeepLense methods on upcoming LSST data, this project focuses on developing a complementary pipeline that integrates LSST’s data access tools with DeepLense workflows. This pipeline will enable efficient data retrieval, preprocessing, and adaptation for various DeepLense applications such as lens finding, super-resolution, and classification.

        Duration
        Total project length: 175/350 hours.

        Difficulty level
        Intermediate/Advanced

        Task ideas
        Explore the existing LSST data access tools and design the workflow to provide the data for the DeepLense tasks.
        Test the workflow on the mock surveys provided by The Rubin Observatory.
        Expected results
        A functional pipeline capable of interfacing LSST data with DeepLense applications.
        Requirements
        Python, familiarity with astronomical data processing, and understanding of data access APIs and pipelines.

        Test
        Please use this link to access the test for this project.

        Mentors
        Michael Toomey (Massachusetts Institute of Technology)
        Sergei Gleyzer (University of Alabama)
        Anna Parul (Observatoire de Paris)
        Lucca Paris (Brown University)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The relevant mentors will then get in touch with you.

        Links
        LSST Pipeline Docs
        Paper 1
        Paper 2
        Corresponding Project
        DEEPLENSE
        Participating Organizations
        Alabama
        Brown
        MIT
        PSL


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_GENIE1.html
        TITLE: Deep Graph anomaly detection with contrastive learning for new physics searches
        CONTENT:
        Machine Learning for Science
        Activities
        Deep Graph anomaly detection with contrastive learning for new physics searches
        Description
        In the search for new physics at the Large Hadron Collider (LHC) a possible approach is to employ anomaly detection techniques to spot events that deviate from the standard model in an unsupervised manner. There have been many such studies using e.g. convolutional autoencoders. In previous GSoC projects, the usage of graph based models have been very successful in generative tasks. In this project we therefore want to employ a graph based architecture to perform anomaly detection on particle collision data.

        The intended model is supposed to perform anomaly detection on a graph-level, corresponding literature can be found in the ‘Links’ section.

        Duration
        Total project length: 175/350 hours.

        Difficulty Level
        Intermediate/Advanced
        Task ideas
        Development of a model for graph based anomaly detection
        Benchmarking on benchmark datasets and comparison to a convolutional autoencoder
        Expected results
        Trained graph based anomaly detection model
        Benchmark of on selected datasets
        Test
        Please use this link to access the test for this project.

        Requirements
        Skills: Python, PyTorch or TensorFlow and some previous experience in Machine Learning.
        Ability to work independently and proactive on a research project
        Mentors
        Sergei Gleyzer (University of Alabama)
        Ali Hariri (EPFL)
        Amal Saif (PSUT)
        Tom Magorsch (TUM)
        Ameya Thete (BITS Pilani)
        Links
        LHC
        Paper 1
        Paper 2
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        GENIE
        Participating Organizations
        Alabama
        EPFL
        TUM


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_E2E4.html
        TITLE: Deep Learning Inference for mass regression
        CONTENT:
        Machine Learning for Science
        Activities
        Deep Learning Inference for mass regression
        Description
        One of the important aspects of searches for new physics at the Large Hadron Collider (LHC) involves the identification and reconstruction of single particles, jets and event topologies of interest in collision events. The End-to-End Deep Learning (E2E) project in the CMS experiment focuses on the development of these reconstruction and identification tasks with innovative deep learning approaches.

        One of the main objectives of the CMS experiments research and development towards high-luminosity LHC is to incorporate cutting-edge machine learning algorithms for particle reconstruction and identification into the CMS software framework (CMSSW) data processing pipeline. This project will focus on the integration of E2E framework with the CMSSW inference engine for use in reconstruction algorithms in offline and high-level trigger systems of the CMS experiment.

        Duration
        Total project length: 175/350 hours.

        Difficulty level
        Intermediate

        Task ideas
        Development of end-to-end deep learning regression for particle property measurements
        Test and integration into CMSSW
        Expected results
        Extension of currently integrated E2E CMSSW prototype to include the regression model inference
        Requirements
        C++, Python, PyTorch and some previous experience in Machine Learning.

        Test
        Please use this link to access the test for this project.

        Mentors
        Ruchi Chudasama (University of Alabama)
        Shravan Chaudhari (New York University)
        Sergei Gleyzer (University of Alabama)
        Purva Chaudhari (Vishwakarma Institute of Technology)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Corresponding Project
        E2E
        Participating Organizations
        Alabama
        New York University
        Vishwakarma Institute of Technology


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_EXXA2.html
        TITLE: Denoising Astronomical Observations of Protoplanetary Disks
        CONTENT:
        Machine Learning for Science
        Activities
        Denoising Astronomical Observations of Protoplanetary Disks
        Description
        Recent advancements in observational astronomy have given the field the ability to resolve protoplanetary disks, the sites of planet formation, in unprecendeted detail. Array telescopes, such as ALMA and VLT, produce data that have revolutionized the study of these environments, spurring a rapid increase in the number of observations, significant advancements in theoretical understandings of planet formation processes, and the need for more efficient and accurate data processing. Traditional data processing algorithms, while advanced and powerful, are often time-consuming, computationally expensive, and can still produce noisy results. State-of-the-art machine learning algorithms, such as diffusion networks, are well-suited to this task and are a prime candidate for implementation in the field of protoplanetary disk astronomy. The purpose of this project is to develop machine learning algorithms to create a pipeline that denoises observational data more quickly and to a greater extent than current methods.

        Duration
        Total project length: 175/350 hours.

        Task Ideas
        Use synthetic observations of protoplanetary disks created using hydrodynamic simulations and radiative transfer to train machine learning models capable of denoising observational data.
        Investigate and select suitable machine learning denoising models that can handle the complexity and heterogeneity of the data.
        Develop a training pipeline that includes data augmentation techniques to enrich the training dataset and improve model robustness.
        Implement the model and train it on the prepared dataset, optimizing for the ability to reproduce the raw synthetic observations.
        Generalize the model to other types of observations, including line emission data and observations from other telescopes.
        Validate the model’s performance on real observational data from ALMA and VLT, comparing the performance to traditional methods.
        Expected Results
        A machine learning denoising model tailored for removing noise from astronomical observations, leveraging the unique characteristics of observational data.
        A detailed analysis of the model’s performance in removing noise from the data, including comparisons to traditional data processing methods and real observational data.
        A publicly available dataset curated for training and testing the model, accompanied by a comprehensive data preprocessing and augmentation pipeline.
        Documentation outlining the model architecture, training process, and guidelines for application to new datasets, ensuring reproducibility and facilitating future research in the field.
        Requirements
        Python, PyTorch, C/Fortran
        Background in astronomy is a bonus but not a requirement
        Test
        Use this link for instructions on completing the test.

        Links
        Previous Paper 1
        Previous Paper 2
        Mentors
        Sergei Gleyzer (University of Alabama)
        Jason Terry (Oxford University)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV. The mentors will then get in touch with you.

        Corresponding Project
        EXXA
        Participating Organizations
        University of Alabama
        Oxford University


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_FALCON1.html
        TITLE: Diffusion Models for Fast Detector Simulation
        CONTENT:
        Machine Learning for Science
        Activities
        Diffusion Models for Fast Detector Simulation
        Description
        DeepFalcon is a generative ultra-fast non-parametric detector simulation package. The goal of this project is to extend DeepFalcon to include diffusion models to improve simulation of calorimeter and tracker hits from particle interaction with the detectors

        Task ideas and expected results
        Implementation of diffusion networks into the falcon training and inference.
        Duration
        Total project length: 175/350 hours.

        Test
        Please use this link to access the test for this project.

        Requirements
        Strong machine learning skills, good knowledge of C++ and Python. Interest in Machine Learning algorithms and applications.

        Mentors
        Harrison Prosper (Florida State University)
        Michelle Kuchera (Davidson College)
        Ali Hariri (EPFL)
        Sinan Gençoğlu (Middle East Technical University)
        Amal Saif (Princess Sumaya University for Technology)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Corresponding Project
        DeepFALCON
        Participating Organizations
        Davidson
        FSU
        EPFL
        CERN
        Middle East Technical University
        Princess Sumaya University for Technology


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_DEEPLENSE5.html
        TITLE: Diffusion Models for Gravitational Lensing Simulation
        CONTENT:
        Machine Learning for Science
        Activities
        Diffusion Models for Gravitational Lensing Simulation
        Description
        Strong gravitational lensing is a promising probe of the substructure of dark matter to better understand its underlying nature. Deep learning methods have the potential to accurately identify images containing substructure and differentiate WIMP particle dark matter from other well-motivated models, including axions and axion-like particles, warm dark matter, etc.

        Traditional simulations of gravitational lensing are time-consuming and require extensive computational resources. This project proposes the use of diffusion models, a class of generative models known for their ability to produce high-quality, detailed images from a distribution of noise, to simulate strong gravitational lensing images. We aim to generate realistic simulations of gravitational lensing events that can be used to augment datasets for machine learning models and facilitate the development of better domain adaptation and self-supervised models aimed at bridging the gap between simulated and real images of gravitational lensing. Furthermore, we will also investigate leveraging conditional diffusion models to generate gravitational lensing simulations by conditioning the model on specific parameters related to the lensing events, such as the mass distribution of the lensing galaxy, orientation, and the redshift of both the source and the lens.

        Duration
        Total project length: 175/350 hours.

        Difficulty level
        intermediate Intermediate/Advanced

        Task ideas
        Explore diffusion models for the generation of strong gravitational lensing images.
        Create a diverse dataset of simulated gravitational lensing images under various astrophysical conditions.
        Expected results
        A diffusion model capable of generating realistic simulations of strong gravitational lensing phenomena.
        Requirements
        Python, PyTorch and relevant past experience in Machine Learning.
        Familiarity with astrophysics and gravitational lensing is preferred but not required.
        Test
        Please use this link to access the test for this project.

        Mentors
        Michael Toomey (Massachusetts Institute of Technology)
        Pranath Reddy (University of Florida)
        Sergei Gleyzer (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The relevant mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Corresponding Project
        DEEPLENSE
        Participating Organizations
        Alabama
        MIT
        Florida


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_E2E3.html
        TITLE: Diffusion models for fast and accurate simulations of low level CMS experiment data.
        CONTENT:
        Machine Learning for Science
        Activities
        Diffusion models for fast and accurate simulations of low level CMS experiment data.
        Description
        One of the important aspects of searches for new physics at the Large Hadron Collider (LHC) involves the identification and reconstruction of single particles, jets and event topologies of interest in collision events. The End-to-End Deep Learning (E2E) project in the CMS experiment focuses on the development of these reconstruction and identification tasks with innovative deep learning approaches.

        Diffusion based generative models are strong candidates for Fast Simulation models. The idea of this project is to build a diffusion-based ML model to model the underlying structure of the data which can be used for generating novel samples from the given distribution. Moreover this project also aims to explore conditional diffusion models that can generate specific types of data given a certain input to the model.

        Duration
        Total project length: 175/350 hours.

        Task ideas
        Experiment with different Diffusion based models to find the best one suited for the E2E case.
        Implementation of conditional diffusion models to generate samples based on specific given properties of the jets.
        Expected results
        Implementation of a conditional diffusion model capable of generating realistic samples resembling the CMS E2E data.
        Difficulty level
        Intermediate

        Requirements
        Python, PyTorch and some previous experience in Machine Learning.

        Test
        Please use this link to access the test for this project.

        Mentors
        Emanuele Usai (University of Alabama)
        Sergei Gleyzer (University of Alabama)
        Diptarko Chaudhari (NISER)
        Eric Reinhardt (University of Alabama)
        Ruchi Chudasama (University of Alabama)
        Bhim Bam (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Corresponding Project
        E2E
        Participating Organizations
        Alabama
        NISER


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_E2E8.html
        TITLE: Discovery of hidden symmetries and conservation laws
        CONTENT:
        Machine Learning for Science
        Activities
        Discovery of hidden symmetries and conservation laws
        Description
        Recent success in the domain of unsupervised and semi-supervised learning has been lately a pivotal factor for development of Physics Aware and Symmetry Aware Machine Learning techniques where a model learns the symmetry of a dataset as a meta task and ends up learning the physics through the same.

        Although most of the symmetries that we work with for SM physics are well defined and formulated, they can be well interpreted in 4-vector or 4-momenta basis. With change of representation the symmetries become elusive and difficult to write and work with. This calls for machine learning techniques that can learn the representation of the given symmetry through the means of a conserved quantity for a given abstract representation space.

        Learning these symmetries not only makes us more prepared to deal with the physics constraints in these abstract spaces and coordinates but also makes us able to build neural networks that are invariant to these symmetries. Such neural networks as seen from the existing literature are more robust, stable, interpretable and data efficient.

        This project will focus on ways to learn hidden symmetries combining the works of

        https://arxiv.org/abs/2109.09721
        https://arxiv.org/pdf/2301.05638v1
        https://arxiv.org/abs/2302.00236
        Duration
        Total project length: 175/350 hours.

        Task ideas
        Develop a deep learning model capable of uncovering the symmetries present in the toy datasets and then extending it to more abstract use cases.
        Using the symmetries discovered to probe the phase space of the CMS datasets.
        Building physics aware models using the symmetries.
        Expected results
        Discover symmetries and conserved quantities present in the CMS dataset.
        Benchmark the models with other previous works in terms of data efficiency and invariance with respect to symmetry operations.
        Difficulty level
        Advanced

        Requirements
        Proficiency in C++, Python
        Experience with PyTorch and TensorFlow
        Previous experience in Deep Learning
        Test
        Please use this link to access the test for this project.

        Mentors
        Diptarko Choudhury (NISER)
        Sergei Gleyzer (University of Alabama)
        Ruchi Chudasama (University of Alabama)
        Samuel Campbell (University of Alabama)
        Emanuele Usai (University of Alabama)
        Alex Roman (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Corresponding Project
        E2E
        Participating Organizations
        Alabama
        NISER


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_E2E2.html
        TITLE: End-to-End event classification with sparse autoencoders
        CONTENT:
        Machine Learning for Science
        Activities
        End-to-End event classification with sparse autoencoders
        Description
        One of the key tasks in particle physics analyses is proper classification of particle collision events based on the parent particles and the process that produced them. To handle this task, we’re developing a flexible machine learning pipeline which can be applied to a broad range of classification tasks. This project will primarily explore the development of sparse autoencoders which can effectively handle particle collision information represented as minimally processed images where the majority of the pixels in the image have very low or zero value. Different techniques have been developed to handle sparse representations such as sparse convolutions and point-cloud structures.

        Duration
        Total project length: 175/350 hours.

        Task ideas
        Develop a scalable sparse autoencoder model pipeline for event classification and reconstruction.
        Expected results
        Improve existing code pipeline with features like multi-GPU parallelism and flexible preprocessing and analysis options.
        Deploy the developed models and pipeline on simulated physics data and analyze performance gains and changes in model understanding from the techniques used.
        Difficulty level
        Advanced

        Requirements
        Significant experience in Python and Machine Learning in Pytorch.
        Preferably some experience with Transformers and multi-GPU parallelization or with the ROOT library developed by CERN.
        Test
        Please use this link to access the test for this project.

        Mentors
        Diptarko Choudhury (NISER)
        Sergei Gleyzer (University of Alabama)
        Ruchi Chudasama (University of Alabama)
        Eric Reinhardt (University of Alabama)
        Emanuele Usai (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Corresponding Project
        E2E
        Participating Organizations
        Alabama
        NISER


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_E2E6.html
        TITLE: End-to-End particle collision track reconstruction
        CONTENT:
        Machine Learning for Science
        Activities
        End-to-End particle collision track reconstruction
        Description
        One of the important aspects of searches for new physics at the Large Hadron Collider (LHC) involves the identification and reconstruction of single particles, jets and event topologies of interest in collision events. The End-to-End Deep Learning (E2E) project in the CMS experiment focuses on the development of these reconstruction and identification tasks with innovative deep learning approaches.

        One potential approach for particle reconstruction is to take minimally processed detector hit information from jets of decayed particles and rebuild the tracks that the originating particles followed and derive further quantities from those tracks. This project will focus on using machine learning models to achieve this reconstruction.

        Duration
        Total project length: 175/350 hours.

        Difficulty level
        Intermediate

        Task ideas
        Development of end-to-end deep learning track reconstruction algorithm
        Test and integration into CMSSW
        Expected results
        Trained track reconstruction algorithm and benchmarks against ground truth in simulated data
        Requirements
        C++, Python, PyTorch and some previous experience in Machine Learning.

        Test
        Please use this link to access the test for this project.

        Mentors
        Ruchi Chudasama (University of Alabama)
        Shravan Chaudhari (New York University)
        Sergei Gleyzer (University of Alabama)
        Purva Chaudhari (Vishwakarma Institute of Technology)
        Diptarko Choudhury (NISER)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Corresponding Project
        E2E
        Participating Organizations
        Alabama
        NISER
        New York University
        Vishwakarma Institute of Technology


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_EXXA1.html
        TITLE: Equivariant Vision Networks for Predicting Planetary Systems' Architectures
        CONTENT:
        Machine Learning for Science
        Activities
        Equivariant Vision Networks for Predicting Planetary Systems' Architectures
        Description
        The architecture of planetary systems, including the number of planets and their orbital configurations, provides crucial insights into their formation and evolution. This project aims to leverage the capabilities of equivariant computer vision networks to predict the number of planets in observed systems from astronomical data. Equivariant networks, due to their ability to handle rotational and reflectional symmetries inherent in astronomical images, offer a promising approach for analyzing spatial data without loss of predictive accuracy due to orientation changes. By regressing on the number of planets, this project seeks to develop a robust model that can adapt to the complexities of observational data, including direct images, transit data, and radial velocity measurements.

        Duration
        Total project length: 175/350 hours.

        Task Ideas
        Review and implement state-of-the-art equivariant neural network architectures suitable for astronomical data analysis.
        Curate a dataset from existing astronomical surveys, including labeled systems with known numbers of planets, for training and testing the model.
        Train the equivariant network on the curated dataset, optimizing for accurate regression on the number of planets in a system.
        Evaluate the model’s performance using a separate test set, focusing on its ability to generalize across different types of planetary systems and observational techniques.
        Explore the integration of additional data modalities (e.g., spectroscopic data) to improve the model’s predictive capabilities.
        Expected Results
        A highly accurate equivariant computer vision model capable of regressing on the number of planets in observed systems, accounting for the complexities and variabilities in astronomical data.
        A comprehensive evaluation of the model’s performance, highlighting its strengths and potential areas for improvement.
        Documentation and guidelines for applying the model to new datasets, facilitating further research and potential real-world applications in exoplanet discovery and characterization.
        Requirements
        Python, PyTorch, C/Fortran
        Background in astronomy is a bonus but not a requirement
        Test
        Use this link for instructions on completing the test.

        Links
        Previous Paper 1
        Previous Paper 2
        Previous Paper 3
        Mentors
        Sergei Gleyzer (University of Alabama)
        Jason Terry (Oxford University)
        Emily Panek (University of Alabama)
        Alex Roman (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV. The mentors will then get in touch with you.

        Corresponding Project
        EXXA
        Participating Organizations
        University of Alabama
        Oxford University


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_QMLHEP4.html
        TITLE: Equivariant quantum neural networks for High Energy Physics Analysis at the LHC
        CONTENT:
        Machine Learning for Science
        Activities
        Equivariant quantum neural networks for High Energy Physics Analysis at the LHC
        Description
        The ambitious HL-LHC program will require enormous computing resources in the next two decades. New technologies are being sought after to replace the present computing infrastructure. A burning question is whether a quantum computer can solve the ever growing demand of computing resources in High Energy Physics (HEP) in general and physics at LHC in particular. Discovery of new physics requires the identification of rare signals against immense backgrounds. Developing machine learning methods will greatly enhance our ability to achieve this objective. With this project, we seek to implement Quantum Machine Learning (QML) methods for LHC HEP analysis based on some QML frameworks (PennyLane, Cirq, Bloqade, …). This will enhance the ability of the HEP community to use QML methods.

        Duration
        Total project length: 175/350 hours.

        Task ideas
        Implement an equivariant quantum neural network.
        Test the equivariant quantum model with HEP datasets
        Benchmark the trained model and compare it against classical and non-equivariant models.
        Expected results
        Trained equivariant quantum neural networks with a QML framework (PennyLane, Cirq, Bloqade, etc.).
        Benchmark of the performance against a non-equivariant model
        Test
        Please use this link to access the test for this project.

        Requirements
        Solid knowledge of machine learning and deep learning
        Knowledge of quantum mechanics
        Strong python skills
        Ability to work independently and proactive on a research project
        Basic mathematics of group theory
        Difficulty Level
        Intermediate/Advanced
        Mentors
        Rui Zhang (University of Wisconsin-Madison)
        Alkaid Cheng (University of Wisconsin Madison)
        Sergei Gleyzer (University of Alabama)
        KC Kong (University of Kansas)
        Alex Roman (University of Alabama)
        Links
        HL-LHC
        LHC
        Pennylane
        Paper 1
        Paper 2
        Paper 3
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        QMLHEP
        Participating Organizations
        Alabama
        Wisconsin
        Kansas


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_CMS1.html
        TITLE: Event Classification With Masked Transformer Autoencoders
        CONTENT:
        Machine Learning for Science
        Activities
        Event Classification With Masked Transformer Autoencoders
        Description
        One of the key tasks in particle physics analyses is proper classification of particle collision events based on the parent particles and the process that produced them. To handle this task, we’re developing a flexible machine learning pipeline which can be applied to a broad range of classification tasks. We’ll leverage a mix of older and newer techniques for transformer models like masking, pretraining using autoencoder architectures, and cross attention of task-specific attention heads.

        Duration
        Total project length: 175/350 hours.

        Task ideas
        Develop a scalable transformer encoder model with task-specific attention heads combined using a cross attention mechanism
        Improve existing code pipeline with features like multi-GPU parallelism and flexible preprocessing and analysis options
        Deploy the developed models and pipeline on simulated physics data and analyze performance gains and changes in model understanding from the techniques used
        Test
        Please use this link to access the test for this project.

        Requirements
        Significant experience in Python and Machine Learning in Pytorch. Preferably some experience with Transformers and multi-GPU parallelization or with the ROOT library developed by CERN.

        Difficulty Level
        Advanced

        Mentors
        Eric Reinhardt (University of Alabama)
        Diptarko Choudhury (NISER)
        Ruchi Chudasama (University of Alabama)
        Emanuele Usai (University of Alabama)
        Sergei Gleyzer (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Blog Post 1
        Paper 1
        Corresponding Project
        CMS
        Participating Organizations
        Alabama
        NISER


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_SYMBA5.html
        TITLE: Evolutionary and Transformer Models for Symbolic Regression
        CONTENT:
        Machine Learning for Science
        Activities
        Evolutionary and Transformer Models for Symbolic Regression
        Description
        Symbolic regression can be used to rapidly provide solutions to problems in science which may have large computational complexity or may even be intractable. It can be used to discover a symbolic expression describing data such as a physical law. Current directions in symbolic regression focus either on evolutionary/genetic programming approaches or alternatively transformer based solutions. This project will explore a combination of these ideas towards a new tool for symbolic regression that can be used to solve many problems in science. As a concrete testbed for these new algorithms, the project will focus on predicting physical quantities, such as cross sections in high-energy physics, e.g a probability that a particular process takes place in the interaction of elementary particles. Its measure provides a testable link between theory and experiment. It is obtained theoretically mainly by calculating the squared amplitude.

        Duration
        Total project length: 175/350 hours.

        Task ideas and expected results
        Extend previous work on genetic algorithms and transformers from previous year’s work
        Benchmark these models on synthetic and high-energy physics datasets
        Requirements
        Significant experience with Transformer machine learning models in Python (preferably using pytorch).

        Difficulty Level
        Advanced

        Test
        Please use this link to access the test for this project.

        Mentors
        Eric Reinhardt (University of Alabama)
        Abdulhakim Alnuqaydan (Qassim University)
        Sergei Gleyzer (University of Alabama)
        Marco Knipfer (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Paper 4
        Paper 5
        Corresponding Project
        SYMBA
        Participating Organizations
        Alabama
        QU


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_EXXA3.html
        TITLE: Exoplanet Atmosphere Characterization
        CONTENT:
        Machine Learning for Science
        Activities
        Exoplanet Atmosphere Characterization
        Description
        The characterization of exoplanet atmospheres is crucial for understanding their compositions, weather patterns, and potential habitability. This project aims to develop machine learning models to analyze spectral data from exoplanets, identifying chemical abundances, cloud/haze structure and different atmospheric processes . The project will leverage data from telescopes and space missions, along with simulations of exoplanetary atmospheres under various conditions, to train and validate the models.

        Duration
        Total project length: 175/350 hours.

        Task Ideas
        Perform simulations of exoplanetary atmospheres with diverse atmospheric conditions: non-isothermal atmospheres; chemical equilibrium/disequilibrium; dawn/dusk asymmetry; distinct weather patterns; cloud/haze coverage etc.
        Train machine learning models on simulated spectral data to recognize different atmospheric conditions and physical processes using transmission and/or emission spectroscopy.
        Develop a ML strategy for searching of potential biosignatures in spectroscopic observations.
        Apply the trained models to real observational data from missions like Hubble, JWST, and future telescopes to characterize exoplanet atmospheres.
        Explore the use of deep learning techniques for enhancing the models’ ability to identify subtle spectral signatures associated with different atmospheric processes.
        Expected Results
        A set of machine learning models capable of accurately characterizing exoplanet atmospheres.
        Analysis of the models’ performance on observational data, demonstrating their applicability to current and future exoplanet studies.
        Requirements
        Python, PyTorch, C/Fortran
        Background in astronomy is a bonus but not a requirement
        Test
        Use this link for instructions on completing the test.

        Mentors
        Katia Matcheva (University of Alabama)
        Konstantin Matchev (University of Alabama)
        Sergei Gleyzer (University of Alabama)
        Jason Terry (Oxford University)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV. The mentors will then get in touch with you.

        Corresponding Project
        EXXA
        Participating Organizations
        University of Alabama
        Oxford University


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_FASEROH.html
        TITLE: Fast Accurate Symbolic Empirical Representation Of Histograms
        CONTENT:
        Machine Learning for Science
        Activities
        Fast Accurate Symbolic Empirical Representation Of Histograms
        Description
        State-of-the-art sequence to sequence models (seq2seq) have yielded spectacular advances in neural machine translation (NMT) (see, for example, Ref1 ). Recently, these models have been successfully applied to symbolic mathematics by conceptualizing the latter as translation from one sequence of symbols to another ( Ref2 ). It is easy to imagine numerous tasks that can be construed as translations. In the proposed Gsoc project the goal is to create a tool that automatically provides an accurate symbolic representation of a histogram by construing the problem as one of translation from a histogram to a symbolic function. We call the project Fast Accurate Symbolic Empirical Representation Of Histograms (FASEROH).

        Duration
        Total project length: 175/350 hours.

        Task ideas
        The goal of the project is to use available seq2seq models to create the mapping between an histogram and a symbolic function. See more details here.
        Expected results
        Since this project will be a proof of principle, the seq2seq task will be limited to 1-dimensional histograms defined on the unit interval.
        Requirements
        Python, previous experience in Machine Learning.

        Test
        Please use this link to access the test for this project.

        Mentors
        Abdulhakim Alnuqaydan (University of Kentucky)
        Harrison Prosper (Florida State University)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        FASEROH
        Participating Organizations
        Kentucky
        FSU


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_DEEPLENSE1.html
        TITLE: Foundation Model for Gravitational Lensing
        CONTENT:
        Machine Learning for Science
        Activities
        Foundation Model for Gravitational Lensing
        Description
        Strong gravitational lensing is a powerful tool for studying dark matter and the large-scale structure of the universe. This project focuses on developing a vision foundation model specifically designed for lensing data, which can be fine-tuned for a variety of downstream tasks, including classification, super-resolution, regression, and lens finding.

        This project will explore different training strategies such as self-supervised learning, contrastive learning, or transformer-based models to learn meaningful representations of lensing images. By leveraging diverse datasets and training methodologies, the model will serve as a general-purpose backbone that can adapt to different astrophysical tasks while improving generalization across various observational conditions.

        Duration
        Total project length: 350 hours.

        Difficulty level
        Advanced

        Task ideas
        Develop a pre-training strategy for learning robust representations of gravitational lensing data.
        Fine-tune the foundation model for multiple tasks such as classification, super-resolution, and regression.
        Evaluate the model’s performance on different astrophysical datasets and benchmark against traditional methods.
        Expected results
        A vision foundation model for gravitational lensing capable of being fine-tuned for various astrophysical tasks.
        Improved generalization and adaptability across different lensing datasets and observational setups.
        Requirements
        Python, PyTorch, experience with machine learning, and familiarity with computer vision techniques.
        Understanding of self-supervised learning, representation learning, and deep learning architectures.
        Test
        Please use this link to access the test for this project.

        Mentors
        Michael Toomey (Massachusetts Institute of Technology)
        Sergei Gleyzer (University of Alabama)
        Pranath Reddy (University of Florida)
        Anna Parul (Observatoire de Paris)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The relevant mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Corresponding Project
        DEEPLENSE
        Participating Organizations
        Alabama
        MIT
        Florida
        PSL


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_EXXA4.html
        TITLE: Foundation Models for Exoplanet Characterization
        CONTENT:
        Machine Learning for Science
        Activities
        Foundation Models for Exoplanet Characterization
        Description
        Advancing the understanding of exoplanets and planet formation requires a wide variety of observational methods and data modalities. Planet formation is a complex process that involves the assembly of a planet from a protoplanetary disk, an environment that instruments have only recently been able to resolve. These observations rely mostly on image data, including line emission and continuum data. The analysis of this data is a complex process, but, when done successfully, it opens new avenues for understanding planet formation, the resulting systems of exoplanets, and the potential of these systems for habitability. A complementary route is to use data from the atmospheres of exoplanets. The characterization of exoplanet atmospheres is crucial for understanding their compositions, weather patterns, and potential habitability. This project aims to develop a foundation machine learning models that will analyze data of different environments from different instruments to further our understanding of planet formation, extoplanet systems, exoplanet properties, and, ultimately, the potential of these systems for habitability. The models will use image data of disks, spectral data from exoplanets, identifying forming exoplanets, processes and substructures that are important in protoplanetary disk evolution, chemical abundances in exoplanet atmosphers, cloud/haze structure, and different atmospheric processes. The project will leverage data from telescopes and space missions, along with simulations of protoplanetary disks and exoplanetary atmospheres under various conditions, to train and validate the models.

        Duration
        Total project length: 175/350 hours.

        Task Ideas
        Assemble a consolidated database using existing protoplanetary disk and exoplanet transit observations from different instruments, spectral resolutions, and spectral ranges from publicly available archives.
        Develop an ML approach to overcome the specific instrumental differences for the different observations. Training can be done on existing synthetic databases simulating the instrument performance (Hubble Space Telescope, JWST, ALMA, Ariel etc.)
        Apply the trained models to real observational data from Hubble, JWST, ALMA, and future telescopes to characterize protoplanetary disks and exoplanet atmospheres.
        Explore the use of different ML architectures for enhancing the models’ ability to identify subtle signatures in the different data modalities associated with important physical properties and processes that may influence the formation and identification of habitable systems.
        Expected Results
        A set of machine learning models capable of accurately characterizing protoplanetary disks and exoplanet atmospheres using inputs from different observations.
        Analysis of the models’ performance on observational data, demonstrating their applicability to current and future exoplanet studies.
        Requirements
        Python
        PyTorch or TensorFlow (or similar)
        Background in astronomy is a bonus but not a requirement
        Test
        Use this link for instructions on completing the test.

        Mentors
        Katia Matcheva (University of Alabama)
        Konstantin Matchev (University of Alabama)
        Sergei Gleyzer (University of Alabama)
        Jason Terry (Oxford University)
        Alex Roman (University of Alabama)
        Emilie Panek (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV. The mentors will then get in touch with you.

        Corresponding Project
        EXXA
        Participating Organizations
        University of Alabama
        Oxford University


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_E2E7.html
        TITLE: Foundation models for End-to-End event reconstruction
        CONTENT:
        Machine Learning for Science
        Activities
        Foundation models for End-to-End event reconstruction
        Description
        One of the important aspects of searches for new physics at the Large Hadron Collider (LHC) involves the identification and reconstruction of single particles, jets and event topologies of interest in collision events. The End-to-End Deep Learning (E2E) project in the CMS experiment focuses on the development of these reconstruction and identification tasks with innovative deep learning approaches.

        This project will focus on the development of foundation models for end-to-end particle reconstruction with the goal of performing generative, classification and regression tasks.

        Duration
        Total project length: 175/350 hours.

        Difficulty level
        Advanced

        Task ideas
        Develop a pre-training strategy for learning robust representations of high-energy physics detector data.
        Fine-tune the foundation model for multiple tasks such as classification, generative, super-resolution, and regression.
        Evaluate the model’s performance on different HEP datasets and benchmark against individual methods for classification, regression etc.
        Expected results
        Trained foundation model and benchmarks
        Requirements
        C++, Python, PyTorch and some previous experience in Machine Learning.

        Test
        Please use this link to access the test for this project.

        Mentors
        Ruchi Chudasama (University of Alabama)
        Shravan Chaudhari (New York University)
        Sergei Gleyzer (University of Alabama)
        Purva Chaudhari (Vishwakarma Institute of Technology)
        Diptarko Choudhury (NISER)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Corresponding Project
        E2E
        Participating Organizations
        Alabama
        NISER
        New York University
        Vishwakarma Institute of Technology


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_SYMBA7.html
        TITLE: Foundation models for symbolic regression tasks
        CONTENT:
        Machine Learning for Science
        Activities
        Foundation models for symbolic regression tasks
        Description
        Symbolic regression can be used to rapidly provide solutions to problems in science which may have large computational complexity or may even be intractable. It can be used to discover a symbolic expression describing data such as a physical law. Many approaches have been explored but this project will focus on building a foundation model which incorporates knowledge about the task of symbolic regression and common data representations for physical systems.

        Duration
        Total project length: 175/350 hours.

        Task ideas and expected results
        Explore physics-informed ideas for improving data representations, physics-aware models, and physics simulations for squared amplitude calculation
        Apply symbolic machine learning techniques to predict the squared amplitudes and cross section for high-energy physics
        Requirements
        Python, C++ and some experience in Machine Learning sequence models.
        Some knowledge of physics and extensive knowledge of mathematics preferred.
        Test
        Please use this link to access the test for this project.

        Difficulty Level
        Advanced

        Mentors
        Abdulhakim Alnuqaydan (Qassim University)
        Sergei Gleyzer (University of Alabama)
        Harrison Prosper (Florida State University)
        Eric Reinhardt (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        SYMBA
        Participating Organizations
        Alabama
        FSU
        QU


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_FALCON2.html
        TITLE: Graph Representation Learning for Fast Detector Simulation
        CONTENT:
        Machine Learning for Science
        Activities
        Graph Representation Learning for Fast Detector Simulation
        Description
        DeepFalcon is a generative ultra-fast non-parametric detector simulation package. The goal of this project is to extend DeepFalcon to extend the current graph VAE to improve simulation of calorimeter and tracker hits from particle interaction with the detectors

        Task ideas and expected results
        Extend and scale Graph VAEs to the multi-layer detectors.
        Test various graph connectivities, pooling etc. to optimize the performance.
        Duration
        Total project length: 175/350 hours.

        Test
        Please use this link to access the test for this project.

        Requirements
        Strong machine learning skills, good knowledge of C++ and Python. Interest in Machine Learning algorithms and applications.

        Mentors
        Ali Hariri (EPFL)
        Sergei Gleyzer (University of Alabama)
        Emanuele Usai (University of Alabama)
        Sinan Gençoğlu (Middle East Technical University)
        Amal Saif (Princess Sumaya University for Technology)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Corresponding Project
        DeepFALCON
        Participating Organizations
        Alabama
        EPFL
        Middle East Technical University
        Princess Sumaya University for Technology
        CERN


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_FALCON3.html
        TITLE: Graph Transformers for Fast Detector Simulation
        CONTENT:
        Machine Learning for Science
        Activities
        Graph Transformers for Fast Detector Simulation
        Description
        DeepFalcon is a generative ultra-fast non-parametric detector simulation package. The goal of this project is to extend DeepFalcon to include diffusion models to improve simulation of calorimeter and tracker hits from particle interaction with the detectors

        Task ideas and expected results
        Extension of the Graph VAE model with Transformer architecture to improve edge prediction
        Duration
        Total project length: 175/350 hours.

        Test
        Please use this link to access the test for this project.

        Requirements
        Strong machine learning skills, good knowledge of C++ and Python. Interest in Machine Learning algorithms and applications.

        Mentors
        Ali Hariri (EPFL)
        Sergei Gleyzer (University of Alabama)
        Emanuele Usai (University of Alabama)
        Sinan Gençoğlu (Middle East Technical University)
        Amal Saif (Princess Sumaya University for Technology)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Corresponding Project
        DeepFALCON
        Participating Organizations
        Alabama
        EPFL
        Middle East Technical University
        Princess Sumaya University for Technology


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_DEEPLENSE4.html
        TITLE: Gravitational Lens Finding
        CONTENT:
        Machine Learning for Science
        Activities
        Gravitational Lens Finding
        Description
        This project focuses on the task of lens finding in the currently available wide-field surveys (e.g., HSC-SSP). The expected number of strong lenses in the large surveys is significantly overpowered by the number of non-lensed objects, which leads to the high number of false positives in typical lens searches.

        The goal of the project is to develop lens finding algorithms, apply them to the observational data, and assess the limitations of the algorithms (for example, analyse the properties of the identified lens population and examine the typical contaminants).

        Duration
        Total project length: 175/350 hours.

        Difficulty level
        Intermediate/Advanced

        Task ideas
        Start with architectures previously explored within the DeepLense project and optimise them for the lens finding task.
        Perform the lens search in the real observational data and analyse the properties of the detected lens candidates.
        Evaluate model performance on different surveys.
        Expected results
        Increase the number of known strong lenses.
        Insight into properties of the identified lens candidates.
        Requirements
        Python, PyTorch, experience with machine learning, familiarity with astrophysics datasets.

        Test
        Please use this link to access the test for this project.

        Mentors
        Sergei Gleyzer (University of Alabama)
        Michael Toomey (Massachusetts Institute of Technology)
        Anna Parul (Observatoire de Paris)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The relevant mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Corresponding Project
        DEEPLENSE
        Participating Organizations
        Alabama
        MIT
        PSL


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_QMLHEP1.html
        TITLE: Implementation of Quantum Generative Adversarial Networks to Perform High Energy Physics Analysis at the LHC
        CONTENT:
        Machine Learning for Science
        Activities
        Implementation of Quantum Generative Adversarial Networks to Perform High Energy Physics Analysis at the LHC
        Description
        The ambitious HL-LHC program will require enormous computing resources in the next two decades. New technologies are being sought to replace the present computing infrastructure. A burning question is whether quantum computers can solve the ever-growing demand for computing resources in High-Energy Physics (HEP) in general and physics at LHC in particular.

        Discovery of new physics requires the identification of rare signals in immense backgrounds. The development of machine learning methods will greatly enhance our ability to achieve this objective.

        With this project we seek to implement Quantum Machine Learning methods for LHC HEP analysis based on the Pennylane framework. This will enhance the ability of the HEP community to use Quantum Machine Learning methods.

        Duration
        Total project length: 175/350 hours.

        Task ideas
        Implement a Quantum Generative Adversarial Network (QGAN) based on a suitable framework, e.g. Pennylane. See e.g. papers for possible models under ‘Links’
        Verify that it works and no mode collapse happens using the MNIST dataset.
        Apply the quantum machine learning method to one LHC flagship physics channel (e.g. double-Higgs production). Compare the quantum machine learning performance to the classical machine learning performance.
        Train a classical GAN and a QGAN on exactly the same tasks and datasets, serving as a direct benchmark. Measure differences in training speed, and the fidelity or quality of generated samples.
        Develop and implement a QGAN that successfully captures the underlying, or “implicit,” probability distribution of the training data and compare the generated and real distributions using distribution-similarity measures.
        Expected results
        Trained Quantum Generative Adversarial Network method based on e.g. Pennylane framework.
        Successfully apply the Quantum Machine Learning method to LHC physics analyses and obtain performance benchmarks to compare to classical machine learning methods.
        A comprehensive comparison of the training time, mode collapse frequency, sample quality scores between QGAN and classical GAN.
        Demonstrate that the QGAN can produce samples whose statistical properties match those of the real dataset.
        Test
        Please use this link to access the test for this project.

        Requirements
        Solid knowledge of machine learning and deep learning
        Knowledge of quantum mechanics
        Strong python skills
        Ability to work independently and proactive on a research project
        Difficulty Level
        Intermediate/Advanced
        Mentors
        Rui Zhang (University of Wisconsin-Madison)
        Sergei Gleyzer (University of Alabama)
        Emanuele Usai (University of Alabama)
        Tom Magorsh (TUM)
        Abhay Kamble (BitsPilani)
        Isabel Pedraza (Benemérita Universidad Autónoma de Puebla)
        Links
        HL-LHC
        LHC
        Pennylane
        Paper 1
        Paper 2
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        QMLHEP
        Participating Organizations
        Alabama
        Wisconsin
        TUM
        BitsPilani
        BUAP


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_GENIE2.html
        TITLE: Learning Parametrization with Implicit Neural Representations
        CONTENT:
        Machine Learning for Science
        Activities
        Learning Parametrization with Implicit Neural Representations
        Description
        In the search for new physics at the Large Hadron Collider (LHC) it is necessary to accurately learn the representation of events that may be described in different ways (point clouds, graphs, grids). Different detector systems can lead to different optimal representations and no single approach is ideal for all detector systems. Conventional representations are usually discrete (point clouds, grids etc.). This project focuses on an alternative approach of parametrizing the representation in terms of a continuous function and approximating it with a neural network.

        Duration
        Total project length: 175/350 hours.

        Difficulty Level
        Intermediate/Advanced
        Task ideas
        Develop implicit neural representation model for particle physics data
        Benchmarking on benchmark datasets
        Expected results
        Functional INR model
        Benchmark results on selected datasets
        Test
        Please use this link to access the test for this project.

        Requirements
        Skills: Python, PyTorch or Keras and some previous experience in Machine Learning.
        Mentors
        Sergei Gleyzer (University of Alabama)
        Ali Hariri (EPFL)
        Amal Saif (PSUT)
        Ameya Thete (BITS Pilani)
        Links
        LHC
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        GENIE
        Participating Organizations
        Alabama
        EPFL
        Princess Sumaya University for Technology
        BITS Pilani Goa


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_QMLHEP6.html
        TITLE: Learning quantum representations of classical high energy physics data with contrastive learning
        CONTENT:
        Machine Learning for Science
        Activities
        Learning quantum representations of classical high energy physics data with contrastive learning
        Description
        The ambitious HL-LHC program will require enormous computing resources in the next two decades. New technologies are being sought after to replace the present computing infrastructure. A burning question is whether quantum computer can solve the ever growing demand of computing resources in High Energy Physics (HEP) in general and physics at LHC in particular. Our goal here is to explore and to demonstrate that Quantum Computing can be the new paradigm (Proof of Principle).

        Discovery of new physics requires the identification of rare signals against immense backgrounds. Development of machine learning methods will greatly enhance our ability to achieve this objective. However, with this ever-growing volume of data in the near future, current machine learning algorithms will require large computing resources and excessive computing time to achieve good performance. Quantum Computing in Qubit platform, where qubits are used instead of bits in classical computer, has the potential to improve the time complexity of classical algorithms.

        With this project we seek to implement Quantum Machine Learning methods for LHC HEP analysis based on e.g. the Pennylane framework. This will enhance the ability of the HEP community to use Quantum Machine Learning methods.

        Duration
        Total project length: 175/350 hours.

        Task ideas
        Implement a trainable embedding function to encode classical data onto a quantum model with contrastive learning. Try and develop different ideas for embedding functions and contrastive losses for training.
        Benchmark the trained embedding against a standard encoding on a given QML model (e.g. a QCNN).
        Expected results
        Trained embedding function for classical data with e.g. Pennylane framework.
        Benchmark of the performance against a standard encoding
        Test
        Please use this link to access the test for this project.

        Requirements
        Solid knowledge of machine learning and deep learning
        Knowledge of quantum mechanics desired
        Strong python skills
        Ability to work independently and proactive on a research project
        Difficulty Level
        Intermediate/Advanced
        Mentors
        Rui Zhang (University of Wisconsin-Madison)
        Alkaid Cheng (University of Wisconsin Madison)
        Sergei Gleyzer (University of Alabama)
        Emanuele Usai (University of Alabama)
        Tom Magorsh (TUM)
        Links
        HL-LHC
        LHC
        Pennylane
        Paper 1
        Paper 2
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        QMLHEP
        Participating Organizations
        Alabama
        Wisconsin
        TUM


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_GENIE3.html
        TITLE: Learning the Latent Structure with Diffusion Models
        CONTENT:
        Machine Learning for Science
        Activities
        Learning the Latent Structure with Diffusion Models
        Description
        In the search for new physics at the Large Hadron Collider (LHC) it is necessary to simulate billions of high-energy collision events at high fidelity. One approach is to use accurate generative modeling to sample from latent space distribution. This project focuses on diffusion models as means of learning the latent structure to produce accurate multidimensional distribution of point cloud data of hits produced by particle interactions with the detectors.

        Duration
        Total project length: 175/350 hours.

        Difficulty Level
        Intermediate/Advanced
        Task ideas
        Develop diffusion models for learning the latent space structure
        Benchmarking on benchmark datasets and comparison to other generative models (VAEs/GANs/etc.)
        Expected results
        Functional diffusion model
        Benchmarks on selected datasets
        Test
        Please use this link to access the test for this project.

        Requirements
        Skills: Python, PyTorch or Keras and some previous experience in Machine Learning.
        Mentors
        Sergei Gleyzer (University of Alabama)
        Ali Hariri (EPFL)
        Amal Saif (PSUT)
        Ameya Thete (BITS Pilani)
        Links
        LHC
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        GENIE
        Participating Organizations
        Alabama
        EPFL
        Princess Sumaya University for Technology
        BITS Pilani Goa


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_E2E5.html
        TITLE: Next generation vision transformers for end to end mass regression and classification
        CONTENT:
        Machine Learning for Science
        Activities
        Next generation vision transformers for end to end mass regression and classification
        Description
        One of the important aspects of searches for new physics at the Large Hadron Collider (LHC) involves the identification and reconstruction of single particles, jets and event topologies of interest in collision events. The End-to-End Deep Learning (E2E) project in the CMS experiment focuses on the development of these reconstruction and identification tasks with innovative deep learning approaches.

        A minimal representation of particle collision data is as an image representation of particle hits in different layers of the detector. This project will explore development of vision transformers incorporating the latest knowledge in the field of computer vision to classify particle collision images by the type of heavy particles generated in the collision and reconstruct the mass of those particles.

        Duration
        Total project length: 175/350 hours.

        Difficulty level
        Intermediate

        Task ideas
        Development of vision transformer models for end-to-end classification and regression
        Expected results
        Trained vision transformer models incorporating the latest computer vision techniques
        Benchmarks against baseline vision transformers and comparison of different vision transformer types
        Requirements
        C++, Python, PyTorch and some previous experience in Machine Learning.

        Test
        Please use this link to access the test for this project.

        Mentors
        Ruchi Chudasama (University of Alabama)
        Shravan Chaudhari (New York University)
        Sergei Gleyzer (University of Alabama)
        Purva Chaudhari (Vishwakarma Institute of Technology)
        Diptarko Choudhury (NISER)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Corresponding Project
        E2E
        Participating Organizations
        Alabama
        New York University
        Vishwakarma Institute of Technology
        NISER


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_SYMBA1.html
        TITLE: Next-Generation Transformer Models for Symbolic Calculations of Squared Amplitudes in HEP
        CONTENT:
        Machine Learning for Science
        Activities
        Next-Generation Transformer Models for Symbolic Calculations of Squared Amplitudes in HEP
        Description
        One of the most important physical quantities in particle physics is the cross section, or a probability that a particular process takes place in the interaction of elementary particles. Its measure provides a testable link between theory and experiment. It is obtained theoretically mainly by calculating the squared amplitude. The approach we use in this project is to treat the amplitude and squared amplitude as mathematical symbolic expressions and use language-translation models to map from the amplitude to squared-amplitude. This project will explore uses of more advanced techniques which could include but are not limited to Kolmogorov-Arnold Network layers in transformers, genetic algorithms and other evolutionary techniques, reinforcement learning.

        Duration
        Total project length: 175/350 hours.

        Task ideas and expected results
        Develop various transformer-based models on sequence-to-sequence tasks
        Benchmark different models on simulated physics datasets of various complexity and sequence lengths to find the best model
        Integrate with the SymbaHEP pipeline
        Requirements
        Significant experience with Transformer machine learning models in Python (preferably using pytorch).

        Difficulty Level
        Advanced

        Test
        Please use this link to access the test for this project.

        Mentors
        Eric Reinhardt (University of Alabama)
        Abdulhakim Alnuqaydan (Qassim University)
        Sergei Gleyzer (University of Alabama)
        Harrison Prosper (Florida State University)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Poster 1
        Blog post 1
        Corresponding Project
        SYMBA
        Participating Organizations
        Alabama
        FSU
        QU


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_GENIE4.html
        TITLE: Non-local GNNs for Jet Classification
        CONTENT:
        Machine Learning for Science
        Activities
        Non-local GNNs for Jet Classification
        Description
        In the search for new physics at the Large Hadron Collider (LHC) a possible approach is to employ anomaly detection techniques to spot events that deviate from the standard model in an unsupervised manner. There have been many such studies using e.g. convolutional autoencoders. In previous GSoC projects, the usage of graph-based models has been very successful in generative tasks.Motivated by the success of graph-based models in various computational tasks, this project seeks to leverage non-local graph neural networks (GNNs) for the classification of jets in particle physics. Unlike conventional methods, which treat jets as independent entities, the proposed approach capitalizes on the inherent relational structure among particles within a jet, represented as a graph. The challenge is to account the long-range dependencies inherent to the jets, which regular GNNs fail to do.

        Duration
        Total project length: 175/350 hours.

        Difficulty Level
        Intermediate/Advanced
        Task ideas
        Develop a model for graph-based jet classification while accounting for long-range dependencies
        Benchmarking on benchmark datasets and comparison to a Transformer and regular MPNNs
        Expected results
        Trained graph-based jet classifier
        Benchmarks on selected datasets
        Test
        Please use this link to access the test for this project.

        Requirements
        Skills: Python, PyTorch or Keras and some previous experience in Machine Learning.
        Mentors
        Sergei Gleyzer (University of Alabama)
        Ali Hariri (EPFL)
        Tom Magorsch (TUM)
        Links
        LHC
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        GENIE
        Participating Organizations
        Alabama
        EPFL
        Princess Sumaya University for Technology
        BITS Pilani Goa


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_FALCON4.html
        TITLE: Optimal Transport in High Energy Physics
        CONTENT:
        Machine Learning for Science
        Activities
        Optimal Transport in High Energy Physics
        Description
        The concept of Optimal Transport (OT) can be very useful in quantifying a distance metric between probability distributions. This project will focus on applying optimal transport methods to classification, anomaly detection and generative modeling tasks in particle physics.

        Duration
        Total project length: 175/350 hours.

        Task ideas and expected results
        Application of optimal transport techniques using deep learning for classification, anomaly detection and graph generative models in high energy physics.

        Test
        Please use this link to access the test for this project.

        Requirements
        Strong machine learning skills, good knowledge of C++ and Python. Interest in Machine Learning algorithms and applications.

        Mentors
        Ali Hariri (EPFL)
        Sergei Gleyzer (University of Alabama)
        Emanuele Usai (University of Alabama)
        Sinan Gençoğlu (Middle East Technical University)
        Amal Saif (Princess Sumaya University for Technology)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        DeepFALCON
        Participating Organizations
        Alabama
        EPFL
        Middle East Technical University
        Princess Sumaya University for Technology
        CERN


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_DEEPLENSE3.html
        TITLE: Physics Guided Machine Learning on Real Lensing Images
        CONTENT:
        Machine Learning for Science
        Activities
        Physics Guided Machine Learning on Real Lensing Images
        Description
        This project focuses on developing a Physics-Informed Neural Network (PINN) framework for analyzing real strong gravitational lensing datasets to study dark matter distribution. Strong gravitational lensing, a key prediction of general relativity, occurs when a massive galaxy or cluster bends light from a background source, creating arcs or Einstein rings. Traditional algorithms struggle or fail entirely when applied to real lensing datasets due to observational complexities and noise. By leveraging PINNs, the project will integrate physical laws directly into the learning process, enhancing the accuracy and interpretability of dark matter inferences. The model will be trained on real lensing images, incorporating observational constraints to refine mass distribution estimates and improve the efficiency of dark matter studies.

        Duration
        Total project length: 175/350 hours.

        Difficulty level
        Intermediate/Advanced

        Task ideas
        Build various physics-informed neural network architectures that are endowed with known physics for real lensing datasets.
        Apply these models to study dark matter in strong lensing images in various contexts: classification, regression, anomaly detection, and more.
        Expected results
        A more capable architecture that can operate on a wider variety of lensing images, including lensing images created with real galaxy datasets.
        Insight into the lensing systems, and their sub-structures.
        Requirements
        Python, PyTorch, experience with machine learning, knowledge of computer vision techniques, familiarity with autoencoders.

        Test
        Please use this link to access the test for this project.

        Mentors
        Michael Toomey (Massachusetts Institute of Technology)
        Sergei Gleyzer (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The relevant mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Corresponding Project
        DEEPLENSE
        Participating Organizations
        Alabama
        MIT


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_GENIE5.html
        TITLE: Physics-Informed Neural Network Diffusion Equation (PINNDE)
        CONTENT:
        Machine Learning for Science
        Activities
        Physics-Informed Neural Network Diffusion Equation (PINNDE)
        Description
        There is much interest in building ultra-fast samplers that map a density that is easy to sample from, typically, an n-dimensional normal to a desired n-dimensional density. One way to compute this mapping is to solve the reverse-time diffusion equation [1], which is an integro-differential equation. In Ref. [2], the integral in this equation is approximated using Monte Carlo integration where the integrand is averaged over N (~5K – 10K) points sampled from the desired distribution. Solving this equation is relatively slow, therefore, typically a neural network is trained to model the mapping from the normal to the desired density using training data generated by repeatedly solving the differential equation.

        In this project, an alternative approach is investigated: modeling the solution to the differential equation using a physics-informed neural network (PINN) [3]. There is a large upfront cost in training the PINN, but this is subsequently amortized over the fast sampling using the PINN. Various neural network architectures for the PINN will be investigated.

        Duration
        Total project length: 175/350 hours.

        Difficulty Level
        Intermediate/Advanced
        Task ideas
        Map a 3D zero mean, unit variance, diagonal normal to a 3D non-Gaussian density using a PINN. The inputs to the PINN are t, x, y, z — that is, the reverse time t ∈ [1, 0] and a point sampled from the 3D normal. The output of the PINN is the vector solution u(t, x, y, z). Since the PINN is conditioned on x, y, z, during training the points can be sampled from any convenient distribution, including quasi-random sampling such as Sobol sampling. (Of course, when used we must sample from a 3D normal.)
        Repeat with increasingly complex 3D non-Gaussian densities.
        Optional: Apply what has been learned from 1 and 2 to build a fast calorimeter simulator. Use Dataset 1 from the Fast Calorimeter Simulation Challenge 2022 [4].
        Publish the results in an ML paper.
        Expected results
        Trained graph-based jet classifier
        Benchmarks on selected datasets
        Test
        Using PyTorch, solve the damped harmonic oscillator [5] using a PINN. Choose fixed initial conditions:
        x(0) = x₀, dx/dz(0) = v₀, with x₀ = 0.7 and v₀ = 1.2.
        Condition the PINN on damping ratios in the range ξ = 0.1 to 0.4.
        Solve on the domain z ∈ [0, 20]:
        d²x/dz² + 2ξ·dx/dz + x = 0
        Requirements
        Experience with numerical solution of ordinary differential equations.
        Familiarity with PyTorch.
        Difficultly Level
        Advanced

        Mentors
        Harrison B. Prosper (Florida State University)
        Pushpalatha Bhat (Fermilab)
        Sergei Gleyzer (University of Alabama)
        Links
        Cheng Lu†, Yuhao Zhou†, Fan Bao†, Jianfei Chen†, Chongxuan Li‡, Jun Zhu, DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps, arXiv:2206.00927v3, 13 Oct 2022.

        Yanfang Lui, Minglei Yang, Zezhong Zhang, Feng Bao, Yanzhao Cao, and Guannan Zhang, Diffusion-Model-Assisted Supervised Learning of Generative Models for Density Estimation, arXiv:2310.14458v1, 22 Oct 2023.

        S. Cuomo et al., Scientific Machine Learning through Physics-Informed Neural Networks: Where we are and What’s next, https://doi.org/10.48550/arXiv.2201.05624.

        https://calochallenge.github.io/homepage/

        https://en.wikipedia.org/wiki/Harmonic_oscillator

        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        GENIE
        Participating Organizations
        Alabama
        FSU
        Fermilab


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_QMLHEP8.html
        TITLE: Q-MAML - Quantum Model-Agnostic Meta-Learning for Variational Quantum Algorithms for High Energy Physics Analysis at the LHC
        CONTENT:
        Machine Learning for Science
        Activities
        Q-MAML - Quantum Model-Agnostic Meta-Learning for Variational Quantum Algorithms for High Energy Physics Analysis at the LHC
        Description
        The rapid data growth at the Large Hadron Collider (LHC) presents an unprecedented challenge for computational resources. As the High Luminosity LHC (HL-LHC) era approaches, existing classical computing infrastructures will struggle to keep up with the increasing complexity of data analysis. Machine learning techniques have already demonstrated their potential in identifying rare physics signals within massive datasets, but the computational cost of model training and optimization limits their efficiency.

        Quantum Computing offers a new paradigm for tackling these challenges by leveraging Variational Quantum Algorithms (VQAs). However, training these quantum models effectively remains challenging due to barren plateaus and inefficient parameter optimization, leading to slow convergence.

        This project explores the potential of AI for Quantum Computing to improve the efficiency of quantum machine learning in High Energy Physics (HEP). By optimizing variational quantum circuits with a classical meta-learning model, we aim to accelerate convergence and reduce the computational burden of quantum optimization. This approach will be tested on real or simulated LHC data, demonstrating the feasibility of quantum-enhanced data analysis for HEP.

        Duration
        Total project length: 175 hours.

        Task ideas
        D(example. Q-MAML) Implementation for HEP Tasks
        Design and implement (Q-MAML) for optimizing variational quantum circuits.
        Apply (Q-MAML) to common HEP-related quantum optimization problems.
        Benchmarking on HEP Datasets
        Compare (Q-MAML-enhanced) quantum models against classical ML models.
        Analyze performance improvements in terms of convergence speed and accuracy.
        Expected results
        Trained variational quantum models optimized for HEP analysis.
        Benchmarks comparing Q-MAML-enhanced quantum optimization to classical methods.
        Demonstration of improved trainability and efficiency of quantum models for LHC data.
        Test
        Please use this link to access the test for this project.

        Requirements
        Strong background in Machine Learning & Deep Learning.
        Knowledge of Quantum Computing (VQAs, Quantum Optimization).
        Proficiency in Python & Pennylane.
        Ability to work independently on research projects.
        Difficulty Level
        Advanced – requires expertise in Quantum ML and HEP data analysis.
        Mentors
        Rui Zhang (University of Wisconsin-Madison)
        Alkaid Cheng (University of Wisconsin Madison)
        Sergei Gleyzer (University of Alabama)
        Konstantin Matchev (University of Alabama)
        Emanuele Usai (University of Alabama)
        Links
        HL-LHC
        LHC
        Pennylane
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        QMLHEP
        Participating Organizations
        Alabama
        Wisconsin


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_QMLHEP9.html
        TITLE: Quantum Diffusion Model for High Energy Physics
        CONTENT:
        Machine Learning for Science
        Activities
        Quantum Diffusion Model for High Energy Physics
        Description
        The ambitious HL-LHC program will require enormous computing resources and datasets in the next two decades. New technologies are being sought after to replace the present computing infrastructure. A burning question is whether quantum computers can solve the ever growing demand of computing resources in High Energy Physics (HEP) in general and physics at LHC in particular. Our goal here is to explore and to demonstrate that Quantum Computing can be the new paradigm (Proof of Principle). Discovery of new physics requires the identification of rare signals against immense backgrounds. Development of machine learning methods will greatly enhance our ability to achieve this objective. However, with this ever-growing volume of data in the near future, current machine learning algorithms will require large computing resources and excessive computing time to achieve good performance. Quantum Computing in Qubit platform, where qubits are used instead of bits in classical computers, has the potential to improve the time complexity of classical algorithms.

        With this project we seek to implement Quantum Machine Learning methods for LHC HEP analysis based on the Pennylane framework. This will enhance the ability of the HEP community to use Quantum Machine Learning methods.

        Duration
        Total project length: 175 hours.

        Task ideas
        Implement a fully quantum diffusion model architecture
        Benchmark the trained model on selected tasks by employing a classical model (DDPM, DDIM, or a similar variant)
        Analyze scalability and computational complexity of the proposed model
        Expected results
        Trained quantum diffusion model
        Benchmark of the performance on a HEP dataset compared against a classical reference model
        Test
        Please use this link to access the test for this project.

        Requirements
        Strong background in Machine Learning & Deep Learning.
        Knowledge of Quantum Computing (VQAs, Quantum Optimization).
        Proficiency in Python & Pennylane.
        Ability to work independently on research projects.
        Difficulty Level
        Advanced – requires expertise in Quantum ML and HEP data analysis.
        Mentors
        Rui Zhang (University of Wisconsin-Madison)
        Sergei Gleyzer (University of Alabama)
        Konstantin Matchev (University of Alabama)
        Tom Magorsh (TUM)
        Links
        HL-LHC
        LHC
        Pennylane
        Paper 1
        Paper 2
        Blog Post
        Paper 3
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        QMLHEP
        Participating Organizations
        Alabama
        Wisconsin
        TUM


        Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
        ~~~~~~~~~~


        URL: https://ml4sci.org/gsoc/2025/proposal_QMLHEP11.html
        TITLE: Quantum Foundation Model for High Energy Physics
        CONTENT:
        Machine Learning for Science
        Activities
        Quantum Foundation Model for High Energy Physics
        Description
        The ambitious HL-LHC program will require enormous computing resources and datasets in the next two decades. New technologies are being sought after to replace the present computing infrastructure. A burning question is whether quantum computers can solve the ever growing demand of computing resources in High Energy Physics (HEP) in general and physics at LHC in particular. Our goal here is to explore and to demonstrate that Quantum Computing can be the new paradigm (Proof of Principle). Discovery of new physics requires the identification of rare signals against immense backgrounds. Development of machine learning methods will greatly enhance our ability to achieve this objective. However, with this ever-growing volume of data in the near future, current machine learning algorithms will require large computing resources and excessive computing time to achieve good performance. Quantum Computing in Qubit platform, where qubits are used instead of bits in classical computers, has the potential to improve the time complexity of classical algorithms.

        With this project we seek to implement Quantum Foundation Model for LHC HEP analysis based on the Pennylane framework. This will enhance the ability of the HEP community to use Quantum Machine Learning methods.

        Duration
        Total project length: 175 hours.

        Task ideas
        Design and implement a quantum foundation model architecture for LHC data
        Benchmark the trained model on selected tasks by employing a classical model
        Analyze scalability and computational complexity of the proposed model
        Expected results
        Trained quantum foundation model
        Benchmark of the performance on a HEP dataset compared against a classical reference model
        Test
        Please use this link to access the test for this project.

        Requirements
        Strong background in Machine Learning & Deep Learning.
        Knowledge of Quantum Computing (VQAs, Quantum Optimization).
        Proficiency in Python & Pennylane.
        Ability to work independently on research projects.
        Difficulty Level
        Advanced – requires expertise in Quantum ML and HEP data analysis.
        Mentors
        Rui Zhang (University of Wisconsin-Madison)
        Sergei Gleyzer (University of Alabama)
        Konstantin Matchev (University of Alabama)
        Tom Magorsh (TUM)
        Links
        HL-LHC
        LHC
        Pennylane

        ~~~~~~~~~~
        Quantum Graph Neural Networks for High Energy Physics Analysis at the LHC

        Description
        The ambitious HL-LHC program will require enormous computing resources in the next two decades. New technologies are being sought to replace the present computing infrastructure. A burning question is whether quantum computers can solve the ever-growing demand for computing resources in High-Energy Physics (HEP) in general and physics at LHC in particular. Discovery of new physics requires the identification of rare signals against immense backgrounds. The development of machine learning methods will greatly enhance our ability to achieve this objective. With this project we seek to implement Quantum Machine Learning methods for LHC HEP analysis based on the Pennylane framework. This will enhance the ability of the HEP community to use Quantum Machine Learning methods.

        Duration
        Total project length: 175/350 hours.

        Task ideas
        Implement a Quantum Graph Neural Network (QGNN) method based on a suitable framework e.g. Pennylane.
        Apply the quantum machine learning method to a benchmark high-energy physics analysis and benchmark the quantum machine learning performance compared to classical machine learning methods
        Expected results
        Trained Quantum Graph Neural Network with e.g. Pennylane framework.
        Apply the Quantum Machine Learning method to LHC physics analysis and compare to classical machine learning methods.
        Test
        Please use this link to access the test for this project.

        Requirements
        Solid knowledge of machine learning and deep learning
        Knowledge of quantum mechanics desired
        Strong python skills
        Ability to work independently and proactive on a research project
        Difficulty Level
        Intermediate/Advanced
        Mentors
        Rui Zhang (University of Wisconsin-Madison)
        Alkaid Cheng (University of Wisconsin-Madison)
        Sergei Gleyzer (University of Alabama)
        KC Kong (University of Kansas)
        Roy Forestano (University of Florida)
        Links
        HL-LHC
        LHC
        Pennylane
        Paper 1
        Paper 2
        Paper 3
        Paper 4
        Paper 5
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        QMLHEP
        Participating Organizations
        Alabama
        Wisconsin
        Kansas
        Florida
        
        ~~~~~~~~~~
        Quantum Kolmogorov-Arnold Networks for High Energy Physics Analysis at the LHC

        Description
        The ambitious HL-LHC program will require enormous computing resources in the next two decades. New technologies are being sought after to replace the present computing infrastructure. A burning question is whether quantum computer can solve the ever growing demand of computing resources in High Energy Physics (HEP) in general and physics at LHC in particular.

        Discovery of new physics requires the identification of rare signals against immense backgrounds. Development of machine learning methods will greatly enhance our ability to achieve this objective. With this project we seek to implement Quantum Machine Learning methods for LHC HEP analysis based on the Pennylane framework. This will enhance the ability of the HEP community to use Quantum Machine Learning methods.

        Duration
        Total project length: 175 hours.

        Task ideas
        Implement a quantum Kolmogorov-Arnold Network architecture.
        Benchmark the trained model on selected tasks
        Expected results
        Trained quantum diffusion model
        Benchmark of the performance on a HEP dataset compared against a classical reference model
        Test
        Please use this link to access the test for this project.

        Requirements
        Solid knowledge of machine learning and deep learning
        Knowledge of quantum mechanics and linear algebra
        Strong python skills
        Ability to work independently and proactive on a research project
        Difficulty Level
        Intermediate/Advanced
        Mentors
        Eric Reinhardt (University of Alabama)
        Dinesh Ramakrishnan (University of Alabama)
        KC Kong (University of Kansas)
        Links
        HL-LHC
        LHC
        Pennylane
        Paper 1
        Paper 2
        Paper 3
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        QMLHEP
        Participating Organizations
        Alabama
        Kansas

        
        ~~~~~~~~~~
        Quantum Machine Learning for Exoplanet Characterization

        Note
        This project is a collaboration with EXXA and QMLHEP.

        Description
        The characterization of exoplanet atmospheres is crucial for understanding their compositions, weather patterns, and potential habitability. This project aims to develop quantum machine learning models to analyze spectral data from exoplanets, identifying chemical abundances, cloud/haze structure and different atmospheric processes. The project will leverage data from telescopes and space missions, along with simulations of exoplanetary atmospheres under various conditions, to train and validate the models.

        Duration
        Total project length: 175/350 hours.

        Task Ideas
        Identify suitable latent representations of the exoplanet transmission data.
        Develop a quantum machine learning architecture for detecting anomalous exoplanets based on synthetic transmission spectra.
        Develop a quantum generative model for simulating exoplanet transmission spectra.
        Apply the trained models to real observational data from missions like Hubble, JWST, and future telescopes to characterize exoplanet atmospheres.
        Benchmark the performance of the developed quantum machine learning models against their classical counterparts.
        Expected Results
        A set of quantum machine learning models capable of accurately modeling exoplanet atmospheres or flagging anomalous spectra.
        Analysis of the models’ performance on observational data, demonstrating their applicability to current and future exoplanet studies.
        Requirements
        Python
        PyTorch or TensorFlow (or similar)
        Some experience with Qiskit or Pennylane is preferred
        Background in astronomy is a bonus but not a requirement
        Test
        Use this link for instructions on completing the test.

        Mentors
        Katia Matcheva (University of Alabama)
        Konstantin Matchev (University of Alabama)
        Sergei Gleyzer (University of Alabama)
        Alex Roman (University of Alabama)
        Emilie Panek (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV. The mentors will then get in touch with you.

        Corresponding Project
        EXXA
        Participating Organizations
        University of Alabama



        
        ~~~~~~~~~~
        Quantum Machine Learning for Exoplanet Characterization

        Note
        This project is a collaboration with EXXA and QMLHEP.

        Description
        The characterization of exoplanet atmospheres is crucial for understanding their compositions, weather patterns, and potential habitability. This project aims to develop quantum machine learning models to analyze spectral data from exoplanets, identifying chemical abundances, cloud/haze structure and different atmospheric processes. The project will leverage data from telescopes and space missions, along with simulations of exoplanetary atmospheres under various conditions, to train and validate the models.

        Duration
        Total project length: 175/350 hours.

        Task Ideas
        Identify suitable latent representations of the exoplanet transmission data.
        Develop a quantum machine learning architecture for detecting anomalous exoplanets based on synthetic transmission spectra.
        Develop a quantum generative model for simulating exoplanet transmission spectra.
        Apply the trained models to real observational data from missions like Hubble, JWST, and future telescopes to characterize exoplanet atmospheres.
        Benchmark the performance of the developed quantum machine learning models against their classical counterparts.
        Expected Results
        A set of quantum machine learning models capable of accurately modeling exoplanet atmospheres or flagging anomalous spectra.
        Analysis of the models’ performance on observational data, demonstrating their applicability to current and future exoplanet studies.
        Requirements
        Python
        PyTorch or TensorFlow (or similar)
        Some experience with Qiskit or Pennylane is preferred
        Background in astronomy is a bonus but not a requirement
        Test
        Use this link for instructions on completing the test.

        Mentors
        Katia Matcheva (University of Alabama)
        Konstantin Matchev (University of Alabama)
        Sergei Gleyzer (University of Alabama)
        Alex Roman (University of Alabama)
        Emilie Panek (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV. The mentors will then get in touch with you.

        Corresponding Project
        QMLHEP
        Participating Organizations
        University of Alabama
        Georgia


        
        ~~~~~~~~~~
        Quantum Particle transformer for High Energy Physics Analysis at the LHC

        Description
        The ambitious HL-LHC program will require enormous computing resources in the next two decades. New technologies are being sought after to replace the present computing infrastructure. A burning question is whether quantum computer can solve the ever growing demand of computing resources in High Energy Physics (HEP) in general and physics at LHC in particular. Our goal here is to explore and to demonstrate that Quantum Computing can be the new paradigm (Proof of Principle).

        Discovery of new physics requires the identification of rare signals against immense backgrounds. The development of machine learning methods will greatly enhance our ability to achieve this objective. However, with this ever-growing volume of data in the near future, current machine learning algorithms will require large computing resources and excessive computing time to achieve good performance. Quantum Computing in the Qubit platform, where qubits are used instead of bits in classical computers, can potentially improve the time complexity of classical algorithms.

        With this project, we seek to implement Quantum Machine Learning methods for LHC HEP analysis based on the Pennylane framework. This will enhance the HEP community’s ability to use Quantum Machine Learning methods.

        Duration
        Total project length: 175 hours.

        Task ideas
        Develop a baseline Particle Transformer (ParT).
        Incorporate quantum-inspired architectures into the ParT model, leveraging VQCs and QONNs to explore potential advantages in efficiency and generalization.
        Train and evaluate the Q-ParT models on HEP datasets, such as jet tagging and particle classification datasets.
        Expected results
        Trained quantum particle transformer models.
        Benchmark of the performance on a HEP dataset compared against a classical reference model
        Test
        Please use this link to access the test for this project.

        Requirements
        Solid knowledge of machine learning and deep learning
        Knowledge of quantum mechanics
        Strong python skills
        Ability to work independently and proactive on a research project
        Difficulty Level
        Intermediate/Advanced
        Mentors
        Rui Zhang (University of Wisconsin-Madison)
        Alkaid Cheng (University of Wisconsin Madison)
        Sergei Gleyzer (University of Alabama)
        Konstantin Matchev (University of Alabama)
        Emanuele Usai (University of Alabama)
        Marçal Comajoan Cara (Polytecnic University of Catalonia)
        Links
        HL-LHC
        LHC
        Pennylane
        Paper 1
        Paper 2
        Paper 3
        Paper 4
        Paper 5
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        QMLHEP
        Participating Organizations
        Alabama
        Wisconsin
        PUC

        
        ~~~~~~~~~~
        Quantum transformer for High Energy Physics Analysis at the LHC

        Description
        The ambitious HL-LHC program will require enormous computing resources in the next two decades. New technologies are being sought after to replace the present computing infrastructure. A burning question is whether quantum computer can solve the ever growing demand of computing resources in High Energy Physics (HEP) in general and physics at LHC in particular.

        Discovery of new physics requires the identification of rare signals against immense backgrounds. Development of machine learning methods will greatly enhance our ability to achieve this objective. With this project we seek to implement Quantum Machine Learning methods for LHC HEP analysis based on the Pennylane framework. This will enhance the ability of the HEP community to use Quantum Machine Learning methods.

        Duration
        Total project length: 175 hours.

        Task ideas
        Implement a quantum transformer architecture (QVIT, QTF).
        Benchmark the trained model on selected tasks by e.g. employing a hybrid transformer (vision and sequence)
        Expected results
        Trained quantum transformer model.
        Benchmark of the performance on a HEP dataset compared against a classical reference model
        Test
        Please use this link to access the test for this project.

        Requirements
        Solid knowledge of machine learning and deep learning
        Knowledge of quantum mechanics desired
        Strong python skills
        Ability to work independently and proactive on a research project
        Difficulty Level
        Intermediate/Advanced
        Mentors
        Rui Zhang (University of Wisconsin-Madison)
        Alkaid Cheng (University of Wisconsin Madison)
        Sergei Gleyzer (University of Alabama)
        Konstantin Matchev (University of Alabama)
        Emanuele Usai (University of Alabama)
        Marçal Comajoan Cara (Polytecnic University of Catalonia)
        Links
        HL-LHC
        LHC
        Pennylane
        Paper 1
        Paper 2
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Corresponding Project
        QMLHEP
        Participating Organizations
        Alabama
        Wisconsin
        PUC
        
        ~~~~~~~~~~
        Semi-supervised Symmetry Discovery

        Description
        Recent success in the domain of unsupervised and semi-supervised learning has been lately a pivotal factor for development of Physics Aware and Symmetry Aware Machine Learning techniques where a model learns the symmetry of a dataset as a meta task and ends up learning the physics through the same.

        Although most of the symmetries that we work with for SM physics are well defined and formulated, they can be well interpreted in 4-vector or 4-momenta basis. With change of representation the symmetries become elusive and difficult to write and work with. This calls for machine learning techniques that can learn the representation of the given symmetry through the means of a conserved quantity for a given abstract representation space.

        Learning these symmetries not only makes us more prepared to deal with the physics constraints in these abstract spaces and coordinates but also makes us able to build neural networks that are invariant to these symmetries. Such neural networks as seen from the existing literature are more robust, stable, interpretable and data efficient.

        This project will focus on ways to learn the symmetries using semi-supervised approaches for the raw CMS calorimetric data stream.

        Duration
        Total project length: 175/350 hours.

        Task ideas
        Build an understanding of the symmetries present and their nature of representation on the CMS detector space link.
        Develop a supervised model to learn some of the symmetries given the conserved quantity and nature of augmentations.
        Extend the supervised approach to a semi-supervised setup to discover symmetries without using the augmentation space link.
        [Advanced Step] Using the symmetries discovered to build physics to build a physics-aware neural network.
        Expected results
        Discover hidden symmetries present in the CMS dataset.
        Benchmark the models with other previous works in terms of data efficiency and invariance with respect to symmetry operations.
        Difficulty level
        Advanced

        Requirements
        Proficiency in C++, Python
        Experience with PyTorch and TensorFlow
        Previous experience in Deep Learning
        Test
        Please use this link to access the test for this project.

        Mentors
        Diptarko Choudhury (NISER)
        Sergei Gleyzer (University of Alabama)
        Ruchi Chudasama (University of Alabama)
        Samuel Campbell (University of Alabama)
        Emanuele Usai (University of Alabama)
        Alex Roman (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Corresponding Project
        SYMMETRY
        Participating Organizations
        Alabama
        NISER


        
        ~~~~~~~~~~
        State-space models for squared amplitude calculation in high-energy physics

        Description
        One of the most important physical quantities in particle physics is the cross section, or a probability that a particular process takes place in the interaction of elementary particles. Its measure provides a testable link between theory and experiment. It is obtained theoretically mainly by calculating the squared amplitude. In this project we will explore state-space models (SSMs) to map from amplitudes to squared amplitudes using sequence to sequence representations.

        Duration
        Total project length: 175/350 hours.

        Task ideas and expected results
        Develop and deploy state-space models (SSM) for symbolic solutions of squared amplitude calculations
        Benchmark the SSM models with other transformer-based solutions
        Integrated with the SymbaHEP pipeline
        Requirements
        Significant experience with machine learning models in Python (preferably using pytorch).

        Difficulty Level
        Advanced

        Test
        Please use this link to access the test for this project.

        Mentors
        Eric Reinhardt (University of Alabama)
        Abdulhakim Alnuqaydan (Qassim University)
        Marco Knipfer (University of Alabama)
        Victor Baules (University of Alabama)
        Dinesh Ramakrishnan (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Poster 1
        Blog post 1
        Corresponding Project
        SYMBA
        Participating Organizations
        Alabama
        QU



        ~~~~~~~~~~
        Super resolution at the CMS detector

        Description
        One of the important aspects of searches for new physics at the Large Hadron Collider (LHC) involves the identification and reconstruction of single particles, jets and event topologies of interest in collision events. In order to correctly reconstruct particles of interest, high resolution is required.

        This project will focus on developing machine learning models to map processed, lower resolution data from particle from simulated particle collisions back to a higher resolution representation.

        Duration
        Total project length: 175/350 hours.

        Task ideas
        Develop a machine-learning super-resolution model to upsample particle collision data
        Analyze performance on ground-truth simulated higher resolution data
        Expected results
        Trained models and benchmarks on simulated data
        Test
        Please use this link to access the test for this project.

        Requirements
        Python, C++, and some previous experience in Machine Learning.

        Mentors
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Corresponding Project
        CMS
        Participating Organizations
        Alabama


        
        ~~~~~~~~~~
        Symbolic empirical representation of squared amplitudes in high-energy physics

        Description
        One of the most important physical quantities in particle physics is the cross section, or a probability that a particular process takes place in the interaction of elementary particles. Its measure provides a testable link between theory and experiment. It is obtained theoretically mainly by calculating the squared amplitude (matrix M).

        Duration
        Total project length: 175/350 hours.

        Task ideas and expected results
        Explore physics-informed ideas for improving data representations, physics-aware models, and physics simulations for squared amplitude calculation
        Apply symbolic machine learning techniques to predict the squared amplitudes and cross section for high-energy physics
        Requirements
        Python, C++ and some experience in Machine Learning sequence models.
        Knowledge of physics and linear algebra is desired
        Test
        Please use this link to access the test for this project.

        Difficulty Level
        Intermediate/Advanced

        Mentors
        Abdulhakim Alnuqaydan (Qassim University)
        Sergei Gleyzer (University of Alabama)
        Harrison Prosper (Florida State University)
        Eric Reinhardt (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Corresponding Project
        SYMBA
        Participating Organizations
        Alabama
        FSU
        QU
        
        ~~~~~~~~~~
        Titans for squared amplitude calculation

        Description
        One of the most important physical quantities in particle physics is the cross section, or a probability that a particular process takes place in the interaction of elementary particles. Its measure provides a testable link between theory and experiment. It is obtained theoretically mainly by calculating the squared amplitude. In this project we will explore google’s novel TITANS architecture to map from amplitudes to squared amplitudes using sequence to sequence representations.

        Duration
        Total project length: 175/350 hours.

        Task ideas and expected results
        Develop symbolic regression models based on the novel Titans model architectures
        Benchmark these models on synthetic and high-energy physics datasets
        Requirements
        Significant experience with developing foundational models in Python (preferably using pytorch).

        Difficulty Level
        Advanced

        Test
        Please use this link to access the test for this project.

        Mentors
        Eric Reinhardt (University of Alabama)
        Sergei Gleyzer (University of Alabama)
        Marco Knipfer (University of Alabama)
        Victor Baules (University of Alabama)
        Dinesh Ramakrishnan (University of Alabama)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Corresponding Project
        SYMBA
        Participating Organizations
        Alabama
                
        ~~~~~~~~~~
        Transformer Models for Symbolic Regression

        Description
        Symbolic regression can be used to rapidly provide solutions to problems in science which may have large computational complexity or may even be intractable. It can be used to discover a symbolic expression describing data such as a physical law. Previous work has explored combinations of Transformer models combined with genetic algorithms or reinforcement learning. Future work on this project might extend those approaches but could also include explorations of alternative approaches such as incorporation of Kolmogorov-Arnold Layers or novel LLM-based approaches. As a concrete testbed for these new algorithms, the project will focus on predicting physical quantities, such as cross sections in high-energy physics, e.g a probability that a particular process takes place in the interaction of elementary particles. Its measure provides a testable link between theory and experiment. It is obtained theoretically mainly by calculating the squared amplitude.

        Duration
        Total project length: 175/350 hours.

        Task ideas and expected results
        Develop symbolic regression models based on next-gen transformer architectures
        Develop a hybrid method based on elements of both approaches
        Benchmark these models on synthetic and high-energy physics datasets
        Requirements
        Significant experience with Transformer machine learning models in Python (preferably using pytorch).

        Difficulty Level
        Intermediate

        Test
        Please use this link to access the test for this project.

        Mentors
        Eric Reinhardt (University of Alabama)
        Harrison Prosper (Florida State University)
        Marco Knipfer (University of Alabama)
        Dinesh Ramakrishnan (University of Alabama)
        François Charton
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Paper 4
        Blog Post 1
        Corresponding Project
        SYMBA
        Participating Organizations
        Alabama
        FSU
        QU

        
        ~~~~~~~~~~
        Unsupervised Super-Resolution and Analysis of Real Lensing Images

        Description
        This project’s aims are twofold: developing an unsupervised super-resolution architecture to upscale the quality of lensing images constructed using real galaxy sources, and to obtain insight about the lenses themselves. An unsupervised super-resolution technique could be very valuable for lensing studies as access to high resolution lensing images for training and study can be limited, especially given potential lensing data from upcoming surveys such as Euclid and LSST. The overall goal of this project is to develop an architecture that can better study the characteristics of the gravitational lenses and their substructure.

        Duration
        Total project length: 175/350 hours.

        Difficulty level
        Intermediate/Advanced

        Task ideas
        Start with unsupervised SR of simulated images and think of ways to bridge the gap to real images.
        Try then integrating into the pipeline modules that study characteristics of the lenses.
        Expected results
        A more capable architecture that can operate on a wider variety of lensing images, including lensing images created with real galaxy datasets.
        Insight into the lensing systems, and their sub-structures.
        Requirements
        Python, PyTorch, experience with machine learning, knowledge of computer vision techniques, familiarity with autoencoders.

        Test
        Please use this link to access the test for this project.

        Mentors
        Michael Toomey (Massachusetts Institute of Technology)
        Sergei Gleyzer (University of Alabama)
        Pranath Reddy (University of Florida)
        Please DO NOT contact mentors directly by email. Instead, please email ml4-sci@cern.ch with Project Title and include your CV and test results. The relevant mentors will then get in touch with you.

        Links
        Paper 1
        Paper 2
        Paper 3
        Corresponding Project
        DEEPLENSE
        Participating Organizations
        Alabama
        MIT
        Florida



    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/machine-learning-for-science-(ml4sci)/
    idea_list_url: https://ml4sci.org/


  - organization_id: 90
    organization_name: MariaDB
    no_of_ideas: 12
    ideas_content: |
     
      MariaDB Server
      MDEV-28395 LOAD DATA plugins
      Full-time project 350h
      LOAD DATA INFILE can flexibly load data into a table from CSV-like files accessible by the mariadbdb process. LOAD XML INFILE can do it for XML files. LOAD DATA LOCAL INFILE and LOAD XML LOCAL INFILE can do it with files accessible by the client, but not by the server. But there are requests to suport loading more file formats and from other locations, for example, from S3.
      This project is to implement support for LOAD plugins and refactor the current LOAD code accordingly. There are two kind of plugins — data parser plugin (CSV-like and XML) and transfer plugin (file and LOCAL). Implementing new plugins is not in the scope of this task, this task is mainly about moving existing code around, creating a possibility for new plugins (like JSON or S3).
      Skills needed: C++, bison
      Mentors: Sergei Golubchik

      ~~~~~~~~~~


      MDEV-36100 Generate vector embeddings automatically on INSERT
      Full-time project 350h
      Implement a syntax and a plugin API that the server will use to generate embeddings for documents that the user stores in the database. This should allow to simplify significantly the vector pipeline. mariadbd will not generate embeddings internally, it will invoke a plugin to do that.
      Skills needed: C++
      Mentors: Sergei Golubchik

      ~~~~~~~~~~
      MDEV-36107 expressions in mysqltest
      Part-time project 175h
      extend mysqltest language to support
      standard arithmetic +, -, *, /, %
      comparisons ==, !=, <, <=, >, >=
      boolean &&, ||, may be ? :
      if possible: string repetition, perl-style x (to replace SELECT REPEAT() in test files)
      This should work in commands let, if, while
      Skills needed: C++
      Mentors: Sergei Golubchik

      ~~~~~~~~~~
      MDEV-36108 variable substitutions in mysqltest
      Part-time project 175h
      extend mysqltest language to support bash-like substitutions:
      ${var}
      ${parameter:offset:length}
      ${#parameter}
      ${parameter/pattern/string/flags}
      may be ${parameterˆ}, ${parameterˆˆ}, ${parameter,}, ${parameter}
      may be ${parameter@function} with functions like u, U, Q, etc
      recursive expansion:
      ${${var}}
      Skills needed: C++
      Mentors: Sergei Golubchik

      ~~~~~~~~~~
      MDEV-18827 Create utility to parse frm files and print their DDL
      Full-time project - potential part-time (175 - 350h, depending on scope)
      FRM files are what MariaDB uses to store metadata about tables. These files can be used to generate DDL statements (CREATE TABLE ...). We are lacking a utility to parse these files which could in turn make DBAs lives easier. The task of this project is to have this utility implemented, making use of MariaDB's FRM parsing logic. You may have to carry out some refactoring to extract the parsing code into a reusable library, once for MariaDB Server, once for the FRM parsing tool.
      Skills needed: C/C++, understanding libraries and APIs.
      Mentors: Vicențiu Ciorbaru / Sergei Golubchik

      ~~~~~~~~~~
      MDEV-9345 Replication to enable filtering on master
      Part-time project 175h
      The current methods of filtering replication events are limited to either 1) at binlog-write time, which can break point-in-time recovery because some committed transactions will be missing from the binary log, or 2) on the replica, which forces all events on the primary server to always be sent to the replica, which can be a security concern and is also not efficient. This task aims to eliminate these limitations by adding in another point at which replication filtering occurs: on the binlog dump threads. This would allow users to both maintain a consistent binary log, and minimize network traffic by guarding events which are never intended for replication.
      Skills needed: C++
      Mentors: Brandon Nesterenko

      ~~~~~~~~~~
      Buildbot build statistics dashboard
      Part-time project 175h TODO - A more ample description will be created.
      Skills needed:
      Mentors: Vlad Radu

      ~~~~~~~~~~


      MCOL-4889 Manual extent vacuuming
      Full-time project 350h

      Here extent is a unit of group of columnar values and partition is a group of extents that stores all column values for a specific portion of a table. MCS has a notion of an empty value for columnar segment/token files and dictionaries. Empty values are marked with a bit in the special 1 byte auxiliary column that is created for every table. When DELETE removes records from a table the records are marked with empty bit in the auxiliary column. The deleted records become a wasted disk space. The goal of the project is to reclaim the wasted disk space either re-creating the whole partition or moving partition values.

      Skills needed: modern C++
      Mentors: Roman Nozdrin

      ~~~~~~~~~~

      MCOL-5142 Support for recursive CTE
      Full-time project 350h

      MariaDB Columnstore lacks recursive CTE handling, so as of now Columnstore hands over the processing back to MariaDB Server if a query contains recursive CTE.

      Here is the info about the feature: https://mariadb.com/kb/en/recursive-common-table-expressions-overview/

      Skills needed: modern C++
      Mentors: Leonid Fedorov

      ~~~~~~~~~~

      MCOL-5598 Support for EXCEPT and INTERSECT SQL expressions
      Full-time project 350h

      MariaDB Columnstore lacks UNION EXCEPT INTERSECT handling, so as of now Columnstore hands over the processing back to MariaDB Server if a query contains UNION EXCEPT or UNION INTERCEPT

      Here is the info about the feature:
      https://mariadb.com/kb/en/except/
      https://mariadb.com/kb/en/intersect/

      Skills needed: modern C++
      Mentors: Alexey Antipovsky

      ~~~~~~~~~~

      MCOL-XXX Bloom-filters for data scanning
      Full-time project 350h

      MariaDB Columnstore lacks indexes so it reads a lot of extra data from disk. This project introduces Bloom-filters to reduce data read from disk during the most IO heavy operation that is scanning.

      Skills needed: modern C++
      Mentors: Roman Nozdrin

      ~~~~~~~~~~

      MCOL-5758 Reduce the computations in JOINS by simpler Bloom-filter-based pre-joins
      Full-time project 350h

      Joins are very heavy algorithms, both in computation and/or in memory use. They need to hold a substantial amount of data in memory and perform hashing and other operations on that data. Joins can overflow memory limits and keeping balance between memory use and performance is tricky. Thus we have to filter information thaat is going into joins as much as possible. Columnstore already does great work in that regard, pushing WHERE filters before joins. This particular task is also concerned with that, adding Bloom filters' operations that approximate JOIN results and perform a secondary read to feed into joins data that is highly likely will be used in a join.

      Skills needed: modern C++
      Mentors: Sergey Zefirov
            
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/mariadb/
    idea_list_url: https://mariadb.com/kb/en/google-summer-of-code-2025/
  

  - organization_id: 91
    organization_name: Meshery
    no_of_ideas: 8
    ideas_content: |
      1. Multi-player Collaboration: Resilient Websockets and GraphQL Subscriptions
      Description:
      Meshery's current implementation of websockets and GraphQL subscriptions is in need of refactoring for increased reliability and resiliency. This client and server-side refactoring includes use of webworkers and separation of concerns for the client-side, and the use of a message broker for the server-side. The project has implications on Meshery's implementation of multi-player collaboration functionality.
      Expected outcomes:
      Resilient websockets and GraphQL subscriptions for Meshery, enabling multi-player collaboration functionality.
      Recommended Skills: Golang, Kubernetes, Azure, well-written and well-spoken English
      Expected project size: large (~175 hour projects)
      Mentors: Lee Calcote, Aabid Sofi
      Issue: https://github.com/meshery/meshery/issues/13554

      ~~~~~~~~~~
      2. Support for Azure in Meshery
      Description:
      Enhance Meshery's existing orchestration capabilities to include support for Azure. The Azure Service Operator(ASO) provides a wide variety of Azure Resources via Kubernetes custom resources as first-class Meshery Models. This involves enabling Meshery to manage and orchestrate Azure services and their resources, similar to how it handles other Kubernetes resources. The project will also include generating support for Azure services and their resources in Meshery's Model generator.
      Expected outcomes:
      Meshery will be able to orchestrate and manage all Azure services supported by ASO. This includes the ability to discover, configure, deploy, and operate the lifecycle of Azure services through Meshery. The Meshery Model generator will be updated to automatically generate models for Azure services, simplifying their integration and management within Meshery. This will be an officially supported feature of Meshery.
      Recommended Skills: Golang, Kubernetes, Azure, well-written and well-spoken English
      Expected project size: large (~175 hour projects)
      Mentors: Lee Calcote, Mia Grenell
      Issue: https://github.com/meshery/meshery/issues/11244

      ~~~~~~~~~~
      3. Kubectl Plugin for MeshSync Snapshot
      Description:
      Develop a kubectl plugin via krew that allows users to temporarily deploy MeshSync, capture the state of their cluster, and then import the snapshot into Meshery for offline infrastructure management. The plugin will serve as a lightweight alternative to a full Meshery deployment while still enabling Meshery Server to understand the state and configuration of Kubernetes cluster, simplyfying common networking challenges between the cluster and Meshery Server.
      Expected outcomes:
      - A functional kubectl plugin that facilitates capturing a MeshSync snapshot of Kubernetes cluster resources.
      - Improved networking efficiency, reducing the complexity of connecting Kubernetes clusters with Meshery Server.
      - Support for selective snapshot capture, including single resources, namespaces, or entire cluster visualizations.
      - Read-only access mode to generate snapshots without requiring full Meshery deployment.
      Recommended Skills: Golang, Krew, Kubernetes, well-written and well-spoken English.
      Expected project size: large (~175 hour projects)
      Mentors: Lee Calcote, James Horton
      Issue: https://github.com/meshery/meshery/issues/11869
      
      ~~~~~~~~~~
      4. Distributed client-side inference (policy evaluation) with WebAssembly (WASM) and OPA in Meshery
      Description:
      Meshery's highly dynamic infrastructure configuration capabilities require real-time evaluation of complex policies. Policies of various types and with a high number of parameters need to be evaluted client-side. With policies expressed in Rego, the goal of this project is to incorporate use of the https://github.com/open-policy-agent/golang-opa-wasm project into Meshery UI, so that a powerful, real-time user experience is possible.
      Expected outcomes:
      The goal of this project is to enhance Meshery's infrastructure configuration capabilities by incorporating real-time policy evaluation using the golang-opa-wasm project. This project will integrate the capabilities of golang-opa-wasm into the Meshery UI, enabling users to experience the existing, powerful, server-side policy evaluation client-side.
      Recommended Skills: WebAssembly, Golang, Open Policy Agent, well-written and well-spoken English.
      Expected project size: large (~175 hour projects)
      Mentors: Lee Calcote, James Horton
      Issue: https://github.com/meshery/meshery/issues/13555
      
      ~~~~~~~~~~
      5. Meshery Model Support for kro ResourceGraphDefinitions (RGDs)
      Description:
      Enhance Meshery's existing orchestration capabilities to include support for kro ResourceGraphDefinitions (RGDs) as first-class Meshery Models. This involves enabling Meshery to manage and orchestrate RGDs, similar to how it handles other Kubernetes resources. The project will also include generating support for ResourceGraphDefinition in Meshery's Model generator.
      Expected outcomes:
      Meshery will be able to orchestrate and manage kro RGDs. This includes the ability to deploy, configure, and manage the lifecycle of RGDs through Meshery. The Meshery Model generator will be updated to automatically generate models for kro RGDs, simplifying their integration and management within Meshery. This will be an officially supported feature of Meshery.
      Recommended Skills: Golang, Cuelang, Well-written and well-spoken English, Kubernetes, DevOps
      Expected project size: large (~350 hour projects)
      Mentors: Lee Calcote, Mia Grenell
      Issue: https://github.com/meshery/meshery/issues/13520
      
      ~~~~~~~~~~
      6. Hands-on tutorials using Meshery Playground
      Description:
      Learning paths with hands-on labs are a crucial resource for DevOps engineers and cloud-native practitioners. The Meshery Playground provides a live cluster environment, making it an ideal platform for learning every kind of cloud and cloud native technology. Meshery Docs is in need of comprehensive tutorials and scenarios covering common infrastructure management use cases. Mission is to create and publish a series of hands-on tutorials using Meshery Playground. Each tutorial will include step-by-step guides, live demonstrations, and interactive labs using the Playground allowing learners to apply their knowledge directly without the hassle of any configuration.These tutorials will be reviewed by various project maintainers and then published in guides/tutorials.
      Expected outcomes:
      - 10+ new tutorials published in Meshery Docs.
      - Each tutorial should be interactive, guiding users through infrastructure.
      - Tutorials should vary in complexity, catering to beginners and advanced learners.
      Recommended Skills: written English, Markdown, Kubernetes, DevOps, and hands-on experience with cloud-native tools.
      Expected project size: large (~350 hour projects)
      Mentors: Lee Calcote, James Horton
      Issue: https://github.com/meshery/meshery/issues/13521
      
      
      ~~~~~~~~~~
      7. Kanvas Snapshot Kubectl Plugin
      Description:
      Kubernetes manifests, especially collections of them, can be complex. This plugin will bridge the gap between Kubernetes cluster and workflow configurations and their visual representation in Kanvas Snapshots. The plugin will allow users to generate a visual snapshot of the combination of multiple Kubernetes manifest files, each containing one or more Kubernetes resources. Users will be able to receive these snapshots either via email or as a URL displayed directly in the terminal.
      Expected outcomes:
      - A functional kubectl plugin that integrates with Meshery to generate Kanvas Snapshots from Kubernetes manifests.
      - Support for both synchronous and asynchronous delivery, allowing users to receive snapshots via email or directly in the terminal.
      Recommended Skills: Golang, Krew, Kubernetes, well-written and well-spoken English.
      Expected project size: large (~175 hour projects)
      Mentors: Lee Calcote, James Horton
      Issue: https://github.com/meshery/meshery/issues/12036
      
      ~~~~~~~~~~
      8. Expanding end-to-end test coverage in Meshery using Playwright
      Description:
      Meshery integrates with many other CNCF projects and technologies. Sustaining those integrations is only possible through automation. To automate functional integration and end-to-end testing, Meshery now uses Playwright as one of the tools for browser testing. End-to-end tests run with each pull request to ensure that changes do not break existing functionality. Expanding the coverage of E2E tests is crucial to improving the reliability of Meshery’s UI and workflows. This project focuses on writing Playwright-based tests for more Meshery components, ensuring robust test coverage across the platform.
      Expected outcomes:
      Development of comprehensive E2E test cases for additional Meshery components using Playwright.
      Recommended Skills: JavaScript, Playwright, GitHub Workflows, familiarity with React or Nextjs would be helpful, CI/CD.
      Expected project size: medium (~175 hour projects)
      Mentors: Lee Calcote, Aabid Sofi
      Issue: https://github.com/meshery/meshery/issues/13514
      
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/meshery/
    idea_list_url: https://meshery.io/programs/gsoc/2025

  - organization_id: 92
    organization_name: MetaBrainz Foundation Inc
    no_of_ideas: 18
    ideas_content: |

        Use Solr search server
        Proposed Mentors: monkey, lucifer

        Languages/skills: Solr search, Typescript

        Estimated Project Length: 350 hours

        Difficulty: hard

        Expected outcomes: A functional multi-entity search server with the same features as the existing search functionality

        Other MetaBrainz projects use Solr search server, while BookBrainz was created using ElasticSearch and has not evolved since. This creates some extra overhead by running two separate search infrastructures and prevents us from optimizing resources.

        For this project, you would entirely replace the search server infrastructure and adapt the existing search to work with Solr. This makes for a project relatively isolated from the rest of the website, the only surface of contact being this file handling most of the indexing and ElasticSearch-specific logic, and this file which adds the website routes that allows users and the website to interact with the search server.

        One relevant point of detail is that we want to maintain multi-entity search (search for authors, works, edition, etc all in one go) compared to the MusicBrainz search for example which requires selecting an entity type before performing a search. This would need to be investigated.

        
        ~~~~~~~~~~
        Set up BookBrainz for internationalization
        Proposed Mentors: monkey

        Languages/skills: Javascript/Typescript

        Estimated Project Length: 175 hours

        Difficulty: easy

        Expected outcomes: Full translation project and workflow set up, with as much as possible of the website text captured for translation

        BookBrainz is currently only in english language, which stops us from reaching a wider audience.

        Thankfully, the MusicBrainz team has had a long experience with internationalization and recently moved to using Weblate.

        You can see this translation server here: https://translations.metabrainz.org/ and more general documentation here: https://musicbrainz.org/doc/Internationalization

        For this project, you would help set up a new translation project on the same Weblate server, and integrate Weblate into BookBrainz.

        You will need to evaluate the best options for how to implement this in BookBrainz.

        Promising frameworks with React support include (but not limited to) Fluent and i18next

        ~~~~~~~~~~

        New Calibre plugin
        Proposed Mentors: monkey

        Languages/skills: python

        Estimated Project Length: 175/350 hours depending on proposed features

        Difficulty: medium

        Expected outcomes: An installable Calibre plugin with basic features, allowing searching for editions by name and author, and improving metadata of e-book files

        Calibre is an established open source e-book library manager.

        There was once a BookBrainz plugin for Calibre (CaliBBre) which has since been abandoned.

        This project would see the revival of this plugin, rewritten from scratch considering the code is 8-9 years old.

        See plugin development documentation here: https://manual.calibre-ebook.com/creating_plugins.html

        Some experience using Calibre and e-books is required for this project.

        Optional goals: sync collections between Calibre and BookBrainz

        ~~~~~~~~~~


        Importing listening history files
        Proposed mentors: Lucifer/Mayhem
        Languages/skills: Python/Flask
        Estimated Project Length: 350 hours
        Difficulty: Easy
        Expected Outcomes: An API endpoint to import listening history from files
        Short Description: Add the ability to import your listening history from ListenBrainz exports, Spotify and Apple Music streaming history, other CSV file formats.

        Full Description: There is currently no way to import your listening history into ListenBrainz from a set of files. This project would see you create a modular back-end system in python that allows importing history files of specific expected formats. This would take the shape of an API endpoint, with some basic options to limit the start and/or end date of imports. Some basic validation for format and structure should be expected

        Expected formats: ListenBrainz export files (JSONL), Spotify extended streaming history (JSON), Apple Music Play Activity (CSV) LB-1744, LastFM export (CSV).

        See associated ticket LB-1746 Each of those format should be a patch describing the data structure and how the data needs to be transformed, allowing future collaborators to easily implement new format patches.

        ~~~~~~~~~~
        Suspense in React
        Proposed mentors: ansh/monkey
        Languages/skills: React/Typescript
        Estimated Project Length: 175 hours
        Difficulty: Easy
        Expected Outcomes: Stream selected components to the front-end to improve page load times.
        Short Description: Add component streaming in the ListenBrainz single-page React app using the Suspense API to improve page load times
        Full Description:

        This project would see you implement the recent Suspense API in React to stream slow-to-acquire data to the front-end, allowing to delay data loading for certain components and improve page load times.

        To achieve this, you'll have to upgrade to React Router v7 and utilize the new streaming support in loaders to incrementally load data, ensuring a faster time-to-interactive.

        Working with us, you’ll identify key pages and components that benefit from deferred loading, adapting our React-Query and React-Router based data strategy. You’ll also refine loading states and transitions to enhance the user experience, making ListenBrainz more responsive, especially for users on slower networks. You’ll also focus on enhancing the user experience by designing effective loading states, ensuring smooth transitions between streamed content, and minimizing disruptions caused by data delays

        ~~~~~~~~~~
        New statistics graphs
        Proposed mentors: Lucifer/Ansh
        Languages/skills: Spark/Python/Nivo (D3 graph library)
        Estimated Project Length: Medium
        Difficulty: Medium
        Expected Outcomes: Cool new graphs to show on users' stats page
        Short Description: You will be working on creating new visualizations of user statistics
        Full Description:

        This project aims to develop new types of graphs that will enable users to better understand their music consumption habits. By leveraging Spark for data processing, you will calculate the necessary data for each graph type. Your work will involve designing and implementing visualizations that are not only informative but also visually appealing, using the Nivo library, which is built on D3.js.

        The tickets we have in mind for this project are: LB-760, LB-343, LB-1736, LB-1737, LB-1159, LB-1588.

        ~~~~~~~~~~
        Notifications
        Proposed mentors: mayhem
        Languages/skills: Python & PostgreSQL
        Estimated Project Length: Medium
        Difficulty: Easy/Medium
        Expected Outcomes: A functional notifications system with relevant API endpoints but no UI
        Short Description: This project will add a notification system so users can be kept up to date with events, reactions, new playlists and features, etc.
        Full Description: The full specification of this project is here: https://docs.google.com/document/d/1jK2OreDzYq_EtZtaUiBSpmQolra2jJgrlUY7o1K0UYc/edit?usp=sharing

        ~~~~~~~~~~
        Integrate music streaming from Subsonic
        Proposed mentors: mayhem/lucifer
        Languages/skills: Python/Flask
        Estimated Project Length: Can be 175 or 350 hours depending on the integration/service chosen.
        Difficulty: Easy
        Expected Outcomes: A new music service integration for users to play recordings on ListenBrainz.
        Short Description: Add support for playing music in BrainzPlayer from a Subsonic API
        Full Description:

        LB has a number of music discovery features that use BrainzPlayer to facilitate track playback. BrainzPlayer (BP) is a custom React component in LB that uses multiple data sources to search and play a track. As of now, it supports Spotify, Youtube and Soundcloud as a music service. LB would like to be able to stream music from a private music collection using web apps like Navidrome, Funkwhale and other apps that implement the Subsonic API. The following major tasks need to be completed: 1) Add subsonic API player as a service to our music services backend; this will require some schema changes/extensions in order to have user specify the URL of their service as part of the music service configuration. 2) Add the react based front-end UI to that allows users to setup their own Subsonic API instance as a service. 3) Add support to BrainzPlayer for logging into the subsonic API service and playing music from it.

        ~~~~~~~~~~
        Integrate Deezer music streaming service for recording listens and playing music
        Proposed mentors: lucifer, ansh
        Languages/skills: Python/Flask, Typescript/React
        Estimated Project Length: Can be 175 or 350 hours depending on the integration/service chosen.
        Difficulty: Easy
        Expected Outcomes: A new music service integration for users to play and record listens on ListenBrainz.
        Short Description: Add support for playing music in BrainzPlayer from the Deezer streaming service.
        Full Description:

        ListenBrainz has a number of music discovery features that use BrainzPlayer to facilitate track playback. BrainzPlayer (BP) is a custom React component in LB that uses multiple data sources to search and play a track. As of now, it supports Spotify, Youtube and Soundcloud as a music service. LB also supports linking a Spotify account to record listening history. We have looked into some other services and found that Deezer provides the music playback and recording listening history capability. Integrating these services into LB would make for a good SoC project.

        ~~~~~~~~~~
        Integrate Internet Archive in BrainzPlayer
        Proposed mentors: lucifer, monkey
        Languages/skills: Python/Flask, Typescript/React, Postgres
        Estimated Project Length: 350 hours
        Difficulty: medium
        Excepted Outcomes: A deployable component to play internet archive music
        Short Description: Add support for playing music in BrainzPlayer from the Internet Archive

        Full Description:

        ListenBrainz has a number of music discovery features that use BrainzPlayer to facilitate track playback. BrainzPlayer (BP) is a custom React component in LB that uses multiple data sources to search and play a track. The 78 RPMs and Cylinder Recordings is a collection of digitized recordings from physical releases of the early 20th century. Each recording comes with audio streaming, and metadata web service. It can be used to retrieve metadata automatically and to embed a player in ListenBrainz using BrainzPlayer. A lot of similar music collections are hosted by the Internet Archive which can be made available for playing on ListenBrainz.

        ~~~~~~~~~~
        Onboarding Revamp in ListenBrainz Android
        Proposed mentors: jasje, akshaaatt

        Languages/skills: Kotlin, Compose, Android, MVVM, Figma
        Estimated Project Length: 175 hours
        Difficulty: Medium
        Expected outcomes: An onboarding flow that integrates our login, permissions and a new Listen submission onboarding flow.
        Short Description: Re-work the currently existing on-boarding flow.
        Full Description:

        ListenBrainz Android currently has an onboarding flow that appears first time a user installs and opens the app. This flow is critical for user retention and reasoning for permissions we use since our aim is to stay as transparent as possible. Currently there are a few issues and lack of features that plague the current onboarding:

        It asks asks for permissions abruptly and has no fallback for cases where permission may be rejected once (showing rationale dialog) or twice
        It has loop holes to exit unintentionally, breaking the meaning of our flow in the first place.
        It lacks certain screens essential to our Listen Submission onboarding where:
        We ask for notification access permission.
        User may select the apps they want listens to be submitted for.
        We would like to ask user to disable background battery optimizations for seamless Listen Submission.
        Show implications of not enabling the service.
        Improve integration of currently existing login flow which is abruptly asked as well, without alerting the user of implications by not signing in.
        Relies on external onboarding library which is not customizable to our needs.
        Above changes would require us to refactor some options inside settings which are directly linked to the problem we are trying to solve.

        Another improvement we want is to alert user of any new app update which is always shown once per update on app startup which will be fetched from either Play store or Github (for F-droid downloads).

        This project should aim to enhance / re-work the onboarding flow by removing the currently existing library and build an extensible implementation which solves the above problems. Proposals tackling all these problems in detail would be appreciated.

        ~~~~~~~~~~
        Integrate Listening now and BrainzPlayer in ListenBrainz Android
        Proposed mentors: jasje, akshaaatt

        Languages/skills: Kotlin, Compose, Android, MVVM, Figma
        Estimated Project Length: 175 hours
        Difficulty: Hard
        Expected outcomes: Seamless integration between BrainzPlayer and Listening now to show currently played song.
        Short Description: Fix bugs related to BrainzPlayer and integrate ListenBrainz's Listening now with BrainzPlayer's currently playing song.
        Full Description:

        ListenBrainz Android currently uses a Material Scaffold to show mini-player view of BrainzPlayer's current state. ListenBrainz offers an REST API and Socket API which (combined) reports the current song that is being listened by the user at a given moment across their devices. Currently Listening now is missing from the Android project despite it being present in earlier iterations (API endpoint integration exists) and it is intended to add the feature back in a better way.

        We visualize a system where:

        If the user is not using BrainzPlayer, we would like to show Listening Now to the user and not deal with BrainzPlayer at all.
        If the user is using BrainzPlayer however, we would like to override the Listening Now provided by server to show state of BrainzPlayer.
        If Listening Now is active, we would like to show playlists that are auto played by Remote Playback integrations, i.e., via Spotify or Youtube in app.
        If BrainzPlayer is active, existing view should suffice.
        Objectives of the this project:

        Create and integrate the system mentioned above.
        Fix bugs related to BrainzPlayer (Exoplayer) critical to the UX of this feature.
        Revamp front layer of the Scaffold.
        Implement automatic playback through remote playback integrations (Spotify SDK and Youtube music API) and show the queue in front layer of scaffold.
        Accomplishing the above objectives with tests would be the ultimate goal of this project.



        ~~~~~~~~~~
        Artist, Album, User Pages in ListenBrainz iOS App for all users
        Proposed mentors: akshaaatt
        Languages/skills: Swift, SwiftUI, Alamofire, iOS Development
        Estimated Project Length: 175 hours
        Difficulty: Medium
        Expected outcomes: A finished app feature that allows users to view detailed album, artist, and user pages within the app.
        Short Description: Enhance the mobile app with detailed album, artist, and user pages.
        Full Description:

        This project aims to significantly enhance the user experience of the ListenBrainz mobile application by introducing comprehensive album, artist, and user pages. This initiative will bridge the gap between the app and the ListenBrainz website's extensive database, offering a richer, more detailed exploration of music data directly within the app.

        The primary goal is to enable users to delve into detailed pages for albums, artists, and other users within the app. These pages will provide in-depth information, such as album track lists, artist discographies, similar artists, and detailed user profiles including their music preferences, listening habits, and social connections.

        Key features of this project include:

        Album Pages: Display detailed album information including track lists, release dates, genres, and artist links. Integration with music streaming services to listen to tracks directly from the app may also be explored.
        Artist Pages: Offer comprehensive artist profiles featuring a biography, discography, related artists, and upcoming events. This will enable users to discover new music and learn more about their favorite artists.
        User Pages: Enhance user profiles to include detailed listening statistics, favorite tracks, albums, and artists. Implement a feature for users to follow others and explore music communities within the app.
        To ensure a seamless and intuitive user experience, the project will require close adherence to the UI/UX design guidelines provided by the ListenBrainz design team. This includes creating responsive layouts that adapt to various screen sizes and implementing a modern, user-friendly interface design using SwiftUI for iOS.

        By completing this project, the ListenBrainz app will become a more comprehensive platform for music discovery and community engagement, offering detailed insights into albums, artists, and user profiles, all within a beautifully designed mobile application interface.

        
        ~~~~~~~~~~
        ListenBrainz iOS App - Road to Production
        Proposed mentors: akshaaatt

        Languages/skills: Swift, SwiftUI, Alamofire, iOS Development
        Estimated Project Length: 175 hours
        Difficulty: Easy
        Expected Outcomes: Match user interface and functionality as per figmas and the Android app, address bugs and ensure app stability.
        Short Description: To launch the iOS mobile app on the app store, we need to get relevant approvals. The design should be consistent, the app should be stable and all the app offerings should work as desired.
        Full Description:

        The developer should make sure that the Feed, Profile/Dashboard, Explore and Settings are all consistent with the Android app/relevant Figma design.

        The aim should be:

        A fully functional ListenBrainz app for iOS that matches the user interface and functionality outlined in the project's design documents. Figma
        A stable and reliable app experience, with all features working as intended and any identified bugs resolved.
        By completing this project, the ListenBrainz app will offer a comprehensive user experience, mirroring the website's and Android app's functionality.


        ~~~~~~~~~~
        Modernize search storage format for the MusicBrainz database
        Proposed mentor: lucifer
        Proposed co-mentors: bitmap, reosarevok, yvanzo
        Languages/skills: Solr, Python, Java
        Forum for discussion
        Estimated Project Length: 350 hours
        Difficulty: medium


        




        The MusicBrainz (MB) database has a Solr search engine used for both website search and search API. It stores the data in search fields. Two output formats are supported: MB XML (returned directly to API clients) and MB JSON (returned both to API clients and to the website server). The MB JSON format is automatically generated from the MB XML format. A RELAX NG schema is used to generate bindings and check the MB XML output. However, storing this MB XML format additionally to the search fields is redundant and inefficient (in disk usage and indexing time). Actually the current implementation has not been deeply revisited since the early versions of Solr.

        It would be helpful to modernize the format used to store data for search in Solr. Minimum goals:

        Upgrade the Solr schema version from 1.5 to 1.7
        Complete fields (in configsets and indexer) to store all the data to be returned
        Create two response writers to return data from fields to MB XML/MB JSON formats (with automated validation tests)
        Many extra goals can be added by the candidate if wanted and if time permits. See tickets.

        References:

        MusicBrainz search architecture
        MusicBrainz Solr response writer
        MusicBrainz Solr configsets
        MusicBrainz RELAX NG schema
        Solr schema 1.6 release notes
        Solr schema 1.7 release notes
        Tickets for MusicBrainz search
        
        ~~~~~~~~~~
        Extend the mail service with template API
        Proposed mentors: bitmap
        Languages/skills: Rust
        Forum for discussion
        Estimated Project Length: 350 hours
        Difficulty: medium

        Since last summer, a new mail rendering service is gradually being used by MusicBrainz to replace Template Toolkit which has had its day. The new service is written in Rust and is based on MJML markup language (for proper rendering in mail clients) and MessageFormat 1 (for internationalization). However, the mail templates currently have to be written in the same repository as the mail service. It makes adding a new template (since both the project and the mail service have to be updated, released, and deployed) and sharing translation resources more difficult. While the current implementation is suitable to work with MusicBrainz, it has always been in sight to make the mail service available to the other MetaBrainz projects afterwards.

        Allowing to load templates through API would be a great extension to the mail service, making it possible to maintain the templates in the repositories of their respective projects and to load/update these on demand without requiring to redeploy the mail service.

        Many extra goals can be added by the candidate if wanted and if time permits. There are several mail templates in different projects to be adapted or reworked. There are also some cron jobs to send daily mails that would greatly benefit a full rewrite in Rust.

        References:

        Last summer project
        MusicBrainz mail service

        ~~~~~~~~~~
        Implement a daemon that corrects out-of-sync cover art and event art metadata on archive.org
        Proposed mentor: bitmap
        Full Description: reosarevok, yvanzo
        Full Description: Python, SQL
        Forum for discussion
        Full Description: 175 hours
        Full Description: medium

        The Cover Art Archive and Event Art Archive store both metadata about the entity in question and metadata about the available images.

        Historically there have been service issues that have introduced inconsistencies in these metadata files:

        Outdated entity metadata (incorrect titles, artists, dates, etc.)
        Outdated image metadata (types, comments, thumbnails, etc.)
        Images that exist on archive.org but are missing from index.json (or the MusicBrainz database)
        Images are are listed in index.json (or the MusicBrainz database) but are missing from archive.org
        Malformed JSON (strings being used instead of integers, encoding issues, etc.)
        Many such issues have been described as part of ROpdebee's excellent auditing work in IMG-129.

        Recently a new artwork-indexer service has been deployed which manages the metadata in question. The task of this project would be to extend the artwork-indexer to monitor entities in the MusicBrainz database having images, and automatically check and repair the types of issues listed above.

        Ideally we can use the auditing results in jira:IMG-129 to generate queued tasks that prioritize checking the entities contained in the audit.

        Note that some initial work on this idea was started by bitmap.


        ~~~~~~~~~~


        Matrix room archiver
        Proposed mentor: julian45 (possibly zas, lucifer?)
        Languages/skills: TBD languages/Matrix/Docker/Prometheus
        Estimated project length: 350 hours
        Difficulty: Medium

        Last summer, we migrated from IRC to Matrix for communication. We have BrainzBot (a fork of BotBotMe), an IRC-based bot that reads all messages and logs them to a Postgres database. These logs are displayed on chatlogs.metabrainz.org. Although we have a functioning IRC-Matrix bridge so that BrainzBot's chatlogging still works, BrainzBot is unmaintained and uses dependencies with known vulnerabilities. Due to this and our focus on Matrix as our communications platform of choice, we would quite prefer to move BrainzBot's functions to a more modern bot.

        The target solution should be Matrix homeserver-agnostic (i.e., not necessarily require reading out of a specific homeserver implementation's database), be able to run in a Docker container, and expose a metrics endpoint for monitoring/alerting with Prometheus and Grafana (though Sentry would be a nice bonus). In addition, there are a few commands (e.g., macros for recalling specific reaction images, giving kudos to another user) that should be accommodated by the new bot.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/metabrainz-foundation-inc/
    idea_list_url: https://wiki.musicbrainz.org/Development/Summer_of_Code/2025

  - organization_id: 93
    organization_name: Micro Electronics Research Lab - UITU
    no_of_ideas: 5
    ideas_content: |
      
      Project 01: Integrating TCAM IP into Chipyard via MMIO and RoCC Interfaces
      Difficulty: Hard
      Designation: 350 hours (large)
      Required Skills & Tools: CHISEL, Verilog, C/C++.
      Mentors: Shahzaib Kashif, Dr. Ali Ahmed, Sajjad Ahmed
      Chat Channel: Discord Channel
      Overview:
      This project aims to integrate a Ternary Content Addressable Memory (TCAM) IP with our forked version of Chipyard as both a Memory-Mapped I/O (MMIO) peripheral and a RoCC (Rocket Custom Coprocessor) accelerator. The TCAM is a high-speed search memory that enables efficient lookup operations, making it useful for applications such as networking, security, and database acceleration.
      The key objectives of this project are:
      MMIO Integration: Attach the TCAM IP as an MMIO device within the Chipyard SoC. This will allow the core to communicate with the TCAM using standard memory operations.
      RoCC Integration: Implement the TCAM as a RoCC accelerator, leveraging the Rocket Core’s RoCC interface for direct communication with the processor.
      Software Interface: Develop a user-space software library or API that enables applications to interact with the TCAM seamlessly. This should include functions for writing, reading, and searching within the TCAM.
      Testing & Verification: Validate the correctness and performance of the integration by writing test programs that run on the generated SoC containing (Core + TCAM as MMIO) and (Core + TCAM as RoCC).
      Expected Outcomes:
      A fully integrated TCAM IP with Chipyard, accessible via both MMIO and RoCC.
      A software library that provides an easy-to-use interface for interacting with TCAM.
      Test programs that demonstrate TCAM functionality on the generated SoC.
      Documentation to help future contributors extend or modify the TCAM integration.
      Skills Required:
      Familiarity with RISC-V and Chipyard framework.
      Experience with Chisel/Verilog for hardware design.
      Knowledge of SoC integration, MMIO, and RoCC interfaces.
      Proficiency in C/C++ for writing the software interface.

      ~~~~~~~~~~
      Project 02: A.U.T.O.V.A.R. - Automated UVM Tuning Orchestrated Via AI Reasoning
      Difficulty: Hard
      Designation: 350 hours (large)
      Required Skills & Tools: UVM, SystemVerilog, Python, Machine Learning, NLP, Transformers, Reinforcement Learning, Regression Testing, Hardware Verification.
      Mentors: Dr. Farhan Ahmed Karim
      Chat Channel: Discord Channel
      Overview:
      A.U.T.O.V.A.R. is an AI-powered framework designed to automate the modification of UVM components (drivers, monitors, scoreboards, sequences) based on evolving DUT specifications. By leveraging NLP and ML, the system extracts key parameters from DUT documentation and updates verification environments accordingly. Reinforcement learning ensures that the generated UVM components are validated against regression tests and optimized for coverage. This project aims to minimize manual effort, reduce human error, and accelerate the verification cycle in hardware design.
      Methodology
      DUT Specification Analysis
      Use natural language processing (NLP) and machine learning (ML) to parse DUT specifications (e.g. interface documents, or protocol standards).
      Extract key parameters: signal names, timing requirements, protocol rules, and transaction formats.
      UVM Component Modification
      Train an A.I. model (e.g., a transformer-based architecture) to map DUT changes to UVM component updates:
      Drivers/Monitors: Adjust transaction generation/collection logic based on new signal timing or protocol rules.
      Scoreboards: Update reference models and error-checking algorithms to reflect DUT functionality.
      Sequences: Regenerate test sequences to cover new scenarios or constraints.
      Use reinforcement learning (RL) to validate modified components against regression tests and optimize for coverage.
      Enable real-time feedback loops: Test failures trigger iterative AI refinement of UVM components.
      Expected Outcomes:
      AI-powered parser for DUT specifications using NLP
      Automated UVM component adaptation based on DUT changes
      Integration of reinforcement learning for optimizing verification environments
      Real-time feedback loops for iterative UVM refinement
      Improved verification efficiency and reduced manual workload

      ~~~~~~~~~~
      Project 03: AEGIS - AI-Enhanced Generation of Intelligent Scenarios
      Difficulty: Hard
      Designation: 350 hours (large)
      Required Skills & Tools: UVM, SystemVerilog, Python, Machine Learning, NLP, Reinforcement Learning, Hardware Verification, ASIC/FPGA Design, AXI/PCIe/USB Protocols.
      Mentors: Dr. Farhan Ahmed Karim, Shahzaib Kashif
      Chat Channel: Discord Channel
      Overview
      AEGIS is an AI-driven framework designed to automate the generation of optimized test cases for hardware verification. Using NLP, the system extracts key features from DUT specifications and synthesizes test scenarios targeting corner cases, protocol compliance, and functional coverage. Reinforcement learning helps prioritize high-impact tests to maximize verification efficiency. The generated test cases are integrated into UVM environments with automated sequences, scoreboard checks, and assertions.
      Methodology
      DUT Specification Parsing
      Use NLP to analyze DUT specifications (e.g. protocol standards, or natural-language requirements).
      Extract critical features: interfaces, timing diagrams, protocol rules, and functional modes.
      Test Case Synthesis
      Train an A.I. model to map DUT specifications to test scenarios, including:
      Corner Cases: Stress tests for boundary conditions (e.g., FIFO overflow, clock domain crossings).
      Protocol Compliance: Tests for adherence to standards like AXI, PCIe, or USB.
      Functional Coverage: Scenarios targeting untested logic in the DUT.
      Use reinforcement learning (RL) to prioritize high-impact tests that maximize coverage metrics.
      Integration with Verification Environment
      Generate UVM-compatible test sequences, scoreboard checks, and assertions.
      Expected Outcomes
      AI-powered DUT specification parser using NLP
      Automated test scenario generation covering corner cases, protocol compliance, and functional coverage
      Reinforcement learning-based test prioritization for enhanced coverage
      UVM-compatible test sequences, assertions, and scoreboard integration
      Improved verification speed and reduced manual test generation effort

      ~~~~~~~~~~
      Project 04: AURUM - Automated UVM Reference of Userspec Model
      Difficulty: Hard
      Designation: 350 hours (large)
      Required Skills & Tools: UVM, SystemVerilog, Python, NLP, Machine Learning, Formal Verification, SMT Solvers, Hardware Verification, Behavioral Modeling.
      Mentors: Talha Ahmed
      Chat Channel: Discord Channel
      Overview
      AURUM is an AI-driven framework that automates the generation of high-accuracy golden/reference models from DUT specifications. Using NLP, the system extracts functional requirements, protocols, and constraints to generate executable golden models. AI-based behavioral cloning ensures high-fidelity mapping from specifications to code, while self-validation techniques, including formal verification and adaptive learning, ensure correctness. This approach reduces manual model development efforts, minimizes human error, and accelerates verification cycles.
      Methodology
      Specification Analysis
      NLP Parsing: Extract functional requirements, protocols, and timing constraints from DUT specifications (text documents, or UML diagrams).
      Contextual Understanding: Use A.I. model to infer implicit requirements (e.g., "FIFO depth = 16" implies overflow/underflow conditions).
      Model Generation
      Code Synthesis: Convert parsed specifications into executable golden models.
      Example: Translate "32-bit CRC32 calculator" into a Python function using the IEEE 802.3 polynomial.
      Behavioral Cloning: Train A.I. models on existing golden model-DUT pairs to learn specification-to-code mappings.
      Self-Validation
      Consistency Checks: Use formal methods (e.g., SMT solvers) to verify AI-generated models against specifications.
      Adaptive Learning: Refine models using test failures and coverage feedback from verification environments.
      Expected Outcomes
      AI-powered specification parser to extract DUT functionalities
      Automated synthesis of golden/reference models from specifications
      Behavioral cloning for learning specification-to-code mappings
      Formal verification and self-validation using SMT solvers
      Integration with UVM-based verification environments

      ~~~~~~~~~~
      Project 05: General Test Bench for RISC-V CPUs Using PYUVM
      Difficulty: Medium
      Designation: 350 hours (large)
      Required Skills & Tools: UVM, SystemVerilog, Python, Functional Verification, Hardware Verification, Behavioral Modeling.
      Mentors: Zeeshan Rafique
      Chat Channel: Discord Channel
      Overview
      With the increasing adoption of RISC-V as an open-source Instruction Set Architecture (ISA), there is a growing need for effective and reusable verification methodologies. This project aims to develop a general test bench for RISC-V CPUs using pyuvm, a Python-based Universal Verification Methodology (UVM) framework. The goal is to create a structured, reusable, and automated verification environment that facilitates CPU validation, functional correctness, and compliance testing.
      Benefits to the Community
      Unified Verification Framework : Provides a consistent and reusable test environment across different RISC-V CPU implementations.
      Accessibility: Uses Python and pyuvm, making UVM-based verification more accessible to a broader audience.
      Automation: Supports automated test execution and result analysis, reducing the manual effort in CPU verification.
      Compliance and Debugging: Ensures conformance with the RISC-V specification and aids in debugging CPU designs.
      Methodology
      Test Bench Architecture:
      Modular design with transaction-level modeling.
      Sequence generation for instruction execution.
      Coverage collection and analysis.
      Integration with RISC-V Simulators:
      Support for Verilator and Spike.
      Automated simulation result analysis.
      Test Suite Development:
      Basic functional tests (ALU, control flow, memory access, etc.).
      Compliance tests for RISC-V ISA validation.
      Directed and random instruction sequences for robustness.
      Automation and Reporting:
      Python-based scripting for test execution.
      Logging and result visualization.
      Expected Outcomes
      A generic test bench framework for RISC-V CPUs using pyuvm.
      A set of reusable test cases covering core CPU functionalities.
      Integration with open-source RISC-V simulators (e.g., Verilator, Spike).
      Scripts for automated testing and reporting.
      Documentation on usage and extension.
      Skills Required to standout:
      Familiarity with RISC-V architecture and CPU design.
      Experience with Python-based verification frameworks.
      Knowledge of UVM and hardware simulation tools.
      Basic understanding of Formal verification.
      Understanding of Verilator, Spike, or other RISC-V simulators (preferred).
      Future Enhancements:
      Extend coverage to advanced RISC-V features (e.g., vector extensions, privileged mode testing).
      Integrate with formal verification tools.
      Support multi-core RISC-V CPU verification.
      References:
      PYUVM Documentation
      Cocotb
      RISC-V Specifications
      RISC-V Spike Simulator
      Verilator
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/micro-electronics-research-lab-uitu/
    idea_list_url: https://github.com/merledu/Google-Summer-of-Code/wiki/GSoC'25-Project-Ideas-List

  - organization_id: 94
    organization_name: Mixxx
    no_of_ideas: 9
    ideas_content: |
     
      Adding an AI infrastructure with cross-platform hardware acceleration
      Typical AI applications in the DJ environment (STEM separation, music analysis) require very high computing power. However, as the commercial DJ software DJay Pro demonstrates, it is possible to perform these on modern laptop hardware in real time with high audio quality. This is made possible by the use of the dedicated Neural Processing Unit (NPU) or powerful Graphical Processing Units (GPU). As cross-platform software, Mixxx must be able to do this on:
      macOS (ARM M1/2 with Neural Engine NPU)
      macOS (x64 with GPU only)
      Linux with various NPU and GPU solutions from different manufacturers
      Windows with various NPU and GPU solutions from different manufacturers
      Today, there is only one AI framework that supports full hardware acceleration across all these platforms, which is ONNX Runtime (onnxruntime.ai). This project is about the integration of ONNX Runtime with ExecutionProviders for CPU (all operating systems), as well as at least one NPU or GPU acceleration solution into Mixxx. This project explicitly includes contributions to third-party projects, in particular to the package managers VCPKG and the Linux distribution Debian/Ubuntu, which Mixxx uses to integrate dependencies. A further aspect to handle is, that these libraries, as well as, the AI models itself are significiantly larger than the current dependencies that come with Mixxx. This requires the development of suitable solutions for the continuous code integration (CI) and for the distribution to the end users.
      Expected Outcome: ONNX Runtime with ExecutionProviders for CPU (all operating systems), as well as at least one NPU or GPU acceleration solution builds within the Mixxx environment. All changes on third-party code is contributed upstream to the particuar projects.
      Skills: Knowledge of CMake, C++. Basic experience with contributing packages to package managers/Linux distributions.
      Possible Mentor: Jörg
      Difficulty: Medium
      Size: 350 h

      ~~~~~~~~~~
      Converting Demucs v4 (Hybrid Transformer) AI model to ONNX format
      With Demucs v4 https://github.com/adefossez/demucs, there is a high quality stem separation model available as OpenSource. But, this is a PyTorch model that cannot be used in a C++ project with support for any kind of acceleration hardware. To allow this, the model needs to be converted to the ONNX format to run in ONNX Runtime. This conversion is not trivial, as the DSP functions required for most audio applications are not equivalent in PyTorch and ONNX. In particular, the short-time Fourier transformations STFT/ISTFT must be remodeled in ONNX to enable the automatic ONNX export of PyTorch. It must be demonstrated that the exported ONNX model produces equivalent results as the original PyTorch model. Therefore a minimal C/C++ command line program supporting MP3 files and embedding ONNX Runtime and the exported model should be created.
      Expected Outcome: The model runs in ONNX Runtime and generates similar results as the original
      Skills: Basic knowledge of C/C++. Sound experience with the creation of AI models - preferably in ONNX.
      Possible Mentor: Jörg
      Difficulty: Difficult
      Size: 175 h

      ~~~~~~~~~~
      AI music analyzer to detect Beats, Downbeats, Phrases
      While Mixxx has a solid analyzer for beat/tempo detection, it is traditionally DSP-based, while the state of the art has moved to a hybrid approach of AI models that include some DSP routines for data pre-processing. Commercial DJ software with such AI music analyzers (DJay Pro, DJ Studio) demonstrates virtually always perfect beat recognition in DJ Medien's tests, even on challenging tracks with a variety of tempo changes. There are OpenSource music analyzer models available, nanmely https://github.com/JoergAtGithub/all-in-one (https://huggingface.co/spaces/taejunkim/all-in-one / https://taejun.kim/music-dissector/0427_justthewayyouare). While a science project with impressive results, this is a PyTorch model that cannot be used in a C++ project with support for any kind of acceleration hardware (it's based on the Demucs HT model above), also here an ONNX model is needed. This project is about building an infrastructure that allows Mixxx developers to optimize the analyzer, check the correctness of the results and generate production-ready ONNX models for the Mixxx DJ software in an automated workflow. In particular, the process when a user reports a track with incorrectly detected beats/downbeats/phrase-length/phrase-type and we need to optimize the model needs to be implemented. The main focus of this process is to ensure that the optimization for one track does not lead to worse recognition for other tracks.
      Skills: Knowledge of C/C++. Sound experience with the creation of AI models - preferably in ONNX.
      Possible Mentor: Daniel Schürmann
      Difficulty: Difficult
      Size: 175 h

      ~~~~~~~~~~
      AI driven STEMS seperator
      Currently creation of stem files files is a manual process in preparation of a DJ set. Many DJs can't effort the time and the storage space for extracting stem files. In this project a temporary stem file shall be created on demand from the Mixxx GUI. Part of the project shall be evaluation of already published algorithms. Integration of one of them into the Mixxx analyzer and handling of the caching an the required GUI for this feature.
      Expected Outcome: Playing and remixing of stem files
      Skills: Good understanding of sound processing, C++
      Possible Mentor: ?
      Difficulty: Medium
      Size: 175 h

      ~~~~~~~~~~
      Using The Harmonix Set to automatically evalute the output of our music analyzers
      The Harmonix Set https://github.com/urinieto/harmonixset repository contains human annotated labels for 912 Western Pop music tracks. This is a great base to benchmark current and future music analyzers in Mixxx. This project is about the automatic execution of the Mixxx Analyzer in a local development environment using all tracks of the Harmonix Set, that are available on the developer's local hard disk and generate a report that visualizes the deviations.
      Expected Outcome: A lightweight tool or script that can be executed out-of-the-box on Windows, macOS and Linux.
      Skills: Experience C++ and a common scripting environment like Python
      Music files: The Mixxx project cannot provide the music files, so the students must have a larger number of the music files listed in The Harmonix Set available themselves.
      Possible Mentor: Jörg
      Difficulty: Easy
      Size: 175 h

      ~~~~~~~~~~
      Streamline Search-possibilities.
      To give users to use their track collection optimal, they need all kinds of search possibilities. At the moment Mixxx has a lineEdit (with memory to recall previous searches) which converts the input to a sql-query. In the library and in the players users can find 'related' tracks, based on similar artist, bpm, key. We have some on-going projects (like SearchCrates and a popup FastSearch) to extend the search-engine and we started a survey to get a picture of our users concrete wishes. This project consists in:
      streamlining all search-possibilities,
      making combinations between the different possibilities concrete
      creating features to help users without database background to create a complex search
      fine tuning and optimizing searches in speed and result
      possibility to create a keywords-table to speedup searches
      Expected Outcome: An integrated search engine that combines all possibilities to search and store the results in a user-friendly way, according to the results of the user survey.
      Skills: Logic in SQL, affinity with music, notions of DJ-ing, C++, lots of enthusiasm.
      Possible Mentor: Evelynne
      Difficulty: Medium
      Size: 175 h (or more depending on the project proposal)

      ~~~~~~~~~~
      Sharp Scratching
      Currently crossfader changes are stretched on audio buffer time to avoid pop sounds. This is too long for some scratching styles. During this project you need to dive into the audio engine code find the code that is responsible for crossfading and make it independent from the audio buffer size.
      https://github.com/mixxxdj/mixxx/issues/8899 https://github.com/mixxxdj/mixxx/issues/11253
      Expected Outcome: Cut type crossfader curve, suitable for scratching.
      Skills: Good understanding of sound processing, C++
      Possible Mentor: Daniel Schürmann
      Difficulty: Medium
      Size: 175 h

      ~~~~~~~~~~
      Auto completion for the Genre track metadata
      Mixxx allows to assign a Genre to a track. This is currently a free text field that allows different spellings for the same Genre like Hiphop, Hip-Hop or Hip Hop. If you use all of these, you will not see all tracks when filtering. This project shall fix it, by auto-complete the Genre when entering, to genres that are already used for other tracks in the library. It shall be also allowed to add additional Genres to a track. This project can be extended by implementing a Tree of Genres for lookup and by auto suggesting a Genre from Discogs or MusicBrainz. https://musicbrainz.org/genres
      Expected Outcome: A new auto completer for the Genre edit box
      Skills: Basic SQLite, Basic C++
      Possible Mentor: Daniel Schürmann
      Difficulty: Easy
      Size: 90 h

      ~~~~~~~~~~
      Resample options
      Mixxx uses a linear resample when scratching. This is blazing fast, but the sound can be improved. Here Mixxx should provide more resample options. This project involves to review the already used resample libraries RubberBand and Soundtouch and compare them with other candidates. The one with the best Sound/CPU load trade of shall be selected. Make sure that it supports on the fly changing of the sample rate without artefacts. This project may also involve to contribute a missing feature to such library.
      https://github.com/mixxxdj/mixxx/issues/9328
      Expected Outcome: Optional replacement of the linear resampler.
      Skills: Good understanding of sound processing, C++
      Possible Mentor: Daniel Schürmann
      Difficulty: Easy
      Size: 175 h
      
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/mixxx/
    idea_list_url: https://github.com/mixxxdj/mixxx/wiki/GSOC-2025-Ideas

  - organization_id: 95
    organization_name: National Resource for Network Biology (NRNB)
    no_of_ideas: 23
    ideas_content: |
      
      Chatbot to query VCell modeling resources
      Difficulty: Medium
      GUI
      LLM
      Machine learning
      Modeling
      Python
      RDF
      REST
      SBML
      Scheme
      Size: 175h
      VCell
      Status: Open.
      #263 
      In nrnb/GoogleSummerOfCode;
      · vcellmike opened 2 days agoon Mar 12, 2025

      Background
      Predictive mathematical modeling is an essential part of systems biology and is interconnected with information management. Systems biology information is stored in specialized formats (http://co.mbine.org/) that facilitate data storage and analysis (e.g. http://sbgn.org/, http://sbml.org/). These formats are not designed for easy human readability and thus require specialized software to visualize and interpret results. There is an RDF/XML schema for storage of each type of data. Traditionally, to understand this data, you need specific tools that perform a specific set of queries. AI allows users to explore different type of data directly https://www.nature.com/articles/s41540-025-00496-z. We prototyped a ChatGPT chatbot (https://chatgpt.com/g/g-n3asZvWaM-vcell-models-explorer) to explore VCell models (http://vcell.org/). The design of the Chatbot is described in the following presentation: https://drive.google.com/file/d/1jLNjl-ZxZDeGcRxVL754Oao4GYsM4u0Y/view . It is using VCell API https://vcell.cam.uchc.edu/api/v0/biomodel.

      Goal
      Develop a local chatbot and the web interface for querying VCell resources and provide relevant information about VCell models, modeling techniques, and using VCell software.
      Here are sample queries that the chatbot should answer:

      Exploring VCell database, e.g.
      * List all models by a certain user
      * List all models that have a specific type of geometry (e.g. analytic, constructed solid, etc), that use specific solver (e.g. CVODE), etc.
      * List all models that deal with Calcium
      Exploring individual models (both from the database using auth0 authorization, and uploaded by a user):
      *How many reactions are in a certain model? Describe mathematics, parameters, simulations.
      * What biological papers have similar modeling mechanisms?
      * Draw the reaction diagram in SBGN format
      Assist user in using VCell:
      *How to model enzymatic reaction?
      * How to define an analytic geometry?
      * How to plot a histogram for multiple simulations?
      * What do colors mean in spatial simulations plot?
      Assist a user in designing new models:
      * Generate a model for ligand-binding to receptors
      * Combine two existing models into a unified one.
      Possibly expand the project to SBML/BioPAX data, answering all the same queries
      Difficulty Level: Medium/Hard
      We explore the new area where

      Size and Length of Project
      medium: 175 hours
      12 weeks
      Skills
      The suggested technologies (to be discussed) are

      Streamlit/Python (https://streamlit.io/) for client-server structure
      Node.js (https://nodejs.org/) for the graphical front end
      Hugging Face for building, training, and deploying ML models
      Llama (https://www.llama.com/) open-source AI model
      Unsloth AI (https://unsloth.ai/) for fine-tuning for Llama models
      (possibly) NVIDIA for speeding up fetching answers
      Public Repository
      https://github.com/vcellmike/VCellChatBot

      Potential Mentors
      Michael Blinov (blinov@uchc.edu), Ming Zhang (mingzh@lanl.gov)


      ~~~~~~~~~~



      Curation Support Tools for the Creation of a Lung Cancer Disease Map
      Difficulty: Medium
      LLM
      Python
      Size: 175h
      Status: Open.
      #262 
      In nrnb/GoogleSummerOfCode;
      · cannin opened 2 weeks agoon Feb 28, 2025
      7
      comments

      Important Note
      Look at Getting Started before asking questions.

      Background
      Similar to other professions, biologists need fast and reliable ways of summarizing massive amounts of research content found in literature. AI agents that produce detailed, factual, and unbiased research reports with citations are highly important. Tools like OpenAI Deep Research are steps in this direction along with open-source tools like the GPT-Researcher (https://github.com/assafelovic/gpt-researcher). One particular common type of report seeks to understand the biological networks involved in particular diseases or other processes. Communities like DiseaseMaps (https://disease-maps.io/projects/) seek to do this at the scale of diseases like Parkinson's disease which include both written material (https://pmc.ncbi.nlm.nih.gov/articles/PMC4153395/) and interactive diagrams (https://pdmap.uni.lu) that often become the source for mathematical models.

      Goal
      The goal of the project develop additional features or fine-tuning capabilities for gpt-researcher to support the automatic generation of reports for the curation of disease maps. The Related Links has a list of potential resources, including examples of existing reports and automatically generated reports as well as resources (e.g., EMMAA) that remain inaccessible to current state of the art tools like Deep Research.

      Getting Started
      Read the entirety of this Project Description.
      Look at Getting Started, Goal and Related Links (especially Deep Research versus Human).
      Compare GPT-Researcher and Deep Research in versus the human reports (Related Links).
      Write a feasible proposal draft that outlines at some of the differences you see between automated and human reports and presents a plan to address this subset of differences.
      Important: Avoid asking the generic questions such as how to start or if you can work on this project; just write a draft proposal if interested; draft feedback can be provided. Also, good proposals tend to have basic demonstrative code or point to specific code that will be enhanced/modified.

      Difficulty Level: Medium
      This is a more open-ended project; it will require a proposal that is focused enough to be achievable during the time frame.

      Size and Length of Project
      medium: 175 hours
      12 weeks
      Skills
      Essential skills: Python
      Nice to have skills: Javascript
      Related Links
      https://github.com/assafelovic/gpt-researcher
      Collections of automatically extracted interactions for diseases (including lung cancer): https://emmaa.indra.bio/
      Deep Research versus Human: Deep Research: https://drive.google.com/file/d/19z-PIz3JQLlOlv1wj-tFTgtK0px2-rqg/view?usp=sharing Human: https://pmc.ncbi.nlm.nih.gov/articles/PMC3898398/
      Example Reports:
      https://disease-maps.io/projects/
      Lung Cancer Report (try to replicate this): https://link.springer.com/article/10.1007/s00335-025-10110-6
      SIRT1/PARP1: https://pmc.ncbi.nlm.nih.gov/articles/PMC3898398/
      Potential Mentors
      Anbumathi Palanisamy
      Augustin Luna




      ~~~~~~~~~~


      Optimization of SBOannotator for Dynamic Term Integration and AI Enhancement
      Difficulty: Medium
      GUI
      LLM
      Python
      REST
      SBML
      Size: 175h
      Status: Open.
      Feature
      #261 
      In nrnb/GoogleSummerOfCode;
      · NantiaL opened 2 weeks agoon Feb 28, 2025
      8
      comments

      Background
      SBOannotator is the first standalone tool that automatically assigns Systems Biology Ontology (SBO) terms to multiple entities of a given SBML (Systems Biology Markup Language) model. Its main strength lies in annotating biochemical reactions within metabolic models, as the correct assignment of precise SBO annotations requires extensive classification. SBO terms play a crucial role in precisely defining the functions of various components within biological models. By assigning these terms, the interpretability and overall understanding of the model are significantly improved. They help categorize reactions, metabolites, and other entities based on their roles, making it easier to analyze and compare different models. However, in large-scale models containing thousands of reactions and chemical species, manually assigning SBO terms becomes a highly complex and time-consuming task.
      Currently, SBOannotator assigns terms that are hard-coded, making it unable to integrate newly introduced ontologies. Additionally, it derives enzymatic information needed for the correct classification of reactions from the BiGG database or a predefined static SQL (Structured Query Language) database.
      This project aims to optimize SBOannotator by implementing a dynamic retrieval and update mechanism, incorporating Large Language Models (LLMs) for intelligent term suggestions, and developing an intuitive graphical user interface (GUI) for better usability.

      Goal
      Develop a system to dynamically fetch newly introduced SBO terms from the OLS (Ontology Lookup Service) server.
      Improve enzymatic data retrieval by integrating alternative sources beyond BiGG.
      Implement LLM-based annotation assistance to predict and recommend relevant SBO terms.
      Improve user experience through interactive visualizations.
      Develop a user-friendly GUI
      Difficulty Level: Medium
      The project involves multiple technical components, including API accessing mechanisms, LLM integration, and GUI development.
      While these tasks require expertise, they are not extremely advanced and can be accomplished within the GSoC timeframe.

      Size and Length of Project
      medium: 175 hours
      12-14 weeks
      Note that the project length for small projects should be 10-12 weeks.

      Skills
      Essential skills:
      Python
      git
      LLMs
      Nice to have skills:
      Basic understanding and interest on SBML models
      Frontend/GUI development
      Public Repository
      SBOannotator GitHub Repository

      Potential Mentors
      Nantia Leonidou - nantia.leonidou@dkfz-heidelberg.de

      ~~~~~~~~~~
      Using GraphRAG for Automated Data Analysis with LLMs to Explore Cancer Pharmacogenomics Data
      Difficulty: Medium
      LLM
      Python
      R
      Shiny
      Size: 175h
      Status: Open.
      #260 
      In nrnb/GoogleSummerOfCode;
      · cannin opened last monthon Feb 15, 2025
      12
      comments

      Background
      CellMiner Cross-Database (CellMinerCDB, discover.nci.nih.gov/cellminercdb) allows integration and analysis of molecular and pharmacological data within and across cancer cell line datasets. The software is written in the R programming language using the R Shiny web framework. The database contains data on -omics (e.g., gene expression, mutations, etc.), drug response, and sample annotation information that internally exist as tables that have been processed to simplify data analysis. The web interface a set of analyses to be performed with accompanying plots, but it is limited. The amount of data across individual datasets is also growing. The goal is to create tools that leverage large language models (LLMs) to explore this data from a chat interface.

      Goal
      The goal of the project develop a chat interface using LLM-based AI for exploring the available data. The interface will need to interpret user instructions to generate working code making use of the CellMinerCDB API (rcellminer, see related links) that will then be run with a response returned. The data within the CellminerCDB database is amendable to mapping as a graph for use with GraphRAG (e.g., 1: publications describe datasets, genes, drugs, samples, 2: drugs target proteins, etc.) for data retrieval.

      Getting Started
      Look at the links; read the CellMinerCDB publication and rcellminer documentation. Try to find similar projects or ideas online using LangChain. Draft a proposal with your ideas.

      Difficulty Level: Medium
      Simple to start, but a major challenge is in getting "working code" that necessitates efforts such as advanced prompt engineering and other techniques the candidate needs to identify.

      Size and Length of Project
      medium: 175 hours
      12 weeks
      Skills
      Essential skills: Python
      Nice to have skills: R, LangChain, LangGraph, data analysis, and LLM APIs (GPT4, Ollama, etc.), Neo4J/Cypher
      Related links
      https://www.langchain.com/langchain
      https://github.com/CBIIT/cellminercdb
      https://github.com/CBIIT/rcellminer
      https://www.bioconductor.org/packages/release/bioc/html/rcellminer.html
      https://bioconductor.org/packages/release/data/experiment/html/rcellminerData.html
      https://discover.nci.nih.gov/rsconnect/cellminercdb/
      Publication with example analyses to be automated: https://academic.oup.com/nar/article/49/D1/D1083/5983630
      Potential Mentors
      Augustin Luna




      ~~~~~~~~~~
      Enhancing the Systems Biology Simulation Core Library (SBSCL) with a Solver-Agnostic Framework for Constraint-Based Simulation and Analysis
      Difficulty: Medium
      Java
      SBML
      Size: 175h
      Status: Open.
      Feature
      #259 
      In nrnb/GoogleSummerOfCode;
      · draeger opened on Feb 9on Feb 9, 2025
      4
      comments

      Background
      Flux Balance Analysis (FBA) is a widely used approach for simulating biological networks based on linear programming. Several commercial and open-source solvers exist for efficient linear optimization, including CPLEX, Gurobi, GLPK, CBC, and SCIP. These solvers enable researchers to analyze metabolic networks, optimize reaction fluxes, and predict cellular behaviors.

      Previously, SBSCL supported linear optimization through the SCPSolver library, which provided an abstraction layer for different solvers. However, with the introduction of Apple’s M1 and later chips, many existing solvers no longer function across all systems, limiting SBSCL’s compatibility and usability.

      This project aims to implement a new abstraction layer within SBSCL, allowing users to select from multiple solvers or use a default solver while maintaining a unified interface. This abstraction will ensure that linear programming tasks specified in SBML models are forwarded to an appropriate solver and the results are seamlessly returned.

      Goal
      The primary goal of this project is to enhance SBSCL by reintroducing a solver abstraction layer similar to SCPSolver. The expected outcomes include:

      Designing and implementing a solver-agnostic interface for linear programming tasks.
      Integrating support for multiple solvers, including CPLEX, Gurobi, GLPK, CBC, and SCIP.
      Providing a mechanism for users to select solvers based on availability and licensing.
      Ensuring compatibility across different hardware architectures, including Apple M1 and beyond.
      Validating the implementation using SBML-based test cases.
      Difficulty Level: Medium
      The project requires knowledge of Java™ programming, linear optimization, and SBML. While existing solvers handle the core computation, designing a flexible and efficient abstraction layer presents a moderate challenge, particularly in ensuring cross-platform compatibility and performance consistency.

      Size and Length of Project
      Medium: 175 hours

      12 weeks

      Skills
      Essential skills:
      Java programming
      Flux Balance Analysis (FBA)
      Linear optimization
      SBML (Systems Biology Markup Language)
      Knowledge of git
      Public Repository
      SBSCL GitHub Repository

      Potential Mentors
      Andreas Dräger - andreas.draeger@informatik.uni-halle.de

      ~~~~~~~~~~
      A highly efficient numerical ordinary differential equation solver in the Systems Biology Simulation Core Library
      C++
      Difficulty: Medium
      High-performance computing
      Java
      SBML
      SED-ML
      Size: 175h
      Status: Open.
      Feature
      #258 
      In nrnb/GoogleSummerOfCode;
      · draeger opened on Feb 9on Feb 9, 2025
      8
      comments

      Background
      The Systems Biology Simulation Core Library (SBSCL) is an open-source Java™ library that enables efficient simulation of biological models encoded in SBML (Systems Biology Markup Language). Numerical solvers play a crucial role in solving the ordinary differential equation (ODE) systems that arise in these models. One well-known solver, LSODA (Livermore Solver for Ordinary Differential Equations), is implemented in C++ and has shown high efficiency and accuracy. Another important C++ library is CVODE.

      A Java implementation of LSODA has been drafted but remains unfinished. This project aims to finalize this algorithm, test it, and validate it against the SBML Test Suite. The SBML Test Suite contains over 1000 manually created equation systems with analytical solutions, providing a robust benchmark to ensure the correctness and accuracy of the Java LSODA implementation.

      This project aims to complete and integrate the LSODA solver into SBSCL, enabling efficient and accurate ODE solving in Java-based simulation workflows.

      Goal
      The primary goal of this project is to finalize the Java implementation of the LSODA solver and validate its correctness against the SBML Test Suite. The expected outcomes include:

      Completing the existing Java draft of the LSODA solver.
      Writing comprehensive test cases to ensure correctness and stability.
      Running the solver against the SBML Test Suite and comparing results with analytical solutions.
      Ensuring performance and numerical accuracy match the C++ implementation.
      Integrating the finalized solver into SBSCL.
      Writing a Java wrapper for libLSODA to compare the LSODA implementation with that library more easily.
      Difficulty Level: Medium
      The project requires a solid understanding of numerical methods for solving ODEs, Java programming, and scientific computing. While the existing C++ implementation provides a reference, translating and optimizing the solver in Java while ensuring numerical precision can be challenging. However, the structured test suite simplifies validation, making the project achievable within the GSoC timeframe.

      Size and Length of Project
      Medium: 175 hours
      12 weeks
      Skills
      Essential skills:
      Object-oriented programming with Java
      Numerical methods for ODE solving
      Interest in scientific computing
      Nice to have skills:
      Knowledge of git
      Interest in systems biology and SBML (the Systems Biology Markup Language)
      Public Repository
      SBSCL GitHub Repository

      Potential Mentors
      Andreas Dräger - andreas.draeger@informatik.uni-halle.de
      Akira Funahashi - funa@bio.keio.ac.jp
      Arthur Neumann - art.neumann@outlook.com
      Taichi Araki - araki@fun.bio.keio.ac.jp


      ~~~~~~~~~~
      Development of a converter between SBOL2 and SBOL3 in Python
      Difficulty: Hard
      Python
      SBOL
      Size: 350h
      Status: Open.
      #257 
      In nrnb/GoogleSummerOfCode;
      · Gonza10V opened on Feb 6on Feb 6, 2025
      6
      comments

      Background
      Synthetic Biology (SynBio) looks for engineering biological systems and has created abstractions and standards for that endeavor. The Synthetic Biology Open Language (SBOL) was developed by the SynBio community as a standard to represent biological designs hierarchically [1]. With its last release SBOL 3.1 the standard has reached a mature state with the capacity to encode data throughout the Design-Build-Test-Learn (DBTL) cycle. The problem is that most of the tools from the SBOL software ecosystem uses SBOL2, including SynBioHub, a database with the largest collection of data in SBOL, and there is no complete converter between SBOL2 and SBOL3. The community has started a project to develop such a converter but advances have been slow and help is needed to finish it. The converter is in an SBOL-utilities module sbol3_sbol2_conversion. The converter module architecture has an easy to contribute format. It defines two classes 'SBOL3To2ConversionVisitor' and 'SBOL2To3ConversionVisitor'. These objects orchestrate the conversion by visiting each member of a SBOL 'Document' to map it into the other version. Each SBOL element has a function/method to be converted. This project aims to contribute to the development of the SBOL converter in Python between versions 2.3 and 3.1. This project provides hands-on experience in Python, GitHub, unittest, CI/CD, pySBOL2 and pySBOL3.

      [1] Buecherl, Lukas, et al. "Synthetic biology open language (SBOL) version 3.1. 0." Journal of integrative bioinformatics 20.1 (2023): 20220058.

      Goal
      Contribute to the development of a converter between SBOL2 and SBOL3 in Python

      Specific Goals:
      Encode minimal examples for SBOL2 and SBOL3 classes.
      Develop functions for converting classes for converting SBOL2 to 3 and SBOL3 to 2.
      Test conversion by using minimal examples to make round-trip conversion
      Document the converter and create example notebooks.

      Difficulty Level: Hard
      This project involves encoding designs in SBOL2 and SBOL3, developing Python functions and documenting the advances.

      Size and Length of Project
      large: 350 hours
      22 weeks
      Skills
      Essential skills: Python, GitHub, Git
      Nice to have skills: SBOL

      Public Repository
      https://github.com/SynBioDex/SBOL-utilities

      Potential Mentors
      Gonzalo Vidal (Gonzalo.vidalpena@colorado.edu)
      Jake Beal

      ~~~~~~~~~~
      cy3sbml update: major fixes, library upgrades, and new features
      Cytoscape
      Difficulty: Medium
      Java
      SBML
      Size: 175h
      Status: Open.
      #256 
      In nrnb/GoogleSummerOfCode;
      · matthiaskoenig opened on Feb 4on Feb 4, 2025
      7
      comments

      Background
      cy3sbml is a Cytoscape 3 app designed to integrate the Systems Biology Markup Language (SBML) into the visualization of biological networks. Our goal is to provide a powerful visualization tool for computational models and simulations that seamlessly integrates with computational modeling frameworks and workflows.

      Image

      cy3sbml offers a wide range of functionalities for working with SBML-encoded models, including:

      Visualization of SBML network annotations within the network context.
      Direct import of models from repositories such as BioModels.
      One-click access to SBML model information and validation resources.
      Integration with annotation resources like MIRIAM and Ontology Lookup Service (OLS).
      Key Features:

      Java-based SBML parser for Cytoscape, leveraging JSBML.
      Full support for all versions of SBML.
      SBML validation with detailed warnings and error messages.
      Network graph based on species/reaction models.
      Visual representation of SBML objects, including Kinetics, FunctionDefinitions, Parameters, and more.
      Support for SBML extensions such as qual, comp, and fbc.
      Access to RDF-based annotation information within the network context, alongside non-RDF annotations.
      We are preparing a new release of cy3sbml, which will address major bug fixes, incorporate updates to libraries, and introduce new features like:

      Support for the automation API.
      Enhanced visualization of SBML graphs.
      Update to the Ontology Lookup Service (OLS) to version 4.
      Goal
      The goal of this project is to develop a new release of cy3sbml that resolves existing bugs, updates core libraries, and integrates the latest version of the automation API, alongside improvements in graph visualization.

      Difficulty Level: Easy/Medium/Hard
      Medium
      This project requires experience with Java, OSGI, and Maven.

      Size and Length of Project
      Estimated effort: 175 hours
      Duration: 12 weeks
      Skills
      Students should be familiar with the following technologies:

      Essential skills:

      Java
      Maven
      Cytoscape
      Nice to have skills:

      Familiarity with SBML
      Public Repository
      cy3sbml GitHub Repository
      cy3sbml on Cytoscape Apps
      Potential Mentors
      Matthias König, konigmatt@googlemail.com
      Andreas Dräger


      ~~~~~~~~~~
      BioSeqJournal: Julia Journaled Sequences Library
      C++
      Difficulty: Hard
      Julia
      Size: 175h
      Status: Open.
      #255 
      In nrnb/GoogleSummerOfCode;
      · marcoxa opened on Jan 28on Jan 28, 2025
      7
      comments

      Background
      Simulators tracking mutations in a cell population, e.g., to study the evolution of a solid tumor, must manipulate many DNA/RNA sequences at a time. It is obviously unfeasible to duplicate a full sequence every time a mutation happens. Any such simulator must therefore deal rely on sophisticated data structures just tracking the delta's from one sequence to the next, while keeping them in a tree-like (or more complex) data structure.

      Goal
      The goal of the the project is to complete and extend a Julia library that implements a form of journaled sequence, alongside a proper API for its manipulation. An important key identifying such sequences will be time.

      Difficulty Level: Medium/Hard
      The difficulty of the project is twofold: first of all the developer will have to understand the data structures that have been proposed to solve similar problems (cf., SeqAn and render them in Julia; next the developer will want to explore the adaptation of aprroximate search algorithms for the data structure just developed.

      The second part may turn out to be difficult, given the time allotted for the project.

      Size and Length of Project
      Size
      The project size is medium: 175 hours.

      Length
      Timeline is flexible and the project is 12 weeks

      Skills
      Essential skills: Julia, Algorithms and Data Structures Knowledge.
      Nice to have skills: C/C++
      Public Repository
      The current repository is: BioJournals. A new one will probably be needed in the future.

      Potential Mentors
      Marco Antoniotti, marco.antoniotti@unimib.it
      Daniele Ramazzotti, daniele.ramazzotti@unimib.it

      ~~~~~~~~~~
      Refactor Cytosnap to use Playwright
      Canvas
      Cytoscape.js
      Difficulty: Easy
      JavaScript
      Size: 175h
      Status: Open.
      #254 
      In nrnb/GoogleSummerOfCode;
      · maxkfranz opened on Jan 27on Jan 27, 2025
      11
      comments

      Background
      Describe the current state of the project and the main problem or issue being addressed by the proposed idea. Details should include links and references.

      Cytosnap is a package to render and export Cytoscape.js graphs as various image formats.
      Cytosnap currently uses Puppeteer to do this, and Puppeteer has several maintenance and compatibility issues.
      Playwright is a newer alternative to Puppeteer, which would address these issues.
      Skia Canvas is a lighter-weight alternative to Puppeteer and Playwright, which could simplify deployment. Skia Canvas only supports rendering the HTML5 <canvas> API as an exported image, whereas Playwright includes a full browser environment.
      Goal
      Describe what the end result of the GSoC project should be.

      Refactor Cytosnap to use Playwright instead of Puppeteer.
      Add Playwright tests to ensure that the refactored Cytosnap project is working properly according to the Cytosnap public API.
      Configure GitHub Actions to automatically run the new Playwright tests on new commits and pull requests.
      Add support for using Skia Canvas.
      This would be enabled with an option like engine: 'skia'.
      Use Playwright if the user specifies engine: 'playwright'. Cytosnap should support both.
      Mark Skia Canvas and Playwright as optional dependencies. The user can decide which to install based on which he wants to use in his project.
      Add automated tests using Mocha for engine: 'skia'.
      Difficulty Level: Easy/Medium/Hard
      Give a difficulty level, either Easy, Medium or Hard. Make sure to tag the issue with this difficulty.
      Describe with a sentence or two why the project is this difficulty level.

      Easy if:

      The applicant has prior experience with JS and Node.js.
      The applicant has experience with JS build systems, like Webpack or Vite.
      Size and Length of Project
      Define the project commitment as either “small: 90 hours", "medium: 175 hours" or "large: 350 hours" and the timeline between 10 and 22 weeks, for example:

      medium: 175 hours
      12 weeks
      Note that the project length for small projects should be 10-12 weeks.

      Skills
      List skills/technologies that the student should be familiar with. Also tag the issue with these.

      Essential skills:

      JS (significant experience with the language & modern tooling)
      Nice to have skills, from most to least important:

      The HTML5 canvas API
      Headless browsers / rendering: Puppeteer, Playwright, Skia Canvas, Selenium, etc.
      Build systems like Webpack or Vite
      GitHub Actions
      Public Repository
      Link to a public, open-source repository for your project. All code from accepted projects must be open source and public throughout the coding period and beyond.

      https://github.com/cytoscape/cytosnap

      Potential Mentors
      List the names and email contacts for potential mentors.

      Max Franz
      Mike Kucera
      Gary Bader


      ~~~~~~~~~~
      Web-Based Interactive Visualization to integrate Geneset Analysis with DBRetina
      CSS
      Cytoscape.js
      Difficulty: Medium
      HTML
      JavaScript
      Size: 175h
      Status: Open.
      #251 
      In nrnb/GoogleSummerOfCode;
      · MoHelmy opened on Jan 25on Jan 25, 2025
      25
      comments

      Background
      DBRetina is a high-performance bioinformatics command-line tool (CLI) designed to compute pairwise distances among large collections of gene sets, enabling the generation of comprehensive similarity networks. Its computational efficiency eliminates the need to rely on outdated gene sets, allowing users to seamlessly integrate and curate the latest versions of various molecular databases. In addition, DBRetina allows users to incorporate their own gene sets into the network, offering unprecedented resolution for enrichment analysis and unlocking new insights.

      Challenge
      As a CLI tool, users still have to download the gene sets from suitable molecular databases, transform them into a Gene Set Database Format to be suitable for processing by DBRetina, and explore the outputs in suitable visualization tools. Therefore, we propose a unified web interface to streamline gene set analysis by integrating DBRetina’s computational power, biomedical database interoperability, and Cytoscape-based network visualization. This platform will democratize access to advanced genomic comparisons while ensuring scalability and user-friendliness.

      Goal
      To develop an interactive visualization for datasets in DBRetina with the following core functionalities:

      Biomedical Database Integration
      User Geneset Upload & Validation
      In-Browser DBRetina Execution
      Interactive Network Visualization
      Difficulty Level: Easy/Medium
      Size and Length of Project
      medium: 175 hours
      12-16 weeks
      Skills
      Essential skills: Cytoscape.JS, HTML, CSS, JS
      Nice to have skills: web development experience

      Public Repository
      DBRetina: https://dbretina.github.io/DBRetina/
      Cytoscape.js: https://js.cytoscape.org/
      WebAssembly: https://webassembly.org/
      Gene Set Formats: https://software.broadinstitute.org/cancer/software/gsea/wiki/index.php/Data_formats
      Potential Mentors
      Tamer Mansour
      Mohamed Helmy

      ~~~~~~~~~~
      Integrating DBRetina with an LLM-Powered Chatbot for Genomic Data Exploration
      C++
      CSS
      Difficulty: Hard
      HTML
      LLM
      Machine learning
      Size: 175h
      Status: Open.
      #250 
      In nrnb/GoogleSummerOfCode;
      · MoHelmy opened on Jan 25on Jan 25, 2025
      12
      comments

      Introduction to DBRetina
      DBRetina is a high-performance bioinformatics tool with an efficient linear algorithm for calculating the pairwise distance among large collections of gene sets. This algorithm enables easy construction of a comprehensive pairwise molecular similarity network within and across several molecular databases. To enable efficient search and visualization of this huge similarity network, DBRetina can transform the final output into a format compatible with the Neo4j graph databases.

      Challenge:
      While DBRetina bridges genomic analytics and graph databases, querying Neo4j requires Cypher query language expertise, limiting accessibility for non-technical researchers.

      Goal and Aims
      To develop an LLM-Driven chatbot that translates natural language questions into Cypher queries, enabling intuitive interaction with DBRetina-generated Neo4j graphs.
      This chatbot aims to:
      Increase accessibility: Enables non-technical users to query complex genomic networks.
      Improve efficiency: Reduces query-writing time by ~70% (based on LLM benchmarks ).
      Scalability: Adapts to evolving graph schemas and supports multi-database integration.

      Difficulty Level: Medium/Hard
      Size and Length of Project
      medium: 175 hours
      12 -16 weeks
      Skills
      Essential skills: LLM fine tuning, Experience with Graph databases, HTML, CSS, JS
      Nice to have skills: C++

      Public Repository
      DBRetina Documentation
      Neo4j Cypher Manual
      LLM Fine-Tuning for KBQA

      Potential Mentors
      Mohamed Helmy
      Tamer Mansour

      ~~~~~~~~~~
      Website for VCellDB.org
      CSS
      Difficulty: Medium
      HTML
      Java
      JavaScript
      JSON
      REST
      Size: 175h
      VCell
      web services
      XML
      Status: Open.
      #249 
      In nrnb/GoogleSummerOfCode;
      · vcellmike opened on Jan 24on Jan 24, 2025
      20
      comments

      Background
      VCell (http://vcell.org/; https://github.com/virtualcell/vcell) is an open-source software platform that can model and simulate reaction networks. It is in existence for over 20 years and has several thousand users. It is a client-based architecture with models centrally stored in Oracle database. The models can be accessed via REST API https://vcell.cam.uchc.edu/api/v0/biomodel. The prototype interface for accessing and displaying model information is deployed at http://www.vcelldb.org (currently maybe working improperly), available at https://github.com/virtualcell/modelbricks-webapp. It is implemented in Handlebars, with most information retrieved via API, and some information stored locally as JSON.

      Goal
      Provide a complete search and filter page.
      Add static pages as directed.
      Redesign and add missing elements to model pages.
      Make all pages scalable and pretty.
      Use visualization as implemented in https://bnglviz.github.io/examples.html (https://github.com/bnglViz/bnglViz.github.io)
      Modify REST API to add retrieval of new elements.
      Difficulty Level: Easy/Medium
      Provided good skills in HTML/CSS, Handlebars and Java skills to update API, the project is very technical and visual.

      Size and Length of Project
      medium: 175 hours
      12 weeks
      Skills
      Essential skills: Handlebars, Javascript, CSS, HTML
      Desired: Java, REST API

      Public Repository
      https://github.com/virtualcell/modelbricks-webapp

      Potential Mentors
      Michael Blinov
      James Schaff

      ~~~~~~~~~~
      COBRAxy: spatial and single-cell metabolic modelling
      Difficulty: Medium
      Galaxy
      Python
      Size: 175h
      Status: Open.
      #248 
      In nrnb/GoogleSummerOfCode;
      · kiaradamiani opened on Jan 22on Jan 22, 2025
      14
      comments

      Background
      Galaxy is an open-source platform designed to make advanced bioinformatics analyses accessible and reproducible. Among its many applications, constraint-based metabolic modeling (CBM) plays a pivotal role in exploring cellular metabolism through predictive simulations of flux distributions in metabolic networks.

      Current tools in the Galaxy ecosystem, such as MaREA4Galaxy, provide robust capabilities for analyzing metabolic networks based on gene expression data. However, these tools are primarily focused on bulk RNA-seq data and do not yet fully support single-cell RNA-seq (scRNA-seq) or spatial transcriptomics data. High-resolution single-cell and spatial data offer unprecedented opportunities to study metabolic heterogeneity and spatially localized metabolic activities but require significant adaptations to workflows and computational tools.

      Existing Python libraries, such as COBRApy, implement key CBM techniques, including flux balance analysis (FBA) and flux variability analysis (FVA). Efforts like cobraxy have already ported some of these functionalities into Galaxy, but gaps remain—particularly in the support for single-cell FBA (scFBA) and the integration of spatial transcriptomics workflows. Moreover, there is a need to improve the computational efficiency of sampling algorithms by interfacing directly with solvers such as Gurobi or Gulp.

      This project aims to address these gaps by extending Galaxy’s CBM capabilities to support single-cell and spatial data integration, along with optimizations to statistical testing and computational efficiency.

      Goal
      This project builds on the foundation of MaREA4Galaxy, a Galaxy tool designed for metabolic reaction enrichment analysis, expanding its scope to:

      Support single-cell metabolic analysis: Implement models like scFBA, which integrate transcriptomics data into population-based flux models to capture metabolic heterogeneity at single-cell resolution.
      Integrate spatial transcriptomics workflows: Enable mapping of metabolic activities onto physical tissue architectures and co-localization analyses.
      Improve computational efficiency: Optimize the sampling algorithm by directly interfacing with solvers like Gurobi or Gulp, bypassing intermediate steps in COBRApy to reduce runtime.
      Enhance statistical testing: Introduce advanced methods for pathway enrichment analyses, including p-value adjustments (e.g., Bonferroni, FDR) and Bayesian approaches to improve result reliability.
      Develop visualization tools: Enable spatial overlays and interactive visualizations for flux distributions and pathway activities.
      Difficulty Level: Medium
      This project is categorized as medium difficulty because the integration of existing Python tools into Galaxy workflows is straightforward but requires careful adaptation to handle single-cell and spatial data effectively.

      Size and Length of Project
      Define the project commitment as either “small: 90 hours", "medium: 175 hours" or "large: 350 hours" and the timeline between 10 and 22 weeks, for example:

      medium: 175 hours
      12 weeks
      Note that the project length for small projects should be 10-12 weeks.

      Skills
      Essential skills:

      Python programming
      Constraint-based metabolic modeling (e.g., FBA, scFBA)
      Nice to have skills:

      Galaxy tool development
      Experience with single-cell scRNA-seq
      Public Repository
      The existing COBRAxy tools can be found in the following repository:
      COBRAxy on Galaxy ToolShed

      Potential Mentors
      Chiara Damiani, chiara.damiani@unimib.it
      Bruno Galuzzi , brunogiovanni.galuzzi@cnr.it

      Getting started:
      have a look at the demo of current COBRAxy version here: http://marea4galaxy.cloud.ba.infn.it/galaxy
      read the references listed in the readme of each tool of the toolsuite
      try perform an analysis using this tutorial: https://drive.google.com/file/d/125l1SqjJ2wrnQl9e7D6_UdxqmK9afsbI/view?usp=sharing
      read the preprint on spatial flux balance analysis for flux visualization ideas: https://www.biorxiv.org/content/10.1101/2024.11.28.625842v2


      ~~~~~~~~~~
      Improving Cytoscape.js layout utilities
      Cytoscape.js
      Difficulty: Hard
      JavaScript
      Size: 175h
      Status: Open.
      #247 
      In nrnb/GoogleSummerOfCode;
      · ugurdogrusoz opened on Jan 22on Jan 22, 2025
      5
      comments

      Background
      Using graphs in the visual analysis of relational data has proven to be very important. Such visualization is only effective when graphs that are created on the fly can be automatically laid out in a nice, understandable fashion. Not only that, changes to such graphs over time should also be nicely integrated into an existing layout without destroying the user's mental map.

      Cytoscape.js is a highly popular and widely used graph library for visualizing relational data in various domains including biology. It comes with many layout extensions. In addition, a utility library to support these layout extensions was developed to further improve the layout support of a visual software component. This library for instance can help for compactly bringing components of a disconnected graph.

      Goal
      The goal of this project is to improve the existing functionality in choosing good initial locations for any new graph elements on evolving/changing graphs.

      Difficulty Level: Hard
      This project requires CS background to understand description of some new algorithms and choosing the right data structures to implement them.

      Size and Length of Project
      medium: 175 hours
      12 weeks
      Note that the project length for small projects should be 10-12 weeks.

      Skills
      Essential skills: JavaScript, understanding of graph algorithms
      Nice to have skills: Cytoscape.js

      Public Repository
      https://github.com/iVis-at-Bilkent/cytoscape.js-layout-utilities

      Potential Mentors
      Ugur Dogrusoz



      ~~~~~~~~~~
      Automating the constructions of datasets from SynBioHub to streamline the trainning of ML models on standardized data in SBOL
      Difficulty: Medium
      Machine learning
      Python
      SBOL
      Size: 175h
      Status: Open.
      #246 
      In nrnb/GoogleSummerOfCode;
      · Gonza10V opened on Jan 17on Jan 17, 2025
      9
      comments

      Background
      Machine Learning (ML) quickly advanced in the last few years. Key to the ML models is the training process where models learn from data. Therefore, data quality and quantity are fundamental to model performance. Datasets like ImageNet have promoted the use of ML on the Computer Vision field for image classification leading to major advances like the development of AlexNet and ResNet for example. Synthetic Biology (SynBio) looks for engineering biological systems and has created abstractions and standards for that endeavor. Sequence-to-expression is a hallmark for SynBio but the field lacks easy to use datasets so researchers and developers can focus on creating new models instead of gathering and preprocessing data. The Synthetic Biology Open Language (SBOL) [1] was developed by the SynBio community as a standard to represent biological designs hierarchically. SynBioHub is a repository of designs in SBOL, with an API for easy programmatic access. To promote the development and training of ML models from SBOL we will collect data from bibliography [2], encode it in SBOL and make it available on SynBioHub. Then, we will develop a Python package to facilitate the creation of datasets from data in SynBioHub. This will include the query and preprocessing of data to be usable for ML model training. We will test the package by training ML models reproducing results from the paper from where the data was extracted. Finally, we will explore the performance of Graph Neural Networks (GNN) as SBOL is represented in graphs and GNN should be better to extract data from it.

      [1] Buecherl, Lukas, et al. "Synthetic biology open language (SBOL) version 3.1. 0." Journal of integrative bioinformatics 20.1 (2023): 20220058.
      [2] Urtecho, Guillaume, et al. "Genome-wide Functional Characterization of Escherichia coli Promoters and Sequence Elements Encoding Their Regulation." eLife 12 (2023).

      Goal
      Develop a Python package for dataset building from SynBioHub.

      Specific Goals:
      Encode data from reference [2] in SBOL and upload it to SynBioHub.
      Create a Python package to query and preprocess data from SynBioHub.
      Train an ML model replicating reference [2] results.
      Explore the performance of GNN on the same data.
      Document the package and create example notebooks.

      Difficulty Level: Medium
      This project involves encoding designs in SBOL, development of a Python package for data set creation and training on ML models.

      Size and Length of Project
      medium: 175 hours
      16 weeks
      Skills
      Essential skills: Python, GitHub, Git, ML
      Nice to have skills: SBOL

      Public Repository
      https://github.com/synbiodex

      Potential Mentors
      Gonzalo Vidal (Gonzalo.vidalpena@colorado.edu)
      Chris Myers (Chris.myers@colorado.edu)



      ~~~~~~~~~~
      Assisting the creation of SBGN diagrams using large language models (LLMs)
      CSS
      Difficulty: Medium
      HTML
      JavaScript
      LLM
      SBGN
      Size: 175h
      Status: Open.
      #245 
      In nrnb/GoogleSummerOfCode;
      · hasanbalci opened on Jan 10on Jan 10, 2025
      10
      comments

      Background
      Systems Biology Graphical Notation (SBGN) is a standard language for representing biological pathways with SBGNML being the exchange and storage format for SBGN. SBGN diagrams are created using the developed SBGN editors (Newt, CellDesigner, SBGN-ED etc.) and they can be saved as SBGNML files. However, using these editors can sometimes be a difficult process, especially for those who try to use them for the first time, due to their complicated menus and toolbars. In addition, creating an SBGN map drawn on a paper or on a tablet during a meeting or lab discussion again to save it as SBGNML requires extra time and effort. To overcome these issues, we are developing a service and sample app (Image-to-SBGN Converter) to automatically convert hand-drawn SBGN maps to SBGNML by utilizing large language modes (LLMs). In addition to the conversion, this tool also allows user to see the resulting converted diagram and shows node-related information (see figure).

      Screenshot 2025-01-10 at 8 26 53 AM
      Goal
      The goal of the project is to add some features to our app that will make the job of users easier before and after conversion and enable them to get more efficiency. These features include but are not limited to:

      Adding more conversion-related options to the Settings section
      Adding a quick edit feature if the result of the conversion has missing/wrong nodes/edges
      Providing functionality to open the converted map in an SBGN editor such as Newt for advanced editing
      Providing more detailed information about nodes and edges in Object View
      Adding layout options
      Difficulty Level: Easy-Medium
      Difficulty of the required features range from easy (making UI edits) to medium (using Cytoscape.js extensiones or querying data via REST API).

      Size and Length of Project
      medium: 175 hours
      12 weeks
      Skills
      Essential skills: JavaScript, HTML/CSS, Node.js
      Nice to have skills: Cytoscape.js, LLM APIs (GPT, Gemini, Ollama etc.)

      Public Repository
      https://github.com/sciluna/image-to-sbgn

      Potential Mentors
      Hasan Balci
      Augustin Luna

      ~~~~~~~~~~
      Getting the complexity score from SBOL files to streamline DNA synthesis using standards
      Difficulty: Medium
      Python
      SBOL
      Size: 175h
      Status: Open.
      #241 
      In nrnb/GoogleSummerOfCode;
      · Gonza10V opened on Mar 26, 2024on Mar 26, 2024
      8
      comments

      Background
      Synthetic biologists use the Design, Build, Test, Learn (DBTL) cycle to engineer biological systems. The Synthetic Biology Open Language (SBOL) was developed by the community as a standard to represent biological designs and covers the whole DBTL cycle. Although this standard is used and agreed by the community it is mostly used in its visual format and the data format has not been widely adopted, being PDF the primary format to share DNA sequences [1]. The adoption of SBOL [2] by the community can increase the reproducibility of experiments, facilitating building upon previous knowledge.
      To streamline the DBTL cycle and increase the adoption of SBOL we propose the development of a function in SBOL-utilities that allow researchers to easily check synthesizability by different synthesis providers.

      [1] Mante, J., Myers, C.J. Advancing reuse of genetic parts: progress and remaining challenges. Nat Commun 14, 2953 (2023). https://doi.org/10.1038/s41467-023-38791-0
      [2]Buecherl, Lukas, Mitchell, Thomas, Scott-Brown, James, Vaidyanathan, Prashant, Vidal, Gonzalo, Baig, Hasan, Bartley, Bryan, Beal, Jacob, Crowther, Matthew, Fontanarrosa, Pedro, Gorochowski, Thomas, Grünberg, Raik, Kulkarni, Vishwesh, McLaughlin, James, Mısırlı, Göksel, Oberortner, Ernst, Wipat, Anil and Myers, Chris. "Synthetic biology open language (SBOL) version 3.1.0" Journal of Integrative Bioinformatics, vol. 20, no. 1, 2023, pp. 20220058. https://doi.org/10.1515/jib-2022-0058

      Goal
      To build a function to assess the complexity score of DNA sequences in SBOL using Twist API. Develop a function that integrates the previous function with the existing IDT complexity score function to get relevant synthesizability information.

      Specific Goals:
      A function that uses a SBOL file as input, interfaces the TWIST API, and outputs the complexity score.
      Contribute that function to sbol-utilities by adding propper format and tests.
      Develop a mediator to encapsulate functions to get complexity score for different providers (TWIST, IDT).
      Document the mediator and how to add complexity score calculation for other providers.

      Difficulty Level: Medium
      This project involves the understanding of an API, the development of Python functions and integrating them using unittest in the CI/CD workflow of sbol-utilities.

      Size and Length of Project
      medium: 175 hours
      16 weeks
      Skills
      Essential skills: Python
      Nice to have skills: API calls, Git, DevOps

      Public Repository
      https://github.com/SynBioDex/SBOL-utilities

      Potential Mentors
      Gonzalo Vidal (Gonzalo.vidalpena@colorado.edu)
      Jake Beal

      ~~~~~~~~~~
      Cytoscape Automated Testing Suite for Biomedical Visualization
      Cytoscape
      Difficulty: Medium
      JavaScript
      Python
      REST
      Size: 175h
      Status: Open.
      #233 
      In nrnb/GoogleSummerOfCode;
      · jingjingbic opened on Jan 15, 2024on Jan 15, 2024
      10
      comments

      Background
      Cytoscape is an invaluable open-source tool in the field of biomedical research, offering robust data visualization capabilities, particularly for molecular networks. Its ecosystem, enriched by over 370 specialized apps available in the App Store, facilitates diverse functionalities ranging from database access to novel analysis methods. However, the recent development of Cytoscape Web, an online variant, has introduced complexities in maintaining the platform's integrity and quality across versions. As the ecosystem expands, the challenge of ensuring consistent and reliable product releases grows. Thus, the development of sophisticated testing tools becomes imperative to uphold the high standards of Cytoscape's offerings.

      Goal
      The primary goal of this project is to create an automated testing framework tailored for Cytoscape, with a specific focus on scientific figure preparation—a critical use case for the software. This framework will utilize a collection of Cytoscape session files and CX documents, integral in generating figures for various scientific publications. It aims to verify whether the newest versions of both Cytoscape and Cytoscape Web can accurately reproduce these figures. A key aspect of this project involves ensuring that figures produced by Cytoscape Web are consistent with those generated by the desktop version. The framework will facilitate communication with Cytoscape Desktop through the CyRest API and automate tests on Cytoscape Web using renowned frameworks like Playwright . A significant part of the testing process will involve comparing newly generated images against established 'gold standard' figures, employing image analysis tools (OpenCV, ImageMagick) and advanced language models (such as Gemini and GPT-4) to produce comprehensive test reports.

      Difficulty Level: Medium
      Size and Length of Project
      175 hours
      12 weeks
      Skills
      Javascript, TypeScript, Python, Cytoscape

      Public Repository
      https://github.com/cytoscape/cytoscape-web
      https://github.com/cytoscape/
      Potential Mentors
      Jing Chen
      Kei Ono
      Dylan Fong
      Chris Churas


      ~~~~~~~~~~
      Large Network Renderer
      Cytoscape
      Difficulty: Medium
      Hierarchical network
      HiView
      JavaScript
      JSON
      NDEx
      OpenGL
      Size: 175h
      Status: Open.
      #229 
      In nrnb/GoogleSummerOfCode;
      · jingjingbic opened on Jan 12, 2024on Jan 12, 2024
      13
      comments

      Background
      The rise of web-based visualization tools has significantly impacted data interaction, especially in the biomedical sector. However, a major challenge persists: efficiently rendering very large networks, which often comprise 500,000 to 1 million elements, including nodes and edges. Current web visualization tools struggle with such extensive datasets, resulting in performance bottlenecks and limited user interactivity.
      The "Large Network Renderer" project seeks to overcome these limitations. This JavaScript library will significantly enhance the Cytoscape Web project by enabling the effective rendering of large-scale CX networks in web browsers. Its key advantage is the capability to manage very large datasets while ensuring fluid performance and interactive user experience. Beyond Cytoscape, "Large Network Renderer" will serve as an indispensable tool for other web applications handling extensive network visualizations, like the Network Data Exchange (NDEx) and NDEX-IQuery. This endeavor is vital for the progression of web-based data analysis tools, empowering researchers to delve into large, complex datasets with newfound depth.

      Goal
      The objective of this project is extending the initial proof of concept already developed as a prototype. Our focus will extend to supporting a list of commonly used visual properties in this renderer. Key tasks will include:
      Adding more visualization capability to the renderer

      More basic shapes for nodes
      More supports for the edge type
      Performance Evaluation
      Iterative Optimization
      Documentation
      Examples Creation
      Automated test
      This application is built on top of the popular WebGL-based data visualization framework Deck.gl. Since this is a high-level library designed to visualize large data set, you can write the additional features without deep knowledge of WebGL low-level API.

      How to Start
      Interested applicants should:

      Explore libraries/sites/repos mentioned above
      Explore https://deck.gl/ to understand the framework
      Understand the concept of Layers in Deck.gl
      Learn how to create a custom Layers
      Difficulty Level: Medium
      Size and Length of Project
      175 hours
      12 weeks
      Skills
      Javascript / TypeScript
      Knowledge of WebGL API is a plus, but not required
      Public Repository
      https://github.com/idekerlab/large-graph-renderer
      https://github.com/cytoscape/cytoscape-web
      https://github.com/idekerlab/network-viewer
      Potential Mentors
      Kei Ono
      Dylan Fong
      Jing Chen


      ~~~~~~~~~~
      Cytoscape.js extension template using ESM
      Cytoscape.js
      Difficulty: Easy
      JavaScript
      Size: 175h
      Status: Open.
      #223 
      In nrnb/GoogleSummerOfCode;
      · maxkfranz opened on Mar 2, 2023on Mar 2, 2023
      29
      comments

      Background
      Cytoscape.js is a library used to visualise and analyse networks in the browser or in Node.js.

      Problems to solve:

      A lot of JS projects now, and any recent projects, use ESM (either natively in the browser or with a bundler). The core Cytoscape.js library supports ESM. The extensions do not.
      Someone using ESM would have to do complicated configurations to make the extensions work with a bundler.
      Someone using ESM directly in the browser would have to use workarounds in their own code to make extensions work. This would not be straightforward, especially for novices.
      It’s difficult for someone to contribute an extension, unless they’re fairly well skilled technically.
      Technical background:

      ESM is now the module standard for JS.
      The existing extensions largely use Webpack to build UMD (CJS, AMD, globals). They should use Rollup to build ESM and UMD in future.
      The main library already uses Rollup to build ESM and UMD.
      Goal
      Build a template extension using a Github template repository.
      Use your template to update the main first-party extensions.
      Add the template extension to the documentation. A new app author should just click a button to get a new repo for their extension on GitHub. Then they can just focus on their extension itself.
      Difficulty Level
      Easy. It’s straightforward to do. The core library can be used as a reference. It’s a laborious process, though.

      Size and Length of Project
      Define the project commitment as either "medium: 175 hours" or "large: 350 hours" and the timeline between 10 and 22 weeks, for example:

      medium: 175 hours
      12 weeks
      Skills
      Essential skills: JS, attention to detail, testing
      Nice to have skills: Experience using Cytoscape.js

      Public Repository
      https://js.cytoscape.org/

      Potential Mentors
      Max Franz (maxkfranz@gmail.com)
      Mike Kucera (mikekucera@gmail.com)
      Christian Lopes (chrtannus@gmail.com)
      Gary Bader (gary.bader@utoronto.ca)

      ~~~~~~~~~~
      Prototype COSE Network Layout Algorithm to Support Biological Context for Layouts More Intuitive to Humans
      Cytoscape.js
      Difficulty: Medium
      JavaScript
      JSON
      Size: 175h
      Status: Open.
      #219 
      In nrnb/GoogleSummerOfCode;
      · cannin opened on Jan 21, 2023on Jan 21, 2023
      15
      comments

      Background
      Pathway knowledge describing interactions between proteins and other biological molecules is essential for interpreting and integrating diverse genomics data, understanding disease mechanisms and informing medical decision making. Consequently, pathway visualization is very useful for biomedical research. Researchers often visualize pathways with spatial relationships in mind (i.e., proteins on the cell surface at the top and those in the nucleus (the most cell interior) towards the bottom. This spatial information is missing from most generic graph layout algorithms.

      COSE Layout
      The CoSE (pron. "cosay", Compound Spring Embedder) layout for Cytoscape.js developed by i-Vis Lab in Bilkent University is a spring embedder layout with support for compound graphs (nested structures) and varying (non-uniform) node dimensions. A faster version of this layout style called fCoSE, also supporting user-defined placement constraints can be found here.
      (demo, compound demo).

      Citation: U. Dogrusoz, et al, "A Layout Algorithm For Undirected Compound Graphs", Information Sciences, 179, pp. 980-994, 2009.

      Video: fCOSE: https://www.youtube.com/watch?v=vRZVlwntzGY

      Gene Information using Gene Ontology (GO)
      The Gene Ontology knowledgebase provides a computational representation of our current scientific knowledge about the functions, localization, and involved processes for genes.

      Example Gene Localization: https://www.genecards.org/cgi-bin/carddisp.pl?gene=ITGB4#localization-ptm

      GO is an immense hierarchy, but it can be simplified to include a reduced set of terms:

      Cellular Compartment Hierarchy (Nucleus): https://www.informatics.jax.org/vocab/gene_ontology/GO:0005634
      GO Subsets (GO Slim): http://geneontology.org/docs/download-ontology/
      Generate a GO Slim: https://github.com/owlcollab/owltools/wiki/Map2Slim
      Goal
      The goal is to prototype an updated version of this algorithm that includes spatial information and makes automatic use of this information for layout purposes.

      How to Start
      Interested applicants should:

      Explore libraries/sites/repos mentioned above
      Explore code base for fCOSE
      Develop a proposal for incorporating GO information into fCOSE
      Difficulty Level: Medium
      Size and Length of Project
      175 hours
      12 weeks

      Skills
      Javascript

      Public Repository
      https://github.com/iVis-at-Bilkent/cytoscape.js-fcose
      https://github.com/cytoscape/cytoscape.js
      Potential Mentors
      Augustin Luna ({first_name}_{last_name} AT hms.harvard.edu)
      Ugur Dogrusoz


      ~~~~~~~~~~
      Making biological network knowledge discoverable and accessible on search engines
      CSS
      Difficulty: Easy
      HTML
      JavaScript
      Python
      Size: 175h
      XML
      Status: Open.
      #218 
      In nrnb/GoogleSummerOfCode;
      · cannin opened on Jan 21, 2023on Jan 21, 2023
      48
      comments

      Background
      A biological pathway is a network consisting of interactions between biological molecules (e.g. proteins and chemicals) in a cell that lead to a certain product or a change. Researchers commonly use such networks to summarize research results about how biological molecules interact in healthy individuals and how changes in these relationships can lead to diseases, such as arthritis and cancer.

      Pathway Commons (PC) is a popular web resource that aggregates machine-readable data about biological pathways (>6 600) and interactions (>3.5 million) from 23 popular curated public databases. Users can interactively explore this resource through the PC Search page to find out how a query (e.g. gene or disease) is connected to millions of pathways and interactions in the collection.

      Goal
      Create a sitemap for PC Search pathway and interaction network pages.

      Sub-Tasks
      This work will involve modifications to the PC Search source code:

      Identify the biological network data items in PC Search to be included in a sitemap
      There are two types of networks - “Pathways” and “Interactions” - which are accessed from https://apps.pathwaycommons.org
      Pathways
      Example pathway page: Transcriptional activation of cell cycle inhibitor p21 curated by Reactome
      Collection of pathway IDs (specified by a pathway URI) and metadata for latest PC version (14) available in download file pc-hgnc.gmt.gz.
      Interactions
      Example Interactions page: Interaction neighborhood for TP53
      You will create a list of interaction IDs (specified by a HGNC symbol) that would be useful to researchers
      Top gene queries in PC Search (via Google Analytics) and/or “Hot Genes” from Gene Cards
      Explore network content and representations (formats) and identify those that allow items to be visible on Google (manual, small-scale)
      Explore and evaluate different formats e.g.:
      Static page
      sitemap
      Explore and evaluate different content e.g.:
      Name of entities (e.g. genes, proteins, organism)
      Text-based descriptions
      Snapshot images of networks
      Scale production of content to cover all types of networks
      Generate a system to expose all individual pathway and interaction pages
      Stretch goals
      Creating network snapshots at-scale
      Consider services like Systems Biology Layout & Rendering Service (SyBLaRS)
      Accommodating large, complex networks (hairballs)
      e.g. Caspase Cascade in Apoptosis - NCI Pathway Interaction Database: Pathway
      Significance
      This will immediately improve the indexing of PC Search pages by Google. More broadly, this project will expand the audience of researchers able to access and reuse biological research knowledge curated from publications. This will accelerate research discovery and increase the value of each knowledge item in PC Search.

      How to start
      Explore the PC Search webpage
      Familiarize yourself with the PC Search source code
      Difficulty Level: Easy
      Size and Length of Project
      175 hours
      12 weeks
      Skills
      JavaScript and HTML (essential), CSS
      Public Repository
      app-ui source code on GitHub
      Potential Mentors
      Augustin Luna ({first_name}_{last_name} AT hms.harvard.edu)
      Jeffrey Wong (jeffvin.wong AT utoronto.ca)

      ~~~~~~~~~~
 
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/national-resource-for-network-biology-(nrnb)/
    idea_list_url: https://github.com/nrnb/GoogleSummerOfCode/issues


  - organization_id: 96
    organization_name: Neovim
    no_of_ideas: 7
    ideas_content: |

      AI primitives
      Size: 175 hours
      Difficulty: Medium
      Desirable Skills:
      Lua
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Tracking issue: https://github.com/neovim/neovim/issues/32084
      Description:
      Although Nvim doesn't plan to include AI features by default, it should provide basic features that make it easy to build AI plugins (chat, completion, etc.)
      Expected Result:
      Identify and implement Nvim features that make it easy for users to build high-quality AI "chat" and "completion" plugins. For example:
      Support textDocument/inlineCompletion from the LSP 3.18 spec.
      Add a way to mark a buffer or window as "busy" or "in progress", that works with the default statusline (and custom statuslines).
      Add a "progress meter" interface to the Nvim standard library.
      Improvements to the "prompt buffer" concept
      multiline input
      paste into the prompt
      a builtin "filetype" with standard highlighting
      standard headers with distinctive highlighting
      standard mappings
      ...?

      ~~~~~~~~~~
      ":restart" command
      Size: 175 hours
      Difficulty: Medium
      Desirable Skills:
      C
      Lua
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Tracking issue: https://github.com/neovim/neovim/issues/32484
      Description:
      Developing/troubleshooting plugins has friction because "restarting" Nvim requires quitting, then manually starting again, in some fashion.
      Expected Result:
      Implement a :restart command which allows Nvim to restart itself. This will involve some knowledge of inter-process communication / RPC.
      
      ~~~~~~~~~~
      Restore :terminal buffers after restart
      Size: 175 hours
      Difficulty: Easy
      Desirable Skills:
      Lua
      C (minimal)
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Tracking issue: https://github.com/neovim/neovim/issues/28297
      Description:
      Currently, the contents of :terminal buffers isn't preserved after Nvim restarts. Or when a :terminal buffer is closed, its contents can't be reloaded.
      Expected Result:
      :terminal buffer contents can be saved to the filesystem.
      User has a way to view saved terminal buffers and reload them.
      Visiting a "mark" in a terminal buffer reloads the terminal buffer if it's not loaded.
      :terminal buffers optionally are included in Nvim "session" files and restored when the session is reloaded.
     
      
      ~~~~~~~~~~
      "Remote SSH" features
      Size: 350 hours
      Difficulty: Medium
      Desirable Skills:
      Lua
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Tracking issue: https://github.com/neovim/neovim/issues/21635
      Description:
      Working with remote systems could be more "ergonomic". VSCode's "remote ssh" plugin demonstrates how ergonomics can greatly improve usability.
      Expected Result:
      Introduce a command or some sort of interface that Allows the user to:
      input a ssh URI (hostname + port)
      or select from a list of hosts discovered from your local ~/.ssh/config
      nvim connects to the remote ssh endpoint using your local ~/.ssh credentials
      or prompts for password as needed
      nvim starts a new local UI that attaches to a remote nvim server running on the remote machine.
      if necessary, nvim auto-installs itself on the remote machine.
      it also installs your plugins, on the remote!
      the local nvim UI controls the remote nvim server, and you can use it to work on the remote machine very much like a local nvim.
      
      ~~~~~~~~~~
      Visual-first editing
      Size: 350 hours
      Difficulty: Medium-Hard
      Desirable Skills:
      C and Lua
      Familiar with event-loop programming model
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Tracking issue: https://github.com/neovim/neovim/issues/16296
      Description:
      Vim tradtionally has a "verb-object" editing model, whereas editors like kakoune and helix have "object-verb". The existing visual-mode in Nvim could be enhanced to support this in Nvim.
      Expected Result:
      Visual-mode in Nvim becomes more intuitive and useful:
      it can be repeated with dot (.)
      introduce a modifier similar to v, except normal-mode commands work in this mode, after the "selection" is chosen.
      
      
      ~~~~~~~~~~
      GUI Features
      Size: 175 hours
      Difficulty: Medium-Hard
      Desirable Skills:
      C and related tools
      Familiar with event-loop programming model
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Description:
      Nvim GUIs are implemented as processes communicating with Nvim. Originally the UI protocol exposed most functionality as a single, terminal-like screen grid. Work has been done to allow UIs (including embeddings in GUI editors, like VSCode) to render the screen layout themselves, based on semantic updates from Nvim. Some screen elements like the cmdline, popupmenu and message area has been externalized. As a result of a 2018 GSOC project, windows can be drawn on separate grids.
      Expected Result:
      Further improvements to the GUI protocol.
      Some UIs want to render the buffer contents themselves. A solution would be a UI protocol mode, where the rendered grid is not used, rather all decorations, such as syntax highlighting, conceals, virtual text are transmitted for the current viewport. Such an UI would be able to render text without the restrictions of the builtin monospace grid. Then the UI should be able to inform nvim about usage of virtual columns and wrapping, so that vim commands such as gj are consistent with how text is presented to the user.
      Another path is to improve the core Nvim grid model. We could allow the width and height of cells be different for each row. This would allow for heading text with different font size, and pictures rendered inside windows.
      Putting forward your own ideas of UI improvements is encouraged. Read the docs for the implemented extensions as well as the tracking issue for ongoing/planned work, as a starting point.
      
      ~~~~~~~~~~
      IDE "Vim mode"
      Size: 175 hours
      Difficulty: Medium
      Desirable Skills:
      Familiar with RPC
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Description:
      Implement "Vim mode" in an editor/IDE (such as IntelliJ) by embedding a nvim instance.
      Expected Result:
      Full Nvim editing should be available in the editor/IDE, while also allowing the user to use the native editor/IDE features.
      Examples:
      VSCode integration
      Sublime Text integration
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/neovim/
    idea_list_url: https://github.com/neovim/neovim/wiki/Google-Summer-of-Code#gsoc-ideas-2025


  - organization_id: 97
    organization_name: Neuroinformatics Unit
    no_of_ideas: 16
    ideas_content: |
      support for kalman filters in movement

      One of movement’s priority features is to support versatile and efficient methods for data cleaning and filtering. To this aim, we would like to add support for applying Kalman filter in movement.

      In its simplest implementation, we would like to be able to use Kalman filters to smooth position, velocity and acceleration timeseries. However, the same functionality could be expanded to other use cases, for example to fix identity switches between animals in multi-animal tracking data, or to improve point trajectory estimations by aggregating information from multiple sources. We are open to either implementing from scratch or wrapping an existing Python implementation. We would like to work with the GSoC contributor to design the best possible solution.

      Deliverables

      A Python implementation of a Kalman filter for smoothing position, velocity and acceleration timeseries.

      A Python implementation of a Kalman filter for fixing identity switches in multi-animal tracking data (stretch goal).

      Tests to cover any added functionality.

      Documentation for the new functionality.

      An example use case in the movement gallery.

      Duration

      Medium (~175 hours).

      Difficulty

      This project is well-suited for a student or a beginner contributor to open source.

      Required skills

      Experience with Python, NumPy and/or pandas.

      Nice-to-haves

      Experience with xarray and pytest.

      Familiarity with pose estimation frameworks and their usual workflow (DeepLabCut, SLEAP, idtracker…)

      Experience or interest in digital signal processing methods, linear dynamical systems or state space modelling.

      Potential mentors

      @niksirbi

      @sfmig

      Further reading

      movement mission and scope, roadmap and contributing guide.

      KalmanFilter.NET tutorial.

      An example implementation in Python using linear dynamical systems for tracking.

      Python implementations of Kalman filters, such as pykalman

      State-space models packages with support for Kalman filters, such as dynamax, or time series analysis packages such as darts.
      ~~~~~~~~~~

      Implementing outlier detection algorithms in 


      A common issue with most popular pose estimation frameworks used in animal behaviour research is that often they produce inaccurate results that are difficult to detect without manual inspection. For example, for a few frames, the bodypart of an animal may be incorrectly located in a position far from the rest of the bodyparts, leading to a “jerky” and unrealistic trajectory.

      The goal of this project is to add functionality to easily detect such outlier keypoints, so that users can perform quality control on the predicted keypoints and remove or correct erroneous or implausible ones. Following the ideas implemented in the LightningPose framework, we would like to implement outlier detection methods based on the heuristics below:

      temporal smoothness: often we can assume that the changes in position from frame f to frame f+1 should be smooth. For example, if the animal is moving in a straight line, the position of the mean keypoint should not change abruptly. This is not always the case, for example eye or head movements, may be saccadic, but it does cover a large number of cases.

      pose plausibility: the position of the keypoints should be plausible given they represent bodyparts in an animal. For example, if the animal is walking, the position of the keypoints should be consistent with the animal’s body shape and the expected range of motion of the joints. One way to implement this constraint could be following LigthningPose’s approach, which derives “plausibility” using principal component analysis - i.e. a pose is flagged as implausible if it lies outside a certain low-dimensional subspace.

      multi-view consistency: given two or more views of the same animal (e.g. using two cameras, or a camera and a mirror showing a different view), the two views of the same keypoint must be consistent in 3D. This means they should be “projectable” to some 3D subspace (computed for example with principal components analysis), because the true position of that keypoint is a single point in 3D.

      Deliverables

      Implementing an outlier detection module, with methods for temporal smoothness, pose plausibility and multi-view consistency.

      Tests to cover any added functionality.

      Documentation for the new functionality.

      An example use case in the movement gallery.

      Duration

      Large (~350 hours)

      Difficulty

      This project is well suited for an intermediate contributor to open source.

      Required skills

      Experience with Python, NumPy and/or pandas.

      Nice-to-haves

      Experience with xarray and pytest.

      Familiarity with pose estimation frameworks and their usual workflow (see for example DeepLabCut, SLEAP or idtracker).

      Experience or interest in digital signal processing methods, linear dynamical systems or state space modelling.

      Potential mentors

      @niksirbi

      @sfmig

      Further reading

      movement mission and scope, roadmap and contributing guide.

      LightningPose paper and codebase


      ~~~~~~~~~~

      Calibrating confidence cores in movement
      Most pose estimation frameworks provide a confidence score for each predicted keypoint, but these scores are often not well-calibrated, i.e. they do not reflect the true probability of that keypoint being correctly detected. It would be very useful to be able to produce calibrated confidence scores of the keypoint predictions. This would allow us to more fairly compare results across pose estimation frameworks, better filter high/low confidence values, and better interpret model performance.

      The goal of this project would be to implement a method to calibrate the confidence scores provided by the pose estimation frameworks supported in movement.

      One approach to implement this could be similar to the one presented in keypoint-moseq, where the confidence scores are calibrated using an interactive widget that fits a regression line to the log(confidence), log(error) pairs obtained through annotation.

      Another option could be to calibrate the confidence scores using a logistic regression model. The model is trained on a dataset of ground truth keypoints and the corresponding confidence scores, and then used to predict the true probability of the keypoint being correctly detected.

      We are open to other suggestions and would like to work with the GSoC contributor to design together a good working solution.

      Deliverables

      A Python implementation of a method to calibrate the confidence scores provided by at least one of the pose estimation frameworks supported in movement (DeepLabCut, SLEAP, LightningPose, anipose).

      Tests to cover any added functionality.

      Documentation for the new functionality.

      An example use case in the movement gallery.

      Duration

      Medium (~175 hours)

      Difficulty

      This project is well-suited for a beginner or intermediate contributor to open source.

      Required skills

      Experience with Python, NumPy and/or pandas.

      Nice-to-haves

      Experience with xarray, pytest or napari.

      Familiarity with pose estimation frameworks and their usual workflow (see for example DeepLabCut, SLEAP or idtracker).

      Experience with supervised machine learning methods and probability calibration.

      Potential mentors

      @niksirbi

      @sfmig

      Further reading

      There are nice explanations of the calibration issue for the case of classification (but note that in pose estimation we solve a regression problem, not a classification one):

      Calibrating Neural Networks

      Scikit-learn: probability calibration
      ~~~~~~~~~~

      Web-based graphical user interface for movement

      As stated in its design principles, movement is committed to ensuring ease of use and broad accessibility, to support scientist and researchers of all coding levels. This involves developing an intuitive graphical user interface (GUI), which the team has implemented using napari, a popular Python library for n-dimensional image visualisation, annotation, and analysis.

      However, there would be additional value in providing a web-based GUI for movement. Specifically one that would allow for interactive data visualisations within Jupyter Notebooks, a tool very popular among data scientists and researchers particularly during data exploration stages. A web-based GUI may also allow for easier sharing of results and analyses with collaborators, and may facilitate cloud-based workflows

      The goal of this project is to develop a prototype for a web-based GUI for movement. At this early stage, we think it makes sense to explore both options (napari-based and web-based) and evaluate their respective strengths and limitations. They should be independently developed but strive to present a consistent interface to the user.

      Deliverables

      A good prototype for a web-based GUI for movement would include the following features:

      Data loading functionality: ability to load a file containing keypoint or bounding boxes trajectories in the formats supported by movement.

      Video visualisation: ability to overlay the imported trajectories on top of the associated video, and go through them frame by frame.

      Data exploration: ability to filter, sort and visualise the trajectories in different ways. For example, the user may want to only visualise the trajectories of a single animal, or only the trajectories of a subset of keypoints.

      Exporting functionality: ability to export the data visualisation as a video or as a set of images.

      Duration

      Medium (~175 hours)

      Difficulty

      This project is well-suited for an intermediate contributor to open source.

      Required skills

      Experience with Python, NumPy and/or pandas.

      Nice-to-haves

      Experience with xarray and pytest.

      Familiarity with pose estimation frameworks and their manual annotation workflow (see for example DeepLabCutor SLEAP).

      Experience developing data web apps in Python, with tools such as Dash Plotly or fastplotlib.

      Interest in data visualisation.

      Potential mentors

      @niksirbi

      @sfmig

      Further reading

      dash-plotly tutorials and documentation, especially the sections “Dash fundamentals” and “Dash callbacks”.

      fastplotlib examples and documentation.




      ~~~~~~~~~~

      Front-end support for filtering module in movement

      One of the key features of movement is its filtering module, which allows users to clean and process their data before further analysis. However, the current implementation of the filtering module is only accessible via Python scripting, which can be inconvenient for users who are less familiar with programming. To make movement more accessible to a wider audience, we would like to add a filtering widget to our napari graphical user interface.

      The goal of this project is to develop this user-friendly interface for the filtering module that allows users to interactively apply filters to their data. This will involve designing and implementing a widget (or set of widgets) that allow users to select the filters they want to apply, adjust their parameters, and preview the results. The interface should be intuitive and easy to use, with clear visual feedback to help users understand the effects of each filter.

      Deliverables

      A user-friendly napari widget that acts as a front-end to movement’s filtering module. We would like to support at least the following methods: filter by confidence, median filter and the SavGol filter. The user should be able to adjust the parameters of each filter and preview the results in real-time.

      A set of widgets that allow users to select filters, adjust their parameters, and preview the results.

      Tests to cover any added functionality.

      Documentation for the new functionality.

      A short video tutorial demoing the widget’s use (stretch goal).

      Duration

      Medium (~175 hours)

      Difficulty

      This project is well-suited for an intermediate contributor to open source.

      Required skills

      Experience with Python, NumPy and/or pandas.

      Nice-to-haves

      Experience developing or using napari plugins.

      Interest in data visualisation.

      Experience with digital signal processing methods or time series analysis.

      Familiarity with pose estimation frameworks and their usual workflow (DeepLabCut, SLEAP, idtracker).

      Potential mentors

      @niksirbi

      @sfmig

      Further reading

      napari usage tutorials and contributing guide.

      napari Plugin documentation, particularly the section on Building a plugin

      ~~~~~~~~~~
      Support for any-point trackers in ethology

      The main goal of ethology is to facilitate the application of a wide range of computer vision tasks to animal behaviour research, by providing a unified data analysis interface across these tasks.

      Any-point tracking is a good example of a computer vision task that is maturing within the field of computer vision, but it still relatively inaccessible to animal behaviour researchers. The task consists on the following: given a video and a set of query points on a frame of that video, predict the location of those points on every other frame of the video. This is a more general problem than the pose estimation one, which typically focuses on predicting the location of a fixed set of keypoints on an animal’s body. As a result, any-point tracking tools could prove to be a very valuable tool for studying animal behaviour, with potential to supplement or potentially even replace pose estimation.

      Depending on the quality of the trajectories generated by any-point trackers, these could be useful to study the movement patterns of animals directly, or they may be more helpful as a semi-automatic way to quickly generate labelled data. In recent years, there has been an increase in the development of any-point trackers, such as cotracker3 and TAPIR. The goal of this project is to add support for any-point trackers to ethology, so that users can easily apply these tools to their data and analyse the trajectories generated.

      Deliverables

      The expected deliverables include:

      A prototype napari widget, that allows the user to load a video and select the query points to track.

      Back-end functionality to read the query points from the napari widget, and run inference on a pre-trained any-point tracker model, such as those provided by cotracker3 or TAPIR.

      Ability to read the generated trajectories as a movement dataset.

      Front-end support on the napari widget to overlay the trajectories generated by the any-point tracker on the video.

      As a stretch goal, the widget could be extended to allow the user to run inference directly from the napari GUI.

      Duration

      Large (~350 hours)

      Difficulty

      This project is well-suited for an intermediate or advanced contributor to open source.

      Required skills

      Experience with Python and PyTorch.

      Nice-to-haves

      Experience developing or using napari plugins.

      Experience with computer vision applications, particularly pose estimation and any-point tracking approaches.

      Potential mentors

      @sfmig

      @niksirbi

      Further reading

      cotracker3 paper and code

      TAPIR paper and code

      napari usage tutorials and contributing guide.

      napari Plugin documentation, particularly the section on Building a plugin.


      ~~~~~~~~~~

      Improve cellfinder's classification
      The BrainGlobe cellfinder tool is used to detect cells in large whole-brain images. It uses traditional image processing to find possible cell candidates and passes them to a customisable classifier to split the candidates into cells and no-cells. cellfinder relies heavily on pytorch and keras.

      cellfinder currently uses a residual neural network (ResNet) to classify cell candidates, and deep learning network architectures have progressed since. In this project, you will explore newer architectures for the classification network as alternatives to ResNet, and see whether they work better and/or faster than the existing implementation.

      Deliverables

      A Python implementation of at least one new Deep Learning network architecture in cellfinder

      Quantitative comparison between the current and new architecture

      Tests to cover any added functionality.

      Documentation for the new functionality.

      A blog explaining the new network and its advantages and disadvantages.

      Duration

      Medium (~175 hours) or Large (~350 hours).

      Difficulty

      This project is well-suited for an intermediate contributor to open source.

      Required skills

      Experience with Python, NumPy and/or pandas.

      At least initial understanding of machine learning algorithms

      Nice-to-haves

      Experience working with machine learning frameworks, in particular keras or pytorch

      Experience working with image data

      Potential mentors

      @IgorTatarnikov

      @alessandrofelder

      Further reading

      BrainGlobe developer guide

      cellfinder paper

      cellfinder code
      ~~~~~~~~~~

      cellfinder support for two-dimensional brain images

      The BrainGlobe cellfinder tool is used to detect cells in large whole-brain images. It uses traditional image processing to find possible cell candidates and passes them to a customisable classifier to split the candidates into cells and no-cells. cellfinder relies heavily on pytorch and keras.

      cellfinder currently uses a residual neural network (ResNet) to classify cell candidates. This network is designed for three-dimensional whole-brain images, but neuroscientists often take images of two-dimensional slices of the brain. In this project, you would adapt cellfinder to support two-dimensional data. This would involve implementing a new neural network suitable for two-dimensional images, as well as refactoring some of the image processing code.

      Deliverables

      A modified implementation of the existing image processing algorithm (blob detection) in cellfinder that detects cell candidates in both two- and three-dimensional images

      A Python implementation of a neural network in cellfinder that classifies cell candidates from two-dimensional images.

      Tests to cover any added functionality.

      Documentation for the new functionality.

      A blog showcasing the use of cellfinder on two-dimensional images of brains.

      Duration

      Large (~350 hours).

      Difficulty

      This project is well-suited for an intermediate contributor to open source.

      Required skills

      Experience with Python, NumPy and/or pandas.

      At least initial understanding of machine learning algorithms

      Nice-to-haves

      Experience working with machine learning frameworks, in particular keras or pytorch

      Experience working with image data

      Potential mentors

      @IgorTatarnikov

      @alessandrofelder

      Further reading

      BrainGlobe developer guide

      cellfinder paper

      cellfinder code

      ~~~~~~~~~~
      cellfinder support for arbitrary number of channels

      The BrainGlobe cellfinder tool is used to detect cells in large whole-brain images. It uses traditional image processing to find possible cell candidates and passes them to a customisable classifier to split the candidates into cells and no-cells. cellfinder relies heavily on pytorch and keras.

      cellfinder was originally designed to work with two channels: the “background” channel and the “signal” channel. This is a limitation, because sometimes only the signal channel is acquired, or there are several signal channels containing useful information. In this project, you would explore ways to allow cellfinder to classify cells based on information from an arbitrary number of channels. This could allow cellfinder to not just detect cells, but classify their type based on their shape and other features.

      Deliverables

      A modified implementation of the existing image processing algorithm (blob detection) in cellfinder that can detect cell candidates from an arbitrary number of channels.

      A modified implementation of the neural network in cellfinder that can classify cell candidates from brain images with an arbitrary number of channels.

      Tests to cover any added functionality.

      Documentation for the new functionality.

      A blog showcasing the use of cellfinder on images with 1 or 3 channels.

      Duration

      Large (~350 hours).

      Difficulty

      This project is well-suited for an intermediate contributor to open source.

      Required skills

      Experience with Python, NumPy and/or pandas.

      At least initial understanding of machine learning algorithms

      Nice-to-haves

      Experience working with machine learning frameworks, in particular keras or pytorch

      Experience working with image data

      Potential mentors

      @IgorTatarnikov

      @alessandrofelder

      Further reading

      BrainGlobe developer guide

      cellfinder paper

      cellfinder code


      ~~~~~~~~~~

      Add to BrainGlobe's data visualisation tools

      The BrainGlobe brainrender tool is widely used to visualise brain data in a common coordinate space defined by a “brain atlas” (We refer to this data as “atlas-registered” data). However, brainrender is inaccessible to people without programming skills. The brainrender-napari tool aims to make brainrender functionality available to more people through a plugin for the popular open-source graphical image viewer napari.

      Although brainrender and brainrender-napari share some functionality, some publicly available atlas-registered data is not yet available in brainrender-napari. In this project, we would implement code to allow users to visualise publicly available atlas-registered data from mouse and fish brains in brainrender-napari

      Deliverables

      A Python implementation of a napari widget that allows users to download and visualise atlas-registered data.

      Tests to cover any added functionality.

      Documentation for the new functionality.

      Duration

      Small (~90 hours) or Medium (~175 hours).

      Difficulty

      This project is well-suited for a student or a beginner contributor to open source.

      Required skills

      Experience with Python.

      Nice-to-haves

      Experience working with data visualisation

      Experience working with image data

      Potential mentors

      @alessandrofelder

      @IgorTatarnikov

      Further reading

      BrainGlobe developer guide

      brainrender paper

      brainrender code

      brainrender-napari code

      napari usage tutorials.

      napari Plugin documentation, particularly the section on Building a plugin.
      ~~~~~~~~~~

      Update atlas packaging scripts to atlas API v2

      Neuroanatomical atlases define a common coordinate space for the brain, and have been created for many species (mouse, fish, …) and imaging modalities (MRI, lightsheet microscopy, …). A central piece of BrainGlobe’s ecosystem is the BrainGlobe Atlas API. Importantly, the Atlas API allows the use of any BrainGlobe tool with many publicly available atlases, by exposing them through the same, consistent Python interface. This is possible thanks to packaging scripts contributed by the community, that convert public data to a standard format.

      The standard format is somewhat limited, and we improve its utility by adhering to a new community standard for neuroanatomical atlases, “OpenMINDS SANDS”.

      Deliverables

      Modifying atlas packaging Python code to write to OpenMINDS SANDS

      Adapting at least one packaging script to use the new functionality.

      Tests to cover any added/changed functionality.

      Documentation for the new functionality.

      Duration

      Medium (~175 hours) or Large (~350 hours).

      Difficulty

      This project is well-suited for a student or a beginner contributor to open source.

      Required skills

      Experience with Python.

      Nice-to-haves

      Experience working with data standards or data schema

      Experience working with image data

      Potential mentors

      @alessandrofelder

      @IgorTatarnikov

      Further reading

      BrainGlobe atlas API paper

      Getting started with OpenMINDS

      OpenMINDS SANDS BrainAtlas specification


      ~~~~~~~~~~

      brainglobe-registration

      The BrainGlobe brainglobe-registration tool is used to register 2D and 3D images to a common coordinate space defined by an atlas (`brainglobe-atlasapi’). This is a crucial step in many neuroscientific analyses, as it allows data from different experiments to be compared and combined.

      The current implementation relies on a manual selection of the specific 2D region, or 3D subvolume of the atlas to be used as the registration target. This is a time-consuming process, and can be error-prone. In this project, you would implement and compare methods to automatically select the region to be registered, based on the data itself. This could be done by using an adaptive grid search, ML based techniques, or Bayesian optimisation.

      Deliverables

      A new preprocessing step in brainglobe-registration that automatically selects the region of the atlas to be used as the registration target.

      Quantitative comparison between at least two different methods for selecting the region.

      Tests to cover any added functionality.

      Documentation for the new functionality.

      A blog showcasing the new functionality.

      Duration

      Medium (~175 hours) or Large (~350 hours) depending on experience.

      Difficulty

      This project is well-suited for an intermediate contributor to open source.

      Required skills

      Experience with Python, NumPy.

      At least initial understanding of machine learning algorithms

      Nice-to-haves

      Experience with image registration

      Experience with ITK or elastix

      Experience working with image data

      Potential mentors

      @IgorTatarnikov

      @alessandrofelder

      Further reading

      BrainGlobe developer guide

      elastix manual (pdf)

      Bayesian optimisation

      ~~~~~~~~~~

      Allow Google Drive or AWS as remote storage

      In systems neuroscience, a lack of standardisation in data organisation schemes creates a barrier to data-sharing and collaboration. datashuttle provides a Python API and terminal user interface (TUI) to allow researchers to create, validate and transfer folders in a standardised way.

      Projects can be transferred between computer systems in datashuttle via SSH or mounting drives. We would like to support transfer to Google Drive or and Amazon Web Services (AWS) buckets. Under the hood datashuttle uses RClone, which already implements transfer to Google Drive and AWS.

      Deliverables

      Extend datashuttle functionality to permit transfer between a local filesystem and Google Drive or AWS. This will involve exposing new functionality within the Python API as well as the terminal user interface.

      Tests to cover any added functionality.

      Documentation for the new functionality.

      Duration

      Medium (~175 hours)

      Difficulty

      This project is well-suited for a beginner contributor to open source.

      Required skills Experience with Python

      Nice-to-haves Experience with network data transfers (e.g. rsync, rclone, Google Drive, AWS)

      Potential mentors

      @JoeZiminski

      Further reading

      datashuttle and RClone websites.


      ~~~~~~~~~~

      Extend the funtionality of the terminal user interface

      In systems neuroscience, a lack of standardisation in data organisation schemes creates a barrier to data-sharing and collaboration. datashuttle provides a Python API and terminal user interface (TUI) to allow researchers to create, validate and transfer folders in a standardised way.

      In datashuttle, there are a number of features which are available in the Python API but not yet exposed in the terminal interface. datashuttle uses textual to create the TUI. This project would involve extending the functionality of the TUI, providing experience in coding for graphical user interfaces, in particular terminal user interfaces.

      Deliverables

      A python implementation adding textual widgets that perform and display project validation. This will include buttons, radio-buttons and drop down menus and a log display for validation errors.

      Improvements to user experience:

      Implement code to allow a responsive user interface while a transfer job is performed.

      Add buttons and drop-down list to edit a directory tree.

      Tests to cover any added functionality.

      Documentation for the new functionality.

      Duration

      Medium (~175 hours)

      Difficulty

      This project is well-suited for a student or a beginner contributor to open source. No experience in graphical or terminal user interfaces is required.

      Required skills Experience with Python

      Potential mentors

      @JoeZiminski

      Further reading

      TheNeuroBlueprint and datashuttle websites.






      ~~~~~~~~~~

      Add motion correction preprocessing

      Extracellular electrophysiology is a technique used to record the activity of thousands of neurons in the brain simultaneously. Understanding how this neural activity drives behavior requires reliably identifying and distinguishing individual neurons based on their electrophysiological signatures—a process known as spike sorting.

      spikewrap is a Python package designed to streamline electrophysiology preprocessing and spike sorting across experimental projects. It leverages SpikeInterface, a popular package that exposes many electrophysiology processing tools. The aim of spikewrap is to abstract away implementation details and make running electrophysiological analysis as simple as possible.

      This project involves adding ‘motion correction’ preprocessing to spikewrap.

      Deliverables

      Add SpikeInterface motion correction functionality to spikewrap

      Test motion correction functions.

      Document the new functionality

      Duration

      Large (~350 hours)

      Difficulty

      In terms of coding requirements, a beginner or intermediate developer would be well suited. However, the project will require working closely with extracellular electrophysiological data, which can be quite complex. Therefore, domain knowledge of extracellular electrophysiology would be an advantage.

      Required skills Experience with Python and running neuroscience (preferably electrophysiology) experiments.

      Nice-to-haves Experience with extracellular electrophysiology.

      Potential mentors

      @JoeZiminski

      Further reading

      spikewrap and SpikeInterface documentation.



      ~~~~~~~~~~

      Extend spikewrap test functionality

      spikewrap is a young project in the prototyping phase. Testing the package is not straightforward and requires access to GPU hardware and SLURM scheduling software on a high-performance compute (HPC) cluster. Currently, test suite is currently lagging development.

      This project will involve developing a comprehensive test suite for running experimental pipelines in spikewrap. This will involve running all possible options the software supports on an HPC system, leveraging GPU, SLURM and singularity image functionality.

      Duration

      Large (~350 hours)

      Difficulty

      This project is well-suited for a beginner to intermediate level developer, in particular with an interest in testing infrastructure. Less domain knowledge is required for this project compared to Add motion correction preprocessing.

      Required skills Experience with Python

      Potential mentors

      @JoeZiminski

      Further reading

      spikewrap and SpikeInterface documentation.



     

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/neuroinformatics-unit/
    idea_list_url: https://neuroinformatics.dev/get-involved/gsoc

  - organization_id: 98
    organization_name: NumFOCUS
    no_of_ideas: 86
    ideas_content: |
      
      aeon

      Project #1: Clustering - Distance-Based time series clustering algorithms
      This project involves implementing clustering algorithms with integration to our distances module.

      Complexity: High

      Duration 350 hours

      Mentors: Chris Holder (@chrisholder), Matthew Middlehurst (@MatthewMiddlehurst) and Tony Bagnall (@TonyBagnall)

      Description
      Clustering algorithms making use of distance measures are popular approaches for time series clustering. While well-known measures such as Euclidean Distance (ED) are used for feature vector clustering, algorithms can be adapted for time series data by using elastic distances such as Dynamic Time Warping (DTW) to compare two series. The aeon implementation of various distance measures and clustering algorithms were recently used to evaluate the effectiveness of different elastic distances for clustering [1].

      While the aeon distances module is already extensive, there are still clusterers that could be implemented. aeon currently has common algorithms such as KMeans and KMedoids, but is missing algorithms such as Density Peaks [2], DBSCAN [3] and Hierarchical clustering approaches. The project will involve implementing and evaluating some of these, and ensuring they are properly integrated to use the wide variety of functions in the distances module.

      Required Skills
      Python 3
      Git and GitHub
      Basic understanding of machine learning, specifically clustering algorithms and distance measures
      Optional but useful skills:

      Writing code using numba
      For understanding the alternative implementations: Java
      Expected Outcome(s)
      A Python implementation of one or more algorithms using the aeon time series classification API.
      An evaluation of the mentees implementation against alternative implementations of the algorithm, showing that the implementation is as accurate and efficient enough that it is feasible to run experiments with.
      References
      Holder, C., Middlehurst, M. and Bagnall, A., 2024. A review and evaluation of elastic distance functions for time series clustering. Knowledge and Information Systems, 66(2), pp.765-809.
      Rodriguez, A. and Laio, A., 2014. Clustering by fast search and find of density peaks. science, 344(6191), pp.1492-1496.
      Ester, M., Kriegel, H.P., Sander, J. and Xu, X., 1996, August. A density-based algorithm for discovering clusters in large spatial databases with noise. In kdd (Vol. 96, No. 34, pp. 226-231).
      
      
      ~~~~~~~~~~
      Project #2: Forecasting - Implementing and evaluating machine learning forecasters
      Complexity: High

      Duration 350 hours

      Mentors: Tony Bagnall (@TonyBagnall) and Matthew Middlehurst (@MatthewMiddlehurst)

      Description
      This project will investigate algorithms for forecasting based on traditional machine learning (tree based) and time series machine learning (transformation based). Note this project will not involve deep learning based forecasting. It will involve helping develop the aeon framework to work more transparently with ML algorithms, evaluating regression algorithms already in aeon[1] for forecasting problems [2] and implementing at least one algorithm from the literature not already in aeon, such as SETAR-Tree [3].

      Required Skills
      Python 3
      Git and GitHub
      Basic understanding of forecasting.
      Basic understanding of machine learning, specifically decision trees.
      Expected Outcome(s)
      Contributions to the aeon forecasting module.
      Implementation of a machine learning forecasting algortihms.
      Help write up results for a technical report/academic paper (depending on outcomes).
      References
      Guijo-Rubio, D., Middlehurst, M., Arcencio, G., Silva, D.F. and Bagnall, A., 2023. Unsupervised feature based algorithms for time series extrinsic regression. arXiv preprint arXiv:2305.01429.
      https://forecasters.org/resources/time-series-data/
      Godahewa, R., Webb, G.I., Schmidt, D. and Bergmeir, C., 2023. SETAR-Tree: a novel and accurate tree algorithm for global time series forecasting. Machine Learning, pp.1-37.
      
      ~~~~~~~~~~
      Project #3: Forecasting - Deep learning for forecasting
      Complexity: High

      Duration 350 hours

      Mentors: Ali Ismail-Fawaz (@hadifawaz1999), Tony Bagnall (@TonyBagnall) and Matthew Middlehurst (@MatthewMiddlehurst)

      Description
      Time series forecasting plays a crucial role in numerous domains, including finance, healthcare, energy, and climate science. This project aims to integrate deep learning-based time series forecasting models into aeon. By leveraging state-of-the-art architectures such as Transformers [1], Temporal Convolutional Networks (TCNs) [2], and Long Short-Term Memory (LSTM) [3] networks, the project will enhance aeon's forecasting capabilities. The goal is to provide scalable, efficient, and user-friendly deep learning models tailored for time series applications, expanding aeon's functionality and usability for researchers and practitioners.

      Required Skills
      Python 3
      Experience with TensorFlow or PyTorch for building and training deep learning models.
      Git and Github
      Optional but useful skills:

      Basic knowledge about Time Series Forecasting is appreciated
      Expected Outcome(s)
      A python framework for deep learning models as a submodule of the aeon time series forecasting module.
      Integration the models' neural network part into the networks module of aeon.
      Integration of features similar to existing deep learning modules in aeon such as saving and loading models.
      Testing the developped models with all their features and attend a high coverage.
      Developing notebooks for deep time series forecasting.
      References
      Zhou, Haoyi, et al. "Informer: Beyond efficient transformer for long sequence time-series forecasting." Proceedings of the AAAI conference on artificial intelligence. Vol. 35. No. 12. 2021.
      Bai, Shaojie, J. Zico Kolter, and Vladlen Koltun. "An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv." arXiv preprint arXiv:1803.01271 10 (2018).
      Salinas, David, et al. "DeepAR: Probabilistic forecasting with autoregressive recurrent networks." International journal of forecasting 36.3 (2020): 1181-1191.
      
      ~~~~~~~~~~
      Project #4: Documentation - Improving the aeon documentations interactivity and testing
      Complexity: Medium

      Duration 90 or 175 hours

      Mentors: Matthew Middlehurst (@MatthewMiddlehurst), Tony Bagnall (@TonyBagnall) and Antoine Guillaume (@baraline)

      Description
      The aeon documentation is a key resource for users of the toolkit. It provides information on how to install the toolkit, how to use the toolkit, and how to contribute to the toolkit. The aeon documentation is built using sphinx and hosted on readthedocs.

      While there are always improvements that can be made to the general documentation itself (e.g., improving the clarity of the text, adding more examples, etc.) for both webpages and estimator docstrings, this project focuses on implementing functions to automatically link relevant API pages together and ensure new pull requests are accompanied by the appropriate documentation. Some examples of improvements that could be made include:

      Linking to examples to in API pages where the function/class is used similar to scikit-learn (e.g., here)
      Improving the estimator overview page by further integrating the tags system or adding search and filtering functionality
      Implementing workflows to ensure that new public functionality includes a valid docstring (i.e. has a description, parameters, returns, etc. sections where relevant)
      There is a lot of potential for additional functionality, so feel free to suggest improvements or new features outside the examples provided.

      Required Skills
      Python 3
      Git and GitHub
      Understanding of how sphinx is used to build documentation
      Optional but useful skills:

      Understanding of GitHub Actions and writing workflows
      Expected Outcome(s)
      At least one new feature or improvement to the aeon documentation webpage (outside of general text improvements)
      And/Or (depending on project duration scope)

      Improvement to the aeon testing suite to ensure that new PRs are accompanied by the appropriate documentation
      
      ~~~~~~~~~~
      Project #5: Maintenance - Modernising the aeon linting and type checking workflows
      Complexity: Medium

      Duration 90 or 175 hours

      Mentors: Matthew Middlehurst (@MatthewMiddlehurst), Tony Bagnall (@TonyBagnall) and Antoine Guillaume (@baraline)

      Description
      This project involves updating the aeon linting and type checking workflows to use modern tools and ensure that the codebase is up to date with the latest Python standards.

      The aeon toolkit uses pre-commit to run code quality checks on all code changes and ensure that they meet the project's standards. This includes a number of checks and formatting tools, such as black, flake8, and isort (see here). Over time new tools have been released such as ruff and tools we previously used such as pydocstyle have been deprecated. The first part of this project will involve modernising the pre-commit configuration to use the latest tools.

      aeon contributors have been encouraged to add type hints to the codebase, but this is a gradual process and there are still many parts of the codebase that are not fully typed. A big issue we face in this is the current lack of automated testing to ensure that implemented type hints are accurate. This second part project will involve implementing robust testing utilities to help contributors and reviewers ensure that new type hints are correct.

      Other ideas to improve the code quality testing in aeon pull requests or deliver feedback from tests to contributors are welcome.

      Required Skills
      Python 3
      Git and GitHub
      Understanding of GitHub Actions and writing workflows
      Expected Outcome(s)
      Updated workflows for checking code quality in aeon pull requests
      Automated testing and utilities to help contributors implement accurate type hints for aeon code.
      
      ~~~~~~~~~~
      Project #6: Enhancement - Implementing multithreading for aeon estimators and tools for evaluating multithreading performance
      Complexity: Medium

      Duration 175 or 350 hours

      Mentors: Matthew Middlehurst (@MatthewMiddlehurst),

      Description
      Multithreading in aeon for estimators does not have a set structure or library that must be used. Most algorithms which have an n_jobs parameter available use a mix of Joblib and numba multithreading. Algorithms which do have the capability for multithreading have not been thoroughly tested, and as such the efficiency of these implementations is unknown.

      As well as expanding the amount of estimators which can use multiple threads, we would like to develop tools to evaluate whether this threading is efficient and develop documentation for contributors which want to add multithreading to aeon estimators.

      This project is very open, so please do be specific on your plans to improve multithreading in aeon if you make an application.

      Required Skills
      Python 3
      Git and GitHub
      Knowledge of Joblib and/or other libraries multithreading in Python
      Optional but useful skills:

      Understanding of GitHub Actions and writing workflows
      Experience with writing multithreaded code
      Expected Outcome(s)
      Tools and testing for evaluting the efficiency of multithreaded code while maintaining single threaded performance
      The addition of multithreading as a capability for aeon estimators (prefereably in the classification, regression and clustering modules)

      ~~~~~~~~~~

      Project 1 - Standardize Type Annotations
      level Mid

      Expected Size 350h

      A significant portion of AiiDA’s source code is currently excluded from mypy checks, leading to inconsistent or missing type annotations across different modules. The goal of this project is to systematically add and refine type annotations throughout AiiDA’s codebase, ensuring that all functions, classes, and methods are correctly typed. Standardizing type annotations will improve code readability, maintainability, and reduce future bugs.

      Expected Outcomes:
      Comprehensive and consistent type annotations across all AiiDA modules.
      Removal of unnecessary exclusions from mypy checks.
      Improved developer experience and reduced ambiguity when extending or refactoring AiiDA’s code.
      Required Skills:
      Basic familiarity with Python.
      Understanding of typing in Python (e.g., typing module, type hints, generics).
      Familiarity with static type checking tools (e.g., mypy) is helpful but not strictly required, as it can be learned during the project.
      Mentors
      Jusong Yu @unkcpz
      Julian Geiger @GeigerJ2
      
      ~~~~~~~~~~
      Project 2 - Support Running Blocking Processes Using Multithreading
      level Advanced

      Expected Size 350h

      AiiDA defines running jobs as AiiDA processes, which are state machines whose states are stored on the file system—allowing them to recover after reboots and continue executing remote jobs. It uses Python’s asyncio library to handle I/O-bound tasks, such as submitting jobs and waiting for remote execution. We avoid exposing the asynchronous syntax by providing only synchronous entry points when launching jobs, shielding end users from the complexities of asynchronous programming. However, synchronous Python functions within AiiDA run in a blocking manner within the event loop of main thread. Enabling multithreading would significantly boost AiiDA’s throughput by allowing these blocking processes to run concurrently.

      Expected outcomes
      Streamline event loop management.
      Deprecate nest-asyncio in favor of greenlet.
      Enable synchronous function execution in newly spawned threads.
      Skills
      Familiarity with Python
      Experience with asynchronous and parallel programming
      Mentors
      Jusong Yu @unkcpz
      Julian Geiger @GeigerJ2

      ~~~~~~~~~~
      Project 3 - Training an LLM to generate a queries from natural language prompts
      level Mid / Advanced

      Expected Size 350h

      One of the most powerful aspects of using AiiDA to run your workflows is that the automatically generated provenance can be used to flexibly query for the data that the user is interested in. However, while the QueryBuilder provides this flexibility, it can be challenging to learn and even time-consuming for experienced users.

      To address this issue, this project aims to develop a tool utilizing large language models (LLMs) to generate queries from natural language prompts. Additionally, LLM-based code generation can be useful for broader AiiDA applications, so the project may optionally be extended to support general AiiDA code generation.

      While existing LLMs like ChatGPT already perform fairly well, their generated code is often incorrect or outdated. By creating a diverse and maintainable dataset of query prompts and corresponding Python code, and either fine-tuning a dedicated LLM or designing carefully engineered prompts, we aim to improve the accuracy of generated queries, providing users with a powerful tool for extracting relevant results more effectively. The student will have the opportunity to actively participate in decision-making to determine the best approach.

      Expected outcomes
      By the end of this project, we aim to have a lightweight tool that can reliably generate a correct QueryBuilder instance from a user prompt. This will require:

      A database that maps natural language prompts to the corresponding queries, which can be easily and incrementally expanded.
      LLM trained on this database that converts prompts into a QueryBuilder instance, and optionally into more general AiiDA code.
      A user-friendly interface for that can be installed locally in the form of a Python package and optionally an online tool integrated with the Materials Cloud.
      Skills
      We expect you to be familiar with object-oriented programming in Python.
      You need to have experience in working with large language models.
      Additionally, a first look into AI engineering is required.
      Note
      This project poses an exciting challenge for both students and mentors. While the AiiDA team may not have extensive experience with LLM, we eagerly anticipate students bringing their knowledge to the table. We are ready to provide expertise for the actual queries and more, making this collaboration a dynamic and enriching opportunity.

      Mentors
      Ali Khosravi @khsrali
      Jusong Yu @unkcpz



      AiiDA
      ~~~~~~~~~~

      Feature Parity
      We are in the process of refactoring ArviZ into three sub-packages: ArviZ-base, ArviZ-stats, and ArviZ-plots. You can see an example of this new structure in arviz-plots. This refactor introduces changes to both the API and internal implementation, with most of the design decisions already established. However, the main task remaining is bringing existing features from legacy ArviZ into the new structure.

      Some key features still missing include:

      Model comparison using PSIS-LOO-CV (both in arviz-stats and arviz-plots)
      Model criticism tools, such as prior and posterior predictive checks (mostly ArviZ-plots, including plot_ppc and specialized plots for discrete data)
      Sampling diagnostics, particularly visualization tools like rank plots, rank_ecdf plots, parallel coordinate plots, etc
      To ensure full feature parity with legacy ArviZ, we need to reintroduce these functionalities while also incorporating some new features, such as additional LOO utilities.

      Since these tasks are extensive, we do not expect a single student to implement all of them. Instead, students should discuss with the project developers to select the features that best match their interests, skills, and goals.

      Expected output
      The expected output is a collection of implemented and tested features that enhance feature parity with the legacy version, accompanied by relevant documentation.

      Required skills
      Participants focusing on plotting features should be familiar with plot faceting, and the grammar of graphics, and comfortable working with xarray. Basic knowledge of plotting libraries such as Matplotlib, Bokeh, and Plotly is also required.

      Those primarily interested in adding statistical or diagnostic features should have a good understanding of Bayesian statistics and be comfortable with xarray. Depending on the specific features they plan to implement, they should also be familiar with at least one of the following topics: prior/posterior predictive checks, model comparison, or sampling diagnostics.

      Info
      Expected size: 350h
      Difficulty rating: hard
      Potential mentors: Osvaldo Martin, Andy Maloney

      ~~~~~~~~~~
      Prior elicitation
      PreliZ currently supports elicitation on the parameter space, allowing users to specify probability distributions for model parameters based on their prior knowledge. Additionally, it includes a few experimental functions for predictive elicitation on the observed space, enabling users to directly elicit distributions over predicted outcomes.

      The goal of this project is to enhance and broaden the predictive elicitation tools by refining their implementation, boosting flexibility, and improving usability. This includes enhancing interactive components, enabling resampling based on user inputs, integrating additional statistical steps, and improving interoperability with other elements in the PreliZ framework, like distributions and elicitation methods on the parameter space.

      Required skills
      People working on this project will need to be familiar with Bayesian statistics, Prior elicitation PreliZ and possibly also ipywidgets.

      Expected outcome
      The expected outcome of this project will be features and accompanying documentation that demonstrate how they can be effectively integrated into a Bayesian workflow.

      Info
      Expected size: 350h
      Difficulty rating: hard
      Potential Mentors: Osvaldo Martin, Rohan Babbar






      ArviZ

      ~~~~~~~~~~


      rattler WASM
      We would love to have a WASM build of rattler. We have a prototype, but it has a lot of rough edges.

      A fully functional WASM build of rattler would be able to:

      resolve conda packages using the resolvo resolver
      download, extract and link them into the filesystem of emscripten
      The prospective student will have to make changes across rattler to support WASM, and potentially in some dependencies of rattler, too.
      The motivating use cases are as an alternative to picomamba in the emscripten-forge project, as well as to serve as a backend for a Dependabot integration.

      Expected outcomes:
      The expected outcome of this work would be a version of rattler that can run easily in the browser or another WASM runtime. We expect a few patches to rattler itself, as well as dependencies of rattler (such as the Rust bindings to bzip2, zstd, and more). Most importantly, it would be great to demonstrate that the SAT solver at the core of rattler (resolvo) can run fine in WASM. If time permits, we would add some TypeScript bindings to start the integration with Dependabot.

      Complexity: Hard
      Duration: 350 Hours
      Mentors: @wolfv / @baszalmstra
      Required Skills: Build systems, Rust

      ~~~~~~~~~~

      

      rattler speed and security improvements
      We would love for someone to take another look at security and speed in rattler.

      We already ship rattler_sandbox for lightweight process sandboxing, but we have yet to roll it out to all function in the rattler codebase. It would be especially useful when executing arbitrary package scripts, such as activation scripts, post-link and pre-unlink scripts.

      Furthermore, we would also like to implement sandboxing for Windows, which is a bigger topic, but highly interesting.

      Expected outcomes
      When the project is finished, the mutating parts of rattler (such as installing packages) can pass an optional "sandbox" configuration parameter. If the parameter is set to true, then certain actions (such as running activation scripts or post-link scripts) are executed in a special sandbox that makes sure that the script has no network access and cannot write outside of a constrained set of locations.

      If time permits, we take another look at sandboxing on Windows, and add support for a Windows sandbox using windows AppJail.

      Complexity: Hard
      Duration: 350 Hours
      Mentors: @wolfv / @baszalmstra
      Required Skills: Rust
      conda / rattler

      ~~~~~~~~~~

      Proposal 1: Efficient Detection of Unique Images from Overlapping Images
      Rationale:
      Develop a workflow to compute unique image detections from overlapping images using either the weecology/DoubleCounting repository or the open-forest-observatory/geograypher repository. This project will focus on implementing an efficient algorithm for removing double counting among overlapping images.

      Approach:
      Choose a suitable repository either weecology/DoubleCounting or open-forest-observatory/geograypher for implementing the unique image detections workflow.
      Develop an efficient algorithm for removing double counting among overlapping images.
      Evaluate the performance of the workflow on various datasets.
      Expected Outcomes:
      A workflow for computing unique image detections from overlapping images.
      Documentation on using the workflow.
      Source Code: DeepForest

      Degree of Difficulty:
      Intermediate, long (350 hours)
      Skills:
      Deep learning
      Git/GitHub
      Machine learning
      Software testing
      Python and Python package deployment
      Mentors:
      @bw4sz
      @henrysenyondo
      @ethanwhite

      ~~~~~~~~~~

      
      Proposal 2: Developing an Active Learning Module for DeepForest
      Rationale:
      Implement an active learning module for DeepForest, allowing users to select new images for model training based on current model scores. This project will focus on integrating the BOEM repository's active learning code into DeepForest, enabling more efficient model training and improved accuracy.

      Approach:
      Integrate the BOEM repository's active learning code into DeepForest.
      Develop a user-friendly interface for selecting new images based on model scores.
      Evaluate the effectiveness of the active learning module in improving model accuracy.
      Expected Outcomes:
      An active learning module for DeepForest using BOEM.
      Documentation on using the active learning module.
      Source Code: DeepForest

      Degree of Difficulty:
      Intermediate, long (350 hours)
      Skills:
      Deep learning
      Git/GitHub
      Active learning
      Python and Python package deployment
      Mentors:
      @bw4sz
      @henrysenyondo
      @ethanwhite

      ~~~~~~~~~~
      Proposal 3: The Airborne Wildlife benchmark dataset.
      https://github.com/landing-ai/vision-agent?tab=readme-ov-file

      Rationale:
      There are hundreds of airborne wildlife datasets out there, most are unavailable, in many different formats and organizations and cannot be used for machine learning model training. We have identified hundreds of datasets and will work with partners to collect, standardize and training a general airborne animal detector.

      Approach:
      Download and organize datasets from previously identified sources
      Clone the MillionTrees repo https://milliontrees.idtrees.org/en/latest/ to create a MillionAnimals benchmark. The organization, evaluation and structure is already well defined.
      Develop baseline models for a single general animal detector across taxa and backgrounds for screening of images, much as camera traps has https://github.com/agentmorris/MegaDetector. This work may be in partnership with https://github.com/microsoft/CameraTraps, depending on the readiness and state of the repo.
      Connect and document both MillionTrees and MillionAnimals with DeepForest for reproducible model training.
      Expected Outcomes:
      An agent-interaction module for DeepForest using VisionAgent.
      Documentation on using the agent module.
      Source Code: DeepForest

      Degree of Difficulty:
      Intermediate, long (350 hours)
      Skills:
      Deep learning
      Git/GitHub
      Active learning
      Python and Python package deployment
      Mentors:
      @bw4sz
      @henrysenyondo
      @ethanwhite

      ~~~~~~~~~~
      Proposal 4: DeepForest Vision Agent connection with LandingAI
      https://github.com/landing-ai/vision-agent?tab=readme-ov-file

      Rationale:
      Text-based queries of images for labeling and organization.

      Approach:
      Create configuration for DeepForest users to register LLM keys
      Object detection and segmentation workflows
      Develop a user-friendly interface for selecting new images based on agent responses
      Evaluate the effectiveness of the active learning module in improving model accuracy.
      Expected Outcomes:
      An agent-interaction module for DeepForest using VisionAgent. Documentation on using the agent module.

      Source Code: DeepForest

      Degree of Difficulty:
      Intermediate, long (350 hours)
      Skills:
      Deep learning
      Git/GitHub
      Active learning
      Python and Python package deployment
      Mentors:
      @bw4sz
      @henrysenyondo
      @ethanwhite
      
      ~~~~~~~~~~
      
      Proposal 5: Integrating BIOCLIP Backbone into DeepForest's CropModel for Improved Accuracy
      https://huggingface.co/imageomics/bioclip https://github.com/Imageomics/bioclip/tree/main

      The DeepForest crop model Source Code: CropModel

      Rationale:
      Develop a BIOCLIP backbone for the CropModel, enabling improved accuracy and efficiency in crop classification tasks. This project will focus on integrating the BIOCLIP architecture into the CropModel framework.

      About Bioclip
      BioCLIP is a foundation model for the tree of life, built using CLIP architecture as a vision model for general organismal biology. It is trained on TreeOfLife-10M, our specially-created dataset covering over 450K taxa--the most biologically diverse ML-ready dataset available to date. Through rigorous benchmarking on a diverse set of fine-grained biological classification tasks, BioCLIP consistently outperformed existing baselines by 16% to 17% absolute. Through intrinsic evaluation, we found that BioCLIP learned a hierarchical representation aligned to the tree of life, which demonstrates its potential for robust generalizability.

      Approach:
      Integrate the BIOCLIP architecture into the CropModel framework.
      Evaluate the performance of the BIOCLIP backbone on various airbore wildlife classification datasets. Can it be finetuned? What kind of zero-shot performance does it have?
      Develop a user-friendly interface for using the BIOCLIP backbone within CropModel. Combining prompts with images.
      Expected Outcomes:
      A BIOCLIP backbone for the CropModel.
      Documentation on using the BIOCLIP backbone within CropModel.
      Degree of Difficulty:
      Intermediate, long (350 hours)
      Skills:
      Deep learning
      Git/GitHub
      Crop classification models
      Python and Python package deployment
      Mentors:
      @bw4sz
      @henrysenyondo
      @ethanwhite

      Data Retriever

      ~~~~~~~~~~


      Project 1: Translation System for DISCOVER Cookbook
      Synopsis
      This project aims to develop a translation system for the DISCOVER Cookbook, making it accessible to a global audience through automated and community-driven translations. See the #175 and some related issues like #53 and #54

      Benefits to the Community
      Providing multilingual support will enhance accessibility and inclusion, allowing more people worldwide to benefit from the DISCOVER Cookbook's content.

      Deliverables
      Develop a translation workflow for the cookbook.
      Integrate a language selection mechanism within the book.
      Implement a system to update translations as content evolves.
      Engage and onboard community translators.
      Technical Details
      Generating Translations

      Evaluate and select a translation service (e.g., Google Translate, Microsoft Translator, or community-driven translation frameworks).
      Establish a workflow ensuring translation consistency and quality.
      Adding Language Switches

      Implement an intuitive UI for selecting languages (e.g., dropdown menu, toggle button).
      Ensure cross-platform compatibility and responsiveness.
      Updating Translations

      Develop a system to track and update translated content when the original text changes.
      Implement a notification mechanism to alert translators of necessary updates.
      Engaging Translators

      Launch a call for contributors via community channels.
      Set up a recognition system for translators (e.g., contributor tagging, acknowledgments).
      Provide guidelines and resources to ensure translation quality.
      Expected Outcomes
      By the end of GSoC 2025, we aim to have a fully functional translation system that enables users to access the DISCOVER Cookbook in multiple languages, with an efficient process for managing updates and engaging translators.

      Complexity
      High

      Duration
      350 hours

      Mentors
      Andy Terrel (@aterrel)
      Kamila Stepniowski (@kamila-NF)

      ~~~~~~~~~~
      Project 2: Versioning System for DISCOVER Cookbook
      Synopsis
      This project involves designing and implementing a versioning system for the DISCOVER Cookbook, allowing users to select different book editions from the website. See the #219.

      Benefits to the Community
      A versioning system will enable users to access different editions of the cookbook, accommodating updates while preserving past versions for reference.

      Deliverables
      Develop a mechanism to manage different book editions.
      Implement a user-friendly interface for selecting versions.
      Ensure seamless integration with the website’s existing structure.
      Technical Details
      Define a structured approach for storing and retrieving book versions.
      Implement a version selector on the website UI.
      Ensure backward compatibility and easy content management.
      Expected Outcomes
      Users will be able to navigate through various editions of the cookbook effortlessly, ensuring continued access to previous versions while benefiting from the latest updates.

      Complexity
      Medium

      Duration
      350 hours

      Mentors
      Andy Terrel (@aterrel)
      Kamila Stepniowski (@kamila-NF)
      Application Guidelines
      Prospective applicants should:

      Review the DISCOVER Cookbook contributor guide and related issues.
      Engage in discussions on our community thread for clarifications.
      Submit a well-structured proposal detailing their approach to the chosen project.
      DISCOVER Cookbook

      ~~~~~~~~~~

      Degree-constrained null models and graph construction
      Description: Network null models, i.e. random graphs with prescribed properties, are an essential tool in the analysis of complex networks. The goal of this project is to develop a detailed computational toolkit within the igraph library for working with degree-constrained null models. This will involve implementing functions that: 1. randomize a graph while preserving its degrees as well as other properties (variants of rewire()); 2. given some degrees, construct a graph (variants of realize_degree_sequence()); 3. determine if a graph with given degrees exists (variants of is_graphical()). While some of this is already possible with igraph, this project will greatly expand the available functionality, considering simple/multigraphs, directed/undirected graphs, bipartite graphs, acyclic graphs, weakly/strongly connected graphs, etc. It will also replace some existing implementations with more algorithmically efficient versions. The work consists of porting existing prototype implementations to the igraph C library, developing unit tests and benchmarks to ensure correctness and performance, and optionally exposing the functionality to Python/R.
      Expected outcome: Implement, document and test functions for testing the existence of, constructing, and randomizing graphs of different types with given degrees. Optionally, expose the functionality in igraph's Python or R interface.
      Mentors: @Tagl and @szhorvat.
      Recommended skills: Knowledge of C and basic C++; Interest in and some experience with graph theory and algorithms.
      Expected time commitment: 175 hrs; a larger project of 350 hrs can be discussed.
      Difficulty: Medium.
      
      ~~~~~~~~~~
      Community detection guide
      Description: This project involves developing a detailed and practical network community detection guide using igraph. The two review articles Community detection in graphs and Community detection in networks: A user guide can be used as a starting point for developing the content. Tentative topic list: 1. explanation of community detection methods and their tradeoffs 2. the concept of modularity 3. controlling the number of communities; resolution parameters 4. partition similarity measures 5. hierarchical clustering 6. consensus clustering 7. significance of community structure 8. overlapping communities; clique percolation 9. visualization techniques
      Expected outcome: An executable document (such as Jupyter notebook, R Markdown or Mathematica notebook) that demonstrates tasks related to community detection using igraph. This must be done in at least one of Python or R, and may optionally be translated to additional languages (including Mathematica).
      Mentors: @szhorvat and @RU-Lokamruth
      Recommended skills: Knowledge of Python or R; Technical writing; Basic familiarity with network science and an willingness to dive deep into the theory of community detection.
      Expected time commitment: 90 hrs or 175 hrs, depending on the amount material covered, and whether the guide is developed for one or multiple programming languages.
      Difficulty: Easy to medium.
      
      ~~~~~~~~~~
      Interface to network data repositories
      Description: The goal of this project is to create a framework within igraph's Python interface for directly importing data from online network repositories. The primary repository to use is Netzschleuder. Time allowing, additional repositories can be considered. Candidates with a very strong knowledge of R can discuss implementing this for igraph's R interface instead of Python. The work involves investigating the most convenient format for importing the data from Netzschleuder, potentially developing a new importer if this is deemed necessary, and designing a data import framework, and finally implementing a practical importer for Netzschleuder.
      Expected outcome: Functionality for directly loading network datasets into igraph from the Netzschleuder data repository.
      Mentors: @ntamas and @szhorvat.
      Recommended skills: Python and basic C programming; Interest in network science.
      Expected time commitment: 175 hrs.
      Difficulty: Medium.
      igraph

      ~~~~~~~~~~

      Creating a cookie-cutter backend repository in NetworkX
      Abstract: NetworkX has recently incorporated a backend plugin system based on Python entry-points. This project aims to develop a template backend repository to help developers create their own NetworkX backends with ease. The template will clearly distinguish between the mandatory, optional, and additional features/requirements that a NetworkX backend package needs to have. We expect this template backend to be forked by the developers, and then they would only have to add their backend implementation for the algorithms they want to support at the designated places, and they would not have to care about setting up all the other aspects of a backend unless they want to enable or adopt any of the optional or additional functionalities of a backend. You can start by:

      looking at nx-j4f (a dummy backend) and nx-parallel (a simple backend) for inspiration.

      reading and understanding Backends and Configs documentation.

      Feel free to ask questions or open an issue if you find something hard to understand, as the above documentations are not that well-written.

      Recommended Skills: Python, willingness to roll up your sleeves and dig deep and understand the dispatching mechanism in NetworkX, and ability to take feedback and iterate on your work.

      Expected Outcome: A “ready-to-fork” and comprehensive backend template in the NetworkX organization.

      Expected time commitment: ~350 hours project

      Complexity: Medium

      Interested Mentors: @Schefflera-Arboricola, @dschult

      ~~~~~~~~~~

      Adding embarrassingly parallel graph algorithms in nx-parallel
      Abstract: nx-parallel is a NetworkX backend that uses joblib for implementing parallel graph algorithms. Currently, only some of the NetworkX algorithms are implemented in nx-parallel. We expect the contributor to find embarrassingly parallel graph algorithms from the wide variety of graph algorithms implemented in NetworkX and then write their parallel implementations in nx-parallel. You can start by looking at:

      the implementations of existing algorithms in nx-parallel for inspiration.

      Joblib docs: Embarrassingly parallel for loops

      Find more details in Issue#82.

      Recommended Skills: Python, willingness to roll up your sleeves and dig deep and understand nx-parallel’s infrastructure, and ability to take feedback and iterate on your work.

      Expected Outcome: 3 parallel graph algorithms (~175 hours), or 7 (~350 hours), implemented in nx-parallel.

      Complexity: Medium

      Interested Mentors: @Schefflera-Arboricola, @dschult

      ~~~~~~~~~~

      Pedagogical Interactive Notebooks for Algorithms Implemented in NetworkX
      Abstract: NetworkX has a wide variety of algorithms implemented. Even though the algorithms are well documented, explanations of the ideas behind the algorithms are often missing and we would like to collect these, write Jupyter notebooks to elucidate these ideas and explore the algorithms experimentally, and publish the notebooks at networkx/notebooks. The goal is to gives readers a deeper outlook behind standard network science and graph theory algorithms and encourage them to delve further into the topic.

      Recommended Skills: Python, Jupyter notebooks, graph algorithms.

      Expected Outcome: A collection of Interactive Jupyter notebooks which explain and explore network algorithms to readers and users of NetworkX. For example, see this notebook on Geometric Generator Models

      Complexity: Depending on the algorithms you are interested to work on.

      Interested Mentors: @MridulS, @rossbar, @Schefflera-Arboricola

      Expected time commitment: This project can be either a medium project (~175 hours) or a large project (~350 hours). The contributor is expected to contribute 2-3 pedagogical interactive notebooks for the medium duration project and 4-5 notebooks for the long duration project.

      Incorporate a Python library for ISMAGs isomorphism calculations
      Abstract: A team from Sandia Labs has converted the original java implementation of the ISMAGS isomorphism routines to Python. They have invited us to incorporate that code into NetworkX if we are interested. We’d like someone to learn the ISMAGS code we currently provide, and the code from this new library and figure out what the best combination is to include in NetworkX moving forward. That could be two separate subpackages of tools, or more likely a combination of the two sets of code, or a third incantation that combines good features from each.

      Recommended Skills: Python, graph algorithms.

      Expected Outcome: A plan for how to best incorporate ISMAGS into NetworkX along with code to do that incorporation.

      Interested Mentors: @dschult, @rossbar

      Expected time commitment: This project will be a full time 10 week project (~350 hrs).

      ~~~~~~~~~~

      Centrality Atlas
      Abstract: The goal of this project would be to produce a comprehensive review of network centrality measures. Centrality is a central concept in network science and has many applications across domains. NetworkX provides many functions for measuring various types of network centrality. The individual centrality functions are typically well-described by their docstrings (though there’s always room for improvement!); however, there currently is no big-picture overview of centrality. Furthermore, many of the centrality measures are closely related, but there is no documentation that describes these relationships.

      Recommended Skills: Python, literature review, technical writing

      Expected Outcome: An executable document that provides an overview and applications of network centrality measures. Potential outputs include (but are not limited to): an article for nx-guides (see above) and/or an example gallery for centrality measures.

      Interested Mentors: @dschult, @rossbar, @Schefflera-Arboricola

      Expected time commitment: Variable, though a high-quality review article would be expected to take several months of dedicated research (~350 hours).


      NetworkX

      ~~~~~~~~~~

      Bioframe
      Level: Mid / Hard
      Expected Size: 350h

      Bioframe provides a framework for genomic data analysis using Pandas DataFrames, including genomic interval arithmetic.

      Expected Outcomes:
      Improved access to genome assembly metadata in Python via the NCBI Datasets API.
      Extended support for 2D genomic intervals (Issue #25).
      Implementation of operations on binned genomes and their intervals (Issue #116).
      Development of out-of-core genomic interval arithmetic for large-scale genomic data.
      Required Skills:
      Python
      Data science with Python (numpy/pandas)
      Background in mathematics
      Mentors:
      Geoff Fudenberg, Anton Goloborodko, Nezar Abdennur

      Publication: https://academic.oup.com/bioinformatics/article/40/2/btae088/7613967

      ~~~~~~~~~~

      Cooler
      Level: Medium
      Expected Size: 350h



      Cooler is the standard storage format and Python package for Hi-C and 3C+ data based on HDF5 format, designed for storage and manipulation of extremely large Hi-C datasets at any resolution, but is not limited to Hi-C data in any way. These massive heatmaps can be explored using a multiscale genome browser such as HiGlass and analyzed with a growing array of downstream analysis software, including cooltools.

      Expected Outcomes:
      Implementation of the powerful and flexible Zarr storage system as an alternative and cloud-friendly backend for cooler.
      Development of an Xarray-based API for genomic heatmaps via cooler.
      Resolution of API differences between Zarr and HDF5.
      Required Skills:
      Python
      Numpy
      Familiarity with at least one of HDF5, Zarr, or Xarray
      Mentors:
      Nezar Abdennur, Thomas Reimonn, Conrad Bzura

      Publication: https://academic.oup.com/bioinformatics/article/36/1/311/5530598

      ~~~~~~~~~~

      Cooltools
      Level: Hard
      Expected Size: 350h

      Cooltools a suite of computational tools to perform various downstream analytical workflows on genomic contact maps in cooler files. The individual datasets are typically much larger than what can fit memory at once, demanding an out-of-core data processing approach. The unified CLI + Python API design facilitates creating workflows on high-performance computing clusters as well as in custom data analysis notebooks or simple scripts. As the key part of interpreting and extracting biological insights from Hi-C and 3C-based datasets, Open2C maintains a collection of detailed educational tutorials on key concepts in 3C+ data analysis using interactive notebooks based largely on cooltools; see open2c_examples.

      Expected Outcomes:
      Benchmarking and optimization of scalable, sparse matrix factorization methods for Hi-C data.
      Migration of log-smoothing code to a dedicated repository (Issue #505).
      Improvements in parallelization and process optimization.
      Required Skills:
      Python data science stack (numpy/pandas)
      Background in linear algebra
      Mentors:
      Geoff Fudenberg, Ilya Flamer

      Publication: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012067

      ~~~~~~~~~~

      Pairtools
      Level: Medium
      Expected Size: 350h

      Pairtools is a simple and fast command-line framework for low-level stream-based processing of sequencing data from a 3C+ experiment. Pairtools fulfills the fundamental step of 3C+ data processing: detecting genomic contacts from experimental sequencing data and provides tools to sort, manipulate, filter, and classify these pairs,to design feature-rich pipelines for specialized experimental protocols or studies, as well as perform quality assessment of billions of contacts detected in a given experiment.

      Expected Outcomes:
      Integration of the new binary pairs format based on Apache Parquet.
      Turning the pairtools CLI into a domain-specific language (DSL) allowing on-demand pipeline construction.
      Exploration of intermediate representations for multi-contact data.
      Required Skills:
      Python
      Numpy and pandas
      CLI tool design following Unix-style guidelines
      Mentors:
      Anton Goloborodko

      Reference: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012164

      ~~~~~~~~~~

      Liftover_2D
      Level: Medium
      Expected Size: 350h

      Liftover_2D is a new tool in progress for fast and effective conversion of chromatin interactions between genome assemblies and bin schemes, integrating with the Open2C framework.

      Expected Outcomes:
      Development of an efficient model for contact pair conversion between assemblies.
      Implementation of an API and CLI for file conversion.
      Performance benchmarking against existing alternatives.
      Required Skills:
      Python
      Numpy, pandas, polars
      CLI tool design following Unix and Scientific Python style guidelines
      Mentors:
      Aleksandra Galitsyna

      





      Open2C

      ~~~~~~~~~~

      1) Adding More Optimizer Interfaces to optimagic
      Project Overview
      Complexity: Beginner to Intermediate. Requires solid Python programming skills
      and basic understanding of numerical optimization. Familiarity with different
      optimization algorithms is a plus.
      Duration: 90h, 175h, or 350h. The scope can be adjusted based on the student's
      background and the number of optimizers they choose to integrate.
      Mentors: @janosg (@timmens)
      The core of optimagic is an internal optimizer interface that makes it really easy to add new optimizers. Just as an example: wrapping optimizers from scipy or NlOpt took less than 50 lines of code per optimizer on average (e.g. here. This is possible because all of the heavy lifting is done in an algorithm agnostic way. This includes basic tests for each optimizer.

      The main things that need to be done to add an optimizer to optimagic are:

      Translate the names of all frequently occurring tuning parameters to our naming scheme and find good and descriptive names for the remaining ones
      Translate the optimizer output to an optimagic.InternalOptimizeResult
      Provide information about the optimizer via the mark.minimizer decorator.
      Create a subclass of Algorithm and do the actual optimization in _solve_internal_problem
      Create benchmarks and improve the default values of tuning parameters.
      Write documentation

      We are happy to help you with the first optimizer to make the process as smooth as possible.

      Why is this important?

      There is no single "best" optimization algorithm that works well for all problems. Look here and here for examples. Different algorithms have different strengths and weaknesses, and the best choice often
      depends on the specific characteristics of the objective function (e.g., smoothness,
      dimensionality, presence of constraints). By providing access to a wider range of
      optimizers, optimagic empowers users to experiment and find the most efficient
      solution for their particular problem. This also reduces the need for users to learn
      the intricacies of multiple optimization packages.

      Project Goals:

      The core idea is to wrap additional optimizers, giving them a consistent interface
      within optimagic's minimize function.

      A good starting point for optimizers you could wrap is:

      Powell's gradient-free optimizers via PRIMA
      Optimizers from Nevergrad
      Optimizers from Bayesian Optimization
      Migrad via iminuit
      SNOPT, SLSQP, and others via PyOptSparse (or direct wrapping)
      Knitro (https://www.artelys.com/app/docs/knitro/2_userGuide/gettingStarted/startPython.html)
      Optimizers from ensmallen via pyensmallen
      Optimizers from the book "Practical Mathematical Optimization" (source code available from authors to be vendored in optimagic)
      Optimizers from the argmin package (in Rust)
      However, this list is not exhaustive, and you can propose other optimizers. The long run goal of optimagic is to support any optimizer with Python bindings!

      Expected Output:

      Minimal Goal (90h): Wrap and document the optimizers from one optimizer library listed above. Write tests for the optimizers and benchmark their performance using optimagic’s built-in benchmarking capabilities
      Intermediate Goal (175h): Add extensive benchmarking and improve the default values for the tuning parameters of the algorithms you added.
      Main Goal (350h): Add half of the optimizers listed above to optimagic
      Stretch Goal: Add all of the optimizers listed above to optimagic

      ~~~~~~~~~~

      
      2) Enabling Backend-Agnostic Plotting in optimagic
      Project Overview
      Complexity: Beginner to intermediate. Requires solid Python programming skills and
      experience with designing user-friendly interfaces. Familiarity with at least one
      plotting library (e.g., Matplotlib, Seaborn, Plotly) is essential. Some design skills and knowledge of color theory are a bonus.
      Duration: 175h
      Mentors: @timmens (@janosg)
      This project aims to increase the flexibility of optimagic's plotting functions by
      allowing users to choose their preferred plotting backend. Currently, optimagic relies
      completely on Plotly for visualizations. This project will introduce a mechanism to
      dynamically select the plotting backend (e.g., Matplotlib, Seaborn, or Plotly), giving
      users more control over the appearance and interactivity of their plots.

      Why is this important?

      Different users have different preferences and requirements for plotting. Some may
      prefer the static, publication-quality plots of Matplotlib, while others may need the
      interactive features of Plotly, or the aesthetic style of Seaborn. By allowing users to
      choose their backend, optimagic becomes more adaptable to diverse workflows and avoids
      imposing a single plotting library on all users.

      Project Goals:

      Design a Backend Selection Mechanism: Develop a clean and user-friendly way for
      users to specify their desired plotting backend. This could involve:

      A backend argument in plotting functions (e.g., slice_plot(..., backend="matplotlib")).
      A global configuration setting that sets the default backend.
      Implement Backend Support: Adapt the existing plotting functions to work with at
      least two backends (e.g., Matplotlib and Plotly). This will involve:

      Separating all code that is not related to the actual plotting (e.g. the code for generating or transforming the data that is going to be plotted) from the actual plotting code.
      Creating separate code paths within the plotting functions to generate plots using
      the selected backend.
      Abstracting common plotting operations (e.g., setting titles, labels, legends) to
      minimize code duplication.
      Add Documentation and Examples: Clearly document the new backend selection
      mechanism and provide examples demonstrating how to use different backends.

      Expected Output:

      Intermediate Goal (175h): A modified set of optimagic's plotting functions (e.g.,
      criterion_plot, params_plot, slice_plot) that accept a backend argument and can generate plots using at least Matplotlib/seaborn and Plotly. This includes clear documentation
      and usage examples for each supported backend.
      Main Goal (350h): Add support for more backends (e.g. bokeh, Altair)
      Stretch Goal: Add support for plots in dark and light mode and style the plots for all backends in a recognizable optimagic design and make sure all plots are accessible for users with vision impairments


      optimagic

      ~~~~~~~~~~

      Project Title: Add to the pvlib example gallery
      Project Description: The pvlib example gallery is a collection of stand-alone python scripts showing examples of using pvlib to model various aspects of solar power. It is organized roughly by modeling topic/pvlib module. Most topics have only one or two examples that only cover a small part of the relevant pvlib functionality. Some parts of pvlib don't even have a topic section yet! This project's goal is to add new examples in one or more gallery topic areas. Proposals for any topic areas are welcome, but here are some gaps that would be great to address:

      New topic: examples of customizing pvlib's ModelChain class for common use cases
      New topic: examples of using pvlib.iotools to retrieve and parse weather data that then gets passed on to the modeling part of pvlib
      Existing topics: flesh out with additional examples
      Expected Outcomes: The primary outcome is a set of python scripts in docs/examples. A secondary outcome is to identify improvements to pvlib-python for usability and flexibility.

      Skills Required / Preferred: some python required, familiarity with solar power modeling.

      Mentors: Adam R. Jensen arajen@dtu.dk Kevin Anderson ksande@sandia.gov

      Length: 175 hours

      Difficulty: Easy

      ~~~~~~~~~~

      

      Project Title: Benchmarking and Profiling
      Project Description: pvlib python has a small set of benchmarks (see here and here) to test how long various models take to execute and whether performance is improving or slowing down. However, only a small fraction of the package is currently benchmarked. Solar power simulation often requires analyzing very long (multi-year) or high-resolution (sub-hour) time-series, therefore benchmarking performance and profiling is important to analysts. The goal of this project is to implement a broader and more cohesive set of AirSpeed Velocity (asv) benchmarks to measure and record performance over time, and to identify bottlenecks for improvement.

      Expected Outcomes: One or more pvlib modules is fully covered by asv benchmarks

      Skills Required / Preferred: some python required, curiosity, desire to learn, knowledge of asv, profiling, or benchmarks desirable

      Mentors: Adam R. Jensen arajen@dtu.dk, Kevin Anderson ksande@sandia.gov

      Length: 175 hours

      Difficulty: Medium

      ~~~~~~~~~~

      Project Title: Automating parameter estimation
      Project Description: A key part of the PV modeling ecosystem is the CEC module database. pvlib uses a processed version of this database produced periodically by the SAM team. When the underlying CEC database updates, it would be nice to automate the SAM team's process so that the processed version is updated as well. This project is to adapt the manual parameter estimation process currently used by the SAM team and create a robust codebase that can perform this parameter estimation in a hands-off fashion.

      Expected Outcomes: A new repository in the pvlib organization implementing the parameter estimation process, and ideally a scheduled GitHub Action to execute the process.

      Skills Required / Preferred: some experience with optimization required, familiarity with PV I-V modeling preferred

      Mentors: Cliff Hansen cwhanse@sandia.gov

      Length: 350 hours

      Difficulty: Hard

      ~~~~~~~~~~

      Project Title: Compatibility with the Array API
      Project Description: An exciting development in the Python ecosystem is the Python array API standard, a uniform interface across the various array libraries (NumPy, Xarray, JAX, etc). Historically, pvlib has been written for compatibility with NumPy arrays and Pandas Series, but making use of the Array API to expand compatibility to other array libraries could be very beneficial. A successful proposal for this project will include some investigation about what it would take to adopt the Array API across pvlib.

      Expected Outcomes: A plan/roadmap for adopting the Array API, Array API compatibility in several pvlib modules, and automated tests ensuring compatibility across the various array packages.

      Skills Required / Preferred: familiarity with various array libraries and automated testing in CI

      Mentors: Kevin Anderson ksande@sandia.gov, Adam R. Jensen arajen@dtu.dk

      Length: 350 hours

      Difficulty: Hard
      pvlib

      ~~~~~~~~~~

      Adding type hints to PyBaMM models
      PyBaMM (Python Battery Mathematical Modelling) has evolved significantly since 2019 as a framework for battery modeling applications. While the focus on performance optimization has led to impressive speed improvements across PyBaMM and the time taken from conducting an experiment to its industrial impact, it has introduced complexity that can make code validation and maintenance challenging. This project aims to systematically introduce static typing to PyBaMM’s codebase, particularly focusing on the pybamm.models component and surrounding areas, to enhance code safety and improve the developer experience.

      The current lack of type hints in PyBaMM creates several challenges. Silent failures in the validation of model arguments often only surface at runtime, making debugging difficult and time-consuming. New contributors frequently struggle to understand the expected input and output types for functions and methods, leading to a steeper learning curve. This absence also limits IDE support for code completion and error detection, making model development less efficient for researchers. Additionally, maintaining API consistency across different parts of the API becomes more challenging without clear type definitions, and numerical operations can fail unexpectedly due to unclear data type expectations.

      Hence, this project seeks to implement a comprehensive typing system to improve PyBaMM’s codebase. By enhancing code reliability through static type checking, we can catch errors earlier in the development process. The addition of clear type signatures will serve as implicit documentation, making the codebase more accessible to new contributors. This improvement in tooling support will accelerate development workflows and make maintenance and refactoring tasks more manageable. Furthermore, the typing system will facilitate better integration with downstream scientific libraries that rely on PyBaMM, such as PyBOP and other upcoming projects.

      The scope could be expanded to include more sophisticated items towards a stretch goal if time permits. This might include creating separate type stub files for improved modularity, developing custom types for battery-specific validation, and extending type coverage to additional modules beyond the core models.

      Technical details
      The implementation of the typing system will require careful evaluation of different approaches by the student, and they can explore either inline type hints in existing code, or separate .pyi stub files for backward compatibility, or the creation of a standalone pybamm-stubs package, or potentially a hybrid approach combining multiple methods. Each approach has its own trade-offs in terms of maintenance burden, backward compatibility, and ease of implementation – the student is expected to survey the existing strategy adopted by Scientific Python libraries and choose the most suitable approach for PyBaMM.

      Previously, type hints were added to the expression tree via pybamm-team/pybamm#3578, which can serve as a reference for the student.

      The type system design will require particular attention to several key areas. The student may need to create custom types for battery-specific parameters, ensuring they accurately represent the domain concepts. The system must handle NumPy array types and dimensional analysis effectively, define clear type hierarchies for different battery models, and manage type compatibility with scientific computing libraries. The implementation of generic types for flexible model arguments will also prove to be essential for maintaining the PyBaMM framework’s versatility.

      Expected outcomes
      Type system architecture: documentation of typing strategy and conventions, type hierarchy design for battery models, integration plan with existing codebase

      Implementation: type hints for core pybamm.models API, custom type definitions for battery-specific components as needed, a short migration guide for adding types to other modules

      Validation: CI integration with type checkers (Mypy, Pyright, basedmypy) as pre-commit hooks, documentation for type checking workflow and updates to the contributing guide

      Documentation: Updated API documentation with type information, and a guide for downstream libraries on utilizing type information provided by PyBaMM

      Desired skills
      Some experience with static typing in Python is beneficial, but not required.
      Python programming experience, Git version control, and GitHub workflow for open-source projects
      An affinity for reading lots of code and documentation
      An interest in scientific computing and battery modeling (prior experience not required)
      As a plus, knowledge on how to use scientific computing libraries (NumPy, SciPy)
      Some understanding of continuous integration providers (GitHub Actions, etc.) is beneficial, but not required.
      Difficulty
      Easy. This project is suitable for a 175-hour duration.

      Potential mentors
      Arjun Verma
      Agriya Khetarpal

      ~~~~~~~~~~
      Adding a spirally wound geometry for thermal simulations in PyBaMM
      With the increasing demand for high-performance batteries, accurate thermal modeling of battery behavior is essential. A key challenge is the interaction between electrochemical and thermal dynamics in complicated battery geometries, which affects performance, safety, and lifespan. This project aims to develop a framework for the addition of coupled electrochemical-thermal simulations in PyBaMM in higher-dimensional geometries (e.g. cylindrical)

      This project aims to couple the electrochemical models already available in PyBaMM, such as the SPM or DFN, with a higher-dimensional thermal model. As a proof of concept, the model will be used to simulate temperature distributions throughout the cell under different operating conditions.

      As a first step, a 3D thermal model will be implemented in PyBaMM with a constant heat source term. This will require adding new 3D meshes and spatial methods to PyBaMM (ideally by adding an existing 3D Finite Volume package as a dependency, such as Gmsh, Meshlib, Salome, etc). Next, this thermal model will be coupled with an electrochemical model, which will provide the heat source term. Finally, the coupling will be made two-way so that the lumped temperature from the 3D model feeds back into the electrochemical model.

      As a stretch goal, the project will explore the integration of 3D temperature profiles obtained from the spirally wound 3D thermal model back into the electrochemical model. This would enable feedback coupling, where the electrochemical model depends on the temperature distribution of the 3D model, providing a foundation for more complex coupling strategies in future research.

      Expected outcomes
      The expected outcome of this study is a proof-of-concept 3D thermal model implemented in PyBaMM, along with the necessary meshing and discretization capabilities. It includes a computational framework for electrochemical-thermal coupling on new cell geometries, and the implementation of a spirally wound geometry for thermal simulations in PyBaMM.

      Desired skills
      Python programming experience, Git version control, and GitHub workflow for open-source projects
      An interest in scientific computing and battery modeling
      Experience with numerical methods for solving differential equations
      Experience with meshing libraries (e.g. Finite Volumes or Finite Elements) is desirable but not required
      As a plus, knowledge of how to use scientific computing libraries (NumPy, SciPy, SUNDIALS)
      Difficulty
      Hard. This project is suitable for a 350-hour duration.

      Potential mentors
      Robert Timms
      Nachiketh Grandhi

      ~~~~~~~~~~
      Adding a dispatching mechanism for third-party models
      With a constantly expanding user base and community, including and working with third-party battery models has become a hassle for PyBaMM users. This project aims to develop a standardized framework for the integration, distribution, and dynamic utilization of third-party battery models implemented with PyBaMM, addressing current limitations in accessibility for users with varying technical backgrounds.

      This project serves as an extension of the cookiecutter project (GSoC 2024), which aimed to reduce the entry barrier for building and distributing PyBaMM projects with the community. This project will build on top of the 2024 project, aiming to establish a standardized model distribution and dispatching framework with seamless PyBaMM integration. The project will define guidelines for structuring models and documentation to facilitate easy distribution and dynamic loading of models. The models will be distributed via model entry points through a new dispatching API for PyBaMM.

      Additionally, the mentee may need to enhance the existing copier template to enforce standardized plugin structures for third-party models, as a parallel primary goal of this project. The packaging and distribution system of the template will be refactored to comply with the new model entry points/dispatch API of PyBaMM. To streamline model retrieval, the mentee will have to design a system incorporating a serverless indexing mechanism for pulling third-party models using the PyBaMM third-party model registries, the registries would contain compatibility and constraint scope. The project will also implement caching and lazy loading mechanisms to optimize performance as a stretch goal. Read fsspec for reference.

      The student will have an opportunity to learn software engineering with Python, including adding features, writing tests, writing user-facing documentation, designing examples, and building CI/CD pipelines. Additionally, their work will be a significant open-source contribution to scientific computing and and expanding battery modeling research as it will create an easy to use PyBaMM development ecosystem that any researcher could adopt, modify and distribute.

      Expected Outcomes
      A dispatch API that could pass parameters/arguments from PyBaMM to third-party models for seamless integration. The dispatch API would also serve as a mechanism for setting constraints and compatibility checks to verify the parameters before passing them to the loaded model.
      A centralized model registry where constraints for different models can be set up. The constraints in the registry can be defined as JSON or through a configuration file defining information about the model. These constraints should be pre-loaded for checks before loading the model itself.
      Refactored entry points API to accommodate the dispatch API. The entry point would also serve as a loader for these third-party models that are not contained within PyBaMM, collectively, the entry points API and the dispatch API will form a framework for integrating, packaging, and distributing battery models amongst PyBaMM users.
      Updates to the copier template, making it compatible with the new dispatch API, simplifying the setup processes for writing custom models, and better project generation support.
      An effective user experience for using third-party PyBaMM models.
      A detailed and easy to read guide and documentation on building and distributing custom PyBaMM models.
      A caching and lazy loading mechanism for the entry points for efficiency.
      Desired Skills
      Python programming experience, Git version control, and GitHub workflow for open-source projects
      Experience with implementing entry points, building and distributing pure-Python packages is beneficial but not required
      Familiarity with cookiecutter/copier templates and their templating engines
      An interest in scientific computing and battery modeling
      Difficulty
      Medium. This project is suitable for a 350-hour duration.
      PyBaMM

      ~~~~~~~~~~

      Spatial modeling
      This project will build on previous GSoC projects to continue improving PyMCs support for modeling spatial processes. There are many possible algorithms one may choose to work on, such as Gaussian process based methods for point processes like Nearest Neighbor GPs or the Vecchia approximation, and models that are types of Gaussian Markov Random Fields, like CAR, ICAR and BYM models. Implementations of these can be found in the R package CARBayes and INLA.

      Potential mentors:
      Bill Engels
      Chris Fonnesbeck
      Info
      Hours: 350
      Expected outcome: An implementation of one or more of the methods listed above, along with one or more notebook examples that can be added to the PyMC docs demonstrating these techniques.
      Skills required: Python, statistics, GPs
      Difficulty: Medium

      ~~~~~~~~~~
      Implement New Statespace Models
      Linear state space models offer a general framework for implementing a huge number of time series models in PyMC. PyMC-Experimental currently has a statespace module that implements SARIMAX, VARMAX, and structural models. The module helps users with estimation, forecasting, and causal analysis using these models.

      Currently the module does not match all statespace models offered in the statsmodels.tsa.statespace module. In particular, dynamic factor models. This project could implement one or both of these models in the existing statespace framework.

      In addition, the project would produce an example notebook showing how to do analysis with the new model, similar to the SARIMAX notebook found here.

      This project will require interacting with PyTensor, which is the backend used by PyMC. See https://www.pymc.io/projects/docs/en/v5.0.2/learn/core_notebooks/pymc_pytensor.html for more details. An understanding of time series analysis is also helpful, but not a requirement (you can learn as you go).

      Potential Mentors
      Jesse Grabowski
      Info
      Hours: 350
      Expected outcome: New statespace model(s) in the pymc_experimental.statespace module
      Skills required: Python; time series econometrics
      Difficulty: Medium


      PyMC

      ~~~~~~~~~~

      Street-Based Tessellation (momepy)
      An urban space 
      S
      refers to a set of disjoint regions 
      R
      i
      which are usually represented by a partition, e.g., census tract, hexagonal tessellation, grid-like partition. Therefore, a space can be defined as a union of region boundaries 
      S
      =
      ∂
      R
      1
      ,
      ∂
      R
      2
      ,
      …
      ,
      ∂
      R
      n
      such that 
      ∂
      R
      i
      ∩
      ∂
      R
      j
      =
      ∅
      ,
      ;
      ∀
      i
      ≠
      j
      .

      In momepy, we have a definition of Morphological Tesselation (MT) and Enclosed Tessellation (ET) which are crucial for capturing urban morphology characteristics. MT is generated based on voronoi diagrams given building footprints, while ET is an enhanced version of MT that considers natural barriers such as street network, rivers and railways. However, street-based tessellation (ST) is a intuitive way to define a tessellation given natural barriers. ST is a tessellation version that inputs a street network and output city blocks containing geographic entities.

      Morphological Tesselation (Code)
      See example of ST code in Jupyter Notebook
      Objective
      Enhance momepy adding support to Street-Based Tessellation (ST)

      Related Reading
      Momepy paper (Link)
      Morphological Tessellation (Link)
      Enclosed Tessellation (Link)
      Difficulty
      It is considered medium-level project. Note that it will depend on the familiarity with python packaging development.

      Skills:
      knowledge of python (required)
      familiarity with python packaging - OOP, tests, docs - (preferred)
      spatial data science (preferred)
      Mentors
      Germano Barcelos
      Project Size
      Short (~175 hours)

      ~~~~~~~~~~

      Routing Engine (Spatial Optimization - spopt)
      Spopt is one of the subpackages of PySAL which solves spatial optimization problems provinding regionalization, and facility-location models through region and locate modules, respectively. Spatial optimization is a wide research area which also covers routing problems such as vehicle routing. VRP problem aims at determine a set of vehicle routes to perform all (or some) transportation requests with the given set fleet at minimum cost. This problem has many variants and it is a widely research topic.

      Objective
      Develop route engine for spopt. Look at the draft PR.

      Ideas
      Feasibility Check of CVRP
      Split Delivery VRP
      Prize-Collecting VRP
      Related Reading
      Vehicle Routing Problems, Methods, and Applications - Daniele Vigo and Paulo Toth
      PyVRP Resources (Docs, Paper)
      Skills
      interest in vehicle routing and spatial optimization
      knowledge and experience with vehicle routing theories (preferred)
      familiarity with python packaging - OOP, tests, docs - (preferred)
      spatial data science (preferred)
      Difficulty Level
      It is considered hard-level project. This project combine python packaging, spatial optimization theories (operations research and linear algebra)

      Mentors
      Levi John Wolf
      Germano Barcelos
      Project Size
      350 hours

      ~~~~~~~~~~

      Flow Refueling Location Models (Spatial Optimization - spopt)
      Spopt is one of the subpackages of PySAL, which solves spatial optimization problems providing regionalization, and facility-location models through region and locate modules, respectively. Spatial optimization is a wide research area which not only covers facility location modeling, but also includes network coverage problems. Instead of locating central facilities to serve demand at fixed points in space in the traditional location-allocation problems, the flow-capturing location models (FCLM) designed by Hodgson (1990) aim to serve demand consisting of origin-destination flows along their shortest paths. The Flow Refueling Location models (FRLM) was extended from FCLM and was designed originally by Kuby & Lim (2005) to optimise the alternative fuel vehicles (i.e. EVs, hydrogen vehicles) refuelling problems.

      Various extensions and better solution techniques of the models have been designed later on, including deviation FRLM, and the arc-cover-path-cover FRLM formulation. This problem has many variants, and it is a widely researched topic.

      Objective
      Develop FRLM and DFRLM for spopt.

      Ideas
      Develop FRLM based on the arc-cover-path-cover formulation
      Develop DFRLM
      Integrate the input and output for effective open science workflow for similar types of analysis
      Related Reading
      FCLM publication: Hodgson, M. J. (1990). A Flow-Capturing Location-Allocation Model. Geographical Analysis, 22(3), 270–279. https://doi.org/10.1111/j.1538-4632.1990.tb00210.x
      Original FRLM publication: Kuby, M., & Lim, S. (2005). The flow-refueling location problem for alternative-fuel vehicles. Socio-Economic Planning Sciences, 39(2), 125–145. https://doi.org/10.1016/j.seps.2004.03.001
      DFRLM publication: Kim, J.-G., & Kuby, M. (2012). The deviation-flow refueling location model for optimizing a network of refueling stations. International Journal of Hydrogen Energy, 37(6), 5406–5420. https://doi.org/10.1016/j.ijhydene.2011.08.108
      Arc-cover-path-cover FRLM publication: Capar, I., Kuby, M., Leon, V. J., & Tsai, Y.-J. (2013). An arc cover–path-cover formulation and strategic analysis of alternative-fuel station locations. European Journal of Operational Research, 227(1), 142–151. https://doi.org/10.1016/j.ejor.2012.11.033
      Skills
      interest in transportation network location-allocation problems and spatial optimization
      knowledge and experience with network location-allocation theories (preferred)
      familiarity with python packaging - OOP, tests, docs - (preferred)
      spatial data science (preferred)
      Difficulty Level
      It is considered medium-level project. This project combine python packaging, spatial optimization theories (operations research and linear algebra)

      Mentors
      Qunshan Zhao
      Levi John Wolf
      Project Size
      350 hours




      PySAL

      ~~~~~~~~~~

      1 - QuTiP QOC GRAPE and CRAB
      The qutip-qoc package supersedes the qutip-qtrl for everything quantum control related in QuTiP. The GRAPE and CRAB algorithms were implemented in qutip-qtrl almost a decade ago. The qutip-qoc package has a user interface that is more closely aligned with that of the main qutip package. It already has two algorithms coded within it, GOAT and a reinforcement learning based method, and it supports the GRAPE and CRAB through a dependency on qutip-qtrl. The plan is to implement the GRAPE and CRAB algorithms in qutip-qoc directly, using qutip-qtrl for guidance and benchmarks, in order remove the qutip-qoc dependency on qutip-qtrl. The aim of the project is to improve the maintainability of QOC algorithms in QuTiP by removing this dependency and improvements in the code, such as utilizing qutip core functions. The qutip-qoc documentation and tutorial notebooks are also to be updated to include details of these implementations.

      Ideally the project would also include swapping of the dependency of qutip-qip from qutip-qtrl to qutip-qoc. This would give qutip-qip users greater flexibility in quantum circuit control pulse optimization, with the additional the algorithms available in the qutip-qoc package.

      Project size:

      350 hours
      Difficulty:

      Hard
      Deliverables:

      Optimization algorithms that can used within the qutip-qoc package
      Integration of qutip-qoc within the qutip-qip package
      Skills:

      Familiar with Python
      Familiar with Git
      Some understanding of control theory and optimization
      Some understanding of quantum dynamics
      Mentors:

      Alex Pitchford (alex.pitchford@gmail.com)
      Patrick Hopf (hopf.patrick@gmx.de)
      Boxi Li (etamin1201@gmail.com)

      ~~~~~~~~~~
      2 - Hamiltonian Library
      QuTiP has a wide range of quantum operators available for use, with many example Hamiltonians and other dynamics generators (e.g. Lindbladians) demonstrated in the documentation and tutorials. (for brevity we shall refer to all such dynamics generators as 'Hamiltonians'.) However, there is no shared library for these, such that they can be called upon in examples or by users. We see quite often the same Hamiltonian built from scratch in the tutorials and documentations This project would be to create a library of quantum systems ready to use by providing a few physical quantities. Some example of such systems would be:

      Jaynes-Cummings
      Rabi
      Dicke
      common spin-chain models
      etc.
      Ideally these Hamiltonians would be defined in some language agnostic format (e.g. JSON) so that they can be used in other packages such as Quantum Toolkit for Julia. It is important to understand that the Hamiltonians have time (and other) parameter dependencies, so these need to be supported. It would also be good to have method to generate LaTeX representations (and maybe pretty-print text) of the Hamiltonians so that they can be easily rendered in the documentation and tutorials.

      Project size:

      350 hours
      Difficulty:

      Medium
      Deliverables:

      a collection of quantum system descriptions to use in QuTiP (and other packages).
      a clean, intuitive user interface for them.
      tutorial and documentation for each of them.
      a language agnostic format for sharing them.
      Skills:

      Familiar with Python, Jupyter, git and GitHub.
      Good knowledge of quantum mechanics
      Mentors:

      Simon Cross (hodgestar@gmail.com)
      Eric Giguère (eric.giguere@calculquebec.ca)
      Neill Lambert (nwlambert@gmail.com)

      ~~~~~~~~~~
      3 - QuantumToolbox in Julia - Superoperator representations
      QuantumToolbox.jl is a package that has basically the similar syntax with QuTiP but written in Julia programming language.

      In the current version of QuantumToolbox.jl, SuperOperator-type only supports the standard Liouvillian formalism. But there are other useful formalisms such as Choi, Kraus, Stinespring, and 
      χ
      , suitable for different research topics in quantum physics.

      The plan is to implement other formalisms (representations) which are supported by QuTiP into QuantumToolbox.jl. Also, the corresponding functions such as iscptp and conversions between different representations. By using the multiple dispatch feature in Julia, one should be able to further improve the performance.

      Important

      The names, arguments, keyword arguments, and outputs of the new functions must align with QuTiP.

      Caution

      The new implementations should not cause any type-instability or breaks to the current API.

      Project size:

      350 hours
      Difficulty:

      Medium
      Deliverables:

      Implement different superoperator representations.
      Support the conversions between different representations (same functions in QuTiP).
      Integrate these new features into some existing functions which requires SuperOperator.
      Add a new documentation page to describe this implementation in detail.
      Skills:

      Familiar with Julia
      Familiar with Git
      Some understanding of quantum dynamics
      Some understanding of Liouvillian, Choi, Kraus, Stinespring, and 
      χ
      representations
      Mentors:

      Alberto Mercurio (alberto.mercurio96@gmail.com)
      Yi-Te Huang (yitehuang.tw@gmail.com)

      ~~~~~~~~~~
      4 - QuantumToolbox in Julia - Excitation number restricted space
      QuantumToolbox.jl is a package that has basically the similar syntax with QuTiP but written in Julia programming language.

      The excitation number restricted (ENR) space constructs a basis for multipartite systems which contains only states that have an overall number of excitations. This is particularly useful for systems where the model conserves excitation number. It is useful if one wants to reduce memory cost. However, one must be careful in choosing a large enough number of excitations to obtain convergence.

      The plan is to implement the similar functionality within QuTiP (EnrSpace and related functions) into QuantumToolbox.jl. By using the multiple dispatch feature in Julia, one should be able to further improve the performance.

      Important

      The names, arguments, keyword arguments, and outputs of the new functions must align with QuTiP.

      Caution

      The new implementations should not cause any type-instability or breaks to the current API.

      Project size:

      350 hours
      Difficulty:

      Medium
      Deliverables:

      Implement the ENR space.
      Support some basic functions (same as QuTiP) to generate common quantum states and operators in ENR space.
      Integrate these new features into some existing functions, especially the functions that could change tensor structures (such as tensor and ptrace).
      Add a new documentation page to describe this implementation.
      Add a tutorial and give an example to demonstrate this feature.
      Skills:

      Familiar with Julia
      Familiar with Git
      Some understanding of quantum dynamics
      Some understanding of fock state and excitation number restricted space
      Mentors:

      Alberto Mercurio (alberto.mercurio96@gmail.com)
      Yi-Te Huang (yitehuang.tw@gmail.com)



      Qutip

      ~~~~~~~~~~


      1) Bridging Simulation-Based Inference (SBI) and Probabilistic Programming
      Project Overview
      Complexity: Intermediate. Requires solid Python programming skills, basic understanding of PyTorch and basic knowledge of Bayesian inference concepts (likelihood, posterior, prior, MCMC, variational inference).
      Duration: 175-350h, depending on background and prior experience.
      Mentors: @janfb (@manuelgloeckler)
      This project aims to connect the power of simulation-based inference (SBI) with the flexibility of probabilistic programming languages (PPLs) like PyMC and Pyro. SBI lets us perform Bayesian inference even when we don't have a traditional likelihood function – instead, we use a simulator to generate data. SBI learns an approximate likelihood from these simulations. PPLs, on the other hand, provide powerful tools for building and performing inference with complex Bayesian models, including hierarchical models. This project will bridge the gap, making it easier to use SBI-learned likelihoods within the rich modeling environment of PPLs.

      Why is this important?

      Many real-world problems involve hierarchical structures – for example, analyzing data from multiple individuals, each with multiple measurements, or modeling variations across different experimental conditions. PPLs excel at handling these hierarchical models. Currently, using SBI with these kinds of complex models is challenging. This project will unlock the ability to combine the strengths of both approaches: using SBI to handle the simulator, and a PPL to handle the hierarchical structure and advanced inference techniques.

      Project Goals:

      The core idea is to make the "synthetic" (approximate) likelihoods learned by SBI compatible with the model specification and inference engines like Pyro. This will allow users to:

      Define a simulator (as usual in SBI).
      Train an SBI method (NLE, or NRE) to learn an approximate likelihood.
      Use this learned likelihood within a Pyro model, just like any other likelihood function.
      Use this learned likelihood within a (hierachical) Bayesian model.
      Perform inference (e.g., MCMC or Variational Inference) using the PPL's built-in tools.
      Expected Output:

      Minimal Goal: A working example demonstrating inference on a simple model (e.g., inferring the mean of a Gaussian distribution) within Pyro, where the likelihood is a "synthetic likelihood" learned by SBI.
      Main Goal: A working example demonstrating inference in a multi-level hierarchical model (e.g., a model with group-level and individual-level parameters) within Pyro, using a synthetic likelihood learned by SBI. This will showcase the power of the integration for more complex, real-world scenarios.
      Stretch goal: Provide infrastructure for defining models and samplers, and integrate this new functionality into sbi itself.
      
      ~~~~~~~~~~
      2) Implementing the Simformer Algorithm for Simulation-Based Inference
      Project Overview
      Complexity: High. Requires strong Python programming skills, solid understanding of PyTorch, familiarity with deep learning concepts (e.g., neural networks, transformers, backpropagation, optimization), basic knowledge of Bayesian inference.
      Duration: 350h, depending on background and prior experience.
      Mentors: @manuelgloeckler (@deismic)
      This project focuses on implementing the Simformer algorithm, a novel approach to SBI introduced by Gloeckler et al. (2024), within the sbi Python package. The Simformer offers a unified, "all-in-one" framework for SBI, integrating posterior estimation, likelihood estimation, and posterior predictions. This project involves translating the theoretical concepts and mathematical formulation of the Simformer into a robust, well-tested, and user-friendly PyTorch implementation within sbi.

      This project provides a chance to implement and contribute a state-of-the-art deep learning algorithm for simulation-based inference, gaining practical experience with Transformer architectures and contributing to a growing area of research.

      Background: What is the Simformer?

      Traditional SBI methods often specialize in either posterior estimation (e.g., NPE) or likelihood estimation (e.g., NLE). The Simformer breaks this dichotomy by framing SBI as a sequence modeling problem. It leverages a Transformer architecture, commonly used in natural language processing, to model the joint distribution of parameters and simulation outputs. This allows the Simformer to, at inference time, perform arbitrary conditioning of the joint, e.g., condition on the observed data to approximate the posterior, or condition on parameters to approximate the likelihood; all within a single, unified framework. This additionally allows the application of sbi to problems with dynamic dimensionality (i.e. functional variables). The architecture is described in detail in Gloeckler et al. (2024) and in a helpful blog post (https://transferlab.ai/pills/2024/all-in-one-simulation-based-inference/). The original implementation is available in JAX at https://github.com/mackelab/simformer.

      Project Goals:

      Implement the Core Simformer components in PyTorch: Translate the mathematical formulation of the Simformer (as described in the paper and blog post) into Python code using PyTorch, using the JAX implementation as a guideline. This includes:

      Designing and implementing the Transformer architecture, specifically tailored for SBI, in PyTorch. This will likely involve adapting components from existing Transformer implementations. Specifically, it should allow for the adjustment of the attention mask to incorporate information about the dependence structure present in the task.
      Developing efficient data loading and preprocessing routines to handle simulation data in a format suitable for the Transformer. Specifically, this requires implementing a (learnable) Tokenizer that will lower all variables in the joint distribution to a token representation that can be processed by the Transformer.
      Integrate with the sbi Package: Ensure the PyTorch implementation of the Simformer seamlessly integrates with the existing sbi framework. This involves:

      Implementing the appropriate loss functions for training the Simformer (as described in the paper). This should, at best, seamlessly integrate with the current infrastructure for training diffusion models within the sbi package.
      Creating a user-friendly API for training and using the Simformer, consistent with other sbi inference methods.
      Writing comprehensive unit tests to ensure the correctness and robustness of the implementation.
      Demonstrate Functionality and Performance:

      Create tutorial notebooks showcasing how to use the Simformer for various inference tasks (parameter estimation, etc.).
      Compare the performance of the Simformer to existing SBI methods (e.g., NPE, NLE, NRE) using the mini-sbibm benchmark available in sbi. This will demonstrate the advantages and potential limitations of the Simformer in different scenarios.
      Expected Output:

      MVP: A working PyTorch implementation of the core Simformer algorithm, integrated with sbi, which can be trained on a simple benchmark problem (e.g., inferring parameters of a Gaussian distribution).
      Main Goal: A fully functional and well-tested PyTorch-based Simformer implementation within sbi, with a user-friendly API, comprehensive documentation, and example notebooks demonstrating its use on various inference tasks and comparing its performance to other SBI methods.
      Stretch Goal: Explore and implement extensions to the Simformer improving training stability/efficiency with alternative training objectives, support for joint distributions with dynamic dimension, and flexible and structured Tokenizers that allow to assignment of embedding nets to variables of a certain data type (i.e. a cnn for an image), compressing it to a single (or few) tokens.
      
      ~~~~~~~~~~
      3) From "Stringly Typed" to "Strongly Typed" Arguments in sbi
      Project Overview
      Complexity: Intermediate. Strong Python programming skills, e.g., understanding of Python data structures like dictionaries and lists, and familiarity with object-oriented programming, understanding of Python type hints. concepts (e.g., neural networks, transformers, backpropagation, optimization), basic knowledge of Bayesian inference.
      Duration: 175-350, depending on background and prior experience.
      Mentors: @janosg (@janfb)
      This project aims to improve the robustness and developer experience of the sbi package by transitioning from "stringly typed" arguments to “strongly typed” arguments in key functions and classes (see this blogpost or this talk for details). Currently, sbi often uses strings to specify options, particularly for algorithm choices (e.g., density_estimator="maf") and configuration dictionaries (e.g., mcmc_parameters: Dict[str, Any]). While flexible, this approach is prone to errors like typos, lacks autocompletion in IDEs, and makes it harder to discover available options. This project will introduce a more structured and type-safe way to specify these options, inspired by techniques used in Rust and outlined in the optimagic enhancement proposal (https://optimagic.readthedocs.io/en/latest/development/ep-02-typing.html).

      This project offers a hands-on opportunity to learn and apply best practices in modern Python development, focusing on type safety and API design, skills that are highly valuable in any software engineering role.

      Project Goals:

      Identify Key Areas for Improvement: Analyze the sbi codebase to identify functions and classes where stringly typed arguments are prevalent and could be replaced with stronger typing. This includes, but is not limited to:

      density_estimator arguments in inference methods.
      mcmc_method arguments.
      Configuration dictionaries like mcmc_parameters.
      Implement Strong Typing: Replace string-based options with more robust alternatives, such as:

      Enums: For choices with a fixed set of valid options (e.g., different density estimators or MCMC methods). This provides autocompletion and prevents typos. This follows the pattern discussed in the provided blog post.
      Pydantic Models (or Dataclasses): For configuration dictionaries, replacing Dict[str, Any] with structured classes that define the expected fields and types. This provides validation and autocompletion for configuration parameters. This is inspired by the optimagic enhancement proposal.
      Update Documentation and Tests: Thoroughly update the documentation and unit tests to reflect the changes in the API. Ensure backward compatibility where possible, or provide clear deprecation warnings and migration instructions.

      Expected Output:

      MVP: A refactored version of at least one key function (e.g., a function accepting a density_estimator argument) that uses enums instead of strings for option selection. This should include updated documentation and tests.
      Main Goal: A significant portion of the sbi codebase refactored to use enums and Pydantic models (or dataclasses) for argument specification, leading to improved type safety, better developer experience, and reduced risk of user errors. This should include comprehensive documentation and updated unit tests.
      Stretch Goal: Explore generating documentation automatically from the typed definitions.
      Pages 3
      Find a page…
      Home
      GSoC_2025_Projects
      Google Summer of Code with SBI
      Introduction
      Timeline
      How to apply
      Projects ideas
      1) Bridging Simulation-Based Inference (SBI) and Probabilistic Programming
      Project Overview
      2) Implementing the Simformer Algorithm for Simulation-Based Inference
      Project Overview
      3) From "Stringly Typed" to "Strongly Typed" Arguments in sbi
      Project Overview
      Release workflow
      Clone this wiki locally
      https://github.com/sbi-dev/sbi.wiki.git
      Footer

      sbi

      ~~~~~~~~~~

      Translation of Modelica Standard Library Components to the ModelingToolkit Standard Library
      The ModelingToolkit Standard Library is a standard library of pre-built components for the ModelingToolkit acausal modeling system. It can be improved by porting pre-built physical components from other acausal modeling systems, such as the Modelica Standard Library

      Recommended Skills: Background knowledge in mathematical modeling.

      Expected Results: Ported components and tutorials from the Modelica Standard Library to the ModelingToolkit Standard Library

      Mentors: Chris Rackauckas

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy to Medium depending on the chosen subtasks.

      ~~~~~~~~~~

      LinearSolve.jl Distributed Algorithms
      LinearSolve.jl is the higher level interface for solving linear systems Ax=b which allows algorithms like ODE solvers and nonlinear solvers to easily switch between using sparse direct methods, Krylov methods, and more. However, automating the solution of linear systems when A is a distributed matrix across an HPC cluster would allow many large applications to become easy. The global of this project would be to integrate with libraries such as Elemental.jl, PartitionedArrays.jl, and PETSc.jl to make this easy.

      Recommended Skills: Background knowledge in numerical linear algebra and parallel computing.

      Expected Results: New parallel algorithms wrapped into LinearSolve.jl

      Mentors: Chris Rackauckas

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy to Medium depending on the chosen subtasks.

      ~~~~~~~~~~

      NonlinearSolve.jl Globalization, Quasi-Newton and Efficiency
      There are many ways to solve f(x)=0, and there are many applications, from partial differential equation solvers to optimizers, which use nonlinear solvers in the inner loop. NonlinearSolve.jl is the core nonlinear solver library of the Julia programming language and it currently exists mostly as a wrapper to older codes (some written in Fortran), but this has many downsides. Those wrapped libraries do not support GPU-acceleration, they do not have fast paths with static arrays for small equations, they do not support higher precision arithmetic, etc. The goal of this project would be to extend the native Julia nonlinear solvers beyond Newton-Raphson and demonstrate the capabilities with this extended feature set. Features can include globalizing methods, Quasi-Newton (Broyden etc.), nonlinear preconditioning, line searches, and more.

      Recommended Skills: Background knowledge in numerical analysis.

      Expected Results: New tutorials in SciMLTutorials and benchmarks in SciMLBenchmarks.

      Mentors: Chris Rackauckas and Utkarsh

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy to Medium depending on the chosen subtasks.

      ~~~~~~~~~~

      Benchmarks and Tutorial Writing
      Many university classes use the SciML ecosystem for its teaching, and thus classrooms all over the world will be improved. Tutorials that capture more domains will allow professors teaching biological modeling courses to not have to manually rewrite physics-based tutorials to match their curriculum, and conversion of READMEs to documentation will help such professors link to reference portions for these tools in their lecture notes.

      Additionally, these benchmarks are a widely referenced cross-language benchmark of differential equations, which gives a standard between Python, R, Julia, MATLAB, and many C++ and Fortran packages. Improving the technical writing around the benchmarks can make this set of documents more widely accessible, and enlarging the scope of topics will help individuals of all programming languages better assess the methods they should be choosing for their problems.

      Note that this will include authorship for SciML publications which use the benchmarks.

      Recommended Skills: Background knowledge in numerical analysis and modeling.

      Expected Results: New tutorials in SciMLTutorials and benchmarks in SciMLBenchmarks.

      Mentors: Chris Rackauckas

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy.

      ~~~~~~~~~~



      Generalized multistart optimization strategies
      Multistart refers to a global optimization methodology wherein local solvers are run from multiple points in the parameter space and once they converge to local minimas this can then be used to either further refine the solution or a minimum operation of the obtained local minimas for getting the global minima.

      There has been some work to implement two approaches already namely, a simple quasimontecarlo initialization and using the Particle Swarm Optimization method for some iterations. There is scope for coming up with novel methods here as well thus making this project very suitable for research focused candidates.

      So a generalized implemetation of these strategies, like TikTak and improving the ones mentioned above to be compatible with all solvers supported by Optimization.jl will be impactful. This should be done through the EnsembleProblem interface thus leveraging the already available parallelization infrastructure which is essential in these methods for performance.

      Recommended Skills: Background knowledge in optimization and parallelization.

      Expected Results: A suite of multistart methods available trhough the SciML EnsembleProblem interface.

      Mentors: Vaibhav Dixit, Chris Rackauckas

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy to Hard depending on the chosen subtasks.

      ~~~~~~~~~~

      Improved interfacing between ModelingToolkit.jl and Optimization.jl
      GalacticOptim.jl wraps multiple optimization packages local and global to provide a common interface. GalacticOptim.jl adds a few high-level features, such as integrating with automatic differentiation, to make its usage fairly simple for most cases, while allowing all of the options in a single unified interface. Currently ModelingToolkit.jl is provided as one of the AD backend options and can also be used to define the optimization problem symbolically directly. Thsi support is currently limited and doesn't cover things like constraints yet, but there is tremendous value to be gained by leveraging symbolic simplification possible with ModelingToolkit. This project would also cover integrating into MathOptInterface to by using the symbolic expressions generated from MTK, in addition to the current MOI wrapper available in Optimization.

      Recommended Skills: Background knowledge of standard machine learning, statistical, or optimization techniques. Familiarity with the relevant packages, ModelingToolkit, Optimization and MathOptInterface would be helpful to get started.

      Expected Results: Feature complete symbolic optimization problem interface.

      Mentors: Vaibhav Dixit, Chris Rackauckas

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy to Medium depending on the chosen subtasks.

      ~~~~~~~~~~

      First class OptimizationState to support machine learning optimization better
      A core requirement in a lot of optimization tasks involves being able to observe intermediate state of the solvers, especially in ML adjacent problems. Recently an OptimizationState object has been added to Optimization.jl for supporting these usecases. There is a lot of scope for making this more performant and featureful as well as extending it to more solver wrappers. This project is quite open eneded and can be designed as per the candidates motivation. Some specific things could be utilizing the derivative oracle calls to store their values without recomputing it, allowing visualizations of the training loop through predefined callbacks, using the state for non-standard stopping criterias in global optimization etc.

      Recommended Skills: Background knowledge in optimization and familiarity with machine learning workflows.

      Expected Results: Improvements to OptimizationState and its interactions with solvers.

      Mentors: Vaibhav Dixit, Chris Rackauckas

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy to Medium depending on the chosen subtasks.

      ~~~~~~~~~~

      SciML native Line Search implementations
      A variety of optimization solvers rely on utilizing line search within their routine. The current julia implementation for these line searching methods exist in LineSearches.jl and is used quite extensively, but it is quite an old package and leaves some performance on the table. An implementation of these methods compatible with SciML solvers for nonlinear and optimization problems will be an impactful contribution for making these solvers efficient.

      Recommended Skills: Background knowledge in optimization.

      Expected Results: A package with implementation of linesearch methods.

      Mentors: Vaibhav Dixit, Avik Pal, Utkarsh, Chris Rackauckas

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy to Medium depending on the chosen subtasks.

      ~~~~~~~~~~



      Native Julia ODE, SDE, DAE, DDE, and (S)PDE Solvers
      The DifferentialEquations.jl ecosystem has an extensive set of state-of-the-art methods for solving differential equations hosted by the SciML Scientific Machine Learning Software Organization. By mixing native methods and wrapped methods under the same dispatch system, DifferentialEquations.jl serves both as a system to deploy and research the most modern efficient methodologies. While most of the basic methods have been developed and optimized, many newer methods need high performance implementations and real-world tests of their efficiency claims. In this project students will be paired with current researchers in the discipline to get a handle on some of the latest techniques and build efficient implementations into the *DiffEq libraries (OrdinaryDiffEq.jl, StochasticDiffEq.jl, DelayDiffEq.jl). Possible families of methods to implement are:

      Global error estimating ODE solvers

      Implicit-Explicit (IMEX) Methods

      Geometric (exponential) integrators

      Low memory Runge-Kutta methods

      Multistep methods specialized for second order ODEs (satellite simulation)

      Parallel (multithreaded) extrapolation (both explicit and implicit)

      Parallel Implicit Integrating Factor Methods (PDEs and SPDEs)

      Parallel-in-time ODE Methods

      Rosenbrock-W methods

      Approximate matrix factorization

      Runge-Kutta-Chebyshev Methods (high stability RK methods)

      Fully Implicit Runge-Kutta (FIRK) methods

      Anderson Acceleration

      Boundary value problem (BVP) solvers like MIRK and collocation methods

      BDF methods for differential-algebraic equations (DAEs)

      Methods for stiff stochastic differential equations

      Many of these methods are the basis of high-efficiency partial differential equation (PDE) solvers and are thus important to many communities like computational fluid dynamics, mathematical biology, and quantum mechanics.

      This project is good for both software engineers interested in the field of numerical analysis and those students who are interested in pursuing graduate research in the field.

      Recommended Skills: Background knowledge in numerical analysis, numerical linear algebra, and the ability (or eagerness to learn) to write fast code.

      Expected Results: Contributions of production-quality solver methods.

      Mentors: Chris Rackauckas, Yingbo Ma, Kanav Gupta and Utkarsh

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy to Hard depending on the chosen subtasks.

      ~~~~~~~~~~

      Performance enhancements for differential equation solvers
      Wouldn't it be cool to have had a part in the development of widely used efficient differential equation solvers? DifferentialEquations.jl has a wide range of existing methods and an extensive benchmark suite which is used for tuning the methods for performance. Many of its methods are already the fastest in their class, but there is still a lot of performance enhancement work that can be done. In this project you can learn the details about a wide range of methods and dig into the optimization of the algorithm's strategy and the implementation in order to improve benchmarks. Projects that could potentially improve the performance of the full differential equations ecosystem include:

      Alternative adaptive stepsize techniques and step optimization

      Pointer swapping tricks

      Quasi-Newton globalization and optimization

      Cache size reductions

      Enhanced within-method multithreading, distributed parallelism, and GPU usage

      Improved automated method choosing

      Adaptive preconditioning on large-scale (PDE) discretizations

      Recommended Skills: Background knowledge in numerical analysis, numerical linear algebra, and the ability (or eagerness to learn) to write fast code.

      Expected Results: Improved benchmarks to share with the community.

      Mentors: Chris Rackauckas and Yingbo Ma

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy to Hard depending on the chosen subtasks.

      ~~~~~~~~~~

      Discretizations of partial differential equations
      There are two ways to approach libraries for partial differential equations (PDEs): one can build "toolkits" which enable users to discretize any PDE but require knowledge of numerical PDE methods, or one can build "full-stop" PDE solvers for specific PDEs. There are many different ways solving PDEs could be approached, and here are some ideas for potential projects:

      Automated PDE discretization tooling. We want users to describe a PDE in its mathematical form and automate the rest of the solution process. See this issue for details.

      Enhancement of existing tools for discretizing PDEs. The finite differencing (FDM) library MethodOfLines.jl could be enhanced to allow non-uniform grids or composition of operators. The finite element method (FEM) library FEniCS.jl could wrap more of the FEniCS library.

      Full stop solvers of common fluid dynamical equations, such as diffusion-advection-convection equations, or of hyperbolic PDEs such as the Hamilton-Jacobi-Bellman equations would be useful to many users.

      Using stochastic differential equation (SDE) solvers to efficiently (and highly parallel) approximate certain PDEs.

      Development of ODE solvers for more efficiently solving specific types of PDE discretizations. See the "Native Julia solvers for ordinary differential equations" project.

      Recommended Skills: Background knowledge in numerical methods for solving differential equations. Some basic knowledge of PDEs, but mostly a willingness to learn and a strong understanding of calculus and linear algebra.

      Expected Results: A production-quality PDE solver package for some common PDEs.

      Mentors: Chris Rackauckas and Alex Jones

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Medium to Hard depending on the chosen subtasks.

      ~~~~~~~~~~

      Jump Process Simulation Algorithms
      Jump processes are a widely used approach for modeling biological, chemical and epidemiological systems that can account for both stochastic interactions, and spatial transport, of proteins/particles/agents. JumpProcesses.jl provides a library of optimized solvers for exactly simulating jump processes, including recently added solvers that allow for the simulation of spatially-distributed jump processes (where particles/agents move on graphs or general meshes). A variety of possible projects to extend and enhance the current tooling include

      Adding additional stochastic simulation algorithms such as partial propensity methods (either explicitly or via wrapping the C++ pSSALib).

      Exploring cache-optimized table and queue data structures to improve performance of current solvers.

      Extending the current graph and spatial algorithms to support interactions between particles/agents at different spatial locations, and developing tooling to automatically calculate transition rates via PDE discretization techniques.

      Extending StochasticDiffEq.jl with τ-leap algorithms to enable the approximate, but more computationally efficient, simulation of jump processes.

      Extending JumpProcesses and StochasticDiffEq with hybrid simulation capabilities, allowing models that mix ODEs, SDE and jump processes and can dynamically partition model components between each mathematical representation as needed to maintain physical accuracy.

      Extending JumpProcesses's simulation algorithm collection to better support time-dependent rate functions and delays.

      Recommended Skills: An understanding of how the Gillespie method or basic jump process simulation algorithms work, and experience using DiffEqJump.jl to simulate jump processes.

      Expected Results: Completing one or more of the preceding improvements to the jump process simulation tooling.

      Mentors: Samuel Isaacson and Chris Rackauckas.

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Medium to Hard depending on the chosen subtasks.


      Modelingtoolkit based Parser for Physics Informed Neural Networks (PINNs)
      NeuralPDE.jl uses ModelingTookit.jl to define differential equations for solving PINNs. Currently, the loss functions for PINNs are constructed manually, which limits their applicability to a specific subset of systems. By utilizing ModelingToolkit.jl, loss functions could be generated symbolically, enabling broader generalization across diverse systems and improving flexibility. To achieve this, parsing the equations symbolically is essential.

      Recommended Skills: Background knowledge in symbolics and machine learning.

      Expected Results: New Parser for lowering from Modelingtoolkit systems to loss functions.

      Mentors: Chris Rackauckas and Sathvik Bhagavan

      ~~~~~~~~~~

      Improvements to Physics-Informed Neural networks (PINN) for solving differential equations
      Neural networks can be used as a method for efficiently solving difficult partial differential equations. Efficient implementations of physics-informed machine learning from recent papers are being explored as part of the NeuralPDE.jl package. The issue tracker contains links to papers which would be interesting new neural network based methods to implement and benchmark against classical techniques.

      Recommended Skills: Background knowledge in numerical analysis and machine learning.

      Expected Results: New neural network based solver methods.

      Mentors: Chris Rackauckas and Sathvik Bhagavan

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy to Hard depending on the chosen subtasks.

      ~~~~~~~~~~

      Improvements to Neural and Universal Differential Equations
      Neural ordinary differential equations have been shown to be a way to use machine learning to learn differential equation models. Further improvements to the methodology, like universal differential equations have incorporated physical and biological knowledge into the system in order to make it a data and compute efficient learning method. However, there are many computational aspects left to explore. The purpose of this project is to enhance the universal differential equation approximation abilities of DiffEqFlux.jl, adding features like:

      Improved adjoints for DAEs and SDEs

      Non-neural network universal approximators

      Various improvements to minibatching

      Support for second order ODEs (i.e. symplectic integrators)

      Continuous normalizing flows and FFJORD

      See the DiffEqFlux.jl issue tracker for full details.

      This project is good for both software engineers interested in the field of scientific machine learning and those students who are interested in perusing graduate research in the field.

      Recommended Skills: Background knowledge in numerical analysis and machine learning.

      Expected Results: New and improved methods for neural and universal differential equations.

      Mentors: Chris Rackauckas and Anas Abdelrehim

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Medium to Hard depending on the chosen subtasks.

      ~~~~~~~~~~

      Accelerating optimization via machine learning with surrogate models: Surrogates.jl
      In many cases, when attempting to optimize a function f(p) each calculation of f is very expensive. For example, evaluating f may require solving a PDE or other applications of complex linear algebra. Thus, instead of always directly evaluating f, one can develop a surrogate model g which is approximately f by training on previous data collected from f evaluations. This technique of using a trained surrogate in place of the real function is called surrogate optimization and mixes techniques from machine learning to accelerate optimization.

      The purpose of this project is to further improve Surrogates.jl by: adding new surrogate models, adding new optimization techniques, showcasing compatibility with the SciML ecosystem and fixing unwanted behaviour with some current surrogate models. The issue tracker contains list of new surrogate models which can be added.

      Recommended Skills: Background knowledge of standard machine learning, statistical, or optimization techniques. Strong knowledge of numerical analysis is helpful but not required.

      Expected Results: Improving Surrogates.jl with new surrogate models and new optimization techniques.

      Mentors: Chris Rackauckas and Sathvik Bhagavan

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Medium to Hard depending on the chosen subtasks.

      ~~~~~~~~~~

      Tools for global sensitivity analysis
      Global Sensitivity Analysis is a popular tool to assess the effect that parameters have on a differential equation model. A good introduction can be found in this thesis. Global Sensitivity Analysis tools can be much more efficient than Local Sensitivity Analysis tools, and give a better view of how parameters affect the model in a more general sense. The goal of this project would be to implement more global sensitivity analysis methods like the eFAST method into GlobalSensitivity.jl which can be used with any differential equation solver on the common interface.

      Recommended Skills: An understanding of how to use DifferentialEquations.jl to solve equations.

      Expected Results: Efficient functions for performing global sensitivity analysis.

      Mentors: Chris Rackauckas and Vaibhav Dixit

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy to Medium depending on the chosen subtasks.

      ~~~~~~~~~~
      Symbolic Matrix and Tensor Calculus
      Matrix calculus is the ability to do calculus directly on matrix expressions rather than requiring the performance of the calculus on the scalar quantities. For example, x'*A*x + c*sin(y)'*x differntiates to 2*A*x + c*sin(y). Currently, Symbolics.jl does not support matrix calculus, only scalar calculus, so the work would be to expand the support to include handling of symbolic matrices.

      For more information, see this paper and this paper.

      Recommended Skills: High school/freshman calculus and a willingness to learn symbolic computing

      Expected Results: A working implementation of matrix calculus

      Mentors: Chris Rackauckas and Aayush Sabharwal

      Duration: 350 hours

      ~~~~~~~~~~

      Symbolic Integration in Symbolics.jl
      Implement the heuristic approach to symbolic integration. Then hook into a repository of rules such as RUMI. See also the potential of using symbolic-numeric integration techniques (https://github.com/SciML/SymbolicNumericIntegration.jl)

      Recommended Skills: High school/Freshman Calculus

      Expected Results: A working implementation of symbolic integration in the Symbolics.jl library, along with documentation and tutorials demonstrating its use in scientific disciplines.

      Mentors: Chris Rackauckas and Aayush Sabharwal

      Duration: 350 hours

      ~~~~~~~~~~

      Automatically improving floating point accuracy (Herbie)
      Herbie documents a way to optimize floating point functions so as to reduce instruction count while reorganizing operations such that floating point inaccuracies do not get magnified. It would be a great addition to have this written in Julia and have it work on Symbolics.jl expressions. An ideal implementation would use the e-graph facilities of Metatheory.jl to implement this.

      Mentors: Chris Rackauckas, Aayush Sabharwal, Alessandro Cheli

      Duration: 350 hours

      ~~~~~~~~~~

      Reparametrizing ODE models with scaling transformations
      Project Overview: Many ODE models appearing in applications have hidden symmetries which makes the solution of data fitting problem nonunique. StructuralIdentifiability.jl offers algorithms for proposing new coordinates for the model removing this redundancy. The approach used at the moment relies on heavy computations and may be very slow for larger models. Scaling is a particular type of reparametrizations which can be discovered much faster. The goal of the project would be to implement such faster algorithms (adapting them to the context of identifiability assessment) and integrate into StructuralIdentifiability.jl.

      Mentors: Alexander Demin, Gleb Pogudin

      Project Difficulty: Medium

      Estimated Duration: 350 hours

      ~~~~~~~~~~


      Parameter identifiability analysis
      Parameter identifiability analysis is an analysis that describes whether the parameters of a dynamical system can be identified from data or whether they are redundant. There are two forms of identifiability analysis: structural and practical. Structural identifiability analysis relates changes in the solution of the ODE directly to other parameters, showcasing that it is impossible to distinguish between parameter A being higher and parameter B being lower, or the vice versa situation, given only data about the solution because of how the two interact. This could be done directly on the symbolic form of the equation as part of ModelingToolkit.jl. Meanwhile, practical identifiability analysis looks as to whether the parameters are non-identifiable in a practical sense, for example if two parameters are numerically indistinguishable (given possibly noisy data). In this case, numerical techniques being built in DiffEqSensitivity.jl, such as a nonlinear likelihood profiler or an information sensitivity measure can be used to showcase whether a parameter has a unique enough effect to be determined.

      Recommended Skills: A basic background in differential equations and the ability to use numerical ODE solver libraries. Background in the numerical analysis of differential equation solvers is not required.

      Expected Results: Efficient and high-quality implementations of parameter identifiability methods.

      Mentors: Chris Rackauckas

      Expected Project Size: 350 hour.

      Difficulty: Hard.

      ~~~~~~~~~~

      Model Order Reduction
      Model order reduction is a technique for automatically finding a small model which approximates the large model but is computationally much cheaper. We plan to use the infrastructure built by ModelingToolkit.jl to implement a litany of methods and find out the best way to accelerate differential equation solves.

      Recommended Skills: A basic background in differential equations and the ability to use numerical ODE solver libraries. Background in the numerical analysis of differential equation solvers is not required.

      Expected Results: Efficient and high-quality implementations of model order reduction methods.

      Mentors: Chris Rackauckas

      Expected Project Size: 350 hour.

      Difficulty: Medium to Hard depending on the chosen subtasks.

      ~~~~~~~~~~

      Automated symbolic manipulations of differential equation systems
      Numerically solving a differential equation can be difficult, and thus it can be helpful for users to simplify their model before handing it to the solver. Alas this takes time... so let's automate it! ModelingToolkit.jl is a project for automating the model transformation process. Various parts of the library are still open, such as:

      Support for DAEs, DDEs, and SDEs

      Pantelides algorithm for DAE index reduction

      Lamperti transforms

      Automatic construction of adjoint solutions

      Tearing in nonlinear solvers

      Solving distributed delay equations

      Recommended Skills: A basic background in differential equations and the ability to use numerical ODE solver libraries. Background in the numerical analysis of differential equation solvers is not required.

      Expected Results: Efficient and high-quality implementations of model transformation methods.

      Mentors: Chris Rackauckas and Yingbo Ma

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Medium to Hard depending on the chosen subtasks.

      ~~~~~~~~~~

      Symbolic chemistry and calculating reaction rate coefficients
      Catalyst is a great tool to model chemical reactions, but often reaction rate coefficients are usually suspect. There are well established methods to calculate what these coefficients should be given the activation energy of a reaction. We want to automate part of this modeling, allowing the user to provide atom-bond graphs and have coefficients determined for free.

      Data structures to represent chemical species, compounds, ions, and isotopes

      Arrhenius equation calculation of reaction rate coefficients k(T)

      Automatically balancing reactions using above data structures

      Verifying conservation of energy for each Reaction in a ReactionSystem

      Recommended Skills: Strong understanding of chemistry and Julia open-source programming, particularly Symbolics.jl and ModelingToolkit.jl.

      Expected Results: Define an interface for providing a Symbolics.jl object that contains relevant metadata for calculating activation energy and reaction rate coefficients using the Arrhenius equation.

      Mentors: Chris Rackauckas, Anand Jain and Samuel Isaacson

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy to Medium depending on the chosen subtasks.

      ~~~~~~~~~~

      Symbolic Analysis and Transformations of Chemical Reaction Networks
      Catalyst.jl provides the ability to create symbolic models of chemical reaction networks, generate symbolic differential equation and stochastic process models from them, and offers some limited ability to analyze the symbolic chemical reaction networks. There are a variety of ways Catalyst.jl's core capabilities could be expanded, including adding

      tooling for detecting and classifying steady-states and their equilibria for mass-action systems (i.e. polynomial ODE systems).

      tooling to infer from reaction network graph representations possible dynamic and equilibrium behaviors using chemical reaction network theory.

      methods to reduce the size of reaction networks via the elimination of conserved species.

      support for elimination of aliased species between different Catalyst model components to enable more modular composition of Catalyst-based models.

      new ModelingToolkit-based systems to represent τ-leaping and/or abstract master equation representations, along with translation layers to generate such systems from Catalyst reaction network models.

      new ModelingToolkit-based representations for hybrid systems mixing reactions across modeling scales (ODEs, SDEs, jump processes), along with translation layers to generate such systems from Catalyst reaction network models.

      the ability for Catalyst reactions to allow random variables or general parameters to encode reaction stoichiometry, with updates to ModelingToolkit and Symbolics to support the generation of corresponding ODE, SDE and jump process models.

      Recommended Skills: Strong understanding of ODE models for chemical systems and Julia open-source programming, particularly Symbolics.jl and ModelingToolkit.jl.

      Expected Results: Extend Catalyst with one or more of the preceding features, with corresponding ModelingToolkit updates, enabling users to build, analyze, and simulate Catalyst-derived models incorporating the new components.

      Mentors: Samuel Isaacson and Chris Rackauckas.

      Expected Project Size: 175 hour or 350 hour depending on the chosen subtasks.

      Difficulty: Easy to Hard depending on the chosen subtasks.




      SciML

      ~~~~~~~~~~


      loo package:
      The loo package is one of most used packages for cross-validation of Bayesian models and is an integral part of the Stan ecosystem. It has over 3 million downloads and several thousand citations. As advancements are made and new methods are developed, it is important that the loo package stays up to date. This project would add new validation methods and diagnostics, and improve the usability of existing functions to create a unified interface for all the implemented measures of model evaluation. Time required: 350h Contact: Aki Vehtari

      ~~~~~~~~~~
      
      bayesplot package:
      The bayesplot package is part of the Stan ecosystem and widely used for visualizing the results of Bayesian inference. The package has 2 million downloads and over one thousand citations. This project would add new visualisations, especially for predictive checks of discrete and categorical outcomes, as well as keep the documentation of the package updated to ensure low barrier for future contributions. Time required: 350h Contact: Aki Vehtari
      Stan

      ~~~~~~~~~~

      Implementation of Finite volume method in TNL
      In this project, the student will implement the fundamental components of the Finite Volume Method (FVM) in TNL. The goal is to develop a solver for either the compressible or incompressible Navier-Stokes equations in 3D. TNL provides essential data structures for unstructured numerical meshes, sparse matrices, and linear system solvers, so the student's primary focus will be on implementing the main numerical scheme.
      Thanks to TNL’s unified interface, no prior knowledge of GPU programming is required. If the student successfully completes this task, they can explore additional directions based on their interests, such as:

      Implementing a semi-implicit or fully implicit solver.
      Adding support for an algebraic multigrid solver for the resulting linear systems.

      Expected outcome: Basic implementation of FVM in TNL.
      Preferred skills: Programming in C++17, fundamental knowledge of FVM or capability to get familiar with basics of this method (see for example references [1,2]). No knowledge of programming of GPUs is necessary for this project.
      Difficulty: intermediate, 350 hours
      TNL

      
      ~~~~~~~~~~

      Project Title: Create and add to an example gallery for toqito
      Project Description:

      The example gallery should be a collection of stand-alone Python scripts showing examples of using toqito to showcase various use cases in quantum information theory research. Most topics have only one or two examples that only cover a small part of the relevant toqito functionality. This project's goal is to create an examples page with tiled thumbnails that link to specific examples and to additional add new examples in one or more gallery topic areas. Proposals for any topic areas are welcome, but here are some gaps that would be great to address:

      New topic: examples of customizing toqito's ExtendedNonlocalGame class for use cases associated to quantum key distribution (QKD), bit commitment (BC), etc.
      New topic: examples that showcase quantum state antidistinguishability (using modules in the state_opt/ directory) to illustrate explicit examples from the literature.
      Existing topics: flesh out with additional examples
      As an ideal example of such a gallery, refer to the scikit-learn examples page as an ideal format for showcasing the examples as well as the scope and style of the examples to include on this page.

      Expected Outcomes: The primary outcome is to create an example gallery page (like the one from scikit-learn) and to populate this page with (at least) 3 - 5 examples that showcase the toqito module for specific quantum computing applications. Some set of these examples could be reworked from the existing documentation page, but at least two of the dedicated examples should be new and showcase a feature that is not currently showcased.

      Skills Required / Preferred: some Python required, familiarity with quantum computing and some linear algebra.

      Mentors: Vincent Russo vincentrusso1@gmail.com, Purva Thakre quantum.purvat@gmail.com

      Length: 175 hours

      Difficulty: Easy

      ~~~~~~~~~~

      Project Title: Benchmarking and Profiling
      Project Description:

      Create a set of benchmarks to test how long various models take to execute and whether performance is improving or slowing down. The goal of this project is to implement a broad and more cohesive set of benchmarks to measure and record performance over time and to identify bottlenecks for improvement. We also would want to create a set of benchmarks compared to other quantum software packages (i.e. QETLAB, Ket.jl, Yao.jl, etc.).

      Expected Outcomes: One or more toqito modules are fully covered by benchmarks

      Skills Required / Preferred: some Python required, curiosity, desire to learn, knowledge of profiling, or benchmarks desirable

      Mentors: Vincent Russo vincentrusso1@gmail.com, Purva Thakre quantum.purvat@gmail.com

      Length: 175 hours

      Difficulty: Medium

      ~~~~~~~~~~

      Project Title: Tools for Quantum State Distinguishability and Exclusion
      Project Description: toqito currently has modules to investigate the subdomains of quantum state distinguishability (ppt_distinguishability.py, state_distinguishability.py, is_distinguishable.py) and quantum state exclusion (is_antidistinguishable.py, state_exclusion.py). The goal of this project will be to create a general module that is able to take as input an ensemble of quantum states (a set of complex-valued vectors and associated probability vector) and to be able to perform various "figure-of-merit" distinguishability and exclusion analyses on the given ensemble.

      Many of the tools used to perform these analyses can be performed by semidefinite programs (SDPs). There are many solvers in Python (cvxpy, picos, etc.) that specialize in the mathematical software to implement these optimizations problems numerically.

      Expected Outcomes: A complete module that is able to process an ensemble of quantum states and successfully perform the corresponding optimization problems that cover figures-of-merit including "minimum-error", "unambiguous", etc. paradigms of quantum state distinguishability and exclusion. In the ideal case, these tools could be directly applied to writing up a paper that focuses on a specific problem in this research domain (contingent on time, expertise, and interest by the student).

      Skills Required / Preferred: Familiarity with linear algebra and convex optimization. While some background in quantum information or quantum computing is useful, this can mostly be abstracted to be concerned with tools like SDPs (semidefinite programs) and the quantum information knowledge can be obtained during the internship.

      Mentors: Vincent Russo vincentrusso1@gmail.com, Purva Thakre quantum.purvat@gmail.com

      Length: 350 hours

      Difficulty: Hard

      ~~~~~~~~~~

      Project Title: Numerical analysis of nonlocal and extended nonlocal games
      Project Description: toqito currently has modules to study both nonlocal (nonlocal_games.py) and extended nonlocal games (extended_nonlocal_games.py). The goal of this project will be to enhance the functionality (specifically of the extended nonlocal game code) and make use of these improvements to apply to solving open questions in the realm of extended nonlocal games. As these games are by proxy less well understood than their less general nonlocal game counterparts, computational methods will likely prove fruitful in resolving open questions.

      For instance, there are a number of directions that one could consider numerically as open questions arising from DOI:10.48550/arXiv.1704.07375.

      Expected Outcomes: A set of computational enhancements and additions to the extended nonlocal game module for additional performance and applicability. Ideally, numerical methods to resolve open questions in extended nonlocal games, and if the student is motivated and inclined, research potential for publication.

      Skills Required / Preferred: Familiarity with quantum information theory. Strong mathematical background with an emphasis on linear algebra. An interest and some level of knowledge on nonlocal games, Bell inequalities, and interactive proof systems is a bonus.

      Mentors: Vincent Russo vincentrusso1@gmail.com, Purva Thakre quantum.purvat@gmail.com

      Length: 350 hours

      Difficulty: Hard
      toqito

      ~~~~~~~~~~
      Project Idea I - Bit-Packing
      Abstract 🗂

      Many engineering and science domains work with data from Analog-to-Digital Converters (ADCs). These ADCs typically return an (unsigned) integer value, e.g., 10 bits or 12 bits. When stored as (u)int16, this creates a substantial overhead. Therefore, we want to investigate if a "bit packing" shuffle filter can be implemented to just pack the data (without using conventional compression techniques) or to pack the data in addition to using existing compression.

      This idea was discussed in the Zarr Benchmarking & Performance meetings (notes here) and multiple participants expressed their interest in this feature. Additional topics discussed:

      Use additional entropy coding step: Huffman, arithmetic, etc.
      Tasks 📝

      We haven’t defined concrete steps for this project yet. We encourage the interested contributor to discuss the procedure/tasks with the mentor. Please read, understand and document existing information about shuffle filters and how they are used in Zarr.

      Check by how much file size can be improved
      Check by how much write speed can be improved (either just packing, or packing and compression)
      Check by how much read speed can be improved (either just packing, or packing and compression)
      Extended Tasks 📝

      Benchmark obtained implementations and present results to the Zarr Benchmarking & Performance group.

      Perhaps a "stretch goal", for hardware-inclined coders, could be to hand-code at least one SIMD-optimized bit-packing algorithm, and compare its performance against an algorithm written purely in a high-level language.

      Project Length ⏰

      175 hours

      Priority ⏩

      Medium

      Complexity 👨🏻‍💻

      Medium

      Potential Mentors 😇

      Vincent Immler
      Akshay Subramaniam

      ~~~~~~~~~~
      Project Idea II - Low-Latency Optimizations
      Abstract 🗂

      Previous investigations within the Zarr Benchmarking & Performance group revealed that when Zarr is used in a low-latency environment (e.g., data is read from a fast SSD) in combination with one-pass statistical algorithms or cryptographic hash functions to process the data, then the burden of I/O is higher than that of the computation, which makes an unoptimized asynchronous prefetch fail.

      Tasks 📝

      The goal of this project is to investigate this problem in a more detailed way, compare to theoretical throughput limits, and perform experiments with the upcoming Zarr V3 version (in particular, with sharded selections over multiple chunks), to either confirm improvements over the previous behavior, or to investigate further improvements that can be realized without a full re-implementation of Zarr-Python. Examples:

      Prefetch continuously through a session and/or more efficient OS interfaces (io_uring)
      Wrap callable function into Zarr for automated iteration through the data
      Check compatibility with Numba for processing outside of the OS-level interfaces
      Benchmark reference:

      https://github.com/zarr-developers/zarr-benchmark
      Extended Tasks 📝

      Benchmark obtained implementations and present results to the Zarr Benchmarking & Performance group.

      Project Length ⏰

      175 hours

      Priority ⏩

      Medium

      Complexity 👨🏻‍💻

      High

      Potential Mentors 😇

      Vincent Immler
      Akshay Subramaniam
      Zarr
     
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/numfocus/
    idea_list_url: https://github.com/numfocus/gsoc/blob/master/2025/ideas-list.md


  - organization_id: 99
    organization_name: OSGeo (Open Source Geospatial Foundation)
    no_of_ideas: 11
    ideas_content: |

      Parallelization of existing tools
      There are several tools that would benefit from parallelization with OpenMP, e.g. r.texture, r.horizon, r.fill.stats, r/v.surf.idw, r.viewshed, v.to.rast, r.grow.distance, v.surf.bspline, ... For overview of current state, see Raster_Parallelization_with_OpenMP.

      Requirements: familiarity with C, OpenMP
      Mentor: Huidae Cho
      Co-mentor: Vaclav Petras, Anna Petrasova
      Project length: 175 or 350 hours (take your pick)
      Rating: medium
      Expected Outcomes: parallelized module or modules, depending on complexity
      Test of skills: suggest/implement solution for https://github.com/OSGeo/grass/issues/2644
      
      ~~~~~~~~~~

      Improve GRASS user experience in Jupyter Notebook

      InteractiveMap in grass.jupyter library
      Python package grass.jupyter was developed during GSoC 2021 to simplify running GRASS from Jupyter Notebooks and displaying data. This project could focus on adding features such as increasing interactivity of displayed data using ipyleaflet, adding API for managing projects and subprojects (i.e., locations/mapsets), creating GUI for commands, ...

      Requirements: Python
      Mentor: Anna Petrasova
      Co-mentor: Vaclav Petras, Helena Mitasova, Corey White
      Project length: 175 or 350 hours (take your pick)
      Rating: easy to medium
      Expected Outcomes: improved user experience when using GRASS through notebooks
      Test of skills: https://github.com/OSGeo/grass/issues/3276, or write a test for grass.jupyter library using python unittest or pytest, more info here.
      
      
      ~~~~~~~~~~
      Add JSON output to different tools in C
      There are several tools in GRASS that would benefit from a JSON-formatted output, see this issue for a list of tools. Besides adding the JSON output, the work would also include adding tests and basic documentation.

      Requirements: C, Python for tests
      Mentor: Vaclav Petras
      Co-mentor: Anna Petrasova, Corey White
      Project length: 175 or 350 hours (take your pick)
      Rating: easy to medium
      Expected Outcomes: one or more (depending on project length and complexity of the tool) tools with well tested JSON output
      Test of skills: Address https://github.com/OSGeo/grass/issues/1044 for r.surf.fractal
      
      ~~~~~~~~~~
      Support writing tests with pytest
      The current testing framework, grass.gunittest, was written before migration to Git/GitHub and when long free runs in 3rd party services were unthinkable. Additionally, some no longer relevant goals were prioritized, such as independence on the current code, detailed custom HTML reports, success tracking over time, and high specialization towards GRASS-specifics.
      grass.gunittest is based on Python unittest package and many projects since then migrated to //pytest//, e.g., GDAL and Numpy. While unittest is inspired by Java's JUnit, pytest is designed to support writing small, readable tests, and uses plain `assert` statements instead of many different assert methods.
      Using pytest should lead to tests which feel more like Python scripts and to minimum of testing-specific code.
      An example issue of grass.gunittest is that it doesn't work well with tests of the main GRASS executable (prominence of `grass ... --exec` is yet another new thing which changed since grass.gunittest was designed).
      Two main things needed:
      Create general comparison functions from the grass.gunittest assert methods so that they can be used with pytest.
      Current grass.script.setup.init function and grass.script.core.create_location function don't work well in the context of a pytest test function. More
      Additional things needed:
      Fixture for pytest to set up and tear down a GRASS session in a temporary mapset.
      Requirements: Python
      Project length: 175 or 350 hours (take your pick)
      Mentor: Vaclav Petras
      Co-mentor: Stefan Blumentrath
      Proposed by: Vaclav Petras
      Rating: easy to medium
      Expected Outcomes: Convenient way of writing tests with pytest
      Test of skills: Fix failing tests and/or write new tests (more is better). Alternatively, addressing a smaller problem in the testing framework is a good task, too.
      
      ~~~~~~~~~~
      New easy-to-use CLI and API for GRASS GIS
      Make running of GRASS GIS modules as easy as it is to run GDAL commands.
      `grass run r.slope.aspect elevation=elevation.tiff slope=slope.tiff aspect=aspect.tiff`
      CLI like GDAL has.
      No GRASS Database, Location, Mapset to deal with.
      No import, export from user perspective.
      Reasonable defaults for things like region.
      CLI and API still allows user to specify any of the above.
      Idea page with details: wiki:GSoC/2021/EasyToUseCliAndApiIdea
      Project length: 350 hours
      Rating: medium
      Requirements:
      Language: Python
      Proposal: Student needs to show sufficient understanding of the GRASS GIS Database structure and significantly extend on text below in terms of more concrete formulation of ideas and identification of missing and existing parts.
      Mentors: Vaclav Petras
      Co-mentors: Stefan Blumentrath, Corey White
      Proposed by: Vaclav Petras
      Expected outcomes: New subcommand which easily runs a GRASS module on GeoTiff and GeoPackage.
      Test and training tasks:
      Solve one of the tickets linked at the idea page.
      Add features to `grass` executable interface:
      Make it possible to associate `*.gxw` files with `grass` executable (#1204) or at least add `--gui-workspace` or preferably just recognize it in the command line (distinguish it from database/location/mapset).
      Extend `--exec` functionality:
      Add `--region` to set a temporary computational region for the execution, e.g. `--region="raster=raster_name"`
      Add `--import-raster=some/file.tiff` which imports (r.import) a raster file (same for vector and similarly for export).
      Add `--link-raster=some/file.tiff` which links (r.external) a raster file (same for vector and similarly for r.external.out).


      
      ~~~~~~~~~~
      GUI: Add space-time datasets support in Data Catalog

      Data catalog
      Currently GRASS Data Catalog shows only raster and vector maps. The goal of this project is to add support for space-time datasets. It is mainly space-time raster datasets. In the next phase of the project support for other types of space-time datasets (vector and 3D raster) could be added. Besides displaying space-time datasets in the layer tree, it is also about adding the equivalent functionality currently available for raster and vector layers from the context menu.

      Requirements: familiar with Python
      Project length: 175 or 350 hours
      Mentor: Martin Landa
      Co-mentor: Anna Petrasova
      Proposed by: Martin Landa
      Rating: medium
      Expected Outcomes: 175 hours basic support for space-time raster datasets; 350 extended support also for other space-time datasets types (vector, 3D raster)
      Test of skills:
      suggest/implement solution for completing https://github.com/OSGeo/grass/issues/2599


      ~~~~~~~~~~

      GRAPH C++ Boost graph algorithms (175/350 hours)

      From Boost Graph 1.56 which is the official minimum version since v3.2. In section 22 (Algorithms), there is a list of algorithms from where:

      Sparse Matrix Ordering Algorithms
      Graph Metrics
      and many more sections
      Have algorithms not yet been implemented on pgRouting
      For the proposal choose one algorithm (175 hours) or two algorithms (350 hours) that are not yet implemented in pgRouting.

      The proposal must include:

      All requirements from GSoC
      All requirements from OSGeo
      The details of the algorithm need to have
      Section: Testing data
      Section: Proposed Documentation
      Consider that the expected products at the end of GSoC are:

      Self Documented Code
      User's Documentation
      Simple pgtap tests
      Section: testing data
      The section must have the following statements

      Link to the Boost example
      CREATE
      INSERT
      SELECT
      A drawing representing the created graph (can be hand made as Graphs do not have geometries)
      That will allow mentors to test data

      Section: Proposed Documentation
      Try to make it look like a pgRouting function documentation

      Notes
      Normally the Boost algorithms come with an example, base your proposal on that example's graph Example:

      From You would need to CREATE TABLE foo ... and INSERT INTO foo ... a PostgreSQL/pgRouting representation of the graph in the example (remember that on C/C++ counting start from 0, but on PostgreSQL counting start from 1)

            Pair edges[14] = { Pair(0,3), //a-d    in PostgreSQL -> (1,4)
                          Pair(0,5),  //a-f
                          Pair(1,2),  //b-c
      ...
                          Pair(5,7),  //f-h
                          Pair(6,7) }; //g-h 
      Then test that the query can be executed and give a result with pgr_dijkstra:

      SELECT * FROM pgr_kingOrdering('SELECT * FROM foo', 1, 7);

      ~~~~~~~~~~

      Migrating and updating the existing CWL runners
      Duration - 150 hrs

      The ZOO-Project-DRU is a server implementation of the OGC API - Processes - Part 1: Core Standard and the OGC API - Processes - Part 2: Deploy, Replace, Undeploy draft specification. To enable the execution of processes resulting from deploying an Earth Observation Application Package encoded in CWL, the ZOO-Project-DRU relies on CWL runners. There are more and more CWL runners. Some are hosted on the EOEPCA repositories for official distribution in the EOEPCA/EOEPCA+ projects; some are on the other organizations. As the project progresses, the code from the different runners may contain generic parts that are repeated in the other runners. The goal of the project is to gather the existing runners under the same organization: the ZOO-Project and organize the repositories, for being able to have a single entry point for all the runners. The Python code should be updated in such a way that it eases the creation of new runners. The same applies to the service templates that are disseminated from different sources.

      Mentor: [Gérald Fenoy, Rajat Shinde,

      Difficulty: Moderate

      Pre-requisites: Python, OGC standards

      Expected Outcome: ZOO-Project tests suite.

      Idea in Detail: We are expecting the following deliverables from the project:

      The selected contributor is expected to propose a way to organize the repositories so that there is a single entry point for all the runners, make the code more generic, potentially by adding abstract classes, and provide documentation on how to create a new runner.

      The contributor is expected to:

      Propose (and demonstrate) a way to efficiently organize the repositories to have a single entry point for all the runners.

      Make the code of the runners more generic.

      Provide documentation on how to implement a new runner.

      List of existing runners:

      https://github.com/EOEPCA/eoepca-zoo-wes-runner
      https://github.com/EOEPCA/zoo-argowf-runner
      https://github.com/EOEPCA/zoo-calrissian-runner
      List of existing templates:

      https://github.com/EOEPCA/eoepca-proc-service-template-wes
      https://github.com/gfenoy/zoo-argo-wf-proc-service-template
      https://github.com/EOEPCA/eoepca-proc-service-template
      https://github.com/eoap/zoo-service-template
      The Contributors are encouraged to reach out toGérald Fenoy and Rajat Shinde for any queries regarding the test mentioned above. The queries can also be posted to OSGeo SOC mailing list - soc(AT)lists(DOT)osgeo(DOT)org or the ZOO Project Slack channel.

      ~~~~~~~~~~

      Ideas 1: Grafana Data Source Plugin for istSOS4
      Large size project - duration 350 hrs

      Mentor: Massimiliano Cannata, Daniele Strigaro, Claudio Primerano
      Difficulty: Moderate
      Pre-requisites: JavaScript/TypeScript, REST-API, React

      Synopsis
      This project aims to develop a Grafana data source plugin for istSOS4, implementing the OGC SensorThings API. The plugin will allow istSOS users to create rich and interactive Grafana dashboards, leveraging any type of query or request supported by istSOS4 and the SensorThings standard.

      Benefits to the Community
      Enhanced Data Visualization: Users will be able to integrate istSOS4 data directly into Grafana, benefiting from its powerful visualization capabilities.
      Flexibility & Customization: The plugin will support the full range of SensorThings API queries, enabling customized and dynamic data representation.
      Open & Interoperable: By aligning with open standards, the solution will foster interoperability with IoT, environmental monitoring, and smart city applications.
      Deliverables
      A fully functional Grafana data source plugin that connects to istSOS4 using SensorThings API.
      Support for real-time data streaming and historical data queries.
      A user-friendly configuration UI for defining data sources and setting up custom queries.
      Comprehensive documentation and examples for easy adoption by the community.
      Ideal Candidate
      Experience with JavaScript/TypeScript and Grafana plugin development.
      Familiarity with REST APIs, istSOS4 open API interface, OGC SensorThings API, and IoT data standards.
      Interest in geospatial data, sensor networks, and real-time monitoring.
      Why This Matters?
      istSOS is a well-established open-source Sensor Observation Service (SOS), and the istSOS4-Things has been recently released but still doesn't have any specific dashboard to view data and perform visual analytics. This project will bridge the gap between sensor data collection and powerful visualization. Researchers, developers, and IoT enthusiasts will benefit from seamless integration with Grafana, empowering data-driven decision-making in environmental monitoring, smart cities, and beyond.

      ~~~~~~~~~~
      
      Ideas 2: Web Administration Interface for istSOS
      Large size project - duration 350 hrs

      Mentor: Massimiliano Cannata, Daniele Strigaro, Claudio Primerano
      Difficulty: Moderate
      Pre-requisites: JavaScript/TypeScript, REST-API, React

      Synopsis
      This project aims to develop a web-based administration interface for istSOS, making it easier to manage and monitor SensorThings API components. The interface will provide a user-friendly way to register, for example, new Sensors and Things, set metadata, and monitor sensor metrics such as received data, transmission delays, and overall system health.

      Benefits to the Community
      Simplified Sensor Management: Users will be able to register, update, and manage SensorThings API components through an intuitive web interface.
      Improved Monitoring & Control: The interface will offer real-time insights into sensor performance, data reception status, and potential transmission delays.
      Enhanced Usability: Eliminates the need for complex API interactions, making istSOS more accessible to researchers, engineers, and IoT enthusiasts.
      Deliverables
      A fully functional web UI for managing istSOS SensorThings components.
      Features for SensrThingsAPI entities (sensor, things, etc.) registration, metadata configuration, and system status monitoring.
      Visual analytics on sensor data reception, delays, and health status.
      Comprehensive documentation and user guides for easy adoption.
      Ideal Candidate
      Experience with JavaScript/TypeScript, React or Vue.js, and backend frameworks (Python/Flask or Node.js).
      Familiarity with REST APIs, OGC SensorThings API, and IoT data management.
      Interest in environmental monitoring, smart cities, and sensor networks.
      Why This Matters?
      Currently, managing istSOS SensorThings API components requires manual API interactions. This project will provide a more intuitive and efficient way to administer istSOS instances, making sensor registration and monitoring more accessible and user-friendly for a broader audience.

      ~~~~~~~~~~
      
      Ideas 3: [small] istSOS setup configuration wizard
      Small size project - duration 90 hrs

      Mentor: Massimiliano Cannata, Daniele Strigaro, Claudio Primerano
      Difficulty: Moderate
      Pre-requisites: JavaScript/TypeScript, REST-API, React

      istSOS Setup Configuration Wizard
      Synopsis
      This project aims to develop a setup configuration wizard with a graphical user interface (GUI) to simplify the deployment of istSOS4 in a Docker environment. The wizard will guide users through the configuration process, generating a valid Docker environment file (.env) to set up the containerized application efficiently.

      Benefits to the Community
      User-Friendly Deployment: Reduces the complexity of setting up istSOS4 by providing an interactive step-by-step configuration process.
      Error Reduction: Ensures that all required settings are properly defined, minimizing misconfigurations and deployment issues.
      Streamlined Docker Integration: Automates the generation of the .env file, making istSOS4 setup more accessible to non-expert users.
      Deliverables
      A web-based or desktop GUI wizard for configuring istSOS4 settings.
      Automatic validation and generation of the .env file for Docker deployment.
      Support for common configuration options, including database settings, API endpoints, and logging preferences.
      Comprehensive documentation and tutorials to assist users in deploying istSOS4.
      Ideal Candidate
      Experience with Python/Flask, JavaScript/React/Vue.js, or Electron.js, streamlit or Tkinter for UI development.
      Familiarity with Docker, environment variables, and containerized applications.
      Interest in automation, environmental monitoring, and open-source GIS solutions.
      Why This Matters?
      Setting up istSOS4 in a Docker-based environment can be challenging, especially for new users. This project will simplify the process, making istSOS4 more accessible to researchers, engineers, and developers, ultimately improving adoption and usability.

      
      
       
    
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/osgeo-(open-source-geospatial-foundation)/
    idea_list_url: https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2025_Ideas


  - organization_id: 100
    organization_name: OWASP Foundation
    no_of_ideas: 35
    ideas_content: |
     
        🔸 Modern UI/UX Overhaul & Lightweight Front-End in React (~350h)
        A complete redesign of BLT’s interface, improving accessibility, usability, and aesthetics. The new front-end will be built with React and Tailwind CSS, ensuring high performance while maintaining a lightweight architecture under 100MB. Dark mode will be the default, with full responsiveness and an enhanced user experience.
        ~~~~~~~~~~
        🔸 Organization Dashboard – Enhanced Vulnerability & Bug Management (~350h)
        Redesign and expand the organization dashboard to provide seamless management of bug bounties, security reports, and contributor metrics. Features will include advanced filtering, real-time analytics, and improved collaboration tools for security teams.
        ~~~~~~~~~~
        🔸 Secure API Development & Migration to Django Ninja (~350h)
        Migrate our existing and develop a secure, well-documented API with automated security tests to support the new front-end. This may involve migrating from Django Rest Framework to Django Ninja for improved performance, maintainability, and API efficiency.
        
        ~~~~~~~~~~
        🔸 Gamification & Blockchain Rewards System (Ordinals & Solana) (~350h)
        Introduce GitHub-integrated contribution tracking that rewards security researchers with Bitcoin Ordinals and Solana-based incentives. This will integrate with other parts of the website as well such as daily check-ins and code quality. Gamification elements such as badges, leaderboards, and contribution tiers will encourage engagement and collaboration in open-source security.
        
        ~~~~~~~~~~
        🔸 Decentralized Bidding System for Issues (Bitcoin Cash Integration) (~350h)
        Create a decentralized system where developers can bid on GitHub issues using Bitcoin Cash, ensuring direct transactions between contributors and project owners without BLT handling funds.
        
        
        ~~~~~~~~~~
        🔸 AI-Powered Code Review & Smart Prioritization System for Maintainers (~350h)
        Develop an AI-driven GitHub assistant that analyzes pull requests, detects security vulnerabilities, and provides real-time suggestions for improving code quality. A smart prioritization system will help maintainers rank issues based on urgency, community impact, and dependencies.
        
        ~~~~~~~~~~
        🔸 Enhanced Slack Bot for Real-Time Security Alerts & Automation (~175h)
        Expand the BLT Slack bot to automate vulnerability tracking, send real-time alerts for new issues, and integrate GitHub notifications and contributor activity updates for teams.
        ~~~~~~~~~~
        OWASP DevSecOps Maturity Model
        Join us in enhancing the DSOMM, a pivotal tool designed to improve the security and operational efficiency of software development processes. We are looking for passionate students to contribute to two major areas: our main application development in JavaScript and our metric analyzer and collector in Java. Whether you are looking to tackle medium-sized challenges or are ready to embark on a larger project, we have exciting opportunities for you.
        To receive early feedback please:
        put your proposal on Google Docs and submit it to the OWASP Organization on Google’s GSoC page in “Draft Shared” mode.
        Please pick “dsomm” as Proposal Tag to make them easier to find for us. Thank you!
        
        
        ~~~~~~~~~~
        Medium Feature Pack for the DSOMM Main Application (JS)
        This pack includes tasks that are crucial for enhancing the user experience and functionality of the DSOMM main application. Contributors will address existing issues and add new features:
        Implement a State or Tag for “Not yet assessed”, addressing Issue #241
        Enhance the Excel download feature in “Mapping” by adding assessment information, as discussed in Issue #244
        Refine the handling of subcategories to streamline the organization and presentation of maturity model elements, making the tool more intuitive. See Issue #194
        Introduce the Adding of Diagrams feature to enhance the visualization of DevSecOps processes and maturity levels, as outlined in Issue #183
        Your Idea: Proposals that innovate or enhance the metric collection and analysis process are highly encouraged.
        
        ~~~~~~~~~~
        Large Feature Pack for the metric Analyzer and Collector (Java)
        This pack challenges students to develop the entire workflow from data collection to visualization for DSOMM metrics, including the implementation of a Kafka queue. Projects include:
        Design and implement a collector for OWASP DefectDojo, fetching Mean Time to Resolve (MTTR) and Mean Time to Patch (MTTP) via the defectdjo-client which fetches MTTR/MTTP)
        Develop a collector for Jira, to retrieve information about security tasks.
        Create a collector for Jenkins and Kubernetes, aimed at measuring deployment frequency by team, a key metric in DevOps performance.
        Engineer a collector for GitHub and Bitbucket, to calculate MTTP by tracking pull request opening and merge dates. In addition, check that branch protection is enabled and a .gitignore exists in the root file system.
        Engineer a collector for gitleaks, fetching Mean Time to Resolve (MTTR) and Mean Time to Patch (MTTP)
        Your Idea: Proposals that innovate or enhance the metric collection and analysis process are highly encouraged.
        Please take a look at the architecture digram of DSOMM metricCA. The whole way from the collector to grafana needs to be implemented. Please note that a queue Kafka and Prometheus is currently not implemented and needs to be implemented in the collector and in the metricAnalyzer.
        For Backstage, Jira and Confluence a defined format and tags might be used to identify the corresponding team and type of document (e.g. threat modeling/pentest).
        Prerequisites
        Proficiency in the corresponding programming language (JavaScript for the main application, Java for the metric analyzer and collector)
        Previous contributions to open-source projects are highly desirable, demonstrating your commitment and collaborative skills
        Mentors
        Reach out to us on Slack to discuss these and other ideas!
        Timo Pagel
        Aryan Prasad
        
        
        ~~~~~~~~~~
        OWASP Nettacker
        OWASP Nettacker is a Modular Automated Penetration Testing/ Information gathering Framework and Vulnerability Scanner fully written in Python. Nettacker can run a variety of scans discovering subdomains, open ports, services, vulnerabilities, misconfigurations, default credentials.
        Explanation of Ideas
        fix scan engine multi-threading/queuing issues
        improve WebUI / add dashboard
        add DefectDojo integration / output report format
        add SARIF output report format
        implement testing framework, get 70% code coverage level
        Getting Started
        Repositories:
        OWASP Nettacker on OWASP GitHub
        Join OWASP Slack and contact us on channel #project-nettacker
        Knowldege Requirements
        Python
        Flask
        HTML/CSS/JavaScript
        previous vulnerability scanning/bug bounty hunting experience
        Mentors
        Sam Stepanyan
        Ali Razmjoo
        Arkadii Yakovets
        
        ~~~~~~~~~~
        OWASP Nest
        OWASP Nest is a comprehensive platform designed to enhance collaboration and contribution within the OWASP community. The application serves as a central hub for exploring OWASP projects and ways to contribute to them, empowering contributors to find opportunities that align with their interests and expertise. Our mission is to drive real-world collaboration and elevate the OWASP organization by addressing key challenges and streamlining processes.
        Repository
        backend
        frontend
        schema
        Technical Stack
        Python, Django, Pytest
        TypeScript, React, Jest
        Chakra UI, Tailwind CSS
        PostgreSQL, Algolia
        Docker, k8s, AWS

        ~~~~~~~~~~
      
        OWASP Contribution Hub: Aiming to streamline the onboarding process and connect contributors with mentors and impactful projects. This milestone focuses on improving collaboration within the OWASP community.
        
        ~~~~~~~~~~
        OWASP Nest API: The development of REST and GraphQL API endpoints for OWASP Projects, Chapters, Events, and Committees. This milestone will standardize data access across OWASP’s resources.
        
        ~~~~~~~~~~
        OWASP Nest Kubernetes Adoption: This milestone focuses on migrating the OWASP Nest application to Kubernetes, ensuring scalability, reliability, and ease of deployment.
        
        ~~~~~~~~~~
        OWASP NestBot AI agent/assistant: Develop an AI-powered OWASP NestBot Slack assistant that acts as an auto-responder for frequently asked questions, guides users to the appropriate OWASP channels, and handles typical OWASP community queries.
        ~~~~~~~~~~
        OWASP Project Health Dashboard: A dashboard for monitoring the health of OWASP projects. This includes tracking vital metrics such as release frequency, issue resolution, and contributor growth.
        
        ~~~~~~~~~~
        OWASP Schema: Developing and extending a standardized schema for OWASP Projects and Chapters. This milestone aims to ensure consistency and ease of integration across OWASP resources.
        ~~~~~~~~~~
        OWASP Snapshots: Creating a summary of activities within OWASP projects, chapters, and events, including new blog posts and news, to keep the community informed about recent developments.
        ~~~~~~~~~~
        OWASP Juice Shop
        OWASP Juice Shop is probably the most modern and sophisticated insecure web application! It can be used in security trainings, awareness demos, CTFs and as a guinea pig for security tools! Juice Shop encompasses vulnerabilities from the entire OWASP Top Ten along with many other security flaws found in real-world applications!
        To receive early feedback please:
        put your proposal on Google Docs and submit it to the OWASP Organization on Google’s GSoC page in “Draft Shared” mode.
        Please pick “juice shop” as Proposal Tag to make them easier to find for us. Thank you!
        Explanation of Ideas
        MultiJuicer as a CTF Platform
        MultiJuicer saw some enhancements of its Team Score Board last year. It now is not that far away from being a full-fledged CTF platform of its own. This project should focus on the remaining features needed to make MultiJuicer a fully functional CTF platform. This should include making the Team Score Board visually attractive, flavorfully unique and more competition-oriented. The existing Solution Webhook integration already marks solved challenges automatically, but other information like team cheat score, progress over time etc. are not tracked or displayed today. The MultiJuicer CTF should offer the same features as the Juice Shop CTF tool in order to configure the availability of hints. This should include a way to allow teams to pay for hints with some of their collected points. To avoid issues with bigger teams hacking on the same instance of Juice Shop, a team grouping mechanism could be considered as well. The progress on the CTF Score Board could then be aggregated on group level for different teams/instances.
        
        ~~~~~~~~~~
        Test suite harmonization
        Juice Shop had a full replacement of its end-to-end test suite - from Protractor to Cypress - in its GSoC 2022 project. Now it is time to take on the remainin test suites, especially the Integration/API tests currently running on Frisby.js. That library as not seen updates in 2+ years and it became more and more flaky over the years, causing occasional CI/CD failures and time-consuming retry-mechanisms to keep those in check. A new foundation for these tests is needed. In scope is also to look at the frontend and backend unit test suites, and find a way to reduce the number of test frameworks being used in order to achieve higher consistency and less complexity for maintenance of the project. This project should include the test suites in the Juice Shop CTF tool as well. Proposals that also have the augmentation of MultiJuicer with end-to-end tests in scope, are specially welcome.
        
        ~~~~~~~~~~
        Juice Shop side-project rennovation
        The Juice Shop CTF Tool is currently implemented in vanilla JavaScript. It should be migrated to TypeScript for consistency of maintenance with the main project. Furthermore, the code linting should be adapted to the main Juice Shop ESLint standards. Test coverage and relevance should be reviewed and strengthened where necessary.
        Similarly, the following other sub-projects should be rennovated and brought onto an identical tech stack: Juicy Statistics, Juicy Coupon Bot, Juicy Chat Bot, and Juicy Coupon Lambda.
        ~~~~~~~~~~
        PyGoat
        PyGoat is an open-source, intentionally vulnerable Python web application designed to help developers and security enthusiasts learn about web application security. It provides hands-on experience in identifying and mitigating common security vulnerabilities, making it a valuable resource for practicing secure coding and penetration testing techniques.
       
        
        ~~~~~~~~~~
        Refactor the webapp, move away vulnarable labs from the main website.
        ~~~~~~~~~~
        Deploy a microservice architecture based approch for the labs.
        
        ~~~~~~~~~~
        Add new labs to the project.
        
        ~~~~~~~~~~
        Improvment of interactive playgrounds.
        
        ~~~~~~~~~~
        Extend labs to other languages as well.
        
        ~~~~~~~~~~
        Prepare for OWASP Top 10:2025 section
        Mentors
        ardiansyah
        Rupak Biswas(Rupak on slack)

        ~~~~~~~~~~
        OpenCRE
        OpenCRE is the world’s largest Cybersecurity knowledge graph. It semantically links information between standards, knowledge bases and security tools. Also, it allows users to extend the graph themselves and contains a RAG chatbot implementation. OpenCRE is a great GSOC project if you’re looking to add “Data science/engineering”, “Knowledge Graph and AI” with a focus on Legal Tech and cybersecurity in your CV.
        Repository
        OpenCRE
        Skills Required
        HTML/CSS/React-Typescript
        Python
        Flask
        Docker
        Getting started
        Check the GitHub project and the issues marked as either good first issue , help wanted or GSOC
        Join OWASP Slack and contact us on channel #project-opencre
        Projects / Ideas
        There are many small, medium and large project in the Issues Page tagged with GSOC that we are interested in, depending on your background and interests they are split in the following categories: AI, Frontend, Backend, FullStack. They all contain a bit of frontend and data analysis and graph operations. Priorities for us are:
        
        ~~~~~~~~~~
        Make the gap analysis functionality faster
        ~~~~~~~~~~
        MyOpenCRE

        ~~~~~~~~~~
        Releasing the Explorer page
        Mentors
        Spyros Gasteratos
        Rob Van Der Veer
        Paola Gardenas
        Edit on GitHub

        ~~~~~~~~~~



        Preferred for "Medium" GSoC 2025 project Difficulty: Hard OWTF Modernization

        OWTF has evolved over time, but parts of the codebase are outdated, have technical debt, and may not be optimized for newer Python versions or best practices. This project aims to modernize the OWTF codebase, ensuring long-term maintainability, security, and efficiency. Key Objectives

        Fix Long-Standing Bugs & Improve Stability
        Audit and resolve GitHub issues related to stability, crashes, and performance bottlenecks.
        Enhance logging and error handling for better debugging.
        Improve unit tests and CI/CD pipelines to catch regressions early.
        Optimize Plugin Execution & Dependency Management
        Upgrade outdated third-party security tools used in plugins.
        Reduce dependency bloat by removing redundant libraries.
        Use async execution where applicable for better performance.
        Expected Outcomes
        ✔️ OWTF will be cleaner, faster, and easier to maintain.
        ✔️ The project will be future-proofed with up-to-date dependencies.
        ✔️ Stability and performance will be significantly improved.

        ~~~~~~~~~~

        Preferred for "Medium" GSoC 2025 project Difficulty: Hard MiTM proxy upgrade

        OWTF’s proxy was written almost 10 years ago based on the Tornado Web Framework. It is in rough shape and needs a lot of improvement on the transaction recording, storing, and modification side. We want to make it as good as MiTM proxy.

        Expected Outcomes
        ✔️ Modern mitm proxy that allows modificaiton of requests and responses on the fly
        ✔️ Better integration with the framework to record a variety of requests and responses.
        ✔️ Stability and performance.

        Mentors
        Viyat Bhalodia
        Abraham Aranguren

    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/owasp-foundation/
    idea_list_url: https://owasp.org/www-community/initiatives/gsoc/gsoc2025ideas
  

  - organization_id: 101
    organization_name: Open Climate Fix
    no_of_ideas: 8
    ideas_content: |
      Open Data PVnet
      Project Description
      We're building an open-source solar forecasting pipeline to integrate with OCF's PVNet model, using publicly available Numerical Weather Prediction data to forecast solar generation at the national level, starting with the UK. Currently, our main forecasting tool, Quartz Solar, is trained using a mixture of public and private datasets, and we want to create an effective model that uses 100% open data. 

      The data is ready to go, but we need a ML engineer to train the model. The aim will be to start with a UK forecast, but then extend to different countries.

      Expected Outcome
      A UK ML Solar forecast trained on free NWP data with the accuracy benchmarked.

      Other Key Information
      Expected Size: 170hrs
      Skills: ML knowledge, Pytorch, Python. NWP knowledge is a bonus
      Difficulty level: Medium
      Related Reading: https://github.com/openclimatefix/open-data-pvnet, https://github.com/orgs/openclimatefix/discussions/24  
      Potential mentors: Peter, Sukh, please make contact on here
      
      
      ~~~~~~~~~~
      Cloudcasting ML
      Project Description
      Traditionally, forecasting tools are trained using historical satellite data. As part of an innovative new project, we have been training a model to predict satellite images up to 3 hours ahead over the UK. This work is still at early stages, but we have already proved that a satellite forecast using a very simple ML model can improve our solar energy forecast. There is lots of opportunity to improve on this new and unique satellite forecast, from trying different video prediction and AI weather model architectures to training a diffusion based model to stop the satellite forecast being blurry.

      Expected Outcome
      An improved satellite forecast model

      Other Key Information
      Expected Size: 350hrs
      Skills: ML, pytorch, python
      Difficulty level: Hard
      Related Reading: https://www.openclimatefix.org/projects/cloud-forecasting, https://github.com/openclimatefix/sat_pred, https://github.com/orgs/openclimatefix/discussions/25 
      Potential mentors: James, please make contact on here
      
      
      ~~~~~~~~~~
      Streaming Zarr from Cloud Storage (Ice Chunk + Zarr 3) 
      Project Description
      We use a large amount of Satellite and Numerical Weather Prediction data all saved in Zarr format for training our ML models. We normally have a local copy, rather than using the cloud. We would like to explore using Ice Chunk and Zarr 3. It would be great to create a benchmark when training our PVNet model with data in cloud storage (using modern stack like Ice Chunk + Zarr 3). We could then use this to measure speed and compare it to training using data on disk.

      Expected Outcome
      A quantitative comparison between the speeds when using these new tools and not. 

      Other Key Information
      Expected Size: 175hrs
      Skills: ML Knowledge, Familiarity with training ML Models with Pytorch, Python, Data Analysis. Zarr is a bonus
      Difficulty level: Medium
      Related Reading: https://github.com/openclimatefix/Satip/issues/222, https://github.com/orgs/openclimatefix/discussions/29  
      Potential mentors: sol@openclimatefix.org, peter@openclimatefix.org 

      
      ~~~~~~~~~~
      Solar Forecast with TZ-SAM: Create Forecasts for Sites or a Grid (Country) Based on Transition Zero’s Solar Asset Mapper
      Project Description
      The Transition Zero Solar Asset Mapper (TZ-SAM) is a new open source tool launched by not-for-profit Transition Zero (TZ). It provides a database of large solar farms, around 60,00 in total, from around the world that have been identified by using advanced AI satellite imagery identification. We want to use the TZ Solar asset mapper dataset to forecast each of the sites it identifies and/or map out total capacities for large sites in each country. Then we can use these capacities to generate solar forecasts for different grids around the world. 

      Expected Outcome
      Basic solar forecasts, using Open Quartz, for every site/grid/country in the TZ-SAM dataset using a global NWP provider. Bonus: Aim to have it in production by the end of the mentoring period. 

      Other Key Information
      Expected Size: 175hrs 
      Skills: Running ML models, docker
      Difficulty level: Medium 
      Related Reading: https://www.transitionzero.org/products/solar-asset-mapper https://github.com/openclimatefix/open-source-quartz-solar-forecast, https://github.com/orgs/openclimatefix/discussions/28 
      Potential mentors: Zak, please make contact on here

      
      ~~~~~~~~~~
      Cloudcasting UI
      Project Description
      We've been working on forecasting clouds using satellite imagery, and we would now like to take the next step and make an exciting visual representation of these cloud forecasts. This is an exciting and innovative project in the weather forecasting space. We would either implement this into our current product, Quartz Solar Forecast, or a separate tool all together.

      Expected Outcome
      A UI that clearly shows cloud forecasting. 

      Other Key Information
      Expected Size: 175hrs
      Skills: Plotting and visualising in a front end language, understanding of user experience, good problem solving skills.
      Difficulty level: Medium
      Related Reading: https://openclimatefix.org/projects/cloud-forecasting  
      Potential mentors: Brad, please make contact on here

      
      ~~~~~~~~~~
      Adjuster this! TabPFN as a replacement for the adjuster
      Project Description
      For the OCF Quartz Solar forecasting model, we have a simple “adjuster” model. It currently looks at the pattern of errors in the last week, and adjust the new forecast. We would like to experiment with a new foundational timeseries forecasting model, TabPFN, with the planned outcome to dynamically adjust our PV forecasting model based on historical errors and improve the forecasting skill. Can compare to current rules based averages method used. 

      Expected Outcome
      An answer to whether a pretrained ML model such as TabPFN can provide better adjustment of solar forecasts than rules based methods. If yes, then the plan would be to incorporate this into OCF's production system.

      Other Key Information
      Expected Size: 90hrs
      Skills: ML knowledge + familiarity with ML tools, some data processing skills required e.g. pandas
      Difficulty level: Easy
      Related Reading: https://github.com/openclimatefix/india-forecast-app/blob/main/india_forecast_app/adjuster.py, https://github.com/PriorLabs/TabPFN , https://github.com/orgs/openclimatefix/discussions/27 
      Potential mentors: Sukh, please make contact on here

      
      ~~~~~~~~~~
      Quartz Solar: New data source in ML model
      Project Description
      Adding new data sources usually gives a boost to the predictive power of our models, and finding innovative ways of extracting information from them can be even more beneficial. We would like to explore ways to improve our solar energy forecast with an ablation study of how much data on features like dust or neighbouring sites can contribute to the precision of the model. The project can be scaled depending on time constraints.

      Expected Outcome
      A comparative analysis of the effects of auxiliary data sources on the forecast quality.

      Other Key Information
      Expected Size: 175hrs
      Skills: Familiarity with training ML models, preferably with pytorch. Data analysis skills would be highly beneficial
      Difficulty level: Medium-Hard
      Related Reading: https://github.com/openclimatefix/open-data-pvnet, https://github.com/openclimatefix/PVNet, https://github.com/orgs/openclimatefix/discussions/26  
      Potential mentors: Alex, Sukh, please make contact on here

      ~~~~~~~~~~
      Improving Probabilistic Solar Forecasts
      Project Description
      Quantile regression approach in probabilistic solar forecasting directly estimates specific quantiles of the predictive distribution. Instead of direct quantity outputs, the proposition is modification of final layers to predict parameters of Gaussian Mixture Model(s) - for each component the mean, STD and coefficient. This should fundamentally capture more complex multimodal uncertainties inherent within probabilistic solar forecasting.

      Expected Outcome
      Complete continuous probability distribution as opposed to fixed quantiles. Better representation of uncertainties (such as transitions) and better capture of bimodal scenarios. Overall hopefully more accurate modelling and pattern comprehension - stronger uncertainty bounds perhaps.

      Other Key Information
      Expected Size: 90hrs
      Skills: Academically - statistics / mathematics / engineering to Masters level. Experience implementing GMMs from scratch. ML/DL/PyTorch. Related architectural knowledge.
      Difficulty level: Easy-Medium
      Related Reading: https://github.com/openclimatefix/PVNet, https://scikit-learn.org/stable/modules/mixture.html https://github.com/ldeecke/gmm-torch, https://github.com/orgs/openclimatefix/discussions/30 
      Potential mentors: Felix, please make contact on here

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-climate-fix/
    idea_list_url: https://docs.google.com/document/d/1nh6pdIjCTSLWwgFhgIV1gpG8CbIqGyoCFDHOfWmKdwA/edit?usp=sharing

  - organization_id: 102
    organization_name: Open Food Facts
    no_of_ideas: 8
    ideas_content: |
      Folksonomy Engine: a one size fit all for any product data
      Description
      At Open Food Facts we are on a mission to collect any factual data about food products, but also cosmetics, and any products. Modelling every possible products is a challenging task but also topics can be very different based on usage. For example some researchers are interested in knowing the correlation between sugar in cereals and the presence of a cartoon on the front package.
      Faithful to our crowded sourced approach to open data collection, we devised Folksonomy Engine, akin to the way Open Street Map works.
      The basics are there, but we need to make it more easy and efficient to use in order to reach a large public. We must introduce better properties suggestion, reusable widgets and
      Expected outcomes
      The project, should deliver new API features, like suggestion based on popularity and categories, a better handling of nested properties values, tools for exploring and merging values.
      It should also deliver an improved reusable javascript based web interface for display and edition, with maybe some formalization of properties definition.
      The roadmap can be changed while iterating over features, to better achieve the goal of usability by a large variety of contributors.
      Project information
      repository: https://github.com/openfoodfacts/folksonomy_api (and https://github.com/openfoodfacts/folksonomy_frontend)
      Slack channels: #folksonomy_engine
      Potential mentors: Alex G. (slack: Alex G., alex -at- openfoodfacts.org, github: alexgarel), Charles Nepote
      Project duration: 175 hours or 350 hours
      Skills required: Python, Javascript
      Difficulty rating: Medium
      
      
      ~~~~~~~~~~
      Add a way to easily extend the features of the Open Food Facts website, mobile app and reusing apps
      Description
      Open Food Facts gathers raw product data and computes attributes (e.g. nutritional and environmental scores, allergens) that users can filter and rank products on, and knowledge panels to provide useful and actionable information (e.g. information about ingredients). We already have an internal API for sending attributes and knowledge panels to the Open Food Facts website and mobile app. We now want to make it much easier to our community to create new attributes and knowledge panels to create extensions for our website, app and all the apps that reuse Open Food Facts data.
      Expected outcomes
      The task is to create a standalone system in Python to compute attribute and knowledge panels from the raw JSON product data (we already have a standalone sytem to compute panels for categories that can be reused as a model). The system should make it easy for community developers to create and test new attributes and knowledge panels. As a first use case, the system will provide attributes and panels to let users declare that they do not eat specific ingredients of their choosing.
      Project information
      repository: https://github.com/openfoodfacts/facets-knowledge-panels
      Slack channels: #productopener
      Potential mentors: Stéphane Gigandet, Pierre Slamich, Alex Garel
      Project duration: ~350 hours
      Skills required: Python, JSON REST API
      Difficulty rating: Medium

      ~~~~~~~~~~
      Moodle Integration Plugin
      Description
      This project aims to create a bridge between Moodle, a popular learning platform (stats), and Open Food Facts (OFF), the open database of food products. The goal is to facilitate the creation of high-quality educational resources on healthy and sustainable food choices. It will make OFF data easily accessible to course creators. It could also lead teachers and students to contribute data into OFF through educational activities like hunger games, scan parties, etc.
      Expected outcomes
      A Moodle integration plugin for Open Food Facts. This plugin should allow the automatic import of OFF data into:
      Moodle Blocks, to display food information in the side dock (column on the right)
      Moodle Database activitiy and Glossary activity, to make food information accessible in the main course sections
      Moodle Question bank and Quizz activity, for the creation of quizzes
      Ultimately, the project also plans for an OFF Moodle theme and a resource sharing hub like MoodleNet. We may swap one of these items into the project backlog, if a contributor prefers to.
      Project information
      Repo: to be created on May 8
      Slack channels: #summerofcode #education
      Potential mentors: Louis Bastarache
      Project duration: 350 hours
      Skills required: PHP, HTML, MySQL and a data source here
      Difficulty rating: Medium
      Moodle: https://moodle.mieuxchoisir.org/

      ~~~~~~~~~~
      H5P Content Generator
      Description
      This project aims to create a bridge between H5P and the Open Food Facts database. It's related to the Moodle project, but it's shorter and the skills are different. It would make food content available on Moodle, but also on CMS, wiki and web pages. Consider it as an ETL project: you have to extract data from the OFF DB, transform it, and load it in an HTML5 package. We will need a UI/API to use it. It's an ongoing project, so should be easier to complete something in less than 350 hours.
      Expected outcomes
      A standalone H5P generator that will create H5P content types based on OFF data. We've begun to work on automatic content generation from the OFF database. The next step would be to improve our work and generate some H5P content types. Since we have a generation recipe for them, the content types that we target first are Drag the words, Fill in the blanks, Mark the words, Quiz, Single choise set and Summary.
      Project information
      Repo: to be created on May 8
      Slack channels: #summerofcode #education
      Potential mentors: Louis Bastarache
      Project duration: 175-350 hours
      Skills required: PHP, Java, Spring, Firebase and a data source here
      Difficulty rating: Medium

      ~~~~~~~~~~
      Open Food Facts Explorer - a new generation frontend
      Description
      The Open Food Facts Explorer is a modern frontend for Open Food Facts, developed using SvelteKit. It offers functionalities such as basic editing, product page displays with Knowledge Panels support, search capabilities, and user authentication. Additionally, it incorporates the new folksonomy engine and a taxonomy explorer, enhancing data organization and accessibility.
      Expected outcomes
      The main objective of the project is to refine and expand its features to align with the standard Open Food Facts website.
      Decoupling the backend from the frontend will improve the long-term maintainability of the codebase, while leveraging a modern JavaScript framework will facilitate the development of new features.
      It also has the potential to make the website far more easy to use on a mobile, which constitute more than 70% of visits
      SvelteKit's support for server-side rendering (SSR) and emphasis on accessibility enhance the responsiveness of the web application, broadening its potential reach.
      The development roadmap remains flexible, allowing adjustments during iterations to improve usability and ensure feature completeness.
      Project information
      Repository: https://github.com/openfoodfacts/openfoodfacts-explorer
      Slack channels: #off-explorer
      Potential mentors: VaiTon
      Project duration: ~175 hours
      Skills required: TypeScript, Svelte and SvelteKit (really easy to learn), a basic understanding of HTTP APIs
      Difficulty rating: Medium (for its length)


      ~~~~~~~~~~
      
      Add Mini Games to the Open Food Facts Mobile App
      Description
      Open Food Facts empowers users with information about food products. This project aims to enhance user engagement and education by introducing fun, informative mini-games within the Open Food Facts mobile app. These games will leverage the existing Open Food Facts data. The games will focus on contributions, and increasing user understanding of food .
      Potential mini-games are:
      Hunger Games (AI Prediction Validation): This game will present users with questions about products, one after the other, on a given topic (category, nutrition facts, ingredients…). Users will then be asked to validate the prediction, and will move to a similar prediction for another product.
      How Much Sugar? (Sugar Cube Guessing): This game will display a product image and name. Users will guess the number of sugar cubes equivalent to the product's sugar content per serving (or per 100g). The actual number of sugar cubes will drop in a playful animation.
      Caloprix (Nutri-Score Guessing): This game challenges users to guess the Nutri-Score (A, B, C, D, or E) of a product based on its image, name, and potentially a limited set of other data points (e.g., category). The game will reveal the correct Nutri-Score and provide a brief explanation of what factors contribute to that score. The game ends when the user gets it wrong. The goal is to get as many good answers as possible in a row.
      The Price is Right (Price Guessing): This game challenges you to guess the price of an item of a product, and answers you by saying “More” or “Less”. The goal is to guess the right prices in as little guesses as possible.
      
      Expected Outcomes
      Working Mini-Games: Several mini-games integrated into the Open Food Facts mobile app (iOS and Android) and our website.
      User Interface: A clean, intuitive, and engaging user interface for each mini-game, consistent with the Open Food Facts app's design.
      Testing: Thorough testing of the mini-games on various devices and screen sizes.
      Project Information
      Main Repository: https://github.com/openfoodfacts/smooth-app
      Web version of Hunger Games for reference: https://hunger.openfoodfacts.org
      Slack Channels: #mobile-app-dev, #dev
      Potential Mentors: Edouard M, Primael Q and Pierre S
      Project Duration: ~350 hours
      Skills Required:
      Mobile App Development with Flutter
      JSON REST API interaction
      Design integration
      An experience with web development would be a great plus
      Difficulty Rating: Medium


      ~~~~~~~~~~
      
      Porting Open Prices Features to the Open Food Facts Mobile App
      Description
      This project aims to integrate the core features of Open Prices into the Open Food Facts mobile application. Open Prices allows users to contribute and view price information for products, creating a valuable resource for consumers. Currently, this functionality is primarily available on the Open Prices website. Bringing Open Prices to the mobile app will significantly increase accessibility and user engagement, leveraging the app's existing user base. This will empower users to easily compare prices while shopping, contribute new price data on-the-go. The project will focus on seamlessly integrating these features into the existing app structure, ensuring a consistent and user-friendly experience.
      Expected outcomes
      Beautify the current user Interface and review the current user Experience (UI/UX) for existing flows: Prioritize a user-friendly and intuitive interface for both viewing and contributing price data, adhering to mobile design best practices.
      Price Viewing: Implement the ability to browse and search for product prices within the Open Food Facts mobile app. This should include clear display of current and historical prices, potentially with visualizations (e.g., price trends).
      Bulk Price Contribution using Artificial Intelligence: Enable users to easily add new bulk price information for products directly through the app. This should include mechanisms for data validation and image uploads for price verification.
      Offline Functionality: Add offline price contribution (data synced when a connection is available) using the current background task system
      Project Information
      Repository: https://github.com/openfoodfacts/smooth-app
      Slack channels: #prices
      Potential mentors: Raphael O., Edouard M., Pierre (contacted via Slack/GitHub)
      Project duration: ~175 hours (can be adjusted based on specific feature scope)
      Skills required: Flutter, mobile app development experience, familiarity with RESTful APIs, basic understanding of data visualization.
      Difficulty rating: Medium (due to mobile development complexities and API integration)

      ~~~~~~~~~~
      Enhancing Developer Experience Through Automation and Workflow Optimization
      Description
      This project aims to significantly improve the developer experience (DevX) within Open Food Facts by automating workflows and streamlining processes. The initiative focuses on delivering practical code contributions that enhance productivity and simplify daily tasks for developers. Key components include automated documentation generation, optimized GitHub workflow management, integration of cloud-based development environments, automated deployment pipelines for testing changes, and conditional test execution to reduce build times.
      Expected outcomes
      Deliverables and KPI / benefits:
      KPIs: Reduced build/test times, faster issue resolution, and improved developer satisfaction.
      Automated Documentation Pipeline: A system that continuously updates project documentation (eg. OpenAPI specs) in sync with code changes.
      Examples include using markdown-based solutions such as MDX, nextra.site, fumadocs, or mintlify. For instance, Langufuse’s documentation (Langufuse Documentation) serves as both a technical resource and a marketing tool, illustrating how a well-maintained documentation system can elevate a project’s profile.
      Additional examples include the markdown-only page OSS LLMOps Stack and the documentation repository langfuse-docs.
      Modern Development Environments: Integration of solutions like GitPod or GitHub Codespaces to provide uniform, pre-configured setups for contributors.
      Automated Deployment for Testing: Pipelines that deploy changes immediately for real-time testing feedback.
      Enhanced Testing Efficiency: Conditional test execution that reduces unnecessary build and test cycle times.
      Optimized GitHub Workflow: Automation scripts or GitHub Actions for issue triage, pull request management, and repository organization (example script to reduce labels).
      Develop an NLP/AI-powered solution to categorize, prioritize, and suggest resolutions for open GitHub issues within the Open Food Facts ecosystem.
      Implement a dashboard/overview (simple example) for better repository management, tracking contributions.
      Project information
      repositories: openfoodfacts-server, openfoodfacts-python, smooth-app, robotoff
      DevOps Issue tracker
      Slack channels: #dev, #infrastructure
      Potential mentors: Hangy, with assistance from Malte.
      Project duration: ~90 hours (focused implementation), ~175 hours (moderate scope), or ~350 hours (comprehensive integration)
      Skills required:
      Proficiency in scripting (Python, Bash)
      Experience with CI/CD systems (GitHub Actions, Jenkins)
      Familiarity with containerization (Docker)
      Knowledge of cloud-based development environments
      Understanding of testing frameworks and automation strategies
      Difficulty rating: Moderate to Advanced – Involves integrating diverse tools and workflows to significantly enhance developer experience.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-food-facts/
    idea_list_url: https://wiki.openfoodfacts.org/GSOC/2025_ideas_list

  - organization_id: 103
    organization_name: Open HealthCare Network
    no_of_ideas: 16
    ideas_content: |
      Offline Data Entry Support
      Google Summer Of Code
      /care_fe#10533
      Open in GitHub

      Project Detail
      The Offline Data Entry Support feature aims to ensure that CARE forms remain fully functional even when a user's device is offline. This enhancement will enable users to continue entering data without interruption by storing inputs locally and synchronizing them with the central server once connectivity is restored. Additionally, the feature will handle conflict resolution to maintain data integrity during concurrent updates.

      Features To Be Implemented
      Offline Form Functionality: Modify forms to operate seamlessly without an active internet connection.
      Local Data Storage: Implement mechanisms to cache or store form data locally when offline.
      Automatic Synchronization: Develop a process to automatically sync stored data with the central server when the device reconnects.
      Conflict Resolution: Create a robust system to handle data conflicts arising from multiple offline updates.
      User Notifications: Provide visual cues to inform users about their offline status and the progress of data synchronization.
      Note: The offline data entry capability should integrate smoothly with existing CARE modules without disrupting the user experience.

      Learning Path
      Details
      Complexity	Large
      Required Skills	ReactJS, NodeJS, TypeScript, Django, PWA/Offline Capabilities, Local Storage APIs
      Mentors	@rithviknishad @bodhisha @sainak
      Project Size	350 hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: CARE Frontend
      For setting up the backend, please refer to the readme file available at: CARE Backend
      Acceptance Criteria
      Offline functionality works reliably across various devices and network conditions.
      Data entered offline is securely stored and synchronized accurately once connectivity is restored.
      The conflict resolution mechanism effectively handles simultaneous offline updates.
      User notifications clearly indicate offline status and synchronization progress.
      All CI/CD workflows pass, with comprehensive testing and peer code reviews completed.
      Milestone
      Analyze current CARE forms and assess offline capability requirements.
      Research and select suitable offline storage and synchronization strategies.
      Implement offline functionality within existing forms.
      Develop local storage and automatic synchronization logic.
      Build conflict resolution and user notification features.
      Conduct extensive testing under varied network conditions.
      Complete QA and code review.


      ~~~~~~~~~~
      Enhancing Medication Notifications in CARE 3.0 for Palliative Care & Adherence
      Google Summer Of Code
      /care_fe#10475
      Open in GitHub

      Project Detail
      The Enhancing Medication Notifications in CARE 3.0 for Palliative Care & Adherence project aims to improve medication adherence and palliative care support by integrating multi-channel medication reminders and notifications. Leveraging FHIR’s MedicationRequest resource, HL7 communication protocols, and FHIR Subscriptions, this enhancement ensures that patients, caregivers, volunteers, and nurses receive timely alerts about medication schedules. This project will support palliative care patients by automating reminders for critical medications and treatments, and it will provide a comprehensive monitoring dashboard for caregivers and healthcare professionals.

      Features To Be Implemented
      FHIR MedicationRequest Extension: Extend the FHIR MedicationRequest resource (or implement a background job) to track reminder schedules.
      Real-Time FHIR Subscription Integration: Use FHIR Subscriptions to trigger real-time events for upcoming medication doses.
      Multi-Channel Notification System:
      Implement Push Notifications for in-app alerts.
      Integrate SMS Alerts via services such as Twilio or Nexmo.
      Configure Email Notifications using providers like Postmark or Brevo.
      Set up Automated Calls for elderly and visually impaired patients.
      Nurse & Volunteer Dashboard: Build a web dashboard to monitor medication adherence, enabling caregivers to track which patients have taken or missed their medications.
      Role-Based Notification Preferences: Enable customizable notification settings for patients, caregivers, and volunteers.
      Note: The notifications system should integrate seamlessly with CARE 3.0’s EHR and be based on FHIR standards for medication tracking and administration.

      How This Adds Value to CARE 3.0
      Supports Palliative Care: Automates reminders for pain medications and palliative treatments, ensuring timely care and enhanced patient comfort.
      Improves Medication Adherence: Reduces missed doses by providing automated, multi-channel reminders, with alerts for caregivers if a dose is missed.
      FHIR-Based Integration: Utilizes FHIR’s MedicationRequest and MedicationAdministration resources to schedule and track medication, with real-time notifications enabled by FHIR Subscriptions.
      Multi-Channel Coverage: Extends notification capabilities beyond internal messaging through push, SMS, email, and automated calls.
      Monitoring Dashboard: Provides a dedicated dashboard for nurses and volunteers to monitor medication adherence and intervene when necessary.
      Learning Path
      Details
      Complexity	Large
      Required Skills	ReactJS, NodeJS, TypeScript, Django, FHIR Standards, HL7, Notification Systems, API Integration
      Mentors	@bodhisha @khavinshankar Neil
      Project Size	350 hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: CARE Frontend
      For setting up the backend, please refer to the readme file available at: CARE Backend
      Acceptance Criteria
      All CI/CD workflows run successfully.
      FHIR MedicationRequest is extended or complemented with background jobs to track medication reminder schedules.
      Real-time notifications are triggered using FHIR Subscriptions.
      Multi-channel notifications (Push, SMS, Email, Automated Calls) are successfully integrated.
      The nurse/volunteer dashboard displays accurate medication adherence data.
      Role-based notification preferences are configurable by users.
      Comprehensive documentation, testing, and code reviews are completed.
      Milestone
      Analyze CARE 3.0’s existing EHR and FHIR Medication resources.
      Design the extension (or background job) for medication reminder scheduling.
      Implement FHIR Subscription triggers for real-time notifications.
      Develop and integrate multi-channel notification services (Push, SMS, Email, Calls).
      Build and test the nurse & volunteer dashboard.
      Enable role-based notification preferences.
      Conduct extensive QA, testing, and peer code reviews.
      Finalize documentation and deploy the enhanced notification system.

      ~~~~~~~~~~
      FHIR Risk Assessment
      Google Summer Of Code
      /care_fe#10599
      Open in GitHub

      Project Detail
      The FHIR Risk Assessment project aims to extend CARE’s capabilities by incorporating the FHIR Risk Assessment specification. This project involves designing and implementing backend models and API endpoints to handle risk assessment data, as well as creating a user-friendly frontend interface to capture and display this information. The goal is to provide healthcare professionals with a standardized method to evaluate patient risks.

      Features To Be Implemented
      Backend Risk Models: Implement risk assessment data models adhering to FHIR specifications.
      API Endpoints: Develop API endpoints to manage and retrieve risk assessment data.
      User Interface: Create an intuitive UI for clinicians to input and review risk assessments.
      Data Validation: Ensure risk assessment inputs are validated against FHIR standards.
      Note: Risk assessment data should be integrated with patient profiles for comprehensive healthcare management.

      Learning Path
      Details
      Complexity	Large
      Required Skills	ReactJS, NodeJS, TypeScript, Django, FHIR Standards
      Mentors	@nihal467 @bodhisha Agile
      Project Size	350 hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: CARE Frontend
      For setting up the backend, please refer to the readme file available at: CARE Backend
      Acceptance Criteria
      All CI/CD tests must pass.
      Backend models and endpoints fully comply with FHIR risk assessment standards.
      The user interface is responsive and intuitive for clinical use.
      Extensive documentation, testing, and QA are completed.
      Code reviews confirm the solution meets long-term sustainability requirements.
      Milestone
      Understand current CARE architecture and FHIR risk assessment guidelines.
      Design the risk assessment data model and API structure.
      Develop backend models and endpoints for risk assessment.
      Build and integrate the frontend interface.
      Validate and test data inputs against FHIR standards.
      Complete integration testing, QA, and documentation.
      Finalize code reviews and merge the implementation.

      ~~~~~~~~~~
      Whatsapp bot for CARE
      Google Summer Of Code
      /care_fe#10509
      Open in GitHub

      Project Detail
      CARE is a centralized capacity management and patient management system, central to the 10BedICU Project, integrating patients, doctors, hospitals, labs, specialized treatment centers, hospital administrators, and shifting control cells. Hospitals update crucial information about their assets, providing district administration with a comprehensive view of the healthcare system via smart dashboards. CARE digitizes patient records, streamlines workflows for pandemic management, and is deployed in remote areas, enabling Tele-ICU services for underserved citizens. It revolutionizes healthcare management, enhancing efficiency, accessibility, and patient outcomes.

      Features To Be Implemented
      Build a wrapper on care that IM bots can use to get information or send a notification. The idea behind this feature is to ease and improve the user experience.

      Build a generic IM wrapper for care which the respective bots can use to interact with care

      Build a WhatsApp bot which can be used by both patients and hospital staff

      For Patients

      Should fetch their patient records
      Should fetch their current medications
      Should fetch their procedures
      For Users (Hospital Staff)

      Should fetch their schedules (to be done after scheduling)
      The above-mentioned list of items (both For Patients and For Users) is subject to change, the mentioned features are just to give an idea of what needs to be done.

      While implementing this, a conscious effort should be taken to prevent the Private Personal Information (PPI) of other patients from being shared.

      Learning Path
      Details
      Complexity	Medium
      Required Skills	Python, Django
      Mentors	@shivankacker @rithviknishad @tellmeY18
      Project Size	175 Hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: https://github.com/coronasafe/care_fe
      For setting up the backend, please refer to the readme file available at: https://github.com/coronasafe/care
      Acceptance Criteria
      Code is logically structured for long-term project sustainability.
      Proper descriptions should be included for review purposes.
      QA and Code Review
      Milestone
      Get to know CARE as a product and understand the workflow.
      Understand the requirements.
      Implement the tasks mentioned above
      Write tests for the implemented functionality
      Optimise the code
      Review and QA

      ~~~~~~~~~~
      Copilot App Plugin For CARE
      Google Summer Of Code
      /care_fe#10470
      Open in GitHub

      Project Detail
      The Copilot App Plugin project introduces a floating button to the CARE application, enabling users to chat directly with a bot for various support tasks. This includes generating detailed reports, summarizing treatment plans, and addressing queries related to patient conditions.

      Features To Be Implemented
      Floating Action Button (FAB):
      Add a floating button to the CARE app interface that, when clicked, opens the chat interface.

      Chat Interface Integration:
      Implement a chat UI where users can interact with the bot. This interface should be simple, intuitive, and responsive.

      Report Generation:
      Allow users to request and receive detailed patient reports via the chat interface.

      Treatment Summaries:
      Enable the bot to provide concise summaries of ongoing or completed treatment plans.

      Condition Queries:
      Equip the bot to handle queries about patient conditions, including clarifications and guidance based on available patient data.

      Note: The bot’s responses should be consistent, accurate, and secure. It must adhere to data privacy standards and ensure the integrity of sensitive medical information.

      Learning Path
      Details
      Complexity	Medium
      Required Skills	ReactJS, NodeJS, TypeScript, Chatbot APIs, Data Privacy Regulations
      Mentors	@tellmeY18 @mathew-alex @shivankacker
      Project Size	175 hours
      Link to Documentation for Product Set-Up
      Frontend setup instructions: CARE Frontend
      Backend setup instructions: CARE Backend
      Acceptance Criteria
      The floating action button integrates seamlessly with the CARE UI.
      The chat interface is user-friendly and fully functional.
      The bot can reliably generate reports, summarize treatment plans, and answer condition-related queries.
      Comprehensive testing is performed to ensure data accuracy and privacy compliance.
      Documentation is updated to reflect all changes.
      Peer reviews and QA processes are successfully completed.
      Milestone
      Design and implement the floating action button (FAB).
      Develop the chat interface and integrate it with the bot backend.
      Implement report generation capabilities.
      Add logic for summarizing treatments and answering patient condition queries.
      Conduct thorough testing and refine the chatbot’s responses.
      Finalize documentation and perform QA reviews.

      ~~~~~~~~~~
      Diet Management in CARE
      Google Summer Of Code
      /care_fe#10471
      Open in GitHub

      Project Detail
      The Diet Management module in CARE is designed to help patients and healthcare professionals manage and track nutritional plans effectively. This module will integrate dietary guidelines, personalized meal plans, and calorie tracking to promote healthy eating habits. By incorporating diet management into CARE, users can monitor their nutrition alongside their medical records, leading to improved health outcomes.

      Features To Be Implemented
      Meal Plan Integration: Develop functionality to integrate and display daily meal plans based on individual dietary requirements.
      Calorie Tracking: Implement a feature to allow users to log and monitor their daily calorie intake.
      Nutritional Recommendations: Generate personalized nutritional suggestions based on user profiles and health data.
      Patient Record Integration: Ensure that dietary data is seamlessly synced with the overall patient record dashboard.
      Note: All diet management logs and plans should be accessible via the patient’s overview section for easy reference.

      Learning Path
      Details
      Complexity	Medium
      Required Skills	ReactJS, NodeJS, TypeScript, Django
      Mentors	@dauntlessnomad @vigneshhari @mathew-alex
      Project Size	300 hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: CARE Frontend
      For setting up the backend, please refer to the readme file available at: CARE Backend
      Acceptance Criteria
      All CI/CD workflows should pass.
      Code is modular, well-documented, and maintainable.
      Integration of diet management data within the patient dashboard is seamless.
      Comprehensive testing and peer code reviews are completed.
      Milestone
      Get acquainted with CARE’s architecture and understand the existing modules.
      Gather and analyze user requirements for diet management.
      Design UI/UX prototypes for the Diet Management module.
      Develop and integrate the meal plan and calorie tracking features.
      Implement personalized nutritional recommendation logic.
      Conduct integration testing with patient records.
      Complete QA and review.



      ~~~~~~~~~~
      Nutrition Rehabilitation
      Google Summer Of Code
      /care_fe#10474
      Open in GitHub

      Project Detail
      The Nutrition Rehabilitation module focuses on supporting patients during their recovery from malnutrition or health conditions affecting their nutritional status. This module will provide tools to create tailored nutritional rehabilitation plans, track progress over time, and offer dynamic dietary adjustments. It aims to empower healthcare professionals and patients with actionable insights to expedite recovery and improve long-term nutritional outcomes.

      Features To Be Implemented
      Rehabilitation Plan Creation: Develop functionality to create and manage personalized nutrition rehabilitation plans.
      Progress Tracking: Implement tools to monitor and log the nutritional progress of patients over time.
      Dynamic Dietary Adjustments: Enable real-time updates and customizations to rehabilitation plans based on patient progress.
      Reporting and Analytics: Create reports that provide insights into patient improvements and plan efficacy.
      Note: Rehabilitation data should integrate with existing patient records to ensure a unified view of health management.

      Learning Path
      Details
      Complexity	Medium
      Required Skills	ReactJS, NodeJS, TypeScript, Django
      Mentors	@nihal467 Agile @bodhisha
      Project Size	300 hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: CARE Frontend
      For setting up the backend, please refer to the readme file available at: CARE Backend
      Acceptance Criteria
      All CI/CD tests must pass successfully.
      The codebase is clean, modular, and well-documented.
      Rehabilitation plans and progress tracking integrate seamlessly with patient profiles.
      Extensive QA and code reviews have been performed.
      Milestone
      Familiarize with CARE and existing nutrition modules.
      Define requirements and design the rehabilitation workflow.
      Create UI/UX prototypes for the Nutrition Rehabilitation module.
      Implement rehabilitation plan creation and progress tracking features.
      Integrate dynamic dietary adjustment logic.
      Conduct thorough testing and gather user feedback.
      Complete final QA and code reviews.

      ~~~~~~~~~~
      FHIR Immunization
      Google Summer Of Code
      /care_fe#10477
      Open in GitHub

      Project Detail
      The FHIR Immunization project focuses on adding support for the FHIR Immunization specification within CARE. This involves extending the backend models and API endpoints to handle immunization data as per FHIR standards, as well as updating the frontend to allow users to view and manage immunization records seamlessly.

      Features To Be Implemented
      Backend FHIR Models: Develop immunization models that conform to FHIR specifications.
      API Endpoints: Create and document API endpoints to manage immunization data.
      Frontend UI: Build intuitive user interfaces for viewing, adding, and updating immunization records.
      Data Validation: Implement robust validation to ensure compliance with FHIR standards.
      Note: Ensure backward compatibility with existing patient records and data synchronization across modules.

      Learning Path
      Details
      Complexity	Large
      Required Skills	ReactJS, NodeJS, TypeScript, Django, FHIR Standards
      Mentors	@sainak @Jacobjeevan @nihal467
      Project Size	350 hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: CARE Frontend
      For setting up the backend, please refer to the readme file available at: CARE Backend
      Acceptance Criteria
      CI/CD workflows pass without issues.
      Immunization models and endpoints are fully compliant with FHIR standards.
      The frontend provides a seamless experience for managing immunization data.
      Complete documentation and comprehensive testing are in place.
      Peer reviews and QA processes are successfully completed.
      Milestone
      Gain an understanding of the current CARE data model and FHIR standards.
      Design the immunization data schema and API structure.
      Develop and integrate backend immunization models.
      Build and test the frontend UI for immunization records.
      Validate data against FHIR specifications.
      Perform integration testing and finalize documentation.
      Complete QA and final code reviews.

      ~~~~~~~~~~
      ABDM – Patient Centric Flows (PHR Flows)
      Google Summer Of Code
      /care_fe#10478
      Open in GitHub

      Project Detail
      The ABDM – Patient Centric Flows (PHR Flows) project aims to enhance the ABDM module by introducing robust Patient Health Record (PHR) flows. This implementation will empower patients to manage their health information, consents and other abdm related features. The feature will improve patient engagement and promote better health management practices.

      Features To Be Implemented
      PHR Flows Integration: Integrate PHR APIs from ABDM.
      Interactive UI: Build an engaging interface that allows patients to track and manage their health information, consents and other data.
      Security & Compliance: Ensure that the flows adhere to healthcare data privacy and security standards.
      Note: The patient-centric flows should integrate with existing ABDM functionalities and provide a unified view of patient data.

      Learning Path
      Details
      Complexity	Large
      Required Skills	ReactJS, NodeJS, TypeScript, Django, Healthcare IT
      Mentors	@nihal467 @khavinshankar @sainak
      Project Size	350 hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: CARE Frontend
      For setting up the backend, please refer to the readme file available at: CARE Backend
      Acceptance Criteria
      All CI/CD processes must pass without errors.
      The patient portal is intuitive, responsive, and secure.
      Data integration with other ABDM modules is seamless and reliable.
      Comprehensive testing, documentation, and code reviews are conducted.
      The solution complies with healthcare security and privacy standards.
      Milestone
      Get familiar with the CARE in general, ABDM module and current patient data flows.
      Define requirements for patient-centric abdm flows.
      Design the patient portal UI/UX.
      Develop and integrate the PHR flows within ABDM.
      Ensure robust data integration and security measures.
      Conduct extensive testing and gather user feedback.
      Finalize QA, documentation, and code reviews.

      ~~~~~~~~~~
      Improve the Package Showing Health Information
      Google Summer Of Code
      /care_fe#10508
      Open in GitHub

      Project Detail
      The ABDM – Improve the Package Showing Health Information project focuses on enhancing the current hi-profiles package used in ABDM. The existing package displays only minimal health information; this project aims to extend it to support all FHIR profiles used by ABDM. The goal is to present comprehensive and detailed health data, thereby enriching the user experience and providing deeper insights into patient health.

      Features To Be Implemented
      FHIR Profile Support: Extend the hi-profiles package to display all supported FHIR profiles.
      UI Enhancements: Redesign the user interface to accommodate detailed health information.
      Testing & Validation: Implement extensive testing to verify data accuracy and performance improvements.
      Note: The improved package should offer a complete and user-friendly view of patient health information without compromising performance.

      Learning Path
      Details
      Complexity	Large
      Required Skills	ReactJS, NodeJS, TypeScript, FHIR Standards
      Mentors	Agile @khavinshankar @mathew-alex
      Project Size	350 hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: CARE Frontend
      For setting up the backend, please refer to the readme file available at: CARE Backend
      Acceptance Criteria
      All CI/CD workflows run successfully.
      The hi-profiles package supports all required FHIR profiles.
      The redesigned UI presents comprehensive health information clearly.
      Data integration with ABDM’s backend is robust and reliable.
      Full documentation, testing, and code reviews are completed.
      Milestone
      Get familiar with the CARE in general and FHIR data standards.
      Analyze the current hi-profiles package and its limitations.
      Define requirements to support all FHIR profiles.
      Design the enhanced UI for detailed health information display.
      Extend the hi-profiles package and integrate with ABDM backend.
      Perform extensive testing and validate data accuracy.
      Finalize documentation and complete QA.
      Conduct peer reviews and merge the improvements.


      ~~~~~~~~~~
      HR Management Module
      Google Summer Of Code
      /care_fe#10521
      Open in GitHub

      Project Detail
      The CARE HR Module project aims to enhance the human resource management capabilities within CARE. This involves building backend models and API endpoints to handle employee data, developing a user-friendly frontend interface for HR tasks, and providing reporting and dashboard views for better HR oversight.

      Features To Be Implemented
      Employee Data Export and Reporting:
      Enable exporting of employee data and leave records, and provide meaningful reports for HR metrics.
      Staff Profile Integration:
      Automatically populate staff profiles from user data, and allow uploading additional professional documents.
      Leave Tracking:
      Add leave tracking functionality, leveraging existing scheduling exceptions to manage and approve leave requests.
      HR Dashboard View:
      Implement a dashboard with visual insights into key HR data such as leave balances, employee roles, and departmental metrics.
      Note: Ensure that all new features integrate seamlessly with existing CARE modules.

      Learning Path
      Details
      Complexity	Medium
      Required Skills	ReactJS, NodeJS, TypeScript, Django, Data Export, and Dashboard Design
      Mentors	Niel @amit-kr-debug @vigneshhari
      Project Size	175 hours
      Link to Documentation for Product Set-Up
      For frontend setup, refer to: CARE Frontend
      For backend setup, refer to: CARE Backend
      Acceptance Criteria
      CI/CD workflows pass without issues.
      Employee data export and reporting functionality is fully operational.
      Staff profiles auto-fill accurately, with the ability to add additional documentation.
      Leave tracking integrates seamlessly with the HR module.
      The dashboard provides clear, actionable insights.
      Complete documentation and comprehensive testing are in place.
      Peer reviews and QA processes are successfully completed.
      Milestone
      Understand the current HR module structure and data model.
      Design and implement employee data export and reporting features.
      Integrate staff profile auto-fill and professional documentation.
      Add and test the leave tracking functionality.
      Build and refine dashboard views and metrics.
      Perform integration testing and finalize documentation.
      Complete QA and final code reviews.

      ~~~~~~~~~~
      On-Prem Deployment Support
      Google Summer Of Code
      /care_fe#10532
      Open in GitHub

      Project Detail
      The On-Prem Deployment Support project aims to enable a complete offline deployment of CARE for individual facilities. Unlike the current cloud-based central server model, this feature will allow each facility (hospital) to host its own CARE server locally. The on-prem instance should operate independently with full functionality while offering options for optional data synchronization with a central server if needed.

      Features To Be Implemented
      Local Server Deployment: Develop a package or installer for deploying CARE on local servers.
      Independent Operation: Ensure that the on-prem instance functions fully independently without reliance on a central cloud server.
      Data Synchronization (Optional): Implement an optional mechanism for synchronizing data between local instances and a central server.
      Configuration Management: Provide configuration tools and documentation to tailor the on-prem deployment for facility-specific requirements.
      Deployment Automation: Create scripts and automation tools to streamline the installation and maintenance of local CARE servers.
      Note: The on-prem deployment should retain all core functionalities of CARE while ensuring robust performance, data security, and ease of management in a local environment.

      Learning Path
      Details
      Complexity	Large
      Required Skills	ReactJS, NodeJS, TypeScript, Django, DevOps, Docker, Deployment Automation
      Mentors	@sainak @dauntlessnomad @rithviknishad
      Project Size	350 hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: CARE Frontend
      For setting up the backend, please refer to the readme file available at: CARE Backend
      Acceptance Criteria
      A deployable on-prem package or installer is available for local setup.
      The local CARE instance operates independently with full core functionalities.
      Optional data synchronization (if implemented) functions reliably.
      Detailed configuration tools and documentation are provided.
      All CI/CD tests pass with thorough testing, QA, and code reviews completed.
      Milestone
      Assess the current CARE architecture for on-prem deployment viability.
      Define requirements for an independent local CARE server.
      Develop deployment packages, installers, and configuration management tools.
      Implement optional data synchronization mechanisms.
      Test the on-prem deployment in simulated facility environments.
      Finalize documentation, complete QA, and conduct code reviews.
      Release the on-prem deployment package.

      ~~~~~~~~~~
      Integrate UHI as a Plug
      Google Summer Of Code
      /care_fe#10534
      Open in GitHub

      Project Detail
      The Integrate UHI as a Plug project is focused on incorporating UHI (Universal Health Identifier) into CARE as a plug. UHI leverages building blocks to provide a seamless end-to-end experience for users, enabling patients to discover, book, conduct, and pay for services from a variety of participating providers across different applications. This integration will enhance CARE by streamlining healthcare service interactions and providing a unified experience for both patients and providers.

      Features To Be Implemented
      UHI API Integration: Develop connectors to integrate UHI APIs into CARE for service discovery, booking, and payment functionalities.
      Plug Interface: Build a modular plug interface that allows UHI services to be seamlessly integrated into CARE.
      UI Enhancements: Create user interfaces that facilitate the discovery, booking, and payment processes through UHI-enabled applications.
      Data Synchronization: Ensure that data from UHI integrations is synchronized accurately with CARE’s patient records and service modules.
      Testing & Compliance: Implement rigorous testing to validate end-to-end functionality and ensure compliance with healthcare data standards.
      Note: The integration should provide users with a smooth, unified experience while interacting with diverse healthcare service providers via UHI.

      Learning Path
      Details
      Complexity	Large
      Required Skills	ReactJS, NodeJS, TypeScript, Django, API Integration, Payment Gateway Integration, UHI Standards
      Mentors	@khavinshankar @nihal467 @Jacobjeevan
      Project Size	350 hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: CARE Frontend
      For setting up the backend, please refer to the readme file available at: CARE Backend
      Acceptance Criteria
      All CI/CD workflows run successfully.
      UHI APIs are fully integrated, enabling seamless discovery, booking, and payment functionalities.
      The plug interface for UHI is user-friendly and easily configurable.
      Data synchronization between UHI services and CARE is accurate and reliable.
      Comprehensive testing, documentation, and code reviews are completed.
      Milestone
      Research UHI protocols and identify integration requirements with CARE.
      Design the UHI integration architecture and plug interface.
      Develop UHI API connectors and integrate with CARE.
      Implement UI enhancements for service discovery and booking.
      Develop and test payment integration and data synchronization.
      Complete extensive QA, documentation, and code reviews.
      Finalize and deploy the UHI plug integration.

      ~~~~~~~~~~
      SSO Support
      Google Summer Of Code
      /care_fe#10531
      Open in GitHub

      Project Detail
      The SSO Support project aims to integrate Single Sign-On (SSO) functionality into CARE to streamline user authentication and improve overall security. By enabling SSO, users can log in using a single set of credentials across multiple CARE services and applications, reducing password fatigue and simplifying user management. This integration will leverage industry-standard protocols such as OAuth, OpenID Connect, or SAML, ensuring a secure and scalable solution for both internal and external users.

      Features To Be Implemented
      SSO Integration Module: Develop a robust SSO module that supports industry-standard protocols (OAuth, OpenID Connect, and/or SAML).
      Unified Authentication Flow: Implement a seamless authentication flow that allows users to sign in once and access all integrated CARE components.
      Identity Provider (IdP) Integration: Integrate with popular identity providers (e.g., Google, Microsoft, Okta) to facilitate centralized authentication.
      Security Enhancements: Ensure secure handling of tokens and sessions, with compliance to current security standards.
      Role & Permission Management: Extend the user management system to incorporate SSO-based roles and permission assignments.
      Comprehensive Testing: Write and execute unit and integration tests to guarantee the security and reliability of the SSO functionality.
      Note: The SSO module should integrate seamlessly with the existing CARE architecture and provide a consistent, secure authentication experience.

      Learning Path
      Details
      Complexity	Large
      Required Skills	ReactJS, NodeJS, TypeScript, Django, OAuth, OpenID Connect, SAML, Security Standards
      Mentors	@amit-kr-debug @sainak @dauntlessnomad
      Project Size	350 hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: CARE Frontend
      For setting up the backend, please refer to the readme file available at: CARE Backend
      Acceptance Criteria
      The SSO integration supports one or more industry-standard protocols (OAuth, OpenID Connect, and/or SAML).
      Users can authenticate using SSO and seamlessly access various CARE modules.
      Secure token handling and session management are implemented.
      Role and permission management is integrated with the SSO authentication system.
      Comprehensive unit and integration tests are completed, with all CI/CD workflows passing.
      Detailed documentation and successful peer code reviews are provided.
      Milestone
      Assess the current CARE authentication architecture and define SSO requirements.
      Design the SSO integration module and select appropriate protocols.
      Develop and integrate the SSO authentication flow into CARE.
      Implement integrations with selected identity providers.
      Enhance user management to support SSO-based roles and permissions.
      Conduct extensive testing, QA, and peer code reviews.
      Finalize documentation and deploy the SSO support module.

      ~~~~~~~~~~
      Integrate Beckn as Plug
      Google Summer Of Code
      /care_fe#10476
      Open in GitHub

      Project Detail
      The Integrate Beckn as Plug project aims to incorporate the Beckn protocol into CARE as a plug. Beckn is a universal resource discovery and transaction protocol that fosters open, decentralized, and interoperable peer-to-peer networks. By integrating Beckn, CARE can enable seamless resource discovery, standardized transactions, and interoperability across various healthcare modules and external networks, enhancing the overall connectivity of the healthcare ecosystem.

      Features To Be Implemented
      Beckn Protocol Connector: Develop a connector within CARE that supports the Beckn protocol for resource discovery and transaction handling.
      API Endpoints: Create API endpoints that conform to Beckn standards, enabling peer-to-peer communications and standardized transactions.
      Plug Interface: Build a modular interface to integrate Beckn services as a plug into the existing CARE architecture.
      Security & Compliance: Ensure that all data exchanges via the Beckn protocol meet healthcare data security and regulatory compliance standards.
      Testing & Interoperability: Implement comprehensive testing to validate interoperability with external Beckn networks and services.
      Note: The integration should allow seamless connection with Beckn-enabled services without disrupting the existing CARE functionalities.

      Learning Path
      Details
      Complexity	Large
      Required Skills	ReactJS, NodeJS, TypeScript, Django, API Integration, Beckn Protocol Standards
      Mentors	@Jacobjeevan @DraKen0009 @bodhisha
      Project Size	350 hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: CARE Frontend
      For setting up the backend, please refer to the readme file available at: CARE Backend
      Acceptance Criteria
      All CI/CD workflows pass without errors.
      The Beckn protocol connector is fully integrated and adheres to Beckn specifications.
      API endpoints facilitate smooth resource discovery and transaction processes.
      The plug interface allows easy integration and management of Beckn services.
      Comprehensive documentation, testing, and code reviews are completed.
      Milestone
      Analyze the Beckn protocol and its integration points with CARE.
      Design the architecture for the Beckn connector and plug interface.
      Develop and integrate the Beckn protocol connectors and API endpoints.
      Implement security and compliance measures.
      Perform interoperability testing with external Beckn networks.
      Complete QA, documentation, and peer code reviews.
      Finalize and merge the integration.

      ~~~~~~~~~~
      Terminology Server from Google Sheet
      Project Detail
      The Terminology Server from Google Sheet project is designed to offer an alternative or extension to the current snowstorm terminology server by leveraging Google Sheets. This approach aims to simplify the management of healthcare terminologies, making it more user-friendly and cost-effective for the open-source community. Users will be able to update and manage terminologies through an intuitive Google Sheets interface that syncs with CARE.

      Features To Be Implemented
      Google Sheets Integration: Implement functionality to fetch and sync terminology data from Google Sheets.
      Seamless Fallback: Maintain compatibility with the existing snowstorm terminology server as a fallback.
      User Interface: Develop an interface within CARE to manage and view terminologies sourced from Google Sheets.
      Real-Time Synchronization: Ensure that updates in Google Sheets are reflected in CARE in near real-time.
      Note: Data consistency and synchronization must be prioritized to ensure accurate terminology usage across the system.

      Learning Path
      Details
      Complexity	Large
      Required Skills	ReactJS, NodeJS, TypeScript, Django, Google Sheets API
      Mentors	@rithviknishad @amit-kr-debug Neil
      Project Size	350 hours
      Link to documentation for Product Set-Up
      For setting up the frontend, please refer to the readme file available at: CARE Frontend
      For setting up the backend, please refer to the readme file available at: CARE Backend
      Acceptance Criteria
      All CI/CD pipelines run successfully.
      Terminology data is accurately synchronized between Google Sheets and CARE.
      The fallback mechanism to the snowstorm server remains functional.
      The UI is intuitive and provides clear management capabilities.
      Complete testing, documentation, and QA reviews are in place.
      Milestone
      Analyze current terminology management using snowstorm.
      Design the Google Sheets integration workflow.
      Develop the integration layer and real-time sync functionality.
      Create a user interface for terminology management.
      Test data consistency and fallback mechanisms.
      Finalize documentation and perform thorough QA.
      Complete code reviews and merge the updates.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-healthcare-network/
    idea_list_url: https://contributors.ohc.network/projects

  - organization_id: 104
    organization_name: Open Robotics
    no_of_ideas: 16
    ideas_content: |
      Improvements to ROS 2 Doctor 👩🏻‍⚕️
      Prerequisites: Ubuntu and ROS 2 development environment, no need for specialized hardware.
      Necessary programming skills: Familiarity with C/C++/Python, CMake, ABI/API.
      Difficulty level: Medium.
      Potential mentors: Tomoya Fujita
      Expected size: 100 hours to 150 hours.
      Expected outcome: A ROS 2 command line interface ros2cli with doctor sub-command and ros2_documentation.
      Detailed description: Currently, the ROS 2 doctor subcommand, ros2 doctor, is lacking a lot of useful information, such as ROS environment variables, RMW-specific environment variables, and configuration and service information (number of endpoints, QoS compatibility status, etc). This information is really important and useful for debugging issues with ROS 2, and would greatly improve our ability to support issues reported by our user community. In other words, adding this new information to our existing ROS 2 Doctor command would accelerate community communication and make bug reports much more precise! Aligned with ros2cli development, this project also targets the implementation of improved documentation on how to create an issue report with a new issue template.
      Reference pull requests: Add default github issue templates, add: get clients, servers info
      
      
      ~~~~~~~~~~
      Structured Parameter Support for ROS 2
      Prerequisites: Basic knowledge of the rclcpp. No need for specialized hardware.
      Necessary programming skills: Familiarity with C++, YAML, Python and CMake.
      Difficulty level: Medium
      Potential mentors: Janosch Machowinski
      Expected size: 175 hours
      Expected outcome: Ability to use structured parameters in rclcpp
      Detailed description: Currently the ROS 2 Parameter interface only supports ‘basic’ datatypes, or arrays of basic datatypes. (E.g. int, std::string, float, std::vector<int>, std::vector< std::string >, std::vector<float> etc) The scope of this task would be, to add support for structured parameters,this is to say C++ structs as parameters, E.g.
      struct MyConfigData 
      { 
      int id; 
      std::string interfaceName; 
      std::vector<struct SomeOtherData> data; 
      }; 
      To achieve this goal, the following tasks need to be completed:
      Modify ParameterValue -- A new member needs to be added to ParameterValue messages. The new member shall contain a structured parameter in the form of a YAML serialized structure.
      Modify rclcpp -- Currently there a checks in place, that forbid passing of complex structures as parameters, these need to be removed.
      Update parameter value -- The rclcpp::ParameterValue needs to be modified to return the serialized YAML structure.
      Convenience methods -- Add convenience functions to convert the serialized structure to a ROS message. ROS messages have a built-in introspection feature. This feature shall be used, to auto serialize the YAML blob into a ROS message. The introspection feature allows to iterate the ROS message. Therefore one can run over a given ROS message and check, if the YAML blob contains entries for all the members in the ROS message. One can also check, if no additional entries are present in the YAML blob. As the ROS message contains the data type of each member, and a generic function to write it, the deserialization of individual message members can also be implemented in a generic way.
      Stretch goal -- Implement tooling to generate YAML ‘layouts’ from a given ROS message. The goal is to implement a simple command line tool, for generating empty YAML structures for a given ROS message. These empty yaml structures are supposed to be used as templates / copied into configuration files.
      
      
      ~~~~~~~~~~
      C/C++ Struct to ROS Message Converter
      Prerequisites: Basic knowledge of the rclcpp. No need for specialized hardware.
      Necessary programming skills: Familiarity with C++, jinja, YAML, Python and CMake.
      Difficulty level: Medium - Hard
      Potential mentors: Janosch Machowinski
      Expected size: 175 hours
      Expected outcome: Automatic wrapping and unwrapping of C++ structures to ROS messages!
      Detailed description:
      The goal of this proposal is to enable a workflow with ROS 2, were one only needs write C/C++ structures and ROS 2 tooling takes care of the generation of intermediate message generation and serialization. This tooling would greatly reduce the amount of boilerplate code needed to transfer a given structure from one node to another node. The outcome we desire would be a tool that can take input of the form:
      struct Foo { 
        int a; 
        float b; 
      }; 
      
      struct Bar { 
        std::vector<Foo> foos; 
      }; 
      and automatically generate the following two ROS messages along with the corresponding typeAdapters :
      Foo.msg: 
      Int a 
      Float32 b 
      
      Bar: 
      Foo[] foos 
      This goal shall be archived by the usage of castxml , Python and Jinja. Castxml is a tool, that converts C++ headers to an xml abstract syntax tree representation, without the hassle of parsing C/C++ code. Therefore castxml enables simple Python scripts to perform C++ introspection. Jinja is template code generation library, that can be used from Python. Combining castxml with jinja therefore allows us to parse arbitrary C++ structures, introspect them, and generate matching ROS message. It also allows for generation of serialization code from the structure to the ROS message and back.
      Stretch goal: opaque type support
      Opaque types are types, for which no automatic serialization and intermediate message can be generated For example, Eigen::Vector2d
      would be opaque, as some members are private. Therefore there should be the option, to register handlers for these opaque types. The handlers shall enable the user to specify custom messages and converter functions for the given opaque type. Library support would be a secondary stretch goal. The system shall generate installable files, that register (if included / loaded) known types as opaques. The auto-generated ‘library opaques’ should just refer to the already generated messages and converters of the originating library. This would effectively suppress type generation for types from other libraries.
      
      
      ~~~~~~~~~~
      Improvements to ROS 2 Tracing
      Prerequisites: ROS 2 experience, some tracing/LTTng tracer experience, Linux, Git
      Necessary programming skills: C++, Python
      Difficulty level: Medium to Hard
      Potential mentors: Christophe Bédard
      Expected size: 175 hours to 350 hours
      Expected outcome: A solution to allow enabling the ROS 2 tracepoints after an application has already been launched.
      Detailed description: Software tracing is a method of collecting low-level runtime data to understand a system's execution. ros2_tracing is a collection of tracing instrumentation for ROS 2 and tools to configure tracing for ROS 2 applications. See the ros2_tracing repository and this ros2_tracing introduction in the ROS 2 docs. Currently, when tracing a ROS 2 application, the tracer has to be configured and tracing has to be started before launching an application. This is because important trace data is generated during the initialization phase of an application; without this information, trace data generated later (e.g., message publication data) cannot be decoded. This means we cannot decide to start collecting trace data for an application that is already running, which makes debugging a system that’s already running harder. The first goal of this project is to find a solution to allow configuring tracing at any point after the application has been launched. See ros2/ros2_tracing#44. This would also make live tracing easier: live tracing means processing the trace data live, as the application is executing, unlike the typical workflow, which is to process the trace data offline, after the execution. A stretch goal for this project would be to improve the tracing configuration tools (ros2 trace command, Trace launch action) to allow configuring a live tracing session. See ros2/ros2_tracing#149.
      
      
      ~~~~~~~~~~
      Raytracing enabled Faster-Than-Realtime GPU based lidar plugin for Gazebo
      Prerequisites: Cursory understanding of what a GPU is and what "ray tracing" means in the context of graphics. Access to a ray tracing enabled GPU on a non-Apple platform (one can be provided remotely if necessary).
      Necessary programming skills: Familiarity with C++, CMake and an understanding of ABI.
      Difficulty level: Medium to hard.
      Potential mentors: Arjo Chakravarty.
      Expected size: 175 hours to 350 hours.
      Expected outcome: A source buildable package containing a LiDAR plugin for gazebo that exploits raytracing.
      Detailed description: This GSoC project exploits ray tracing GPUs in Gazebo. Recently, GPU manufacturers have been adding raytracing capabilities to their GPUs. This includes Apple, Intel, AMD and NVIDIA. Ray tracing has been shown to be an effective pathway for simulating faster-than-realtime depth sensors. Other simulators that do this only exploit NVIDIA's proprietary OptiX API. Recent work in the Rust wgpu community has made it easy to use the Vulkan APIs for raytracing. Early experiments show the ability to ray trace a 256x256 depth camera at 1000fps on a consumer laptop with a 4 year old GeForce 3090 GPU. A prototype has alreasdy been produced, so this project would be focused on extending the prototype into a complete solution. The prototype builds on the rust wgpu package and a thin C wrapper that enables integration into Gazebo. Potential extension work is to support various types of depth sensors including maritime sonars/radars, along with potential publication to a relevant robotics venue.
      
      
      ~~~~~~~~~~
      Gazebo Plugin For Gaussian Splatting
      Prerequisites: Cursory understanding of what a GPU is. No need for specialized hardware. Some knowledge of what NeRFs and Gaussian Splats are.
      Necessary programming skills: Familiarity with C++, GLSL, and CMake.
      Difficulty level: Medium to hard.
      Potential mentors: Arjo Chakravarty.
      Expected size: 175 hours to 350 hours.
      Expected outcome: A ROS 2 package with the relevant Gazebo plugin to display splats.
      Detailed description: Gaussian splatting is an up and coming technique for realtime photo-realistic rendering. It could solve the problem of photo-realism without the need for a specialized 3D artist. This can be a game-changer for the way we simulate robots. The goal of this project is to write a simple shader plugin for Gazebo that renders these splats. Work in this project may lead to a publication. If the candidate wishes, we could also add ROS tools to generate such splats from ROS 2 bags.
      
      
      ~~~~~~~~~~
      Physics-based sonar simulation and new examples with commonly used hardware for underwater robotics
      Prerequisites: Linux, Git, experience with ROS and Gazebo, familiarity with basic simulation concepts.
      Necessary programming skills: C++, Python and CUDA.
      Difficulty level: Medium
      Potential mentors: Woen-Sug Choi, Mabel Zhang and Rakesh Vivekanandan.
      Expected size: 350 hours.
      Expected outcome: Complete the migration and enhancement of a physics-based sonar simulation plugin, enriched with new example cases for underwater robotics. The project will leverage the ROS 2 framework and the latest long-term support (LTS) version of ROS and Gazebo (ROS Jazzy and Gazebo Harmonic). The ultimate goal is to provide a robust tool that can be optionally upstreamed to the new Gazebo, significantly benefiting the maritime robotics community.
      Detailed description: The focus of this project is migrating and enhancing the physics-based multi-beam sonar simulation from Project DAVE (a community library for maritime robotics using ROS and Gazebo), adapting it to function within the ROS 2 and new Gazebo environments. This includes selecting essential components of Project DAVE to maintain the integrity of example use cases. Key aspects of improvement are:
      Performance Enhancements: Introducing half-precision calculations in CUDA to boost refresh rates, potentially contributing to journal publications.
      Capability Expansion: Extending simulations to incorporate additional sonar types, such as side-scan and mechanical scanning sonar.
      Benchmark Integration: Incorporating benchmark cases for maritime robotics hardware, including notable examples like the BlueROV, to ensure the model's adaptability and accuracy in simulating hydrodynamic properties. This project is inspired by the latest advances in underwater sonar simulation technology, which employs acoustic scattering models and GPU-accelerated CUDA computations to deliver physically accurate sonar imagery at functional refresh rates, crucial for realistic robotics simulations. We believe that these enhancements will not only improve sonar simulation but also provide invaluable resources to the maritime robotics community in developing solutions that are both innovative and practical.
      Releasing sdformat in PyPI
      Prerequisites: Experience with Git, Python packaging, CMake and GitHub Actions.
      Necessary programming skills: CMake, Python and C++.
      Difficulty level: Medium
      Potential mentors: Jose Luis Rivero.
      Expected size: 350 hours.
      Expected outcome: A mechanism that allows the Gazebo project to release sdformat in PYPI.
      Detailed description: Implement a method to generate a Python Wheel from the SDFormat source code using standard Python packaging tools. Automate the process of releasing a Wheel by integrating the Wheel creation into the release pipeline of the Gazebo project. Integrate the PyPI publishing mechanism into the release pipeline. Try to generalize the solution so it can be applied to other Gazebo libraries.
      
      
      ~~~~~~~~~~
      Improve UI/UX of Site Editor
      Prerequisites: Proficiency with modern programming languages like C++, Python, JavaScript, or Rust. Experience creating UI, either using immediate mode (e.g. imgui, egui) or retained mode (e.g. angular, react, Qt) UI frameworks. Great to have: Familiarity with Rust and Bevy, experience with designing UIs, experience using 3D CAD tools Difficulty level: Easy to Medium
      Mentors: Xiyu Oh, Grey.
      Expected size: Medium to Large (320 hours to 480 hours).
      Expected outcome: An improved user experience for the site editor.
      Detailed description: The Open-RMF site editor is a 3D tool for creating and editing digital twins of facilities where robots operate. While the tool has a considerable amount of functionality, it currently suffers from a cluttered UI that might not be intuitive for users. At a minimum this project would aim to declutter and refine the UI by reorganizing the widgets and taking advantage of the builtin capabilities of egui, the UI framework that is currently being used by the site editor. A more ambitious candidate can consider migrating the site editor to a different UI library, perhaps one that is reactive and uses retained mode rendering. The site editor is fully implemented in Rust and the Bevy video game engine, so all work for this project will be done in Rust.
      Expected breakdown:
      Evaluate the current state of the site editor UI/UX by experimenting with its current usability.
      Identify usage pain points and draft ideas for what changes to the UI could improve it.
      Evaluate the capabilities of egui and identify whether it offers the capabilities needed to improve the UI or if another framework should be considered.
      Implement improvements to the UI and iterate. Gather feedback on usability from the team and continue to refine the improvements.
      
      
      ~~~~~~~~~~
      Workflow Diagram Editor
      Prerequisites: Familiarity with graphical behavior models like Behavior Trees or Petri Nets. Proficiency with modern programming languages like C++, Python, JavaScript, or Rust. Great to have: Familiarity with Rust and Bevy, experience with programming 2D canvas widgets.
      Difficulty level: Medium to Hard
      Potential mentors: Grey / Luca Della Vedova
      Expected size: 400 hours to 480 hours
      Expected outcome: A Bevy-based library for graphically editing diagrams on a 2D canvas. The library’s capabilities should be suitable for a follow-up project to create an application to draw and edit workflow diagrams for bevy_impulse.
      Detailed description: bevy_impulse is a library in the Open-RMF project that allows users to define complex multi-agent workflows. Workflows are similar to Behavior Trees but are not limited to a tree structure. They can be considered a special case of Petri Nets. A 2D diagram editor that allows users to sketch workflow diagrams would allow us to unlock the full value of bevy_impulse by enabling visual programming of multi-agent behaviors. A fully realized workflow editing application might not be feasible for the scope of one GSoC term, so we primarily aim to start building a foundation for that application. The library will be developed in Rust using the Bevy game engine so it can be cross-platform and target web assembly for use in web browsers, and integrate well with bevy_impulse’s libraries.
      Expected breakdown:
      Get familiar with Bevy and its surrounding ecosystem of third party plugins.
      Get familiar with the workflow concepts that are used in bevy_impulse, e.g. its various operations and how they connect together.
      Investigate various diagram editing tools (e.g. Unreal’s Blueprint editor and Unity’s Visual Scripting editor) and draw inspiration for how the UI might work.
      Devise a strategy for how the widgets would be rendered in a Bevy application.
      Implement the rendering of the diagram widgets and connection curves
      Provide an API for downstream projects to decorate the diagram widgets according to their use cases.
      
      
      ~~~~~~~~~~
      Multi-Agent Traffic Optimization
      Prerequisites: Proficiency with motion planning and graph search. Experience with Rust programming or familiarity with languages like C++, Python, and JavaScript.
      Great to have: Familiarity with Rust and Bevy, experience with multi-agent path finding algorithms.
      Difficulty level: Medium to Hard
      Potential mentors: Grey / Luca Della Vedova
      Expected size: 320 hours to 480 hours
      Expected outcome: The mapf library is a multi-agent path finding and planning framework developed for the next generation of Open-RMF. For this project the contributor will improve multi-agent traffic debug tools in the Open-RMF site editor and use them to ensure consistent, intuitive multi-agent paths are generated by Open-RMF’s mapf library.
      Detailed description: A key component of Open-RMF is the ability to route multi-agent traffic to avoid conflicts between mobile robot agents that are each performing independent tasks. The mapf library was designed to be a modular, customizable framework for multi-agent path finding. The goal of this project is to pressure test mapf, identify scenarios where it fails or gives inconsistent results, and resolve any underlying issues that could negatively impact its use in a deployment. The site editor will be used to generate test cases, to simulate the results of the mapf library, and to provide a tool to debug the planner. The debugging tool would visualize and step through each iteration of the mapf solving process, allowing the user to investigate how the solver works and identify where it could be improved. This role may involve enhancing the debugging tools in addition to the mapf library itself. Both mapf and the site editor are written in Rust, so this role will be done entirely in Rust.
      Expected breakdown:
      Familiarize yourself with the site editor and how to create different scenarios.
      Familiarize yourself with the debugging tool and how multi-agent plans are generated.
      Build different scenarios, looking for failure cases or sub-optimal solutions.
      Use the debugging tools to track down the causes of undesirable behaviors.
      Ambitious candidates may work on creating pipelines to automatically generate large scenarios and/or to add randomization to test cases.
      
      
      ~~~~~~~~~~
      New Open-RMF Demo: Free Fleet Map Switching
      Prerequisites: Linux, Git, ROS 2, Gazebo, familiarity with Nav2 and Open-RMF are a plus
      Necessary programming skills: Python, C++.
      Difficulty level: Medium
      Potential mentors: Aaron Chong
      Expected size: 480 hours
      Expected outcome: A new Open-RMF demo simulation which showcases Open-RMF integration with a fleet of turtlebots running Nav2 and Free Fleet within a two story building. These two simulated robots will be capable of navigating and performing tasks across the multiple building levels and switching Nav2 maps when arriving at a particular floor via elevator. This new demo will serve as a starting point for folks new to Open-RMF and Free Fleet.
      Detailed description:
      Simulation demo and mapping: Re-use the existing rmf_demos hotel world, to create a new demo world and replace the existing robots with two simulated TurtleBots. These turtlebots will then map the simulation world and share the map between themselves to support single-floor navigation using Nav2.
      Integration of Open-RMF and Free Fleet: Set up a Free Fleet adapter, and integrate it with the two TurtleBots, to support basic single-floor Open-RMF tasks.
      Implement localization and map-switching command: This will allow the simulated robots to traverse levels using the virtual elevators, switch Nav2 maps, and still be able to localize, navigate, and receive Open-RMF commands to perform tasks across levels. Other supporting features within the Free Fleet Adapter will also require implementation. The fleet_adapter_mir can be used as a reference implementation.
      Documentation of usage, configuration and the new simulation as a "how to" guide for users .
      
      
       ~~~~~~~~~~
      ROS Controls projects list

      Mission-Control for ros2_control
      Prerequisites: git and Github
      Necessary programming skills: C++, Python
      Difficulty level: Medium
      Potential mentors: Bence Magyar, Sai Kishor
      Expected size: 175 hours to 350 hours
      Expected outcome: A new tool that supports transitioning ros2_control components between known states using a declarative notation.
      Detailed description: The ros2_control framework focuses on direct management of hardware and their controllers to enable real-time capabilities with ROS. Although those interfaces are easy to use, they provide only "manual" control over the system's state. Therefore, very often in more complex systems our users have to implement an external, state-machine like component that serves as an orchestrator for ros2_control. The main purpose of such a component is to serve as a high-level conductor of ros2_control making sure that at the appropriate moment the right controllers and hardware are in expected states. The project could also synergize with ongoing state visualization efforts as well as an extension to wrangle ROS 2 Managed Nodes. This functionality should replace some high-level components currently used, e.g., MoveIt2-"SimpleControllerManager".
      Goals:
      Defining a scenario in form of a multi-robot and multi-tool configuration and its behavior that serves as a benchmark.
      Review that the controller_manager provides all the necessary data for this application.
      Define a file format for users to declare controller / state presets.
      Implementing the mission-control module/script that sets the controller_manager, i.e., the ros2_control framework, in a specific configuration/state.
      Contributors are encouraged to review existing research papers and open source projects for similar functionality.
      
      
      ~~~~~~~~~~
      Hardware Diagnostics Support for ros2_control
      Prerequisites: git and Github
      Necessary programming skills: strong C++, ROS 2
      Difficulty level: Medium/Hard
      Potential mentors: Bence Magyar, Sai Kishor
      Expected size: 175 hours to 350 hours
      Expected outcome: Reporting capabilities are available for hardware components with minimal code changes
      Detailed description: The ros2_control framework uses a plugin-based system to support multiple hardware drivers at the same time. It takes care of resource constraints between different controllers and hardware components, asynchronous operation of controllers, etc. As of now, controller_manager publishes the diagnostics of itself, and for controllers and hardware components about their lifecycle state and operational statistics such as their periodicity and their execution time. However, A current limitation of the framework is that hardware components, e.g. the ros2_control hardware driver plugin for a given robot, doesn't have a good API for reporting the diagnostics of its own hardware, for instance, the state of the CAN Bus, some internal motor control board stats like temperature, error codes etc. This integration would make the ros2_control, provide complete diagnostics within its ecosystem. This project focuses on setting up an API that hardware manufacturers & driver maintainers can use to report things with minimal code changes to their existing setups.
      Goals:
      Modify the Hardware Interfaces to fetch the hardware diagnostics.
      Possible unification of three hardware interfaces into a single one.
      Add tests to test the integration.
      Add Documentation.

      ~~~~~~~~~~



      Releasing sdformat in PyPI
      Prerequisites: Experience with Git, Python packaging, CMake and GitHub Actions.
      Necessary programming skills: CMake, Python and C++.
      Difficulty level: Medium
      Potential mentors: Jose Luis Rivero.
      Expected size: 350 hours.
      Expected outcome: A mechanism that allows the Gazebo project to release sdformat in PYPI.
      Detailed description: Implement a method to generate a Python Wheel from the SDFormat source code using standard Python packaging tools. Automate the process of releasing a Wheel by integrating the Wheel creation into the release pipeline of the Gazebo project. Integrate the PyPI publishing mechanism into the release pipeline. Try to generalize the solution so it can be applied to other Gazebo libraries.
      
      
      
      ~~~~~~~~~~
      vcstool Modernization and Improvements
      Prerequisites: git and other version control systems, GitHub Actions
      Necessary programming skills: Python
      Difficulty level: Medium
      Potential mentors: Christophe Bédard, Jose Luis Rivero, Clara Berendsen
      Expected size: 175 hours to 350 hours
      Expected outcome: Modernize use of Python, create new useful features
      Detailed description:
      vcstool is a meta version control system tool that interacts with multiple version control systems to make working with multiple repositories easier. It is heavily used in ROS and Gazebo environments, for example when building ROS 2 from source or in the Gazebo source installations. It is an official package in Debian and Ubuntu among other distributions and also available via PyPI. vcstool has not really been maintained over the last few years. The first goal of this project is to update it to bring modern Python support to the code and replace the ancient implementations. The GitHub Actions workflow also needs to be updated, since it uses older versions of actions. There are many bug reports, feature requests, and open PRs (see the original repository). The second goal of this project is to help fix bugs, identify interesting feature requests and implement them, and in general help shape the future direction of vcstool. Expanding vcstool’s API surface so it can be used in place of https://github.com/vcstools/vcstools would be an excellent stretch goal for the project.
      
      ~~~~~~~~~~
      Add support for mixin composition in colcon-mixin.
      Prerequisites: git and GitHub, have used the colcon build tool in the past
      Necessary programming skills: Python
      Difficulty level: Medium
      Potential mentors: Scott Logan, Sean McGrath, Steven! Ragnarök
      Expected size: 175 hours to 350 hours
      Expected outcome: Add new features to colcon-mixin which will allow mixins to reference other mixins.
      Detailed description: colcon is an extensible build tool optimized for building collections of federated projects which is commonly used with Open Robotics projects. Mixins allow for easily repeating complex actions by incorporating command line arguments defined in external files. It is not currently possible for the command-line arguments provided by a mixin to reference other mixins but this feature has been requested in https://github.com/colcon/colcon-mixin/issues/39 This project will involve constructing a mixin graph and exploring how to determine the order of application as well as how mixin arguments extend or override arguments from referenced mixins.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-robotics/
    idea_list_url: https://github.com/osrf/osrf_wiki/wiki/GSoC25

  - organization_id: 105
    organization_name: Open Science Initiative for Perfusion Imaging
    no_of_ideas: 12
    ideas_content: |
      
      OSIPI package – DCE Module
      Proposed mentors: Luis Torres, Sirisha Tadimalla
      
      Languages/skills: Python
      
      Estimated project length: 350 hours
      
      Difficulty: Moderate/Difficult
      
      Category: Core development
      
      Relevant links: OSIPI python package, GSoC 2024 project  
      
      Description: Building on the foundational work from last year’s GSoC project—which established the core infrastructure for the OSIPI perfusion package—this project focuses on creating the Dynamic Contrast Enhanced (DCE) MRI module. In keeping with OSIPI’s lexicon and guidelines, the DCE module will introduce a standardized toolkit for processing DCE datasets. Specifically, the contributor will implement robust data read/write functionalities, standard pharmacokinetic modeling algorithms, and advanced deconvolution methods to derive quantitative perfusion parameters — providing an end-to-end solution that simplifies the DCE image processing pipeline.
      
      Expected outcomes:
      
      The key outcome of this project will be the DCE module for our unified OSIPI package.
      
      Methods for handling DICOM and NIFTI/BIDS data.
      Methods for Pharmacokinetic Modeling for Estimation of Physiological Parameters
      Robust unit-testing
      Documentation
      Requirements:
      
      (Minimum) Background in linear algebra and python
      (Recommended) Git, Image Processing
      (Ideal) Background in medical image processing


      ~~~~~~~~~~



      OSIPI package – Blood-brain barrier module
      Proposed mentors: Ben Dickie, Jan Petr
      
      Languages/skills: Python
      
      Estimated project length: 350 hours
      
      Difficulty: Difficult
      
      Category: Optimization
      
      Relevant links: ExploreASL, DCE module - GSoC 2024 project 
      
      Project description: Building on the foundational work from last year’s GSoC project—which established the core infrastructure for the OSIPI perfusion package—this project focuses on creating the functionality to model blood-brain barrier (BBB) water exchange. Specifically, the contributor will implement robust data read/write functionalities,and create Python functions to model BBB exchange — providing an end-to-end solution that simplifies and standardizes the estimation of BBB water exchange for ASL and DCE-MRI data.  
      
      Expected outcomes:
      
      The key outcome of this project will be the BBB module for our unified OSIPI package:
      
      Methods for handling DICOM and NIFTI/BIDS data.
      Methods for Pharmacokinetic Modeling for Estimation of Physiological Parameters of azeeBBB transfer in DCE and ASL data
      Robust unit-testing
      Documentation
      Requirements:
      
      (Minimum) Background in linear algebra
      (Recommended) Git, Image Processing and Python Modeling (e.g. SciPy, NumPy)
      (Optional) Background in medical image processing

      ~~~~~~~~~~
      
      OSIPI package - ASL module
      Proposed mentors: Maria Mora, Zhiliang Wei
      
      Languages/skills: Python
      
      Estimated project length: 350 hours
      
      Difficulty: Moderate
      
      Category: Core development
      
      Relevant links: OSIPI Task Force 2.2,  ISMRM 2022 abstract, PyASLtoolbox, GSoC 2024 project
      
      Project description: The current version of the ASL module has no modularity to explore and test different preprocessing snippets (i.e., algorithms) across pipelines. In addition, these tools are designed for brain imaging and lack adaptability for broader applications beyond the brain. A modular PyASL library will bridge this gap, providing researchers and developers with a versatile platform to test and integrate new functionalities more efficiently, tailor pipelines to specific research needs, and support algorithmic exploration for population- or organ-specific ASL imaging processing.
      
      Expected outcomes:
      
      Redesign of the current PyASL architecture to incorporate modularity such that it can be integrated in the unified Python package, i.e., break down the existing pipelines into preprocessing snippets.
      Modification of current CBF quantification methods is also needed to quantify perfusion in other organs.
      Implementation of a framework for developers to add or modify specific preprocessing snippets or quantification approaches.
      Documentation of the improved PyASL.
      Requirements:
      
      (Minimum) Python proficiency
      (Recommended) Experience in modular software design.
      (Ideal) Familiarity with neuroimaging preprocessing pipelines.

      ~~~~~~~~~~
      
      OSIPI package - ASL module extension for preclinical imaging
      Proposed mentors: Zhiliang Wei, Maria Mora
      
      Languages/skills: Python/Matlab
      
      Estimated project length: 175 h
      
      Relevant links: OSIPI TF 2.2, ISMRM abstract 2022, PyASL at GitHub, GSoC 2024 project
      
      Difficulty: Moderate
      
      Category: Core development
      
      Project description: The first version of the library was done within GSoC 2024. This project aims to extend the current repository with a preclinical ASL package, including scanner method files, parameter protocols, and data processing codes. Harmonizing processing is difficult when data comes from various sequences. There are too many variations to be considered. The preclinical ASL is a good chance to try standardization from sequences to imaging parameters and subsequently to processing.
      
      Expected outcomes:
      
      Established perfusion imaging package (including sequence, protocol, and processing tool) for small animals
      Pulsed and pseudo-continuous ASL packages usable for preclinical studies
      Requirements:
      
      (Minimum) Python proficiency
      (Recommended) Experience in modular software design
      (Ideal) Basic knowledge of neuroimaging processing


      ~~~~~~~~~~
      OSIPI package - automated testing for ASL module
      Proposed mentors: Azeez Adebimpe, Yifan Shuai, Maria Mora
      
      Languages/skills: Python, CI/CD (GitHub Actions, Travis CI), pytest
      
      Estimated project length: 175
      
      Links: OSIPI TF 2.2, ISMRM 2022 abstract, PyASL at GitHub, GSoC 2024 project 
      
      Difficulty: Moderate
      
      Project description: The first version of the library was done within GSoC 2024. Currently, TF members are testing these contributions manually. This manual process involves writing code specifically for testing purposes and publishing the test results on a separate website. As new code contributions are added, the test results need to be manually updated,  making the process time-consuming and error-prone. The primary objective of this project is to develop a comprehensive framework that automates the entire testing process, starting from the creation of individual tests to the publication of results on the dedicated website. The ultimate goal is to establish an automated testing algorithm for each step in the processing pipeline.
      
      Expected outcomes:
      
      1. Development of an automated testing framework for the ASL processing module.
      
      2. Integrate CI/CD pipelines to run tests automatically and dynamically publish results to a dedicated website.
      
      
      Requirements:
      
      (Minimum) Strong proficiency in Python. Experience with automated testing frameworks (e.g., pytest, unittest).
      (Recommended) Familiarity with MRI processing pipelines
      (Ideal) Knowledge of CI/CD tools (e.g., GitHub Actions, Travis CI, or Jenkins)

      ~~~~~~~~~~
      
      
      OSIPI package - IVIM module extends the testing framework for AI/Bayesian models
      Proposed mentors: Eric Peterson, Daan Kuppens
      
      Languages/skills: Python
      
      Estimated project length: 350 hours
      
      Difficulty: Moderate
      
      Category: core development
      
      Project description: This project aims to significantly enhance the existing IVIM repository testing framework to effectively evaluate the performance and reliability of AI and Bayesian models. The current framework has limitations in testing models with diverse requirements, such as difficulty in adapting to different model architectures, training procedures, and evaluation metrics; inadequate support for testing deep learning models, Bayesian networks, reinforcement learning algorithms, etc; difficulty in testing models under various conditions, including noisy data, missing values, and extreme parameter settings.
      
      Expected outcomes:
      
      This project will focus on refactoring the framework into reusable components to improve maintainability and facilitate customization; introducing flexible configuration options to allow for easy adjustment of testing parameters (e.g., dataset size, number of iterations, evaluation metrics); extensibility by developing a plugin system or similar mechanism to enable easy integration of new testing modules for different AI/ML algorithms.
      
      This project will result in a significantly improved testing framework that empowers developers and researchers to rigorously evaluate the performance and reliability of AI and Bayesian models, leading to more robust and trustworthy IVIM fitting.
      
      Requirements:
      
      (Required) Unittest, PyTest, or similar
      Basic understanding of AI/ML concepts (e.g., supervised learning, Bayesian inference)
      Version control (Git), code style, documentation


      ~~~~~~~~~~
      
      Standardized scoring pipeline for OSIPI challenges
      Proposed mentors: Andre Paschoal, Soudabeh Kargar
      
      Languages/skills: Python, GitHub
      
      Estimated project length: 175 hours
      
      Links: OSIPI/TF6.2_DCE-DSC-MRI_Challenges: TF6.2, ASL OSIPI Challenge, DCE OSIPI Challenge, OSIPI TF 6.2
      
      Difficulty: Moderate
      
      Category: Low hanging-fruit
      
      Project description: OSIPI has organized two challenges in the past that focused on the analysis of perfusion imaging data. The aim of the challenges is to understand where differences between analysis pipelines come from and to determine best practices in the analysis of perfusion analysis. We are currently preparing for follow-up challenges. The analysis of the challenge data was done separately for both challenges but based on similar methods. To make future challenges more efficient and standardized, we would like to develop a standardized pipeline for the analysis of challenge data. The code from previous challenges will serve as a starting point.
      
      Expected outcomes:
      
      Standardized pipeline in Python for evaluation of OSIPI challenges
      Requirements:
      
      Python proficiency, GitHub

      ~~~~~~~~~~
      
      Database and web development
      Methods section generator for ASL
      Proposed mentors: David Thomas, Jan Petr, Hanliang Xu
      
      Languages/skills: Python
      
      Estimated project length: 175 hours
      
      Difficulty: Moderate
      
      Category: Core development
      
      Relevant links: OSIPI TF4.1, ASL Lexicon, GSoC 2024 project, GSoC 2024 final report
      
      Project description: For transparency and reproducibility in MRI research studies, it is important to report the sequence acquisition parameters accurately. Accessing these parameters from the image file headers requires familiarity with file formats and interpretation of the information they contain. The aim of this project is to provide a simple-to-use Python-based software tool that reads the metadata from ASL MRI image files, extracts the important data acquisition parameters, and formats them in a short text paragraph that can be ‘cut-and-pasted’ into the “Methods/Acquisition” section of a scientific publication. The tool will work with known and standardized data definitions and will be able to handle exceptions and missing data, handle several different data types, and check/report data consistency.
      
      
      Expected outcomes: 
      
      The backend currently handles input from BIDS data (Brain imaging data structure = NiFTI and JSON data) and DICOM data (in a pilot mode). The web-based GUI allows file uploads and automated report generation. We would like to add the following features:
      
      Current GUI reports missing required parameters. Add a new feature that interactively asks the user to provide the missing parameters;
      Improve the testing framework for comparing the input database with manually checked reference reports;
      Improve and finalize the module for the DICOM input to handle hidden and private tags that are specific for different input data (mentors will provide the keys to interpret these tags);
      Improve the modularity of the software to make future extensions to other sequences (DSC/DCE/IVIM) easy.
      Requirements:
      
      (Minimal) Python and basic experience in the development of web-based frontends
      (Willing to) Learn and understand the basics of the particular MRI sequences
      (Optional) Experience in medical imaging, MRI, or DICOM format

      ~~~~~~~~~~
      
      
      Knowledge Atlas for OSIPI perfusion lexicons
      Proposed mentors: Ben Dickie, Patricia Clement
      
      Languages/skills: SQL
      
      Estimated project length: 350 hours
      
      Difficulty: Moderate
      
      Category: Core development
      
      Languages/skills: Python, databases, web development
      
      Relevant links: https://github.com/OSIPI/OSIPI_CAPLEX
      
      Project description: A key problem in imaging science is the lack of reproducibility, which can arise from a number of sources, from the acquisition method itself, or simply whether or not the process is described clearly enough for others to follow. To address this, OSIPI has developed 2 lexicons (one for DCE/DSC and one for ASL). The contrast agent-based lexicon (CAPLEX) is currently hosted on a GitHub documentation site, whereas the ASL lexicon is still only accessible through Google Docs. This project will continue preliminary work to overhaul how the two lexicons are displayed and accessed by migrating to a database and building a web app to display the lexicon content and tools.
      
      Expected outcomes:
      
      A database consisting of lexicons, as well as providing room for future database projects
      Web app to display lexicon content and tools
      Requirements:
      
      Databases (e.g. SQL), Experience with data handling and manipulation (e.g., file I/O, databases)
      Basic knowledge of web development frameworks (e.g., Flask, Django, FastAPI) for API development
      Basic understanding of medical imaging concepts

      ~~~~~~~~~~
      
      Unified HTML pages for OSIPI output
      Proposed mentors: Petra van Houdt, Luis Torres
      
      Languages/skills: Python, Markdown
      
      Estimated project length: 90 hours
      
      Difficulty: Easy
      
      Category: Low-hanging fruit
      
      Relevant links: OSIPI_CAPLEX, OSIPI DCE-DSC code
      
      Project description: Over time, OSIPI has produced several projects with published documentation.  However, due to the nature of our organization’s organic growth, their styles, structure, and fundamental set-ups are different, which leads to difficulty organizing, searching, and finding relevant information in our docs. In this project, we will standardize our approach by leveraging current best practices for HTML generation and styling and then subsequently port all of the existing documentation to this new approach. One of the outcomes of this project is to provide recommendations for future documentation tasks that comply with our styling.  
      
      Expected outcomes:
      
      The main outcome of this project is to create a unified standard/style for our documentation hosted via GitHub.
      A secondary outcome will be to unify current documentation with our defined standard.
      Requirements:
      
      (Required) Python, Markdown
      (Optional) HTML/CSS
      (Ideal) Github Pages, MkDocs, Admonitions

      ~~~~~~~~~~
      
      Infrastructure/Automation
      Dockerized Data Processing Pipeline for Medical Imaging
      Proposed mentors: Eric Peterson, Luis Torres
      
      Languages/skills: Python
      
      Estimated project length: 350 hours
      
      Difficulty: Moderate
      
      Category: Infrastructure/automation
      
      Project description:
      
      This project aims to develop a containerized pipeline that can efficiently process medical imaging data using IVIM or other tools. The modularized docker images will encapsulate all necessary dependencies, enabling cross-platform deployment, execution and integration with clinical imaging pipelines. Finally, we want to enable visual orchestration of the resulting pipeline through a web-based interface.
      
      Expected outcomes:
      
      Key outcomes will include:
      
      Modular, containerized processing pipelines with support for reading and writing data as DICOM and NIfTI from local disks, cloud storage, and DICOM server integrations (such as PACS).
      A simple web-based interface for orchestrating the image processing pipeline enabling users to monitor the status of processing jobs, view logs, and configure runtime parameters.
      Ultimately this project will result in a valuable tool for medical imaging researchers and practitioners. The containerized pipeline will streamline data processing workflows, improve efficiency, and facilitate collaboration by providing a standardized and reproducible environment for image analysis tasks.
      
      
      Requirements:
      
      (Required) Unittest, pytest, Docker
      (Optional) Kubernetes, Airflow/Argo
      Basic understanding of medical imaging concepts (e.g., DICOM format)
      Experience with data handling and manipulation (e.g., file I/O, databases)
      Basic knowledge of web development frameworks (e.g., Flask, Django, FastAPI) for API development
      
      
      ~~~~~~~~~~
      GitHub testing for ExploreASL pipeline 
      Proposed mentors: Henk-Jan Mutsaerts, Mathijs Dijsselhof, Jan Petr
      
      Languages/skills: GitHub, Matlab
      
      Estimated project length: 90 hours
      
      Difficulty: Easy
      
      Relevant links: ExploreASL code, ExploreASL publication
      
      Category: Low hanging-fruit
      
      Project description: While basic processing of ASL perfusion MRI data can be done using in-house scripts or GUIs, a dedicated pipeline able to batch-process large heterogeneous datasets is needed to process large clinical studies efficiently. ExploreASL is an open-source package that was developed specifically for this task. Testing is of the highest importance in sustaining further software development in a larger group of collaborators. While we have several tests in place, we lack their joint integration and automation.
      
      
      Expected outcomes: 
      
      We need to configure GitHub actions to run the collection of our test automatically:
      
      Configure and debug GitHub actions to run our Matlab test scripts on different OSes.
      Adapt the test result to the JUnit or similar format
      Requirements:
      
      (Minimal) GitHub and Matlab experience
      (Optional) Experience with GitHub actions and JUnit testing
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-science-initiative-for-perfusion-imaging/
    idea_list_url: https://docs.google.com/document/d/e/2PACX-1vSuYh57hsLUXbmrA5tozX4Ucne0sRXnmFt5xBA88gzDZJKZYD4-Bq04J9acer2d_i6NP6xhimmz4m5i/pub


  - organization_id: 106
    organization_name: Open Science Labs
    no_of_ideas: 13
    ideas_content: |


      Alpha One Labs
      Project Idea 001: AI-Powered Personalized Learning Assistant
      Abstract
      An AI-driven personalized tutor that adapts to each student's learning style, offering real-time assistance, tailored study plans, and interactive lessons. This assistant enhances engagement by providing instant feedback, adaptive content recommendations, and structured learning paths.

      License
      GNU General Public License v3.0: https://github.com/alphaonelabs/education-website/blob/main/LICENSE

      Code of Conduct
      https://github.com/alphaonelabs/education-website?tab=coc-ov-file#readme

      Current State
      Initial AI tutoring prototype developed using OpenAI API.
      Basic chatbot functionality in place for answering questions and tracking student progress.
      Requires further integration with study planning tools and enhanced AI-driven feedback.
      Tasks
      Improve AI-generated responses for specific subjects.
      Implement personalized study plans based on learning patterns.
      Integrate voice-based interaction for accessibility.
      Develop a student progress dashboard.
      Expected Outcomes
      A fully functional AI assistant that provides real-time tutoring, personalized learning paths, and progress tracking.
      Improved engagement through interactive AI-powered learning.
      Scalable platform for multiple learning disciplines.
      Details
      Prerequisites: Machine Learning (NLP), Python, OpenAI API, Django/Node.js, React/Tailwind CSS
      Duration: 175 hours
      Complexity: Medium
      Potential Mentor(s): Daniel Jones, Lena Carter
      References
      OpenAI API Documentation
      Best practices for AI-driven education platforms

      ~~~~~~~~~~
      Project Idea 002: Real-Time Collaborative Virtual Classroom
      Abstract
      A live, interactive digital classroom that mimics an in-person learning environment with real-time chat, collaborative whiteboards, breakout rooms, and document sharing. This project enhances remote learning by fostering engagement and seamless collaboration.

      License
      GNU General Public License v3.0: https://github.com/alphaonelabs/education-website/blob/main/LICENSE

      Code of Conduct
      https://github.com/alphaonelabs/education-website?tab=coc-ov-file#readme

      Current State
      Basic real-time chat and document collaboration functionalities implemented.
      Requires whiteboard, breakout rooms, and improved WebRTC integration for real-time communication.
      Tasks
      Implement live collaborative whiteboards with annotation features.
      Develop breakout rooms for group discussions.
      Enhance real-time audio/video communication for seamless interaction.
      Improve user authentication and session management.
      Expected Outcomes
      A fully integrated virtual classroom with real-time communication and collaboration tools.
      Increased engagement through interactive learning features.
      Scalability for educational institutions and online courses.
      Details
      Prerequisites: WebSockets, WebRTC, Django/Node.js, React, Firebase/PostgreSQL
      Duration: 175 hours
      Complexity: High
      Potential Mentor(s): Daniel Jones, Lena Carter
      References
      WebRTC Documentation
      Best practices for real-time collaborative tools

      ~~~~~~~~~~
      Project Idea 003: Data-Driven Analytics Dashboard for Educators
      Abstract
      A comprehensive analytics dashboard that provides educators with actionable insights into student performance, engagement, and learning patterns. This tool empowers teachers to adapt lesson plans, identify struggling students, and measure course effectiveness.

      License
      GNU General Public License v3.0: https://github.com/alphaonelabs/education-website/blob/main/LICENSE

      Code of Conduct
      https://github.com/alphaonelabs/education-website?tab=coc-ov-file#readme

      Current State
      Basic data collection pipeline implemented.
      Requires better visualization, predictive analytics, and integration with AI grading tools.
      Tasks
      Implement data visualization for student progress tracking.
      Develop AI-powered insights for personalized recommendations.
      Integrate with automatic grading and feedback systems.
      Enhance report generation for educators and administrators.
      Expected Outcomes
      A fully functional analytics dashboard offering real-time insights.
      Improved student performance tracking through AI-driven analytics.
      Data-driven decision-making for educators.
      Details
      Prerequisites: Python, Django, PostgreSQL, D3.js/Chart.js, AI/ML (optional)
      Duration: 175 hours
      Complexity: Medium
      Potential Mentor(s): Daniel Jones, Lena Carter
      References
      Data visualization best practices
      AI in education research papers

      ~~~~~~~~~~

      ArxLang/ASTx




      Project Idea 1: Transpiler from ASTx to Python AST
      Abstract
      This project aims to develop a transpiler from ASTx to Python's built-in AST, allowing seamless conversion of ASTx representations into Python's ast module structures. This feature will enable Python code generation from ASTx, making it easier to integrate ASTx with Python-based tools, static analysis, and compilers. The implementation should follow ASTx's existing transpiler structure, leveraging the current ASTx to Python Source Transpiler as a reference.

      Current State
      ASTx provides a transpiler from ASTx to Python source code.
      There is no direct conversion from ASTx to Python's ast module.
      Python's ast module allows programmatic manipulation of Python code.
      A structured approach is required to map ASTx node types to their Python AST equivalents.
      Tasks
      Implement a node visitor pattern to translate ASTx nodes into Python AST nodes.
      Define mappings for:
      Expressions (BinaryOp, FunctionCall, Literals, etc.)
      Statements (IfStmt, WhileStmt, FunctionDef, etc.)
      Declarations (VariableDeclaration, FunctionPrototype, etc.)
      Ensure correct handling of variable scoping and function definitions.
      Integrate the new transpiler into astx.tools.transpilers.python.py.
      Write unit tests to validate conversions between ASTx and Python AST.
      Provide examples and documentation for users.
      Expected Outcomes
      A working transpiler from ASTx to Python AST.
      A test suite ensuring accurate translation.
      Documentation explaining how to use the transpiler.
      Examples showcasing ASTx → Python AST → Python code execution.
      Details
      Prerequisites:

      Understanding of Python's ast module (basic level).
      Familiarity with ASTx and its structure (basic level).
      Experience in compiler design, transpilers, or code generation (basic level).
      Proficiency in Python and visitor patterns (basic level).
      Duration: 350 hours

      Complexity: Medium

      Potential Mentor(s): Ivan Ogasawara, Ana Krelling, Devansh Parmar

      References
      Python ast Module: Python Docs
      ASTx Source Code: GitHub - ASTx
      Existing Python Transpiler: ASTx Python Transpiler
      Python AST Manipulation Example: Python AST Walkthrough

      ~~~~~~~~~~

      Project Idea 1: Adding Pipeline Support
      Abstract
      Makim is a versatile and extensible automation tool designed to simplify complex workflows and tasks in software development. While it excels at managing individual targets, it currently lacks native support for defining and executing pipelines, a critical feature for orchestrating sequences of tasks efficiently. This proposal aims to extend Makim's capabilities by introducing support for defining, running, and visualizing pipelines within Makim configuration files.

      The core objectives of this project are as follows:

      Pipeline Definition: Extend Makim configuration file (YAML format) to include a dedicated section for defining pipelines. Pipelines will consist of a sequence of steps, where each step can be associated with any existing Makim target.

      Pipeline Execution: Implement a pipeline execution mechanism within Makim, allowing users to run defined pipelines using a simple command-line interface. Pipelines should support both linear and branching flows, enabling complex task orchestration.

      Pipeline Visualization: Integrate a graph visualization tool, such as asciinet, to allow users to view the structure and dependencies of defined pipelines. This feature will enhance transparency and aid in debugging complex workflows.

      Documentation: Update Makim's documentation to include comprehensive guidance on defining and executing pipelines. Provide examples and best practices for creating efficient and maintainable pipeline configurations.

      Current State
      Currently, Makim has support for tasks, scheduled tasks, hooks, task dependencies, etc

      Tasks
      https://github.com/osl-incubator/makim/issues/26
      Expected Outcomes
      Support for pipelines
      makim pipeline run
      makim pipeline show
      Updates to the following files:
      src/makim/cli/__init__.py
      src/makim/schema.json
      src/makim/core.py
      Creation of a new files:
      src/makim/cli/pipelines.py (ref: src/makim/cli/cron_handlers.py)
      src/makim/pipelines.py (ref: src/makim/scheduler.py)
      Comprehensive documentation and tests for all new commands.
      Blog post about Makim pipelines
      Details
      Prerequisites:
      Hard Skills:
      Python (intermediate to advanced level)
      Command-line interface development (basic level)
      JSON schema understanding
      Basic concepts about pipelines between commands
      Soft Skills:
      Problem-solving
      Code documentation
      Collaboration through GitHub
      Expected Time: 350 hours
      Complexity: Medium
      Potential Mentor(s): Ivan Ogasawara, Abhijeet Saroha, Sandro Loch, Anavelyz Perez, Yurely Camacho
      References
      https://www.gnu.org/software/bash/manual/html_node/Pipelines.html
      https://airflow.apache.org/docs/apache-airflow/stable/index.html


      ~~~~~~~~~~



      Project Idea 2: Adding Windows Support for Makim
      Abstract
      Makim is a powerful and versatile automation tool used widely in software development for task orchestration and workflow management. However, one significant limitation has been its lack of native support for Windows, a platform frequently used by developers. This project proposal aims to bridge this gap by enhancing Makim's compatibility with Windows environments.

      Currently, Makim relies on the sh library, which is not fully compatible with Windows. The proposed project seeks to abstract the usage of sh within Makim and introduce an alternative approach that seamlessly integrates with Windows systems. Two promising alternatives, subprocess and plumbum, will be explored for this purpose.

      The primary objectives of this project are as follows:

      Windows Compatibility: Implement a platform detection mechanism within Makim to identify when it's running on Windows. When running on Windows, the tool should automatically switch to using the Windows-compatible alternative (e.g., subprocess or plumbum) for executing commands.

      Testing and Evaluation: Thoroughly test the compatibility and performance of the chosen alternative(s) on both Windows and Unix-like systems. Benchmarking will be conducted to determine if the alternative(s) offer advantages over the current sh implementation.

      Documentation: Update Makim's documentation to reflect the new Windows compatibility features and provide clear guidelines for users on how to utilize the tool effectively on Windows platforms.

      Community Engagement: Encourage community involvement by seeking feedback and contributions from users and developers, especially those working in Windows-centric environments. Create blog posts.

      This project presents an exciting opportunity to make Makim more accessible to a broader audience of developers, including those working in Windows-based environments. By addressing this limitation, we aim to enhance the usability and adoption of Makim, further solidifying its position as a valuable automation tool in the software development ecosystem.

      Current State
      Current, Makim doesn't support windows, because it relays on the library sh that doesn't work on windows.

      Tasks
      https://github.com/osl-incubator/makim/issues/47
      Expected Outcomes
      The project should be able to be installed on Windows.
      Ability to be used with powershell as a backend
      The packaging recipe on conda-forge should be updated
      The creation of a blog post about new support
      Documentation should be updated
      The test on CI for windows should be enabled and any issues should be fixed
      Details
      Prerequisites:
      Python
      Object-oriented programming (OOP)
      YAML
      shell script
      Expected Time: 350 hours
      Potential Mentor(s): Ivan Ogasawara, Abhijeet
      References
      https://sh.readthedocs.io/en/latest/
      https://pypi.org/project/plumbum/
      https://docs.python.org/3/library/subprocess.html
      NOTE: Maybe pbs could be used as a reference. It is very old and it cannot be used directly, also the package on pypi doesn't look to be the same lib as the one on github (don't install it!).

      https://stackoverflow.com/a/46471030
      https://github.com/dbarnett/pbs

      ~~~~~~~~~~

      Porting stack.py to C++ backend
      Project Length - 350 hours

      Mentors - @czgdp1807, @anutosh491

      Expected Outcomes - Python tests running with Backend.CPP as the backend.

      ~~~~~~~~~~

      Alternatives to unordered_map, unordered_set for C++ backend
      Project Length - 175 hours

      Mentors - @czgdp1807, @anutosh491

      Expected Outcomes - unordered_map, unordered_set have drop in replacements implement in PyDataStructs.

      ~~~~~~~~~~
      
      Comparing Data Structures
      Project Length - 90 hours

      Mentors - @czgdp1807, @anutosh491

      Expected Outcomes - APIs for comparing two data structures added. Tests added for the same.

      ~~~~~~~~~~
      Graph Algorithms - https://github.com/codezonediitj/pydatastructs/issues?q=is%3Aissue+is%3Aopen+label%3Agraphs.algorithms
      Project Length - 350 hours

      Mentors - @czgdp1807, @anutosh491

      Expected Outcomes - Different graph algorithms added along with proper tests.

      ~~~~~~~~~~

      RAGO

      Project Idea 1: Expand Backend Support for Augmented and Generation Modules
      Abstract
      Rago is a lightweight framework for RAG. Its main idea is to provide a RAG with a very beginner friendly structure for anyone who wants to start to work with this concept.

      Current State
      RAGO currently supports OpenAI as the backend for both the Augmented (Embeddings) and Generation (LLM) modules. To increase flexibility and interoperability, this project aims to add support for multiple additional backends across both modules. This requires prior investigation to determine if each provider offers a Python API that can be integrated into RAGO.

      Tasks
      Investigate the availability and API support of the following embedding providers:
      AI21
      Ollama
      Together
      Fireworks
      MistralAI
      Cohere
      Nomic
      Databricks
      VoyageAI
      IBM
      NVIDIA
      Investigate the availability and API support of the following LLM providers:
      AI21
      Anthropic Claude
      Bedrock
      Cohere
      DeepSeek
      Fireworks
      Ollama
      Together
      Vertex
      NVIDIA
      Implement integration for supported backends.
      Ensure compatibility with RAGO's existing framework.
      Write tests and documentation for each newly integrated backend.
      Expected Outcomes
      RAGO supports multiple embedding and LLM backends.
      Clear documentation and examples for integrating and using different providers.
      A robust test suite to ensure stability across different backends.
      Details
      Prerequisites:
      Experience with Python and API integrations (intermediate level)
      Familiarity with LangChain or similar frameworks (beginner level)
      Understanding of Retrieval-Augmented Generation (RAG) workflows (beginner level)
      Knowledge of embedding models and LLM APIs (beginner level)
      Duration: 350 hours
      Complexity: Medium
      Potential Mentor(s): Ivan Ogasawara, Ever Vino, Sandro Loch, Alexandre de Siqueira
      References
      LangChain LLM Integrations
      LangChain Embedding Integrations

      ~~~~~~~~~~


      Project Idea 1: Create TUI for Sugar Using Textual
      Abstract
      The goal of this project is to develop a Terminal User Interface (TUI) for Sugar, a tool that simplifies container management. This TUI will provide a visual and interactive way to access all functionalities of Sugar directly from the terminal, akin to the user experience offered by k9s for Kubernetes.

      The Sugar TUI aims to enhance the user experience by providing a graphical interface within the terminal, allowing users to interact with Sugar's features more intuitively. The interface will be accessible via the command sugar tui and will be developed using the Textual library in Python, known for its capabilities in building modern, interactive TUIs.

      Key Features:

      Group Selection: Users can select which group of services they want to interact with.
      Service Management: Functionalities to start, restart, and stop services within the chosen group.
      Logs and Stats Viewing: Capability to view logs and check statistics for individual services.
      Service Details: Display detailed information about services, such as IP addresses, volumes, and configuration settings.
      Technical Approach:

      Utilize the Textual library to create a rich, interactive TUI. Textual's modern design and integration capabilities make it an ideal choice for developing a user-friendly interface.
      Design the interface to reflect the hierarchical structure of Sugar's configuration, allowing users to navigate between different groups and services effortlessly.
      Implement command handling in the TUI to perform actions such as starting, stopping, and restarting services.
      Fetch and display real-time data from Sugar, such as service logs, stats, and configuration details.
      Development Plan:

      Initial Setup: Setting up the project structure and integrating the Textual library.
      Interface Design: Designing the layout and navigation of the TUI, including menus and panels.
      Feature Implementation: Developing the core functionalities - group selection, service management, log viewing, and displaying service details.
      Testing and Refinement: Testing of the TUI for usability, performance, and compatibility with existing Sugar functionalities.
      Documentation and Examples: Creating comprehensive documentation and usage examples to assist users in leveraging the new TUI.
      Current State
      Sugar is already published on pypi and conda-forge, and currently works on top of docker compose v2.

      Tasks
      https://github.com/osl-incubator/sugar/issues/42
      Expected Outcomes
      Sugar TUI working from the CLI sugar tui
      Documentation should be updated in order to include this new feature
      The creation of a blog post that explains this new implementation
      Add tests on CI for TUI (as much as possible)
      Details
      Prerequisites:
      Hard Skills:
      Python (intermediate to advanced level)
      Docker (basic level)
      Command-line interface development (basic level)
      JSON schema understanding
      Soft Skills:
      Problem-solving
      Code documentation
      Collaboration through GitHub
      Duration: 350 hours
      Complexity: Medium
      Potential Mentor(s): Ivan Ogasawara, Luis Casas, Sandro Loch, Felipe Paes
      References
      https://docs.docker.com/compose/
      https://textual.textualize.io/

      ~~~~~~~~~~
      Project Idea 2: Add Docker Swarm Support to Sugar
      Abstract
      The goal of this project is to extend the Sugar library with Docker Swarm support. This enhancement will enable Sugar users to manage Docker Swarm clusters directly through Sugar’s command-line interface (CLI). By adding commands for initializing, joining, creating, scaling, updating, and inspecting Swarm services, the project aims to streamline container orchestration workflows for developers.

      Current State
      Sugar currently provides functionalities for Docker Compose, but it lacks support for Docker Swarm. The CLI is modular, making it a good foundation for adding Swarm-specific commands. The existing compose_ext.py module can serve as a reference for implementing the new Swarm extension.
      Tasks
      Add support for Docker Swarm
      Expected Outcomes
      Implementation of new Sugar commands for Docker Swarm:
      sugar swarm init - Initialize a swarm
      sugar swarm join - Join a swarm as a node and/or manager
      sugar swarm create - Create a new service
      sugar swarm inspect - Display detailed information on one or more services
      sugar swarm logs - Fetch logs of a service or task
      sugar swarm ls - List services
      sugar swarm ps - List the tasks of one or more services
      sugar swarm rm - Remove one or more services
      sugar swarm rollback - Revert changes to a service's configuration
      sugar swarm scale - Scale one or multiple replicated services
      sugar swarm update - Update a service
      Updates to the following files:
      src/sugar/cli.py
      src/sugar/schema.json
      src/sugar/core.py
      Creation of a new extension file:
      src/sugar/extensions/swarm.py
      Comprehensive documentation and tests for all new commands.
      Details
      Prerequisites:
      Hard Skills:
      Python (intermediate to advanced level)
      Docker and Docker Swarm (basic level)
      Command-line interface development (basic level)
      JSON schema understanding
      Soft Skills:
      Problem-solving
      Code documentation
      Collaboration through GitHub
      Duration: 350 hours
      Complexity: Medium
      Potential Mentor(s): Ivan Ogasawara, Luis Casas, Sandro Loch, Felipe Paes
      References
      Docker Swarm Overview
      Sugar Repository

      


            
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-science-labs/
    idea_list_url: https://opensciencelabs.org/opportunities/gsoc/project-ideas/


  - organization_id: 107
    organization_name: Open Technologies Alliance - GFOSS
    no_of_ideas: 16
    ideas_content: |
      Expanding HassIO smart home capabilities via low-code automation development[edit | edit source]
      Brief Explanation[edit | edit source]
      Smart environments are becoming quite popular in the home setting consisting of a broad range of connected devices. While offering a novel set of possibilities, this also contributes to the complexity of the environment, posing new challenges to allowing the full potential of a sensorized home to be made available to users. SmAuto, is a Domain Specific Language (DSL) that enables users to program complex automation scenarios and pipelines, for connected IoT devices in smart environments, that go beyond simple tasks. It was initially developed by the ISSEL research team (AUTH) as textual DSL and later evolved into a web-based low-code development environment. SmAuto lacks extra features like utilization of external REST data sources, time delays, semantic annotation, and accessing of in-house entities, etc., thus it should be expanded in this direction. Furthermore, HomeAssistant would benefit from the integration of a low-code approach for rapidly developing and deploying automations, using the entities existing in a smart environment.
      Expected Results[edit | edit source]
      • In the context of this project, we desire to expand the SmAuto DSL with the following features: a) support the REST protocol, so as for the automations to be able to access information from external data sources, b) incorporate auxiliary concepts like Delay, Switches, or Compute nodes, c) SmAuto integration in HA. The integration of SmAuto and HomeAssistant should occur, by creating a new open-source HA addon, where users will be able to design and deploy automations graphically, using the SmAuto low-code environment.
      Duration of the Project[edit | edit source]
      (350 hours).
      Related repositories[edit | edit source]
      https://github.com/robotics-4-all/smauto, https://www.home-assistant.io/
      Knowledge Prerequisites[edit | edit source]
      [Required]: Python, Software engineering, IoT concepts, Unix/Linux, [Desired]: Model Driven Engineering, HomeAssistant, Docker
      Mentors[edit | edit source]
      Konstantinos Panayiotou, Emmanouil Tsardoulias, Andreas Symeonidis

      ~~~~~~~~~~
      
      
      
      A Tool for Visualizing the Arguments, Sentiments and User Interactions of Online Discussions[edit | edit source]
      Brief Explanation[edit | edit source]
      In recent years, the analysis and visualization of dialogue have gained prominence in fields such as computational linguistics, social sciences, and human-computer interaction. The ability to model, analyze, and visualize real-life discussions provides valuable insights into the flow of conversations, the exchange of arguments, and the sentiments conveyed. Such visualizations can improve the understanding of complex discussions, foster decision-making, and even help develop better AI systems for facilitating or mediating discussions. We are particularly interested in online text-only discussions (e.g. on platforms like Reddit).
      Various tools and platforms have been developed in order to facilitate structured discussions and multi-party decision making. Kialo is an online, structured debate platform, where the use of argumentation is the central component. It allows the construction of argument maps, in the form of trees. It promotes thoughtful discussion, understanding of different viewpoints and collaborative decision-making, through visualizations of argument maps.
      Debategraph is another online structured debate platform, using more complex graphs, called &quot;mind-maps&quot;, where arguments are interconnected in a web-like structure. It allows an even wider choice of visualizations of relationships between ideas.
      DebateVis is a tool that can help non-expert users explore and analyze debate transcripts. Given a transcript, the tool produces: (a) an Interactions Graph that summarizes how often each candidate spoke overall, mentioned other candidates and discussed each topic, (b) an Annotated Transcript with automatically extracted topic labels and speaker interactions, (c) a Timeline visualization providing an overview of the debate.
      Finally, VisArgue is a framework proposing a range of visualizations of dialogues, including: Lexical Episode Plots (a timeline representation of the topics discussed), (b) Conversational Topic Visualizations, representing the shifting of focus of individual user on topics, (c) various statistics measuring user participation, respect, justification and accommodation, (d) Lexical Units, which are timeline representations of features such as the amount of argumentation and emotions.
      Although tools such as the above offer important functionality, there are still issues: in most cases, either the source code is not available, or integration with new projects is not seamless, or it is difficult to parameterize the output. Furthermore, the tools above focus mostly on debate, whereas we are also interested in other types of online discussions (e.g. deliberation to improve legislation bills, non-adversarial discussions for intra-company decision making).
      Therefore, this project’s goal is the design and implementation of an open source tool for visualizing and analyzing real-life, online, text-only discussions, exploring subjects like: topics discussed, arguments exchanged and emotions conveyed. The project will also explore how these visualizations can be leveraged for improving public understanding of contentious issues, academic discourse, and online discussion platforms.
      Project Objectives / Contributions:
      - Select, from the literature, prominent dialogue visualization approaches / ideas (e.g. styles of graph-based, or timeline-based, visualizations used) to represent various aspects of real-life online discussions and collect available libraries (not necessarily discussion-specific) that can be used to implement them (e.g. Gephi, NetworkX).
      - Explore the open-source toolkits being developed in the Archimedes project “LLM3: LLMs as mediators and moderators” to measure dialogue quality aspects (e.g., sentiment, politeness, topics, user participation) and select those that can provide useful meta-data for visualizing on-line discussions.
      - Develop a tool capable of ingesting data from real-life online discussions generating relevant meta-data (possibly by calling other toolkits) and producing the desired visualizations of the discussions.
      - Potentially, evaluate the effectiveness of the tool and its visualizations in making complex online discussions understandable to diverse audiences, such as researchers, mediators, or general users.
      Project Impact:
      - A novel, easy-to-use, open source, visualization tool (with accompanying paper) for online, text-only discussions, that can help the analysis of discussions in different settings and domains (e.g. political discourse, academic debates, or customer feedback).
      - Expand the general understanding of how visualization techniques can make debates more accessible and informative (possibly also leading to a publication).
        - Contribution to the Archimedes project “LLM3: LLMs as mediators and moderators” which aims to develop and evaluate LLM-based mediation agents that will actively participate in online discussions, with or without additional human mediation.
      Key Types of Dialogue Visualizations:
      The project will develop and explore several types of dialogue visualizations. Some are briefly described below. The contributor will be free to propose and implement new ones.
          1) Timelines: they represent the chronological flow of a conversation, highlighting key moments such as topic shifts, argument introductions and emotional peaks. Possible Features: topic evolution over time, points of conflict or agreement, visual markers for significant events (e.g. emotional outbursts or resolution points).
          2) Argumentation Graphs: they visualize the logical structure of arguments, including claims, counterclaims and evidence. Possible Features: nodes representing arguments or claims, edges denoting relationships (e.g., support, contradiction).
          3) User Interaction Graphs: they map the relationships and interaction patterns between participants in the debate. Possible Features: nodes representing participants, weighted edges showing the frequency, tone, or sentiment of interactions, clusters indicating subgroups or coalitions in the dialogue.
          4) Sentiment Heatmaps: they analyze and visualize the emotional dynamics of a conversation. Possible Features: color-coded intensity for positive, negative, or neutral sentiments, overlay with timeline or topic visualization for richer insights.
          5) Topic Trees or Topic Flow Diagrams: they represent how topics are introduced, branched out, and revisited during the discussion. Possible Features: hierarchical or radial layouts for topic relationships, highlights of overlapping or transitioning topics.
          6) Hybrid Visualizations: by combining multiple visualization techniques.
      Importance of Dialogue Visualizations:
      Dialogue visualizations, such as those presented above, can support:
      - Topic Analysis: by identifying the main topics discussed and their transitions over time, and by highlighting overlapping topics and their importance to the dialogue.
      - Argumentation Analysis: by understanding the logical flow of arguments, counterarguments, and evidence, and by identifying circular reasoning, weak arguments, or areas of agreement.
      - Sentiment Analysis: by visualizing the emotional tone of the conversation and its impact on the debate, and by examining whether certain sentiments correlate with specific topics or arguments.
      - Participant Dynamics: by mapping the influence and activity of each participant, and by analyzing interaction patterns (e.g., dominance, interruptions, alliances).
      Methodology:
      - Data Collection and Preparation:
      The tool should be able to ingest data from various online debate platforms (e.g. Reddit, Kialo), from political debate transcripts, from academic discourse, as well as from debates among LLM-agents. Since the format of raw data may vary, we propose the use of the Convokit tool in order to homogenise and preprocess the data.
      - Development of Visualization Prototypes:
      Tools/Technologies: Python (matplotlib, seaborn, Plotly), D3.js for web-based visualizations, or tools like Gephi for network analysis. Use natural language processing (NLP) libraries (e.g., spaCy, Hugging Face Transformers) for topic modeling, sentiment analysis, and argument mining, along with tools being developed at the LLM3 project of Archimedes.
      - User Feedback and Iterative Improvement:
      Test the outputs (visualizations) with researchers, mediators, or other stakeholders. Refine designs based on usability feedback and task-specific performance.
      Evaluation
      If time allows, the contributor will contribute in evaluating the effectiveness of their dialogue visualizations, in the context of Archimedes’ LLM3 project, by using them for both real-life and LLM-generated dialogues. Their output will be measured on clarity, usability and informativeness.
      Desired Profile:
      We are looking for a contributor with the following characteristics:
      - Good programming skills in Python (experience in network analysis and / or NLP is a plus).
      - Experience (and interest for) coding visual representations of concepts with libraries such as: matplotlib, seaborn, Plotly, Gephi, D3.js.
      - Interest in the subject of human interaction through dialogue (more specifically, on themes such as: argumentation, topic identification, sentiment analysis).
      - A taste for concise, elegant and efficient solutions / visualizations.
      The contributor will be mentored/supported by members of the LLM3 project, the broader NLP group of Archimedes (https://archimedesai.gr/en/), as well as the NLP Group (http://nlp.cs.aueb.gr/) of the Department of Informatics, Athens University of Economics and Business.
      Conclusion:
      This GSOC project aims to develop an open-source tool that will make complex, online discussions more understandable, insightful, and actionable. By capturing the topics, arguments, sentiments, and participant dynamics, it will offer a comprehensive approach to online dialogue visualization that can benefit multiple fields, from education to public policy.
      Related repositories[edit | edit source]
      https://sites.google.com/view/llm3/home
      Expected Results[edit | edit source]
      A tool able to process real-life, text-only dialogues and produce selected visualizations capturing their essential points.
      Mentors[edit | edit source]
      Dionysios Kontarinis (denniskont@gmail.com), Ion Androutsopoulos, Ioannis Pavlopoulos
      
      
      ~~~~~~~~~~
      PersonalAIs: Generative AI Agent for Personalized Music Recommendations[edit | edit source]
      Brief Explanation[edit | edit source]
      This project aims to develop an AI-powered agent that interacts with users in natural language to determine their emotional state and musical preferences in a conversational manner. The agent will then generate and refine music playlists accordingly. The system will integrate with the Spotify API to provide personalized recommendations based on user preferences, liked songs, and listening history. Users can opt-out of personal data usage for a more exploratory approach. The agent will also enable real-time conversational modifications to playlists, allowing users to tweak mood, energy, and genre preferences.
      Core Features & Technologies:[edit | edit source]
      - Natural Language Processing (NLP): Used to determine user mood and preferences based on conversation.
      - Generative AI: Small LLM models hosted locally or accessed via an API key for dialogue generation.
      - Spotify API Integration: Authentication, playlist management, retrieval of user metadata (liked songs, playlists, etc.).
      - Frontend UI: A web-based chatbot interface similar to ChatGPT.
      - Backend Processing: Handles AI model interactions, API requests, and user session management.
      - Real-time Modifications: Users can refine recommendations by requesting changes in mood, genre, energy, etc.
      Sources &amp;amp; References:
      - Spotify API Documentation: https://developer.spotify.com/documentation/web-api/
      Mood-Based Playlist Research:
      - Generating personalized music playlists based on mood and listening data
      - Moodify: Emotion recognition in songs for personalized recommendations
      Example Datasets:
      - Moodify Dataset (Spotify-based mood labels)
      - Awesome Music Emotion Recognition (MER) Dataset Collection
      Expected Results[edit | edit source]
      ''- A full-stack AI agent (local hosted and/or API Key) that generates personalized music playlists based on user input.  - Integration with Spotify API for user authentication, playlist creation, and retrieval of user metadata.  - Real-time, conversational playlist modifications through a chatbot-style UI.  - Advanced mood detection using NLP or audio analysis. Integration with external music recommendation sources.
      Duration of the Project[edit | edit source]
      (350 hours).
      Knowledge Prerequisites[edit | edit source]
      ''- Basics of Machine Learning and NLP.  - Experience with pre-trained generative models (e.g., GPT, BERT) and recommendation systems.  - Familiarity with APIs, particularly Spotify API.  - Frontend/backend development experience for a chatbot-style UI.
      Mentors[edit | edit source]
      Giannis Prokopiou, Thanos Aidinis
      
      ~~~~~~~~~~
      
      OpenRF 3D[edit | edit source]
      Brief Explanation[edit | edit source]
      This project aims to bridge NVIDIA Sionna’s 6G simulation framework with Cesium’s 3D geospatial engine, enabling real-time, terrain-aware wireless network analysis. The student will develop a bidirectional WebSocket pipeline to dynamically stream Cesium’s elevation and 3D building data into Sionna, where channel models are enhanced to account for terrain-induced pathloss and urban blockages. Simultaneously, Sionna’s ray-traced outputs (e.g., signal strength, beamforming patterns) will be visualized in Cesium as interactive heatmaps and antenna coverage overlays. Key deliverables include a Python/JavaScript interface using Protocol Buffers for efficient data serialization, integration of 3GPP TR38.901 models with real-world terrain, and Jupyter notebooks demonstrating urban/rural 5G optimization.
      Expected Results[edit | edit source]
      By the end of GSoC, this project will deliver a fully functional bidirectional WebSocket pipeline that integrates NVIDIA Sionna’s 6G simulation framework with Cesium’s 3D geospatial engine, enabling real-time, terrain-aware wireless network analysis. The system will dynamically stream Cesium’s elevation and 3D building data into Sionna, enhancing 3GPP TR38.901 propagation models with terrain-induced pathloss and urban blockages. Simultaneously, Sionna’s ray-traced outputs (signal strength, beamforming patterns) will be visualized in Cesium as interactive heatmaps and antenna coverage overlays. The project will develop an optimized Python/JavaScript interface using Protocol Buffers, ensuring low-latency, high-performance data exchange between Cesium and Sionna. Additionally, Jupyter notebooks will demonstrate urban/rural 5G optimization, beamforming analysis, and comparative studies of RF propagation models. The final deliverables will include a fully documented API, setup guides, and tutorials, contributing to the NVIDIA Sionna and Cesium open-source communities. This integration will significantly improve realism in RF simulations, allowing for next-generation 6G research, network optimization, and smart city planning.
      Duration of the Project[edit | edit source]
      (350 hours).
      Related repositories[edit | edit source]
      https://github.com/NVlabs/sionna, https://github.com/CesiumGS/cesium
      Knowledge Prerequisites[edit | edit source]
      A developer with strong Python & JavaScript skills, and an understanding of real-time networking (WebSockets, Protobuf). Experience in wireless communications & 3D geospatial visualization, and prior exposure to Sionna, CesiumJS would be highly beneficial.
      Mentors[edit | edit source]
      Ilias Chrysovergis (https://www.linkedin.com/in/ilias-chrysovergis/), Iason Malkotsis (https://malkotsis.com/)
      
      
      ~~~~~~~~~~
      Exploring and Abstracting Triplestore Alternatives[edit | edit source]
      Brief Explanation[edit | edit source]
      Objective[edit | edit source]
      The primary objective of this project is to explore, analyze, and abstract various triplestore alternatives. The project aims to provide young programmers with a comprehensive understanding of different back-end alternatives that allow for storing data in triple format, commonly known as triplestores.
      Background[edit | edit source]
      Triplestores are a type of database specialized in storing triples, a data structure for representing information in a subject-predicate-object format. They are crucial in semantic web technologies, such as RDF, SPARQL, and OWL. However, there are numerous triplestore alternatives available, each with its own strengths and weaknesses.
      Project Description[edit | edit source]
      This project will involve a detailed exploration of various triplestore alternatives. The participants will perform rudimentary tests and benchmarks on these alternatives to understand their performance, scalability, and other key features.
      The ultimate goal is to develop a library that can act as an abstraction layer for these triplestore alternatives. This library will "hide" the underlying implementation, allowing developers to switch between different triplestores without changing their application code. This abstraction layer can be compared to a library abstracting various specific relational database management systems, all providing very similar functionality, like supporting SQL.
      Methodology[edit | edit source]
      Research: Identify and study various triplestore alternatives. Understand their architecture, features, and limitations.
      Testing: Perform rudimentary tests and benchmarks on the identified triplestore alternatives.
      Analysis: Analyze the test results to understand the performance and scalability of each alternative.
      Development: Develop an abstraction layer that can interface with the various triplestore alternatives.
      Documentation: Document the findings and the usage of the developed library.
      Expected Outcome[edit | edit source]
      By the end of the project, we expect to have a well-documented library that can act as an abstraction layer for various triplestore alternatives. This will provide developers with the flexibility to choose the most suitable triplestore for their specific needs without having to modify their application code.
      Conclusion[edit | edit source]
      This project will not only enhance the understanding of participants about triplestore alternatives but also equip them with the skills to develop an abstraction layer, thereby broadening their programming skills and knowledge.
      Duration of the Project[edit | edit source]
      Long (350 hours)
      Related repositories
      New project, no existing repo available.
      Information links[edit | edit source]
      - Triplestore - Triples - Query language
      Knowledge Prerequisites[edit | edit source]
      Python (mandatory). Other programming languages like C, Go, Rust, Java, might prove useful.
      Mentors:Alexios Zavras, TBD[edit | edit source]
      
      
      ~~~~~~~~~~
      Flexible GovDoc Scanner[edit | edit source]
      Brief Explanation[edit | edit source]
      The goal of this project is to develop the Flex GovDoc Scanner, an application that leverages the Node.js stack, AI tools, and cloud services to transform public incorporation documents from Greece's business portal (ΓΕΜΗ, https://publicity.businessportal.gr/) into structured, searchable data. This project aims to facilitate access to essential company information, such as legal representatives, board members, and incorporation history, by offering advanced discovery capabilities through a REST service.
      Project Overview:
      - Crawl and Index Public Documents:
        Develop a robust crawling mechanism to gather all relevant PDF documents from the ΓΕΜΗ portal while ensuring compliance with legal standards.
      - Extract and Structure Metadata:
        Utilize AI and OCR technologies to extract key metadata from these documents and store them in a structured format.
      - REST Service for Metadata Search:
        Create an efficient REST API to provide users with search functionalities on the extracted metadata, enabling easy access and analysis.
      Related repositories[edit | edit source]
      https://github.com/flexivian/govdoc-scanner
      Expected Outcome[edit | edit source]
      ''- Implement a nodejs application to Crawl and Index Public Documents, utilize an opensource DB optimized for documents - Enhance the application with AI and OCR capabilities to extract metadata from scanned documents - Implement a REST API using nodejs to provide users with search functionalities on the extracted metadata, enabling easy access and analysis.
      Knowledge Prerequisites[edit | edit source]
      nodejs, docker, git , AI concepts and tools, NLP, OCR, RESTful API design and implementation, Knowledge of databases (SQL or NoSQL)
      Mentors:[edit | edit source]
      iskitsas@gmail.com, vasilisnx@gmail.com
      
      
      ~~~~~~~~~~
      Extending the capabilities of OpenTRIM[edit | edit source]
      Brief Explanation[edit | edit source]
      OpenTRIM is a new open-source code for simulating the passage of energetic ions through materials and calculating the associated modifications and damage that they cause to the these materials. It is based on the kinetic Monte-Carlo method and employs the Binary Collision Approximation to describe the interaction between ions and target atoms. OpenTRIM comprises of a set of C++ libraries, a command line program for executing simulations in batch mode and a Qt-based graphical user interface that can be used to configure &amp;amp; run a simulation and evaluate the results. Currently, there are various parts of OpenTRIM where work is needed for improving and extending the capabilities of the code.
      Expected Outcome[edit | edit source]
      1. Extend the base C++ simulation code to include new capabilities for user-defined “tallies”, i.e., scoring tables where data from the simulation are extracted as a function of ion energy, position, direction or other possible optional variables.  2. Create a tool for 2D or 3D visualization of the simulated ion trajectories. 3. Write a number of example simulations, complete with the required input files and evaluation of the output results, which will become a part of the code documentation.
      Duration of the Project[edit | edit source]
      Depending on the proposal
      Related repositories[edit | edit source]
      https://github.com/ir2-lab/OpenTRIM
      Knowledge Prerequisites[edit | edit source]
      C++, Qt (optional), OpenGL (optional)
      Mentors:[edit | edit source]
      George Apostolopoulos (https://github.com/gapost), Michail Axiotis (https://github.com/psaxioti), Eleni Mitsi (https://github.com/elmitsi)
      
      
      ~~~~~~~~~~
      
      Cleaning of HPLT Greek v2 Dataset for GlossApi LLM[edit | edit source]
      Brief Explanation[edit | edit source]
      Cleanup of the Greek datasets at https://hplt-project.org/datasets/v2.0. The cleanup will be done with the help of the glossAPI team.
      For methodology see https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1+.
      Expected Outcome[edit | edit source]
      The goal is to isolate from the html Greek text with normal grammar and complete sentences (not fragmented).
      Duration of the Project[edit | edit source]
      Depending on the proposal
      Related repositories[edit | edit source]
      https://github.com/eellak/glossapi
      Knowledge Prerequisites[edit | edit source]
      Python, βιβλιοθήκες NLP
      Mentors:[edit | edit source]
      Foivos Karounos, Nikolaos Vidras
      
      
      ~~~~~~~~~~
      Add SAML and OpenID Connect support to Consul Democracy[edit | edit source]
      Brief Explanation[edit | edit source]
      Consul Democracy is a web-based citizen participation tool written in Ruby, using the Ruby on Rails framework. Consul Democracy is licensed under the AGPL and its installations are decentralized, meaning there are more than 200 institutions across the world running their own independent server and using a custom version of Consul Democracy. Some of these institutions have authentication solutions based on either SAML or OpenID Connect; however, there's no built-in support for these authentication solutions in Consul Democracy, so each institution has to build their own.
      In Ruby, the OmniAuth library provides a standard way to manage multi-provider authentication. Consul Democracy currently uses several Ruby gems, all based on OmniAuth, to provide authentication via Facebook, Google, Twitter/X and WordPress. There's been an attempt at providing SAML support using the omniauth-saml Ruby gem, but its development hasn't been finished due to the lack of a SAML platform to test against.
      Consul Democracy also supports multitenancy, meaning the same application can be used to manage several institutions (with different domains or subdomains). For authentication using Facebook, Google, Twitter/X or WordPress, Consul Democracy provides the option to use the same configuration for each institution, to use different configurations for different institutions, or a mix of both (one default configuration which can be overwritten per institution).
      The aim of this proposal is to provide generic SAML and OpenID Connect authentication solutions in Consul Democracy so a variety of institutions can easily integrate their existing authentication platform.
      Expected Results.[edit | edit source]
      * Make it possible to authenticate in Consul Democracy using a SAML service
      * Make it possible to authenticate in Consul Democracy using an OpenID Connect service
      * Both SAML and OpenID Connect solutions must allow different configurations for different institutions in a multitenant environment
      * Both SAML and OpenID Connect solutions should be flexible enough so institutions don't have to change the source code in order to configure their service
      * The source code of the SAML and OpenID Connect solutions should be similar to the source code of the existing Facebook, Google, Twitter/X and WordPress solutions
      * Update the documentation with instructions on how to configure SAML and OpenID Connect
      Duration of the Project[edit | edit source]
      Medium Size 175 hrs
      Related Repositories[edit | edit source]
      https://github.com/consuldemocracy/consuldemocracy
      Knowledge Prerequisites[edit | edit source]
      * SAML and OpenID Connect authentication configuration * (Optional) Ruby on Rails and OmniAuth authentication
      Mentors[edit | edit source]
      Javier Martín - https://github.com/javierm, Sebastià Roig - https://github.com/taitus
      
      
      ~~~~~~~~~~
      Docker for Consul Democracy citizen participation platform[edit | edit source]
      Brief Explanation[edit | edit source]
      Consul Democracy is a web-based citizen participation tool written in Ruby, using the Ruby on Rails framework. Consul Democracy is licensed under the AGPL and its installations are decentralized, meaning there are more than 200 institutions across the world running their own independent server and using a custom version of Consul Democracy. That means Consul Democracy developers don't have access to production machines, and so Consul Democracy must be as simple to install and maintain as possible so anyone can do it no matter how familiar they are with the technologies used by Consul Democracy.
      Currently, Consul Democracy is installed on production by running an ansible-based installer which installs all the project dependencies on a Debian GNU/Linux or Ubuntu Linux server. Deployment of new developments is then done using Capistrano.
      The source code of Consul Democracy contains a Dockerfile and a docker-compose.yml file that are exclusively meant for the development environment, in order to make it easier for developers who are familiar with Docker to contribute to the project. However, there's currently no way to deploy to a production environment using Docker, which is inconvenient for institutions who don't use Debian or Ubuntu on their servers, or for institutions who have adopted Docker as their preferred way to setup their servers. The main goal of this proposal is to solve this issue. Since 2024, Ruby on Rails applications are configured to use Kamal by default as a solution to deploy to production using a Docker container. To our knowledge, this would be the most simple solution to our problem.
      There's a third kind of Docker integration, which uses a devcontainer to allow developers to use tools like GitHub Codespaces to run the application in a development environment, which is also configured by default in new Rails applications since 2024, and we'd like to enable this option in Consul Democracy.
      With this developments, we could enable many more municipalities to utilise digital citizen participation - and thus offer their citizens greater involvement in the development of their cities.
      Expected Results.[edit | edit source]
      * Make it possible to install and deploy Consul Democracy applications using Docker in the most simple way (probably with Kamal)
      * Add a devcontainer for integration with GitHub Codespaces
      * Make sure the current development setup with Docker keeps working after the previous additions *
      The configuration files for all three environments mentioned above should have as little duplicate code as possible so they're easy to maintain
      * Update the technical documentation for both development and production environments
      Duration of the Project[edit | edit source]
      Medium Size 175 hrs
      Related Repositories[edit | edit source]
      https://github.com/consuldemocracy/consuldemocracy
      Knowledge Prerequisites[edit | edit source]
      * Experience deploying to production environments using Docker
      * (Optional) Experience using Docker in Ruby on Rails applications
      Mentors[edit | edit source]
      Javier Martín - https://github.com/javierm, Sebastià Roig - https://github.com/taitus
      
      
      ~~~~~~~~~~
      Εxtending the apothesis factory pattern for seamless 2D and 3D lattice integration[edit | edit source]
      Overview[edit | edit source]
      Apothesis is a generalized software for designing, simulating, and analyzing deposition processes using the kinetic Monte Carlo method. It consists of two main components: a lattice (e.g., simple cubic, HPC, etc.) and the processes (adsorption, desorption, diffusion, and surface reactions) that occur within it. Currently, Apothesis includes a factory-based mechanism for lattice creation, but this implementation is limited in scope, primarily focusing on basic lattice structures. To enhance its flexibility and scalability, this proposal aims to extend the factory pattern to support a broader range of 2D and 3D surfaces in a seamless and modular way. This extension will involve introducing specialized lattice factories tailored for different geometries, such as hexagonal, face-centered cubic, and custom surface representations, ensuring compatibility with kinetic Monte Carlo processes. Additionally, a dynamic factory registry system will be implemented, allowing new lattice types to be registered and instantiated at runtime without modifying the core system. This approach will not only improve adaptability but also facilitate user-defined lattice structures while preserving maintainability and efficiency. By refining the factory mechanism, Apothesis will provide a more robust framework for deposition process simulations, enabling researchers and engineers to explore a wider range of surface dynamics with greater ease.
      Related work[edit | edit source]
      Apothesis already implements a factory pattern for lattice creation, but it needs to be expanded to support a broader range of 2D and 3D surfaces in a more seamless and flexible way. The current implementation primarily focuses on basic lattice structures, and extending it would involve introducing specialized factories for different geometries, such as hexagonal, face-centered cubic, and custom surface representations. Enhancing the factory pattern should include a more modular approach, allowing new lattice types to be dynamically registered and instantiated without modifying the core system. Additionally, ensuring that these new lattice structures fully integrate with kinetic Monte Carlo processes—such as adsorption, desorption, diffusion, and surface reactions—will be crucial for maintaining simulation accuracy and consistency. By refining the factory mechanism and introducing a more extensible registry system, Apothesis can achieve greater adaptability, making it easier for users to define and integrate new lattice types while preserving maintainability and scalability.
      Details of your coding project[edit | edit source]
      A potential practical approach to extending the factory pattern in Apothesis for 2D and 3D surfaces involves creating a modular and extensible lattice generation system. This can be achieved by defining an abstract LatticeFactory that enforces a standard way of creating lattice structures while delegating specific implementations to derived factories. Specialized factories such as SimpleCubicLatticeFactory, HexagonalLatticeFactory, FCCLatticeFactory, and GrapheneLatticeFactory can be implemented to handle different lattice geometries while ensuring compatibility with kinetic Monte Carlo processes like adsorption, desorption, diffusion, and surface reactions. Each factory produces a lattice object implementing a common ILattice interface, encapsulating geometry, boundary conditions, and process compatibility. A dynamic factory registry mechanism allows runtime selection and registration of new lattice types, enabling users to introduce custom lattices without modifying the core code. This approach ensures scalability, flexibility, and maintainability by decoupling lattice creation from simulation logic while seamlessly supporting both 2D and 3D structures.
      Size[edit | edit source]
      Large (350 hours)
      Skills[edit | edit source]
      Required: C++, desing patters, experience with physicochemical based software
      Expected impact[edit | edit source]
      The expected impact of extending the factory pattern in Apothesis includes enhanced flexibility, scalability, and efficiency in lattice creation for deposition process simulations. By introducing a more modular and extensible approach, researchers and engineers will be able to seamlessly integrate new 2D and 3D surface structures without modifying core code, reducing development time and increasing adaptability. The improved factory mechanism will ensure better compatibility with kinetic Monte Carlo processes, enabling more accurate and diverse simulations of adsorption, desorption, diffusion, and surface reactions. Additionally, the dynamic factory registry will foster customization and extensibility, allowing users to define and register their own lattice structures, thereby broadening the range of possible simulations. Overall, this enhancement will make Apothesis a more powerful and user-friendly tool, supporting advanced research, industrial applications, and innovation in surface science and material deposition technologies.
      Mentors[edit | edit source]
      • Nikolaos (Nikos) Cheimarios <n.cheimarios at gmail.com> is a researcher with contributions in scientific software development. He has previous experience as mentor in 2020, 2022, 2023 and 2024. He is one of the authors of Apothesis, Chameleon software and several web-based scientific numerical applications.
      • Christianna Gatsiou <christianna.gatsiou at gmail.com>.
      Tests[edit | edit source]
      Students, the following test will be helpful. • Easy: Compile and run Apothesis for the CO heterogeneous catalysis case. • Medium: Perform runs with SimpleCubic and HPC lattices. • Hard: Identify the part of code that creates the lattices. Briefly describe how you would implement the 2D graphene lattice. For tips and references contact the Mentors!
      References[edit | edit source]
      [1] N. Cheimarios, D. To, G. Kokkoris, G. Memos and A.G. Boudouvis “Monte Carlo & Kinetic Monte Carlo models for deposition processes: A review of recent works”, Frontiers in Physics, 9, 165 (2021).
      [2] N. Cheimarios, “Insights into the effect of growth on the Ziff-Gulari-Barshad model and the film properties”, Modelling and Simulation in Materials Science and Engineering, 31, 065007, (2023).
      [3] A.P.F Jansen, "An Introduction to Kinetic Monte Carlo Simulations of Surface Reactions", Springer Berlin, Heidelberg, 2012. https://doi.org/10.1007/978-3-642-29488-4
      [4] M. Andersen, C. Panosetti, K. Reuter, "A Practical Guide to Surface Kinetic Monte Carlo Simulations", Frontiers in Chemistry, 7, 202 (2019).
      
      
      ~~~~~~~~~~
      Identifying transition points in the ZGB model using convolutional neural networks (CNNs)[edit | edit source]
      Scientific computing for physical/chemical sciences and engineering edited this page 3 weeks ago ·
      Overview[edit | edit source]
      In 1986, Ziff, Gulari, and Barshad introduced the ZGB model to computationally study the heterogeneous catalytic process of CO oxidation to CO₂ with O₂ on a metal surface (e.g., Pt). Using Monte Carlo simulations on a simple square lattice, with the partial pressure of CO, yCO, as the only parameter, they demonstrated that at low yCO values, the catalytic surface becomes poisoned (fully covered) by oxygen atoms, preventing the surface reaction and the conversion to CO₂. In this case, the system remains out of equilibrium. As yCO increases, at approximately y1 ≈ 0.389, the system transitions to an equilibrium state where CO begins to convert into CO₂. Further increasing yCO leads to a first-order, discontinuous phase transition at y2 ≈ 0.525, where CO conversion to CO₂ ceases again due to surface poisoning by CO atoms. In 1990, Jensen and Fogedby extended this model by incorporating diffusion phenomena, showing that the transition points shift depending on the diffusion rate, pd , but do not disappear.
      Related work[edit | edit source]
      Apothesis is a generalized open-source software for simulating heterogeneous catalysis and deposition processes via kMC. It is based on performing certain processes (adsorption, desorption, diffusion and surface reaction(s)) on lattices. Currently, Apothesis supports simple cubic, FCC, HPC and diamond lattices. It has been used to study both heterogeneous catalysis of CO and related type growth models [2].
      Details of your coding project[edit | edit source]
      This works aims to predict the transition points using machine learning methods, specifically convolutional neural networks (CNNs), based on surfaces derived from kinetic Monte Carlo simulations from Apothesis at equilibrium states. For that, an outer shell to Apothesis must be build that will read the data from Apothesis and use it for training a CNN and then for the prediction of the transition points.
      Size[edit | edit source]
      Large (350 hours)
      Skills[edit | edit source]
      Required: Python, Tensorflow, experience with physicochemical based software
      Expected impact[edit | edit source]
      The project will build an outer shell for Apothesis to be used in ML/AI applications.
      Mentors[edit | edit source]
      Nikolaos (Nikos) Cheimarios <n.cheimarios at gmail.com> is a researcher with contributions in scientific software development. He has previous experience as mentor in GSoC 2020, 2022, 2023 and 2024. He is one of the authors of Apothesis, Chameleon software and several web-based scientific numerical applications.
      Konstantinos (Kostas) Eftaxias is a data scientist with more than 15 years of experience in research and industry applications. His main interests are computer vision, time series modelling/prediction and reinforcement learning.
      Tests[edit | edit source]
      Students, the following test will be helpful. • Easy: Compile and run Apothesis for the CO heterogeneous catalysis case. • Medium: Take three surfaces (SurfaceSpecies_*.dat) generated by Apothesis and read it in Python. • Hard: Call Apothesis from Python and read the latest surface generated. For tips and references contact the Mentors!
      References[edit | edit source]
      [1] R. M. Ziff, E. Gulari, and Y. Barshad, Kinetic Phase Transitions in an Irreversible Surface-Reaction Model, Phys. Rev. Lett. 56, 2553 (1986).
      [2] I. Jensen and H. C. Fogedby, Kinetic Phase Transitions in a Surface-Reaction Model with Diffusion: Computer Simulations and Mean-Field Theory, Phys. Rev. A 42, 1969 (1990).
      [3] N. Cheimarios, Surface diffusion effects on the system and the film properties of a Ziff–Gulari–Barshad type growth model, Mat. Today Comm. 39, 109189 (2024).
      [4] N. Cheimarios, Mean field approximation of a surface-reaction growth model with dissociation, Phys. Lett. A 524, 129828 (2024).
      [5] Y. Bahri, J. Kadmon, J. Pennington, S. S. Schoenholz, J. Sohl-Dickstein, S. Ganguli, Statistical Mechanics of Deep Learning, Annu. Rev. Condens.Matter Phys. 11, 501 (2020).
      [6] D.W. Tola, M. Bekele, Machine Learning of Nonequilibrium Phase Transition in an Ising Model on Square Lattice, Condens. Matter 8, 83 (2023).
      
      ~~~~~~~~~~
      MyUni[edit | edit source]
      Brief Explanation[edit | edit source]
      There is a University App called MyUoM for Greek universities in https://my.uom.gr/ (followed by an effort in University of West Attica, https://iam.uniwa.gr/). While the app serves as a centralized platform for students and faculty, it currently lacks essential features such as a robust login system, a scalable backend architecture, and the ability to provide real-time updates from official university sources. Additionally, the app does not support a unified framework that allows other universities to easily integrate and customize the platform for their specific needs.
      This project aims to address these limitations by developing a modern, scalable backend architecture and integrating a Content Management System (CMS) to manage frequently changing information. The CMS will enable universities to easily update and distribute news, announcements, and other critical data in real time. Furthermore, the backend will be designed to fetch and synchronize real-time information directly from official university websites, ensuring accuracy and timeliness.
      A key goal of this project is to unify and standardize the efforts of existing implementations (e.g., MyUoM and UniWA) and create a modular, extensible framework that other universities can adopt with minimal effort. By doing so, we aim to foster collaboration among Greek universities and provide a seamless, feature-rich experience for students and faculty across the country.
      This project will not only enhance the functionality of the existing app but also lay the foundation for a national university platform that can be easily extended to support additional institutions, features, and services in the future.
      Expected Results.[edit | edit source]
      Modular and Customizable Architecture: Develop a flexible, scalable structure that can be adapted to the unique needs of different universities. The system will allow each institution to fully customize the interface, content, and functionality to align with their specific requirements.
      Personalized Content and Homepage: Implement a dynamic homepage that displays customizable tiles and content, similar to a WordPress-style page builder. Institutions can personalize the content to highlight important information, announcements, or services.
      Student Portal: Create a dedicated student portal where all student-related data (personal information, academic records, etc.) will be centralized. This portal will serve as a one-stop reference point for students to access their information.
      Admin Panel for Customization: Build an intuitive admin panel that allows university administrators to define the appearance, content, and functionality of their institution's application. This will empower institutions to manage their app independently.
      Backend System for Data Management: Develop a robust backend system to handle all data, including student information, frequently updated content, and static resources (e.g., map images). The backend will ensure efficient data management and retrieval.
      Real-Time Data Integration: Set up a backend that fetches real-time information from official university sources (e.g., announcements, schedules) and integrates static resources to reduce frontend load and improve performance.
      TypeScript Rewrite for Maintainability: Rewrite the existing codebase in TypeScript to enhance code quality, maintainability, and scalability, ensuring the project is future-proof.
      Custom CMS for Dynamic Content: Create a custom Content Management System (CMS) consisting of both FrontEnd and BackEnd components. This CMS will allow universities to easily manage and update frequently changing information.
      Multi-Domain Support: Design a system where the application can be shared across multiple university domains by creating individual instances. This will enable seamless adoption by other institutions while maintaining customization for each.
      Deliverables (before means to help us decide and after means at the end of GSoC)
      Prepare the "Analysis and design" document. We want System Analysis, Feasibility Study, Business Procedures, User stories, EPICS, System Backlog, Requirements Analysis (before).
      Wireframes or mockups (before).
      Final Analysis and design document (after)
      Repository with the code (after).
      Docker image (after).
      Duration of the Project[edit | edit source]
      Depending on the scope
      Related repositories[edit | edit source]
      https://github.com/Open-Source-UoM/MyUoM
      Knowledge Prerequisites[edit | edit source]
         • React.js
         • Express.js (for BackEnd)
         • MySQL (for BackEnd)
         • JavaScript
         • TypeScript
         • Next.js (optional)
      Mentors:[edit | edit source]
      Anastasios Tsalmas tsalmanastasios@gmail.com,
      Efstathios Iosifidis eiosifidis@gmail.com
      Contact:
      There is a list. Please use the list. Write [myuni] as subject and cc both mentors. DON'T send us messages to social media (including Linkedin).
      
      
      ~~~~~~~~~~
      GlossAPI[edit | edit source]
      Brief Explanation[edit | edit source]
      GlossAPI is an open source project seeking to develop a standard open access corpus of the Greek language, and benchmark it against existing and to-be-developed language models, with the objective of providing an upstream service to the Greek tech community. The project is named after a portmandeau of the Greek word for "language" and "API" which creates a visual resemblance to the word Glossary in Greek. This is to express our objective to provide an index of the Greek language via flexible programing interfaces.
      Greek is a language that is under-represented in existing LLMs, while it has a complex history, grammar and writing system. Our trials with existing models have shown lack of syntactic and semantic knowledge of advanced Greek and its nuances, and we have put forth a number of analyses showing that this poses a risk for digital divides, language extinction, and subpar experience for users of public services.
      To our knowledge other LLM projects that tackle the problem of the Greek language are either proprietary, closed code, narrow scope, or otherwise unfit for our purpose which is to provide publicly available, fully open source language models with respect to all code/weights/procedures/data. We reach out and bring together people that have the expertise, the passion, the collections, or the hardware, to take part in this endeavor, that will help the Greek stratup/tech scene catch up with the rapid developments in downstream applications that are now common place for developers of English language generative models.
      Expected Results[edit | edit source]
      The project will result to an Open Source Corpus, representative of the Greek language and its different varieties. At first emphasis will be given to the formal varieties used in government, education and the law. Additionally, we want to represent, in a subsequent training stage, a number of basic knowledge domains to an "undergraduate degree" level. The datasets will be versioned and benchmarked against different models and tokenizers. We also need to develop a sufficient set of evaluation tasks (such as Factual QA - Greek). Finally a couple of foundation models of different architectures will be fitted onto the dataset and the evaluation suite, and published to the community under an open source licence. With these moves we expect to pollinate the Greek tech ecosystem with reliable, inexpensive, and extensible models and datasets, that will help the Greek Open Source AI scence thrive. All data and models will be accompanied by thorough documentation and guides, to ensure replicability and reusability of the results.
      
      Duration of the Project[edit | edit source]
      350 hrs
      Related Repositories[edit | edit source]
      https://github.com/eellak/glossAPI/ https://github.com/eellak/glossAPI/wiki
      
      Knowledge Prerequisites[edit | edit source]
      Corpus Annotation for Language Models Quantitative Corpus Linguistics or Natural Language Processing Python with transformers library, sci-kit learn, numpy, pandas and streamlit, langchain or similar Mathematical statistics or similar discipline Django knowledge is good to have
      Mentors[edit | edit source]
      F.Karounos, A. Melidis, Greek Free Open Source Software/Hardware Alliance
      
      
      ~~~~~~~~~~
      DIY IoT Physics Experiments for education[edit | edit source]
      Brief Explanation[edit | edit source]
      Remote physics experiments for students in all educational levels are the second best to hands-on experiments.  Especially for students who temporarily cannot attend school or in cases like Covid-19 and the lockdowns. In many practical cases, they are the only alternative, as they are available 24/7, they can involve dangerous materials or conditions, they can be accessed from anywhere and any device, they require less maintenance, have lower cost, can be easily modified, or arranged to perform another experiment, and are less probable to be damaged.  They are in line with the modern way of performing experiments, as it is desirable to have as little direct contact with the experiments as possible and use them online.  Examples include online telescopes and electronic microscopes.  This is possible due to automation; data acquisition and manipulation of the experimental data is done using a computer or a single board computer.  In this way students need not take pain stacking notes, especially for experiments that take a lot of time to collect data, sometimes days or months.  Students can concentrate on data processing, the analysis of the results, and arrive at scientifically valid conclusions.  Our laboratory has set up many remote experiments and has more than 10 years’ experience in designing, setting, and servicing remote experiments.  Our remote experiments are based on Arduino and readily available sensors and actuators. The previous year it was designed and implemented a way to make the sensors, and the actuators form an IoT local network so that it will be easier to easily utilize them in different experiments and to build new experiments.  The IoT sensors and actuators are DIY and based on open software.   The previous year GSoC stipend receiver, programed the ESP8266 to receive data from the sensor and transmit the data through MQTT to ThingsBoard. Similarly, for an actuator the ESP8266 to receive MQTT data from ThingsBoard. The stipend receiver prepared five DIY IoT sensors and five actuators. ThingsBoard provided users with visual representation of the data and the control of the experimental setup through dashboards.  There are produced five dashboards for five corresponding experiments.  The present successful applicant will have to produce a digital twin of the experiments.  This will involve open software for producing 3D models of five experiments, allowing them to manipulate the digital twins, view the evolution of the experiment, provide data presentation tools, and extract model parameters.
      Related repositories[edit | edit source]
      https://github.com/totheworld2004/DIY-Physics-IoT[edit | edit source]
      Exprected Outcome:[edit | edit source]
      Five digital twins of corresponding five experiments, their documentation and instructions of how to use them
      Knowledge Prerequisites[edit | edit source]
      Any one for case a)-e) or similar --- a) 3D Web-Based Physics Simulations: Three.js, Babylon.js, p5.js, Godot b) Interactive Dashboards: Plotly Dash, Panel, Bokeh c) Custom Data Visualizations: D3.js, Matplotlib, Jupyter Notebooks d) Game-Based Physics Experiments: Godot, Babylon.js e) Embedded 3D Simulations: Three.js, Babylon.js
      Mentors:[edit | edit source]
      Hariton Polatoglou and Panagiotis Koustoumpardis
      
      
      ~~~~~~~~~~
      eCodeOrama, an educational interactive flow visualization tool for mit scratch programs[edit | edit source]
      Brief Explanation[edit | edit source]
      The project will create a interactive tool to extract, visualize graphically and edit (to improve the presentation of) the layout of the flow of code in blocks / scripts in a mit scratch program and their interaction with any messages or other external events. The tool will use rules to decide on many layout parameters (e.g. the position of the code blocks in the layout, the colors used, etc) but the user will be able to overwrite the default choices. The presentation will be compatible with the codeOrama code layout specification. The tool will also promote code understanding, especially to young students that use scratch, and will include debugging aids. The students can use this flow to better visualize and understand their program, to explain it to others, to debug it and to design extensions and modifications.
      
      Expected Results[edit | edit source]
      A tool to visualize and edit the layout of the event based script flow of a scratch program, keeping it compatible with the codeOrama code layout specification.
      Duration of the Project[edit | edit source]
      350 hours
      Related repositories[edit | edit source]
      https://github.com/sarantos40/eCodeOrama
      Knowledge Prerequisites[edit | edit source]
      python, mit scratch, gui development
      Mentors:[edit | edit source]
      Sarantos Kapidakis (sarantos.kapidakis@gmail.com), Chrysovalantis Sfyrakis
      Category: GSOC
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-technologies-alliance-gfoss/
    idea_list_url: https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2025_proposed_ideas

  - organization_id: 108
    organization_name: Open Transit Software Foundation
    no_of_ideas: 9
    ideas_content: |
      AI/ML Projects
      Transit Stop Identification
      Difficulty: Advanced // Size: 350 hours
      Have you ever tried to find your specific bus or train stop in an app while you’re standing in your city center? Tall buildings make precise GPS location finding a challenge, you may not know which direction you’re facing, and finding the right stop on the OBA map can be really difficult! We want to begin introducing AI/ML features to OneBusAway with a small on-device model that can run on iOS and Android to help identify the ID of a transit stop from a sign and then automatically open the correct stop in the OBA app.
      You will be responsible for:
      Helping to create features in our mobile apps to allow existing users to submit training data (i.e. images of transit stop signs)
      Building the final model on top of MobileNet-v3-Small or another similar model
      Helping to integrate the final model into OBA on iOS and/or Android
      
      ~~~~~~~~~~
      
      Web UI Projects
      Wayfinder Improvements
      Difficulty: Intermediate // Size: 175 hours
      Wayfinder is our best-in-class SvelteKit based web application. It needs a full accessibility audit and fixes made where applicable. Additionally, we’ve built a lot of great features, but they are largely untested today. We need someone to enhance our unit testing suite to ensure that changes don’t cause regressions. Finally, there are a handful of fit and finish improvements that we need to make to the project.
      Expected outcomes:
      An accessibility and usability audit report.
      Implementation of the top recommendations from the report.
      Improved test coverage.
      Fit and finish.

      ~~~~~~~~~~
      Next Generation Sign Mode
      Difficulty: Intermediate // Size: 175 hours
      Next generation Sign Mode is a web application that will let transit agencies and businesses easily create public transit information systems. Our old web app includes a sign mode feature, but the feature didn’t make it into Wayfinder. Instead, we want to see a new, standalone web app built in SvelteKit that matches or exceeds the feature set of the old sign mode.
      See an example of sign mode in action.
      Read the docs to learn more about its options.
      
      
      ~~~~~~~~~~
      Android App
      Accessibility Improvements
      Difficulty: Intermediate // Size: 90 hours
      Our Android app is reasonably accessible, but it needs a full accessibility audit and implementation of the findings/recommendations.
      If you have experience with building Android apps and a desire to make the preeminent open source public transit app for Android more accessible, this is a great project for you! You’ll review our Android app’s support for TalkBack, font sizing, appropriate color contrast, hit target sizing, and other features needed to help everyone take full advantage of the app, create a report documenting your findings, and then fix the top priority issues that you’ve discovered.
      Expected outcomes:
      An accessibility audit report.
      Implementation of the top recommendations from the report.

      ~~~~~~~~~~
     
      iOS App/Apple Platforms
      Improve iOS App Accessibility
      Difficulty: Intermediate // Size: 90 hours
      Our iOS app is reasonably accessible, but it needs a full accessibility audit and implementation of the findings/recommendations.
      If you have experience with building iOS apps in Swift and a desire to make the preeminent open source public transit app for iOS more accessible, this is a great project for you! You’ll review our iOS app’s support for VoiceOver, dynamic text sizing, appropriate color contrast, hit target sizing, and other features needed to help everyone take full advantage of the app, create a report documenting your findings, and then fix the top priority issues that you’ve discovered.
      Expected Outcomes:
      An accessibility audit report.
      Implementation of the top recommendations from the report.

      ~~~~~~~~~~
      Build a Trip Planner
      Difficulty: Advanced // Size: 350 hours
      The OneBusAway iOS app needs a trip planner! Be a founding engineer on the project to build the only Apache 2.0-licensed Open Trip Planner library for iOS, and help hundreds of thousands of people reach their destinations.
      The top feature request for the OBA iOS application for the past ten years running has been for a trip planner! Unfortunately, there are no open source libraries for iOS that are compatible with Open Trip Planner, and that’s where you come in. You’ll work with Aaron, our Executive Director and iOS app maintainer, to design an Apple-quality trip planning experience, and then build it from scratch in Swift and SwiftUI, taking care to incorporate user research findings and platform best practices along the way.
      The result of your work will help hundreds of thousands of people reach their destinations every day, and power the trip planning experiences for every iOS app that uses Open Trip Planner for the next ten years.
      Expected outcomes:
      A production-quality trip planning framework built in Swift/SwiftUI
      Full integration into OneBusAway


      ~~~~~~~~~~
      Build an Apple Watch App
      Difficulty: Advanced // Size: 350 hours
      We’d love to add a companion Apple Watch app for OneBusAway. Ever wanted to build an Apple Watch app from the ground up that would be used by tens of thousands of people on day 1? Now’s your chance!
      Since the introduction of the Apple Watch, we’ve heard from countless users wondering when we’d finally launch a version of our app that is designed for a wrist-based experience. You will help to perform user research, determine the appropriate scope of features, and build our first Apple Watch app, exclusively for watchOS 11 in SwiftUI.
      Expected outcomes:
      A production-quality Apple Watch app, written in Swift and SwiftUI.
      Survey Features
      Difficulty: Intermediate // Size: 175 hours
      One of our GSoC 2024 participants created a survey feature for our Android app, and now we need to replicate that feature on iOS!
      Surveys play a key role in helping transit agencies understand the needs of their riders and ultimately to make transit easier to use. In this project, we hope to build short travel survey functionality into the OneBusAway iOS app that would allow riders to rate aspects of service or answer questions about how to improve their experience on transit.
      While OneBusAway has been a beloved app for our riders for more than a decade, at its roots is the conduct of research to examine the impacts of real-time traveler information on the attitudes and behavior of transit customers. This new functionality would allow us to grow this research arm of OneBusAway for the first time in years. A project for its use has already been identified to help transit agencies better serve women’s unique travel experiences such as mobility of care trips and more complicated travel patterns.
      Expected outcomes:
      A production-quality short survey interaction module (to ask single questions or provide ratings) that can be deployed in the iOS app.
      
      ~~~~~~~~~~
      Golang/Backend Projects
      Historically, most of the OBA backend stack has been written in Java with Spring. We’re starting to move away from Java/Spring, and are hoping to slowly and organically transition our backend projects to Go.
      Watchdog
      Difficulty: Advanced / Size: 175 hours
      Our first Go-based project is a tool called Watchdog, which monitors the availability and behavior of OBA servers and reports out information to a Prometheus server.
      Expected outcomes:
      Build more metrics for Watchdog: right now, we only have a few metrics for Watchdog that have been created. The original Watchdog project had over a dozen. We need to replicate its behavior!
      
      ~~~~~~~~~~
      Integration Test System
      Difficulty: Advanced / Size: 350 hours
      Even though we do have an OpenAPI spec that documents all of our API endpoints, the OBA API server does not have a formal spec or set of tests that define its behavior, or ensure that a breaking API change does not occur. We need a tool built that can validate the output of the OBA API server for a known set of inputs. In other words, given a known set of GTFS data bundle and GTFS-RT Protobuf files, verify that the JSON-over-HTTP output matches the expected output.
      Expected outcomes:
      Build a test harness (i.e. a specialized Docker image) for the OBA API server; it will need to simulate particular dates and times.
      Build a Ruby, Python, or Golang tool that can instantiate the OBA API server inside of its test harness and validate the correctness of the JSON output from a given HTTP call.
      Create a comprehensive test suite that verifies that the OBA API server works as expected for all of its most important API calls.
      
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-transit-software-foundation/
    idea_list_url: https://opentransitsoftwarefoundation.org/2025/01/google-summer-of-code-2025-project-ideas/


  - organization_id: 109
    organization_name: OpenAFS
    no_of_ideas: 11
    ideas_content: |

      Idea: afsio: Add Mount point and ACL creation support
      Project Size: 12 weeks
      Skill Level: Intermediate
      Languages: C
      Description
      The OpenAFS afsio utility is a command-line client for interacting with the AFS filesystem without requiring a kernel module. Currently, afsio is limited to anonymous read and write operations. This project aims to expand afsio's capabilities, enabling authenticated access, mount point creation within AFS volumes, and manipulation of Access Control Lists (ACLs).

      This enhancement would allow site administrators and developers to manage and configure OpenAFS cells using only userspace tools, simplifying deployment and administration.

      Skills Required
      Proficiency in C programming.
      Experience with file system concepts and operations. (permissions, ACLs, mount points)
      Understanding of network security concepts (authentication, key management).
      Familiarity with command-line interface (CLI) design.

      ~~~~~~~~~~


      Idea: netcat for rx
      Project Size: 12 weeks
      Skill Level: Intermediate
      Languages: C
      Description
      netcat (nc) is a versatile utility for reading and writing data over TCP/UDP connections. This project aims to create a similar tool specifically for Rx, the network protocol used by OpenAFS. This new tool will provide a simple and powerful way to interact with Rx-based services, enabling automated testing, debugging, and scripting, much like netcat does for TCP/UDP. Prior knowledge of OpenAFS or Rx is not required, making this a great project for learning about network protocols.

      Skills Required
      Proficiency in C programming.
      Experience with network programming (sockets, TCP/UDP).
      Understanding of basic network security concepts.
      Familiarity with command-line utilities like netcat (nc).

      ~~~~~~~~~~
      Idea: Rx language bindings
      Project Size: 12 weeks
      Skill Level: Intermediate
      Languages: C
      Description
      This project focuses on creating low-level language bindings for Rx, the network protocol used by OpenAFS. These bindings will enable developers to interact with Rx services directly from languages like Python, facilitating the development of testing tools, higher-level utilities, and integrations with other systems.

      Skills Required
      Proficiency in C programming.
      Experience with a target language such as Python (or another suitable language).
      Experience with creating language bindings (e.g., using CFFI, SWIG, or similar tools).
      Understanding of network programming concepts.

      ~~~~~~~~~~
      Idea: Develop a GNOME Shell Extension for OpenAFS
      Project Size: 12 weeks
      Skill Level: Basic
      Languages: Javascript
      Description
      This project aims to create a GNOME Shell extension that provides a graphical interface for managing the OpenAFS client on Linux desktops. The extension will allow users to easily start and stop the OpenAFS client, acquire tokens, and potentially perform other useful user actions or configuration changes, all from within the GNOME Shell environment.

      Skills Required
      Proficiency in JavaScript.
      Experience with GNOME Shell extensions (or a strong willingness to learn).
      Basic understanding of OpenAFS client operations (starting/stopping the client, acquiring tokens).
      
      ~~~~~~~~~~
      Idea: Implement Fileserver Memory Autotuning
      Project Size: 12 weeks
      Skill Level: Intermediate
      Languages: C
      Description
      Currently, OpenAFS fileserver installations require manual configuration of command-line options to specify the amount of memory used by the fileserver process. These options need to be carefully tuned to the host system, and existing presets are often inadequate for modern environments. This project aims to replace the manual configuration with an autotuning mode, allowing the fileserver to automatically adjust its memory footprint based on the available system resources. A starting point for this implementation is already available in the OpenAFS Gerrit code review system.

      Skills Required
      Proficiency in C programming.
      Strong understanding of memory management concepts.
      Experience with performance analysis and tuning (helpful).
      Familiarity with OpenAFS fileserver internals (can be learned during the project).
      
      
      ~~~~~~~~~~
      Idea: Develop a Unit Test Automation Framework
      Project Size: 12 weeks
      Skill Level: Intermediate
      Languages: C, Python
      Description
      The OpenAFS codebase has existing unit tests, implemented with a mix of Perl and C, and rely on the C-TAP test harness. This project aims to design and develop a more extensible and consistent framework for writing, running, and maintaining unit tests for the various components of OpenAFS. This will improve test coverage, make it easier for developers to write new tests, and ensure consistency across the codebase.

      Skills Required
      Proficiency in C and Python programming.
      Experience with unit testing frameworks (e.g., C-TAP, pytest, unittest).
      Understanding of software testing principles and best practices.
      Familiarity with the Test Anything Protocol (TAP) (helpful).

      ~~~~~~~~~~
      Idea: OpenAFS Client/Server Load Testing with K6
      Project Size: 12 weeks
      Skill Level: Intermediate
      Languages: C, javascript
      Description
      k6 is a modern, open-source load testing tool. The xk6 project allows for building custom k6 binaries with support for new protocols. This project investigates using k6 to perform load testing of OpenAFS clients, fileservers, and database servers by developing extensions for OpenAFS’s Rx RPCs.

      Skills Required
      Proficiency in C programming.
      Experience with network programming.
      Understanding of performance testing and load testing concepts.
      Familiarity with k6 (or a strong willingness to learn).

      ~~~~~~~~~~
      Idea: C language static code analysis
      Project Size: 12 weeks
      Skill Level: Intermediate
      Languages: C, Python
      Description
      Various C language static analyzers are used periodically to check the OpenAFS codebase. However, a challenge is managing false positives and creating a system for ongoing, automated analysis and reporting. This project aims to develop a system to periodically run static analyzers on the OpenAFS codebase using the OpenAFS Buildbot, generate useful reports, and prevent new issues from being introduced. The focus will be on minimizing false positives and providing actionable information to developers.

      Skills Required
      Proficiency in C and Python programming.
      Experience with static code analysis tools (e.g., Clang Static Analyzer, Coverity).
      Understanding of software quality assurance principles.
      Familiarity with Buildbot (or other continuous integration systems).

      ~~~~~~~~~~
      Idea: Enhance OpenAFS Command-Line Tools with JSON Output
      Project Size: 12 weeks
      Skill Level: Intermediate
      Languages: C
      Description
      OpenAFS provides a suite of command-line tools for managing and interacting with the distributed file system. Currently, these tools primarily output human-readable text, which can be difficult to parse and use in automated scripts and workflows. Modern systems and automation tools often rely on structured data formats like JSON for interoperability and ease of processing.

      This 12-week project aims to enhance selected OpenAFS command-line tools by adding support for JSON-formatted output. This will make it easier to integrate OpenAFS management tasks into automated scripts, monitoring systems, and other tools that consume structured data.

      Skills Required
      Proficiency in C programming.
      Experience with parsing and generating JSON data.
      Familiarity with command-line interface (CLI) design principles.
      Understanding of scripting and automation concepts (helpful).
      Basic knowledge of OpenAFS and its command-line tools (can be learned during the project, but prior experience is a plus).
      
      ~~~~~~~~~~
      Idea: OpenAFS Linux kernel module: Multi-page folio support
      Project Size: 12 weeks
      Skill Level: Advanced
      Languages: C
      Description
      OpenAFS is a distributed file system that relies on the Linux kernel's memory management for efficient data handling. The kernel's folio API allows for managing groups of contiguous pages as a single unit. While OpenAFS currently uses folios, it does so only in a limited way, treating each folio as equivalent to a single page. This project focuses on extending OpenAFS's folio usage to leverage multi-page folios – contiguous blocks of memory larger than a single page – to potentially improve efficiency.

      The Linux kernel's move towards folios, and particularly multi-page folios, offers several potential advantages:

      Reduced Overhead: Operating on a larger, contiguous memory region with a single folio can reduce function calls, lock contention, and TLB misses compared to individual page operations.
      Improved Cache Efficiency: Larger contiguous regions improve data locality and can increase cache hit rates.
      Facilitating Larger I/O: Multi-page folios naturally support larger read/write operations.
      This 12-week project will investigate and implement the use of multi-page folios within the OpenAFS Linux kernel module. This will involve:

      Identifying Candidate Areas: Analyzing the OpenAFS codebase to pinpoint areas where using multi-page folios would be most beneficial. This includes examining read, write, and metadata operation paths.
      Implementing Multi-Page Folio Support: Modifying the code to allocate, manage, and operate on multi-page folios where appropriate. This will involve careful consideration of memory allocation strategies, data transfer mechanisms, and interactions with the page cache.
      Handling Compatibility: Ensuring the changes work seamlessly with different kernel versions and configurations, including those with varying levels of folio support
      Testing: Thoroughly testing the modified code to ensure correctness and stability.
      Skills Required
      Proficiency in C programming.
      Strong understanding of Linux kernel internals, specifically memory management (page cache, folios) and file system interfaces (VFS).
      Experience with kernel module development and debugging (highly desirable).
      Understanding of the Linux kernel module build process, including linking, loading, and symbol resolution.
      Experience with, or a strong understanding of, the challenges and techniques involved in interfacing non-GPL code with the GPL-licensed Linux kernel (e.g. understanding symbol visibility and export restrictions).
      Familiarity with distributed file systems concepts (helpful).
      
      
      ~~~~~~~~~~
      Idea: Implement Command-line Completion for OpenAFS Commands
      Project Size: 12 weeks
      Skill Level: Intermediate
      Languages: C, Shell
      Description
      OpenAFS provides a suite of command-line tools for managing and interacting with the distributed file system. Currently, these tools lack bash and zsh command-line completion, making them less user-friendly and efficient to use, especially for complex commands or unfamiliar users. This project aims to implement comprehensive Bash completion for the most commonly used OpenAFS commands, significantly improving the command-line experience. The preferred solution would automatically add new command line completions as new options and subcommands are added to the code base.

      Skills Required
      Experience in C programming.
      Proficiency in Shell scripting.
      Experience with Bash and zsh completion (compspec, complete).
      Familiarity with the OpenAFS command-line tools (e.g., `vos`, `fs`, `pts`).
      Basic understanding of OpenAFS concepts (helpful).
       

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openafs/
    idea_list_url: https://www.openafs.org/gsoc/project-ideas.html


  - organization_id: 110
    organization_name: OpenAstronomy
    no_of_ideas: 5
    ideas_content: |
      Spectral timing in Julia
      Create a set of timing and spectral timing methods in Julia
      matteobachettistefanocovinofjebaker
      GSOC 350 h
      stingrayjuliaAstro

      
      Description
      The analysis of time series from astronomical observations in the X-rays is an excellent tool to test advanced physical theories. Of particular interest are the periodicities that are often observed in the X-ray signals coming from the surroundings of accreting black holes, and the evolution of the rotation period of neutron stars. The essential toolbox for X-ray timing analysis includes different kinds of periodograms, cross spectra, and a number of “variability vs energy spectra”, that allow to understand the variability at different energies. This project is about the implementation of a basic set of X-ray timing analysis operations in Julia, continuing the porting of the core operations from the stingray Python package [initiated during Google Summer of Code 2022] (https://github.com/StingraySoftware/Stingray.jl)

      Milestones
      Coding starts
      Gain familiarity with the codebase
      Apply existing analysis to simulated datasets
      Implement I/O operation on FITS files
      1st evaluation
      Implement a series of tests in Julia that the new code will have to pass
      Extend basic operations (periodograms and cross spectra) to event lists and light curves
      Time lags and coherence spectra
      Final evaluation
      A working framework for variability vs energy spectra (covariance spectra, time lags)

      ~~~~~~~~~~




      Electronic spectra for RADIS
      The project aims at adding the possibility to calculated electronic spectra with RADIS, mainly using the newly available molecules in ExoMol
      minouHuberwanp
      GSOC 350 h
      radis

      Description
      The RADIS code was developed for the characterization of plasmas, flames and atmospheres. High-temperature spectral calculations require to resolve the shape of tens of millions of lines, which is the usual performance bottleneck. RADIS implements a new algorithm to compute these lineshapes, and is already one of the fastest line-by-line spectral codes available. It can also compute many different types of spectra (absorption / emission / equilibrium / nonequilibrium). In a typical calculation, a database of coefficients is loaded and these coefficients are multiplied according to physics laws to generate a set of line strengths in a spectrum.

      RADIS can handle different molecular databases such as HITRAN, HITEMP, EXOMOL, and GEISA. Currently, it supports the computation of rovibrational spectra, which correspond to transitions between rotational and vibrational energy levels. However, it lacks the capability to compute electronic spectra from databases like EXOMOL, which would complement its existing capabilities.

      Other codes allow to compute electronic spectra of diatomic molecules and can be used as a reference or comparison point:

      Moose - https://github.com/AntoineTUE/Moose
      MassiveOES - https://bitbucket.org/OES_muni/massiveoes (with Radis/MassiveOES example in https://github.com/radis/massiveOES-examples)
      ExoMol list - https://www.exomol.com/software/
      Milestones
      Coding starts
      Engage with the community on 💬 RADIS Slack

      Have set up a development environment, be familiar with open-source tools (GitHub / Git / Tests) and RADIS architecture

      1st Evaluation
      Adapt how the EXOMOL database is currently employed to allow the computation of electronic spectra at thermal equilibrium (single temperature)

      Add documentation and example. Add tests against other spectral codes.

      To ease the understand of the physics behind the code, the contributor could start with non-equilibrium spectra of atomic species (see Secondary goals). This is entirely optional and up to the contributor.

      2nd Evaluation
      Add the possibility to compute electronic spectra at thermal non-equilibrium (electronic temperature != translational temperature)

      Add documentation and example. Add tests against other spectral codes.

      For diatomic species, start a new database based on MassiveOES sources.

      Final evaluation
      Have all code, tests, and documentation in GitHub.
      Secondary Goals
      RADIS can compute atomic spectra thanks to the hard work of GSOC 2023 and 2024 contributors, see https://github.com/radis/radis/pull/689. An interesting approach would be to start with non-equilibrium spectra of atomic species as the physics is slighly easier than for molecule.

      Document architecture and developer guide when facing unclear points that may appear.

      Review pull requests from other RADIS contributors

      ~~~~~~~~~~


      Fast parsing of large databases and execution bottlenecks
      The conversion of large files from a compressed format to hdf5 should be accelerated
      minouHubTranHuuNhatHuydcmvdbekerom
      GSOC 175 h
      radis

      Description
      The RADIS code was developed for the characterization of plasmas, flames and atmospheres. High-temperature spectral calculations require to resolve the shape of tens of millions of lines, which is the usual performance bottleneck. RADIS implements a new algorithm to compute these lineshapes, and is already one of the fastest line-by-line spectral codes available. It can also compute many different types of spectra (absorption / emission / equilibrium / nonequilibrium). In a typical calculation, a database of coefficients is loaded and these coefficients are multiplied according to physics laws to generate a set of line strengths in a spectrum. RADIS can also handle different molecular databases such as HITRAN, HITEMP, EXOMOL, and GEISA.

      With more and more lines added to the databases, some files grew considerably in size. To be as fast as possible, RADIS convert compressed databases into the HDF5 format. This conversion also increases the size of the files which can take hours to be written in the hard drive (2-3 hours for HITEMP CO2 in its 2025 version). The objective of this project is to accelerate the parsing to HDF5 files.

      Milestones
      Coding starts
      Engage with the community on 💬 RADIS Slack

      Have set up a development environment, be familiar with open-source tools (GitHub / Git / Tests) and RADIS architecture

      1st Evaluation
      Based on the demonstration of @dcmvdbekerom, implement a C++ new parsing algorithm in RADIS. The demonstration can be found here, which includes a detailed explanation and code examples.

      Add documentation and example. Add tests against other spectral codes.

      2nd Evaluation
      Propose a solution to save several HDF5 files instead of a large one in .radisdb. For example, save 10 files of 7 GB each instead of a single 70-GB file for HITEMP CO2

      Write a review of current bottleneck in 1/ the parsing and 2/ the computation of spectra. This bottleneck review should be uploaded on the documentation, with working examples for small (~1 cm-1) and large (~100 cm-1) spectra. See this example: https://github.com/radis/radis/issues/685

      Tackle some of the bottleneck by either modifying the code, leveraging numba, or writing a C++ code.

      Final evaluation
      Have all code, tests, and documentation in GitHub.
      Secondary Goals
      Document architecture and developer guide when facing unclear points that may appear.

      Review pull requests from other RADIS contributors

      Although this project is devoted to CPU computation, the interested contributor can also contribute to the resolution of GPU bottlenecks. For instance: in a GPU computation, the database first needs to be copied to a host buffer (i.e. CPU side), a so called ‘staging buffer’. After that, the database can be copied to the GPU. For integrated GPU’s, i.e. when the GPU is part of the CPU chip (like most Intel and AMD processors), the CPU and GPU memory is shared. Ideally, the database would directly be loaded into the staging buffer to prevent copying the same database 3 times (1: regular load, 2: staging buffer, 3: GPU buffer).

      ~~~~~~~~~~


      Optimizing Radis app
      Our project is all about enhancing user experience to the next level! We're committed to bringing you cutting-edge features and fine-tuning these features for maximum performance and efficiency, and rigorous testing to ensure they meet the needs of our highly valued end users
      erwanparunavabasucom
      GSOC 350 h
      radis

      Description
      RADIS app is a web application for Radis high-resolution infrared molecular spectra. Instead of writing code, this project aims to create an intuitive user interface (UI). It use radis internally to produce spectrum, and the updated version and radis algorithm make it incredibly efficient to compute the millions of lines in only a few minutes. Radis app leverages React 18 to offer the user interface, and FastApi on the backend.

      We are using react-hook-form for the fastest user experience and to maintain performance on the client slide. In the backend, we use FastApi to offer the fastest response. We created this app with the intention of giving both researchers and non-researchers access to the most valuable elements of Radis via a straightforward online application. Our team and contributors are always trying to make the app better. The app has additional features and capabilities in newer versions.

      Our project is all about enhancing user experience to the next level! We’re committed to bringing you cutting-edge features and fine-tuning these features for maximum performance and efficiency, and rigorous testing to ensure they meet the needs of our highly valued end users.

      Milestones
      Coding starts
      Engage with the community on 💬 RADIS Slack

      Have set up a development environment, be familiar with open-source tools (GitHub / Git / Tests) and RADIS App

      Get familiar with RADIS App’s Frontend (how radis app interface works and simulates spectrum )and Backend System (how the app integrated with radis to produce a spectrum)

      1st Evaluation
      Implement exomol database in radis app API

      Fitting feature (user imports their experimental spectrum)

      UI improvements to modern standards

      2nd Evaluation
      Implementation of caching on the API side for faster response times using a in memory caching system.
      Final evaluation
      Improving code coverage and test all the basic features using vitetest and migrating old tests too.

      Fix the feedback loop on the user side (user should be able to submit feedbacks in the app)

      Have all code, tests, and documentation in GitHub.

      Secondary Goals
      Review pull requests from other RADIS contributors, especially if there is a parallel GSoC student.

      ~~~~~~~~~~


      Interactive Database for X-ray observations
      Create an interactive database for analyzing, storing, and classifying X-ray observations of accreting black holes
      mgullikmatteobachetti
      GSOC 350 h
      stingray

      Description
      The increasing number of X-ray telescopes observing accreting black hole sources has led to an incredibly large amount of available observational data. To build a comprehensive understanding of stellar-mass black hole phenomenology, it is essential to access and analyze this information in an intuitive and structured manner.

      This project aims at developing a tool that analyzes, stores, and organizes key data products of multiple observations in a database. Users will be able to interactively explore the database and classify individual observations based on data products retrieved with Stingray, potentially leveraging innovative machine learning techniques. Beyond enabling large-scale classification and the discovery of general trends in accreting black hole binaries, the tool will allow astronomers to identify peculiar features hidden within the vast dataset.

      Challenges: Efficient storage and fast retrieval of data products, ensuring interactivity of the tool, and enabling comparisons across different X-ray instruments.

      Milestones
      Coding starts
      Gain familiarity with the observations (different type of X-ray telescopes) and with the products
      1st evaluation
      Create the database
      Graphic interface to interact with the database
      Final evaluation
      Classification of the observations base on their products (possible use of ML techniques)
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openastronomy/
    idea_list_url: https://openastronomy.org/gsoc/gsoc2025/#/projects
  

  - organization_id: 111
    organization_name: OpenCV
    no_of_ideas: 17
    ideas_content: |
      IDEA: Multi-camera calibration part 3
      Description: During GSoC 2023 a new cool multi-camera calibration algorithm was improved: https://github.com/opencv/opencv/pull/24052. This year we would like to finish this work with more test cases, tune the accuracy and build higher-level user-friendly tool (based on the script from the tutorial) to perform multi-camera calibration. If this is completed before the internship is up, then we'll move on to leveraging the IMU or marker-free calibration.
      Expected Outcomes:
      A series of patches with more unit tests and bug fixes for the multi-camera calibration algorithm
      New/improved documentation on how to calibrate cameras
      A short YouTube video showing off how to use the calibration routines
      Skills Required: Mastery of C++ and Python, mathematical knowledge of camera calibration, ability to code up mathematical models
      Difficulty: Medium-Difficult
      Possible Mentors: Maksym Ivashechkin, Alexander Smorkalov
      Duration: 175 hours

      ~~~~~~~~~~


      IDEA: Multi-camera calibration test
      Description: We are looking for a student to curate best of class calibration data, collect calibration data with various OpenCV Fiducials, and graphically produce calibration board and camera models data (script). Simultaneously, begin to write comprehensive test scripts of all the existing calibration functions. While doing this, if necessary, improve the calibration documentation. Derive from this expected accuracy of fiducial types for various camera types.
      Expected Outcomes:
      Curate camera calibration data from public datasets.
      Collect calibration data for various fiducials and camera types.
      Graphically create camera calibration data with ready to go scripts
      Write test functions for the OpenCV Calibration pipeline
      New/improved documentation on how to calibrate cameras as needed.
      Statistical analysis of the performance (accuracy and variance) of OpenCV fiducials, algorithms and camera types.
      A YouTube video showing describing and demonstrating the OpenCV Calibration testss.
      Resources: OpenCV Fiducial Markers, OpenCV Calibration Functions, OpenCV Camera Calibration Tutorial 1, OpenCV Camera Calibration Tutorial 2
      Skills Required: Mastery of C++ and Python, mathematical knowledge of camera calibration, ability to code up mathematical models
      Difficulty: Medium
      Possible Mentors: Jean-Yves Bouguet, Alexander Smorkalov
      Duration: 175 hours

      ~~~~~~~~~~
      IDEA: Multi-camera calibration toolbox
      Description: Build a higher-level user-friendly tool (based on the script from the calibration tutorial) to perform multi-camera calibration. This should allow easy multi-camera calibration with at multiple Charco patterns and possibly other calibration fiducial patterns. The results will use Monte-Carlo sampling to determine parameter stability, allow easy switching of camera models and output the camera calibration parameters and the fiducial patterns pose in space as well as the extrinsic locations of each camera relative to the others.
      Expected Outcomes:
      Tool with convenient API that will be more or less comparable and compatible with Kalibr tool (https://github.com/ethz-asl/kalibr)
      New/improved documentation on how to calibrate cameras
      A Youtube video demonstrating how to use the box
      Skills Required: Python, mathematical knowledge of camera calibration, ability to code up mathematical models
      Difficulty: Medium-Difficult
      Possible Mentors: Jean-Yves Bouguet, Gary Bradski
      Duration: 175 hours

      ~~~~~~~~~~
      IDEA: Quantized models for OpenCV Model Zoo
      Description: Many modern CPUs, GPUs and specialized NPUs include special instructions and hardware blocks for accelerated inference, especially for INT8 inference. The models don't just become ~4x smaller compared to FP32 original models, the inference speed increases significantly (by 2x-4x or more) as well. The number of quantized models steadily increases, however, beyond image classification there are not so many 8-bit computer vision models with proven high-quality results. We will be interested to add to our model zoo (https://github.com/opencv/opencv_zoo) 8-bit models for object detection, optical flow, pose estimation, text detection and recognition etc.
      Expected Outcomes:
      Series of patches to OpenCV Zoo and maybe to OpenCV DNN (when OpenCV DNN misses 8-bit flavors of certain operations) to add the corresponding models.
      If quantization is performed by student during the project, we will request the corresponding scripts to perform the quantization
      Benchmark results to prove the quality of the quantized models along with the corresponding scripts so that we can reproduce it.
      Skills Required: very good ML engineering skills, good Python programming skills, familiarity with model quantization algorithms and model quality assessment approaches
      Possible Mentors: Feng Yuantao, Zhong Wanli, Vadim Pisarevsky
      Difficulty: Medium
      Duration: 90 to 175 hours, depending on the particular model.

      ~~~~~~~~~~
      IDEA: RISC-V Optimizations
      Description: RISC-V is one of main target platforms for OpenCV. During past several years we brought in some RISC-V optimizations based on RISC-V Vector extension by adding another backend to OpenCV scalable universal intrinsics. We refactored a lot of code in OpenCV to make the vectorized loops compatible with RISC-V backend and more or less efficient. Still, we see a lot of gaps and the performance of certain functions can be further improved. For some critical functions, like convolution in deep learning, it makes sense perhaps to implement custom loops using native RVV intrinsics instead of using OpenCV scalable universal intrinsics. This is what we invite you to do.
      Expected Outcomes:
      A series of patches for core, imgproc, video and dnn modules to bring improved loops that use OpenCV scalable universal intrinsics or native RVV intrinsics to improve the performance. In the first case the optimizations should not degrade performance on other major platforms like x86-64 or ARMv8 with NEON.
      Resources:
      OpenCV Wide Universal Intrinsics Guide
      Implementation of wide universal intrinsics for various platforms, including RISC-V
      Skills Required: mastery plus experience coding in C++; good skills of optimizing code using SIMD.
      Possible Mentors: Mingjie Xing, Maxim Shabunin
      Difficulty: Hard
      Duration: 350 hours

      ~~~~~~~~~~
      IDEA: Dynamic CUDA support in DNN
      Description: OpenCV DNN module includes several backends for efficient inference on various platforms. Some of the backends are heavy and bring in a lot of dependencies, so it makes sense to make the backends dynamic. Recently, we did it with OpenVINO backend: https://github.com/opencv/opencv/pull/21745. The goal of this project is to make CUDA backend of OpenCV DNN dynamic as well. Once it's implemented, we can have a single set of OpenCV binaries and then add the necessary plugin (also in binary form) to accelerate inference on NVidia GPUs without recompiling OpenCV.
      Expected Outcomes:
      A series of patches for dnn and maybe core module to build OpenCV DNN CUDA plugin as a separate binary that could be used by OpenCV DNN. In this case OpenCV itself should not have any dependency of CUDA SDK or runtime - the plugin should encapsulate it. It is fine if the user-supplied tensors (cv::Mat) are automatically uploaded to GPU memory by the engine (cv::dnn::Net) before the inference and the output tensors are downloaded from GPU memory after the inference in such a case.
      Resources:
      Skills Required: mastery plus experience coding in C++; good practical experience in CUDA. Acquaintance with deep learning is desirable but not necessary, since the project is mostly about software engineering, not about ML algorithms or their optimization.
      Possible Mentors: Alexander Smorkalov
      Difficulty: Hard
      Duration: 350 hours

      ~~~~~~~~~~
      IDEA: Synchronized multi camera video recorder
      Description: Multi-camera calibration and multi-view scenarios require synchronous recording with multiple cameras. Need to tune cv::VideoCapture or/and VideoWriter and implement sample for video recording with several cameras with timestamps
      Expected Outcomes:
      Sync video recording sample for several cameras: V4L2, RTSP(?)
      Resources: Overview
      Skills Required: C++
      Possible Mentors: Alexander S.
      Difficulty: Easy-Medium
      Duration: 175

      ~~~~~~~~~~
      IDEA: libcamera back end for VideoCapture
      Description: Discussion: #21653
      Expected Outcomes:
      MIPI camera support on Raspberry Pi
      Resources:
      Skills Required: C++, Linux
      Possible Mentors: TBD
      Difficulty: Medium
      Duration: 175

      ~~~~~~~~~~
      IDEA: Better LLMs support in OpenCV (1)
      Description: Large Language Models, or LLM, are AI models designed to understand, generate and manipulate human language. One of the barrier to better support LLMs is tokenizer support. A tokenizer can break down raw text into smaller pieces (tokens), which are easier for models to understand and process. This project aims to integrate tokenizer in dnn module.
      Expected Outcomes: A patch that integrates tokenizer in dnn module
      Resources:
      Let's Build the GPT Tokenzier https://youtu.be/zduSFxRajkE?si=JF725Ipnzc4R5Nnc
      OpenAI's tokenizer https://github.com/openai/tiktoken
      Hugging Face's AutoTokenizer https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py
      Skills Required: C++, Python, LLMs/Transformers
      Mentor: Yuantao Feng
      Difficulty: Hard
      Duration: 175

      ~~~~~~~~~~
      IDEA: Better LLMs support in OpenCV (2)
      Description: LLMs support in OpenCV is unclear. One of the most key feature in the current dnn engine is fixed memory allocation after model importing, which helps speeding up model inference for CNNs but then becomes the limit of running LLMs that has flexible inputs. This project aims to try LLMs as many as possible with OpenCV, fix dnn engine to support more LLMs, and write demos to show LLMs inference with OpenCV.
      Expected Outcomes:
      Several patches that fix dnn engine to support more LLMs.
      Several patches that add demos to show LLMs inference with OpenCV.
      Resources:
      GPT2 inference with OpenCV https://github.com/opencv/opencv/blob/5.x/samples/dnn/gpt2_inference.py
      LLMs that llama.cpp supports https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#description
      Skills Required: C++, Python, LLMs/Transformers
      Mentor: Yuantao Feng
      Difficulty: Hard
      Duration: 175

      ~~~~~~~~~~
      IDEA: Computational photography algorithms for better image quality
      Description: Improving image quality is important task, which is still not covered well in OpenCV. We already have "non-local means" (photo module) and BM3D (opencv_contrib) denoising algorithms, simple white balance algorithms (opencv_contrib), very simple exposure correction function (equalizeHist in imgproc: grayscale images only) and function for distortion correction (undistort function in imgproc), that's it. The following could be useful to have:
      more efficient/better-quality denoising algorithms
      vignetting correction
      chromatic aberration correction
      smarter white balance algorithms
      exposure correction for color images
      multi-frame (image burst) denoising
      superresolution for still images and video
      deblurring
      color enhancement, defogging
      etc.
      Note that:
      this idea is not about any special effects, 'beautification' etc. It's about improving pure technical image quality
      the idea is quite big, applicant(s) may and probably should suggest to implement a subset of the above items, they can also add something on top (as long as note (a) above is taken into account).
      Expected Outcomes:
      Several patches to opencv_photo module and/or opencv_contrib repo that add the new functionality, tests, samples etc.
      Resources:
      TBD
      Skills Required: C++, Python
      Mentor(s): Gursimar Singh, Vadim Pisarevsky as adviser.
      Difficulty: Hard
      Duration: 175

      ~~~~~~~~~~
      IDEA: Improve OpenCV's security
      Description: OpenCV can be better integrated with https://oss-fuzz.com/ to get better fuzzing, mostly by moving the tests to the OpenCV repository and writing more tests (especially for imgcodecs and videoio). Additionally, sandboxing could be integrated into OpenCV to make sure invalid inputs are safely discarded by integrating sandbox2.
      Expected Outcomes:
      Several patches that improve the oss-fuz integration.
      Several patches that add an optional build of OpenCV with sandbox2 integrated for some functions.
      Resources:
      sandbox2 documentation https://developers.google.com/code-sandboxing/sandbox2
      fuzztest documentation https://github.com/google/fuzztest
      ongoing PR for fuzztest integration: https://github.com/opencv/opencv/pull/24193
      Skills Required: C++
      Mentor: Vincent Rabaud
      Difficulty: Hard
      Duration: 175

      ~~~~~~~~~~
      IDEA: Integrate Fractal ArUco into OpenCV
      Description: Fractal markers are a new concept of marker, which is composed of several fiducial square markers of different size inside. Unlike traditional fiducial markers, the structure of this marker can be detected from a large number of distances, as well as solve problems of partial or total occlusion of the marker.
      Expected Outcomes:
      Integrate Fractal ArUco into OpenCV with a simple API, which should be similar to the ArUco API currently in OpenCV.
      Detailed documents for Fractal ArUco API in OpenCV
      A nice demo to show how to use the algorithm.
      Resources: Frictal ArUco
      Skills Required: C++, Python.
      Mentor: Rafael Muñoz Salinas, Shiqi Yu
      Difficulty: Easy
      Duration: 175 hours

      ~~~~~~~~~~
      IDEA: Integrate JuMarker ArUco into OpenCV
      Description: Fiducial markers such as QR codes, ArUco, and AprilTag have become very popular tools for labeling and camera positioning. They are robust and easy to detect, even in devices with low computing power. However, their industrial appearance deters their use in scenarios where an attractive and visually appealing look is required. In these cases, it would be preferable to use customized markers showing, for instance, a company logo. This work proposes a novel method to design, detect, and track customizable fiducial markers. Our work allows creating markers templates imposing few restrictions on its design, e.g., a company logo or a picture can be used. The designer must indicate positions into the template where bits will encode a unique identifier for each marker. Then, our method will automatically create a dictionary of markers, all following the same design, but each with a unique identifier.
      Expected Outcomes:
      Integrate JuMarker ArUco into OpenCV with a simple API, which should be similar to the ArUco API currently in OpenCV.
      Detailed documents for Fractal ArUco API in OpenCV
      A nice demo to show how to create a JuMarker and to detect it.
      Resources: JuMarker ArUco
      Skills Required: C++, Python.
      Mentor: Rafael Muñoz Salinas, Shiqi Yu
      Difficulty: Hard
      Duration: 350 hours

      ~~~~~~~~~~
      IDEA: LightGlue Matcher with Aliked Feature
      Description: Add the LightGlue feature matcher into opencv (to join the BFMatcher and the FLAAN matcher), then add the ALIKED feature to the feature detector descriptor so that we can use one of the features (ALIKED, SIFT, SURF, ORB, BRISK ...) and match points between two images. Extra, add subpixel accurate detectors keypt2subpx as a post processor on keypoints formatting them correctly.
      Expected Outcomes:
      Add LightGlue as a new feature matcher
      Add ALIKED to DNN as a feature detector descriptor, formatting the output data to work with OpenCV's feature matchers
      Add Subpixel accurate keypoint adjustment keypt2subpx
      Create an example of subpixel accurate feature matching between pairs of images
      Create test code, documentation and a video of it working
      Resources:
      LightGlue Code that works with ALIKED https://github.com/cvg/LightGlue
      LightGlue Paper
      ALIKED Code https://github.com/Shiaoming/ALIKED
      ALIKED Paper
      Subpixel accurate keypoint refinement code https://github.com/KimSinjeong/keypt2subpx
      Subpixel accurate point refinement paper keypt2subpx
      Skills Required: Python, Computer vision AI model training, pytorch
      Mentor: Gary Bradski, Gursimar Singh
      Difficulty: Medium
      Duration: 200

      ~~~~~~~~~~
      IDEA: Basic SLAM
      Description: Using feature detector, descriptors such as LightGlue Code that works with ALIKED, create a SLAM framework for OpenCV (with help from an expert mentor)
      Expected Outcomes:
      Collect video sequences to be tracked such as with LightBlue+ALIKED above or in public SLAM databases
      Develop a SLAM algorithm
      Include unit test code and data
      Create a demo code and video of how to use it
      Resources:
      LightGlue Code that works with ALIKED
      Public SLAM databases
      Comprehensive Survey Paper of SLAM Databases
      Ceres Solver Code
      Skills Required: Python, Ceres, understanding of SLAM
      Mentor: Reza Amayeh
      Difficulty: Hard
      Duration: 200

      ~~~~~~~~~~
      IDEA: QR/Barcode/ArUco detector
      Description: QR, Barcode and ArUco are all popular code in computer vision applications. OpenCV now support all of them, and can detect and decode them. But OpenCV still expect a better detector and decoder for them. If possible, one efficient deep detector for all kinds of codes can simplify the usage. If one efficent deep detector cannot be achieved, several deep models are also acceptable.
      Expected Outcomes:
      Train a deep detector for QR, Barcode and ArUco. Or train three different deep detectors for different codes specifically.
      The trained model should be easy to implement with the current algorithms in OpenCV on QR/Barcode/ArUco.
      A nice demo to show how to use the algorithm.
      Detailed report to demontrate if the trained detector(s) are better than the current solution in OpenCV.
      Resources:
      How to train an efficent face detection model
      YuNet: A Tiny Millisecond-level Face Detector
      Skills Required: C++, Python, and experience on object detection.
      Mentor: Shiqi Yu
      Difficulty: Hard
      Duration: 350 hours
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/opencv/
    idea_list_url: https://github.com/opencv/opencv/wiki/GSoC_2025

  - organization_id: 112
    organization_name: OpenELIS Global
    no_of_ideas: 7
    ideas_content: |
      Creating a generic robust reporting framework 
      350 hours
      OpenELIS already has support for pre-designed reports. This project aims to create a Robust reporting framework for users to be able to create ad-hoc Patient reports from the UI 
      Ability to create ad-hoc Patient reports from the UI
      React , Typescript, Java , Spring , REST
      Mutesasira Moses
      @mozzy mutesa 

      ~~~~~~~~~~
      Improve Integration Tests coverage
      350 hours
      The current Integration Test coverage is still low. 
      This project aims at extending and  creating more Integration Tests to achieve a Test Coverage of at least 60% for the Backend service Layer
      60% Test coverage
      Java , Spring , J-Unit
      Herbert Yiga
      @Herbert Yiga 

      ~~~~~~~~~~
      Re-Write Test management components in React
      350 hours
      Currently ,Most of test management components ie “Modify tests” , “Add Tests” are still not migrated to the new React Frontend. This project aims at migrating the Test management components and some other functionalities (not yet migrated)  to the new React Front End
      Test management components migrated to the new React FrontEnd
      React , Typescript, Java , Spring , REST
        Gita Cliff
      @cliff 

      ~~~~~~~~~~
      Add Support for OpenELIS to use OCL to populate the Data Dictionary 
      350 hours
      Currently , The OpenELIS Data Dictionary is populated manually or through Liquibase scripts.
      This project aims at adding support for OpenELIS to be able to consume data dictionaries from Open Concept Lab(OCL) a Terminology Management System 
        Ability to populate the Data dictionary from OCL
      Built out test catalogs through using new initializer to parse new collection or from extract in initializer
      React , Typescript, java , Spring , REST
        Reagan Makoba
      @reagan meant 

      ~~~~~~~~~~
      Intergrate OpenELIS with Odoo(OpenER)
      350 hours
      This project aims at adding an integration layer between OpenELIS Global2 and Odoo (OpenERP) in order to add support for Billing functionalities with  the OpenELIS Order workflow
      Added support for Billing functionalities with in OpenELIS
      React , Typescript, Java , Spring , REST
        Ragan Makoba
      @reagan meant 

      ~~~~~~~~~~
      
      Improving E2E QA tests
      350 hours
      The current E2E tests have like a 30 % Coverage.
      This project is dedicated to improve the End-to-End (E2E) testing coverage for the New React front end to at least 80% Coverage and ensuring robust validation of the entire application workflow . 
      Improved and comprehensive E2E QA framework to at least 80% coverage
      React , Typescript, 
      Cypress
        Caesy Hauser
      @Casey Iiams-Hauser 

      ~~~~~~~~~~
      Add support for multiple Translation Languages via Transfex
      350 hours
      OpenELIS currently support only two Languages ie English and French .
      This projects aims at adding more support for multiple languages via Transfex
      Spanish as a use case; adopt from 1 to many languages
      Ability to translate the UI messages into multiple Languages and Automated via Transfex
      Typescript, React ,
        Caesy Hauser
      @Casey Iiams-hauser 
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openelis-global/
    idea_list_url: https://uwdigi.atlassian.net/wiki/spaces/OG/pages/321224705/GSoC+2025

  - organization_id: 113
    organization_name: OpenMRS
    no_of_ideas: 12
    ideas_content: |
    
      Support for horizontal scaling of OpenMRS instances 
      Large
      In the scope of the project would be (depending on the progress we make using other contribution channels):
      Adjust codebase across core and O3 modules to use a new storage service described here.
      Adjust code in core and O3 modules to use distributed caching
      Experiment with Hibernate Search using OpenSearch as backend instead of a local Lucene index.
      Java, Hibernate
      @Rafal Korytkowski 

      ~~~~~~~~~~


      Interactive Builder for Form Translations within the Form Builder 
      Large
      Right now, in order to add translations to a form, the way to do this to add it to a configuration folder that can be picked up by Iniz. This is annoying because
      You’d need a developer’s help to know what to do and where to do it
      The JSON file format is quite different from that of a form, so its not very intuitive for a non-techy person to do
      There’s no a dynamic and user-friendly way to do it
      
      The ideas is to create a UI that would enable users to add the translations for a form for any language.
      React, CSS
      @nethmi 

      ~~~~~~~~~~
      Performance Testing Enhancement Project
      Medium
      The current load tests cover only two scenarios, limiting performance insights. This project aims to:
      Identify key scenarios that should be tested for better system performance evaluation.
      Implement additional performance tests to ensure comprehensive coverage.
      Enhance the existing test framework for scalability and reliability.
      This will improve OpenMRS’s ability to handle high-load conditions and optimize system performance.
      Java, Gatling
      @Jayasanka Weerasinghe 

      ~~~~~~~~~~
      Service Queues
      Medium
      We have a service queues app in O3, which is functional, but needs some attention, both to the frontend design and to the backend APIs that are used to populate it. The goal here would be to fix various UI issues and improve the overall performance and reliability of the queue module. The Service Queues view is incredibly useful for managing outpatient clinics, allowing users to track who is waiting for service, how long they’ve been waiting for etc.
      React, Java
      @Ian Bacher 

      ~~~~~~~~~~
      
      
      Improved Audit Logging
      Medium
      We added Hibernate Envers for audit logging in OpenMRS 2.7.0, but right now, admin users cannot easily view or manage these logs. 
      This project aims to build a backend module that can
      Show Audit Logs: Pull and display audits for database tables.
      Filters: Let users filter logs by things like who made the changes, when, and what they changed.
      REST Endpoints: Add APIs so other systems can access the audit data.
      Java, Spring, Hibernate
      @Wikum Weerakutti 
      @Manoj Rathnapriya

      ~~~~~~~~~~ 
      Enhancing OpenAPI Documentation Generation 
      Medium
      Errors related to the Swagger documentation have been under review, with efforts made to upgrade it to the latest versions of OpenAPI (or a similar version). The necessary pull requests have already been submitted.
      For this GSoC, it is suggested that, in addition to the ongoing work, efforts should be directed towards developing tooling or a mechanism that would enable the automatic generation of Swagger documentation by analyzing Javadocs, return types, and other relevant elements. Some work has already been undertaken to achieve this, utilizing reflection to scan OpenMRS resource handlers. It is proposed that further developments be made on top of this existing foundation to enhance the envisioned tooling.
      The ultimate objective is for the OpenAPI specification to be generated at compile time rather than at runtime, as is currently the case. This shift would ensure that errors are identified at compile time rather than being detected during runtime.
      For reference,
      Improving Our Swagger Documentation Process
      Upgrade swagger from 2.0 to swagger/openapi 3.0
      Enhancing OpenAPI Documentation Generation 
      Java, OpenAPI
      @Chi Bong Ho 
      @herman muhereza 

      ~~~~~~~~~~
      Fix the Fast Data Entry feature
      Medium
      The Bulk Data Entry feature (BDE) is broken and unusable in the OpenMRS community’s main product (the O3 RefApp). No community organization or contributor has had the time or ability to fix this, and yet it is an important foundational feature for OpenMRS users.
      The goal of this project is to fix the BDE feature and get it useable again in the O3 RefApp, primarily by engineering the feature to leverage the React Form Engine instead of the Angular Form Engine.
      React
      @Samuel Male 
          
      ~~~~~~~~~~    
      OpenMRS Standalone
      Large
      Replace the Standalone with something else. Very old, can’t even build in our latest releases - we disable it as the technology no longer works and is no longer supported. We now just ship the .war file and README. Suggestion to leverage Docker - something that works by double clicking and then just runs.
      We never intended to use the OpenMRS Standalone version in production. But it turned out to be used in a number of places because they found it easier to use for sites that did not have support staff with advanced IT skills. We are also seeing an increasing number of people in our community who do not have lots of computer skills and just want something to download, click and run for their hospitals.
      Java
      @Daniel Kayiwa 
      @Wikum Weerakutti 

      ~~~~~~~~~~
      Integrating Data Filter for Data Segregation / Multi-tenancy
      Large
      Data Filter is a powerful module that uses Hibernate’s filtering APIs to add additional where clauses to various SELECT statements. The use-case for this is to allow system-wide filters to be applied to the data added. Currently Data Filter includes a default set of filters that restrict the availability of data on patients to a set of locations a user has access to. The point of this project would be to expand on these capabilities to add things like: an administrative UI for associating users and patients with specific locations, additional rules to account for the various modules used in the O3 RefApp, templates for additional rules that may be useful (i.e., tie the ability to see obs with certain codes to certain privileges).
      Java, Hibernate
      @Joshua Nsereko 
      @Wyclif Luyima 

      ~~~~~~~~~~
      Immunization & Vaccination Schedule app for O3
      Medium
      Immunization Schedules (timings) are a key feature to make sure people (especially children) get the right vaccinations, at the right times, and enough of them, so that they are safely covered from diseases. 
      This visual project will make it easier for clinicians to see how many doses a child/person has had, and what immunizations they are due for.
      React
      @Dennis Kigen 

      ~~~~~~~~~~


      Implement Stricter Typescript configuration
      Medium
      This project aims to enforce stricter TypeScript configurations across OpenMRS repositories, ensuring developers follow best practices for strong typing. The primary goal is to eliminate the use of any, enforce strict type safety, and refactor existing code to comply with these rules.
      By implementing stricter TypeScript settings and refining type definitions, this project will enhance code maintainability, reduce runtime errors, and improve the overall developer experience.
      React, Typescript
      @Christopher Lumu 
      
      ~~~~~~~~~~
      Improved Implementer Tools
      Medium
      The Implementor Tools in OpenMRS can be enhanced for better usability and functionality.
      Proposed Improvements:
      Color Picker & Preview: Currently, only the hex code is shown. Or at least adding a color picker and visual preview would improve user experience.
      Better Nested Object Handling: The UI editor struggles with nested objects, making it harder to edit complex structures.
      Font Visibility Fixes: Some font colors blend into the background, affecting readability. Improved contrast would enhance accessibility.
      Other potential improvements include better validation, UI optimizations, and enhancements to streamline configuration. These changes will make the tool more intuitive and user-friendly.
      React
      @Vineet Sharma 

    
        
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openmrs/
    idea_list_url: https://openmrs.atlassian.net/wiki/spaces/RES/pages/322404353/Summer+of+Code+2025

  - organization_id: 114
    organization_name: OpenMS
    no_of_ideas: 9
    ideas_content: |
      1) PEPTIDE M/Z CALCULATOR
      Proposed Mentors: Arslan Siraj, Tom Müller
      Skills: Python, Git, Streamlit
      Estimated Project Length: 90 hours | Difficulty: Easy
      In mass spectrometry (MS) proteomics and metabolomics, one common task is to compute the mass-to-charge (m/z) ratio of the analyte so that it can be located in a spectrum. Although the calculation is computationally simple and can easily be performed by the pyopenms package, this simple, commonly used calculation can be cumbersome for wet lab scientists with little programming experience. In this project the student will use the new OpenMS-WebApps template to create a simple GUI to allow researchers to perform this calculation. This calculation can be performed using pyopenms as demonstrated here Furthermore, this outcome web application further can be extend to other MS calculations tasks (e-g theoretical spectra generation etc) for quick interpretation of MS data.
      
      ~~~~~~~~~~
      2) WRITE A GENERIC VISUALIZATION APP FOR MZQC
      Proposed Mentors: Chris Bielow, Arslan Siraj
      Skills: Visualization, Controlled Vocabularies, Python|R
      Estimated Project Length: 175 hours | Difficulty: Easy to Medium
      Adoption and public exposure of quality control in mass-spectrometry (MS) has gained increasing traction in recent years. The Proteomics Standard Initiative (PSI) has developed an open exchange format named mzQC, which aims to foster capturing, exchanging and archiving quality control related data across all MS-based OMICS, such as proteomics, metabolomics and lipidomics. Currently, there exists no package which is capable of visualizing and summarizing the content of any given mzQC file (e.g. as obtained from a publication’s supplemental material).
      Tasks:
      Pick a visualization framework of your choice (e.g. Streamlit or R Shiny) and write code (Python or R) to allow a user to explore the content of a given (uploaded) mzQC file.
      Visualization could be a textual summary as well as (interactive) plots for the QC data contained within the mzQC file. Depending on the metrics properties, automated plot types should be chosen.
      
      ~~~~~~~~~~
      3) IMPROVING PYOPENMS TOOL PARAMETER ACCESSIBILITY
      Proposed Mentors: Tom Müller, Joshua Charkow
      Skills: Python, Cython, Git
      Estimated Project Length: 175 hours | Difficulty: Medium
      PyOpenMS provides Python bindings for OpenMS, a powerful open-source C++ library for computational mass spectrometry. These bindings are automatically generated using Cython and the autowrap package. While C++ developers prioritize performance and fine-grained control, Python developers emphasize readability and ease of use. Simply exposing a C++ API to Python often results in an interface that feels unnatural to Python users. One area where this is particularly evident in PyOpenMS is the handling of parameters in OpenMS algorithms. Currently, retrieving and modifying parameters requires multiple steps: instantiating an object from an algorithm class, calling a method to obtain parameters, modifying them through a dedicated ‘Param’ class, and applying them via a setter method. This workflow is complex and does not align with Pythonic conventions. The task is to improve the usability of PyOpenMS by enabling parameter setting directly via keyword arguments when instantiating objects of an algorithm class and making parameters easily accessible through the help() function for interactive exploration.
      Tasks:
      Modify the Cython binding for function type checking and conversion.
      Add Pythonic helper functions for type checking and conversion.
      Port the C++ tool documentation to Python.
      ~~~~~~~~~~
      1) PYTHONIC MZML HANDLING
      Proposed Mentors: Joshua Charkow, Tom Müller Skills: Python, Git Estimated Project Length: 175 hours | Difficulty: Easy
      Liquid-Chromatography-Mass Spectrometry data is commonly stored in sparse multidimensional data containing billions of peaks and can easily exceed a few gigabytes when compressed on disk. Python is commonly used in the field for exploratory analysis and development of novel data processing algorithms. The most common format for storing mass spectrometry data is in .mzML, an XML based format Although numerous libraries exist for parsing .mzML files in Python, an open source XML based format most commonly used in the field, each library contains its own UI which might not be intuitive for data scientists just starting with mass spectrometry. Recently, the alphatims package was introduced which stores mass spectrometry data in a pandas dataframe like structure making it quite accessible data manipulation and exploration. Notably, this format takes advantage of python’s slicing syntax making it intuitive for all data scientists. However, this package only supports “.d” files which are vendor specific and not applicable to the broader mass spectrometry community. In this project, the student will create a “pythonic” .mzML file reader inspired by alphatims by extending the current available .mzML python parsers.
      Tasks:
      Leaverage the pyopenms documentation to get familiar with pyopenms .mzML file reading.
      Create a class which allows for splicing of the .mzML file across various dimensions and returning a DataFrame object.
      Benchmarking this class on various .mzML files for read times and memory usage.
      creating a python package and releasing it on PyPI.
      
      ~~~~~~~~~~
      2) WRITE A C++ LIBRARY TO READ/WRITE MZQC
      Proposed Mentors: Chris Bielow, Nils Hoffmann Skills: C++, Controlled Vocabularies, JSON, CMake, GitHub CI
      Estimated Project Length: 350 hours | Difficulty: Easy to Medium
      Adoption and public exposure of quality control in mass-spectrometry (MS) has gained increasing traction in recent years. The Proteomics Standard Initiative (PSI) has developed an open exchange format named mzQC,which aims to foster capturing, exchanging and archiving quality control related data across all MS-based OMICS, such as proteomics, metabolomics and lipidomics. Currently, there exist core libraries to read and write mzQC in Python, R, and Java. See MS-Quality-Hub.
      Tasks:
      implement a new mzQC Core library in C++ which supports reading/writing of mzQC
      publish the library on GitHub under a permissive license (BSD-3clause) as a subproject of MS-Quality-Hub.
      write class/unit tests and run them using GithubActions
      integrate your library into OpenMS (incl. adaptation of the build system to include your library) and substitute existing code to create an mzQC
      
      ~~~~~~~~~~
      3) INTEGRATE APACHE PARQUET INTO OPENMS BUILD SYSTEM
      Proposed Mentors: Timo Sachsenberg, Samuel Wein
      Skills: CMake, GitHub CI, C++, Python
      Estimated Project Length: 350 hours | Difficulty: Medium
      Proteomics and metabolomics mass spectrometry studies are generating datasets of unprecedented size as they scale to include more and more samples. Managing and processing these large datasets efficiently requires robust and scalable data handling solutions to make results readily available for downstream processing tasks like machine learning.
      The task is to integrate Apache Parquet, a columnar storage format, into OpenMS as a fundamental step toward enabling faster data processing, reducing memory usage, and improving scalability. The integration will involve:
      Updating the OpenMS build system with new CMake configurations.
      Developing comprehensive tests to validate functionality and performance.
      Adapting CI/CD pipelines for macOS, Linux, and Windows to ensure cross-platform compatibility.
      ~~~~~~~~~~
      4) UNIVERSAL MASS SPECTROMETRY DATA PROCESSING IN PYTHON
      Proposed Mentors: Wout Bittremieux, Janne Heirman
      Skills: Python, R, GitHub CI
      Estimated Project Length: 350 hours | Difficulty: Medium
      A major challenge in mass spectrometry (MS) data analysis is the lack of interoperability between different open-source software tools. While various data processing packages in Python exist, many of these suffer from development inefficiencies due to having to implement duplicate functionality.
      This project aims to address these inefficiences by integrating leading open-source MS processing and visualization tools, such as spectrum_utils, pyOpenMS, Pyteomics, and matchms. The goal is to seamlessly connect these tools, harnessing similar internal MS data representations across different tools, allowing users to easily move between different software tools without redundant re-implementation of core functionality.
      To achieve this, we will develop translation layers between different MS tools, enabling smooth data exchange both within and across programming languages; optimize existing algorithms to handle the ever-growing size of MS datasets efficiently, ensuring faster and more scalable data processing; and create a unified workflow that makes MS analysis more intuitive, accessible, and powerful for researchers worldwide.
      By building these bridges, this project will empower scientists to focus on discoveries rather than data format headaches, fostering collaboration and innovation across the mass spectrometry community.
      ~~~~~~~~~~
      
      
      
      1) DIFFUSION DECONVOLUTION OF DIA-MS/MS DATA (D^4 | DQUARTIC)
      Proposed Mentors: Justin Sing, Leon Xu
      Skills: Python, PyTorch, Deep Learning
      Estimated Project Length: 350 hours | Difficulty: Medium to Advanced
      Diffusion models have revolutionized generative AI, excelling in tasks like image enhancement and speech separation. This project applies similar principles to Data-Independent Acquisition Mass Spectrometry (DIA-MS)—a technique that captures complex, overlapping signals requiring deconvolution. This project offers an exciting opportunity to apply deep learning & generative AI techniques to a real-world bioinformatics challenge. If you enjoy working on AI models for signal processing, deconvolution, and scientific applications, we’d love to have you on board!
      Problem: DIA-MS produces two correlated data types: MS1: A low-resolution “overview” (analogous to a blurry image or background noise in audio). MS2: Detailed but highly multiplexed signals (akin to overlapping voices in an audio recording).
      The goal is to train a diffusion model to deconvolve and denoise MS2 signals, using MS1 as a guiding signal—similar to how Stable Diffusion refines blurry images or Whisper (OpenAI) separates speech from noise.
      Current Progress & Next Steps:
      A baseline U-Net-based diffusion model already shows promising results on synthetic mixtures of DIA-MS data. The next phase is to:
      a. Train the model on raw DIA-MS data for direct peptide signal separation. b. Integrate MS1 and MS2 peptide feature masks (from OpenSwath, DIA-NN, or Spectronaut) as conditioning signals—similar to how segmentation masks guide image super-resolution. c. Investigate pseudo-DDA spectra generation (e.g., diaUMPIRE, diaTracer) by incorporating intermediate deconvolution steps.
      Tasks:
      Optimize Data Loading: Implement efficient pipelines for handling large-scale DIA-MS data.
      Improve Memory Efficiency: Apply quantization to reduce model footprint, similar to vision models.
      Enhance Conditioning Signals: Refine how the model extracts targeted peptide signals from MS1/MS2 data.
      Explore Alternative Architectures: Test transformer-based backbones (e.g., ViTs) for potential performance gains.
      
      ~~~~~~~~~~
      2) OPTIMIZING CASANOVO FOR FAST AND ACCURATE DE NOVO PEPTIDE SEQUENCING
      Proposed Mentors: William Stafford Noble, Wout Bittremieux
      Skills: Python, PyTorch, deep learning, profiling
      Estimated Project Length: 350 hours | Difficulty: Advanced
      De novo peptide sequencing is a powerful approach for molecular discovery by deciphering peptides directly from tandem mass spectrometry (MS/MS) data. Casanovo is a state-of-the-art AI tool that treats de novo sequencing like a language translation problem—converting sequences of peaks in an MS/MS spectrum into amino acid sequences, just like translating one language into another. Powered by a transformer deep neural network, Casanovo has already revolutionized peptide sequencing, but its inference speed remains a bottleneck, particularly during beam search decoding, the step responsible for selecting the best peptide candidates.
      By making Casanovo faster and more efficient, we can unlock new biological insights at an unprecedented scale. Whether it’s identifying unknown proteins, uncovering disease biomarkers, or advancing drug discovery, your contributions will have a real-world impact on science and healthcare. If you love machine learning, performance optimization, and AI-driven discovery, this project is your chance to make a difference in computational biology!
      This project aims to optimize Casanovo’s speed, enabling researchers to process larger datasets, make new discoveries faster, and push the boundaries of proteomics research. You will:
      a. Profile performance bottlenecks in Casanovo’s inference pipeline to pinpoint slowdowns. b. Optimize beam search decoding and other key computations to improve runtime efficiency. c. Enhance scalability, ensuring Casanovo can handle the growing demands of big-data proteomics.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openms/
    idea_list_url: https://www.openms.org/news/gsoc2025/

  - organization_id: 115
    organization_name: OpenStreetMap
    no_of_ideas: 13
    ideas_content: |
      
      Modernize the 3D Model Repository
      Suggested By
      Tordanik
      Summary
      The 3D Model Repository (3DMR) is a website which lets users upload openly licensed 3D models and link them with OSM data. Renderers such as OSM2World can use this to create 3D scenes of real-world locations. The goal of this project is to improve the 3DMR by adopting glTF as the format for 3D models, and to upgrade the codebase to current versions of Django and Oauth. In addition to these essential updates, the project would be an opportunity to improve the website UI and API.
      Mandatory skills
      Python
      Useful skills
      Django, JavaScript, 3D graphics
      Length
      350 hours
      Difficulty
      medium
      Possible Mentors
      Lonvia, Tordanik
      Notes
      As a minimum requirement for applicants, we expect you to set up a local copy of the existing codebase on your own prior to submitting your application so you have a starting point for your work.
      
      
      ~~~~~~~~~~
      
      Temporary road closures database and API
      Suggested By
      SimonPoole
      Summary
      Produce a prototype repository and API for temporary road closures and similar for use in OSM (navigation) apps that supports user submitted data, at least one prototype integration in an OSM Navigation app is expected.
      Mandatory skills
      Postgres/SQL, languages suitable for prototyping for an UI and an API
      Useful skills
      having a brain
      Length
      350 hours
      Difficulty
      advanced
      Possible Mentors
      SimonPoole
      Notes
      The assumption is that the API will deliver the information in OpenLR format and that data entry can either be via an extension to an app, or a web UI. For an implementation of OpenLR and matching to OSM data see https://github.com/FraunhoferIVI/openlr Contribution guidelines for projects that I mentor contribution guidelines https://github.com/simonpoole/GSOC/blob/main/guidelines.md
      
      
      ~~~~~~~~~~
      Searching
      Nominatim - Transliteration of Search Results
      Suggested By
      Lonvia
      Summary
      OpenStreetMap registers names of streets, POIs and places usually in the local language. Larger features like cities or states have translations into other languages but simple POIs like restaurants or hotels often have the local name only. That means that it is quite possible that when searching in OSM data, results are returned that are not only in an unknown language but also in an unknown script, making it impossible to read. Transliteration solves this problem by transfering an unknown script into one the user knows an can read. For this project we want to add transliteration to results of the search engine Nominatim when there are a results that the user may not be able to read.
      Mandatory skills
      Python
      Useful skills
      knowledge of a non-Latin script or the willingness to learn basic reading of one during the project
      Length
      175 hours
      Difficulty
      medium (some research is expected and smaller road blocks that need to be solved independently)
      Possible Mentors
      Lonvia, mtmail
      Notes
      The map on openstreetmap.de shows transliterated names. Have a look especially at Asia and compare with the standard map on [1]. The code for the localisation of the German map can give some useful pointers to libraries for transliteration.
      Comments
      Please also see the general hints for contributing to Nominatim for GSOC at User:Lonvia/GSoC_2021_Nominatim_Projects.
      
      ~~~~~~~~~~
      Nominatim - Category search using ID presets
      Suggested By
      Lonvia
      Summary
      When users search places, they often like to use category words ("hotels in Berlin", "Eiffel tower bus stop", ...). Nominatim has limited support for such category searches. It defines Nominatim/Special_Phrases which are detected in the search query and then used to filter the results. The manually curated lists in the wiki are rather tedious to keep and duplicate other community-maintained lists. For this project, you should explore the tagging presets of the ID editor. The presets contain an extensive list of category names for OSM tags with many translations. The goal of this project is to make these terms searchable with Nominatim. Given that the editors and search engines have very different goals, this will not be a straightforward translation. You will have to experiment and research how category words are used in search, which may include thinking about into simple linguistic problems in a multi-lingual setting.
      Mandatory skills
      basic understanding of OSM tagging including some experience with editing OSM data, basic Python
      Useful skills
      SQL(Postgresql, Postgis)
      Required experience
      intermediate
      Length
      175 or 350 hours
      Difficulty
      medium to advanced
      Possible Mentors
      Lonvia, mtmail
      Notes
      This idea can be either done as a shorter 175h project concentrating on extracting and using simple category words from ID's presets. This would be of medium difficulty. At a length of 350h, students can dive more deeply into the search algorithms for categories and improve them to also find subcategories ("vegan restaurants").
      Comments
      Original issue at [2]. Please also see the general hints for contributing to Nominatim for GSOC at User:Lonvia/GSoC_2021_Nominatim_Projects.
      
      ~~~~~~~~~~
      Routing
      Valhalla - Faster Tile Builds
      Suggested By
      Kevinkreiser
      Summary
      The router relies on a preprocessing step to build a graph from OSM data. This graph tile build is a multiphase process that takes around a day to run on modern hardware. There are a number optimization experiments we can try to bring the overall build time down. More info here: https://github.com/valhalla/valhalla/issues/5099
      Mandatory skills
      familiarity with c-like languages
      Useful skills
      multithreading, performance profiling, knowledge of graph structures
      Required experience
      novice
      Length
      175 hours
      Difficulty
      moderate
      Possible Mentors
      Kevinkreiser
      Notes
      Comments
      Experimentation is encouraged, we should pull whatever threads look to be most promising in our experiments.
      
      ~~~~~~~~~~
      Ferrostar - Snapshot Recording, Testing, and Replay
      Suggested By
      Ian Wagner (on osm, edits, contrib, heatmap, chngset com.)
      Summary
      Ferrostar is a rust based cross-platform turn-by-turn navigation SDK. Ferrostar works with multiple routing engines and using tools like Mozilla's UniFFI and TSify, integrates with modular UI for native iOS, Android and a web PWA (thanks to GSOC 2024!).
      But not all navigation goes according to plan! If we could record the inputs from a navigation session (GPS etc.), and the new state after each update, we can “see through the user’s eyes” when something goes wrong. The contributor will help build such a session logging and snapshot testing tool.
      In addition to the backend (Rust), the contributor will also build a frontend integration for at least one platform (Native iOS or Android, or Typescript web components).
      Mandatory skills
      Rust; some mobile or web
      Useful skills
      Most work will be in Rust, but there will also be some work in a frontend platform of your choice (iOS, Android, Web); you don’t need to be an excellent frontend designer or anything, but some existing knowledge will help.
      Length
      175 hours
      Difficulty
      medium
      Possible Mentors
      Ian Wagner (on osm, edits, contrib, heatmap, chngset com.) and Jacob Fielding
      Notes
      GitHub discussion
      iD editor

      ~~~~~~~~~~
      MapRoulette Integration in iD
      Suggested By
      @tordans
      Summary
      Similar to the QA Layers in iD, add a MapRoulette integration to see and resolve tasks. The UI can be mostly backported from Rapid. However, the underlying code will likely need to be changed to fit into the iD architecture. More at https://github.com/openstreetmap/iD/issues/10758
      Mandatory skills
      JavaScript, D3
      Useful skills
      Working with APIs in JavaScript, OSM mapping experience
      Required experience
      intermediate
      Length
      175 hours
      Difficulty
      medium
      Possible Mentors
      Martin Raifer
      Notes
      
      Comments
      

      ~~~~~~~~~~
      Improve Sidewalk mapping in iD
      Suggested By
      @tordans
      Summary
      Backport the improvements for Sidewalk mapping from Rapid to iD and modify them based on community feedback. More at https://github.com/openstreetmap/iD/issues/10757 and https://github.com/openstreetmap/iD/issues/10743
      Mandatory skills
      JavaScript, D3, strong OSM mapping background
      Useful skills
      -
      Required experience
      advanced
      Length
      175 hours
      Difficulty
      medium
      Possible Mentors
      Martin Raifer
      Notes
      -
      Comments
      -

      ~~~~~~~~~~
      Widget for opening hours
      Suggested By
      Martin Raifer
      Summary
      The goal of this project would be to implement a user interface widget which should a) provide a better visual interpretation of already mapped Key:opening_hours (for example in the form of a time table), b) checks for the validity of the contents of the tag, and c) allow to more easily add or modify such information. The widget should be able to take the most common formats into account and allow a fallback to show the full tag content for more complex situations.
      Mandatory skills
      JavaScript
      Useful skills
      Experience with the D3.js framework, OSM tagging/mapping workflows, and iD development
      Required experience
      intermediate
      Length
      90 or 175 hours
      Difficulty
      medium
      Possible Mentors
      Martin Raifer
      Notes
      This project could be extended to 175 hours by enhancing the functionality of the widget also to UI fields for tags with temporal conditions.
      
      ~~~~~~~~~~
      Add a "kbar" for an alternative way to configure iD
      Suggested By
      @tordans
      Summary
      iD has many options that can be toggled during a mapping session. The concept of a "kbar" (https://kbar.vercel.app/) provides an alternative way to reach those options. This would allow power users to quickly change settings without adding keyboard shortcuts to each setting (and memorizing them). See https://github.com/openstreetmap/iD/issues/8801 for more
      Mandatory skills
      JavaScript, D3
      Useful skills
      -
      Required experience
      advanced
      Length
      175 hours
      Difficulty
      medium
      Possible Mentors
      Martin Raifer, Tobias
      Notes
      -
      Comments
      -
      
      ~~~~~~~~~~
      Vespucci
      AI extraction of information from camera captured images
      Suggested By
      SimonPoole
      Summary
      Develop a solution to extract text from a captured image or directly from the camera. The captured text should either be able to be used as a tag value, or to generate a set of tags that can be directly applied to an osm object. It is mandatory that this only uses resources available on device.
      Mandatory skills
      Java or Kotlin
      Useful skills
      gradle, experience with Android development
      Length
      350 hours
      Difficulty
      medium to challenging
      Possible Mentors
      SimonPoole
      Notes
      The successful candidate will need to have access to a suitably powerful Android device. Googles MLkit might be a potential starting point for text recognition. Note that the use of models and code that cannot be distributed on open terms is not possible. Vespucci repo: https://github.com/MarcusWolschon/osmeditor4android , contribution guidelines https://github.com/simonpoole/GSOC/blob/main/guidelines.md
      
      ~~~~~~~~~~
      Every Door
      Photos in Every Door
      Suggested By
      User:Zverik
      Summary
      Many people have asked for photos in Every Door. They need to be of two kinds: photo notes, and pictures of OpenStreetMap objects. The former may be probably attached to OSM notes and share the StreetComplete infrastructure, while the latter must use Panoramax and add relevant tags. There will be an authentication hurdle, probably related to sharing OAuth tokens. This might also involve collaborating with MapComplete author on their instance.
      Mandatory skills
      Flutter + Dart
      Useful skills
      UX design, Riverpod
      Required experience
      intermediate
      Length
      175 hours
      Difficulty
      medium
      Possible Mentors
      User:Zverik
      Notes
      The Every Door code base is currently undergoing a major refactoring, so it's unclear how easy or hard this would be. But with an experience in basic app design this should be not very hard.
      
      ~~~~~~~~~~
      Test coverage for Every Door
      Suggested By
      User:Zverik
      Summary
      Every Door has grown into a big application with a lot of moving parts. Modifying it is sometimes risky, which leads to bugs not patched for a long time. Some little things are covered with tests, but there are absolutely no widget tests, and data tests are also largely missing. Here we need to cover with tests three main areas: providers, field widgets and classes, and helper classes.
      Mandatory skills
      Flutter + Dart, QA
      Useful skills
      Riverpod
      Required experience
      high
      Length
      350 hours
      Difficulty
      medium
      Possible Mentors
      User:Zverik
      Notes
      This is not a front-facing tasks: the app won't get better from your work. But it hardens the foundation for future improvements. You need to have some experience in planning and writing tests, and reading flutter code.
      Categories: Google Summer of Code 2025Google Summer of Code ideas
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openstreetmap/
    idea_list_url: https://wiki.openstreetmap.org/wiki/Google_Summer_of_Code/2025/Project_ideas


  - organization_id: 116
    organization_name: OpenVINO Toolkit
    no_of_ideas:
    ideas_content: |
      Spend your summer doing something exciting and valuable for the open-source community, and join Google Summer of Code. Read more about how the program works on this page.
      OpenVINO Toolkit has been a mentoring organization since 2022!
      Announcements
      Please subscribe this discussion and check it regularly for important announcements.
      Prerequisite task
      We require one pull request sent to our OpenVINO repository from each potential GSoC contributor before accepting participation for GSoC. We would like to see if you know how to code, use git and GitHub, and your coding style. To fulfill this requirement, please:
      Visit the OpenVINO Good First Issues board or Anomalib Good First Issues.
      Select one of the unassigned tickets ("Contributors Needed" column) and ask for the assignment.
      Discuss the solution with the OpenVINO developers.
      Implement it according to the OpenVINO contribution guide or Anomalib contribution guide.
      If you encounter any issues talk to our developers on Discord.
      Create a new pull request with your work.
      Wait for the review and eventual merge.
      Please note the above task is mandatory. However, we reserve the right to review and merge only the selected PRs. Not merging or closing your PR doesn't change your chances of being accepted for GSoC. Due to the expected large number of requests, the review process can be delayed, so please be patient.
      If you're unfamiliar with git and GitHub, check out this blog. The blog is about contributing to OpenVINO core project, but the workflow is same for all projects.
      Application Template
      Your application should consist of the following parts:
      About you
      Your full name
      Your university/current enrollment
      The timezone you live in
      Short bio
      Your experience in programming (especially C++ and Python)
      Your experience in ML and DL
      About the project
      What is your choice?
      Why did you choose this specific idea?
      How much time do you plan to invest in the project?
      Provide an abstract of the solution
      Provide a detailed timeline of how you want to implement the project (include the main points you want to cover and dates)
      General questions
      How do you know OpenVINO?
      What do you know about OpenVINO?
      Have you already contributed to the OpenVINO project? (please include links)
      How could you apply it to your professional development?
      Describe any other career development plan you have for the summer in addition to GSoC.
      Why should we pick you?
      Tasks
      Link to your pull request (for the prerequisite task – the top part of this document), even if it is already merged or closed
      Proposal examples can be found here and here. Please get in touch with us early to discuss your application with the mentor.
      The proposal must be uploaded to the GSoC website during the GSoC contributor application period (according to the dates in timeline).
      Project ideas for 2025
      All project ideas for 2025 can be found here.
      Projects already implemented (2022-2024)
      Projects implemented in the past can be found here.
      Contribution guidelines
      Contribution guidelines can be found here.
      Contact us
      Open OpenVINO discussions tab
      Start a new discussion by pushing the green button (if you cannot see the button, it means you're not logged in)
      Select a "Google Summer of Code" category and add the "gsoc" label
      Ask your question (please be aware everything you post there is publicly available)
      Please get in touch with us early to discuss your application with the mentor. Mentors will do their best to reply to all contributors, but due to a large contributor interest this year, they may not be able to respond to all inquiries
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openvino-toolkit/
    idea_list_url: https://github.com/openvinotoolkit/openvino/wiki/Google-Summer-Of-Code#project-ideas-for-2025


  - organization_id: 117
    organization_name: OpenWISP
    no_of_ideas: 9
    ideas_content: |
      
      Mass Commands
      Important
      Languages and technologies used: Python, Django, JavaScript, WebSockets, REST API.
      Mentors: Gagan Deep, Purhan Kaushik, Kapil Bansal.
      Project size: 350 hours.
      Difficulty rate: medium.
      This project idea aims to extend OpenWISP's remote device management capabilities by enabling users to execute shell commands on multiple devices simultaneously. Currently, OpenWISP supports executing commands on a single device at a time. This project will introduce a bulk execution feature while maintaining the existing security, rules, and limitations of the single-device command execution feature.
      The mass command operation will be accessible from two main entry points:
      An admin action on the device list page, allowing users to select multiple devices and send a shell command in bulk.
      A dedicated mass command admin section, where users can initiate bulk command execution with various targeting options:
      All devices in the system (restricted to superusers).
      All devices within a specific organization.
      All devices within a specific device group.
      All devices within a specific geographic location.
      Specific selected devices.
      The UI will guide users step-by-step, dynamically displaying relevant fields based on the selected target scope. For example, if a user selects "All devices in a specific organization", an auto-complete list of organizations will be displayed next.
      The system will provide real-time tracking of command execution results. Inspired by OpenWISP Firmware Upgrader's mass upgrade feature, the UI will receive live updates via WebSockets, displaying command output as soon as it is received from the devices. Additionally:
      The device detail page will show executed commands under the "Recent Commands" tab.
      Commands that were part of a mass operation will be clearly marked, with a link to the corresponding mass command operation page.
      To support API-based management, the REST API will be extended with the following capabilities:
      Create new mass command operations.
      Retrieve mass command operations and their results (with pagination).
      Delete mass command operations.
      Modify the single-shell command API to reference the mass command operation ID if applicable.
      Prerequisites to work on this project
      Applicants must demonstrate a solid understanding of Python, Django, HTML, CSS, JavaScript, WebSockets, and OpenWISP Controller.
      Expected outcomes
      Implementation of mass shell command execution in OpenWISP, replicating the rules and limitations of single-device execution.
      Development of an intuitive UI with the Django admin for selecting devices and tracking command results in real-time.
      Admin action for device list page.
      Enhancement of the device detail page to reflect mass command history for individual devices.
      Extension of the REST API to support mass command operations.
      Comprehensive automated tests covering the new feature.
      Updated documentation, including:
      Feature description with usage instructions.
      A short example usage video for YouTube that we can showcase on the website.
      
      
      ~~~~~~~~~~
      
      X.509 Certificate Generator Templates
      Important
      Languages and technologies used: Python, Django, JavaScript.
      Mentors: Federico Capoano, Aryaman, Nitesh Sinha.
      Project size: 90 hours.
      Difficulty rate: medium.
      This GSoC project aims to enhance OpenWISP's certificate management capabilities by enabling the generation of x509 certificates for general use, beyond OpenVPN.
      Currently, OpenWISP supports generating x509 certificates exclusively for OpenVPN clients, where each VPN client template produces a certificate signed by the CA linked to the corresponding VPN server. However, many users have requested support for generating certificates for other purposes, such as securing web servers.
      The proposed solution involves introducing a new template type that allows users to generate certificates using a selected CA. This template should provide configurable options, including:
      Certificate duration
      Key length
      Digest algorithm
      If left unspecified, these options should default to the CA's standard settings.
      Prerequisites to work on this project
      Applicants must demonstrate a solid understanding of Python, Django, JavaScript, and OpenWISP Controller.
      Expected outcomes
      Implement a new certificate template type in OpenWISP to support general-purpose x509 certificate generation.
      Allow users to select a CA and configure certificate properties.
      Integrate with OpenWISP's configuration management to expose certificate details (public key, private key, and UUID) as variables for automated deployment.
      Write automated tests to ensure the correctness and reliability of the new functionality.
      Updated documentation, including:
      Feature overview in a dedicated page with step-by-step usage instructions.
      Short Video demonstration.
      
      
      ~~~~~~~~~~
      WHOIS Information and IP Address-Based Geolocation
      Important
      Languages and technologies used: Python, Django, REST API.
      Mentors: Federico Capoano, Nitesh Sinha, Kapil Bansal
      Project size: 175 hours.
      Difficulty rate: Easy/Medium.
      This GSoC project aims to enhance OpenWISP’s device management capabilities by integrating WHOIS data retrieval and automatic fuzzy geolocation based on public IP addresses.
      The project consists of two main features:
      1. WHOIS Information Retrieval
      When a device reports a last_ip that is a public IP and differs from the previously stored value, OpenWISP should automatically trigger a background Celery task to retrieve and store its WHOIS information.
      A summary of key WHOIS details (e.g., organization name, country, ISP) will be displayed alongside the last_ip field on the device detail page.
      Users will have the option to expand this section to view additional details.
      The REST API should include WHOIS summary information in the device list and device detail endpoints.
      An additional API option in the device details endpoint should allow retrieving the complete WHOIS data stored in the database.
      2. Fuzzy Geolocation from IP Addresses
      The system should attempt to determine approximate geographic coordinates based on the device’s last_ip and create a Location object with this data, marking it as Fuzzy (a different term may be considered).
      IP-based geolocation must be processed in a background Celery task to avoid slowing down the main processes.
      The UI should clearly indicate that this location is estimated and encourage users to manually refine it for greater accuracy.
      A notification can be sent to users suggesting they review or confirm the estimated location.
      If the Location object remains unmodified and marked as fuzzy, OpenWISP should detect changes in the device's public IP address and reattempt IP-based geolocation, updating the coordinates if they differ.
      The Location admin list page should include a filter for fuzzy locations.
      The Device admin list page should include a filter for devices with fuzzy locations (expanding on the existing filter for devices with or without geographic locations).
      This feature should be configurable at both the global and organization levels, allowing administrators to enable or disable it as needed. Existing modules already provide organization settings that default to global configuration, see FallbackBooleanChoiceField for reference.
      The OpenWISP Controller REST API must be updated to support these functionalities:
      Include the fuzzy field in the Location list and detail endpoints.
      Allow filtering fuzzy locations.
      Allow filtering devices with fuzzy locations.
      Prerequisites to work on this project
      Applicants must demonstrate a solid understanding of Python, Django, REST APIs, HTML, CSS, JavaScript, OpenWISP Controller, and django-loci.
      Expected Outcomes
      Implementation of WHOIS data retrieval as a background operation and display within the OpenWISP Controller admin panel.
      Development of fuzzy geolocation based on public IPs, with clear UI explanations and manual override options.
      Integration with OpenWISP’s notification system to suggest location refinements.
      Admin filters to identify fuzzy locations and devices with fuzzy locations.
      Configurable settings to enable or disable the feature globally or per organization.
      REST API enhancements to reflect the new functionalities.
      Comprehensive automated tests ensuring feature reliability.
      Updated documentation, including:
      A feature overview with step-by-step usage instructions on dedicated pages.
      Videos demonstrating WHOIS data retrieval and geolocation results.
      Configuration details for enabling or disabling these features.
      
      
      ~~~~~~~~~~
      Improve OpenWISP General Map: Indoor, Mobile, Linkable URLs
      Important
      Languages and technologies used: Python, Django, JavaScript, Leaflet, netjsongraph.js.
      Mentors: Federico Capoano, Nitesh Sinha, Gagan Deep.
      Project size: 350 hours.
      Difficulty rate: medium.
      This GSoC project aims to enhance the user experience of the general map within OpenWISP, a feature introduced in the last stable version.
      By developing a dedicated map page, facilitating precise device tracking, and seamlessly integrating indoor floor plans, the project endeavors to significantly improve the usability and functionality of the mapping interface, ensuring a more intuitive and effective user experience.
      Prerequisites to work on this project
      Applicants must demonstrate a solid understanding of Python, Django, Leaflet library, JavaScript, OpenWISP Controller, OpenWISP Monitoring. and netjsongraph.js.
      Expected outcomes
      Add a dedicated map page: Introduce a dedicated page to display all network devices on a map. This view will offer the same functionality as the map in the dashboard, with the sole difference being that this page focuses on rendering only the map. It will be used for linking specific points on the map within the rest of the OpenWISP UI.
      Allow tracking mobile coordinates: OpenWISP Controller provides a way for devices to update their co-ordinates, we want to make the map able to update in real time as devices send their updated coordinates.
      Integrate indoor floor plan functionality in the map: The netjsongraph.js library allows to render indoor maps, we want to make use of this feature to display the indoor location of devices and we want this feature to be accessible from the general map. When zooming in on a device which is flagged as indoor and has floor plans saved in the database, users should see an option to switch to the indoor view. This view would show the floor plan of the indoor location and any device located on the floor plan, it shall also account for the following use cases:
      An indoor location can have multiple floors. The view should be allow users to navigate between different floors.
      There can be multiple devices on the same floor. The view should show all the devices on a floor. This will require developing an API endpoint which returns location of devices on the floor plan
      Make map actions bookmarkable: Update the URL when clicking on a node/link to view its details. Visiting this URL should automatically focus on the specified node/link and display its details, if available. This functionality should also accommodate geo-maps using coordinates. Clicking on a node/link to view it's details should update the the page's URL. When visiting this URL, the map should automatically focus the said node/link. It shall also open the node's/link's details if they are available. This should work on geographic maps, indoor maps and logical maps.
      Add button to general map from device detail: Implement a button on the device detail page to allow users to navigate from the device detail to the general map and inspect the device's location on the map. The map should focus on the specific device in question. This feature should also be available for indoor maps, providing a button in the floor plan section to open the general map with the indoor view focused.
      Throughout the code changes, it is imperative to maintain stable test coverage and keep the README documentation up to date.
      Note
      The "expected outcomes" mentioned above include links to corresponding GitHub issues. However, these issues may not cover all aspects of the project and are primarily intended to gather technical details. Applicants are encouraged to seek clarification, propose solutions and open more issues if needed.
      Applicants are also expected to deepen their understanding of the UI changes required by preparing wireframes or mockups, which must be included in their application. Demonstrating a willingness and enthusiasm to learn about UI/UX development is crucial for the success of this project.
      
      ~~~~~~~~~~
      Improve netjsongraph.js resiliency and visualization
      Important
      Languages and technologies used: Javascript, NodeJS, HTML, CSS
      Mentors: Nitesh Sinha, Federico Capoano.
      Project size: 175 hours.
      Difficulty rate: medium.
      The goal of this project is to improve the latest version of the netjsongraph.js visualization library to improve resiliency and functionality.
      Prerequisites to work on this project
      The contributor should have a proven track record and experience with Javascript, React JS, NodeJS, HTML and CSS.
      Familiarity with OpenWISP Network Topology and OpenWISP Monitoring is a plus.
      Expected outcomes
      The applicant must open pull requests for the following issues which must be merged by the final closing date of the program:
      Allow showing node names on geo map on high zoom levels: The node names should be shown by default on high zoom levels.
      Map should respect zoom levels of tile providers: We shall limit the map zoom levels based on the tile provider. We can make the supported zoom levels configurable and provide sensible defaults.
      Prevent overlapping of clusters: The clusters of different categories with the same location are overlapped. Instead, we should find a way to prevent this behavior.
      Add resiliency for invalid data: The library should not crash if invalid data is provided, e.g. different nodes with same ID. Instead, it should handle such cases gracefully and log the errors.
      Display additional data (connected clients) on nodes: It shall be possible to show connected clients on nodes. This feature needs to be flexible, such that it can be used to show different kinds of data.
      Show node labels only after hitting a certain zoom level: At present, the node labels become cluttered and unreadable when zoomed out excessively. To enhance readability, we need to add a feature in the library that allows configuring the zoom level at which node labels should start appearing.
      Each issue contains the details which the applicant needs to know in order to complete the project successfully.
      At each step of code changing the test coverage must be maintained stable and the documentation in the README must be kept up to date.
      
      
      ~~~~~~~~~~
      Improve UX and Flexibility of the Firmware Upgrader Module
      Important
      Languages and technologies used: Python, Django, OpenWrt.
      Mentors: Oliver Kraitschy, Purhan Kaushik.
      Project size: 175 hours.
      Difficulty rate: easy/medium.
      The goal of this project is to improve the Firmware Upgrader module to make its mass upgrade operation feature more versatile and to improve the user experience by showing progress in real time.
      Prerequisites to work on this project
      The applicant must demonstrate good understanding of Python, Django, Javascript and OpenWISP Controller.
      They must demonstrate also a basic understanding of OpenWISP Firmware Upgrader, OpenWrt and UI development.
      Prior experience with OpenWrt is not extremely required but welcome.
      Expected outcomes
      The applicant must open pull-requests for the following issues which must be merged by the final closing date of the program:
      [feature] REST API is missing endpoints for DeviceFirmware
      [feature:UI] Show upgrade progress in real time in the UI
      [feature] Allow to perform mass upgrade of devices by their group
      [feature] Allow to perform mass upgrade of devices by their location
      Each issue contains the details which the applicant needs to know in order to complete the project successfully.
      At each step of code changing the test coverage must be maintained stable and the documentation in the README must be kept up to date.
      Training Issues
      The applicant may warm up in the application phase by working on the following issues:
      [bug] FileNotFoundError when trying to delete an image which links a non existing file
      [change] Improve endpoints to download firmware images
      [feature] Allow management of UpgradeOperation objects in the admin
      
      
      ~~~~~~~~~~
      Add more timeseries database clients to OpenWISP Monitoring
      Important
      Languages and technologies used: Python, Django, InfluxDB, Elasticsearch.
      Mentors: Gagan Deep, Aryaman, Sankalp.
      Project size: 350 hours.
      Difficulty rate: medium.
      The goal of this project is to add more Time Series DB options to OpenWISP while keeping good maintainability.
      Prerequisites to work on this project
      The applicant must demonstrate good understanding of OpenWISP Monitoring, and demonstrate basic knowledge of NetJSON format, InfluxDB and Elasticsearch.
      Expected outcomes
      Complete the support to Elasticsearch. Support to Elasticsearch was added in 2020 but was not completed.
      The old pull request has to be updated on the current code base
      The merge conflicts have to be resolved
      All the tests must pass, new tests for new charts and metrics added to InfluxDB must be added (see [feature] Chart mobile (LTE/5G/UMTS/GSM) signal strength #270)
      The usage shall be documented, we must make sure there's at least one dedicated CI build for Elasticsearch
      We must allow to install and use Elasticsearch instead of InfluxDB from ansible-openwisp2 and docker-openwisp
      The requests to Elasticsearch shall be optimized as described in [timeseries] Optimize elasticsearch #168.
      Add support for InfluxDB 2.0 as a new timeseries backend, this way we can support both InfluxDB <= 1.8 and InfluxDB >= 2.0.
      All the automated tests for InfluxDB 1.8 must be replicated and must pass
      The usage and setup shall be documented
      We must make sure there's at least one dedicated CI build for Elasticsearch
      We must allow choosing between InfluxDB 1.8 and InfluxDB 2.0 from ansible-openwisp2 and docker-openwisp.
      
      ~~~~~~~~~~
      OpenWISP VPN Deployer Linux Package
      Important
      Languages and technologies used: Linux, Python, Django, WebSockets, OpenVPN, WireGuard, WireGuard over VXLAN, ZeroTier.
      Mentors: Federico Capoano, Gagan Deep, Oliver Kraitschy.
      Project size: 350 hours.
      Difficulty level: medium/hard.
      This GSoC project aims to simplify the deployment and management of VPN servers integrated with OpenWISP.
      The goal is to develop an easy-to-install program that automates the deployment of VPN servers synchronized with OpenWISP in real time. This reduces manual intervention and ensures configuration consistency between the VPN server objects in the OpenWISP database and the deployed VPN instances.
      Key Features
      The program will run on Linux-based servers and will:
      Be implemented in Python to ensure maintainability and extensibility.
      Use a Makefile to generate installation packages for major Linux distributions:
      DEB (for Debian, Ubuntu, and related distributions)
      RPM (for Red Hat, Fedora, and similar systems)
      Snap (for broader Linux compatibility)
      Establish a WebSocket connection with OpenWISP to listen for changes in VPN server configurations and synchronize local settings accordingly.
      Keep the local list of peers and the certificate revocation list (CRL) updated whenever VPN clients are added, removed, or modified.
      Support the following VPN tunneling technologies:
      OpenVPN
      WireGuard
      WireGuard over VXLAN
      ZeroTier
      Provide a command-line utility to simplify the initial setup. This utility will:
      Guide users step by step, making it accessible even to those with limited experience.
      Allow users to select the VPN technology to be deployed.
      Verify that the necessary system packages are installed and provide clear warnings if dependencies are missing.
      Assist in securely connecting and synchronizing with OpenWISP.
      Note
      The command-line utility must apply all necessary changes in the OpenWISP database via the REST API. If any required modifications cannot be performed with the current API, the contributor will be responsible for implementing the missing functionality.
      To facilitate authentication, the utility will guide users in retrieving their OpenWISP REST API token. A proposed approach is to provide a link to the OpenWISP admin interface, where users can generate and copy their API token easily.
      Support running multiple instances, where each instance manages a separate VPN server independently.
      Implement structured logging with dedicated log files for each instance, adhering to Linux logging best practices and supporting log rotation.
      Provide comprehensive documentation in ReStructuredText format, following OpenWISP conventions:
      Documentation will be stored in a /docs directory, with a clear separation between user guides and developer documentation.
      A video demonstration will be included, which can be published on YouTube to increase project visibility.
      Update the OpenWISP documentation to cover installation, configuration, and best practices.
      To support this project, OpenWISP Controller will need to be updated to expose a WebSocket endpoint. This will allow the VPN synchronization program to receive real-time configuration updates.
      Prerequisites to work on this project
      Applicants should have a solid understanding of:
      Python and Django.
      WebSockets.
      At least one of the supported VPN technologies (OpenVPN, WireGuard, WireGuard over VXLAN, ZeroTier).
      System administration and Linux packaging (preferred but not required).
      Expected Outcomes
      A Python-based VPN synchronization tool.
      A command-line setup utility for easy first-time configuration.
      WebSocket-based synchronization between VPN servers and OpenWISP.
      Automated packaging for major Linux distributions.
      Structured logging with proper log rotation.
      Enhancements to OpenWISP Controller to support WebSocket-based synchronization and any required REST API modifications.
      Automated tests to ensure reliability and stability.
      Comprehensive documentation, including setup guides and best practices.
      A short tutorial video demonstrating installation and usage.
      
      
      ~~~~~~~~~~
      Enhancing Uspot Captive Portal for OpenWrt
      Important
      Languages and technologies used: ucode, C, OpenWrt, RADIUS.
      Mentors: Federico Capoano, Sankalp.
      Project size: 350 hours.
      Difficulty rate: hard.
      This GSoC project aims to improve Uspot, a relatively new captive portal for OpenWrt, by implementing critical missing features that are essential for large-scale deployments. Uspot is a promising replacement for CoovaChilli, which is no longer actively developed and only receives occasional maintenance patches. However, Uspot lacks several important capabilities that CoovaChilli provides. This project will focus on adding the most critical missing features to ensure Uspot can be a viable alternative.
      Feature list
      1. Traffic Reporting for RADIUS Accounting Interim-Updates
      Implement RADIUS accounting interim-update support.
      Add an option to swap input and output traffic counters (similar to CoovaChilli's swapoctets option).
      2. No-Challenge Authentication Mode
      Implement a nochallenge mode where passwords are sent in plain-text to RADIUS.
      Justification: OpenWISP uses Django’s modern hashing algorithms, which are significantly stronger than those supported by RADIUS.
      Security: This method is secure as long as communication between the captive portal and RADIUS is encrypted using VPNs or RadSec.
      3. Support for RadSec (RADIUS over TLS)
      Ensure RadSec can be used to encrypt RADIUS packets.
      Provide documentation on how to configure Uspot with RadSec.
      4. Bandwidth Limitation Features
      Static Configuration: Applied to all users globally.
      Dynamic RADIUS-based Configuration: Bandwidth limits based on RADIUS attributes (e.g., WISPr-Bandwidth-Max-Down, WISPr-Bandwidth-Max-Up), allowing differentiated speeds based on user type.
      These features are available bu not documented right now, so let's make sure they're properly documented.
      5. Traffic Consumption Limits
      Implement RADIUS attributes to limit total data consumption per user:
      ChilliSpot-Max-Total-Octets
      WISPr-Bandwidth-Max-Total
      CoovaChilli-Max-Total-Gigawords (important for limits above 4.29 GB, overcoming 32-bit integer limitations).
      6. VLAN Tagging Support
      Allow tagging user traffic with VLANs:
      Global VLAN Configuration: Apply a default VLAN tag to all users.
      RADIUS-based VLAN Assignment: Dynamically assign VLANs based on RADIUS Access-Accept attributes, which allows to tag traffic with different VLANs based on rules defined at the application level.
      Prerequisites to work on this project
      Applicants must demonstrate a solid understanding of:
      ucode proficiency.
      C programming (for modifying Uspot’s core functionality).
      Networking protocols, including RADIUS and VLANs.
      OpenWrt development (building and packaging OpenWrt software).
      Secure authentication mechanisms (RadSec, HTTPS authentication).
      Linux network stack, particularly how OpenWrt handles network interfaces and firewall rules.
      Expected Outcomes
      Implementation of the missing features in Uspot, getting closer to parity with key CoovaChilli functionalities.
      Comprehensive testing and validation of each new feature.
      Ensure all changes are merged upstream into the Uspot repository.
      Update OpenWrt packages for the most recent two OpenWrt versions to include these enhancements.
      Provide documentation on how to configure all the features mentioned in the project description.
      Potential adoption of Uspot as a fully functional captive portal replacement for CoovaChilli in OpenWISP deployments by mentioning it in the documentation of OpenWISP.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openwisp/
    idea_list_url: https://openwisp.io/docs/dev/developer/gsoc-ideas-2025.html

  - organization_id: 118
    organization_name: Oppia Foundation
    no_of_ideas: 10
    ideas_content: |
      1.1. Clean up the structure for study guides and worked examples
      Project Description:
      Oppia topics include a list of skills to teach. These skills are grouped into subtopics (like 'Basic Concepts of Division'), each with its own study guide (or 'subtopic page' in the backend). Currently, subtopic pages are implemented as a single large rich-text field, which makes them hard to translate and limits how we can display them. We'd like to split this rich-text field into multiple heading/content parts. In the above example, the updated subtopic page would have two sections ("What is division?" and "Parts of a division equation"), and the subtopic page editor would have a list of sections, each with its own "heading" plain-text field and "content" rich-text field.
      Additionally, both skill explanations and subtopic pages should be able to include worked examples. Previously, worked examples were implemented as an explicit subfield of the SkillContents object that is contained in the Skill model. We would like to implement worked examples as a general rich-text component instead, since this allows them to be used in contexts beyond skills as well.
      The aim of this project is therefore to clean up the incorrect modelling described above and make the necessary updates to the viewing and editing flows for subtopic pages, worked examples, and their associated translations/voiceovers.
      Links to PRD and mocks:
      Subtopic pages (study guides): Figma mocks and design thread
      Worked examples: Figma mocks, design thread, and reference PRD. Note that some parts of the PRD are excluded -- see the "not in scope" section below.
      Tracking issues: #18305, #19851
      Not in scope:
      Implementing new rich-text components other than "Worked Example".
      Implementing the "Words to know!" and "Otter Tip!" sections in the revision card Figma mocks.
      Enabling the use of worked examples in hints and feedback. (We will do this later once we have tried out the functionality in subtopic pages and skill descriptions.)
      Implementing the more detailed validation described in the PRD (for limiting the number of worked examples to 2 if there are no images, or limiting them to 3 if there are images). For now, we will go with a general limit of 2.
      Size: Large (~350 hours)
      Difficulty: Moderate/Hard
      Potential mentors: @kevintab95
      Product/technical clarifiers: @seanlip (product), @kevintab95 (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-1-lace-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Debug and fix CI failures/flakes.
      Write Python code with unit tests.
      Write TS + Angular code with unit tests.
      Write or modify e2e/acceptance tests.
      Write or modify Beam jobs, with tests.
      Related issues:
      RTE-related issues
      Validation (backend + frontend)
      Translation-related issues
      Suggested Milestones:
      Milestone 1: In SubtopicPageContents, carry out migrations to do the following:
      Convert the existing subtitled_html field into the new structure (a sections "repeated JsonProperty" field consisting of {heading: SubtitledUnicode, content: SubtitledHtml} dicts).
      Introduce a unique content ID for each translatable field, similar to explorations.
      Move the written translations and voiceovers for subtopic pages in EntityTranslationsModel and EntityVoiceoversModel, instead of within the SubtopicPage object (similar to explorations).
      Update the subtopic page editor UI to accommodate the new structure, and the learner UI to match the Figma mocks. Then, deprecate the old subtitled_html field.
      Milestone 2: Verify that the existing worked_examples fields are empty in production, then carry out a schema migration to safely deprecate the worked_examples field in the skill_contents part of the SkillModel, and remove it from the skill editor UI as well.
      Implement a new 'Worked Example' RTE component that appears only in the skill explanation and subtopic page RTEs, and validate that skill explanations cannot have more than 2 such components. Add acceptance tests for the learner and creator flows to verify that they align with these mocks. Ensure that this component is translatable in the contributor dashboard, and update the translation guide to include it.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points

      ~~~~~~~~~~
      1.2. Fix the most common server errors
      Project Description:
      We currently see a number of unaddressed server errors on hosted instances of Oppia. Many server errors relate to user-facing bugs, and are a good clue that something is problematic in the application. Furthermore, frequently occurring errors result in the server logs getting noisy, to the point that they are no longer treated as alerts because the volume of errors is too high.
      The aim of this project is to address the 15 most common server errors, and improve/clarify the logging infrastructure to make server errors easier to debug in general. This would also make it easier to catch new issues during test deployments, and reduce the overall error rate of the app. "Addressing a server error" entails the following:
      Find a set of setup steps and actions that reliably reproduce the error on a local machine (see this tutorial). If more insight is needed, it is also fine to add some logging and do another deployment to get more information.
      Identify the root cause of the error.
      Confirm the expected behaviour with the product/tech leads, if needed.
      Fix the error and add tests (which could be frontend, backend, or full-stack) to ensure that the error does not happen again. Some of the other steps listed in this wiki page might also be of interest. Note that some errors may be due to data issues, in which case a migration job or direct editing might be required, as well as stricter typing/validation to ensure that the issue doesn't reoccur.
      Tracking issues:
      #21807, #21841 and #21872 are quality-of-life improvements to help make server errors easier to debug.
      See this link for a list of the most common server errors.
      Note that the project will only cover a subset of the above, per the milestones described below. This will be the subject of a discussion between the contributor, mentor and org admins at the start of CBP.
      Size: Medium (~175 hours)
      Difficulty: Moderate
      Potential mentors: @Nik-09
      Product/technical clarifiers: @kevintab95 (product), @Nik-09 (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-1-lace-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Write Python code with unit tests.
      Write TS + Angular code with unit tests.
      Write or modify e2e/acceptance tests.
      Write or modify Beam jobs, with tests. (This is because you might need to write audit jobs for debugging certain errors.)
      Figure out repro steps based on info from server logs.
      Related issues:
      Consider taking up issues like #21807, #21841 and/or #21872 to make errors easier to reproduce / debug.
      You might also want to try some issues from this list to see whether this project is a good fit. In any issues you attempt, try to demonstrate your ability to (a) reproduce server errors deterministically, (b) write a debugging doc to narrow down the source of an error if you can’t pinpoint it in one go, (c) find the clear root cause of an error, and (d) prevent the error from happening in the future.
      If you like, you can also suggest other improvements to the logging infrastructure that would make it easier to fix "server error" issues. (It is fine to file issues for these improvements and get assigned to them in the usual way. However, you should have tried to tackle at least one server error with a debugging doc, and the improvements you suggest should help address the problems you ran into while trying to figure out what caused the error.)
      Suggested Milestones:
      Milestone 1: Fix the 7 most common server errors, and improve the logging for server errors as needed.
      Milestone 2: Fix the 8 next-most common server errors.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points

      ~~~~~~~~~~
      1.3. Lesson player redesign
      Project Description:
      The aim of this project is to redesign Oppia's existing lesson player according to these mocks. The goals of the redesign are to make the lesson player intuitive to navigate, easy to add features to in the future, and more engaging for younger audiences. The new lesson player should work well on mobile, desktop and tablet devices, as well as in RTL and LTR languages. (Note that some parts of the mocks are out of scope -- see the "Not in scope" section below.)
      The new functionality should be developed behind the /lesson URL (which should, for now, redirect to the same backend handlers as /explore), and be gated behind a feature flag. Once the lesson player is ready to launch, all /explore URLs should be redirected to /lesson instead, and the new lesson player should be used for all lessons.
      Relevant links: Mini-PRD and mocks
      Tracking issues: #19217
      Not in scope:
      Implementing the speed adjuster in the voiceover toolbar
      Implementing the "Get Help" control in the sidebar and the tutorials within it
      Size: Large (~350 hours)
      Difficulty: Hard
      Potential mentors: @amyyeung17
      Product/technical clarifiers: @seanlip (product), @amyyeung17 (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-1-lace-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Debug and fix CI failures/flakes.
      Write Python code with unit tests.
      Write TS + Angular code with unit tests.
      Write or modify e2e/acceptance tests.
      Related issues:
      Any non-backlog issues in the "Lesson Player CUJs" section of the LaCE project board (try to choose ones that relate specifically to the exploration player interface). Also, see the guidance in the last part of the "What we're looking for in proposals" section below.
      Suggested Milestones:
      Milestone 1: Move all non-UI-specific logic in the exploration player page to services, so that they can be used in both the existing and new exploration players. Then, build the following parts of the new exploration player page at the /lesson URL:
      The overall layout (sub-navbar, main player area, sidebar, footer, audio bar). Only the back-and-forth navigation and "Continue" buttons in the footer need to work at this stage; the rest can be implemented in Milestone 2.
      The main "conversation flow" UI (including all interactions).
      The "correct answer" pop-up and confetti.
      By the end of this milestone, it should be possible to play any Oppia exploration via the /lesson/{{exploration_id}} URL (if the feature flag is turned on), submit and view wrong answers, and navigate back-and-forth through the lesson. Also, the exploration editor preview tab, practice questions page and diagnostic test pages (which use components of the lesson player) should show the new UI if the flag is turned on, and the old UI if it is not. Finally, if the flag is turned on, the /explore URL should redirect to the corresponding /lesson page.
      Milestone 2: Transfer the remaining UI components to the new layout, updating or adding new acceptance tests as needed to verify their behaviour:
      Hints, solutions and concept cards
      The voiceover audio player
      The share, feedback, report and "exit lesson" buttons
      The progress-saving and checkpoints flow
      The end-of-lesson next steps (rate lesson, go to new lesson, practice, etc.)
      Flip the launch flag, and, once the new player is serving in production, remove the code for the old lesson player.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points
      Contributor Dashboard team

      ~~~~~~~~~~
      2.1. Show AI-powered translation suggestions to translation submitters
      Project Description:
      This project involves showing auto-generated suggestions in the Contributor Dashboard translation submission modal, so that translation submitters can edit and submit those translations, rather than needing to generate completely new ones from scratch each time. These suggestions would arise from autogenerated translations from an AI-powered translation service.
      The project involves implementing a system for updating EntityTranslationsModel to associate each (content_id, language) pair with both a "manual" and "auto" translation (similar to VoiceoverType in feconf.py for voiceovers). The manual translation should only be populated once a translation is approved by a human reviewer (possibly after edits); this translation is shown to the learner when playing lessons. On the other hand, automatic translations will only be shown as suggestions to translation submitters via the contributor dashboard. To understand the effectiveness of the AI suggestions, the contributor admin dashboard will also display information about how many times the AI suggestions were used as-is, without any edits.
      There should also be a button on the Admin page that can bulk-generate auto-translations via a Beam job. This job should be run to populate the initial auto-translations once the pipeline is ready. Subsequently, any additions/edits to a curated entity (lesson, topic, skill, etc.) should trigger an auto-translation of the added/edited content, and publishing a curated entity should trigger an auto-translation of all strings in the entity. In other words, the auto-translations should always be up-to-date with the English strings in the current version of the entity.
      Link to PRD: Language Management and Lesson Auto-Translation PRD (a bit out of date)
      Tracking issues: #16164 (part), #19681
      Not in scope:
      Configuring the list of prioritized languages for translation
      Auto-generation of voiceovers (in any language)
      Enabling translations for concept cards, review cards, or practice questions
      Showing auto-generated translations in the learner view (see https://github.com/oppia/oppia/issues/16164 for more information).
      Size: Large (~350 hours)
      Difficulty: Hard
      Potential mentors: @chris7716
      Product/technical clarifiers: @seanlip (product), @chris7716 (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-2-contributor-dashboard-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Debug and fix CI failures/flakes.
      Write Python code with unit tests.
      Write TS + Angular code with unit tests.
      Write or modify e2e/acceptance tests.
      Write or modify Beam jobs, with tests.
      Related issues:
      Issues related to translation submitters are good ones to tackle: https://github.com/orgs/oppia/projects/18/views/4?sliceBy%5Bvalue%5D=Translation+submitters
      Suggested Milestones:
      Milestone 1: The computer-aided translation (CAT) backend is completed, and can process any rich-text field properly (including components like images, skill links, etc.), including validating that the autotranslated string has the same number and type of rich-text components as the original string. Storage models are updated to store these autogenerated translations, and the relevant statistics models and regeneration jobs are also updated to include the number of times a translation suggestion exactly matches the auto-translation. The wiki pages are also updated to explain how to add new languages and translation providers to the system.
      At the end of the milestone, admins should be able to configure the CAT service provider for each language, and run a job to generate auto-translations for any untranslated texts for curated lessons. (They can select 'all entities', 'all entities of a specific type', or a specific entity; and they can select 'all prioritized languages' or a particular language.)
      Milestone 2: When a curated entity (lesson, topic, skill, etc.) is edited, this should trigger an auto-translation of the added/edited content. When a curated entity is published, this should trigger a full auto-translation of all strings that don't have auto-translations yet. These auto-generated translations are then shown to contributors in the contributor dashboard UI, together with an annotation explaining their origin.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points
      Developer Workflow Team

      ~~~~~~~~~~
      3.1. Acceptance tests
      Project Description:
      In order to streamline releases, we are planning to ensure that all critical user journeys (CUJs) on the Oppia web application are covered by acceptance tests. This is important because it will provide assurance that, on the merge of every PR, these critical user journeys still function correctly, which means that no major breakages will result if the develop branch gets deployed to production. Additionally, having a complete set of acceptance tests that are organized by CUJ makes it easier to audit whether or not a particular CUJ has been included, and it also helps developers add tests for new CUJs while still keeping the tests well-organized.
      This project includes:
      Writing acceptance tests for the as-yet-uncovered CUJs in a way that keeps the tests organized and maintainable. This might also include small updates to the acceptance test framework, e.g. extracting utility functions to enable code reuse or providing relevant functionality for a group of tests.
      Tightening all page utility functions to have pre/post checks (in the form of "wait" statements) and proper error messaging, so that it is easier to debug flakes. The pre-check wait ensures that the conditions are good for performing the action, and the post-check wait ensures that the action has fully completed.
      Deleting e2e tests whose functionality has been fully replaced by the acceptance tests.
      Relevant documents:
      Current CUJ tracker: Critical User Journeys v2
      Spreadsheet that details most of the tests that need to be written: Web QA Test Matrix (arranged by user type)
      Tracking issues: #21646
      Not in scope:
      Configuring the list of prioritized languages for translation
      Auto-generation of voiceovers (in any language)
      Enabling translations for concept cards, review cards, or practice questions
      Showing auto-generated translations in the learner view (see https://github.com/oppia/oppia/issues/16164 for more information).
      Size: Large (~350 hours)
      Difficulty: Easy / Moderate
      Potential mentors: @imchristie
      Product/technical clarifiers: @seanlip (product), @imchristie (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-3-dev-workflow-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Debug and fix CI failures/flakes.
      Write TS + Angular code with unit tests.
      Write or modify e2e/acceptance tests.
      Related issues:
      Acceptance test infrastructure: https://github.com/orgs/oppia/projects/8/views/11?sliceBy%5Bvalue%5D=Acceptance+Tests
      Suggested Milestones:
      Milestone 1: Tighten all existing page utility functions in core/tests/puppeteer-acceptance-tests to have appropriate pre/post checks. Complete all acceptance tests for exploration creators, logged-out users, and logged-in users (as specified in #21646), and ensure that they run on all PRs by adding them to the "acceptance test" GitHub workflow. Remove any existing webdriverio tests whose functionality is fully covered by the new acceptance tests.
      Milestone 2: Complete all other remaining acceptance tests (as specified in #21646), and ensure that they run on all PRs by adding them to the "acceptance test" GitHub workflow. Remove any existing webdriverio tests whose functionality is fully covered by the new acceptance tests. If any webdriverio tests remain after this step, translate them into CUJs and work with the QA team to make them part of the CUJ document, then implement the corresponding acceptance tests. Finally, remove the old webdriverio and e2e test framework completely.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points

      ~~~~~~~~~~
      3.2. Consolidate entity migration jobs
      Project Description:
      The Oppia codebase includes several different versioned entities which store learning material: explorations, skills, stories, subtopic pages, questions, topics, and collections. The infrastructure to maintain each of these versioned entities has been developed separately, and is a bit patchy (for example, migrations of old snapshots have not been implemented for some of the entities). This is making it difficult to remove some of the old version upgrade functions in the codebase which are no longer needed.
      The aim of this project is to standardize these migration jobs so that there is a single, standard way to migrate and upgrade versioned models. This will (a) ensure that all the versioned models can be easily updated on a periodic basis, (b) let us delete the code for upgrading from old versions once all the entities of that version have been upgraded, and (c) simplify the remaining version upgrade code.
      Tracking issues: #22023
      Size: Medium (~175 hours)
      Difficulty: Moderate
      Potential mentors: @U8NWXD
      Product/technical clarifiers: @seanlip (product), @U8NWXD (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-3-dev-workflow-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Write Python code with unit tests.
      Write or modify Beam jobs, with tests.
      Additionally, strong technical design skills and a good sense of code architecture are helpful.
      Related issues:
      #16556 is a good issue to look into, since it will help you become familiar with the migration job infrastructure.
      Issues related to Beam jobs are also good ones to look at.
      Suggested Milestones:
      Milestone 1: Create a BaseVersionedDomainObject which specifies object member mappings to storage model properties in a declarative way, and also specifies the "schema version field" corresponding to each JsonProperty-related field. Add tests to ensure that all JsonProperties are accounted for. Then, replace all existing domain objects for versioned models with subclasses of BaseVersionedDomainObject. Additionally, ensure that all functions that convert storage models to domain objects also migrate domain objects to the latest schema version.
      Milestone 2: Create BaseMigrateVersionedModelJob and BaseMigrateVersionedModelSnapshotsJob classes with the core logic for upgrading models and snapshots to the latest schema versions, respectively. Use these to build both job and audit job subclasses for all versioned models (explorations, skills, stories, subtopic pages, questions, topics, collections) with proper logging and error reporting (e.g. if a migration fails, the model that could not be migrated should be logged for debugging). Test these jobs on production data to ensure that they work correctly, and fix any issues that arise. Finally, run all the jobs in all our production environments, so that all the models and snapshots on the server are upgraded to the latest schema versions, then remove the old jobs and the old conversion functions for all 7 versioned models, as well as the methods they call (similar to what was done in https://github.com/oppia/oppia/pull/12256/files).
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points

      ~~~~~~~~~~
      3.3. Standardize and validate domain objects and storage models
      Project Description:
      Oppia's production data is organized using NDB storage models, which in simple terms can be thought of as objects having different properties. For instance, data related to a user can be stored in a UserSettingsModel with properties like username, user ID, etc.
      Different inter-model relationships exist as well, corresponding to relationships between prod data. For instance, a story includes a list of explorations. So, a StoryModel might include the IDs of all the ExplorationModels it is composed of.
      For proper functioning of the Oppia application, it is important to ensure that all the models are internally consistent and that the relationships between models are valid. The aim of this project is therefore to ensure that all production data is valid by:
      Ensuring that domain objects exist for all prod models, and that they have full validate() functions.
      Implementing Beam jobs that audit production data and flag any errors. These jobs should validate the model properties as well as inter-model relationships. After these jobs are run, any errors should be investigated, and checks should be implemented to ensure that such problems don’t reoccur in the future with new data.
      Tracking issues:
      #21970
      #21905
      #21869
      Not in scope: Migrating existing datastore data to address the validation issues found in the first milestone.
      Size: Large (~350 hours)
      Difficulty: Moderate
      Potential mentors: @ankita240796
      Product/technical clarifiers: @seanlip (product), @ankita240796 (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-3-dev-workflow-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Write Python code with unit tests.
      Write or modify Beam jobs, with tests.
      Related issues:
      https://github.com/oppia/oppia/issues/21970
      https://github.com/oppia/oppia/issues/21905
      https://github.com/oppia/oppia/issues/21869
      The first checkbox item from any of the following:
      https://github.com/oppia/oppia/issues/14968
      https://github.com/oppia/oppia/issues/14967
      https://github.com/oppia/oppia/issues/14969
      https://github.com/oppia/oppia/issues/14971
      https://github.com/oppia/oppia/issues/14972
      Suggested Milestones:
      Milestone 1: Domain objects exist for all storage models, and include validate() methods that fully validate the domain object's internal consistency and correctness. The usage of storage models in the domain layer is restricted to the interfaces for getting and saving datastore models, and they are not passed further around the codebase. 50% of the validation jobs for the storage models are implemented and run successfully. For each validation error found, an issue is filed with clear action steps for (a) stopping the error from happening for new data, and (b) migrating old data to fix the error.
      Milestone 2: All remaining validation jobs for the storage models are implemented and run successfully, and issues are filed for all validation errors as described in Milestone 1. All root causes of the validation issues found in Milestones 1 and 2 are identified and fixed, so that the error no longer happens for new data. (This corresponds to part (a) of each issue in Milestone 1.)
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points

      ~~~~~~~~~~
      Android team
      4.1. Flashbacks
      Project Description:
      When learners make a mistake on a concept they have previously demonstrated in an earlier part of a lesson, it often makes sense to redirect them back to an earlier card to try and reinforce earlier concepts that the learner may have not fully understood. However, in the current app implementation, learners subsequently need to re-answer all the cards between the earlier state and the state they had reached, which is frustrating.
      This project aims to provide a new feature called 'flashbacks' which helps to bring the benefits of earlier redirection (i.e. reviewing an earlier concept that directly ties to the learner's likely misconception) without the frustrating experience of having to redo the all the questions up to returning back to the question that originally caused the learner to become stuck.
      Additionally, this project also includes improving the general look-and-feel of submitted answers for both multiple choice and item selection interactions as these both currently rely on HTML generation rather than having a cleaner, natively rendered experience. This change will also allow them to be displayed properly in the 'flashback' experience.
      Relevant links: Tracking issue with mocks links (https://github.com/oppia/design-team/issues/179) and PRD (incomplete). Please note the following regarding these mocks:
      The mocks don't include explicit changes for multiple choice and item selection.
      The mocks don't quite represent the correct 'inline' experience that needs to be introduced for the 'Learn Again' button (which should be part of the answer & response section of the incorrect answer that is prompting for a revisit).
      Only the mocks with the orange toolbars are actually correct and need to be implemented (except for the otter, and the return button should be part of the flow rather than overlaid).
      Tracking issues: #5732
      Size: Medium (~175 hours)
      Difficulty: Moderate
      Potential mentors: @adhiamboperes
      Product/technical clarifiers: @seanlip (product), @BenHenning (technical)
      Discussion forum: https://github.com/oppia/oppia-android/discussions/categories/gsoc-q-a-4-android-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Build the app and install it on a local device or emulator. Then verify that you can (a) build a non-test library target locally, (b) run a unit test locally, and (c) play through the app locally.
      Write new Kotlin code with unit tests.
      Change Android UIs, write tests for them, and manually verify that they work.
      Related issues:
      Key issue: #5572. This tracks introducing a short-term solution of the broader problem this GSoC project aims to solve.
      Issues related to portions of the codebase that will be affected by this project:
      #5728
      #5568
      #3646
      #2973
      #1273
      Suggested Milestones:
      Milestone 1:
      The new flashback dialog is implemented and hooked up to the existing soft redirection button. (The in-line flow does not need to work at this stage.)
      When a learner is redirected, the Flashback Dialog should appear. Upon confirmation, the learner is taken back to the most recent instance of the card without adding a duplicate to the stack. This ensures a smoother learning experience without unnecessary reattempts of intermediate questions.
      Milestone 2:
      Integrate the Flashback Dialog into the learner flow with an in-line view, where the "Learn Again" button is directly attached to the incorrect answer that triggered the flashback.
      Implement the updated designs for multiple choice and item selection interactions submitted answers to ensure a cleaner, natively rendered experience.
      Additionally, add relevant UI tests to verify the new functionality.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points

      ~~~~~~~~~~
      4.2. Platform parameters dashboard
      Project Description:
      Feature flags are a special type of configurable platform parameter which allows the team to stage features behind remotely configurable flags until they're ready to be launched. This allows features to be developed across multiple releases without users seeing part of the feature (or app stability issues when the feature is enabled), ensuring the team releases high-quality features and doesn't hurt the overall quality and performance of the app. Broadly, platform parameters allow the team to configure the overall app (which can be useful both for feature flags, as described above, and safety 'knobs' such as controlling rate limits to remote APIs to help reduce the chance of server outages).
      This project entails introducing a developer-only UI (as part of the developer options section of the app) which displays all platform parameters and feature flags in the app, their current enabled/disabled status (for feature flags) or values (for platform parameters), and their sync status (i.e. whether they're being synced from the server or using a local developer default). It also allows an explicit manual override to force the feature on or off, or to override the platform parameter's value.
      Relevant links:
      Sample mocks for the new UI
      #5725: a reimplementation of the platform parameter and feature flag system
      #5565: introduction of cleaner support for overriding platform parameters and feature flags in tests
      Tracking issues: #5345
      Size: Medium (~175 hours)
      Difficulty: Moderate
      Potential mentors: @Rd4dev
      Product/technical clarifiers: @BenHenning (product + technical)
      Discussion forum: https://github.com/oppia/oppia-android/discussions/categories/gsoc-q-a-4-android-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Build the app and install it on a local device or emulator. Then verify that you can (a) build a non-test library target locally, (b) run a unit test locally, and (c) play through the app locally.
      Write new Kotlin code with unit tests.
      Change Android UIs, write tests for them, and manually verify that they work.
      Related issues:
      Issues related to portions of the codebase that will be affected by this project:
      #46 - Note that this is a good issue to build familiarity with the developer workflow menu workings, and has smaller chunks that can be done in isolation.
      #5600 - Note that this is a specific part of #46 above.
      #5636
      #3506
      Suggested Milestones:
      Milestone 1: Key deliverables:
      Display a list of platform parameters and feature flags from a Developer Options menu, along with their current values and sync statuses.
      Set up initial tests to demonstrate that the UI displays correctly.
      The new UI correctly shows all platform parameters and feature flags, and their correct values and sync statuses.
      Milestone 2: Key deliverables:
      Support for overwriting and resetting both feature flags and platform parameters back to their default values, including force-restarting the app upon navigating away from the menu (so that the changes can take effect).
      Updated UI tests for the new functionality.
      The new screen fully supports overriding various platform parameters and feature flag values.
      Support for force downloading flags from Oppia web (i.e. by calling PlatformParameterController.downloadRemoteParameters() and asking for an app restart).
      Pending overrides and the indicator for downloading state both should 'survive' device rotations (that is, rotating the device should not cause any temporary state in the UI to be lost).
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points

      ~~~~~~~~~~
      4.3. Android lint infrastructure and fixes
      Project Description:
      The Android build ecosystem supports a linting tool which catches a variety of Android-specific problems (beyond those that can be caught by more general-purpose linters like ktlint). Historically a Gradle feature, Android Lint is not yet directly supported in the Bazel world (though there are some alternatives available). This project involves:
      Introducing an Oppia Android script that runs Android lint directly.
      Supporting the same exemption override support (via XML) but using a textproto interface for parity with the allow-listing and deny-listing configurations used in other Oppia Android scripts.
      Pre-populating the exemption list with existing known failures.
      Adding wiki documentation to explain how to use the new script.
      Filing and/or updating issues with findings such that all remaining Android lint issues are properly tracked in the repository.
      Updating CI to run the Android lint script.
      Fixing the following categories of lint issues:
      All categories classified as 'errors' by the tool.
      All of the following 'warning' categories:
      OldTargetApi
      UnusedAttribute
      Typos
      StringFormatCount
      ObsoleteSdkInt
      UnusedResources
      UselessLeaf
      UselessParent
      UnusedIds
      DuplicateStrings
      SelectableText
      LabelFor
      RtlSymmetry
      UnknownNullness
      Tracking issues: #5734
      Size: Large (~350 hours)
      Difficulty: Hard
      Potential mentors: @BenHenning
      Product/technical clarifiers: @BenHenning (product + technical)
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Build the app and install it on a local device or emulator. Then verify that you can (a) build a non-test library target locally, (b) run a unit test locally, and (c) play through the app locally.
      Write new Kotlin code with unit tests.
      Related issues:
      Issues related to portions of the codebase that will be affected by this project:
      Most issues under the 'priority' section of the CLaM team board are likely to help build familiarity with broad parts of the codebase which will help with addressing lint issues.
      Adding tests for scripts will help build familiarity with the scripting work: #4971. The stats script is especially relevant, too, as it is built to wrap utilities normally used via the command line (not unlike Android lint), including AAPT and apkanalyzer.
      #5169 - currently tracked lint categories (note that these aren't all possible categories that can and will be found by the script).
      Suggested Milestones:
      Milestone 1: Key deliverables:
      Introduce a new script that can run Android lint checks with support for a local textproto file that can override specific failures to allow them to pass.
      Check in a populated exemption list with all known exemptions.
      Introduce a new wiki page explaining how to use the script and update the exemption list.
      Introduce CI support for the new script so that it runs for every change to develop and for all PRs.
      Milestone 2: Key deliverables:
      Fix all of the error categories of lint issues, plus the warning categories mentioned in the project description.
      Ensure all exemptions that aren't fixed as part of this project have corresponding tracking issues filed and spec'd with enough context for contributors to work on them.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/oppia-foundation/
    idea_list_url: https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#oppias-project-ideas-list


  - organization_id: 119
    organization_name: Organic Maps
    no_of_ideas: 7
    ideas_content: |
      Bookmarks Backup to Google Drive on Android
      Implement a bookmarks backup feature for Google Drive on Android, similar to the iCloud sync available on iOS and following WhatsApp's approach to Google Drive/iCloud backups. This functionality should enable users to securely store their bookmarks in Google Drive and restore them when needed, such as after reinstalling the app or switching to a new device. The implementation should integrate with the Google Drive API, ensuring secure authentication, proper permission management, and seamless multi-device support.
      Scope of Work:
      Develop a feature to allow both automatic and manual backups of bookmarks to Google Drive.
      Ensure effortless restoration when migrating to a new device or reinstalling the app.
      Integrate Google API to handle secure authentication and data access.
      Provide multi-device support to sync and restore bookmarks across different devices.
      Estimate:
      Medium complexity, 175 hours
      Required Skills:
      Android/Java
      Mentors:
      @rtsisyk
      @strump
      References:
      Google Drive Backup Issue
      
      
      ~~~~~~~~~~
      Bookmarks Backup to NextCloud on Android
      Implement a bookmarks backup feature for Google Drive on Android, similar to the iCloud sync available on iOS and following WhatsApp's approach to Google Drive/iCloud backups. This functionality should allow users to securely store their bookmarks on any NextCloud server and restore them when needed, such as during device migration or after reinstalling the app. The implementation should integrate with the NextCloud API, ensuring secure authentication, proper permission handling, and multi-device support.
      Scope of Work:
      Implement automatic and manual backup of bookmarks to NextCloud.
      Ensure compatibility with any NextCloud server.
      Integrate with the NextCloud API for secure authentication.
      Provide multi-device support to sync and restore bookmarks across different devices.
      Estimate:
      Medium complexity, 175 hours
      Required Skills:
      Android/Java
      Mentors:
      @rtsisyk
      @strump
      References:
      NextCloud Backup Issue
      
      ~~~~~~~~~~
      Opening Hours Parser Revamp
      This project aims to redesign and enhance the "opening hours" parser in Organic Maps, improving accuracy, compatibility, and robustness when interpreting OSM-based business hours. Organic Maps relies on OpenStreetMap (OSM) data to display place information, including operating hours. However, parsing these hours correctly is complex due to varying formats, regional differences, and nuanced rules embedded in OSM data.
      Scope of Work:
      Improve parsing logic to handle different time formats and regional variations.
      Fix known parsing errors and discrepancies.
      Optimize performance and efficiency of the parser.
      Ensure compatibility with the latest OSM opening hours format.
      Implement automated tests to maintain long-term accuracy.
      Estimate:
      Low complexity, 175 hours
      Required Skills:
      C++
      References:
      Opening Hours Issues
      Issue #7974
      
      
      ~~~~~~~~~~
      HUD (Heads-Up Display) Mode
      Add a HUD (Heads-Up Display) Mode in Organic Maps to enhance navigation while driving. This feature should allow users to project a mirrored version of the navigation screen onto a car’s windshield using a reflective surface, improving visibility and reducing distractions.
      Scope of Work:
      HUD Mode Toggle: Add an option in the navigation settings to enable/disable HUD mode.
      Mirrored Display: Implement a mirrored interface to ensure correct readability when reflected on the windshield.
      High-Contrast UI: Optimize the UI for night and day modes to improve legibility.
      Auto-Dimming: Adjust brightness based on ambient light for better visibility at night.
      Compatibility: Ensure smooth performance across various Android and iOS devices.
      Estimate:
      Medium complexity, 175 hours
      Required Skills:
      Android (Kotlin/Java) and iOS (Swift) development
      UX/UI design for automotive displays
      References:
      HUD Mode Issue
      
      ~~~~~~~~~~
      CarPlay Improvements
      Enhance the CarPlay experience in Organic Maps by addressing user-reported issues and implementing improvements based on feedback. The goal is to optimize usability, responsiveness, and overall integration for a smoother in-car navigation experience.
      Scope of Work:
      Review and prioritize user-reported CarPlay issues.
      Fix known bugs affecting CarPlay functionality.
      Improve UI/UX for better readability and interaction.
      Enhance performance and responsiveness.
      Ensure compatibility with the latest CarPlay updates.
      A standalone CarPlay-enabled device will be provided for testing and development purposes.
      Estimate:
      Medium (175 hours) to High (350 hours) - depending on the specific tasks chosen.
      Required Skills:
      iOS development (Swift, Objective-C, CarPlay framework)
      References:
      CarPlay Issues
      
      
      ~~~~~~~~~~
      Photos from Wikidata
      Enable the app to dynamically fetch and display photos from Wikidata (Wikipedia) when users open a specific point on the map. This feature will enhance the user experience by providing real-time images of places, improving navigation and discovery.
      Scope of Work:
      Enhance the map generator to include links to Wikidata.
      Fetch photos dynamically from Wikidata when users select a place.
      Implement caching to optimize performance and reduce API requests.
      Create a consistent and intuitive UI/UX for displaying images.
      Estimate:
      High complexity, 350 hours
      Required Skills:
      Android (Kotlin/Java) and/or iOS (Swift) development
      References:
      Wikidata API Documentation
      Wikidata Photos Issue
      
      ~~~~~~~~~~
      OpenStreetMap Editor Improvements
      Organic Maps allows adding or editing POIs on the map even offline, and uploading all edits directly into OpenStreetMap when the connection is available again. The Editor is designed to be easy-to-use, so that anyone (even your granny) can improve the map data for everyone. Improving and expanding the editing tool is crucial for improving the map data as it allow our users to fill gaps and keeping information up to date.
      There are several issues and features related to the Organic Maps Editor. For an overview over the most important ones, take a look at the Collection of Editor issues as well as the Editor UX issues.
      The scope of the project includes both fixing bugs as well as expanding the functionality. Some possible tasks to work on:
      Enable business change when editing a POI  #3491
      Allow adding and editing of more complex OSM types #4523
      Add category icons to the editor category list #9357
      Make it possible to add OSM note to the specific location #266
      Upload recorded tracks to OpenStreetMap to draw missing roads later, or directly draw roads using the recorded data
      List recently used categories when adding objects to openstreetmap #8033
      Scope of Work:
      TBD
      Estimate:
      TBD
      Required Skills:
      C++
      iOS/Android for the UI-related tasks
      References:
      https://www.openstreetmap.org/
      https://wiki.openstreetmap.org/wiki/Editors
      https://github.com/organicmaps/organicmaps/issues?q=is%3Aissue+is%3Aopen+label%3AEditor+
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/organic-maps/
    idea_list_url: https://github.com/organicmaps/organicmaps/wiki/GSoC-2025-ideas


  - organization_id: 120
    organization_name: PAL Robotics
    no_of_ideas: 6
    ideas_content: |
      Payload visualization/metrics
      This project aims to develop a ROS 2-based software tool that allows users to assess and visualize the useful payload a robot can handle, based on its kinematic and dynamic properties. The tool will process the robot’s URDF (Unified Robot Description Format), taking into account actuation constraints, it will provide intuitive visualizations of available payload in a specific configuration or a workspace representation of payload capabilities. Additionally, it will include functionality to extract joint requirements (torque, power, and stiffness) needed to achieve a desired payload, helping roboticists optimize robot design.
      Expected Impact
      This tool will benefit roboticists, engineers, and researchers working on mobile robots, manipulators, and humanoid platforms. It will provide an intuitive way to evaluate, optimize, and redesign robots based on payload requirements, making it easier to select suitable actuators during the design phase.
      Mentors: Luca Marchionni
      Project Size: 175 hours
      Difficulty: Medium
      Skills Required: C++ or Python, ROS 2 basics, experience with URDF, familiarity with RViz plugin development. Rigid Body Dynamics Libraries such as Pinnochio or RBDL
      Outcome:
      A C++ or Python tool to compute and visualize payload capacity in a specific robot joint configuration or inside the robot’s workspace.
      A joint requirement estimation module that suggests required actuator capabilities for achieving a specified payload.
      Integration with ROS 2, URDF, and RViz
      A custom RViz plugin to dynamically display payload constraints and actuator requirements.
      Documentation and example cases for different robotic platforms (TIAGo Pro, TALOS and other available open source robot models).
      
      
      ~~~~~~~~~~
      ROS 2 Action Mux
      The ROS 2 Action Muxer could be a nice middleware tool designed to manage multiple action servers with predefined priority levels. It provides a client interface to an underlying action server while exposing multiple action servers that dynamically handle goals based on priority. Higher-priority goals preempt lower-priority ones, ensuring efficient resource management in multi-program frameworks.
      In robotic systems and automation frameworks, multiple programs often require access to shared resources. However, not all goals should be treated equally—some, like emergency stop actions, must take precedence over routine operations. A structured priority system is essential to ensure that critical goals are executed without disruption from lower-priority tasks.
      Mentors: Sai Kishor Kothakota
      Project Size: 175 hours
      Difficulty: Medium/Hard
      Skills Required: C++, ROS 2 Basics
      Outcome:
      Develop an action multiplexer that routes requests to a single action server while managing multiple priorities that work for any type of action message types
      Implement a preemption mechanism where high-priority goals interrupt lower-priority ones.
      Provide a user-friendly client API to integrate seamlessly with existing ROS 2 systems.
      Add proper tests for the mechanism of preemption and acceptance of the goals
      Propagate the feedback of the action to the appropriate action server
      
      
      ~~~~~~~~~~
      RFID simulation plugin for Gazebo Harmonic
      This project aims to develop an RFID simulation plugin for Gazebo Harmonic to enable the testing of RFID-based applications in a virtual environment. This plugin will simulate RFID readers and tags, allowing developers to validate systems involving object identification, inventory management, and localization.
      Gazebo Classic had limited support for RFID sensors and tags, but it handled only very basic detection (binary presence/absence). However, this plugin was never ported to Gazebo Harmonic. With Gazebo Classic reaching its end-of-life in January 2025, there’s a need to re-implement RFID simulation capabilities in modern versions of Gazebo.
      The proposed plugin will simulate RFID systems by modeling physical wave transmission (e.g Friis transmission equation) and incorporating noise factors to achieve realistic behavior. This includes accounting for signal attenuation, interference, and environmental conditions that affect RFID performance.
      During the project, the RFID plugin will be validated making use of PAL open-source simulation packages.
      Mentors: Oscar Martinez
      Project Size: 175 hours
      Difficulty: Medium
      Skills Required: C++, ROS 2 basics, Gazebo simulation and plugin development, RFID
      Outcome:
      Implementation of a physically realistic RFID sensor plugin in Gazebo Harmonic, with configurable power (0-30 dBm), antenna gain and noise parameters.
      Integration with ROS 2 by publishing rfid_msgs/Detection (suggested name) messages with timestamped RSSI and tag metadata.
      Validation Scenarios: 3 demo worlds (static tags, mobile robot, cluttered environment).
      Documentation: API reference and tutorials for plugin configuration.
      
      ~~~~~~~~~~
      ROS 2 Control Ecosystem Visualization
      The ROS 2 Control Ecosystem Visualization project aims to develop a tool, either as an RQT plugin or a web-based interface, to provide an intuitive and real-time representation of the state of a ROS 2 Control ecosystem. This tool will enable users to monitor the flow of data, visualize active controllers, and gain insights into system performance.
      Managing and debugging a ROS 2 Control ecosystem can be challenging due to the complexity of controllers, hardware interfaces, and data streams. Understanding how different components interact in real-time is crucial for ensuring optimal performance and troubleshooting system issues effectively. A dedicated visualization tool can bridge this gap by providing a clear and interactive overview of the control stack.
      Mentors: Sai Kishor Kothakota
      Project Size: 350 Hours
      Difficulty: Medium/Hard
      Skills Required: Qt framework, JavaScript, Proficiency in working with ROS 2 action, service, and topic communication
      Outcome:
      Develop an interactive visualization tool that represents the state of the ROS 2 Control ecosystem.
      Display data flow, including active controllers, hardware states, and command execution.
      Provide an intuitive user interface that supports filtering and customizing displayed information.
      Ensure seamless integration with existing ROS 2 systems and facilitate debugging and performance analysis.
      
      
      ~~~~~~~~~~
      ROS2 python-launch-lsp-server
      The ROS 2 launchfile system manages the launch of and configuration of one or many processes and can also start other launchfiles. Python launchfiles use launch descriptions which are made of ordered lists of actions and groups of actions. It may also contain substitutions throughout the description, which are used to add some flexibility and configuration to the descriptions in a structured way.
      That high flexibility of this system comes with the downside of being hard to understand what parameters are being used by one project or what executables are being started before runtime. This is where LSP server can become handy for the development of large ros2 packages. It can help verify the proper use of arguments, use go to references when working with other files, pre-processing ros2 substitutions.
      Mentors: Thomas Ung
      Project Size: 175 hours
      Difficulty: Medium
      Skills Required: Rust, ROS 2 Basics, familiarity with LSP, AST
      Outcome:
      Implement go-to-definition for going through ros2launch file
      Implement code completion for Actions and Substitutions
      Implement find references
      Implement Executable argument suggestions
      Implement syntactic error diagnostic
      Documentation on how to integrate with lsp compatible editors
      
      ~~~~~~~~~~
      PlayMotion2 plugin-based system
      PlayMotion2 is a motion control package designed for robots that use ROS 2. It allows you to load a set of pre-recorded motions and execute them on robots. Currently, the framework is limited to working with JointTrajectory controllers, which are commonly used for controlling robotic joints based on pre-defined trajectories.
      The primary goal of this project is to evolve PlayMotion2 into a modular, plugin-based system. This will allow for the development of specialized plugins tailored to different types of controllers, making the framework more flexible and extensible.
      This project will use ROS 2 Humble Hawksbill.
      Mentors: Noel Jiménez García
      Project Size: 350 hours
      Difficulty: Medium/Hard
      Skills Required: C++, Inheritance, ROS 2, ros2_control, Gazebo simulation and plugin development.
      Outcome:
      Plugin-based system for executing motions with different types of controllers
      Abstract class for plugin definition
      Plugin for JointTrajectoryController
      Plugin for other controller type (TBD)
      Documentation and tutorial for creating a controller plugin for PlayMotion2
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/pal-robotics/
    idea_list_url: https://pal-robotics.com/2025-google-summer-code-proposals/#tips-successful-gsoc
  

  - organization_id: 121
    organization_name: PEcAn Project
    no_of_ideas: 5
    ideas_content: |
      
      1. Global Sensitivity Analysis / Uncertainty Partitioning
      This project would extend PEcAn's existing uncertainty partitioning routines, which are primarily one-at-a-time and focused on model parameters, to also consider ensemble-based uncertainties in other model inputs (meteorology, soils, vegetation, phenology, etc). This project would employ Sobol' methods and some uncommitted code exists that manually prototyped how this would be done in PEcAn. The goal would be to refactor/reimplement this prototype into a reliable, automated system and apply it to some key test cases in both natural and managed ecosystems.
      Expected outcomes:
      A successful project would complete the following tasks:
      Reliable, automated Sobol sensitivity analyss and uncertainty partitioning across multiple model inputs.
      Applications to test case(s) in natural and / or managed ecosystems.
      Prerequisites:
      Required: R (existing workflow and prototype is in R)
      Helpful: familiarity with sensitivity analyses
      Contact person:
      Mike @Dietze
      Duration:
      Flexible to work as either a Medium (175hr) or Large (350 hr)
      Difficulty:
      Medium

      ~~~~~~~~~~
      2. Parallelization of Model Runs on HPC
      This project would extend PEcAn's existing run mechanisms to be able to run on a High Performance Compute cluster (HPC) using Apptainer. For uncertaintity analysis, PEcAn will run the same model 1000s of times with small permutations. This is a perfect use for an HPC run. The goal is to not submit 1000s of jobs, but have a single job with multiple nodes that will run all of the ensembles efficiently. Running can be orchistrated using RabbitMQ, but other methods are also encouraged. The end goal should be for the PEcAn system to be launched, and run the full workflow on the HPC from start to finish leveraging as many nodes as it is given during the submission.
      Expected outcomes:
      A successful project would complete the following tasks:
      Show different ways to launch jobs (rabbitmq, lock files, simple round robin, etc)
      Report of different options and how they can be enabled.
      Prerequisites:
      Required: R (existing workflow and prototype is in R), Docker
      Helpful: Familiarity with HPC and Apptainer
      Contact person:
      Rob @Kooper
      Duration:
      Flexible to work as either a Medium (175hr) or Large (350 hr)
      Difficulty:
      Medium

      ~~~~~~~~~~
      3. Database and Data Improvements
      PEcAn relies on the BETYdb database to store trait and yield data as well as model provenance information. This project aims to separate trait data from provenance tracking, ensure that PEcAn is able to run without the server currently required to run the Postgres database used by BETYdb, and enable flexible data sharing in place of a server-reliant sync mechanism. The goal is to make PEcAn workflows easier to test, deploy, and use while also making data more accessible.
      Potential Directions
      Minimal BETYdb Database: Create a simplified version of BETYdb for demonstrations and Integration tests, which might include:
      Review the provenance information we currently log, identify components that no longer need to be tracked or that should be temporary rather than permanent records, and build tools to clean unneeded records from the database.
      Design and create a freestanding version of the trait data, including choosing the format and distribution method, implementing whatever pipelines are needed to move the data over, and documenting how to use and update the result.
      Review the information we currently log, identify components that no longer need to be tracked or that should be temporary rather than permanent, and build tools to clean unneeded/expired records from the database.
      Non-Database Setup: Enable workflows that do not require PostgreSQL or a web front-end, potentially including:
      Identify PEcAn modules that are still DB-dependent and refactor them to allow freestanding use
      Implement mechanisms for decoupling the DB from the model pipelines in time and space while still tracking provenance. Perhaps this could involve separate prep/execution/post-logging phases, but we encourage your creative suggestions.
      Create tools that maximize interoperability with data from other sources, including from external databases or the user's own observations.
      Identify functionality from the "BETYdb network" sync system that is out of date and replace or remove it as needed.
      Expected outcomes:
      A successful project would complete a subset of the following tasks:
      A lightweight, distributable demo Postgres database.
      A distributable dataset of the existing trait and yield records in a maximally reusable format (i.e. maybe not Postgres)
      A workflow that is independent of the Postgres database.
      Skills Required:
      Familiarity with database concepts required
      Postgres experience helpful (and required if proposing DB cleanup tasks)
      R experience helpful (and required if proposing PEcAn code changes)
      Contact person:
      Chris Black (@infotroph)
      Duration:
      Suitable for a Medium (175hr) or Large (350 hr) project.
      Difficulty:
      Intermediate to hard

      ~~~~~~~~~~
      4. Development of Notebook-based PEcAn Workflows
      The PEcAn workflow is currently run using either a web based user interface, an API, or custom R scripts. The web based user interface is easiest to use, but has limited functionality whereas the custom R scripts and API are more flexible, but require more experience.
      This project will focus on building Quarto notebooks that provide an interface to PEcAn that is both welcoming to new users and flexible enough to be a starting point for more advanced users. It will build on existing Pull Request 1733.
      Expected outcomes:
      Two or more template workflows for running the PEcAn workflow.
      Written vignette and video tutorial introducing their use.
      Prerequisites:
      Familiarity with R.
      Familiarity with R studio and Quarto or Rmarkdown is a plus.
      Contact person: David LeBauer @dlebauer, Nihar Sanda @koolgax99
      Duration: Medium (175hr)
      Difficulty: Medium

      ~~~~~~~~~~
      5. Refactoring Compile-time Flags to Runtime Flags in SIPNET
      Project Overview
      The ecosystem SIPNET is a core component of many PEcAn analyses. SIPNET is compiled with multiple compile-time flags that control whether different features are turned on and off. Thus, as currently configured, each model structure requires a separate compiled binary.
      This project will refactor these flags to be runtime-configurable via command-line arguments or a configuration file, improving usability and testing efficiency.
      Expected Outcomes
      Convert selected SIPNET compile-time flags to runtime options.
      Develop a global configuration object for managing runtime flags.
      Improve testability by enabling different configurations without recompiling.
      Prerequisites
      Required: C, experience with compilers and build systems.
      Helpful: Understanding of simulation models.
      Mentor(s)
      David LeBauer (@dlebauer)
      Mike Longfritz
      Duration
      Medium (175hr) or Large (350hr)
      Difficulty
      Medium to Hard
      Project Ideas
      1. Global Sensitivity Analysis / Uncertainty Partitioning
      2. Parallelization of Model Runs on HPC
      3. Database and Data Improvements
      4. Development of Notebook-based PEcAn Workflows
      5. Refactoring Compile-time Flags to Runtime Flags in SIPNET
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/pecan-project/
    idea_list_url: https://pecanproject.github.io/gsoc_ideas

  - organization_id: 122
    organization_name: Pharo Consortium
    no_of_ideas: 22
    ideas_content: |
      Phizura: Live Music Coding!
      
      Description
      Phizura is a cool music recording project that uses the Coypu package in Pharo to help DJs create and play music live. Coypu is a set of tools designed for programming music on-the-fly, originally made for SymbolicSound Kyma but compatible with any OSC-enabled app and MIDI hardware. It features a user-friendly syntax inspired by TidalCycles, making it easy to interact with music software. By capturing the commands and timing of their performances, Phizura will turn these into easy-to-read code. This means DJs can record their sets and reproduce them later, making it a fun way to document their creativity!


      Expected outcome
      The goal of Phizura is to build a system that lets DJs record and replay their live performances through generated code. Students will get hands-on experience with music programming while creating something exciting and useful. Phizura will help them explore new ways to make and share music!


      Required skills	Basic OOP, Unit tests, Pharo
      Preferred skills	Object oriented programming
      Project size	Medium (175 hours)
      Difficulty	Medium 😉
      Mentors

      Sebastian Jordan

      sebastian.jordan@inria.fr

      Domenico Cipriani

      mspgate@googlemail.com

      ~~~~~~~~~~

      
      Pharo VM running as Docker Scratch image
      Description
      This project aims to enable an efficient deployment mechanism for Pharo applications, where they run in a Docker scratch (layer 0) image without any operating system dependency or overhead. Being able to run pharo in an efficient docker image simplifies deployment particularly in the web space where docker images are becoming a defacto standard. Pharo is quite unique as its possible to run without any file io dependencies in a self contained manner that matches scratch image requirements. The smaller size of a scratch image also means improved resource management and also reduces secuirty risks inherent with operating system overhead that isn't needed for many classes of pharo application, particularly web based ones. The student will need to study the hello world docker scratch example and then figure out how to statically compile the vm, necessary plugins and image so that no dynamic operating system dependencies are needed for execution.


      Expected outcome
      Have a pharo vm+image run in a docker scratch image where there is no operating system dependency or overhead


      Required skills	Docker, VM, CI/CD, C, Pharo
      Preferred skills	Web Applications
      Project size	Medium (175 hours)
      Difficulty	Medium 😉
      Mentors

      Tim Mackinnon

      macta@testit.works


      ~~~~~~~~~~

      Improve coding UX
      Description
      Improve the text editor capabilities for coding. It includes text drag n drop, better parenthesis support, and multiple selection.


      Expected outcome
      Support multi-cursor/selection (see pharo #17788)
      Add text drag n drop support (see pharo #2634)
      Enhance parenthesis support (see pharo #2635).

      Required skills	OOP, Debugging, Code Analysis
      Preferred skills	UI/UX
      Project size	Medium (175 hours)
      Difficulty	Hard 🙃
      Mentors

      Gabriel Darbord

      gabriel.darbord@inria.fr

      Nahuel Palumbo

      nahuel.palumbo@inria.fr


      ~~~~~~~~~~

      Implementation of standard data structures and algorithms
      Description
      Support for data structures such as various kinds of lists and trees are weakly supported in Pharo, while the ones that are implemented are not wel designed which makes maintenance and extensions more difficult. A nice data structures design with a stable and reflective API together with corresponding algorithms implementation are the main task in this project idea.


      Expected outcome
      The main goal is to create a flexible and extensible data structures design and to implement at least some of basic lists such as (double-)linked lists, a heap, a stack, a buffer, and some of basic trees e.g. a binary tree, a binary search tree, a self-balancing tree, an AVL, a red-black, or a B-tree.


      Required skills	OOP, Data structures and algorithms
      Preferred skills	
      Project size	Large (350 hours)
      Difficulty	Medium 😉
      Mentors

      Gordana Rakic

      goca@dmi.uns.ac.rs

      Stephane Ducasse

      stephane.ducasse@inria.fr

      Sebastian Jordan

      sebastian.jordan@inria.fr



      ~~~~~~~~~~

      Optimisations for a Meta-Compiler
      Description
      This project has the objective of improving the optimisation capabilities of the Druid meta-compiler. Druid is a meta-compiler that generates Just-In-Time Compiler code from an Interpreter definition. It performs an abstract meta-interpretation to generate an SSA-based Intermediate Representation (IR); this IR is optimised and used to generate machine code. With Druid, language implementors can define their interpreters and generate a JIT Compiler from them.


      Expected outcome
      Implement some optimisation over Druid's IR, such as Dead Store Elimination, Class Hierarchy Analysis, and Arithmetic Operations Transformation. It is possible also to improve any already implemented optimisations such as Inline, Global Value Numbering, Loop Invariant Code Motion, etc.


      Required skills	OOP
      Preferred skills	Compilers
      Project size	Medium (175 hours)
      Difficulty	Medium 😉
      Mentors

      Nahuel Palumbo

      nahuel.palumbo@inria.fr

      Guillermo Polito

      guillermopolito@gmail.com



      ~~~~~~~~~~

      Optimizing the Pharo Compiler with Bytecode-Level Inlining
      Description
      This project explores inlining Pharo methods at the bytecode level to improve performance. The approach involves gathering runtime information about method calls and recompiling the sender method with inlined callees. By reducing the number of method calls in the VM, this optimization aims to enhance execution speed.


      Expected outcome
      Optimize bytecode generation for Collection methods by:

      Developing a type system to gather type information at runtime.
      Extending the experimental optimizing compiler to use collected types for inlining message sends.
      Tracking inlined methods to ensure automatic recompilation when modified.
      This experiment seeks to refine Pharo’s compilation strategy, leveraging method inlining for better performance while maintaining flexibility in dynamic code updates.


      Required skills	OOP
      Preferred skills	Compilers
      Project size	Large (350 hours)
      Difficulty	Hard 🙃
      Mentors

      Nahuel Palumbo

      nahuel.palumbo@inria.fr

      Pablo Tesone

      tesonep@gmail.com

      ~~~~~~~~~~

      Virtual Devices for PharoThings
      Description
      PharoThings implements communication with a connected physical hardware or with a remote one through TelePharo when the local hardware is not available. This makes PharoThings strongly dependent on physical hardware. Elimination of this dependency might be very useful for learning and testing purposes, while it is possible by simulation of hardware response by random actions of virtual objects playing hardware roles.


      Expected outcome
      Design and implement solution that provides higher availability of remote devices through TelePharo by inclusion of virtual devises when physical ones are not present.


      Required skills	OOP, Pharo, IoT, Communication skills
      Preferred skills	PharoThings, TelePharo
      Project size	Medium (175 hours)
      Difficulty	Medium 😉
      Mentors

      Oleksandr Zaitsev

      oleksandr.zaitsev@cirad.fr

      Gordana Rakic

      goca@dmi.uns.ac.rs

      ~~~~~~~~~~

      Using CFG to analyze tests
      Description
      To produce an initial model that represents the Control-Graph-Flow (CFG) of an Pharo application, including application tests, we need to perform an static analysis on the program. The analysis of the program is done traversing Abstract Syntax Tree (AST) of the methods, and class definitions. Pharo provides a set of existent tools to manipulate and traverse ASTs, and reflective tools to inspect programs in Pharo. Also, there are implementations of required tools to be used or extended (AST interpreters, CFG extraction tools, type inferers (Phineas), etc). This task can be divided in three main points: (1) developing the CFG model, (2) extract the information from the Pharo AST, (3) perform traversal and analyses over it. For extracting the information in the AST and form the CGF, the student should use tools already existent in Pharo (AST interpreters/Type inferer). Finally, it can be possible to perform an analysis on the existing information. For example, it is possible to extract the effective classes and methods that are covered by a given test; or calculate the dependencies between classes and methods. This topic provides an oportunity of working on the meta-level of programs, while the student will learn how to get information from an existing program, and how to reflect about it. These tools and abilities are basic when working with programming languages, refactorings, tools, etc.


      Expected outcome
      Create the CFG model and design and implement solution that traverses the AST and builds the CFG extracts the information from the Pharo AST, performs traversal and analyses over it, orimarily analysis of tests.


      Required skills	OOP, Pharo, Communication skills
      Preferred skills	Testing, Type Inference
      Project size	Medium (175 hours)
      Difficulty	Medium 😉
      Mentors

      Pablo Tesone

      tesonep@gmail.com

      Gordana Rakic

      goca@dmi.uns.ac.rs


      ~~~~~~~~~~

      Meta-Object Protocol for Object-Centric Debugging Tools Implementation
      Description
      In this project, the student will start for a MOP prototype, improve the MOP design, extend it, test it, and apply it to the implementation of object-centric debuggers.


      Expected outcome
      Design and implement a meta-object protocol for building object-centric debugging tools.


      Required skills	OOP, Debugging, Reflection, Communication skills
      Preferred skills	Reflection
      Project size	Medium (175 hours)
      Difficulty	Hard 🙃
      Mentors

      Steven Costiou

      steven.costiou@inria.fr

      Valentin Bourcier

      valentin.bourcier@inria.fr




      ~~~~~~~~~~

      Fault Location DrTest Plugin
      Description
      In this project, the student will implement two or three different fault location algorithms, for this, it will also be necessary to implement a matrix coverage. Then we will integrate the fault location algorithms in the DrTest UI tool, and of course to Pharo itself.


      Expected outcome
      The goal is implement a plugin for DrTest that implements two or three fault location state-of-the-art algorithms.


      Required skills	OOP, Pharo, Communication skills
      Preferred skills	Testing, Dynamic Analysis
      Project size	Medium (175 hours)
      Difficulty	Medium 😉
      Mentors

      Juan Pablo Sandoval

      juampiboy@gmail.com

      Sebastian Jordan

      sebastian.jordan@inria.fr

      ~~~~~~~~~~

      A Seamless interface between LLMs and Pharo
      Description
      This project aims to create an intuitive interface between Pharo and large language models (LLMs). By integrating Pharo with LLMs, developers can leverage AI-powered assistance, automation, and natural language processing (NLP) while maintaining Pharo’s unique live programming environment. Perfect project to get familiar with Pharo and different development techniques while enabling its users to experience LLMs in one of the best live environments!


      Expected outcome
      The goal is to implement native UI interface that will interact with various LLM providers. Users should be able to chat with chosen type of LLM, and create custom actions that will send code to LLMs to make modifications on them.


      Required skills	OOP, Communication skills
      Preferred skills	AI, Pharo
      Project size	Medium (175 hours)
      Difficulty	Medium 😉
      Mentors

      Balša Šarenac

      balsasarenac@uns.ac.rs

      Omar Abedelkader

      omar.abedelkader@inria.fr

      ~~~~~~~~~~

      Enhancing Pharo’s Refactoring Engine for a Smarter Development Experience
      Description
      One of its key strengths is its powerful development environment, which includes an advanced refactoring engine. Originally pioneered in Smalltalk, the refactoring engine plays a crucial role in maintaining code quality, improving design, and enhancing developer productivity. This proposal aims to improve Pharo’s refactoring engine by addressing usability, migrating to modern tools, and extending its capabilities with additional refactorings. By refining the refactoring workflow, this project will ensure a smoother experience for developers while keeping Pharo’s tooling at the forefront of modern software engineering practices. Ideal project to learn a lot about Pharo, ASTs, desgin, refactorings, software engineering in general!


      Expected outcome
      The goals include: streamlining user experience, migration to new tools and architecture, analysis and implementation of existing refactorings and improved testing.


      Required skills	OOP, Pharo, Debugging, Communication skills
      Preferred skills	Testing, Reflection
      Project size	Medium (175 hours)
      Difficulty	Medium 😉
      Mentors

      Balša Šarenac

      balsasarenac@uns.ac.rs

      Juan Pablo Sandoval

      juampiboy@gmail.com

      ~~~~~~~~~~

      Adding Game Tiles and Sprites to Cormas
      Description
      The current version of Cormas allows us to visualize the space and agents in the simulation using colors and geometric shapes (circles, rectangles, etc.). In this project, we want to add support for custom tilesets like the ones that are used in computer games. This would allow us to greatly improve the visual capabilities of Cormas by using custom pixel art. In Pharo, we already have support for sprites, which means that we know how to implement this project technically and can guide GSoC contributor in this. This project will require a lot of creativity because we expect contributor to propos a nice API and to build a collection of game tiles that can be used in Cormas.


      Expected outcome
      Add support for pixel art tilesets to Cormas
      Propose a collection of default tiles and the methods for loading custom ones
      Propose an API for configuring Cormas model to use a given tileset
      Implement some of our existing models with tiles, and demonstrate them through videos and blog posts

      Required skills	Pharo, Object-oriented programming
      Preferred skills	Visualization, Art, Gaming
      Project size	Large (350 hours)
      Difficulty	Medium 😉
      Mentors

      Milton Mamani Torres

      akevalion@gmail.com

      Oleksandr Zaitsev

      oleksandr.zaitsev@cirad.fr


      ~~~~~~~~~~
      
      Sound Effect Library for Agent-Based Simulations
      Description
      In Pharo, there is a library for generating and synthesizing music. We want to use it to add sound effects to Cormas simulations. It will start with simple sound effects, for example, when a cow says Mooo or when walking of a grass makes a sound. Then we will explore to which extent a simulation can be perceived through sound. Can different scenarios (high energy / low energy) sound differntly? Can sounds help us understand simulations better? This is an innovative project that can have an important impact in the field participatory simulations by making our tools more accessible and more intuitive for people with disabilities and for the local stakeholders who do not have a technical background.


      Expected outcome
      Create simple sound effects in Pharo and release them as a library
      Assign those sound effects to actions and events in Cormas simulations
      Build an API for manipulating sounds in Cormas
      Explore the patterns that emerge is a simulation through sound effects

      Required skills	Pharo, Object-oriented programming
      Preferred skills	Cormas, C
      Project size	Large (350 hours)
      Difficulty	Medium 😉
      Mentors

      Domenico Cipriani

      mspgate@googlemail.com

      Oleksandr Zaitsev

      oleksandr.zaitsev@cirad.fr
      ~~~~~~~~~~

      Analysing Cormas Code with Moose
      Description
      Moose is a platform for software and data analysis implemented in Pharo. It provides an extensive toolkit for exploring the source code of a given project, find code defects, bad practices, etc. Cormas is a legacy software system that has been in development for more than 25 years. It has been migrated from one dialect of Smalltalk to another, it has been maintained by different people with different levels of expertise and different programming practices. As such, Cormas is a very interesting case study for code analysis. Using Moose, we can detect dead code (methods that are no longer used), split god classes and methods (the ones that are clearly too large), reorganize packages to reduce coupling, improve test coverage. All this information can be extremely valuable for Cormas development and it can also contribute to the improvement of Moose platform.


      Expected outcome
      Learn to use Moose (we have detailed guides and tutorials)
      Load the source code of Cormas into Moose
      Perform various analyses and build visualizations
      Report the findings to the Cormas community
      Improve the source code of Cormas

      Required skills	Pharo, Object-oriented programming
      Preferred skills	Cormas, Moose
      Project size	Medium (175 hours)
      Difficulty	Easy 😊
      Mentors

      Nicolas Anquetil

      nicolas.anquetil@inria.fr

      Oleksandr Zaitsev

      oleksandr.zaitsev@cirad.fr

      ~~~~~~~~~~

      Computer Vision for Game Piece Detection
      Description
      The goal of this project is to enhance the interactive functionality of Cormas by building a computer vision system for detecting tangible objects such as board game pieces. Such a system would permit people to play a serious game on a physical board and have a camera detect the movement of pieces and automatically update the Cormas model. The game could then be stored, replayed, interacted with, and analysed using Cormas.

      Object detection can be implemented based on the smartphone camera or with a more advanced dedicated tool such as Azure Kinect. Adaptation of Cormas platform for receiving live input from real world is a very important aspect of this project.


      Expected outcome
      Implement and test the API in Cormas for positioning agents on the spatial grid
      Implement a prototype of an object detection system using computer vision
      Connect the implemented object detection system to Cormas
      Implement calibration and board initialization

      Required skills	Machine Learing, Computer Vision
      Preferred skills	Pharo, Python, PyTorch, YOLO, Open CV
      Project size	Large (350 hours)
      Difficulty	Hard 🙃
      Mentors

      Etienne Delay

      etienne.delay@cirad.fr

      Oleksandr Zaitsev

      oleksandr.zaitsev@cirad.fr

      ~~~~~~~~~~

      Adding Hexagonal Cells to Cormas Pharo
      Description
      In VisualWorks version of Cormas, we had a good support for hexagonal cells. In the current version of Cormas that we have in Pharo, we can only use square cells. The goal of this project is therefore to (re-)implement the hexagonal grid. The contribution of this project can also be submitted to Roassal3 visualization library. We would like to take inspiration from this article: Hexagonal Grids from Red Blob Games to implement the hexagonal geometry in Roassal and use it to enhance the spatial model of Cormas.


      Expected outcome
      Implement hexagonal grid layout in Roassal based on the article cited above
      Use hexagonal layout to add hexagonal cells to the spatial model of Cormas
      Experiemnt with the possibility of dynamically switching between square and hexagonal grids in the simulation
      Experiment with other types of grids, for example, triangular

      Required skills	Pharo, Object-Oriented Programming
      Preferred skills	Computer Graphics, Geometry, Roassal
      Project size	Large (350 hours)
      Difficulty	Hard 🙃
      Mentors

      Milton Mamani Torres

      akevalion@gmail.com

      Oleksandr Zaitsev

      oleksandr.zaitsev@cirad.fr

      ~~~~~~~~~~

      A text-to-speech (TTS) tool for Pharo
      Description
      The project, named PAM (Pharo Automated Mouth), is inspired by the JavaScript/Web Audio adaptation of SAM (Software Automated Mouth) for the Commodore 64.

      This tool is designed to enhance Pharo’s accessibility, making the environment more inclusive for users who rely on speech synthesis. Additionally, we aim to achieve significantly improved audio clarity and intelligibility compared to SAM.

      PAM will consist of two core components:

      A reciter that processes input text, converting it into a phonemic and prosodic representation.
      A Digital Signal Processor (DSP) that translates these articulation traits into real-time audio.
      Expected Outcomes

      A DSP written in Phausto, offering a selection of four different voice types.
      A well-documented tool with a modular design, allowing for easy extension to other natural languages.
      This project aims to provide a robust and extensible TTS solution for Pharo, significantly improving speech synthesis quality while fostering accessibility.

      Expected outcome
      The goal of this project is to develop a text-to-speech (TTS) tool for Pharo, leveraging Phausto's formant and subtractive synthesis capabilities as the audio backend. There is a previous work done in Squeak to take as reference.


      Required skills	OOP, Autodidact, Communication skills
      Preferred skills	Sound synthesis
      Project size	Large (350 hours)
      Difficulty	Medium 😉
      Mentors

      Domenico Cipriani

      mspgate@googlemail.com

      Nahuel Palumbo

      nahuel.palumbo@inria.fr

      ~~~~~~~~~~

      Improve the Green threads / Fiber
      Description
      Pharo currently implements Green Threads / Fiber through the Process class. However, certain edge cases exhibit undefined behavior. This project aims to thoroughly test these cases, document the current implementation, identify potential bugs, and work towards fixing them to ensure a more robust and reliable concurrency model.


      Expected outcome
      Improve the implementation of Green threads / Fiber in Pharo:

      Find and test border cases
      Find bugs and fix them.

      Required skills	Refactoring, OOP
      Preferred skills	
      Project size	Medium (175 hours)
      Difficulty	Medium 😉
      Mentors

      Guillermo Polito

      guillermopolito@gmail.com

      Pablo Tesone

      tesonep@gmail.com

      ~~~~~~~~~~

      Enhance Register Allocation at Control Flow Merge Points During JIT Compilation
      Description
      The JIT compiler in the Pharo VM uses an Abstract Interpreter to translate Pharo methods into machine code. This interpreter applies optimizations to minimize stack access during register allocation.

      Currently, the implementation maintains a single abstract state per method, even across branches. As a result, the JIT compiler must handle this constraint explicitly, leading to complex and hard-to-understand code when managing control flow merges.

      This project aims to extend the register allocation mechanism to support multiple abstract states, enabling better handling of control flow merge points and improving both code clarity and performance.


      Expected outcome
      Expand the register allocation strategy to effectively manage multiple abstract states at control flow merge points, simplifying JIT compilation and improving optimization potential.


      Required skills	Refactoring, OOP
      Preferred skills	Compilers
      Project size	Medium (175 hours)
      Difficulty	Medium 😉
      Mentors

      Guillermo Polito

      guillermopolito@gmail.com

      Nahuel Palumbo

      nahuel.palumbo@inria.fr

      ~~~~~~~~~~

      Enhance Slang with Separate Compilation
      Description
      Slang is a framework for writing Virtual Machines in Smalltalk and compiling them to C for performance reasons. It translates selected Smalltalk classes and methods into C code.

      Currently, the generated C code is merged into a few large files, making it difficult to read and manage. This project aims to introduce separate compilation by generating multiple C files—potentially one per class or hierarchy—resulting in smaller, more modular, and more readable code.


      Expected outcome
      Implement separate compilation in Slang to generate multiple C files, improving readability, maintainability, and compilation efficiency.


      Required skills	Refactoring, OOP, C
      Preferred skills	
      Project size	Medium (175 hours)
      Difficulty	Medium 😉
      Mentors

      Guillermo Polito

      guillermopolito@gmail.com

      Nahuel Palumbo

      nahuel.palumbo@inria.fr

      ~~~~~~~~~~

      Eliminate Object Pointers in JIT-Compiled Code for Better GC Performance
      Description
      In the Pharo VM, JIT compilation embeds object pointers directly into compiled machine code. These pointers must be visited during garbage collection to properly manage memory.

      Currently, the Garbage Collector must traverse and disassemble the compiled machine code to locate these pointers, introducing a performance overhead. This project aims to modify both the JIT compiler and the Garbage Collector to use a separate structure—an object-pointer table—to store and access object references efficiently.


      Expected outcome
      Optimize garbage collection by removing object pointers from JIT-generated machine code. This includes:

      Identifying where the JIT compiler embeds object pointers.
      Modifying the JIT compiler to store object references in an object-pointer table instead of inline in the machine code.
      Updating the Garbage Collector to traverse the object-pointer table instead of disassembling machine code.
      This approach reduces GC overhead, improving performance and simplifying memory management in the Pharo VM.


      Required skills	Refactoring, OOP
      Preferred skills	Compilers, Garbage Collection
      Project size	Medium (175 hours)
      Difficulty	Hard 🙃
      Mentors

      Guillermo Polito

      guillermopolito@gmail.com

      Nahuel Palumbo

      nahuel.palumbo@inria.fr

      



      
     
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/pharo-consortium/
    idea_list_url: https://gsoc.pharo.org/ideas

  - organization_id: 123
    organization_name: Plone Foundation
    no_of_ideas: 4
    ideas_content: |
      Volto themes
      Skills: React
      The objective of this project is to create new ready-to-use Volto themes.
      Size: 175
      Rating: intermediate
      Possible mentors: Rafael, E.S. Tyrer
      Expected outcome: Volto themes and documentation

      ~~~~~~~~~~
      Workflow manager for Volto
      Skills: React and Python
      Size: 350
      Rating: hard
      Possible mentors: Rafael, E.S. Tyrer
      Expected outcome: a working Plone add-on implementing the feature, with tests and documentation.
      
      ~~~~~~~~~~
      Update pas.plugins.authomatic to the current state of different providers
      Skills: React, Python
      Size: 175
      Rating: intermediate
      Possible mentor: Jens W. Klein
      Expected outcome: a working Plone add-on implementing the feature, with tests and documentation.
      
      ~~~~~~~~~~
      Repeater block
      Skills: React, Python
      The ability to reuse blocks types as the items in a listing to make listings more powerful. e.g. teaser listing, image listing etc.
      In addition the ability to have sources plugins so listings can be other kinds of data not just plone search, for example social media posts, RSS feeds, related/recommended items to this content or links to search pages with different facets preselected.
      Size: 175
      Rating: intermediate
      Possible mentors: Rafael, E.S. Tyrer
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/plone-foundation/
    idea_list_url: https://plone.org/community/gsoc/2025

  - organization_id: 124
    organization_name: PostgreSQL
    no_of_ideas: 11
    ideas_content: |
      Upgrade pgwatch Grafana dashboards to v11
      Project Description
      The project focuses on updating the current pgwatch Grafana dashboards to ensure full compatibility with Grafana version 11. While a portion of the dashboards have already been automatically migrated to the new Grafana v11 model, they still require polishing and manual rework to fully leverage the new features and to address any discrepancies caused by differences between Grafana v10 and v11. Key differences include the removal of AngularJS-based components, modifications in panel JSON structure, and enhanced transformation capabilities. The mentee is welcome to improve the overall dashboarding experience by integrating new features, updating deprecated elements, and enhancing panels as needed.
      Skills needed
      Proficiency in Grafana dashboard configuration and JSON model modifications
      Familiarity with the differences between Grafana v10 and v11
      Experience with Docker and Linux environments
      Basic understanding of web development concepts (HTML, CSS, JavaScript)
      PostgreSQL
      Difficulty level
      Moderate
      Project size
      Medium (~175 hours)
      Mentors
      Pavlo Golub
      Akshat Jaimini
      Rajiv Harlalka
      Expected outcomes
      A refined set of Grafana dashboards for pgwatch that are fully compatible with Grafana v11
      Updated and polished JSON definitions that correctly incorporate new v11 features (such as improved visualizations, transformation options, and updated panel configurations)
      Enhanced dashboards and panels that integrate new features, account for deprecated features, and improve the overall user experience
      Documentation outlining the migration process with guidelines for future dashboard updates
      References
      pgwatch
      Breaking changes in Grafana v11.0
      Removal of AngularJS support in Grafana: what you need to know
      Angular support deprecation
      Custom v10 dashboards by postgres.ai (example of customization)


      ~~~~~~~~~~
      Enhancements to pgwatch v3 RPC integration
      Project Description
      In GSoC 2024, we integrated Remote Procedure Calls within pgwatch v3 to provide a functionality called Remote Sinks. In 2025 we would like to enhance this implementation by adding more features and utilizing the full capabilities of Remote Procedure Calls. In this iteration of GSoC, we want to improve the existing implementation and add more features that can make remote sinks more useful and extensible.
      Skills needed
      Go
      PostgreSQL
      Difficulty level
      Easy
      Project size
      Medium (175 hours)
      Can be modified according to proposed solution
      Mentors
      Akshat Jaimini
      Pavlo Golub
      Andreas Scherbaum
      Expected outcomes
      Provide an authentication protocol for the current RPC implementation
      Additional sink implementations that showcase extensibility of RPC sinks
      Optimized architecture
      Improved developer experience for building custom sinks
      This is not a strict & exhaustive list and we encourage contributors to provide their own creative input as well
      References
      pgwatch v3: [1]
      Remote Sinks implementation for pgwatch: [2]

      ~~~~~~~~~~
      
      ABI Compliance Checker
      Project Description
      Develop and deploy an "ABI Compliance Checker", to be integrated into the PostgreSQL development process similar to coverage.postgresql.org. The checker should run on every commit to the project and produce an ABI compliance report, and trigger an alert when an ABI has changed in an incompatible way. See this thread for an example of such a report, and some details on how it was implemented. Use it as starting point for building the tool.
      Once the tool reliably produces reports, work with the infrastructure team to get it added to the development pipeline and to publicly publish its reports.
      Background
      PostgreSQL recently added Server API and ABI Stability Guidance to help extension authors to understand how and when the server API and ABI are and are not likely to change. In practice, the guidance is that the API and ABI should maintain compatibility between minor releases (e.g., 17.0 to 17.1), but not major releases. This has long been the implicit guidance, but now it is explicit, and due to be included in the PostgreSQL 18 docs.
      Today the committers adhere to this policy purely through the review process, which means once in a while an incompatible change will be included in a minor release. Such changes have been extremely rare, but this past fall an ABI change was unexpectedly shipped in PostgreSQL 17.1. It was quickly reversed in PostgreSQL 17.2, but highlights the need for some process to catch such changes before they're released.
      This project will help reduce the change of such an incident again by automatically checking for ABI changes. This will improve the adherence to the guidance, perhaps allow it to be upgraded to a reliability _policy_, and give extension developers and package maintainers assurance about the reliability of extension builds on PostgreSQL minor releases.
      Skills needed
      C Programming
      Command-line tooling
      HTML & CSS
      Service deployment
      Automation
      Difficulty level
      Medium
      Project size
      Medium (175 hours)
      Mentors
      David Wheeler
      Pavlo Golub
      Expected outcomes
      Working implementation of a subdomain of postgresql.org or as part of the build farm featuring ABI compatibility reports for every commit pushed to a back branch of PostgreSQL
      Notifications of failures sent via email to the committers
      Git repository for the project for ongoing maintenance
      Integration into the PostgreSQL infrastructure build and deploy processes
      References
      abi-dumper, a potential tool
      PostgreSQL Build Farm
      Build Farm Server Code
      pgsql-hackers discussion of an example of a report and the need for a project like this
      Server API and ABI Stability Guidance

      ~~~~~~~~~~
      Performance Farm: BuildBot test result data transformation
      Project Description
      Buildbot is a continuous integration framework being used to proof the next generation of the PostgreSQL Performance Farm project. This project is to extract data from BuildBot's database of test results, the PostgreSQL git repository, and the data saved on the Buildbot Worker to transform it, and load it into a new reporting database so that is it easier to query results.
      The contributor is not expected to be familiar with Buildbot's database schema prior to starting, or the details of the various tests that are being run. An introduction to some of those details will be part of the start of the project.
      The reference section has a link to a script that does the data transformation on the fly, so the goal to do something similar. Define a database scheme and perform the data transformation to load new data.
      Skills needed
      SQL
      POSIX Shell Scripting
      git
      Difficulty level
      Easy
      Project size
      Medium (175 hours)
      Mentors
      Andreas Scherbaum
      Mark Wong
      Expected outcomes
      Schema design of new reporting database
      A set of SQL and shell scripts that can be used in the Performance Farm project
      References
      git
      PostgreSQL
      Example script building a static report for DBT-2 test results doing the data transformation on the fly.
      
      ~~~~~~~~~~
      Performance Farm: Web user interface for navigating results
      Project Description
      Develop a front end in interface in JavaScript for navigating test data.
      The Performance Farm prototype runs various tests against all supported branches of PostgreSQL, but the prototype doesn't really have a good interface.
      Here is an example of a static way data is visualized for the results of a single system. The primary way test results are views are for on specific test (e.g. DBT-2), only on one system at a time (e.g. vanillaleaf), and at one specific scale. Then metrics from multiple git branches (e.g. HEAD, REL_17_STABLE, REL_16_STABLE, etc) may all be viewed at the same time, for any code change (i.e. commit) in the PostgreSQL repository.
      Here is an excerpt of raw data from one specific test for one specific system:
         branch,revision,scale,ctime,metric,complete_at
         REL_13_STABLE,3850fcca69b5db0694ceb5d1134699dc247f201e,100,1708386677,564578.0,1728363218
         REL_13_STABLE,9061fd23c28faebcb29bdfb262975639715975c0,100,1708719713,557362.69,1728362912
         REL_13_STABLE,43cca9de9a0adf3fb47aaa6310cc0022a78eee8a,100,1708895707,570032.0,1728362591
      An ideal interface will let the user:
      select the branches to display
      adjust the date range on the fly
      mouse over any data point to see
      commit hash
      brief commit description
      url link to full commit
      Skills needed
      JavaScript
      Difficulty level
      Medium
      Project size
      Long (350 hours)
      Mentors
      Rajiv Harlalka
      Mark Wong
      Andreas Scherbaum
      Expected outcomes
      Working implementation of a JavaScript interface
      References
      git repository - where code is expected to live, but currently no existing javascript code
      
      
      ~~~~~~~~~~
      pgexporter: Extension support
      Project Description
      pgexporter [1] is a Prometheus [5] exporter for PostgreSQL [4]. This project looks to enhance its functionality with support for PostgreSQL extensions. There needs to be a general framework such that it is easy to add extensions or use different versions. Top extensions like pg_stat_statements should be supported by the distribution.
      Skills needed
      C
      PostgreSQL
      Difficulty level
      Medium
      Project size
      Long (350 hours)
      Mentors
      Saurav Pal <palsaurav (dot) 2020 (at) gmail (dot) com>
      Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>
      Expected outcomes
      Top PostgreSQL extensions working out-of-the-box in pgexporter releases
      References
      [1] https://github.com/pgexporter/pgexporter
      [2] https://github.com/pgexporter/pgexporter_ext
      [3] https://pgexporter.github.io/
      [4] https://www.postgresql.org/
      [5] https://prometheus.io/
      
      
      ~~~~~~~~~~
      pgmoneta: WAL record filtering
      Project Description
      Apply custom filtering rules to WAL records before generating new files.
      Filter based on:
      Transaction type (INSERT, UPDATE, DELETE, etc.).
      Schema or table names to allow selective replication.
      Custom conditions for targeted processing.
      Expand with Cross-Version WAL Streaming where these files can be streamed to other versions of PostgreSQL based backups.
      Skills needed
      C
      PostgreSQL
      Difficulty level
      Hard
      Project size
      Long (350 hours)
      Mentors
      Shahryar Soltanpour <shahryar (dot) soltanpour (at) gmail (dot) com>
      Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>
      Expected outcomes
      Implement filtering mechanism that can generate PostgreSQL WAL files for different versions.
      References
      [1] https://github.com/pgmoneta/pgmoneta
      [2] https://pgmoneta.github.io/
      [3] https://www.postgresql.org/
      
      ~~~~~~~~~~
      pgmoneta: Incremental backup for PostgreSQL 13-16
      Project Description
      Implement functionality in pgmoneta and pgmoneta_ext such that an incremental backup can be taken from PostgreSQL 13 to 16.
      This work can build upon the work done in the incremental backup support for PostgreSQL 17 inside of pgmoneta.
      Skills needed
      C
      PostgreSQL
      Difficulty level
      Hard
      Project size
      Long (350 hours)
      Mentors
      Haoran Zhang <andrewzhr9911 (at) gmail (dot) com>
      Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>
      Expected outcomes
      Incremental backup working inside pgmoneta for PostgreSQL 13 - 16
      References
      [1] https://github.com/pgmoneta/pgmoneta
      [2] https://github.com/pgmoneta/pgmoneta_ext
      [3] https://pgmoneta.github.io/
      [4] https://www.postgresql.org/
      
      
      ~~~~~~~~~~
      pgmoneta: Clustering support
      Project Description
      Implement functionality in pgmoneta and pgmoneta_ext such that pgmoneta can operate in a clustered way meaning f.ex. the result of a backup operation is replicated to another pgmoneta node.
      It should be possible to control which node replicates to which node(s).
      Skills needed
      C
      PostgreSQL
      Difficulty level
      Hard
      Project size
      Long (350 hours)
      Mentors
      Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>
      Haoran Zhang <andrewzhr9911 (at) gmail (dot) com>
      Expected outcomes
      Have backup replicate between pgmoneta nodes
      References
      [1] https://github.com/pgmoneta/pgmoneta
      [2] https://github.com/pgmoneta/pgmoneta_ext
      [3] https://pgmoneta.github.io/
      [4] https://www.postgresql.org/
      \
      
      ~~~~~~~~~~
      pgagroal: Enhance security
      Project Description
      This project looks to enhance the security in pgagroal.
      Areas could include
      Database aliases
      Better support for X.509 certificates
      Improve the vault implementation
      Skills needed
      C
      PostgreSQL
      Difficulty level
      Medium
      Project size
      Long (350 hours)
      Mentors
      Luca Ferrari <fluca1978 (at) gmail (dot) com>
      Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>
      Expected outcomes
      Allow users to configure pgagroal in a more secure way
      References
      [1] https://github.com/agroal/pgagroal
      [2] https://agroal.github.io/pgagroal/
      [3] https://www.postgresql.org/
      
      ~~~~~~~~~~
      WAL-G: Investigating incremental backup bug using WAL summary
      Project Description
      WAL-G has supported incremental backups since 2019 by tracking changed pages in WAL records (WAL-delta backups [3]). However, a critical bug [4] was discovered in 2022, leading to the temporary disabling of this feature. Debugging the issue was challenging due to the lack of a reference implementation for comparison.
      PostgreSQL 17 introduced incremental backup based on WAL summaries, providing a built-in way to track modified pages. This functionality now allows us to compare WAL summary files generated by PostgreSQL 17 and WAL-G to:
      Identify differences in how changed pages are recorded.
      Detect inconsistencies that might explain the WAL-G bug.
      Contribute to fixing WAL-G’s incremental backup mechanism.
      This investigation is essential for improving incremental backup reliability in WAL-G.
      Skills needed
      Go (for working with WAL-G’s implementation)
      C (optional)
      PostgreSQL
      Difficulty level
      Medium
      Project size
      Long (350 hours)
      Mentors
      Marat Bogatyrev
      Dan Zakhlystov
      Akshat Jaimini
      Expected outcomes
      A tool that compares WAL summary files from WAL-G and PostgreSQL 17.
      Identification of discrepancies in changed page tracking between WAL-G and PostgreSQL 17.
      References
      WAL-G: [5]
      PostgreSQL 17 - Incremental Backup Documentation: [6]
      WAL summarizer process in PostgreSQL 17 - commit: [7]
      Category: Google Summer of Code
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/postgresql/
    idea_list_url: https://wiki.postgresql.org/wiki/GSoC_2025

  - organization_id: 125
    organization_name: Processing Foundation
    no_of_ideas: 6
    ideas_content: |
      Friendly Sketch Embedder for p5.js
      Create a user-friendly tool that guides a p5.js user of any level to help showcase their work in their own websites. Anyone can make a sketch with p5.js - as interactive art, as teaching material, as data visualization, as game, as diary, and as anything else they can imagine! A p5.js sketch is a canvas element that can be included in any website, and existing tutorials help to do this. How can embedding a sketch be streamlined, and support all the different kinds of use-cases and customizations? For example, a teacher may want to include code snippets; an artist may want to arrange multiple sketches next to one another.
      Expected outcomes: A possible technical outcome could be a standalone interactive webpage with user-friendly settings that helps visitors to generate sketch embed code depending on their needs. The community impact can be very wide, making it easier for users to take their work beyond a classroom or a tutorial and into their own interactive online space.
      Skills: Some familiarity of JavaScript is needed, but this could be a good project to sharpen your skills!
      Possible mentor: Dora Do
      Size and Rating: 90H, Easy/Medium

      ~~~~~~~~~~
      User-Friendly Features in the p5.js Editor
      The p5.js Editor has thousands of users, and 15% of them use the current autocomplete feature - try it out by turning it on in the settings! How can this feature be improved or expanded to make writing code in the p5.js Editor even friendlier? For a longer/larger project, you can propose a custom context menu for the p5.js Editor: when a user right-clicks, what would be helpful for them to able to see and do? Alternatively, we welcome proposals that focus on improving the accessibility of the autocomplete hinter, such as for screenreader users.
      Expected outcomes: A possible technical outcome could be a pull request or a release in the p5.js-web-editor project that updates the autocomplete widget, or adds a custom context menu widget. The community impact will be among those who use the p5.js Editor, which gets around 200,000 views weekly!
      Skills: Some experience with JavaScript required. Familiarity with digital accessibility (a11y); TypeScript; and/or documentation.js/JSDoc can be a plus.
      Possible mentor: Diya Solanki
      Size and Rating: 90H-175H, Medium

      ~~~~~~~~~~
      Approachable Accessibility for p5.js Editor Contributors
      Accessibility is very important for the p5.js Editor, but contributors sometimes face challenges testing and implementing accessibility feature. This project starts with ARIA-roles to the File Manager, Project List View, or User Account Settings. Based on the challenges encountered by the contributor, they can explore ways to make accessibility testing more approachable for future contributors by creating a proof-of-concept tool in the following areas: seamless integration of manual testing, increasing understanding of UX for screen reader users, or strategies for ARIA internationalization. We have found that automated accessibility testing tools alone are not thorough enough, but accessibility testing (both manual and automated) is needed for every feature addition.
      Expected outcomes: A possible technical outcome could be pull request(s) in the p5.js-web-editor repository that implements editor accessibility improvements. This project idea focuses on improving developer tooling, so the community impact extends to both users of the p5.js Editor, and to its contributors.
      Skills: Some familiarity of JavaScript is needed, but this could be a good project to sharpen your skills!
      Possible Mentor: Tristan Espinoza
      Size and Rating: 90H, Easy/Medium

      ~~~~~~~~~~
      Bring Visual Tests to Processing
      This project aims to implement a visual snapshot testing system for Processing, inspired by the one used in p5.js (read about it in the p5.js documentation or in a recent contributor blogpost). Snapshot tests help catch visual regressions by automatically comparing generated images before and after code changes. The project will focus on building the testing framework, automating comparisons using pixel matching, and integrating the system into GitHub workflows for optional testing on pull requests. This project also involves porting existing p5.js snapshot tests and developing new ones for Processing’s Java environment. This will improve test coverage, help catch regressions, and make it easier for contributors to propose changes with confidence.
      Expected Outcomes: The technical outcome would be an automated snapshot testing system for Processing with pixel comparisons, GitHub integration, baseline snapshots, and documentation. This project idea focuses on improving developer tooling, so the community impact extends to both users of Processing, and to its current and future contributors!
      Possible Mentors: Claudine Chen
      Skills required/preferred: Java, JavaScript, GitHub Actions/Workflows
      Size and Rating: 175H, Medium

      ~~~~~~~~~~
      Code Translation between Processing Sound and p5.sound.js
      Both p5.js and Processing support sound synthesis, playback, and analysis, but only p5.js does it directly in the web browser with p5.sound.js. An automated tool converting Processing Sound to p5.sound.js and vice versa would benefit both communities: Processing Sound users could more easily share work on the web, and p5.sound.js users could more easily adapt their sketches to a wide variety of devices. A code translation tool could also serve as a proof of concept for broader Processing–p5.js translation, which would improve sharing and collaboration across platforms beyond sound.
      Expected Outcomes: A possible technical outcome could be a standalone interactive webpage with user-friendly settings that helps convert Processing Sound sketches into p5.sound.js sketches, and vice versa. This project idea focuses on improving developer tooling, so the community impact extends to both users of Processing Sound and p5.sound.js, and to current and future contributors!
      Possible Mentors: Kevin Stadler
      Skills: experience with both Java and JavaScript essential; optionally: some familiarity with p5.sound.js, Processing Sound, or Web Audio technologies can be a plus
      Size and Rating: 175H, Medium/Hard

      ~~~~~~~~~~
      Friendly p5.js Reference Translation Tasks
      The p5.js website provides the most up-to-date reference for p5.js and p5.sound.js in five languages. The reference is automatically generated from inline documentation in the code, and translations are provided by contributors. How can friendlier developer tools - such as GitHub automations - could help contributors work on translating documentation? The p5.js reference strives to be user-friendly, welcoming, and accurate, so it is important that translation itself is not automated. Making it easier to contribute a translation helps invite more users of p5.js around the world to get involved in contributing to p5.js!
      Expected Outcomes: The technical outcome would be GitHub Action(s) in the p5.js reference website repository. This project idea focuses on improving developer tooling, so the community impact extends to p5.js contributors and users worldwide!
      Skills/tech: JavaScript, Astro, Github Actions/Workflows; optional: JSDoc, documentation.js
      Possible mentor: Stalgia Grigg
      Size and Rating: 175H, Medium/Hard
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/processing-foundation/
    idea_list_url: https://github.com/processing/Processing-Foundation-GSoC/wiki/Project-Ideas-List-(GSoC-2025)


  - organization_id: 126
    organization_name: Project Mesa
    no_of_ideas: 6
    ideas_content: | 
      Front End Upgrade
      Summary
      Mesa recently transitioned to a new Solara-based visualization system that enables interactive, browser-based model exploration. While the core functionality is in place, there are several opportunities to enhance its robustness, performance, and user experience. This project aims to stabilize and extend Mesa's visualization capabilities, making them more powerful and user-friendly.
      Motivation
      The visualization system is one of Mesa's most important features - it allows modelers to see complex emergent behaviors and share their models with others. The recent transition from a Tornado-based system to Solara (PR #2263) brought modern web technologies and improved interactivity, but also revealed areas needing refinement. A well-functioning visualization system is crucial for Mesa's adoption and usability.
      Historical Context
      Mesa's visualization evolved significantly:
      Initially used a Tornado-based server system
      In Mesa 2.x, added experimental Jupyter support using Solara
      Mesa 3.0 fully transitioned to Solara-based visualization
      Recent major improvements include unified plotting backends (PR #2430) and API refinements (PR #2299)
      Overall Goal
      Create a visualization system that is:
      Robust and performant
      Easy to use for basic cases
      Flexible for advanced customization
      Well-documented with clear examples
      Consistent across different spaces (grid, network, continuous)
      Expected GSoC Outcomes
      Core Improvements:
      Add support for rotating markers to visualize agent orientation/heading (#2342)
      Enable configurable visualization update intervals for performance (#2579)
      Create an AgentPortrayalStyle class to replace the current dictionary system (#2436)
      Allow direct model access and control from visualization (#2176)
      Update Mesa Examples to use the new visualization approach
      Visual Enhancements:
      Improve grid drawing aesthetics and styling options (#2438)
      Refactor Altair plotting backend to match Matplotlib's clean architecture (#2435)
      Add support for all space types and property layers
      Enable customizable color schemes and visual themes
      Documentation:
      Extend and improve the visualization tutorial
      Document all visualization components and their customization options
      Provide example implementations for common visualization patterns
      Testing:
      Add automated tests for visualization components
      Create benchmarks for visualization performance
      Set up CI testing for example visualizations (mesa-examples#137)
      Skills Required
      Required:
      Python programming
      Experience with data visualization libraries (Matplotlib, Altair)
      Understanding of software design patterns
      Basic knowledge of frontend development
      Preferred:
      Familiarity with Solara or similar frameworks
      Experience with interactive visualizations
      Understanding of agent-based modeling concepts
      Level: Medium/Hard
      Size 350 hours
      Mentors
      Primary: Tom
      Backup: Jackie, Ewout
      Getting Started
      Review the Visualization Tutorial
      Study examples using the new visualization system
      Examine the visualization code in mesa/visualization/solara_viz.py
      Try implementing a small enhancement in one of the example models

      ~~~~~~~~~~
      Mesa-LLM: Generative Agent-Based Modeling with Large Language Models Empowered Agents
      Summary
      This project aims to integrate large language models (LLMs) as decision-making agents into the Mesa agent-based modeling (ABM) framework. This project will enable more sophisticated, language-driven agent behaviors, allowing researchers to model scenarios involving communication, negotiation, and decision-making influenced by natural language.
      Motivation
      Current implementations of LLM-based agents often require significant manual coding effort and lack a streamlined interface for designing modular agent architectures. By providing an accessible and flexible API, this project will make it easier for researchers and practitioners to develop, test, and iterate on complex LLM-based agents for applications in areas such as collaborative problem-solving, simulation of human-like reasoning, and dynamic decision-making.
      Overall Goal
      To design and implement an extension for Mesa that allows users to create LLM-powered agents using a modular and user-friendly approach, by assembling reusable components like planning, memory, and reasoning modules. The extension will enable agents to interact using natural language, process textual data, and make decisions informed by LLM capabilities. The project will design and implement robust APIs, integration tools, and documentation to enable rapid prototyping of agents (e.g., Chain-of-Thought, ReWOO, Tree-of-Thought, etc) using different paradigms (e.g., sequential, class-based, functional approach, etc), facilitating research and experimentation in agent-based modeling and natural language reasoning.
      Expected Outcomes
      Core Features:
      Develop modular components for defining and configuring LLM-based agents (e.g., interaction modules, memory systems, decision-making units).
      Create built-in templates and presets for common use cases (e.g., ReACT agent).
      These components will seamlessly integrate with existing Mesa functionality, leveraging the established framework for agent behaviors and environment interactions.
      Users will be able to plug these modules into their existing simulations with minimal adjustments.
      Enhancement & Improvements:
      Support for integrating various LLMs and frameworks (e.g., Hugging Face, LLama, OpenAI).
      Tools for visualizing and debugging agent behavior at the module level.
      Documentation:
      Comprehensive user guides for building agents using the modular API.
      Tutorials demonstrating step-by-step construction of popular LLM-based agents.
      Developer documentation for extending and customizing the API.
      Testing & Quality Assurance:
      Unit tests for individual modules and their integration.
      Benchmarking against standard agent-based tasks to ensure performance and usability.
      CI/CD pipeline to maintain high code quality and reliability.
      Scientific Contribution
      This project is expected to produce at least one scientific publication, such as a submission to the Journal of Open Source Software (JOSS) or a relevant venue in computational social science or agent-based modeling (e.g., SIMULATION). Selected candidate will have the opportunity to contribute to the publication process. This will include help drafting, refining the paper, and being listed as one of the authors, depending on the level of contributions.
      Skills Required
      Required:
      Strong Python programming skills.
      Familiarity with agent-based modeling frameworks like Mesa.
      Experience working with large language models and their APIs.
      Preferred:
      Knowledge of advanced LLM techniques.
      Familiarity with modular library design principles.
      Experience in designing intuitive APIs for scientific computing.
      Knowledge areas:
      Agent-based modeling
      Modular system design
      Natural language reasoning and planning with LLMs
      Project Size: 175/350 hours
      Mentors
      Primary: Boyu
      Backup: Tom, Jackie
      Recommended Bibliography
      Cheng, Y., Zhang, C., Zhang, Z., Meng, X., Hong, S., Li, W., ... & He, X. (2024). Exploring large language model based intelligent agents: Definitions, methods, and prospects. arXiv preprint arXiv:2401.03428. https://doi.org/10.48550/arXiv.2401.03428
      Gao, C., Lan, X., Li, N., Yuan, Y., Ding, J., Zhou, Z., ... & Li, Y. (2024). Large language models empowered agent-based modeling and simulation: A survey and perspectives. Humanities and Social Sciences Communications, 11(1), 1-24. https://doi.org/10.1057/s41599-024-03611-3
      Ghaffarzadegan, N., Majumdar, A., Williams, R., & Hosseinichimeh, N. (2024). Generative agent‐based modeling: an introduction and tutorial. System Dynamics Review, 40(1), e1761. https://doi.org/10.1002/sdr.1761
      Guo, T., Chen, X., Wang, Y., Chang, R., Pei, S., Chawla, N. V., ... & Zhang, X. (2024). Large language model based multi-agents: A survey of progress and challenges. arXiv preprint arXiv:2402.01680. https://doi.org/10.48550/arXiv.2402.01680
      Lu, Y., Aleta, A., Du, C., Shi, L., & Moreno, Y. (2024). LLMs and generative agent-based models for complex systems research. Physics of Life Reviews. https://doi.org/10.1016/j.plrev.2024.10.013
      Ma, Q., Xue, X., Zhou, D., Yu, X., Liu, D., Zhang, X., ... & Ma, W. (2024). Computational experiments meet large language model based agents: A survey and perspective. arXiv preprint arXiv:2402.00262. https://doi.org/10.48550/arXiv.2402.00262
      Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., ... & Wen, J. (2024). A survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6), 186345. https://doi.org/10.1007/s11704-024-40231-1
      
      
      ~~~~~~~~~~
      Mesa-frames Upgrade
      Summary
      Mesa-frames has proven to be a powerful extension for Mesa, offering significant performance improvements through vectorized operations on dataframes. This project aims to stabilize Mesa-frames, improve its integration with Mesa's core functionality, and establish it as a production-ready solution for large-scale agent-based modeling.
      Motivation
      Mesa-frames has demonstrated impressive performance gains (up to 200x speedup) by leveraging pandas and polars for vectorized operations. While the initial implementation is promising, there are opportunities to improve stability, expand functionality, and better integrate with Mesa's core features. Making Mesa-frames production-ready would provide the Mesa community with a robust solution for scaling agent-based models to handle thousands or millions of agents efficiently.
      Historical Context
      Mesa-frames was developed in 2024 as a GSoC project to address Mesa's performance limitations with large numbers of agents. Key developments include:
      Initial proof-of-concept showing significant performance gains (Discussion #1939)
      Support for both pandas and polars backends
      Integration with Mesa's AgentSet API
      Basic implementation of core Mesa functionality
      Overall Goal
      Create a stable, well-tested, and fully-featured version of Mesa-frames that seamlessly integrates with Mesa while maintaining its performance advantages. This includes expanding documentation, improving test coverage, and implementing missing Mesa functionality.
      Expected Outcomes
      Core Features:
      Address outstanding issues in the mesa-frames repo
      Implement missing Mesa functionality (e.g., PropertyLayers, NetworkGrid support)
      Create a stable release cadence aligned with Mesa's releases
      Improve continuous integration and testing infrastructure
      Enhancement & Improvements:
      Add support for more of Mesa's spaces (mesa-frames#6)
      Implement GPU support through cuDF (mesa-frames#10)
      Optimize performance for common agent-based modeling patterns
      Support for discrete event scheduling (mesa-frames#9)
      Documentation:
      Expand tutorials with advanced usage examples
      Create migration guides from Mesa to Mesa-frames
      Add performance optimization guidelines
      Document integration patterns with other Mesa extensions
      Testing & Quality Assurance:
      Implement comprehensive test suite covering all features
      Add performance regression tests
      Create benchmarks comparing Mesa and Mesa-frames implementations
      Set up continuous performance monitoring
      Skills Required
      Required:
      Strong Python programming skills
      Experience with pandas and/or polars
      Understanding of vectorized operations
      Familiarity with agent-based modeling concepts
      Preferred:
      Experience with Mesa or similar ABM frameworks
      Knowledge of GPU computing (cuDF)
      Background in performance optimization
      Understanding of continuous integration practices
      Level: Medium/Hard
      Size: 175 / 350 hours
      Mentors
      Primary: Adam
      Backup: Tom, Jackie, Jan
      Getting Started
      Review the Mesa-frames source code and documentation
      Study the introductory tutorial
      Examine open issues in the Mesa-frames repository
      Try implementing a simple model using both Mesa and Mesa-frames to understand the differences
      ~~~~~~~~~~
      Behavioral Framework
      Summary
      Create a comprehensive behavior and state management framework for Mesa that allows agents to have continuously changing states, perform time-consuming tasks, and make decisions based on established behavioral theories. This project aims to provide Mesa users with powerful tools for creating sophisticated agents that can realistically model both discrete and continuous behaviors while following established behavioral theories.
      Motivation
      Mesa currently lacks first-class support for modeling complex agent behaviors that involve continuous state changes, time-consuming actions, and sophisticated decision-making. This makes it difficult to implement realistic agent behaviors like continuous resource depletion, parallel activities, or adaptive decision-making. By providing a unified framework, we can make it easier for modelers to create more sophisticated and realistic agent behaviors.
      Historical Context
      Mesa has evolved from simple discrete-time steps to support more flexible timing through the DiscreteEventScheduler. Recent discussions (#2529, #2526, #2538) and work (PR #2547) have laid the groundwork for more sophisticated agent modeling capabilities. This project would unify and expand these efforts into a cohesive framework.
      Overall Goal
      Create a unified behavioral framework that integrates continuous states, task management, and behavioral decision-making, allowing modelers to create sophisticated agents that can realistically simulate complex real-world behaviors.
      Expected Outcomes
      Core Features:
      State management system for both discrete and continuous states
      Task system for handling time-consuming activities
      Behavioral framework supporting multiple decision-making approaches
      Integration between states, tasks and behaviors
      Enhancement & Improvements:
      Priority and scheduling system for tasks
      Support for interrupting and resuming tasks
      State history tracking and analysis tools
      Event system for state changes and task completion
      Documentation:
      Comprehensive API documentation
      Set of tutorials demonstrating common use cases
      Example models showcasing framework capabilities
      Integration guide with existing Mesa features
      Testing & Quality Assurance:
      Unit tests for all components
      Integration tests for framework interactions
      Performance benchmarks
      Example model tests
      Skills Required
      Required:
      Strong Python programming experience
      Good understanding of OOP and design patterns
      Familiarity with agent-based modeling concepts
      Experience with automated testing
      Preferred:
      Knowledge of behavioral modeling theories
      Experience with discrete event simulation
      Familiarity with state machines
      Background in social science or ecology
      Difficulty: Hard
      Project Size: 350 hours
      Mentors
      Primary: Jackie
      Backup: Ewout
      Getting Started
      Key Documentation:
      Review discussions #2529, #2526, #2538
      Study implementation in PR #2547
      Examine Mesa's time management and event scheduling systems
      Initial Tasks:
      Review and understand the state management PR
      Set up a test environment with Mesa's development version
      Try implementing a simple model using continuous states
      Join discussions on behavioral framework design
      Read up on relevant literature

      ~~~~~~~~~~
      Unifying Geospatial Support in Mesa
      Summary
      Integrate Mesa-geo's geospatial capabilities directly into Mesa as a mesa.geo module, leveraging Mesa's new cell and continuous spaces architecture while preserving GIS functionality. This will simplify dependency management, ensure API consistency, and make spatial modeling more accessible.
      Motivation
      Mesa and Mesa-geo have evolved separately, leading to duplicate implementations and compatibility challenges. As Mesa adopts new space abstractions like the experimental cell space and reimplements continuous space, there's an opportunity to unify spatial modeling in Mesa. This would simplify maintenance, ensure consistent APIs, and make GIS features a first-class citizen in Mesa.
      Historical Context
      Mesa's spatial modeling has evolved significantly. The current grid system is being replaced by the experimental cell space system, which provides more flexibility and better performance.
      Mesa-geo was originally developed as a separate package to add GIS capabilities to Mesa. Recent discussions about moving to a monorepo and the development of Mesa's new conceptual model of Space suggest the time is right for integration.
      Overall Goal
      Create a unified spatial modeling framework in Mesa that handles both regular and geospatial spaces through a consistent API, while maintaining full GIS functionality.
      Expected Outcomes
      Core Features:
      Integrate Mesa-geo's core functionality (GeoSpace, GeoAgent) into Mesa as mesa.geo module
      Adapt Mesa-geo to use Mesa's new cell space system as its foundation
      Integration of GIS coordinate systems and transformations into Mesa's space framework
      Unified property layer system that works across all space types (addressing #2431)
      Migration path for existing Mesa-geo users
      Enhancement & Improvements:
      Refactor RasterLayer to use Mesa's PropertyLayer (mesa-geo#201)
      Extend Mesa's continuous space to handle geographic coordinates
      Support for GIS file formats (GeoJSON, shapefiles) in Mesa's core I/O
      Improved integration with visualization system
      Documentation:
      Updated space concepts documentation
      Migration guide for Mesa-geo users
      New tutorials demonstrating integrated GIS features
      API reference for geospatial functionality
      Testing & Quality Assurance:
      Test suite covering GIS-specific functionality
      Benchmark suite for spatial operations
      Example models demonstrating migration
      CI/CD integration for GIS dependencies
      Skills Required
      Required:
      Python programming
      Understanding of GIS concepts
      Experience with Mesa and/or Mesa-geo
      Familiarity with spatial data libraries (Shapely, GeoPandas)
      Preferred:
      Experience with coordinate reference systems
      Understanding of Mesa's architecture
      Knowledge areas: Medium/Hard difficulty
      Project Size: 350 hours:
      Mentors
      Primary: Jackie
      Backup: Boyu
      Getting Started
      Review Mesa's space conceptual model
      Study the new continuous space implementation
      Examine Mesa-geo's COVID-19 example model
      Join discussions about property layers


      ~~~~~~~~~~
      Mesa Blocks
      Summary
      Build a low code/no code extension so users can rapidly assemble and run custom agent based models
      Motivation
      Agent Based Models have always been challenge by the reality of complex systems - every detail does matter. This does not however, mean that building blocks from models cannot be reused. Have easily reusable building blocks that can be connected together with other core model parts or even opened up and customized can help users more rapidly assemble and customize valid models, while also helping people get better models faster to aid in their decision making.
      Historical Context
      Developing ways to rapidly build models has always been a hard challenge for ABMs and reusable building blocks represents an proven way to help mitigate this challenge. Mesa tried to build the ecosystem first but could not maintain it and there are other efforts to find solutions, notably Reusable Building Blocks for ABMS
      Overall Goal
      To have a prototype of low code/ show code approach that allows users to rapidly build and explore models.
      Expected Outcomes
      Core Features:
      Users can drag and drop blocks to rapidly assemble models
      Easily build new blocks and share with the Mesa community
      Allow users to go into and customize blocks
      Skills Required
      Required:
      Python programming
      Experience with Mesa and/or Mesa-geo
      Preferred:
      Knowledge of No code/low code tools
      Understanding of Mesa's architecture
      Knowledge areas: Hard difficulty
      Project Size: 350 hours:
      Mentors
      Primary: Tom
      Backup: Jackie
      Getting Started
      Some possible starting libraries. The below was created with the help of ChatGPT but there may be some better options.
      Library Strength Integration with Mesa
      NodeGraphQt Full Python drag & drop system Possible best for custom Mesa UI
      NoFlo Flow-based programming Needs custom Python adaptation
      Node-RED Web-based flow editor Requires Node.js but works with Python
      Unreal Blueprints No-code game simulation Best for Wargame AI/Mesa in Unreal
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/project-mesa/
    idea_list_url: https://github.com/projectmesa/mesa/wiki/Google-Summer-of-Code-2025


  - organization_id: 127
    organization_name: Prometheus-Operator
    no_of_ideas: 2
    ideas_content: |
      
      Status for configuration objects
      Description: A frequent pain point for users is to understand whether their configuration resources are applied and if it's not the case, what's the issue. We improved a bit the situation by emitting events when the reconciliation loop rejects configuration resources but it would be even better if the information was persisted in the status subresource (for instance comparing the resource's generation against the observed generation can indicate if the latest version is reconciled or not).
      While workload resources like Prometheus and Alertmanager have gained a Status subresource, there's no such thing (yet) for configuration resources like ServiceMonitor, PodMonitor, AlertmanagerConfig, Probe, ScrapeConfig and PrometheusRule. The main difference between workload and configuration resources is that configuration resources can be selected by multiple workloads: for example, 2 different Prometheus resources can select the same ServiceMonitor resource. As a consequence, we can't use the same API already defined for workload resources. Please note that we don't want to forbid this situation since it is a perfectly valid and supported use case (for instance running 2 stacks in parallel during migrations).
      Recommended Skills: Go, Kubernetes
      Expected project size: large
      Mentors:
      Jayapriya Pai (@slashpai, slashpai9@gmail.com)
      Simon Pasquier (@simonpasquier, pasquier.simon@gmail.com)
      M Vishwanath Sai (@mviswanathsai, mviswanath.sai.met21@itbhu.ac.in)
      Upstream Issue (URL): prometheus-operator/prometheus-operator#3335
      

      ~~~~~~~~~~
      
      Daemonset mode for the Prometheus Agent
      Description: During the last GSoC, Prometheus Operator gained the option to deploy a PrometheusAgent custom resource as a DaemonSet (instead of the default StatefulSet mode). The project was a success and met its objectives but the feature is still behind a feature flag because not all the functionalities have been implemented. The expectations for this year are to identify the remaining gaps, write a plan of action, implement the missing features and write documentation (tutorials for instance).
      Recommended Skills: Go, Kubernetes
      Expected project size: medium
      Mentor(s):
      Jayapriya Pai (@slashpai, slashpai9@gmail.com)
      Simon Pasquier (@simonpasquier, pasquier.simon@gmail.com)
      M Vishwanath Sai (@mviswanathsai, mviswanath.sai.met21@itbhu.ac.in)
      Upstream Issue (URL): prometheus-operator/prometheus-operator#5495
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/prometheus-operator/
    idea_list_url: https://github.com/prometheus-operator/community/blob/main/mentoring/gsoc/2025/project_ideas.md

  - organization_id: 128
    organization_name: 47
    ideas_content: |

      1. Expand Artificial Life Model Library
      Difficulty: Intermediate
      Size: 350 hours (large)
      Description: Expand Tölvera's library of basal behaviors and models (tv.v) by implementing new systems inspired by natural phenomena. Models could include ant colony optimization, predator-prey dynamics, chemotaxis, plant growth, cellular automata variants, and other complex adaptive systems. Each implementation should prioritize real-time performance and composability with existing models.

      Expected Outcomes:

      At least 3 new working basal models with tests
      Documentation for each model explaining scientific background and parameters
      Example programs showing composition with existing models
      Performance benchmarks demonstrating real-time capability
      Required Skills:

      Python programming
      Basic understanding of complex systems/artificial life
      Familiarity with numerical methods
      Interest in biological/physical systems

      ~~~~~~~~~~
      2. Generative AI/LLM Interface
      Difficulty: Intermediate
      Size: 350 hours (large)
      Description: Create a new module (tv.llm) that enables natural language interaction with Tölvera. This includes developing a structured JSON representation of Tölvera programs for LLM manipulation, implementing prompt engineering for program generation/modification, and building an interactive CLI/UI for natural language control.

      Expected Outcomes:

      JSON schema for Tölvera program representation
      Prompt engineering system for program manipulation
      CLI tool for natural language interaction
      Documentation of prompt design patterns
      Example programs showing common interaction patterns
      Test suite for LLM interactions
      Required Skills:

      Python programming
      Experience with LLM APIs and prompt engineering
      Knowledge of JSON schemas and validation
      UI/UX design fundamentals

      ~~~~~~~~~~
      3. Physics Module
      Difficulty: Advanced
      Size: 350 hours (large)
      Description: Design and implement a new physics module (tv.phy) that adds collision detection, fluid dynamics, and soft-body physics capabilities that can be composed with existing Tölvera models. The physics implementations should prioritize real-time performance and artistic exploration over physical accuracy, while maintaining believability.

      Expected Outcomes:

      Modular physics engine supporting particles and basic shapes
      Integration with particle system (tv.p) and species system
      At least 3 example physics behaviors (collisions, fluids, soft-bodies)
      Documentation and tests
      Example programs demonstrating physics composition with other models
      Required Skills:

      Strong Python programming skills
      Computer graphics and physics simulation experience
      GPU programming knowledge (Taichi preferred)
      Math background (linear algebra, numerical methods)

      ~~~~~~~~~~
      4. Scalable Particle System
      Difficulty: Intermediate/Advanced
      Size: 350 hours (large)
      Description: Redesign Tölvera's particle system (tv.p) to handle millions of particles efficiently. This involves implementing spatial partitioning, GPU optimization, and multispecies interaction improvements. The goal is to enable much more complex scenes while maintaining real-time performance.

      Expected Outcomes:

      Redesigned particle system with improved performance
      Thoughtful creative coding APIs for ease of composition with other Tölvera features
      Features for filtering particles based on their properties and behaviours
      Benchmarking test, performance comparison across platforms
      Update examples to demonstrate new system
      Required Skills:

      Strong Python and GPU programming
      Experience with particle systems
      Optimization and profiling skills
      Knowledge of spatial data structures

      ~~~~~~~~~~
      5. High Performance Computer Vision
      Difficulty: Intermediate/Advanced
      Size: 350 hours (large)
      Description: Optimize Tölvera's computer vision module (tv.cv) to achieve reliable real-time performance with multiple tracking features enabled (hands, face, pose). This involves profiling and improving the integration of OpenCV and MediaPipe, implementing frame buffering and GPU acceleration where possible, and developing a robust camera input system.

      Expected Outcomes:

      Redesigned video capture pipeline with improved performance
      GPU-accelerated preprocessing where possible
      Robust camera input system with error handling
      Comprehensive benchmarking suite
      Example programs demonstrating sustained real-time performance
      Cross-platform testing and optimization
      Required Skills:

      Strong Python programming
      Experience with OpenCV and MediaPipe
      Video processing and real-time systems expertise
      GPU programming knowledge
      Performance optimization skills

      ~~~~~~~~~~
      6. Real-time OSC Mapping Engine
      Difficulty: Intermediate
      Size: 175 hours (medium)
      Description: Improve Tölvera's Open Sound Control (tv.osc) implementation by redesigning the mapping engine for better maintainability and extensibility. This includes streamlining the API, improving client integrations, and adding new features for music software interoperability.

      Expected Outcomes:

      Redesigned OSC mapping API
      Improved client generators for Max/MSP, PureData, SuperCollider
      Integration with state (tv.s)
      Integration with iipyper's NDArray Splat operator
      Example programs showing common mapping patterns
      Performance benchmarks for real-time audio rate control
      Required Skills:

      Python programming
      Knowledge of OSC protocol
      Familiarity with music software
      Real-time systems experience

      ~~~~~~~~~~
      7. Packaging and Portable Deployment
      Difficulty Level: Advanced
      Project Length: 350 hours
      Description: Tölvera currently runs as a Python package, but many potential applications would benefit from standalone deployment options. This project aims to create a deployment pipeline that can package Tölvera programs for multiple platforms and use cases, with a focus on maintaining real-time performance and minimal dependencies.

      Expected Outcomes:

      Research and document different packaging approaches including:
      Taichi AOT compilation for GPU-accelerated components
      Python compilation via Nuitka for non-Taichi components
      Implement proof-of-concept deployments for 2-3 target platforms
      Create template projects and documentation for each supported target
      Handle feature subsetting (e.g. disable IML/OSC when not needed)
      Required Skills:

      Python programming
      Familiarity with C/C++ and build systems (CMake)
      Interest in application packaging and deployment
      Basic knowledge of GPU programming concepts

      ~~~~~~~~~~
      8. Creative Coding Sketchbook
      Difficulty: Intermediate
      Size: 350 hours (large)
      Description: Develop Tölvera's proof-of-concept sketchbook into a creative coding environment inspired by Arduino and Processing. This includes creating a robust CLI tool, sketch manager, and improved development workflow. The project aims to make Tölvera more accessible to artists and creative coders while establishing foundations for a potential standalone creative coding platform.

      Expected Outcomes:

      Creative sketchbook system with templates, organisation (categories, tags)
      Consideration of dependency management between sketches
      CLI tool (tolvera) featuring
      Migration of existing Tölvera examples
      Documentation and tests for sketchbook functionality
      Required Skills:

      Python programming
      Experience with CLI development
      Understanding of creative coding workflows
      Interest in developer tooling

      ~~~~~~~~~~
      9. Live Coding Environment
      Difficulty: Intermediate
      Size: 350 hours (large)
      Description: Create a custom live coding environment for Tölvera that improves upon the current Sardine-based proof-of-concept. The project involves developing an asynchronous REPL specifically designed for Tölvera's needs, with special handling for redefining Taichi kernels and state management. This could include creating a VSCode extension to provide syntax highlighting, code completion, and live coding UI features.

      Expected Outcomes:

      Custom async REPL with proper Taichi kernel handling and state persistence
      VSCode extension for syntax highlighting, completion and live evaluation
      Documentation for live coding patterns and extension usage
      Performance benchmarks for REPL vs script
      Required Skills:

      Strong Python and async programming experience
      Knowledge of REPL design and VSCode extension development
      Experience with live coding systems and practices
      Interest in creative coding and developer tooling
      Here's a project idea for developing visual debugging tools for Tölvera:

      ~~~~~~~~~~

      10. Visual Debugging Tools
      Difficulty: Medium
      Size: 350 hours (large)
      Description: Create a comprehensive visual debugging toolkit for Tölvera that helps users understand and debug particle systems from multiple perspectives - from individual particle behavior to system-wide patterns. The project draws inspiration from Seymour Papert's constructionist principles and Bret Victor's "ladder of abstraction" approach to create tools that bridge concrete and abstract understanding of particle systems.

      Expected Outcomes:

      Interactive widget library for visualizing particle properties and behaviors
      Multi-scale visualization tools from particle to system level views
      Real-time parameter exploration and modification interfaces
      Integration with existing debugging workflows and IDEs
      Required Skills:

      Python and visualization programming
      Experience with UI/UX design for developer tools
      Knowledge of debugging tool architecture
      Interest in educational technology principles


      ~~~~~~~~~~





      Support of simple trajectory calculations
      Project description: For flight planning or analysis after the campaign it is useful to perform simple trajectory calculations. The backend will offer the option to calculate trajectories from the waypoints of the flight path to a given time. These will be visualized using as a kml overlay feature or a dedicated plugin. This feature will greatly simplify the planning of self-match flights and allow better association between the visualized maps showing the atmospheric state at certain times with the air actually sampled during the flight. Another application of such trajectories is balloon flight planing i.e. calculation and visualization of a balloon trajectory/flight path from a selected start location to its estimated landing position with a given set of parameters like climbing rate and ceiling altitude. The MSS server usually has already the data necessary for performing the calculations, but a simple trajectory module would need to be implemented/connected. Also, a WMS extension will need to be specified and implemented.

      Duration: 90-350h
      Skills: Python, QT, UI programming, Git, AI-Assistant
      Difficulty level: Hard
      Related Readings/Links:
      https://www.msc-ep.uni-bremen.de/services/lectures/practicals/pr_trajectories_2019.pdf
      https://predict.habhub.org/
      https://mss.readthedocs.io/en/stable/tutorial.html
      Potential mentors: j.ungermann@fz-juelich.de, c.rolf@fz-juelich.de


      ~~~~~~~~~~

      msui: Improve Tutorials
      Project description: Improve the existing tutorial scripts. Merge Text / Audio with movies. Make the tutorials creatable in background without a screen, e.g. xvfb-run on a docker setup Create a bunch short new tutorials. Add new tutorial scripts and potentially integrate the tutorials into the test suite, as a sort of integration test.

      Duration: 90h - 350h

      Skills: Python, Qt, Git, AI-Assistant

      Difficulty level: Medium

      Related Readings/Links:
      https://mss.readthedocs.io/en/stable/tutorials.html
      Potential mentors: rb.proj@gmail.com, m.risse@fz-juelich.de



      ~~~~~~~~~~

      API to use MSS figure objects in other python modules e.g. Jupyter Notebook
      Project description: The MSS tool is currently designed for interactive use and having an mssautoplot cli script for post-campaign analysis, retrieving a standardized set of layers for hundreds of time-steps an automated plotting feature was developed. The next step is to create based on the mssautoplot an API to be used in other python modules.

      This should enable a user to add its own data to our figures used. This is especially interesting for data of the linearview. There a user can overlay on its own measured data. In addition scatter plots shall be enabled. The new API may be used in a Jupyter Notebook. This needs also a different solution to create a mssautoplot.json file by a textual user interface.

      Duration: 175h - 350h

      Skills: Python, Git, Textual, Jupyter Notebook

      Difficulty level: Medium

      Related Readings/Links:
      https://mss.readthedocs.io/en/stable/mssautoplot.html
      https://mss.readthedocs.io/en/stable/tutorial.html
      Potential mentors: rb.proj@gmail.com, j.ungermann@fz-juelich.de, swsrkty@gmail.com




      ~~~~~~~~~~

      mswms: Plot Gallery integrated into server process
      Project description:

      MSS has a gallery feature which currently is a separate process. It currently is called by the standalone server as additional command. We want this to become additional builtin to the server process. Configured by a yaml file and automated update after new datafiles are added. Besides existing parameters new have to become enabled, e.g. mapsection, projection. An extension to a larger project is to add an interactive user interface.

      Duration: 90h - 350h
      Skills: Python, QT, UI programming, Git, AI-Assistant
      Difficulty level: Medium
      Related Readings/Links:
      https://mss.readthedocs.io/en/stable/gallery/index.html
      https://mss.readthedocs.io/en/stable/mswms.html?highlight=gallery#standalone-server-setup
      https://mss.readthedocs.io/en/stable/tutorial.html
      Potential mentors: rb.proj@gmail.com, j.ungermann@fz-juelich.de



      ~~~~~~~~~~

      mswms: Properly implement and support color bars being served separately from the map
      Project description:

      The WMS standard supports delivering color bars as separate image. This is supported in a very basic fashion by the MSUI, but not at all by the MSWMS. In particular in combination with multi-layering, the colorbar must be displayed separately to remain usable (currently all our colorbars are displayed at the same location).

      This task entails

      implementing support for this feature in the MSWMS backend
      properly address “nice” displaying of the colorbar in the frontend for typical use-cases (i.e. less than 3 bars)
      Revamping the existing plotting layers to use this feature.
      Duration: 90-350h
      Skills: Python, QT, UI programming, Git, AI-Assistant
      Difficulty level: Medium
      Related Readings/Links:
      https://github.com/Open-MSS/MSS/issues/1375
      https://www.ogc.org/standards/wms
      https://mss.readthedocs.io/en/stable/tutorial.html
      Potential mentors: rb.proj@gmail.com, j.ungermann@fz-juelich.de



      

      ~~~~~~~~~~

      mscolab: View Layout and Restoring
      Project description:

      The PyQT Gui of the MSS client can currently handle different views by one flight path. This means once a new flight path is loaded and activated all views change to this flight path. Such a View configuration consists of many windows with a complex set of configuration options that are tedious to re-create after shutting down the application. The configuration of individual views can be stored using the autoplot docking widget on a local mssautoplot.json. The mscolab UI should allow for storing and restoring the view configuration of
      multiple windows for the user for an operation. The autoplot dockingwidget may use this configuration too. This includes also to store all qsetting parameters on the server.

      A configuration should been selectable for another flightpath and operation. There should also be a layout option given to any participant of the same flightpath, e.g. two topview connected to different wms servers. A creator of an operation should be able to set the default layout of all participants.

      Duration: 175-350h
      Skills: Python, QT, UI programming, Git, AI-Assistant
      Difficulty level: Medium
      Related Readings/Links:
      Ticket
      QT Cache
      https://mss.readthedocs.io/en/stable/tutorial.html
      Potential mentors: rb.proj@gmail.com, j.ungermann@fz-juelich.de, m.risse@fz-juelich.de

      ~~~~~~~~~~

      replace pyfilesystem2 by pathlib
      Project description: The whole project needs to become refactored for replacing our usage of pyfilesystem2 by pathlib.

      Duration: 175-350h
      Skills: Python, flask, socketIO, pathlib, Git, AI-Assistant
      Difficulty level: Medium
      Related Readings/Links:
      https://github.com/Open-MSS/MSS/issues/2103
      https://github.com/Open-MSS/MSS/issues/2347
      Potential mentors: j.ungermann@fz-juelich.de, rb.proj@gmail.com

      ~~~~~~~~~~

      Improve User Managment
      Project description: Improve the existing MSColab Usermanagment on server and client. We use a role concept for the right managment. On server site the options what a role can do should become configurable.

      Currently any user of the MSColab Server can be added with a role to each operation. We can manage by the manage user interface which operations have which users in which role. We use a category for filtering operations On server site we can interit users and theire roles from a group operation based on a category defined by the client. This is not as comfortable as possible.

      We need an hierarchical structure based on the current category. Instead of using it as attribute it should become a root element for its related operations. The new category root element needs members by roles. These users with their roles are inherited to all operations under this new category grouping element.

      Also creator should become renamed to owner, and there should be more than one user able to get this role, similiar to github/gitlab

      The admin ui interface needs to become adopted and the main UI view could get a tree like structure.

      Duration: 175h - 350h

      Skills: Python, Qt, Git, experience with usermanagment (discord, github, gitlab), AI-Assistant

      Difficulty level: Medium

      Related Readings/Links:
      https://mss.readthedocs.io/en/stable/mscolab.html#user-groups-for-operations
      https://mss.readthedocs.io/en/stable/tutorials/tutorial_mscolab.html
      Potential mentors: rb.proj@gmail.com, j.ungermann@fz-juelich.de


      ~~~~~~~~~~

      use flask-native global configuration
      Project description: Every Flask app has a .config attribute to store configuration. Additionally, for MSColab/MSWMS we have mscolab_settings/mswms_settings. This is redundant, we could just use app.config for everything that should be made globally available in the application in a key-value fashion.

      Duration: 175-350h
      Skills: Python, flask, pytest Git, AI-Assistant
      Difficulty level: Medium
      Related Readings/Links:
      https://github.com/Open-MSS/MSS/issues/2506
      https://github.com/Open-MSS/MSS/issues/2442
      https://flask.palletsprojects.com/en/3.0.x/patterns/appfactories/
      Potential mentors: m.risse@fz-juelich.de, rb.proj@gmail.com





      ~~~~~~~~~~

      Replace multiprocessing usage in test fixtures with subprocess
      Project description: We want to use our tests on all supported platforms. This means we have to remove*/replace the multiprocessing fork method by subprocess. A server process during tests should start in its own python process. This separation enables options for testing with e.g. basic_auth or different wsgi servers.

      Duration: 175-350h
      Skills: Python, (flask), (socketIO), pytest, Git, AI-Assistant
      Difficulty level: Medium
      Related Readings/Links:
      Potential mentors: m.risse@fz-juelich.de, rb.proj@gmail.de


      ~~~~~~~~~~

      Unify file selector
      Difficulty: Medium
      Length: 90 hours
      Skills required: Python, Qt
      Description: Currently we have 2 file selectors for files and folders due to limitations in Qt. This project would use a custom Qt file selector class to unify them.
      Possible mentors: @m3nu

      ~~~~~~~~~~



      Change repository password
      Difficulty: Medium
      Length: 90 hours
      Skills required: Python, Qt
      Description: Currently there is no way to change the Borg repository passphrase. See this issue for more.
      Possible mentors: @m3nu

      ~~~~~~~~~~

      File selector dialog for excluded files and folders
      Difficulty: Small to Medium
      Length: 90 hours
      Skills required: Python, Qt
      Description: This will allow users to use a file selector dialog to add excluded file paths. Instead of pasting or writing match expressions. See also this issue
      Possible mentors: @m3nu

      ~~~~~~~~~~

      Speed up Extract dialog, better logging
      Difficulty: Medium
      Length: 90 hours
      Skills required: Python, Qt
      Description: If there are hundreds of thousands of files, it can take a while for the Extract dialog to parse the list of files from Borg. This project would try to speed it up and also give better logging by removing the secondary logging below the Archive table. See this related issue.
      Possible mentors: @m3nu

      ~~~~~~~~~~

      Error handling and report dialog/wizard
      Difficulty: Medium
      Length: 90 hours
      Skills required: Python, Qt, Unix
      Description: There is already some code to catch errors and display a simple dialog. However it isn't used consistently. This task would add a dialog displaying the errors user friendly and a wizard for reporting an issue on Github. This task would also ensure we catch long Borg errors (maybe via return code).
      Task outline: Get familiar with the kind of errors encountered in vorta and how they are handled. Plan out the use cases and the functionalities of the error dialog and report wizard. Draw a mockup of the new GUI. Implement the GUI as a Qt UI file. Do the coding needed to make the GUI functional. Adjust the existing vorta code to use/work with the new dialog.
      Possible mentors: @real-yfprojects, @m3nu, @Hofer-Julian

      ~~~~~~~~~~

      Expand built-in exclusions
      Difficulty: Easy
      Length: 25 hours
      Skills required: Python, Qt, Regex, Linux
      Description: Last year we added a new exclusion dialog. It allows to ship presets that users can easily exclude in their backups. E.g. to exclude all webdev files. This task would look into how to best add more built-in exclusions while keeping the proecess maintainable.
      Task outline: Research exclusion patterns that would be useful to include Suggest ways to ship them in Vorta, but also keep them updated Implement any changes needed in Exclusion dialog
      Additional details: See discussion #1231
      Possible mentors: @real-yfprojects, @m3nu, @Hofer-Julian

      ~~~~~~~~~~

      Wrap all Borg sub-commands with borgmatic actions
      Difficulty: Easy
      Length: 90 hours
      Skills required: Python, Linux
      Description: borgmatic is effectively a wrapper around Borg backup, providing additional features like a configuration file, database integration, etc. But borgmatic only wraps a fraction of the sub-commands that Borg provides. And for those that it does wrap, it doesn't necessarily support all command-line flags as borgmatic options. Users can always drop back down to running Borg directly for those missing sub-commands (or use the borgmatic borg action), but that doesn't provide all the conveniences of borgmatic and its configuration file.
      Task outline: Implement borgmatic actions for all Borg sub-commands that are not yet implemented. For each Borg flag within those sub-commands, decide whether it makes sense to add a new borgmatic configuration option for it—or whether it would be more appropriate as a borgmatic action command-line flag. Also as part of this work, consider implementing missing flags/options on existing borgmatic actions.
      Additional details: Not all Borg sub-commands make sense to wrap. For instance, Borg invokes borg serve internally, and there's likely not a good use case for running it via borgmatic. Similarly, some Borg flags like --info and --debug shouldn't be exposed directly via borgmatic configuration options or command-line flags, because borgmatic uses them implicitly (e.g. via --verbosity) without exposing them to the end-user. But at the risk of creeping scope, it would be a good idea to look through the ticket backlog when implementing this project, as there may be tickets for adding individual actions that could be implemented as part of this effort. Potential examples: #825, #610, and #345.

      ~~~~~~~~~~
      
      MySQL/MariaDB database directory format support
      Difficulty: Medium
      Length: 80 hours
      Skills required: Python, Linux, MySQL/MariaDB
      Description: Today borgmatic supports dumping MySQL/MariaDB databases directly to Borg for backup purposes and also restoring them directly from Borg. However, borgmatic does not support the MySQL/MariaDB directory format for database dumps currently.
      Task outline: Implement a new directory value (or maybe tab?) for the existing MySQL/MariaDB format configuration options. When that's set, pass the relevant option (--tab=...?) to mysqldump so that database dumps are dumped into a directory instead of as a single file. Note that this will have to bypass the existing streaming to named pipe logic since a directory can't be streamed that way. Also note that there are separate MySQL and MariaDB hooks, which would both need similar updates to support this feature.
      Additional details: Look at the existing PostgreSQL and SQLite hooks for examples of database hooks that support both streaming database dumps and non-streaming directory format database dumps. You can probably take a similar approach with this MySQL/MariaDB work. Also see the ticket.

      ~~~~~~~~~~
      
      Docker/Podman container backups
      Difficulty: Medium
      Length: 120 hours
      Skills required: Python, Linux, Docker/Podman
      Description: borgmatic has a variety of hooks for dumping non-filesystem data sources like databases, but now there's also a need to dump containers or container volumes for backup.
      Task outline: Implement a new borgmatic hook or multiple hooks for dumping and restoring containers or container volumes. Test against both Docker and Podman.
      Additional details: See the ticket for design and implementation ideas, and check out the related linked tickets there for prior discussion on the general topic of borgmatic and container backups.

      ~~~~~~~~~~
      KVM snapshot backups
      Difficulty: Medium
      Length: 100 hours
      Skills required: Python, Linux, KVM/libvirt
      Description: borgmatic has a variety of hooks for dumping data sources like databases and filesystem snapshots. Now there's also a need to snapshot VMs for backup.
      Task outline: Implement a new borgmatic hook for snapshotting KVM VM and including those snapshots in backups.
      Additional details: See the ticket for design and implementation ideas. borgmatic already has three filesystem hooks (ZFS, Btrfs, and LVM) that work by snapshotting and injecting that snapshot directory into the backed up patterns, so a KVM hook could likely take a similar approach. One difference though is that the existing filesystem hooks don't implement anything for the borgmatic restore action, and it may make sense to implement restore for a KVM hook.

      

      ~~~~~~~~~~

      Update Ansible role for new Borgmatic config file format
      Difficulty: Medium
      Length: 90 hours
      Skills required: Ansible, Docker, Linux
      Description: Borgmatic's config file format has rapidly changed and our Ansible role hasn't fully caught up yet. This project would work on adding the new file format as template, adjust testing and add a condition on when to use which version. Also address smaller issues related to recent Borgmatic updates, like database hooks.
      Task outline: Research how verification is done at similar projects. Then make a list of things we like to test. Then see which ones we can test in the context of a Docker test.
      Additional details: See this issue for more.
      Possible mentors: @m3nu

      
      ~~~~~~~~~~
      
      Add more validations to Molecule tests (low priority)
      Difficulty: Medium
      Length: 90 hours
      Skills required: Ansible, Molecule, Docker, Linux
      Description: We already use Molecule to test this role, but only do a few basic validations. This task would add more validations and maybe run a local backup to make sure the role works well.
      Task outline: Research how verification is done at similar projects. Then make a list of things we like to test. Then see which ones we can test in the context of a Docker test.
      Additional details: See this issue for more.
      Possible mentors: @m3nu, @grantbevis (backup mentor)

      ~~~~~~~~~~

      Testing: Outsource test data
      The ilastik-core conda package contains dozens of megabytes of test data that aren't needed for the package to run. We'd like to get rid of them from the package so that it's smaller and quicker to download. The hard part is to find a way to do this that keeps the dev experience afterwards as pain-free as possible...

      Related issues: ilastik/ilastik#2771
      Skills involved: conda packaging ecosystem, GitHub CI/CD, testing/pytest
      Difficulty: Medium
      Duration: Short (90-175h)

      ~~~~~~~~~~
      Handling many files via file-list CSVs
      Image analysis projects typically go through a development or "figuring out a pipeline" phase, and eventually get to the point of passing a large number of images through the finished pipeline. Batch-processing is available at the end of all ilastik workflows, but ilastik's output will usually be a large number of processed images, which the user then wants to take into another tool - which can be quite bothersome. Two goals would be

      
      
      Producing a .csv table of the exported files in a manner that MoBIE understands, which would make quality-control on the exported images easier for many users
      Supporting the same table format in the Input Data step of workflows, so that files exported from one workflow can easily be added to another workflow.
      Related issues: ilastik/ilastik#2822
      Skills involved: Python language, OS/filepath handling
      Difficulty: Easy
      Duration: Short (90-175h)

      ~~~~~~~~~~
      Improve Multicut UX
      "Boundary-based segmentation with multicut" is one of ilastik's most complex workflows. Between the unique labelling required, the potentially inaccessible or unintuitive label colors used, and the ambiguous "Live update"/"Run" functionalities, we often see users struggling to grasp what is going on, or what they should be doing next. There must be ways to rearrange buttons and user interactions for a more intuitive user experience.

      Skills involved: Python language, PyQt
      Difficulty: Easy
      Duration: Variable (90-350h)

      ~~~~~~~~~~
      Support pixel resolution metadata
      In biological images, pixel resolution is an important piece of information, because images might show objects at vastly different scales (nanometers to centimeters). While image files typically include this information as metadata, ilastik currently entirely ignores it.

      The minimum goal for this project would be to read pixel resolution metadata when the user loads a tiff file saved by FIJI, and to re-include the metadata when the user exports in the tiff format, such that FIJI understands it when the tiff exported from ilastik is loaded there. There are many benefits that ilastik could gain from knowing about real-world size of the objects being analyzed, so there is a lot that could be done beyond this minimum.

      Related issues: ilastik/ilastik#2870, ilastik/ilastik#967
      Skills involved: Python language, tifffile, FIJI
      Difficulty: Medium
      Duration: Variable (90-350h)

      ~~~~~~~~~~
      Cross-scale machine learning on large image datasets
      As of version 1.4.1, ilastik supports two multiscale image formats, Precomputed Neuroglancer and OME-Zarr. Currently, users can only choose one of the available image scales and use the dataset at that scale as an input to the existing machine learning workflows.

      We want to take this to the next level and allow users to run machine learning workflows across scales. For example, users could provide pixel labels at a low scale, but choose to train the classifier and run computations at native resolution.

      There are two ways to approach this (alternative project ideas):

      (Harder) Let the user to label images on one scale, but then make it possible to switch the display scale and preview the result at another scale. One problem would need to be addressed before this can even be attempted: Most workflows contain some parts that cannot handle a change in image size within a running workflow.
      (Easier) In the Image Export Options widget, analogous to the existing "Cutout Subregion" (i.e. crop), add an option area to for scaling the export. It should allow the user to enter a scaling factor or alternatively target size (in pixels). The widget could additionally scan if any input images are multiscale, and if so, provide a pre-selection of scaling factors or target sizes that correspond to the input image scales.
      Skills involved: Python language, scikit-image, scikit-learn
      Difficulty: Hard
      Duration: Long (350h)

      ~~~~~~~~~~

      SCode plugin for debugging pocketpy applications
      Difficulty Level: 3/5 (Medium)
      Skill: TypeScript; C
      Project Length: Medium
      Community users have reported that there is no convenient way to debug python applications interpreted by pocketpy. Fortunately, VSCode provides a mechanism of Debugger Extension that allows us to integrate pocketpy debugger into VSCode UI through Debug Adapter Protocol (DAP).

      This project aims to develop a VSCode plugin like Python Debugger, which implements DAP for pocketpy. With this plugin, users can launch their pocketpy applications in VSCode with breakpoints, call stacks, and variable inspection. Students with experience in TypeScript will be helpful for this project.

      ~~~~~~~~~~
      
      #Develop math operators for cTensor library
      Difficulty Level: 4/5 (Hard)
      Skill: C; Further Mathematics
      Project Length: Small or Medium
      pocketpy is providing a tensor library cTensor for users who want to integrate neural networks into their applications. cTensor implements automatic differentiation and dynamic compute graph. It allows users to train and deploy neural networks on client-side devices like mobile phones and microcontrollers (e.g. ESP32-C3). We have a runable prototype located at pocketpy/cTensor. But math operators have not been implemented yet.

      In this project, students will develop forward and backward math operators, as well as basic neural network layers and optimizers (e.g. SGD, Adam). The project is written in C11. We expect students to have a good understanding of further mathematics and C programming.

      ~~~~~~~~~~

      cve-bin-tool: VEX tooling and improvements
      Project description
      In GSoC 2024, we added support for triage using the VEX format, which is a set of standards for storing additional information about how vulnerabilities affect a given product. For example, a product may have backported patches or configuration changes in place that mean the security vulnerability does not apply even if the version of the component being used has a weakness that will show up on scans.

      One of the challenges of VEX is that the rest of the toolchain around it isn't great. It's a JSON-based format which is convenient for machines, but it can be a pain for humans to edit for a variety of reasons, including that only certain values are allowed but typically humans need to use a text editor that gives them no hints about what can and cannot go in a given field.

      We're looking to extend cve-bin-tool to provide some tools for VEX editing and validation, as well as likely extend our support of VEX. Right now, cve-bin-tool does not have a graphical user interface as most of our users need it to work on the command line, nor do we provide an online service. So we will need to work within those limitations at this time.

      Add triage capabilities to our html reports, including the ability to save triage and updated reports. This needs to work offline in the user's browser, so will likely rely heavily on HTML5/Javascript rather than any sort of back end.
      Add command line tools for validation and fixing of invalid VEX files, on the assumption that users will often have slightly incorrect files and need help. We may also want to have tooling to help guide users to remove or archive triage information that is no longer applicable (for example, when a component is updated and the original CVE no longer applies)
      Add command line tools for generation of VEX files. We make blank ones already, but we could probably look at ways to help walk users through which issues are new and should be triaged.
      @anthonyharrison will likely be the mentor on this project, so I'll leave him to fill in more details in the comments below.

      Related reading
      https://cyclonedx.org/capabilities/vex/
      https://www.cisa.gov/sites/default/files/publications/VEX_Use_Cases_Document_508c.pdf
      Skills
      python
      javascript
      software security: knowledge of how software vulnerabilities are triaged, mitigated and solved would be very helpful here.
      You can learn more abou this as you go, but it's worth doing some background reading on how open source projects and corporations handle vulnerabilities if you can because it'll help inform what you propose.
      Difficulty level
      medium/hard.
      Project Length
      350 hours (e.g. full-time for 10 weeks or part-time for longer)
      It would be possible to do part of this project in a 175 hour project, but we may prefer candidates who have the time to do more assuming similar levels of ability
      Mentor
      The primary mentor for this project will likely be @anthonyharrison . Please ask all questions on this issue rather than sending email so you can benefit from the expertise of other contributors and mentors. (and so Anthony doesn't get swamped)
      GSoC Participants Only
      This issue is a potential project idea for GSoC 2025, and is reserved for completion by a selected GSoC contributor. Please do not work on it outside of that program. If you'd like to apply to do it through GSoC, please start by reading #4712.

      

     

      ~~~~~~~~~~

      cve-bin-tool: improved component identification
      Project description
      Thanks to GSoC 2025 we've got PURL support to help improve component identification, and a mismatch database that helps us identify and avoid common mistakes made when we use a basic text search to try to find components and accidentally wind up with a component that has the same name but is written in a different language or something. But there's room for more improvements here!

      Extending the mismatch database to handle certain types of mismatches such as false positive: name collision for python arrow vs rust arrow #3193
      Adding additional data to our mismatch database
      Improve handling PURL data from OSV
      Add a framework for better handling cases where vulnerability data is wrong but will take some time to update. (Especially important as NVD fixes may take months instead of days thanks to their staffing challenges.)
      Stretch goal: looking at other sources of data we can use to refine results.
      Related reading
      Skills
      python
      sqlite
      software security: knowledge of how software vulnerabilities are triaged, mitigated and solved would be very helpful here. (you can learn some of this as you go but it's worth doing some background reading to help inform your design choices)
      Difficulty level
      medium
      Project Length
      350 hours (e.g. full-time for 10 weeks or part-time for longer)
      It would be possible to do part of this project in a 175 hour project, but we may prefer candidates who have the time to do more assuming similar levels of ability
      Mentor
      The primary mentor for this project will depend on what other projects we accept. Please ask all questions on this issue rather than sending email so you can benefit from the expertise of other contributors and mentors. ( Terri's email gets swamped regularly by other work concerns and it's likely she will miss emails send during the GSoC period, but she will answer questions asked in public on this issue or in our gitter chat.)
      GSoC Participants Only
      This issue is a potential project idea for GSoC 2025, and is reserved for completion by a selected GSoC contributor. Please do not work on it outside of that program. If you'd like to apply to do it through GSoC, please start by reading #4712.



      

      ~~~~~~~~~~

      cve-bin-tool: No-scan mode
      Project description
      CVE Binary Tool was designed as a vulnerability scanner, but it can also be used to generate component lists and SBOMs. Some of our users have expressed an interest in having a mode where CVE-bin-tool generates SBOMs without requiring one to download and use vulnerability data. The current database takes around 2.5G of space and 20 minutes to download and process on a fast system with a lot of RAM, so it's rather understandable that people would want to skip that.

      This will require some major refactoring of our database and the order in which things are done, including potentially:

      Appropriate documentation and tests. We recommend writing these first, as documentation will help you get feedback from actual users and tests can help you do test-driven development.
      Major refactoring to separate our component identification parts from our vulnerability identification parts. Right now they're pretty intermixed.
      The ability to generate reports / SBOMs without making database calls at all
      Report changes so we don't claim to have found 0 CVEs when in fact no one even looked it up
      You may want to take a look at how our --offline mode works as well, not because it's a perfect example (it will also need to be refactored) but because it'll help you see the places where we're going to have problems.

      This project is going to be HARD. We'll expect some proposed new architecture diagrams as part of your proposal and ideally you'll have at least a few bigger pull requests under your belt before you start this project, and you're going to need to find a way to break this project up into much smaller pieces that can be merged without breaking the tool as it stands, which is not easy. Expect that you will need to merge at least some code every week.

      Related reading
      feat: no-scan mode #4110
      Skills
      python
      sqlite
      network communication
      software security: knowledge of how software vulnerabilities are triaged, mitigated and solved would be very helpful here. (you can learn some of this as you go but it's worth doing some background reading to help inform your design choices)
      Difficulty level
      hard
      You're really going to have to understand how cve-bin-tool works and be prepared to challenge our older architecture decisions in order to make this work.
      Project Length
      350 hours (e.g. full-time for 10 weeks or part-time for longer)
      It would be possible to do part of this project in a 175 hour project, but we may prefer candidates who have the time to do more assuming similar levels of ability
      Mentor
      The primary mentor for this project will likely be @terriko but @anthonyharrison will also have a lot of feedback and recommendations about architecture changes. Please ask all questions on this issue rather than sending email so you can benefit from the expertise of other contributors and mentors. (Terri's email gets swamped regularly by other work concerns and it's likely she will miss emails send during the GSoC period, but she will answer questions asked in public on this issue or in our gitter chat.)
      GSoC Participants Only
      This issue is a potential project idea for GSoC 2025, and is reserved for completion by a selected GSoC contributor. Please do not work on it outside of that program. If you'd like to apply to do it through GSoC, please start by reading #4712.



      ~~~~~~~~~~

      1a. Improve raw data browsing (pyqtgraph)
      Difficulty
      Medium

      Project length
      350 hours

      Possible mentors
      Alex Gramfort, Eric Larson, Dan McCloy

      Goal
      mne-qt-browser is a modern eletrophysiology browser based on Qt. It offers fast visualization of raw, epochs, and ICA time courses. However, there are many UI and usability improvements that could be added.

      Subgoals
      Improve the overview bar
      Enable interactive switching between time courses and STFT/spectrogram view for individual traces, including UI elements to control various parameters (clim, cmap, n_fft, etc.)
      Add a two-control "time slider" and/or "channel slider" that allows setting the time span and channel span to show
      Optionally, add text overlays for each channel giving their value at the current time point (continuously updating)
      Add the possibility to load a file from the UI (add button or menu) or to simple drop a file in the window to view it
      Multiple other ideas on this project page
      
      ~~~~~~~~~~
      
      1b. Improve raw data browsing (matplotlib)
      Difficulty
      Medium

      Project length
      350 hours

      Possible mentors
      Alex Gramfort, Eric Larson, Dan McCloy

      Goal
      The newer pyqtgraph-based data browser in 1a is modeled on our original Matplotlib-based browser. The Matplotlib data browser is better tested and more feature-complete, but less performant than its pyqtgraph-based counterpart. The main goal is to improve rendering speed. Secondary goals include re-working some of the dialog windows to leverage modern matplotlib capabilities, and adding a zoom-to-rectangle feature.

      Subgoals
      Speed up rendering, both when scrolling (through time or through channels) and when toggling projections on and off (see visualizing how projectors affect the signal). This may involve some or all of the following: blitting, multiprocessing (to precompute projected data), working with SubFigures, LineCollections, clipping.
      Add zoom-to-rectangle (click-drag-release, or fixed ratio zoom-to-pointer; #7006)
      Rework the MNEAnnotationFigure and MNESelectionFigure to address recent changes in the Matplotlib API (see partial progress in #11417 and #11409).
      Improve interaction with annotations (e.g., #9133, #8946, #9199)
      
      ~~~~~~~~~~
      2. Utilize event system for brain and evoked plots
      Difficulty
      Medium

      Project length
      175 hours, 350 hours

      Possible mentors
      Eric Larson, Marijn van Vliet

      Goal
      We have an excellent 3D viewer for brain activations, and multiple ways of viewing evoked data (plot_topo, plot_topomap, plot_joint, etc.), and an event system for linking them. We want to integrate these so that you can, for example, click on a time point in a Brain and have the evoked.plot_topomap update. This should be done using callbacks to allow for customizability.

      Subgoals
      Create missing functionality such as:

      Build an Xfit replacement: https://github.com/mne-tools/mne-python/pull/12071, https://github.com/mne-tools/mne-python/pull/12070, etc.
      Improve inverse interactivity, e.g., allow (evoked, inv) pair to Brain to generate source time courses on the fly
      Integrate the evoked.plot_* matplotlib figures into the brain viewer directly (this is a UI design problem mostly: should it use tabs, or something else?)
      
      ~~~~~~~~~~
      3. Refactor EGIMFF to use mffpy
      Difficulty
      Medium

      Project length
      175 hours

      Possible mentors
      Eric Larson, Dan McCloy

      Goal
      MNE-Python uses internal code for reading EGI-MFF files, but we should leverage mffpy instead. See for example:

      https://github.com/mne-tools/mne-python/issues/6937
      https://github.com/mne-tools/mne-python/issues/8038
      https://github.com/mne-tools/mne-python/issues/11380
      https://github.com/mne-tools/mne-python/issues/12262
      
      
      ~~~~~~~~~~
      4. Improve interoperability with braindecode
      Difficulty
      Hard

      Project length
      175 hours, 350 hours

      Possible mentors
      Eric Larson, Dan McCloy

      Goal
      Quoting braindecode:

      Braindecode is an open-source Python toolbox for decoding raw electrophysiological brain data with deep learning models. It includes dataset fetchers, data preprocessing and visualization tools, as well as implementations of several deep learning architectures and data augmentations for analysis of EEG, ECoG and MEG.

      It could benefit MNE-Python, MNE-BIDS-Pipeline, and braindecode to work on elements of joint interest, such as how to configure, consume, and preprocess M/EEG-BIDS datasets appropriately. The goal of the GSoC project would be to find these points of commonality and work on refactoring and improving these projects.

      
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/python-software-foundation/
    idea_list_url: https://python-gsoc.org/ideas.html

  

  - organization_id: 129
    organization_name: QC-Devs
    no_of_ideas: 10
    ideas_content: |
      Refactor Database Structure #141
      
      Update the AtomDB API to use a better (de)serialization method based on a Python database library, such as ZODB.

      📚 Package Description and Impact
      AtomDB is a database of chemical and physical properties for atomic and ionic species. It includes a Python library for submitting computations to generate database entries, accessing entries, and interpolating their properties at points in space. AtomDB currently uses MsgPack for (de)serializing database entries (instances of dataclasses), but the deserialization is slow, complicated, and uses poor Python practices. This project will involve updating the AtomDB API to use a better (de)serialization method based on a proper database library, such as ZODB, which has seamless interoperability with Python classes and objects. This is a key milestone on AtomDB release schedule.

      👷 What will you do?
      You will update the AtomDB API to replace the MsgPack-based (de)serialization functions database entry files with the ZODB database library. You will port the atomic/ionic species class to be a standalone class (instead of dataclass + wrapper), which will provide transparent (de)serialization with ZODB. Finally, you will port the existing AtomDB entry files to the new database, and modify the build files (pyproject.toml) so that the new database is included with user installations of AtomDB.

      🏁 Expected Outcomes
      (De)serialization works transparently with instances of Species, and is done to and from a ZODB database.
      Species is made a standalone class (not a dataclass), by subclassing the ZODB persistent object base class.
      Old MsgPack database entries are ported to the new database.
      Build files are updated to reflect the change in database files shipped with AtomDB.
      The AtomDB API is tested after the previous changes are made.
      Required skills	Python, OOP, Linux
      Preferred skills	Database experience
      Project size	175 hours, Medium
      Difficulty	Medium 🤔
      🙋 Mentors
      Michelle Richer	richer.m_at_queensu_dot_ca	@msricher
      Gabriela Sánchez-Díaz	sanchezg_at_mcmaster_dot_ca	@gabrielasd
      Farnaz Heidar-Zadeh	farnaz_dot_heidarzadeh_at_queensu_dot_ca	@FarnazH
      📝 Notes
      Supersedes #21


      ~~~~~~~~~~

      Improve Performance Using Screening

      Description
      Use screening based on the overlap between basis functions to improve performance.

      📚 Package Description and Impact
      For large molecules, textbook expressions for quantities expanded in Gaussian basis functions (e.g., the electron density) or integrals based on Gaussian basis functions (e.g., the kinetic-energy integral) typically include many negligible terms. By screening out these terms, and only evaluating terms that are nonnegligible, the performance of GBasis can be greatly enhanced.

      👷 What will you do?
      In GBasis we provide a utility for screening these terms using their overlap, is_overlap_included. When this expression is small, one can also neglect other one-electron integrals. A generalization of this approach allows fast evaluation of spatial quantities and 2-electron integrals. Your main goal would be to screen 1-electron integrals and the evaluation of quantities at (grid) points using overlap screening and its generalization.

      🏁 Expected Outcomes
      Adapt is_overlap_included to screen other one-electron integrals.
      Extend is_overlap_included to three functions, which allows screening spatial evaluations.
      Write tests to ensure correctness and assess performance.
      🏆 An ambitious stretch goal is to implement screening of 2-electron integrals.
      Required skills	Python, OOP
      Preferred skills	Be comfortable with math, physics. Experience with scientific programming, quantum chemistry would be huge plus
      Project size	350 hours, Large
      Difficulty	Medium 😉
      🙋 Mentors
      Marco Martínez-González	mmg870630_at_gmail_dot_com	@marco-2023
      Esteban Vöhringer-Martinez	estebanvohringer_at_qcmmlab_dot_com	@evohringer
      Paul Ayers	ayers_at_mcmaster_dot_ca	@PaulWAyers
      Gabriela Sánchez-Díaz	sanchezg_at_mcmaster_dot_ca	@gabrielasd
      📝 Notes & References
      Supersedes GSoC 2025: Improve Performance Using Screening #167
      Related to GSoC 2025: Arbitrary-order Overlap Integrals (and evaluations enabled thereby) #183 , [BUG] Big memory usage for density evaluation #121,
      Screening is discussed in Chapter 9 of Molecular Electronic Structure Theory.
      A recent(ish) discussion from the Ochsenfeld group
      Paul's notes on overlap screening
      Paul's notes on screening in general. This includes screening for 2-electron integrals, which would be an (ambitious!) stretch goal.

      ~~~~~~~~~~

      Arbitrary-order Overlap Integrals (and evaluations enabled thereby)

      Description
      Add functionality to the GBasis library for arbitrary-order overlaps. One motivation of this is to support the evaluation of the intracule (the distribution function for the interelectronic distance) and the extracule (the distribution function for the center-of-mass of electron pairs). See these review articles.

      📚 Package Description and Impact
      GBasis is a pure-Python package for evaluating and analytically integrating Gaussian-type orbitals and their related quantities. The goal is to build a set of tools to the quantum chemistry community that are easily accessible and easy to use as to facilitate future scientific works.

      👷 What will you do?
      Your main focus will be to add functionality for the overlaps of arbitrarily many Gaussian basis functions. It is important to include screening, as otherwise the evaluations can be quite expensive. An important application, which should be supported with an appropriate API, is evaluation of the intracule and extracule. Another important application is the evaluation of near-arbitrary interparticle repulsions. This is possible because, using tricks popularized by Beylkin and Monzon, almost any interparticle repulsion can be written as a sum of Gaussians. This would include the (many-body) interactions associated with nucleons and other types of cofermions and cobosons. This is a place where some creativity can be exercised, as innovative new algorithms and improved fits are being consistently proposed. That said, these potential applications are beyond the scope of this specific issue, though they are relatively easy extensions thereto.

      This functionality also allows us to compute arbitrary positive integer powers of the electron density and related density matrices analytically. (Typical approaches rely, instead, on numerical integration that become increasingly ill-conditioned for high powers.) This is sometimes useful when describing (very) multicenter bonding.

      3- and 4-Gaussian overlaps from PySCF can be used for testing. 1-Gaussian overlaps and 2-Gaussian overlaps are built-in already and can be used for testing. An algorithm similar to what is needed here is already included in IOData (for two Gaussians). See also the overlap integrals in GBasis.

      🏁 Expected Outcomes
      Implement the overlap for an arbitrary number of (contracted, Cartesian or spherical) Gaussian basis functions.
      Add support for screening, with appropriate default parameters.
      Add functionality for evaluating the intracule and extracule.
      Utilities for computing positive integer powers of the electron density and relevant density matrices.
      Support for (near) arbitrary interparticle repulsion integrals. This uses the aforementioned trick of Beylkin and Monzon. A similar trick is used in MADNESS, which can be used for inspiration.
      Write comprehensive tests and documentation for all new functionality.
      Write tutorial Jupyter notebooks that show how to use the new functionality.
      Required skills	Python, OOP
      Preferred skills	Be comfortable with math and numerical algorithms. Experience with scientific programming and quantum chemistry can help
      Project size	350 hours, Large
      Difficulty	Medium to Hard 🥵
      🙋 Mentors
      Marco Martínez-González	mmg870630_at_gmail_dot_com	@marco-2023
      Farnaz Heidar-Zadeh	farnaz_dot_heidarzadeh_at_queensu_dot_ca	@FarnazH
      Leila Pujal	19lpg_at_queensu_dot_ca	@leila-pujal
      📝 Notes
      An algorithm (two algorithms, in fact) for doing this are included in the attached notes,
      which were developed in the context of the intracule and extracule. The attached notes are old and have Fortran-style pseudocode (they are that old). [To be clear, I would not suggest implementing the direct algorithms for the intracule/extracule. It is better to pass through the multi-Gaussian overlaps.]

      Note that multi-Gaussian overlaps are extremely sparse, so a sparse tensor structure should be used. The main operation one needs are tensor contractions (usually pairing indices to one or more copies of the 1- or 2-electron density matrix), which will determine the type of structure one uses to store the tensor. One may need to use pytorch functionality for this.

      If we had the arbitrary-order overlaps coded, I would argue that we should support some additional evaluations, notably:

      intracule on a grid.
      extracule on a grid.
      integrals of powers of the electron density.
      (maybe) integrals of moments of powers of the electron density. These integrals show up in some of the moment density functional development work that Parr and Nagy did a couple decades ago. That specific topic is not very active right now, though, so this could definitely be deferred to the (far) future.




      ~~~~~~~~~~

      Integration of the Sphere with Maximum Determinant Points
      
      Description
      Add functionality to the Grid library for integration over the surface of a sphere. Currently we support Lebedev quadrature (nonequal weights, sometimes negative weights) and spherical t-designs (equal positive weights). An alternative, with nonequal but always positive weights, is the maximum determinant stategy.

      📚 Package Description and Impact
      Grid is a pure Python library for numerical integration, interpolation and differentiation of interest for the quantum chemistry community.

      👷 What will you do?
      Following the style of the spherical t-design grids, you will add functionality for the maximum determinant strategy. Up to a degree of 200, the points/weights are available here.
      Incidentally, the same web page has one spherical design beyond what we have right now, for degree 325. It would be good to add this to our list.

      🏁 Expected Outcomes
      Add functionality for the maximum determinant strategy spherical integration.
      Add the 
      ℓ
      =
      325
      spherical t-design.
      Write comprehensive tests and documentation for all new functionality.
      Write tutorial Jupyter notebooks that show how to use the new functionality.
      Required skills	Python, OOP
      Preferred skills	Be comfortable with math and numerical algorithms. Experience with scientific programming can help
      Project size	90 hours, Small
      Difficulty	Easy ☺️
      🙋 Mentors
      Marco Martínez-González	mmg870630_at_gmail_dot_com	@marco-2023
      Farnaz Heidar-Zadeh	farnaz.heidarzadeh_at_queensu_dot_ca	@FarnazH
      Paul Ayers	ayers_at_mcmaster_dot_ca	@PaulWAyers
      Ali Tehrani	19at27_at_queensu_dot_ca	@Ali-Tehrani
      📝 Notes
      A stretch goal would be to implement yet another angular integration method, where the grid points are rigorously nested.


      ~~~~~~~~~~

      Adaptive Quadrature Methods

      Description
      Add functionality to the Grid library for adaptive quadrature. Grid has quite efficient methods for (molecular and periodic) molecular integration. However, in cases where the accuracy of a grid is inadequate, one typically has to recompute, from scratch, with a larger grid. It would be better to have nested grids, where one can (ideally locally) improve the accuracy of the grid, without discarding the points that one has already computed.

      📚 Package Description and Impact
      Grid is a pure Python library for numerical integration, interpolation and differentiation of interest for the quantum chemistry community.

      👷 What will you do?
      Use a traditional Becke-style molecular grid, with nested radial (relatively easy) and angular (not too hard; see #258) points. This is effectively a way to adaptively prune a grid.

      🏁 Expected Outcomes
      Implement Issue Nested Angular Grids (for adaptive quadrature) #258 .
      Implement adaptive radial grids.
      Use steps 3 and 4 to construct adaptive Becke-style grids.
      Write comprehensive tests and documentation for all new functionality.
      Write tutorial Jupyter notebooks that show how to use the new functionality.
      Required skills	Python, OOP
      Preferred skills	Be comfortable with math and numerical algorithms. Experience with scientific programming can help
      Project size	175 hours, Medium
      Difficulty	Medium 🤔
      🙋 Mentors
      Marco Martínez-González	mmg870630_at_gmail_dot_com	@marco-2023
      Paul Ayers	ayers_at_mcmaster_dot_ca	@PaulWAyers





      ~~~~~~~~~~

      Transformed Cubic Grids

      Description
      One disadvantage of Becke-style molecular grids is that, due to overlapping atomic grids, there are numerous grid points that have very small, but nonnegligible, weights. Our strategy to overcome this issue is to use a cubic grid, but transform it to real space in such a way that points are concentrated where the integrands of interest are large and/or rapidly changing. The goal of this project is add this functionality to Grid. One nice facet of this approach is that it is easy to adaptively refine a cubic grid, and ergo a transformed cubic grid. This allows for adaptive quadrature to be implemented without too much pain.

      📚 Package Description and Impact
      Grid is a pure Python library for numerical integration, interpolation and differentiation of interest for the quantum chemistry community.

      👷 What will you do?
      A more detailed description of this project is available in issue #15 . The basic idea is to take a cubic grid, and then perform a transformation based on a probability distribution function, using the conditional distribution method.

      🏁 Expected Outcomes
      Refresh pull request Transformed cube (#15) #96 and merge it.
      Implement adaptive transformed cubic grid.
      Write comprehensive tests and documentation for all new functionality.
      Write tutorial Jupyter notebooks that show how to use the new functionality.
      Required skills	Python, OOP
      Preferred skills	Be comfortable with math and numerical algorithms. Experience with scientific programming can help
      Project size	175 hours, Medium
      Difficulty	Medium 🤔
      🙋 Mentors
      Marco Martínez-González	mmg870630_at_gmail_dot_com	@marco-2023
      Farnaz Heidar-Zadeh	farnaz_dot_heidarzadeh_at_queensu_dot_ca	@FarnazH
      Ali Tehrani	19at27_at_queensu_dot_ca	@Ali-Tehrani



      ~~~~~~~~~~

      Improve Robustness of Poisson Solver

      Description
      Improve the robustness of the Poisson solvers that grid uses to evaluate the Coulomb potential due to a charge distribution,

      Φ
      (
      r
      )
      =
      ∫
      ρ
      (
      r
      ′
      )
      |
      r
      −
      r
      ′
      |
      d
      r
      ′

      As pointed out by Becke, this is more efficiently treated, numerically, as a solution to the corresponding Poisson equation.

      ∇
      2
      Φ
      (
      r
      )
      =
      −
      4
      π
      ρ
      (
      r
      )

      📚 Package Description and Impact
      Grid is a pure Python library for numerical integration, interpolation and differentiation of interest for the quantum chemistry community.

      👷 What will you do?
      Grid has two different Poisson solvers, one using a boundary-value method (which seems more robust, but is not perfect #215) and one using an initial-value method which is less robust (see #162). You will attempt to find robust default parameters for these methods. It is conceivable that one needs (much) larger grids for solving the Poisson equation than we routinely use in numerical integration. (Our Gaussian-quadrature-ish grids are especially adapted to integration; for differentiation their accuracy is diminished. Solving the Poisson equation is essentially a differentiation.)

      One approach, which would potentially make the method more robust, would be to use a screened Coulomb kernel instead; that approach can remove the singularity in the equation and, by taking the limit to zero screening, give robust results.

      Another approach, which might be much easier, would be to use the strategy proposed in #16. That is, estimate the density with a linear combination of Gaussians using BFit, so that one only needs to solve the Poisson equation for the error in the fit.

      🏁 Expected Outcomes
      Explore the boundary value solver. Find good values for the default parameters.
      See if the initial value problem can be made more robust or, failing that, if circumstances where it is robust can be identified.
      Develop a protocol where a sufficient grid, algorithm, and algorithm parameters can be selected, allowing high-level porcelain to be designed for the function.
      Explore whether using the "promolecular" trick is beneficial.
      Explore whether screened Coulomb potentials behave better.
      Write comprehensive tests and documentation for all new functionality.
      Write tutorial Jupyter notebooks that show how to use the new functionality.
      Required skills	Python, OOP
      Preferred skills	Be comfortable with math and numerical algorithms. Experience with scientific programming can help
      Project size	350 hours, Large
      Difficulty	Medium 🤔
      🙋 Mentors
      Marco Martínez-González	mmg870630_at_gmail_dot_com	@marco-2023
      Derrick Yang	yxt1991_at_gmail_dot_com	@tczorro
      Esteban Vöhringer-Martinez	estebanvohringer_at_qcmmlab_dot_com	@evohringer
      Ali Tehrani	19at27_at_queensu_dot_ca	@Ali-Tehrani





      ~~~~~~~~~~

      Toolkit for Molecular Hamiltonians

      Description
      Enhance the Model Hamiltonian package by implementing utilities for molecular Hamiltonians manipulation, transformation, and interfacing with quantum chemistry packages.

      📚 Package Description and Impact
      The Model Hamiltonian package aims to provide a comprehensive toolkit for working with molecular Hamiltonians in quantum chemistry calculations. The package will introduce utilities for Hamiltonian transformations, basis set conversions, and integration with popular quantum chemistry software. This will enable researchers to efficiently manipulate and analyze electronic structure calculations while maintaining the flexibility to work with different theoretical frameworks.

      👷 What will you do?
      Your main focus will be on developing utilities for molecular Hamiltonian manipulations. This includes implementing symmetrization procedures, spin-adaptation routines, basis set transformations, and interfaces with external quantum chemistry packages. The project will emphasize creating robust, well-tested APIs that seamlessly integrate with existing quantum chemistry workflows.

      🏁 Expected Outcomes
      Implement Hamiltonian symmetrization utilities to ensure correct properties of Hamiltonians in MO basis
      Develop spin-adaptation routines for generating proper spin eigenfunctions
      Create tools for basis set transformations (MO to AO conversion)
      Implement mapping utilities onto geminal basis representations
      Add support for FCIDump file format reading and writing
      Develop interface with PySCF for seamless integration with quantum chemistry calculations
      Write comprehensive tests and documentation for all new functionality
      Required skills	Python, OOP, Linear Algebra
      Preferred skills	Experience with quantum chemistry software (PySCF, Psi4), familiarity with electronic structure theory, knowledge of group theory
      Project size	350 hours, Large
      Difficulty	Medium to Hard 🥵
      🙋 Mentors

      Valerii Chuiko	valerachuiko_at_gmail_dot_com	@RichRick1
      Paul Ayers	ayers_at_mcmaster_dot_ca	@PaulWAyers





      ~~~~~~~~~~

      Alternative Spin representation

      📚 Package Description and Impact
      This project aims to enhance the Model Hamiltonian package by implementing a new spin representation system. The current implementation's limitations in handling certain spin operators will be addressed through a more flexible and comprehensive approach, enabling support for general XYZ Heisenberg models.

      👷 What will you do?
      You will implement a direct spin modeling system using creation and annihilation operators. The key components include:

      • Implementation of spin operators (
      S
      k
      +
      , 
      S
      k
      −
      , 
      S
      k
      Z
      )
      • Handling of maximum seniority states
      • Support for different 
      N
      α
      and 
      N
      β
      electron configurations
      • Verification of spin algebra commutation relations

      🏁 Expected Outcomes
      Implement new spin operator representations
      S
      k
      +
      =
      a
      k
      α
      †
      a
      k
      β
      S
      k
      −
      =
      a
      k
      β
      †
      a
      k
      α
      S
      k
      Z
      =
      1
      2
      (
      a
      k
      α
      †
      a
      k
      α
      −
      a
      k
      β
      †
      a
      k
      β
      )

      Develop support for general XYZ Heisenberg models
      Write comprehensive documentation for the new spin representation system
      Required skills	Python, Linear Algebra, Quantum Mechanics
      Preferred skills	Experience with quantum chemistry, familiarity with spin operators
      Project size	90 hours, Small
      Difficulty	Medium 🤓
      🙋 Mentors

      Valerii Chuiko	valerachuiko_at_gmail_dot_com	@RichRick1
      Paul Ayers	ayers_at_mcmaster_dot_ca	@PaulWAyers



      ~~~~~~~~~~

      Add Exact Solver for Chemical kinetics

      Description
      Add an exact non-linear solver for systems of simultaneous equilibria to the NICE (“N-species ICE-table”) Julia module.

      📚 Package Description and Impact
      A system of simultaneous equilibria’s steady state can be computed by solving a system of nonlinear equations, although for non-trivial systems, a very good guess at the equilibrium reaction extents is required for this. Kinetic Monte Carlo (KMC) methods are often used, then, to stochastically solve this type of system. The KMC method is slow, however, and cannot arrive at the exact solution, although the result of a KMC computation can be used as an initial guess to then solve the system exactly. Currently, NICE features the KMC method, but not the exact method. This project will entail writing the exact method’s objective function and its Jacobian, and then making use of a nonlinear solver Julia module to program the exact method into NICE.

      👷 What will you do?
      Using the existing NICE reaction system structure, you will write the objective and Jacobian function for the exact equilibrium solution. You will also find a suitable Julia module for nonlinear optimization, and using this, write the function that runs the exact method. You will also write a method that first runs the KMC method, and then uses its output as an initial guess to the exact solver. Finally, you must test these methods.

      🏁 Expected Outcomes
      Implement exact solver objective and Jacobian functions
      Use a nonlinear optimizer library to program the exact method
      Write a hybrid method using the result of the KMC method as the guess for the exact method
      Test each new function and method you have implemented.
      Testing should resolve NICE and NICE.jl give different results #3, as it will effectively assess robustness of multiple methods in nice.jl and enable systematic testing.
      Write comprehensive documentation for all new functionality.
      Write tutorial Jupyter notebooks that show how to use the new functionality.
      Required skills	Julia
      Preferred skills	chemical equilibria and chemical kinetics, nonlinear optimization and objective/Jacobian functions
      Project size	175 hours, Medium
      Difficulty	Medium 🤔
      🙋 Mentors
      Michelle Richer	michellericher93_at_gmail_dot_com	@msricher
      Paul Ayers	ayers_at_mcmaster_dot_ca	@PaulWAyers
      📝 Notes
      Paul's [class notes on simultaneous equilibria]((https://github.com/user-attachments/files/18806883/11Systems.of.Nonlinear.Equations.from.Simultaneous.Equilibria.pdf).
      Short description of the nonlinear equations
      We have an old Fortran implementation for reference.
      This issue supersedes previous issues #2, #3, and #4 . Exact solver translate to Julia #2 has some additional background information and GSoC 2025: Add exact solvers #4 has some useful discussion.

      




            
     
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/qc-devs/
    idea_list_url: https://qcdevs.org/join/qcdevs_gsoc/


  - organization_id: 130
    organization_name: QEMU
    no_of_ideas: 6
    ideas_content: |
      
      Tracing and logging in Rust
      Expected outcome: Implement Rust APIs for tracing and logging.
      The QEMU project is currently experimenting with using the Rust programming language to create new devices. As part of this, we have to write bindings to the C code that make it possible to use it from Rust safely. For example, QEMU needs to include Rust code to manage timers, interrupts and memory regions with safe and idiomatic Rust code.
      QEMU integrates support for tracing using various backends---ranging from good old stdio to systemtap---thanks to a code generator that can produce tracing routines for the hundreds of tracepoints that QEMU supports; for more information see the links below. As part of this project, you will work on adding support for tracing and logging to Rust code.
      The project spans multiple programming languages: the code generator is written in Python, the generated code will of course be Rust, and you will have to read some C to understand the subsystem.
      Among similarly large open source C projects, QEMU is an early adopter for Rust! So you will also have a look at how the two languages can be integrated through the Meson build system.
      Tasks:
      implement bindings for QEMU's logging subsystem (logging is one of the tracing backends)
      analyze the code generated by tracetool for C for the various tracing backends
      try to implement by hand a few tracepoints in Rust
      modify tracetool to generate the Rust code automatically
      Links:
      Tracing in QEMU
      Rust in QEMU status
      Details:
      Project size: 350 hours
      Skill level: intermediate/advanced
      Languages: Python, Rust, C
      Mentor: Paolo Bonzini (OFTC: bonzini, Email: pbonzini@redhat.com)

      ~~~~~~~~~~
      Adding Kani proofs for Virtqueues in Rust-vmm
      Expected outcome: Verify conformance of the virtqueue implementation in rust-vmm to the VirtIO specification.
      In the rust-vmm project, devices rely on the virtqueue implementation provided by the `vm-virtio` crate. This implementation is based on the VirtIO specification, which defines the behavior and requirements for virtqueues. To ensure that the implementation meets these specifications, we have been relying on unit tests that check the output of the code given specific inputs.
      However, writing unit tests can be incomplete, as it's challenging to cover all possible scenarios and edge cases. During this internship, we propose a more comprehensive approach: using Kani proofs to verify that the virtqueue implementation conforms to the VirtIO specification.
      Kani allows us to write exhaustive checks for all possible values, going beyond what unit tests can achieve. By writing Kani proofs, we can confirm that our implementation meets the requirements of the VirtIO specification. If a proof passes, it provides strong evidence that the virtqueue implementation is correct and conformant.
      Kani is an open-source tool and any issues like regarding performance can be reported on GitHub. For more information, the blog[1] contains several examples on how to use Kani in real codebases (including Firecracker). Also, there is a current effort for verifying the Rust Standard Library using Kani [2].
      Tasks:
      Finish current PR that adds a proof for the notification suppression mechanism
      Port add_used() proof
      Port verify_prepare_kick() proof
      Port other proofs from queue.rs
      Links:
      LPC Talk about how we may check conformance in the VirtIO specification (video)
      FOSDEM'25 talk current effort to use Kani
      Kani Blog
      Details:
      Project size: 175 or 350 hours, depending on how many proofs you wish to tackle
      Skill level: intermediate
      Language: Rust
      Mentor: Matias Ezequiel Vara Larsen (mvaralar@redhat.com)
      ~~~~~~~~~~
      FUSE-over-io_uring exports
      Expected outcome: Extend QEMU's FUSE export type with FUSE-over-io_uring support
      FUSE-over-io_uring is a new high-performance interface for Filesystem in Userspace (FUSE) servers. The FUSE kernel code has added uring_cmd support so that FUSE servers can send and receive data directly over io_uring instead of reading/writing from/to the FUSE device. This reduces the number of system calls, as well as allowing for batching and polling, so that CPU overhead should be reduced.
      QEMU's FUSE export type presents a file containing the contents of a disk image. This is a convenient way of using tools like fdisk(1) or dd(1) on a non-raw disk image file, like qcow2, that these tools would otherwise not be able to operate on. The current FUSE export implementation uses libfuse's FUSE device file descriptor handling APIs (fuse_session_fd(), fuse_session_receive_buf(), etc) to read(2)/write(2) in the traditional way.
      Your task is to add FUSE-over-io_uring support as an alternative mode on systems where FUSE-over-io_uring is available.
      Tasks:
      Integrate FUSE-over-io_uring mode into the QEMU FUSE export
      Add support for multiple in-flight requests
      Benchmark with and without FUSE-over-io_uring using the fio(1) tool
      Add support support multiple IOThreads
      Links:
      QEMU FUSE export code
      libfuse branch with FUSE-over-io_uring support
      Overview of low-level FUSE-over-io_uring interface (handled by libfuse, but good background info)
      Details:
      Project size: 350 hours
      Skill level: intermediate
      Language: C
      Mentors: Kevin Wolf (kwolf@redhat.com), Stefan Hajnoczi (stefanha@redhat.com)

      ~~~~~~~~~~
      Asynchronous request handling for virtiofsd
      Expected outcome: Make virtiofsd’s request handling asynchronous, allowing single-threaded parallel request processing.
      virtiofsd is a virtio-fs device implementation, i.e. grants VM guests access to host directories. In its current state, it processes guest requests one by one, which means operations of long duration will block processing of others that could be processed more quickly.
      With asynchronous request processing, longer-lasting operations could continue in the background while other requests with lower latency are fetched and processed in parallel. This should improve performance especially for mixed workloads, i.e. one guest process executing longer-lasting filesystem operations, while another runs random small read requests on a single file.
      Your task is to:
      Get familiar with a Linux AIO interface, preferably io_uring
      Have virtiofsd make use of that interface for its operations
      Make the virtiofsd request loop process requests asynchronously, so requests can be fetched and processed while others are continuing in the background
      Evaluate the resulting performance with different workloads
      How you make the request loop asynchronous will largely be left to your discretion. You can use Rust async together with a runtime like tokio, some other runtime, or an entirely custom one; or keep the code synchronous, but allow deferring operations to the background, and when they complete, return the virtio descriptors to the guest then. That said, we assume that using async would provide the better long-term solution, as long as you’re comfortable to use/learn it.
      Links:
      virtiofsd repository: https://gitlab.com/virtio-fs/virtiofsd
      virtiofsd’s filesystem operations: https://gitlab.com/virtio-fs/virtiofsd/-/blob/main/src/passthrough/mod.rs#L1490
      virtiofsd’s request processing loop: https://gitlab.com/virtio-fs/virtiofsd/-/blob/main/src/vhost_user.rs#L244
      Details:
      Project size: 350 hours
      Skill level: intermediate
      Language: Rust
      Mentors: Hanna Czenczek (hreitz@redhat.com), German Maglione (gmaglione@redhat.com)

      ~~~~~~~~~~
      Implement LASI network card and/or NCR 710 SCSI controller device models
      Expected outcome: Develop device emulations of the HP PA-RISC LASI network card and/or NCR 710 SCSI controller
      QEMU can emulate a lot of physical machines. Beside widely used x86 machines as used with KVM, this includes historic machines based on PowerPC, Alpha or HP PA-RISC CPUs too. To emulate additional historic machine models, device models that emulate specific hardware like network or SCSI cards need to be developed.
      This project is about developing such a device model for the historic HP PA-RISC architecture. Based on the knowledge and interest of the applicant, here are two non-exclusive options:
      1. LASI network card. This is basically an Intel 82596 network chip, which was integrated into another ASIC in the HP 700 series. That chip was used in SUN machines as well, and the full Linux driver source code for the various machines is available. A QEMU device model exists (see here and here), but it's not fully functional yet. Datasheets for this chip exists too. This project is about debugging and analyzing existing code, including development of missing code.
      2. First-generation NCR 710 SCSI controller. Really old machines used a NCR 710 SCSI controller, for which currently no QEMU device model exists. QEMU has a LSI53C895A device model, which partly even allows emulating a LSI53C810, but those chips are "too new" and as such are not accepted and supported on old operating systems (e.g. HP-UX9). The WinUAE project seem to have modified the existing QEMU device model to emulate a NCR 710 to support the Amiga. The goal of this project is to develop a nice & clean NCR 710 device model that can be merged into QEMU.
      Links:
      https://parisc.docs.kernel.org/en/latest/technical_documentation.html
      Details:
      Project size: 350 hours
      Skill level: advanced
      Language: C
      Mentor: Helge Deller (deller@gmx.de)

      ~~~~~~~~~~
      vhost-user devices in Rust on macOS and *BSD
      Expected outcome: Extend rust-vmm crates to support vhost-user devices running on POSIX system like macOS and *BSD.
      VIRTIO devices can be emulated in an external process to QEMU thanks to the vhost-user protocol, which allows QEMU to offload the entire emulation to a daemon. This is done through an AF_UNIX socket used as a control path between the frontend (i.e. QEMU) and the backend (i.e. the vhost-user daemon). QEMU will share guest memory with the daemon, provide all the information for data path setup, and notification mechanisms.
      Moving the emulation of VIRTIO devices to a separate process from QEMU offers significant advantages, primarily in terms of safety, if a device crashes, we can restart it without affecting QEMU. Additionally, this approach simplifies updating device implementations, allows development in other languages (such as Rust as we do in the rust-vmm community), and enhances isolation through seccomp, cgroups, and similar mechanisms.
      The rust-vmm community already provides several crates (e.g. vhost, vhost-user-backend, etc.) to implement a vhost-user backend in an external daemon. For example, these crates are used by virtiofsd (virtio-fs vhost-user device) but also by all vhost-user devices maintained by the rust-vmm community in the rust-vmm/vhost-device workspace. These crates work great on Linux, but unfortunately they use some Linux-specific system calls such as epoll(7) and eventfd(2) that make them impossible to use on other POSIX systems.
      The goal of this project is to make sure that we can use rust-vmm's vhost and vhost-user-backend crates on other POSIX systems besides Linux. If time permits, we could also fix up simple devices such as vhost-device-console or vhost-device-vsock to run on any POSIX systems.
      Tasks:
      Run QEMU with a vhost-user device on macOS or FreeBSD/OpenBSD as covered in the FOSDEM 2025 talk
      Analyze rust-vmm crates (vmm-sys-util, vhost, vhost-user-backend) to understand which components are Linux-specific
      Replace epoll(7) with alternatives such as https://github.com/smol-rs/polling
      Automatic fallback to pipe()/pipe2() if eventfd(2) is not available as QEMU already does
      Handle any other cases discovered during the analysis
      Adapt a simple device such as vhost-device-console or vhost-device-vsock to test that everything works on macOS or FreeBSD/OpenBSD
      Links:
      FOSDEM 2025 talk: Can QEMU and vhost-user devices be used on macOS and *BSD?
      vhost-user spacification
      QEMU series to support vhost-user on any POSIX
      sgarzare's tree where to find some missing QEMU patches
      rust-vmm vhost & vhost-user-backend crates
      rust-vmm vmm-sys-util crate
      rust-vmm vhost-device workspace
      virtio-fs vhost-user device
      Mac build support #110 - rust-vmm/vhost
      Add macOS support #169 - virtio-fs/virtiofsd
      Details:
      Project size: 350 hours
      Skill level: intermediate
      Language: Rust
      Mentors: Stefano Garzarella <sgarzare@redhat.com>, German Maglione <gmaglione@redhat.com>, Oliver Steffen <osteffen@redhat.com>
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/qemu/
    idea_list_url: https://wiki.qemu.org/Google_Summer_of_Code_2025
  

  - organization_id: 131
    organization_name: R project for statistical computing
    no_of_ideas: 18
    ideas_content: |
     
      Animated interactive ggplots 175 or 350 Need contributor TD Hocking, Y Fei JavaScript

      Animated interactive ggplots
 
      Suhaani Agarwal edited this page 11 hours ago · 27 revisions
      Background
      animint2 is an R package for making interactive animated data visualizations on the web, using ggplot syntax and two new keywords:

      showSelected=variable means that only the subset of the data that corresponds to the selected value of variable will be shown.
      clickSelects=variable means that clicking a plot element will change the currently selected value of variable.
      Toby Dylan Hocking initiated the project in 2013, and Susan VanderPlas (2013), Carson Sievert (2014), Tony Tsai (2015), Kevin Ferris (2015), Faizan Khan (2016-2017), Vivek Kumar (2018), Himanshu Singh (2020), Yufan Fei (2022-2023), and Jocelyn Chen (2023) have provided important contributions during previous GSOC projects.

      The animint2 manual is the definitive reference on how to design data visualizations using animint2.

      Related work
      Standard R graphics are based on the pen and paper model, which makes animations and interactivity difficult to accomplish. Some existing packages that provide interactivity and/or animation are

      Non-interactive animations can be accomplished with animation/gganim/gganimate/plotteus (animint2 provides interactions other than moving forward/back in time).
      Some interactions with non-animated linked plots can be done with the qtbase, qtpaint, and cranvas packages (no longer maintained, animint2 provides animation and showSelected).
      Linked plots in the web are possible using SVGAnnotation (no longer maintained) or gridSVG but using these to create such a visualization requires knowledge of Javascript (animint2 designers write only R/ggplot2 code).
      The svgmaps package defines interactivity (hrefs, tooltips) in R code using igeoms, and exports SVG plots using gridSVG, but does not support showing/hiding data subsets (animint2 does).
      The ggvis (dormant/archived) package defines a grammar of interactive graphics that relies on shiny’s reactivity model for most of its interactive capabilities (animint2 does not need a shiny server). Like vegawidget/vegalite in R and Vega-Altair in Python, it uses Vega but does not support the interactive clickSelects/showSelected keywords (animint2 does).
      Interlinked plots are supported by Holiviz, but “not all interactivity will work” when sharing on the web (local python required).
      plotly and ggiraph support
      some client-only interactions (without a shiny server, like animint2),
      usage with a shiny server (calculate something based on what data points the user selected, animint2 does not support this),
      different APIs for interaction (not as simple/powerful as the clickSelects/showSelected keywords supported by animint2). For example plotly uses highlight/filter events which are compatible with other htmlwidgets (animint2 is not compatible with htmlwidgets).
      customization via writing JavaScript/CSS (animint2 R ggplot API does not require writing JavaScript/CSS).
      mostly interacting with a single plot (animint2 emphasizes interactions between multiple different plots linked together via selection variables = common column names/values across data sets). Although there are some documented uses of plotly with multiple linked plots (for example see Client-side linking chapter of plotly book).
      loon provides interactive graphics using the tcltk R package, and is great for exploratory graphics, but does not support the interactive clickSelects/showSelected keywords (animint2 does).
      RIGHT (archived), htmlwidgets, and DC (JavaScript not R) implement interactive plots for some specific plot types (animint2 uses the multi-layered grammar of graphics so is not limited to pre-defined plot types).
      Tableau, PowerBI, and Superset have interactive visualizations/dashboards with pre-defined chart types (not multi-layer). In contrast animint2 has multiple layers, each with specific interactions.
      For even more related work see The animint JCGS paper by Sievert et al (2018), the Graphics and Web technologies task views on CRAN, and Visualization design resources from the UBC InfoVis Group.

      GSOC coding project: new animint2 features + gallery
      The goal of this GSOC project is to implement new features for animint2 in order to

      layout ggplots in a HTML table, using rowspan and colspan so that, for example, one plot can be rendered to the left of two plots stacked on top of each other.
      port the gallery from the NAU rcdata server (~50 data viz with links to R source code), to the new GitHub Pages gallery. This builds on previous work by Nhi Truong in GSOC’24, see related issues/PRs:
      issues with some data viz
      data viz won’t be ported due to duplication
      data viz which can not be ported due to missing files
      This task should be relatively easy, but you first need to make a plan/list of data viz which have already been ported, and to do that you need to carefully examine the data viz in the old and new galleries.
      automatic generation of interaction prompts. It would be great to have a little question mark (?) icon next to each plot, when clicked, we show bullet points that list what interactions are possible with this plot. One bullet point per clickSelects. For example, “Click point to select country” or “Click rect to select year.” use driver.js to make a guided tour of possible interactions.
      animint(video=”http://…”) shows link to video which shows typical interactions. create video for each viz in gallery, then redo each viz, adding video link to each one. issue#151
      An ideal contributor project will also plan to write some tests and documentation (vignette, web page, blog example 1, blog example 2).

      tests and bugfix for geom_abline which does not render correctly in some situations, for example Kernel space features plot on Ch12-SVM in Animint2 Manual.
      Previously Faizan implemented updating of axes/legends after changing the currently displayed data subset. Currently the computations are done in the compiler but there are some limitations, so it would be preferable to move the computations to the renderer. See issue, move scale range calculation to renderer.
      fixing any of the other issues.
      Any other ideas for improving Animint are welcome, as long as they can fit in the 3-month coding time frame.

      Expected impact
      Animint2 already provides useRs with some unique features for interactive data visualization. At the end of GSOC, the animint2 package will be easier to maintain, and have even more features, tests, documentation, and gallery examples.

      Frequently Asked Questions
      Does a contributor need to know both JavaScript and R?
      YES. If you don’t know JavaScript then I suggest you read some tutorials, e.g. Mozilla JavaScript basics, W3Schools, mbostock’s D3 examples.

      Mentors
      Please get in touch with EVALUATING MENTOR Toby Dylan Hocking <toby.hocking@r-project.org> and Yufan Fei <yufanfei8@gmail.com> after completing at least one of the tests below.

      Tests
      Do one or several — doing more hard tests makes you more likely to be selected.

      Easy: do one of the exercises listed in one of the chapters of the animint2 Manual, and upload your visualization to the web using animint2pages. Include a link to your rendered data viz along with your R source code. Even better: use animint2 to visualize some data from your domain of expertise. Show an example of an error that you see when animint2 is loaded/attached at the same time as standard ggplot2.
      Medium: translate an example of the animation package into an Animint. Do not do one of the examples that has already been ported. Post a link to your result on the Ports of animation examples page on the Animint wiki.
      look at source code of one of the animation package functions e.g. grad.desc() for a demonstration of the gradient descent algorithm. Translate the for loops and plot() calls into code that generates data.frames. In the grad.desc() example, there should be one data.frame for the contour lines, one for the arrows, and one for the values of the objective/gradient at each iteration.
      Use the data.frames to make some ggplots. In the grad.desc() example, there should be one ggplot with a geom_contour and a geom_path, and another ggplot with a geom_line that shows objective or gradient value versus iteration, and a geom_tallrect in the background for selecting the iteration number.
      Make a list of ggplots and pass that to animint2dir. For the grad.desc() example the plot list should be something like list(contour=ggplot(), objective=ggplot(), time=list(variable=”iteration”, ms=2000)).
      Medium-hard: first read about how to create a new gallery, then create one that organizes all of the data viz from the Ports of animation examples page.
      Hard: write a testthat unit test based on one of your Animint visualizations. Fork animint and add a renderer test (using animint2HTML) to tests/testthat/test-renderer-YOUR-TEST.R, then send us a Pull Request. Upload a screencast to youtube that shows you executing your test from the R command line (make sure to show two windows, a remote-controlled browser window rendering the data viz, and the R script/terminal that executes the test code).
      Solutions of tests
      Contributors, please post a link to your test results here.

      Your name, your solution here
      Tarun Choudhary, Easy , Medium-test-Solution , Medium-Hard-test-Solution , Hard-test-Solution
      Biplab Sutradhar, Solution
      Suhaani Agarwal , Solutions , Github

      ~~~~~~~~~~

      Time-dependent constraints in gfpop 350 Need contributor V Runge, G Romano C++

      time dependent constraints in gfpop
 
      Toby Dylan Hocking edited this page on Sep 2, 2024 · 1 revision
      Background
      There are many R packages for changepoint detection, which is an important problem in many application domains (genomics, finance, etc). A new changepoint model with up-down constraints has shown state-of-the-art peak detection accuracy in genomic data, and more general models like this can be implemented using the new gfpop package (Runge et al, arXiv:2002.03646).

      Currently the gfpop package only supports constraints which are valid for all time points. The goal of this project is to extend gfpop to allow constraints which depend on time. This will allow implementing fast optimal solvers for several new constrained changepoint models such as Labeled Optimal Partitioning.

      Related work
      Existing R packages fall into two categories:

      generic frameworks such as gfpop, Segmentor3IsBack, changepoint which allow computation of several different types of changepoint models. (but do not allow time dependent constraints)
      domain-specific packages such as LOPART, which computes one model with time dependent constraints (Gaussian loss, label constraints).
      Coding project: time dependent contraints in gfpop
      The goal of the coding project would be to extend gfpop to support time dependent constraints, so a wider variety of models could be specified in this framework.

      I think the easiest way to implement this from a R/C++ interface perspective would be to

      1. Allow user to pass to gfpop a new “rule” argument, a vector of length N (number of data) with entries that are integers which specify an update rule ID to use for each data point.
      2. Add a “rule” argument in the Edge function. This is an integer which should correspond to the IDs provided in 1.
      In practice this could be specified via R code like:

      LOPART.graph <- gfpop::graph(
        gfpop::Edge("normal",   "normal",   type="null", rule=1),
        gfpop::Edge("normal",   "normal",   type="std",  rule=1, penalty=5.5),
        gfpop::Edge("normal",   "normal",   type="null", rule=2),
        gfpop::Edge("noChange", "noChange", type="null", rule=2),
        gfpop::Edge("normal",   "noChange", type="std",  rule=2),
        gfpop::Edge("normal",   "normal",   type="std",  rule=3),
        gfpop::Edge("noChange", "normal",   type="null", rule=3),
        gfpop::Edge("normal",   "normal",   type="null", rule=4))
      gfpop::gfpop(data.vec, LOPART.graph, rule=data.table::fcase(
        unlabeled, 1,
        in.positive.label, 2,
        end.positive.label, 3,
        in.negative.label, 4))
      The idea in the code above is that the data.table::fcase call is like a switch statement that returns a vector with elements from 1 to 4 which specify what update rule/graph to use at each data point (variables unlabeled/in.positive.label etc above are logical vectors that depend on the provided label data in the LOPART model).

      Then when you compute the DP updates you can, instead of using all of the edges, you can instead just use the subset of edges which correspond to the ruleID of the current data point.

      The only tricky part is that we sometimes need to set a cost function to be infinity (if there are no edges coming to it at this data point) and the operators (min-less, min-more, min-env) need to be updated to handle the case of infinite inputs.

      The goal for GSOC will be to implement at least

      up-down constrained model with label constraints (6 rule IDs).
      usual changepoint model with 0/1 label constraints (4 rule IDs, shown in R code above).
      Expected impact
      The gfpop package is already very useful, and incorporating time-dependent constraints will make it more useful.

      Mentors
      Please get in touch after completing at least one of the tests below.

      EVALUATING MENTOR: Vincent Runge <vincent.runge@univ-evry.fr>
      Co-mentor: Toby Dylan Hocking <tdhock5@gmail.com>
      Tests
      Do one or several — doing more hard tests makes you more likely to be selected.

      NOTE: this is a very difficult GSOC project, and so the ideal contributor really should do all tests below. If we can’t find a contributor that can do all these tests, we should probably not fund this GSOC project.

      Easy: write an R function plotModel which takes a gfpop::graph as above and draws a matrix of nodes (one row for each state, one column for each rule) and edges.

      Medium: the Segmentor3IsBack package implements the segment neighborhood model (best models in 1,…,K segments) for the Poisson loss and no constraints, but there is no implementation available for the optimal partitioning model (best K-segment model for a single penalty parameter, without computing the models with 1,…,K-1 segments). The goal of this test is to modify the code in the PeakSegOptimal package, in order to implement a solver for the optimal partitioning problem with Poisson loss and no constraints. Begin by studying PeakSegFPOPLog.cpp which implements the optimal partitioning model for the Poisson loss and the up-down constraints. There are two states in this model, up and down. Since the up-down constrained solver has two states, there are N x 2 optimal cost functions to compute (cost_model_mat is of dimension data_count*2). The cost of being in the up state at data_i is cost_model_mat[data_i] and the cost of being in the down state is cost_model_mat[data_i+data_count]. The min_prev_cost.set_to_min_less_of(down_cost_prev) method enforces a non-decreasing constraint between adjacent segment means, for the state change down->up. Analogously, the PiecewisePoissonLossLog::set_to_min_more_of method enforces a non-increasing constraint for the state change up->down. To implement the unconstrained solver, you just need to implement a new PiecewisePoissonLossLog::set_to_unconstrained_min_of method that computes the minimum constant cost function (one PoissonLossPieceLog object), and then uses that to compute the N x 1 array of optimal cost functions (cost_model_mat). Read about the FPOP algorithm in Maidstone et al 2016 for more info. When you are done with your implementation, check your work by comparing with the output of Segmentor3IsBack::Segmentor(model=1). Perform model selection yourself for a range of penalty parameters. Using testthat, write some test cases which make sure your function gives the same exact model as the corresponding selected Segmentor model.

      Hard: there is not yet an regularized isotonic regression solver for the normal loss (issue), and your goal in this test is to implement one. Like the unconstrained model described the Medium test, the regularized isotonic regression model also has only one state. So you can start by modifying the Medium test code, which should have a cost_model_mat which is N x 1. However the isotonic regression constraint means that all changes are non-decreasing, so you should use set_to_min_less_of instead of set_to_unconstrained_min_of. Now the difficult part: the existing code in the coseg package implements the Poisson loss via class PoissonLossPieceLog, but you need to implement another class for the Normal loss, NormalLossPiece. This class will need to declare different coefficients Constant, Linear, Quadratic for a function f(mean)=Constant + Linear*mean + Quadratic*mean^2. You will need to provide implementations for get_smaller_root and get_larger_root by using the sqrt function in #include <math.h>. It will be judged even better if you can get PoissonLossPieceLog and NormalLossPiece to inherit from the same base class with shared methods (that is the approach that the Segmentor package uses to implement several loss functions, and that is the approach that will be recommended for this GSOC project). Check your work by writing a testthat unit test to make sure that the model returned by your function with penalty=0 is the same as the model returned by the isoreg function (PAVA algorithm). Write another test that checks that the output model is the same as Fpop (when all changes are non-decreasing).

      Solutions of tests
      Contributors, please post a link to your test results here.

      EXAMPLE CONTRIBUTOR 1 NAME, LINK TO GITHUB PROFILE, LINK TO TEST RESULTS.

      ~~~~~~~~~~
      dirichletprocess improvements 350 Need contributor Dean Markwick, TD Hocking ?

      Improving the performance of multivariate normal models in dirichletprocess
 
      Mikael Jagan edited this page 3 days ago · 5 revisions
      Background
      dirichletprocess is a package for fitting nonparametric Bayesian models. It's all written in R and is designed to be easily adapted and modified for easy nonparametric model building. You can drop in dirichletprocess model objects as part of your model without having to worry about the underlying inference routines or algorithms.

      Current multivariate normal sampling in the dirichletprocess package is slow and doesn’t scale with large dimensions or lots of data. This limits how the package can be used and restricts its overall adoption. By improving the performance for multivariate normal type models the number of applications and scale of the task sit can accomplish grows significantly. This will help people use Dirichlet process type models without having to implement their own sampling schemes and instead focus on the modelling work they are most interested in.

      Dean Markwick wrote this package as part of his PhD and it has also received multiple contributions from different authors over the years. It has received some notable citations from R Koenker and Chris Holmes.

      Related work
      Typical Dirichlet process packages require you to use their specified models and lack the flexibility in constructing custom models. They also use C++ and can be tricky to build upon, requiring more background knowledge.

      The mclust package implements EM algo with diagonal covariance matrices with several kinds of constraints (but only classical model selection, no Dirichlet process prior). M step update rules for constrained models are given in https://hal.inria.fr/inria-00074643

      Details of your coding project
      Try changing the imported package from mvtnorm to mc2d (function rmultinormal provides random normal generation vectorized on mean/covariance parameters, so it may be quicker). This requires making sure no functionality is broken after making the change and also benchmarking the difference to ensure there is an increase in performance (decrease in computation time and/or memory usage). Detailed benchmarking could also highlight other areas of potential improvement.
      The end result will provide: a. Robust benchmarking scripts. b. New methods that replace the mvtnorm with the mc2d package. c. Sufficient testing and checking that nothing has broken in the change over.

      Using a constrained covariance matrix. This introduces a new class of models for the multivariate normal distribution to allow for a constrained covariance matrix. This will reduce the number of free parameters and speed up
      The end result will provide: a. New class of mixture models. b. Tests to ensure the functionality is correct. c. Documentation and extension to the vignette detailing the new models.

      Expected impact
      Faster model fitting will help improve the reach of the package and make it a viable option for larger scale problems. Better performance also helps the environment, reducing the amount of CPU cycles needed.

      Mentors
      EVALUATING MENTOR: ???
      Other Dev: Toby Hocking toby.hocking@r-project.org
      Maybe Mentor: Dean Markwick dean.markwick@talk21.com. Finance quant, experienced in Bayesian statistics.
      IMPORTANT: Potential students would need to email Dean or one of the other authors (Gordon J. Ross [aut], Dean Markwick [aut, cre], Kees Mulder ORCID iD [ctb], Giovanni Sighinolfi [ctb], Filippo Fiocchi [ctb]) to see if one of them could be the main/evaluating mentor.
      Tests
      Contributors, please do one or more of the following tests before contacting the mentors above.

      Easy Download the package, fit the normal mixture model to the faithful data set. Fit the multivariate normal model on the iris or palmerspenguin dataset. Plot the resulting distribution for both models.

      Medium Generate some random data from a lognormal distribution mixture model. Fit a Dirichlet process type model to this simulated data. Sample new data from the posterior of the final model and summarise the 5%/95% quantiles of the simulated data. Explore how the prior distribution on the alpha parameter effects the number of clusters. Plot the alpha parameter chains after using different prior distributions to assess how long the model takes to converge.

      Hard Write the MixingDistribution objects and methods to implement your own custom mixture model. Fit this new mixture model to some new data (real or simulated) and plot the resulting posterior distribution. Write out the necessary equations underlying the mixture distribution to be included in the vignette.

      Solutions of tests
      Contributors, please post a link to your test results here.

      EXAMPLE CONTRIBUTOR 1 NAME, LINK TO GITHUB PROFILE, LINK TO TEST RESULTS.
      Vaibhav M, GitHub, Test Results
      Priyanshu Tiwari, GitHub, Test Results



      ~~~~~~~~~~
      data.table 175 or 350 Need contributor TD Hocking, A Chetia C

      Background
      The data.table package is an invaluable tool for data analysis and manipulation.

      Related work /impact
      data.table is one of the most widely used R packages.

      Details of your coding project
      Find one or more students to fix/close some of the hundreds of outstanding issues.

      Maybe would be good to start with the issues labeled as beginner-task.

      It would be easier for me if a student approached and said something like :

      “I want to do some serious C at low level”. I could then propose something there.
      “I want to write documentation/vignette/whitepaper”. Then I could suggest writing about data.table code that hasn’t been written about before.
      “I want to close 100 issues, one per day”. Then maybe I could pick the ones where that might be possible.
      “I want to work on performance testing / benchmarking”
      “I want to work on performance testing/ using atime for benchmarking”. I will teach on how to use atime to check if reported data.table issues have been fixed.
      Mentors/tests
      Test is to find an issue labeled as beginner-task,

      try to reproduce on your own computer, and report your results on the issue (were you able to reproduce? or not?)
      create a PR which would close that issue.
      When you have finished at least one test, please add a link to it on this page, then contact the following mentors:

      Toby Dylan Hocking @tdhock
      Anirban Chetia @Anirban166
      Doris Amoakohene @DorisAmoakohene
      Joshua Wu @joshhwuu
      Potential contributor test results (to edit)

      Contributor Name, link to issue, link to PR
      venom1204 issue1 pr for issue1,issue2 pr for issue2

      ~~~~~~~~~~
      sundialr-(Package-for-solving-ODEs-in-R) 175 or 350 Need contributor S Nayak C/C++

      sundialr (Package for solving ODEs in R)
 
      Dev Goel edited this page on Feb 3 · 2 revisions
      Background
      sundialr is an interface to the well-respected SUNDIALS Ordinary Differential Equations (ODE) solving library by Lawrence Livermore National Laboratory and Southern Methodist University. SUNDIALS provides some of the most advanced, accurate and stable solvers for solving ODEs, Partial Differential Equations (PDEs), Differential Algebraic Equations (DAEs), nonlinear algebraic systems etc.

      sundialr provides as interface to the cvode, cvodes, ida, idas solvers in SUNDIALS which can be used to solve and calculate sensitivities w.r.t. parameters and states for ODEs and DAEs. However, there are other solvers in SUNDIALs (e.g., KINSOL, ARKODE) to which an interface has not yet been created.

      In addition, a simplified interface to the multiple solvers, multiple methods for calculating sensitivities (e.g., adjoint method) needs to be provided. We also aim to add a simple interface to cover common patterns seen in systems described by ODEs such as discontinuity in Right Hand Side (RHS), root-finding, forcing functions to the sundialr functions.

      Related Work
      There is one more package that provides an interface to SUNDIALS, r2sundials, however it also does not provide an interface to all the solvers and methods in underlying SUNDIALS.

      Details of your coding project
      The full code for the R package on CRAN can be found here

      Expected impact
      sundialr aims to bring the best ODE, DAE and nonlinear algebraic solvers to R. We constantly update the package to incorporate changes in SUNDIALS and aim to provide full coverage of this excellent library to allow users to solve large scale systems of equations in R. sundialr should have a wide impact for all users modeling systems described by ODEs and PDEs.

      Mentors
      Satyaprakash Nayak - https://github.com/sn248

      I have extensive experience in developing R packages with complex build systems.

      I am an experienced drug development researcher with more than a decade of experience in R. More about me can be found at my LinkedIn page.

      Tests
      Contributors, please provide some examples of your R package development and C++ skills and sundialr package extensively uses Rcpp which requires knowledge of C++.

      Solution of Test
      Dev Goel, Solution

      ~~~~~~~~~~
      r2sbml-(An-interface-to-SBML-in-R) 175 or 350 Need contributor S Nayak C/C++

      r2sbml (An interface to SBML in R)
 
      Suhaani Agarwal edited this page last week · 3 revisions
      Background
      Systems Biology Markup Language SBML is an XML based free and open data format for computational systems biology for sharing models typically used in mathematical biology, systems biology and pharmacology. It has been developed since 2000 by a community of scientists and developers. More details about SBML can be found here.

      libSBML is a programming library that helps you read, write, manipulate, translate, and validate SBML files and data streams. The library supports all Levels and Versions of SBML. libSBML is written in ISO standard C++ and C and provides APIs for the languages C, C++, C#, Java, JavaScript, MATLAB, Perl, PHP, Python, R, and Ruby.

      r2sbml is an R package which aims to provide an interface to libSBML in R. Currently, it provides an easy way to read and output different aspects of the model, e.g., number of states, number of reactions, parameters etc. However, that is an interface to only very small portion of libSBML.

      Related Work
      There is libSBML R package available from libSBML library itself (link), but I have been unsuccessful in installing it so far.

      There is also SBMLR package in bioconductor, but it is quite old and does not seem under active development.

      Details of your coding project
      One of the main goals of the project will be to add capability to read SBML models and create a model in R which can be solved by using R's capabilities to solve Ordinary Differential Equations, i.e., create files which when loaded create a model, which can be solved in R using packages such as deSolve, mrgsolve, rxode2 and sundialr.

      Expected impact
      SBML is the standard method of communication between modelers to transfer their models between different software, collaborators or for publishing. However, there are no integrated tools to convert a XML file to a model which has clearly laid out the list of states (species), parameters, reactions etc. and is ready to be solved using ODE solvers.

      r2sbml tries to bridged that gap by outputting files which can be used to compile a model that can be solved in R using a variety of already available packages. This capability should greatly increase the ability to use an already published models, check their results and build upon them. We aim to provide a library which uses capabilities of libSBML to read and manipulate different types of systems biology models and aim to test the package with the wide variety of tests available in the SBML Test Suite.

      Mentors
      Satyaprakash Nayak - https://github.com/sn248

      I am an experienced drug development researcher with more than a decade of experience in R. More about me can be found at my LinkedIn page.

      Tests
      Please provide examples of R package development skills and C/C++ development skills.

      Solutions of tests
      Suhaani Agarwal : solution link , github profile
      ~~~~~~~~~~
      torchvision in R improvements 175 or 350 Need contributor C Regouby, TD Hocking C++

      torchvision in R improvements
 
      Mikael Jagan edited this page 3 days ago · 7 revisions
      Background
      torch is a popular package for machine learning, and specifically torchvision provides direct access to computer-vision models and datasets, but R support is missing some features compared to python.

      Related work
      keras/tensorflow in R interface with python, and so are even more difficult to install, compared to torch (uses C/C++ code).

      Details of your coding project
      Implement all of the torchvision data sets: https://github.com/mlverse/torchvision/issues/104
      Implement torchvision models covering 5 new computer-vision tasks:
      Object Detection model like FasterRCNN : https://github.com/mlverse/torchvision/issues/54#issuecomment-885201975 and SSD
      Instance Segmentation model like Mask R-CNN
      Keypoint Detection model like Keypoint R-CNN
      Semantic segmentation model like FCN
      Quantized models providing low footprint image embedding like Quantized ResNet
      Expected impact
      Torch and torchvision are extremely popular so this project could have a large impact.

      Mentors
      Contributors, please contact mentors below after completing at least one of the tests below.

      EVALUATING MENTOR: Christophe Regouby christophe.regouby@free.fr is the maintainer of one of the packages in the torch ecosystem, and contributor to many R packages.
      Toby Hocking toby.hocking@r-project.org is the author of numerous R packages, and has been mentor/admin for R-GSOC since 2013.
      Tests
      Contributors, please do one or more of the following tests before contacting the mentors above.

      Easy: install torch, follow instructions in one of the vignettes to make a figure using Rmd, show us your Rmd source and output HTML/PDF.
      Medium: adapt the Loading data vignette to the case of the spam data.
      Hard: fork torch and write a PR that adds your data loader for the spam data, along with tests and documentation.
      Solutions of tests
      Contributors, please post a link to your test results here.

      EXAMPLE CONTRIBUTOR 1 NAME, LINK TO GITHUB PROFILE, LINK TO TEST RESULTS.

      Prateek Kumar, GitHub Profile, Test Results

      Akanksha Koshti, GitHub Profile, Test Results

      ~~~~~~~~~~
      Optimizing a performance testing workflow by reusing minified R package versions between CI runs 175 Need contributor TD Hocking, Ani Shell
      

      Optimizing a performance testing workflow by reusing minified R package versions between CI runs
 
      PRIYANSHU edited this page on Jan 22 · 10 revisions
      Background
      Autocomment-atime-results is a GitHub Action (GHA) that tests the time/memory-based performance of the incoming changes that are introduced via Pull Requests (PRs) to a GitHub repository for an R package. (For more information on the GHA, feel free to check what I wrote for The-Raft)

      Currently, it is being used extensively in data.table, a well-known and highly-performant package for data manipulation and analysis.

      This action utilizes the atime package to execute various tests, each of which are run across different specified versions of data.table in order to help identify potential performance regressions and improvements in comparison against each other.

      Currently, the GHA rebuilds and reinstalls these numerous versions of data.table for each job run, which consumes a considerable amount of time and CI resources. By optimizing this workflow along the lines of the main idea posted in #6528 (which is to cache the versions that are the same for every PR, or to avoid the reinstallation of the historical data.table versions), substantial time efficiency or speedups in job runs can be achieved. Time savings would be proportional to the number of reusable versions, and the more lightweight these historical versions are in size, the more we can fit in within the limits of usage for the free tier.

      Additionally, it would be favourable to have the GHA support PRs originating from forks.

      Related work
      Caching CI Artifacts: Several GitHub projects leverage artifact caching to avoid redundant computations. For example:

      Actions Upload/Download Artifacts stores and retrieves build artifacts, reducing setup time.
      GitHub Actions Cache helps reuse dependencies like R packages and compiled binaries across CI runs.
      Package Optimizations: The R ecosystem has ways to minimize CI overhead, such as:

      Using --no-manual and --no-build-vignettes flags during R CMD INSTALL to skip non-essential build steps.
      Excluding documentation and tests during package building for deployment-focused workflows.
      The main goal is to incorporate these two fundamental strategies to reduce CI time by reusing simplified historical versions of data.table.

      Supporting all forks: Handling workflows for forked repositories often involves using pull_request_target events or selectively disabling steps that rely on sensitive data. Following best practices outlined in similar workflows is an option. For example:
      bencher.dev provides discussion on adapting actions to support forks.
      Details of your coding project
      The optimization primarily consists of two phases:

      Artifact Caching & Retrieval:

      Utilize upload-artifact to save precompiled versions of historical data.table releases after a CI run.
      Leverage download-artifact to retrieve them at the beginning of subsequent CI runs, avoiding recompilation of versions that are constant across PRs.
      Minimized Package Installation:

      Modify the R CMD INSTALL process to exclude unnecessary components such as documentation, vignettes, tests, and other large directories in order to significantly reduce package size and installation time. The "minified" build process will:
      Remove unnecessary files (NEWS.md for e.g.) and subdirectories (such as inst, man, tests, vignettes, etc.)
      Use installation flags (like --no-manual and --no-build-vignettes)
      Integration with the GHA

      Make modifications to this workflow to check for the availability of the precompiled artifacts - If they are available, download and install them directly; if not, rebuild minified versions and upload them as artifacts for future use. Simply put, one needs to:

      Update the step which includes installation of the different R package versions via atime to include the artifact download logic with appropriate branching (which involves changes in atime code as well).
      Modify the 'Upload results' step to save newly compiled historical versions.
      Finally, ensure that the current set of tests with historical references use cached versions of data.table and estimate the total version count this optimization can support (mileage would vary based on how 'minified' each version is in terms of size) keeping in mind the usage limit for the free tier of GitHub Actions (500 MB and 2k minutes/month at present).

      PRs from forks

      Adapt the workflow to securely handle PRs from forks. For example, making use of pull_request_target events to allow access to repository secrets for testing while avoiding exposure to untrusted code, disabling or modifying artifact upload steps to avoid conflicts or unauthorized access, and clearly documenting how contributors can trigger/debug workflows on forked repositories.

      Expected impact
      It should yield immediately visible benefits in terms of conserving the CI runtime for data.table on GitHub-hosted runners. Subsequently, this enables developers and contributors to iterate more quickly given the faster feedback loops on PRs. And by enabling support for PRs from forks, it will allow collaboration across a broader community of contributors (not restricted to project members).

      Mentors
      Contributors, please contact the mentors below after completing at least one of the tests below.

      EVALUATING MENTOR: Anirban Chetia ac4743@nau.edu
      Other mentors: Toby Hocking toby.hocking@r-project.org
      Tests
      Contributors, please do one or more of the following tests before contacting the mentors above.

      Easy - Given a tarball (e.g. data.table_1.16.99.tar.gz) of the data.table package, write a script that:
      Extracts it, then removes subdirectories and files that are not required for performance testing.
      Recreates a minimal version containing only the essential files for installation.
      Installs that package using R CMD INSTALL.
      Medium - Write a YAML snippet that:
      Checks if a precompiled artifact for a specific historical version of data.table exists.
      If it is found, it downloads and installs the artifact, else it builds the version from source, minifies it, and then uploads it as an artifact for future runs. (Name the artifacts based on version numbers for keeping them distinct)
      Implement a fallback mechanism in the workflow to build the missing version from source in case artifact retrieval fails.
      Hard - Modify my GitHub Action to:
      Incorporate the steps you took to create the workflow for the 'Medium' test.
      Log the time taken to use the precompiled artifacts (would be nice to numerically compare the difference in time with this feature versus without or when building from source) and the disk space utilized by the downloaded artifacts. Additionally, if you can think of any other useful metrics, feel free to include them with your rationale.
      Simulate some CI runs to observe the caching in effect and document gains.
      Make the workflow work with PRs from any contributor's fork. (Optional)
      Bonus points - Beyond minimizing packages and caching artifacts, identify one additional optimization that could further improve the performance of this workflow and share a working proof of concept. Make sure to provide links to the configured workflow and PRs demonstrating results.
      Solutions of tests
      Contributors, please post a link to your test results here.

      EXAMPLE CONTRIBUTOR 1 NAME, LINK TO GITHUB PROFILE, LINK TO TEST RESULTS.
      Sagnik Mandal , https://github.com/criticic , EASY , MEDIUM
      Priyanshu Yadav ,https://github.com/tech0priyanshu , https://github.com/tech0priyanshu/r-package-ci-optimization


      ~~~~~~~~~~
      Updates in VedicDateTime R Package 350 Need contributor ND Bokde, A Gupta

      Background
      The VedicDateTime R package is a powerful tool for working with dates and times in the Vedic calendar system. Over time, the package has proven to be highly useful, but there is still room for improvement. The current version has some limitations, including the need for enhanced accuracy, additional calendar system support, and expanded functionalities for better usability.

      In this project, we propose to update and enhance the VedicDateTime package by incorporating better algorithmic efficiency, improving the integration with modern R packages, introducing robust unit testing, and enhancing package modularity. These updates will significantly improve package usability and performance.

      Related work
      The VedicDateTime R package was originally developed in GSoC-2022 through two projects: Part A and Part B. The development details are available in this journal article.

      This project aims to refine and extend the package further to make it more precise, efficient, and user-friendly. The proposed enhancements will improve its reliability for researchers, historians, and those interested in Vedic timekeeping.

      Details of your coding project
      The goal of this project is to upgrade the VedicDateTime R package. The following updates are planned:

      Refactor package structure: Improve the modularity and maintainability of the package by reorganizing internal functions and implementing cleaner function interfaces.
      Enhance computational efficiency: Optimize existing functions using vectorized computations with the data.table and dplyr packages to improve performance.
      Expand compatibility with other R packages:
      Improve integration with lubridate for seamless datetime manipulations.
      Enhance support for tidyverse functions to make data wrangling easier.
      Provide better compatibility with ggplot2 for visualizing Vedic date-time information.
      Implement robust unit testing:
      Use testthat and covr to ensure code coverage and reliability.
      Include comprehensive test cases to validate Vedic-Gregorian conversions and date-time computations.
      Introduce API improvements:
      Implement function aliases to improve usability and make functions more intuitive.
      Provide better handling of missing or incorrect inputs with informative error messages.
      Improve documentation and vignettes:
      Provide detailed function documentation using roxygen2.
      Add more real-world use cases and expanded examples in the vignettes.
      Create a tutorial for first-time users with sample workflows.
      Expected impact
      These enhancements will significantly improve the performance, modularity, and usability of the VedicDateTime package. The updated package will allow users to efficiently integrate Vedic timekeeping into modern analysis frameworks while ensuring better accuracy and ease of use. Additionally, improved documentation and robust unit tests will facilitate long-term maintenance and community contributions.

      Mentors
      EVALUATING MENTOR:

      Neeraj Dhanraj Bokde, Senior Researcher, Technology Innovation Institute, Abu Dhabi, and former Assistant Professor at the Center for Quantitative Genetics and Genomics, Aarhus University, Denmark. neerajdhanraj@gmail.com.

      Neeraj has a Ph.D. in Data Science and has contributed to several R packages related to time series analysis, testbenches, and domain-specific applications. Neeraj has been a GSoC mentor since 2020. https://www.neerajbokde.in/

      Aditya Gupta, Researcher at the University of Agder, Norway, with extensive experience in data science. Aditya has a Ph.D. in data-driven solutions for environmental issues. adityagupta2590@gmail.com

      Tests
      Students, please complete one or more of the following tests before contacting the mentors:

      Easy: Download the VedicDateTime package and demonstrate it with a naturally occurring time series. Document your findings with RMarkdown.
      Medium: Suggest possible updates or a new feature you would like to include in the next version of the package and justify its importance.
      Hard: Develop a dummy implementation of five functions along with a vignette and pass it with no Error/Warning/Note through https://win-builder.r-project.org/.
      Solutions of tests
      Students should post a link to their test results below:

      Contributor Name	GitHub Profile	Test Results
      Niall Unani	GitHub	Medium Hard

      ~~~~~~~~~~
      imputeTestbench for multivariate time series 350 Need contributor A Gupta, ND Bokde

      imputeTestbench for multivariate time series
 
      Mayank85Y edited this page 13 hours ago · 4 revisions
      Background
      Data cleaning remains one of the most critical and time-consuming steps in Data Science and Data Analytics. Over the years, numerous methods have been proposed for data cleaning processes such as imputation, outlier detection, formatting, and visualization. Evaluating these methods rigorously for large and complex datasets is a major challenge. Tools like the cleanTS R package (Publication) have made significant strides by automating some of these steps.

      One of the core dependencies of cleanTS is the imputeTestbench package (Publication). This package automates performance evaluation and comparison of various imputation methods for time series data. Currently, imputeTestbench primarily supports univariate time series imputation and lacks robust capabilities for multi-variate or large-scale datasets.

      In last year's proposal, we introduced plans to extend imputeTestbench to handle multivariate time series efficiently. Now, we aim to incorporate additional updates and advanced features for improved computational performance and broader applicability. This will include features such as parallelization, integration with modern HPC frameworks, and advanced data structures for time series.

      Related work
      The imputeTestbench package builds on the AutoML concepts for time series imputation, generating missing patterns automatically and evaluating multiple methods simultaneously. Our proposed updates will make imputeTestbench compatible with multivariate datasets and complementary packages like cleanTS, enabling streamlined, end-to-end time series cleaning.

      Details of your coding project
      The goal of this project is to evolve imputeTestbench into a robust, multivariate-ready, and high-performance R package. Key tasks include:

      Multivariate extension:

      Adapt the existing tool to handle multivariate time series from multiple domains (e.g., environmental, financial, sensor data).
      Introduce flexible imputation pipelines that support correlated series, ensuring consistent missing value treatment across multiple variables.
      Enhanced performance & HPC integration:

      Migrate data structures to data.table or equivalent to handle large-scale time series data more efficiently.
      Integrate parallel computing solutions such as future, foreach, or HPC backends to reduce computation time.
      Optionally explore solutions with Apache Spark or distributed computing frameworks for extremely large datasets.
      Advanced imputation methods:

      Embed modern and state-of-the-art time series imputation techniques (e.g., machine-learning-driven approaches, deep learning methods, or advanced statistical models).
      Offer a plugin interface or bridging with Python libraries (using reticulate) for specialized imputation methods.
      Shiny dashboard and improved user interface:

      Develop or refine a Shiny-based dashboard for an interactive user experience.
      Provide real-time visualization of imputation methods’ results, performance comparisons, and parameter tuning.
      Extensive testing & documentation:

      Ensure robust unit testing using testthat with high code coverage.
      Provide comprehensive vignettes illustrating how to use the new features, including step-by-step workflows for multivariate data.
      Document HPC integration details and recommended configurations.
      Expected impact
      With these updates, imputeTestbench will transform into a more powerful AutoML tool for time series imputation. It will support multi-dimensional datasets, modern HPC frameworks, and advanced data structures, making it easier for researchers and practitioners to:

      Rapidly benchmark multiple imputation methods on large or complex datasets.
      Scale computations across local multicore systems or distributed HPC environments.
      Generate reproducible workflows using robust testing and improved documentation.
      Ultimately, this will accelerate and standardize time series imputation in domains such as finance, environmental monitoring, sensor networks, and more.

      Mentors
      Aditya Gupta (Evaluating Mentor): Postdoc at the University of Agder, Norway. Has a Ph.D. in data-driven solutions for environmental issues, currently working on AI for Sustainable Aquaculture. adityagupta2590@gmail.com

      Neeraj Dhanraj Bokde: Senior Researcher at Technology Innovation Institute, Abu Dhabi, and former Assistant Professor at Aarhus University, Denmark. neerajdhanraj@gmail.com. Has a Ph.D. in Data Science and has contributed to multiple R packages on time series analysis.

      Tests
      Students, please do one or more of the following tests before contacting the mentors:

      Easy: Download the imputeTestbench package and demonstrate it on a naturally occurring time series. Document it with RMarkdown.

      Medium: Suggest a new feature or enhancement you would like to see in the next version of the imputeTestbench package.

      Hard: Develop a dummy implementation of five new functions and create a vignette, ensuring it passes with no Error/Warning/Note via https://win-builder.r-project.org/.

      Solutions of tests
      Contributors, please post a link to your test results below:

      Contributor Name	GitHub Profile	Test Results
      Avinab Neogy	avinabneogy23	Solution
      PRIYANSHU	tech0priyanshu	Solution
      Mayank Yadav	Mayank85Y	Solution

      ~~~~~~~~~~
      DBmaps R Package Development 175 Need contributor D Shilane, TD Hocking

      DBmaps R Package Development
 
      Yue(Zelda) Zhang edited this page 2 days ago · 8 revisions
      Background
      The goal of this project is to develop a software package (tentatively named DBmaps) to facilitate the analyses of data from a relational database. Joining/merging tables is often fundamental to this work so that information from different tables can be linked in the same resulting data structure. Currently, this requires significant practical knowledge of the tables, including the ways in which information can be merged and the key variables that link pairs of tables together. Especially in a complex database, the relevant information may only be indirectly linked, potentially through a chain of intermediate tables.

      To that end, this project seeks to construct a set of tools that will automate some of these tasks. Producing a map of the database will help to show the ways in which information can be joined/merged between pairs of tables. This map can be specified by the user, which serves as documentation about their knowledge of the database. Portions of the map can also be potentially filled in through an automatic identification of tables that can be joined and the best candidates for linking variables. A search algorithm can be used to explore the map. The eventual goal is for a user to select the variables from specific tables and to automate the production of the resulting data set.

      Related work
      Within R, there are efficient tools in place for joining/merging tables. However, no package exists to automatically explore the relations between tables in a database, to construct a map of these relations, or to automate joining/merging of indirectly linked variables through intermediate tables.

      Details of your coding project
      The package will include development of a number of important functions for database exploration, mapping, and merging.

      create.DB.map: Construct a data.frame or data.table object. Each row includes tables x and y, an indicator of whether they can be joined/merged, the linking variables by.x and by.y. Optional columns will include the type of join/merge (left,right,inner,outer) and potential aggregations within each table (x and y), such as grouped sums. This is a new function that would be coded in R from scratch.

      map.DB.pairs: Starting with a list of tables, search each pair to establish whether a) the two tables can be joined/merged, and b) the linking variables by.x and by.y that would facilitate the merge. Linking variables would be suggested based upon either the similarities of names or containing the same unique values. This is a new function that would be coded in R from scratch.

      multi.merge: Starting with a list of tables, linking variables, and joining types, perform sequential merging of all of the tables. This would reduce the coding labor of calling nested merges, such as merge(a, merge(b, merge(c, merge(d, merge(e, f))))). This function would be coded in R based upon enhancing a working prototype.

      materialized.view: Starting with inputs of a) the user's selected variables from specific tables in the database and b) a mapping of the database as constructed by create.DB.map(), automatically generate a materialized view. This involves using the database map to merge tables, potentially through intermediate links, and also potentially while performing aggregations such as grouped computations on some tables. This is a new function that would be coded in R from scratch.

      visualize.DB.map: Given a mapping of the database as constructed by create.DB.map(), build a visualization that shows the relationships between tables, links, and potential aggregations. This is a new function that would be coded in R from scratch.

      Expected impact
      Producing an automated mapping of a relational database will help facilitate exploration of the data and documentation of the links. This will help analysts more quickly understand the structure of the database and the ways in which data from various tables can be brought together into materialized views. This will also reduce the coding labor and potential for mistakes in joining/merging multiple tables.

      Mentors
      EVALUATING MENTOR: David Shilane david.shilane@columbia.edu is the author of 7 R packages (formulaic, getDTeval, DTwrappers, DTwrappers2, simitation, nRegression, and tvtools).
      Co-mentor Toby Dylan Hocking has experience in 10+ years of R-GSOC.
      Tests
      Contributors, please do one or more of the following tests before contacting the mentors above.

      Easy: Consider the following data.table objects:

      library(data.table)

      students <- data.table(id = c("A", "B", "C", "D"), Birthdate = c("2001-08-04", "2002-04-28", "2002-06-13", "2002-02-09"))

      scores <- data.table(id = c("B", "C", "E"), homework = c(87,94,92), quiz = c(91, 90, 87))

      Use the merge() function to perform the four types of merges. Show the code and the outputs.

      Medium: Write a function that will merge tables x and y and then merge this combined table with another table z. Make sure your function includes any relevant parameters.

      Hard: Can the contributor write a package with Rd files, tests, and vignettes? Show examples of any work you've contributed to in building an R package.

      Solutions of tests
      Contributors, please post a link to your test results here.

      EXAMPLE CONTRIBUTOR 1 NAME, LINK TO GITHUB PROFILE, LINK TO TEST RESULTS.
      Sagar Udasi, GitHub Profile, Test Results
      Divendra Yadav, GitHub Profile, Test Results
      Akshat Maurya, GitHub Profile, Test Results
      Disha Davey, GitHub Profile, Test Results
      Yue(Zelda) Zhang, GitHub Profile, Test Results
      Please do not edit this footer! Instead click Edit button in upper right.

      ~~~~~~~~~~
      grepreaper R Package Development 175 Need contributor D Shilane, TD Hocking grep

      grepreaper R Package Development
 
      ayraa.ai edited this page last month · 2 revisions
      Background
      This project aims to develop an R software package (grepreaper) for advanced file reading applications. Many tools for basic file reading are available within R's packages. These tools include some parameters, such as skipping preliminary rows or limiting the read to a specified number of records. However, a number of capabilities can be enabled by linking file reading to grep at the command line. Some of these features include:

      Counting the number of records prior to reading the data.
      Extracting only the records that match a specified pattern.
      Reading and aggregating data from multiple files simultaneously (assuming identical structures).
      Within the data.table package, the fread() command enables users to specify their own command-line statements. This allows users to run their own grep commands or use other tools. With that said, command-line programming syntax is specialized and not necessarily familiar to many users of R. To that end, the grepreaper package aims to develop wrapper functions that will facilitate these advanced capabilities. With these tools, R users can benefit from advanced file reading capabilities without having to learn command-line tools. With grepreaper, everyone can reap the rewards of programming with grep.

      Related work
      To our knowledge, there are no existing packages that build grep wrappers for advanced file reading. The authors of this package are also working on a companion package for file reading with AWK at the command line.

      Details of your coding project
      The package will include development and revision of a number of functions:

      grep.count: Count the number of relevant rows of data in one or more files, overall or matching search patterns.

      grep.read: Read and aggregate data from one or more files while allowing for pattern matching.

      The coding process will involve using R to perform a few tasks: a) use string-printing techniques to construct the grep statement, b) build variations on the coding statement to match different types of pattern-matching (such as full or partial patterns, along with regular or inverted matches), and c) read the files through data.table's fread() command. Ideally these functions will also provide options to show either a) the resulting counts/data, b) the command-line grep statement, or c) both. You will begin with some partially-developed code that can be revised and expanded upon.

      Expected impact
      This package will create user-friendly wrapper functions that facilitate connections between R and command-line grep. These tools will enable R users to read and aggregate data from multiple files, search a range of files for matching patterns, and identify the size of the potential data prior to reading. This will give many R users more tools for file reading.

      Mentors
      EVALUATING MENTOR: David Shilane david.shilane@columbia.edu is the author of 7 R packages (formulaic, getDTeval, DTwrappers, DTwrappers2, simitation, nRegression, and tvtools).
      Co-mentor Toby Dylan Hocking has experience in 10+ years of R-GSOC.
      Tests
      Contributors, please do one or more of the following tests before contacting the mentors above.

      Easy: Consider the diamonds data from the ggplot2 package:

      library(ggplot2) library(data.table) data(diamonds)

      Within R, use a call to the grep() function to identify rows of data that match the pattern 'VS'. Count the number of qualifying rows.

      Medium: Within the data.table package, write a call to fread() that feeds a command-line grep statement into the cmd parameter. Use this to count the number of rows that match the pattern 'VS'.

      Hard: Can the contributor write a package with Rd files, tests, and vignettes? Show examples of any work you've contributed to in building an R package.

      Solutions of tests
      Contributors, please post a link to your test results here.

      EXAMPLE CONTRIBUTOR 1 NAME, LINK TO GITHUB PROFILE, LINK TO TEST RESULTS.
      Aarya Pandey, GitHub Profile, Test Results
      Please do not edit this footer! Instead click Edit button in upper right.

      ~~~~~~~~~~
      spinebil: Package to provide diagnostics for projection pursuit 350 Need contributor D Cook, J Leung, U Laa
      spinebil: Package to provide diagnostics for projection pursuit
      
      Dianne Cook edited this page last week · 2 revisions
      Background
      This project will enhance the spinebil package to equip it with new methods for diagnosing projection pursuit (PP) indexes.

      Related work
      The package ferrn provides diagnostics for the projection pursuit guided tour, which is available in the tourr package. The paper by Laa et al describes methods currently available in the spinebil package. This paper also has numerous references to the projection pursuit literature.

      Details of your coding project
      The project involves

      preparing the package for acceptance on CRAN
      adding routines that can assess PP index behaviour, that include
      the practical scale observed,
      the change in function as the projection goes from pure noise to pure structure
      the effect of sample size on index expected value, and selected quantiles
      test these routines on existing indexes
      provide examples of usage of the new functionality
      develop revised scagnostic indexes that have better behaviour
      document code
      write a vignette with example usage
      Expected impact
      The availability of this package will enable better development and testing of new projection pursuit indexes. Projection pursuit is widely used to reduce dimension of high-dimensional data sets, to capture structure and associations that cannot be seen from principal component analysis. It is a linear dimension reduction method, so that it doesn't suffer from hallucinations occurring from non-linear dimension reduction methods like t-SNE and UMAP.

      Mentors
      Contributors, please contact mentors below after completing at least one of the tests below.

      EVALUATING MENTOR: Di Cook dicook@monash.edu is the author of numerous R packages including tourr, nullabor, GGally, and has had extensive GSOC experience since 2012.
      Co-mentor: Jess Leung jessica.leung@monash.edu is an in optimisation.
      Co-mentor: Ursula Laa ursula.laa@boku.ac.at is the current maintainer of the spinebil package, and has two years of GSOC experience.
      Tests
      Contributors, please do one or more of the following tests before contacting the mentors above.

      Easy: Fork the package and run the package checks using devtools. Make the fixes needed for it to pass CRAN checks.
      Medium: Add a GitHub Actions workflow to automate the CRAN checks when code is pushed to the GitHub.
      Hard: Write a simulation to check the minimum and maximum values that we might observe for any 2D pattern for the stringy index available in tourr package. Report the data generated for testing, and the minimum and maximum values that would be expected.
      Solutions of tests
      Contributors, please post a link to your test results here.

      EXAMPLE CONTRIBUTOR 1 NAME, LINK TO GITHUB PROFILE, LINK TO TEST RESULTS.

      ~~~~~~~~~~
      ecotourism: data package containing tourism records and endangered wildlife reports 350 Need contributor D Cook, L Cook
      ecotourism: data package containing tourism records and endangered wildlife reports
 
      Andrew Harper edited this page 2 days ago · 7 revisions
      Background
      This project will provide a data package that can be used for teaching. It can be used to teach visualisation of data with maps, temporal data and making basic plots.

      Related work
      An example package is nycflights13 that contains multiple linked tables. It is motivation to make a similar data set on tourism records related to wildlife sightings available.

      Details of your coding project
      The project involves

      pulling records from three different databases, subsetting and organising
      spatially and temporally match records to provide tables
      document code for creating and updating the data
      write a vignette with example usage
      prepare the package for CRAN submission
      Expected impact
      Data packages have made substantial impact on the community. They are used in classrooms for teaching, and for examples in published research. A great example is the palmerpenguins.

      Mentors
      Contributors, please contact mentors below after completing at least one of the tests below.

      EVALUATING MENTOR: Di Cook dicook@monash.edu is the author of numerous R packages including tourr, nullabor, GGally, and has had extensive GSOC experience since 2012.
      Co-mentor: Lyn Cook l.cook@uq.edu.au is an expert in Australian wildlife.
      Tests
      Contributors, please do one or more of the following tests before contacting the mentors above.

      Easy: Download the occurrence data of platypus in Australia from the Atlas of Living Australia, and make a map showing the spatial locations of sightings for 2024.
      Medium: Use the GSODR to download one year of daily weather data including temperature and precipitation for a station in Victoria, Australia near where large numbers of platypus are spotted.
      Hard: Taking the names of tourism locations described in this variable Stopover state/region/SA2 from the data-raw/domestic_trips_2023-10-08.csv write code to geocode the locations with latitude and longitude.
      Solutions of tests
      Contributors, please post a link to your test results here.

      Dev Goel, Test Solutions
      Harshitha, Test Results
      Andrew Harper Test Solutions
      ~~~~~~~~~~
      Structured covariance matrices for lme4 175 or 350 Writeup in progress B Bolker, E Tanaka, M Jagan possibly some C++
      Background
      Mixed models, also known as mixed-effects models or hierarchical models, are a class of statistical model that incorporates fixed and random effects. These models are widely used where data are correlated or structured, e.g. repeated measures, longitudinal, clustered or hierarchical data, which are common across numerous disciplines. With the exception of the recommended package nlme (which predates R itself), lme4 is the most widely used package for mixed models; it provides several capabilities (generalized models, crossed random effects) that are either impossible or difficult to achieve with nlme.

      However, unlike nlme, lme4 does not allow for structured covariance matrices in random-effects terms (e.g. compound-symmetric, autoregressive, etc.); such matrices are useful both as a way to simplify overly complex models, and to incorporate known structure (e.g. temporal, spatial, or phylogenetic) when estimating random effects.

      This project aims to add these capabilities to lme4.

      Related work
      as mentioned above, nlme provides access to some structured covariance matrices (and other packages, such as ape, extend these capabilities). Although the architecture of nlme and lme4 are completely different, we can use the stuff from nlme both as test/comparison cases, and as inspiration (e.g., the value of a modular/extensible/object-oriented framework for structured covariance matrices).
      such a project was attempted before (see this branch), but was abandoned 11 years ago for a variety of reasons. We can re-use some of this material but will also take lessons from some of the reasons it failed (e.g., premature branching failed to maintain back-compatibility with "base" lme4)
      The glmmTMB package supports a variety of structured covariance matrices (although not in a modular way). We will be able to re-use some of the formula-processing machinery (implemented in the reformulas package).
      The Bayesian/sampling-based MCMCglmm and (to some extent) brms also provide covariance structures. These will be useful mostly for inspiration, since the internal architectures are very different.
      The INLA package provides tools for constructing efficient, spatially structured precision matrices (the inverse of the covariance matrix); it would be nice to be able to take advantage of it, but may not be feasible because the architecture of lme4 is heavily based on Cholesky factors (a matrix square root of the covariance matrix) rather than precision matrices (or Cholesky factors of precision matrices).
      the pedigreemm package implements kinship/pedigree structures in mixed models on top of lme4 machinery. We might be able to incorporate some of this machinery (although more of the code is written in C++, and the methods might be too specialized for easy re-use).
      Details of your coding project
      We will start by reviewing the flexLambda branch to see what aspects of the design, and what parts of the original code, can be re-used vs. needing to be rethought/rewritten.
      This is a good case for test-driven development; we will start by building tests based on fitting with covariance structures available in nlme and glmmTMB
      Our minimal goal is a completely backward-compatible modular structure that implements classes for (at least) diagonal and AR1 covariance structures, including documentation and tests
      Classes will need to include their own print() methods
      An additional feature will be an up2date() function similar to glmmTMB::up2date() which allows re-use of saved models from previous versions of lme4
      Expected impact
      As discussed above, lme4 is one of the most widely used mixed model packages, with strong support from downstream methods. Covariance structures are one of its most important missing features. While other packages (glmmTMB/MCMCglmm/brms) also provide these structures, lme4 is the best scaling method in some cases; its different internal architecture provides diversity in the mixed model ecosystem.

      Mentors
      EVALUATING MENTOR: Ben Bolker bolker@mcmaster.ca is the maintainer of lme4 and an active contributor to glmmTMB. He has previous experience with GSOC (phylobase (as mentor, 2008), directlabels (as co-/secondary mentor, 2021))
      Emi Tanaka emi.tanaka@anu.edu.au is the author of the edibble and nestr CRAN packages and co-maintainer of the Mixed Models task view
      Mikael Jagan jaganmn@mcmaster.ca is an author of the recommended Matrix package and maintainer of several other CRAN packages, and is an active contributor of detailed bug reports and patches for base R.
      Contributors, please contact mentors above after completing at least one of the tests below.

      Tests
      Contributors, please do one or more of the following tests before contacting the mentors above.

      Easy: Write a shell script to be run in the top level directory of the lme4 sources (containing file DESCRIPTION). The script should ensure that all dependencies of lme4 are installed in the user library, then build a source tarball, then perform a check on the source tarball. Run the script and include in your submission the installation and check output from the check directory. If the output suggests problems with your set-up, then fix the problems and try again.

      Medium: Use the modular framework described in ?lme4::modular to write two R functions implementing (some kind of) structured covariance matrices, first by writing a wrapper for the objective function and then by hacking the reTrms list object.

      MJ: Is the task to implement two covariance matrix structures or to write two functions implementing one covariance matrix structure ... ?

      ET: Perhaps switch this one to Hard and below to Medium? This test is close to the objective of the project.

      Hard: Submit a pull request fixing one of the issues in the lme4 GitHub repository. An ideal patch will make minimal necessary changes to the R sources, improve the documentation (where appropriate), and add suitable regression tests. Some suggested issues: #705, #555, #464, #396.

      MJ: I've "suggested" these but feel free to amend.

      Solutions of tests
      Contributors, please post a link to your test results below.

      Contributor Name	GitHub Profile	Test Results

      ~~~~~~~~~~
      pandemonium: GUI for cluster analysis with interactive visualization 350 Need contributor U Laa, G Valencia
      Background
      Cluster analysis is searching for groups of similar observations in a dataset, and can be used to uncover hidden patterns. Many different algorithms have been developed, and they generally come with tuning parameters that can substantially change the clustering solution. Exploring the different choices can provide different insights into the data. In this project we want to use cluster analysis to understand patterns for observations that are represented in two distinct multivariate spaces. For example in physics we might be interested in how parts of a multivariate parameter space for a theoretical model map onto patterns seen in observable space defined by model predictions computed for different measurements. Another example is in hydrology, where we may be interested in the connection between biotic (e.g. distribution of landscapes, ecosystems, communities) and abiotic (e.g. topography, climatic variables, extent of surface water) variables. Finally we can also imagine applications in the exploration of machine learning models, for example exploring the connection between the input variable space with a latent layer in an autoencoder neural network.

      Exploring cluster solutions from one space across the other space will be used to gain insights, and an interactive interface should be used to allow the user to explore different settings in the algorithm for a detailed exploration. This will be implemented in an R Shiny app, and making use of different strategies for multivariate data visualization in connection with cluster analysis.

      Related work
      A prototype of such a Shiny app has been implemented in the pandemonium R package available via GitHub (https://github.com/uschiLaa/pandemonium) and is tailored for one specific physics application, see https://doi.org/10.1140/epjp/s13360-021-02310-1 for details. It uses hierarchical clustering, allows interactive selection of tuning parameters such as the distance metric or the linkage, and includes 8 tabs that use different approaches to investigate the cluster solution across the two spaces, for example parallel coordinate plots, tour visualization and non-linear dimension reduction.

      Details of your coding project
      Starting from the prototype, the aim will be to change this tailor-made app into a general purpose tool that can be applied to any setting where cluster analysis can be used to understand connections between two representation spaces of the same observations. In addition, we will further explore what visualizations are useful, and in particular the options of including interactive visualizations and slice tour visualizations. The app will be developed as an R package and should be made available via CRAN at the end of the project.

      Expected impact
      The package will make exploration of clustering solutions across connected data spaces available in an interactive app, and this will make tools from cluster analysis and multivariate data visualization accessible in a wide range of applications.

      Mentors
      Contributors, please contact mentors below after completing at least one of the tests below.

      EVALUATING MENTOR: Ursula Laa (ursula.laa@boku.ac.at) has written the prototype app and has extensive experience with multivariate data visualization and the development of R packages. She has mentored a successful GSoC project in 2024.
      Co-mentor: German Valencia (german.valencia@monash.edu) will provide expertise for physics applications and how clustering and multivariate visualization can be applied in those settings.
      Tests
      Easy: install the prototype app pandemonium from GitHub and run the included example. Find two clustering settings that produce very different results.
      Medium: Use the detourr R package to generate two different tour paths of any example data, show both tours side-by side with linked brushing between the two displays.
      Hard: Embed the linked display from detourr in the pandemonium app and submit a pull request.
      Solutions of tests
      Contributors, please post a link to your test results here.

      EXAMPLE CONTRIBUTOR 1 NAME, LINK TO GITHUB PROFILE, LINK TO TEST RESULTS.
      Divendra Yadav, GitHub Profile,Easy Solution,Medium Solution,Hard Solution
      ~~~~~~~~~~
      Enhancing the Jaya R Package for Efficient Optimization 350 Need contributor V Tiwari, ND Bokde
      
      Background
      The Jaya R package implements the Jaya optimization algorithm, a gradient-free, population-based method suitable for solving both single-objective and multi-objective optimization problems. Jaya stands out for its simplicity and effectiveness, as it requires no hyperparameter tuning. Although the current version (1.0.3) offers robust foundational features, opportunities remain to enhance its computational efficiency, expand usability, and improve its integration with the broader R ecosystem.

      This GSoC project proposes to significantly upgrade the Jaya package by optimizing existing algorithms, enhancing parallel computation capabilities, improving compatibility with widely-used R packages, and strengthening overall usability and maintainability.

      Related Work
      The Jaya algorithm, introduced by Rao (2016), has demonstrated effectiveness in diverse optimization contexts. The Jaya R package, created by Neeraj Bokde, implements the core features detailed in Rao's work, including adaptive population adjustment and Pareto-based multi-objective optimization.

      The package has seen positive adoption in academia and industry, but additional improvements in performance, modularity, and usability are necessary to support advanced research applications and integration into broader optimization workflows.

      Details of the Coding Project
      The following enhancements will be implemented in the Jaya package:

      1. Algorithmic Efficiency Improvements:
      Optimize performance-critical loops and operations using vectorized functions from data.table or base R.
      Refactor key internal functions to significantly reduce computational overhead.
      2. Enhanced Parallel Computation:
      Extend parallel computing capabilities using the future and furrr packages to support cross-platform, scalable parallelization.
      Improve efficiency for large-scale optimization problems.
      3. Expanded Compatibility with Popular R Ecosystem:
      Provide seamless integration with optimization and data analysis packages such as tidyverse, data.table, and visualization tools such as ggplot2 for intuitive interpretation of optimization results.
      Enhance interoperability with packages such as mlr3 and caret for improved usage in hyperparameter tuning tasks.
      4. Robust Unit Testing and Continuous Integration:
      Implement comprehensive unit testing using testthat and monitor test coverage using covr.
      Establish continuous integration workflows via GitHub Actions to maintain software quality and reliability.
      5. User-Friendly API Improvements:
      Introduce intuitive function aliases and a streamlined interface for easier adoption by new users.
      Enhance input validation and error handling with clear, actionable messages.
      6. Comprehensive Documentation and Tutorials:
      Enrich documentation with detailed examples and workflows, clearly documented using roxygen2.
      Develop vignettes and interactive tutorials demonstrating real-world optimization scenarios.
      Expected Impact
      These enhancements will significantly improve the computational performance, usability, and user adoption of the Jaya package. The updated version will facilitate integration into modern optimization and machine learning workflows, thus benefiting researchers, industry practitioners, and educators. Comprehensive documentation and robust unit testing will ensure the long-term sustainability and ease of community contributions.

      Mentors
      Evaluating Mentor:
      Neeraj Dhanraj Bokde, Senior Researcher at Technology Innovation Institute, Abu Dhabi, and creator of the Jaya package. Neeraj holds a Ph.D. in Data Science, with extensive experience in R package development, optimization algorithms, and GSoC mentorship. neerajdhanraj@gmail.com, https://www.neerajbokde.in/

      Varun Tiwari, Senior Researcher at the DEWA R&D Center, Dubai. Varun has substantial experience in optimization, data-driven modeling, and algorithmic development. varun.etrx@gmail.com

      Tests for Students
      Students should complete at least one test before contacting mentors:

      Easy: Install and demonstrate usage of the current Jaya package for optimizing a simple optimization problem. Provide documentation in RMarkdown.
      Medium: Propose a specific feature or algorithm improvement for inclusion in the package, clearly justifying its value.
      Hard: Implement a basic prototype of proposed new functionality, including associated tests and a minimal vignette. Ensure the package builds successfully with no Error/Warning/Note via win-builder.
      Test Solutions
      Students should submit their test results below:

      Contributor Name	GitHub Profile	Test Results
      Vaibhav Manihar	Github	Test Results
      Priyanshu Tiwari	Github	Easy & Medium Tasks, Hard Task (Package Implementation)
      ~~~~~~~~~~
      Refining the R Dev Container 350 Need contributor H Turner, I Emsley, A Shirdhankar bash

      Background
      The R Dev Container provides a containerised development environment for editing and compiling the R source code. This is especially helpful for new or ad-hoc contributors to base R, as they can save the time and trouble of setting up their own system to build R and focus on code/documentation development.

      The current container uses the VSCode IDE and is designed to be used on GitHub Codespaces or as a Gitpod Workspace (via a GitHub, GitLab, or Bitbucket account), so that people can work in the dev environment through their browser. It is possible to use the container with a local installation of VS Code via Docker Desktop, but this is currently only recommended for Linux users.

      This project aims to make the container useful for a wider range of contributors, by modifying the container to support debugging compiled code and updating the build process so that the container can be used locally by macOS and Windows users. Improved support for local use will provide the foundation to use the container with alternative IDEs, including Positron.

      Related work
      The R Dev Container was first developed for GitHub Codespaces under the Containerized Development Environments for R Google Summer of Code (GSoC) project in 2023. The follow-on project Enhancing the R Dev Container adapted the container to work on Gitpod, as well as implementing a number of enhancements such as using an HTTP graphics device, adding helper scripts to work with multiple builds of R and extending the documentation.

      See the project reports from 2023 and 2024 for more detail.

      Details of your coding project
      There are three improvements we would like to prioritise for this GSoC project:

      Modifying the container configuration to enable debugging with LLDB (issue #96).
      Modify the build process and the container configuration so that local use is practical at least on macOS and preferably also on Windows. (For macOS will require fixing issues #112 and #176)
      Adjust the container to work in the Positron IDE. This may be used locally or via SSH with DevPod.
      Further enhancements could be worked on during the project, such as reducing the image size, which may be more important for local setup.

      All aspects would involve updating the Markdown-based documentation to reflect the new functionality.

      Expected impact
      The R Dev Container has proved a useful tool for novice contributors, especially at R Dev Days when people want to get up and running quickly. However, the lack of support for C debugging means that the Dev Container can only be recommended for working on R code and documentation, while a large proportion of base R is written in C.

      When people are working in remote or low resource environments, running the container on GitHub Codespaces or as a GitLab Workspace may not be practical. Improving the local setup for macOS and Windows users will mean that local use can be recommended as a viable option in general and may even be attractive for experienced contributors that would prefer to use an isolated dev environment.

      While RStudio is still perhaps the most widely used IDE for R, we are prioritising Positron as a familiar IDE that supports C debugging. This may lay the foundation for using the container with other IDEs that support R and C such as CLion and Emacs.

      Mentors
      Contributors, please contact mentors below after completing at least one of the tests below.

      EVALUATING MENTOR: Heather Turner heather.turner@r-project.org chairs the R Contribution Working Group and is an author of several CRAN packages, notably the statistical modelling packages gnm, BradleyTerry2 and PlackettLuce. She was a GSoC co-mentor in 2021-2024.
      Iain Emsley iain.emsley@warwick.ac.uk is a Research Software Engineer who works with containers, infrastructure and uses R in teaching. He was a GSoC co-mentor in 2024.
      Atharva Shirdhankar atharvshk458@gmail.com was the GSoC contributor on the related GSoC projects in 2023 and 2024.
      Tests
      Contributors, please do one or more of the following tests before contacting the mentors above.

      Easy: Go to the R Dev Container repository and start the GitHub Codespace by clicking on the "Code" drop-down menu, clicking the "Codespaces"" tab and selecting "Create codespace on main". It will take several minutes to set up the codespace. Open a new file with a .R extension and click "R (not attached)" in the VS Code footer to attach to an active R terminal. Write a simple line of R code in your R script and run it. Take a screenshot of your R session.
      Medium: Follow the instructions in the Building R section of the R Dev Container README to build R from a checkout of the R Subversion repository, adapting step 2 to checkout revision number 86123. Create a bash script that combines all these steps and takes the Subversion revision number as an argument or option, to build R from a checkout of a specific revision. Take screenshots that show you using the script in the dev container to build R version 86122 - when you start R, it should show the message "R Under development (unstable) (2024-03-14 r86122)". Use multiple screenshots so that we can first see R version 86123 running in VS Code, then see you calling the script with the relevant option or argument, then see (some of) the output it generates, and finally R version 86122 running in VS Code.
      Hard: Follow the instructions in the Contributing to docs to compile the documentation locally. Find a small thing that needs improving in the documentation. There are some open issues that could be used as inspiration: #44, #86, #191. Edit the documentation accordingly and preview your changes. Take a screenshot to show the revised documentation on your computer. Commit your changes and open a pull request for review.
      Hard: Install DevPod and Docker Desktop on your computer. Using the DevPod documentation as a guide, create a workspace from the R Dev Container GitHub repo using Docker Desktop as the "provider" and Positron as the IDE (you will need to install Positron) if you don't yet have it. Take a screenshot of the information messages shown when creating the workspace - depending on your operating system, you may get some warnings and errors. Despite this, a Docker container should be created - try connecting to the container and working through the Running R tutorial that was written for VS Code. What works and what doesn't? Write notes on your experience using the R Dev Container this way: What needs to be fixed? Can you already suggest improvements to be made?
      Solutions of tests
      Contributors, please post a link to your test results here.

      EXAMPLE CONTRIBUTOR 1 NAME, LINK TO GITHUB PROFILE, LINK TO TEST RESULTS
      
     
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/r-project-for-statistical-computing/
    idea_list_url: https://github.com/rstats-gsoc/gsoc2025/wiki/table-of-proposed-coding-projects

  - organization_id: 132
    organization_name: RTEMS Project
    no_of_ideas: 40
    ideas_content: |
    
        Add new DOSFS file system to RTEMS
        Open
        Issue
        created
        2 weeks ago
        by
        Chris Johns
        Mentors
        @joel
        @chris
        Knowledge/Skills
        File systems
        C
        Introduction
        This is a large project to evaluate and port FatFS to RTEMS as a smaller version of the DOS FS file system. The work can also use the FatFs-enhancements if it provides better performance and more features. This will be intended to replace the current DOS FS in RTEMS.

        Part of this project should plan an evaluation of the improvements of the new version compared to the older version (such as #18).

        Please ask the mentors for more information.

        We are interesting in a new DOSFS that is simpler and smaller compared to the existing one in RTEMS which is custom code.

        Requirements
        Supports long file names
        Supports FAT12, FAT16 and FAT32
        Integrates with libblock
        Resources
        http://elm-chan.org/fsw/ff/00index_e.html
        https://github.com/StepUp-Solutions/FatFs-enhancements
        Edited 1 day ago by Chris Johns
        Child items
        0
        No child items are currently assigned. Use child items to break down this issue into smaller parts.
        Linked items
        0
        Link issues together to show that they're related or that one is blocking others. Learn more.
        Activity
        Chris Johns added 
        rtems
        kernel
        
        gsoc
        large
        
        project
        large
        
        lang
        c
        labels 2 weeks ago
        Gedare Bloom changed the description 2 weeks ago 
        Chris Johns changed the description 1 day ago 
        Please register or sign in to reply
        0 Assignees
        None
        Epic
        None
        Labels
        gsoc
        large
        lang
        c
        project
        large
        rtems
        kernel

        ~~~~~~~~~~

        Adding I2C, PWM and Mailbox Support to the Raspberry Pi 4B BSP
        Open
        Issue
        created
        1 month ago
        by
        Shaunak Datar
        Background
        The Raspberry Pi 4B BSP is currently missing support for I2C, PWM, DMA and Mailbox functionalities, which are need for achieving parity with the ARM-based BSP for the Raspberry Pi 3 and to complete work on the sdhci driver which is pending from last year. This project aims to get the Raspberry Pi 4b BSP to be at par with the ARM based Raspberry Pi 3 BSP and add support needed to implement the sdhci driver.

        Approach
        I2C Support: The I2C interface is implemented for the ARM BSP but work on adding support for it in the aarch64 Raspberry Pi 4b BSP is not done yet. For this BSP testing the polling implementation and writing the interrupt driven I2C is pending. Refer the merge request with the polling implementation: rtems/rtos/rtems!363. You will have to write the RTEMS API to interface I2C devices on a Raspberry Pi 4b.
        PWM Support: RTEMS supports PWM with other BSPs like the arm/beagle bsp. Implement the PWM functionality for the BSP referring to the beagle support https://gitlab.rtems.org/rtems/rtos/rtems/-/tree/main/bsps/arm/beagle/pwm?ref_type=heads. And reading the chapter 8 of the BCM2711 datasheet(https://datasheets.raspberrypi.com/bcm2711/bcm2711-peripherals.pdf).
        DMA Support: The completion of SDHCI driver requires BSP to support DMA, FDT, and mailbox. Last year the FDT support was merged. DMA support is pending. To implement DMA support, refer to Chapter 4 in the BCM2711 datasheet which describes the DMA controllers offered by BCM2711. The implementation needs to support 16 DMA channels (4 DMA Lite, 4 DMA4, and 8 standard channels), Control Block based operations, and Legacy Master addressing for peripherals. This work will enable efficient data transfers and complete the SDHCI driver implementation.
        Mailbox Support: Last year's project on the Raspberry Pi 4b BSP mentioned that the sdhci driver is pending and it requires fdt, dma and mailbox support to complete. FDT has already been implemented and hence we will work on adding the mailbox support to the Raspberry Pi 4b BSP. Port the existing mailbox support for Raspberry Pi 3. Update register definitions and implement read and write functionality for the Raspberry Pi 4b BSP. You can refer to the chapter 13 in the BCM2711 datasheet.
        Knowledge/Skills
        C, assembly
        Hardware-level debugging
        Possible Mentors
        @c-mauderer @Barusu @opticron

        project size : large (350 hours)

        ~~~~~~~~~~

        Support Rust std lib on RTEMS
        Open
        Support Rust std lib on RTEMS
        Open
        Issue
        created
        1 month ago
        by
        Gedare Bloom
        Background
        Rust baremetal (i.e., without Rust std lib) can be used with RTEMS on a BSP supported by both RTEMS and Rust: https://docs.rtems.org/docs/main/user/rust/bare-metal.html#bare-metal-rust-with-rtems . But using Rust with #![no_std] is not ideal. DLR created a Rust target for RTEMS for Arm BSPs. This target supports std lib and also has build in the code to start the Rust app with RTEMS. The Rust documentation can be found here: https://doc.rust-lang.org/nightly/rustc/platform-support/armv7-rtems-eabihf.html . The maintainer plans to write documentation for RTEMS when the work is completed. Note that this target is tier 3; meaning it may "break".

        Presently there is no wrapper library to call RTEMS functions from Rust. So, one can use Rust std lib but one must declare RTEMS functions to the Rust compiler and call them directly, i.e. unsafe or write a wrapper oneself.

        Approach
        This project is to make progress toward more portable use of Rust on RTEMS. The approach may take several possible paths depending on interest, such as:

        Adding more targets for other BSPs beyond the Armv7 port.
        Designing and implementing the language wrappers for the API.
        Adding RSB integration for the compiler tools.
        Creating Rust language test suites and examples.
        It may be possible to scope smaller projects to accomplish portions of this effort.

        You might be able to find additional ideas, smaller features, or bugs to fix by searching: https://gitlab.rtems.org/groups/rtems/-/issues/?sort=created_date&state=opened&label_name%5B%5D=lang%3A%3Arust&first_page_size=20

        Knowledge/Skills
        Rust, C/C++

        Possible Mentors
        @joel @gedare @thesummer


        project size : large (350 hours)

        ~~~~~~~~~~

        Port TinyUSB to RTEMS.
        Open
        Issue
        created
        1 year ago
        by
        Trac Migrate
        Original author: @kgardas

        Background
        Although we have libbsd to serve as a USB stack on higher-end devices, something similar to our efforts to use lwIP on lower-end devices may be port of TinyUSB to RTEMS too.

        The project is described as: "TinyUSB is an open-source cross-platform USB Host/Device stack for embedded systems, designed to be memory-safe with no dynamic allocation and thread-safe with all interrupt events being deferred and then handled in the non-ISR task function." -- here: https://docs.tinyusb.org/en/latest/

        Approach
        Discuss with mentors. The project needs to be scoped. There is a port to FreeRTOS so it should be feasible. Check out the https://github.com/hathach/tinyusb/blob/master/docs/contributing/porting.rst porting guide. The project should add the OSAL implementation for RTEMS in the upstream, and create an RSB build recipe for TinyUSB.

        Knowledge/Skills
        C, Python

        Possible Mentors
        @c-mauderer @kgardas @gedare @chris

        Edited 1 month ago by Gedare Bloom




        project size : large (350 hours)

        ~~~~~~~~~~

        Intel Time Coordinated Computing x86-64 BSP Support
        Open
        Intel Time Coordinated Computing x86-64 BSP Support
        Open
        Issue
        created
        2 years ago
        by
        Trac Migrate
        Original author: blackbird

        Overview
        This ticket focuses on Intel related items that refine x86_64 BSP ticket #[ticket:2898]. Intel (Time Coordinated Computing) can enable realtime x86_64 processing through a manufacturer toolkit and driver set and mitigate non-deterministic behaviors caused by system architecture, software architecture, or general limitations. In focus are the TCC and TSN support, and mitigation of SMI related disturbances to realtime operation.

        Goals
        RTEMS BSPs should support existing and upcoming processors and motherboards that feature:

        TSN (Time Sensitive Networking)
        TCC (Time Coordinated Computing)
        1G/2.5G Ethernet (typically Intel i225 Chipset)
        Processor Selection
        The following processor families are of interest, and are refined here: https://www.intel.com.au/content/www/au/en/collections/topics/iot/real-time.html

        D-2700/D-1700
        12th Gen Core E
        11th Gen Core E
        Xeon W-1100E
        Atom x6000E
        In addition, the following Ethernet drivers should be validated on this BSP for TSN

        i225-LM
        i225-IT
        BSP Selection
        Multiple manufacturers support TCC and TSN availability on typically mini-ITX and uITX motherboards, as well as System on-Module vendors. These are primary targets for deployment of the BSP on modern Intel hardware. This is a BIOS/UEFI setting, and may not be available on commercial motherboards, or requires a firmware update.

        Tasks
        Acquire a TCC/TSN capable motherboard and enable the TCC/TSN settings
        if (targeting Elkhart): Refine the PSE firmware as needed and acquire the requisite programmer
        Architect and Develop RTEMS as a supported BSP toward all TCC/TSN targets natively.
        Edited 1 month ago by Gedare Bloom



        project size : large (350 hours)

        ~~~~~~~~~~

        Add SATA support in libbsd
        Open
        Issue
        created
        3 years ago
        by
        Joel Sherrill
        Background
        Currently, RTEMS has no SATA support. This project is to bring the FreeBSD SATA support into rtems-libbsd. This should be able to be tested on qemu for a BSP like pc386 which has simulated SATA. There may be other simulated BSPs which could be used. Ideally, final testing would be on real hardware.

        Approach
        There is a defined process for bringing in code from FreeBSD and rules for modifications allowed. The person taking on this project will have to adhere to those rules.

        Knowledge/Skills
        C

        Possible Mentors
        @opticron @c-mauderer @chris @gedare

        project size : large (350 hours)

        ~~~~~~~~~~

        Integrate Software License Bill of Materials (BOM) using SPDX Tooling
        Open
        Issue
        created
        3 years ago
        by
        Joel Sherrill
        Background and Approach
        The purpose of this project is to identify and integrate tooling that supports SPDX license annotation (see https://spdx.org). Understanding the purpose of SPDX and why its tooling is used is important background for this project. This project will:

        Identify SPDX tooling and ideas that the RTEMS Project could benefit from
        Evaluate use of that tooling
        What types of reports? Consistency checks?
        Evaluate if there are checks for git pre-commit.
        Perhaps evaluate tooling to identify files without SPDX annotation and the licenses used. This will help us run down the remaining files without annotation.
        All tooling should be open source.

        Knowledge/Skills
        Python

        Possible Mentors
        @joel @gedare @vijay @amar



        project size : large (350 hours)

        ~~~~~~~~~~

        Port an OpenGL Implementation to RTEMS
        Open
        Issue
        created
        3 years ago
        by
        Joel Sherrill
        Background
        This ticket reflects the desire to have OpenGL support for RTEMS based upon an open source package under an acceptable license to use with RTEMS. Independent of the implementation ported to RTEMS, the following will need to be done as a minimum:

        port package to RTEMS
        submit all modifications to the upstream package
        provide an RSB recipe (e.g. bset) for the package
        document BSP requirements for supporting the package
        provide examples for using the package with RTEMS
        There are likely multiple BSPs which could support this effort but it is expected that the i386/pc386 BSP running on qemu is likely the best test platform.

        The packages have been identified so far as candidates:

        Mesa3D - https://www.mesa3d.org/
        larger, most full-featured implementation.
        If this can work on RTEMS, this is a great option.
        Drivers from Linux may be problematic.
        PortableGL - https://github.com/rswinkle/PortableGL
        small implementation, less features
        may be only option if Mesa3D can not be ported
        looks light on device drivers.
        Approach
        Needs to be determined with mentor assistance.

        Knowledge/Skills
        C, Python

        Possible Mentors
        @gedare @joel @chris

        project size : large (350 hours)

        


        ~~~~~~~~~~

        Provide SPARC greth Network Drivers for libbsd
        Open
        Issue
        created
        3 years ago
        by
        Joel Sherrill
        Background
        The SPARC BSPs currently support the greth driver only for the legacy TCP/IP stack. Support needs to be provided for this driver for the rtems-libbsd stack.

        Approach
        The existing driver in the RTEMS legacy network stack is available as a starting point. Other drivers have been updated from the legacy stack to rtems-libbsd. Community input will be needed for driver examples and advice on the update.

        See #77 for comparable rtems-lwip ticket. The two can likely be combined in one ambitious project.

        Knowledge/Skills
        C

        Possible Mentors
        @opticron Daniel Hellstrom, @gedare @vijay @amar

        project size : large (350 hours)

        ~~~~~~~~~~


        Provide SPARC greth Network Drivers for lwip
        Open
        Issue
        created
        3 years ago
        by
        Joel Sherrill
        Background
        The SPARC BSPs currently support the greth driver only for the legacy TCP/IP stack. Support needs to be provided for this driver for the rtems-lwip stack.

        Approach
        The existing driver in the RTEMS legacy network stack is available as an example. There may be an older lwip driver available from Gaisler but the greth and lwip are likely to have been updated since this was written.

        Determining the starting point(s) and path forward is an important step in this project.

        See #65 for comparable rtems-libbsd ticket. The two can likely be combined in one ambitious project.

        Knowledge/Skills
        C

        Possible Mentors
        @opticron Daniel Hellstrom, @gedare @vijay



        project size : large (350 hours)

        ~~~~~~~~~~

        Add support for Eclipse Target Communications Framework (TCF)
        Open
        Add support for Eclipse Target Communications Framework (TCF)
        Open
        Issue
        created
        6 years ago
        by
        Joel Sherrill
        This ticket is to track adding RTEMS support for the Eclipse TCF. From https://www.eclipse.org/tcf/.

        TCF is a lightweight, extensible network protocol for driving embedded systems (targets).
        On top of the protocol, TCF provides a complete modern debugger for C/C++ and Ada, as well as the "Target Explorer" for system management. TCF works out of the box for Intel, PPC and ARM Linux targets including the Raspberry Pi. It supports Proxying and Tunneling for IoT devices, and is particularly strong for multi-process debugging even with slow communication links.
        There is an implementation of the agent which is under an appropriate license. It is available from https://gitlab.eclipse.org/eclipse/tcf/tcf.agent

        TCF appears to support more than debugging though. Part of this ticket will be to identify what features need to be supported and how to enable them.

        This needs to be supported by:

        Refactoring libdebugger separating the gdbserver parts into a gdbserver directory and adding a suitable top level that integrates the needed server parts of a debugging agent running on RTEMS, the debugging protocol (gdbserver), the transport and the RTEMS architecture backend support.
        Add the TCF agent code to libdebugger under tcf.
        Integrate the extra services and features TCF provides.
        Note, SMP support in libdebugger is experimental and not full implemented on ARM.

        Skills Needed

        You need good C and C++ skills with a proven record. You need to show socket level and networking programming skills. You will need to comfortable with low-level processor details for a processor libdebugger currently supports.

        Difficulty

        We consider this an advanced project. It will require being able to "debug a debug agent." You will have to deal with the refactoring mentioned as well as careful attention to locking in order to avoid killing the running RTEMS image.

        This is a large (350-hour) project.

        Possible Mentors
        @joel @chris @opticron



        project size : large (350 hours)

        ~~~~~~~~~~

        Google Go run-time library support needs an update
        Open
        Issue
        created
        8 years ago
        by
        Trac Migrate
        Original author: sebastian.huber

        Background and Approach
        The Google Go run-time now uses features provided by #include <ucontext.h>. RTEMS lacks support for this. One option is to port it from FreeBSD to Newlib. Ticket #3640 tracks ucontext.h support.

        RTEMS supports now thread-local storage. It should be enabled.

        The self-contained objects provided by <sys/lock.h> should be used for synchronization.

        This ticket is referenced by the RTEMS Users Guide in the "Features" section as a footnote to Google Go language support. Please remove the footnote when this ticket is closed.

        Knowledge/Skills
        C

        Possible Mentors
        Joel Sherrill, Sebastian Huber, Gedare Bloom






        project size : large (350 hours)

        


        ~~~~~~~~~~

        Add packaging options to RTEMS Deployment
        Open
        Issue
        created
        3 weeks ago
        by
        Chris Johns
        Background
        The RTEMS Deployment project provides a way to build and package for use in production environments. Users can deployment RTEMS using this tool across a number of machines in a development team.

        RTEMS Deployment currently provides support to build a TAR file or an RPM file is run on an RPM based Linux distribution. We would like to increase the packaging options to widen the reach of the RTEMS Deployment tool.

        There are a number of configurations in the deployment repository and the repository is open to users to add more. A configuration provides vertical integration of software packages users want to run in RTEMS on a BSP.

        Approach
        Build amd/amd-kria-k26 configuration and install the TAR file
        Build the same configuration as an RPM on an RPM Linux operating system such as Rocky
        Add support for Debian packages
        Add support for FreeBSD packages
        Knowledge/Skills
        Python
        Unix operating systems
        Creating a VM of an operating system, for example Rocky, Debian or FreeBSD for development and testing
        Preferred is knowledge of packaging of software on Linux
        Possible Mentors
        @chris




        project size : medium (175 hours)

        ~~~~~~~~~~

        Add support for C11 Annex K Bounds Checking Functions
        Open
        Issue
        created
        1 year ago
        by
        Joel Sherrill
        Description
        C11 (https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1548.pdf) Annex K defines a set of alternatives to many Standard C Library functions that perform bounds checking. It is desirable to support these in RTEMS.

        Since these functions are prototyped in standard C header files, it would be nice to have these merged into newlib and prototyped in the header files included there. Prototypes of Annex K functions need to be guarded by the STDC_LIB_EXT1 cpp define. That would be defined by OS in sys/features.h

        There is at least one implementation or possibly forks of one implementation based on there being multiple "safelibc" projects on github.com with permissive licenses. One of the first steps in this project is to determine which upstream project is the official version and should be the one used for the source. The following repositories as a minimum have been identified:

        https://github.com/sbaresearch/slibc
        https://github.com/rurban/safeclib
        https://github.com/coruus/safeclib
        Since the goal is to have the code merged into newlib, there will need to be a list of files and git hash from the source repository so it is possible to easily track updates.

        Mentors
        Mentors: @joel @gedare

        Skills
        C, build systems



        project size : medium (175 hours)

        ~~~~~~~~~~

        malloc_info() changes the state of the heap
        Open
        Issue
        created
        1 year ago
        by
        Chris Johns
        Mentors
        Chris Johns
        Gedare Bloom
        Skills
        This is primarily a C programming project.

        Expected Outcome
        The malloc_info function is made to be side-effect free with respect to the C program heap.

        Description
        The call malloc_info() is useful when looking to heap issues when some allocations are not right. I have found this call changes the state of the heap. I am not sure what is happening but I think a call like this should not effect the state of the heap and only report it.

        The documentation for this call, specification of the requirements, and any related documentation around it should be updated when this call becomes side-effect free.

        This project could potentially be combined with other projects related to memory allocators.

        4946-no-move.diff
        Edited 10 months ago by Amar Takhar



        project size : medium (175 hours)

        ~~~~~~~~~~

        Several arm BSPs cannot build libdebugger with -O0
        Open
        Several arm BSPs cannot build libdebugger with -O0
        Open
        Issue
        created
        1 year ago
        by
        Trac Migrate
        Original author: sebastian.huber

        Mentors
        Chris Johns
        Kinsey Moore
        Expected outcomes
        Fix the build for libdebugger when optimizations are disabled.

        Skills Required
        This will involve going through the libdebugger code base and a potentially deep dive into the binutils/gcc tool chain to determine where these instructions are being generated or why the compiler flags are not being properly used. Skills may cover C, Python, and assembly language/disassembly.

        Description
        The following script detects BSPs which cannot build libdebugger with -O0:

        for i in $(./waf bsplist --rtems-bsp 'arm.*'); do
          echo -e "[$i]\nOPTIMIZATION_FLAGS = -O0" > config.ini
          ./waf configure
          if ! ./waf 1>/dev/null 2>&1; then
            ./waf
          fi
        done
        Example errors:

        [1350/1481] Linking /tmp/sh/b-rtems/arm/raspberrypi/librtemscpu.a
        [1382/1481] Linking /tmp/sh/b-rtems/arm/raspberrypi/librtemstest.a
        [1384/1481] Compiling cpukit/libdebugger/rtems-debugger-arm.c
        [1395/1481] Linking /tmp/sh/b-rtems/arm/raspberrypi/libftpd.a
        [1397/1481] Linking /tmp/sh/b-rtems/arm/raspberrypi/libftpfs.a
        [1417/1481] Linking /tmp/sh/b-rtems/arm/raspberrypi/libjffs2.a
        [1419/1481] Linking /tmp/sh/b-rtems/arm/raspberrypi/libmghttpd.a
        [1422/1481] Linking /tmp/sh/b-rtems/arm/raspberrypi/librtemscxx.a
        [1424/1481] Linking /tmp/sh/b-rtems/arm/raspberrypi/librtemsdefaultconfig.a
        [1430/1481] Linking /tmp/sh/b-rtems/arm/raspberrypi/libtelnetd.a
        [1433/1481] Linking /tmp/sh/b-rtems/arm/raspberrypi/libtftpfs.a
        [1449/1481] Linking /tmp/sh/b-rtems/arm/raspberrypi/libz.a
        /tmp/ccMZlRcp.s: Assembler messages:
        /tmp/ccMZlRcp.s:2895: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:2896: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:2899: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:2900: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3010: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3011: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3013: Error: selected processor does not support `movw r1,#:lower16:hw_breaks' in ARM mode
        /tmp/ccMZlRcp.s:3014: Error: selected processor does not support `movt r1,#:upper16:hw_breaks' in ARM mode
        /tmp/ccMZlRcp.s:3015: Error: selected processor does not support `movw r4,#:lower16:debug_disable_ints' in ARM mode
        /tmp/ccMZlRcp.s:3016: Error: selected processor does not support `movt r4,#:upper16:debug_disable_ints' in ARM mode
        /tmp/ccMZlRcp.s:3020: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3021: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3077: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3078: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3081: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3082: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3192: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3193: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3195: Error: selected processor does not support `movw r1,#:lower16:hw_breaks' in ARM mode
        /tmp/ccMZlRcp.s:3196: Error: selected processor does not support `movt r1,#:upper16:hw_breaks' in ARM mode
        /tmp/ccMZlRcp.s:3197: Error: selected processor does not support `movw r4,#:lower16:debug_disable_ints' in ARM mode
        /tmp/ccMZlRcp.s:3198: Error: selected processor does not support `movt r4,#:upper16:debug_disable_ints' in ARM mode
        /tmp/ccMZlRcp.s:3202: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3203: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3259: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3260: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3263: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3264: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3374: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3375: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3377: Error: selected processor does not support `movw r1,#:lower16:hw_breaks' in ARM mode
        /tmp/ccMZlRcp.s:3378: Error: selected processor does not support `movt r1,#:upper16:hw_breaks' in ARM mode
        /tmp/ccMZlRcp.s:3379: Error: selected processor does not support `movw r4,#:lower16:debug_disable_ints' in ARM mode
        /tmp/ccMZlRcp.s:3380: Error: selected processor does not support `movt r4,#:upper16:debug_disable_ints' in ARM mode
        /tmp/ccMZlRcp.s:3384: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3385: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3441: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3442: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3445: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3446: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3556: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3557: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in ARM mode
        /tmp/ccMZlRcp.s:3559: Error: selected processor does not support `movw r1,#:lower16:hw_breaks' in ARM mode
        /tmp/ccMZlRcp.s:3560: Error: selected processor does not support `movt r1,#:upper16:hw_breaks' in ARM mode
        /tmp/ccMZlRcp.s:3561: Error: selected processor does not support `movw r4,#:lower16:debug_disable_ints' in ARM mode
        /tmp/ccMZlRcp.s:3562: Error: selected processor does not support `movt r4,#:upper16:debug_disable_ints' in ARM mode
        /tmp/ccMZlRcp.s:3566: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in ARM mode
        /tmp/ccMZlRcp.s:3567: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in ARM mode
        1387/1484] Compiling cpukit/libdebugger/rtems-debugger-arm.c
        [1422/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/libmghttpd.a
        [1425/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/librtemscxx.a
        [1436/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/libtftpfs.a
        [1452/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/libz.a
        [1455/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/testsuites/samples/base_sp.exe
        [1458/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/testsuites/samples/capture.exe
        [1461/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/testsuites/samples/cdtest.exe
        [1463/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/testsuites/samples/fileio.exe
        [1465/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/testsuites/samples/hello.exe
        [1467/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/testsuites/samples/iostream.exe
        [1469/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/testsuites/samples/minimum.exe
        [1472/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/testsuites/samples/nsecs.exe
        [1475/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/testsuites/samples/paranoia.exe
        [1478/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/testsuites/samples/ticker.exe
        [1479/1484] Compiling testsuites/samples/unlimited/test3.c
        [1481/1484] Compiling testsuites/samples/unlimited/test2.c
        [1482/1484] Compiling testsuites/samples/unlimited/test1.c
        [1483/1484] Linking /tmp/sh/b-rtems/arm/lpc32xx_mzx/testsuites/samples/unlimited.exe
        /tmp/ccxkPByw.s: Assembler messages:
        /tmp/ccxkPByw.s:3630: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in ARM mode
        /tmp/ccxkPByw.s:3631: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in ARM mode
        /tmp/ccxkPByw.s:3634: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in ARM mode
        /tmp/ccxkPByw.s:3635: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in ARM mode
        /tmp/ccxkPByw.s:3716: Error: invalid register list to push/pop instruction -- `pop {lr}'
        /tmp/ccxkPByw.s:3758: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in Thumb mode
        /tmp/ccxkPByw.s:3759: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in Thumb mode
        /tmp/ccxkPByw.s:3761: Error: selected processor does not support `movw r1,#:lower16:hw_breaks' in Thumb mode
        /tmp/ccxkPByw.s:3762: Error: selected processor does not support `movt r1,#:upper16:hw_breaks' in Thumb mode
        /tmp/ccxkPByw.s:3763: Error: selected processor does not support `movw r4,#:lower16:debug_disable_ints' in Thumb mode
        /tmp/ccxkPByw.s:3764: Error: selected processor does not support `movt r4,#:upper16:debug_disable_ints' in Thumb mode
        /tmp/ccxkPByw.s:3768: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in Thumb mode
        /tmp/ccxkPByw.s:3769: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in Thumb mode
        /tmp/ccxkPByw.s:3776: Error: unshifted register required -- `orr r4,r4,#(1<<11)'
        /tmp/ccxkPByw.s:3783: Error: Thumb does not support this addressing mode -- `str r4,[r3,#4]!'
        /tmp/ccxkPByw.s:3784: Error: Thumb does not support this addressing mode -- `str r5,[r2,#4]!'
        /tmp/ccxkPByw.s:3797: Error: lo register required -- `ldm sp,{r0-r12}'
        /tmp/ccxkPByw.s:3799: Error: instruction not supported in Thumb16 mode -- `subs pc,lr,#0'
        /tmp/ccxkPByw.s:3829: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in ARM mode
        /tmp/ccxkPByw.s:3830: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in ARM mode
        /tmp/ccxkPByw.s:3833: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in ARM mode
        /tmp/ccxkPByw.s:3834: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in ARM mode
        /tmp/ccxkPByw.s:3915: Error: invalid register list to push/pop instruction -- `pop {lr}'
        /tmp/ccxkPByw.s:3957: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in Thumb mode
        /tmp/ccxkPByw.s:3958: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in Thumb mode
        /tmp/ccxkPByw.s:3960: Error: selected processor does not support `movw r1,#:lower16:hw_breaks' in Thumb mode
        /tmp/ccxkPByw.s:3961: Error: selected processor does not support `movt r1,#:upper16:hw_breaks' in Thumb mode
        /tmp/ccxkPByw.s:3962: Error: selected processor does not support `movw r4,#:lower16:debug_disable_ints' in Thumb mode
        /tmp/ccxkPByw.s:3963: Error: selected processor does not support `movt r4,#:upper16:debug_disable_ints' in Thumb mode
        /tmp/ccxkPByw.s:3967: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in Thumb mode
        /tmp/ccxkPByw.s:3968: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in Thumb mode
        /tmp/ccxkPByw.s:3975: Error: unshifted register required -- `orr r4,r4,#(1<<11)'
        /tmp/ccxkPByw.s:3982: Error: Thumb does not support this addressing mode -- `str r4,[r3,#4]!'
        /tmp/ccxkPByw.s:3983: Error: Thumb does not support this addressing mode -- `str r5,[r2,#4]!'
        /tmp/ccxkPByw.s:3996: Error: lo register required -- `ldm sp,{r0-r12}'
        /tmp/ccxkPByw.s:3998: Error: instruction not supported in Thumb16 mode -- `subs pc,lr,#0'
        /tmp/ccxkPByw.s:4028: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in ARM mode
        /tmp/ccxkPByw.s:4029: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in ARM mode
        /tmp/ccxkPByw.s:4032: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in ARM mode
        /tmp/ccxkPByw.s:4033: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in ARM mode
        /tmp/ccxkPByw.s:4114: Error: invalid register list to push/pop instruction -- `pop {lr}'
        /tmp/ccxkPByw.s:4156: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in Thumb mode
        /tmp/ccxkPByw.s:4157: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in Thumb mode
        /tmp/ccxkPByw.s:4159: Error: selected processor does not support `movw r1,#:lower16:hw_breaks' in Thumb mode
        /tmp/ccxkPByw.s:4160: Error: selected processor does not support `movt r1,#:upper16:hw_breaks' in Thumb mode
        /tmp/ccxkPByw.s:4161: Error: selected processor does not support `movw r4,#:lower16:debug_disable_ints' in Thumb mode
        /tmp/ccxkPByw.s:4162: Error: selected processor does not support `movt r4,#:upper16:debug_disable_ints' in Thumb mode
        /tmp/ccxkPByw.s:4166: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in Thumb mode
        /tmp/ccxkPByw.s:4167: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in Thumb mode
        /tmp/ccxkPByw.s:4174: Error: unshifted register required -- `orr r4,r4,#(1<<11)'
        /tmp/ccxkPByw.s:4181: Error: Thumb does not support this addressing mode -- `str r4,[r3,#4]!'
        /tmp/ccxkPByw.s:4182: Error: Thumb does not support this addressing mode -- `str r5,[r2,#4]!'
        /tmp/ccxkPByw.s:4195: Error: lo register required -- `ldm sp,{r0-r12}'
        /tmp/ccxkPByw.s:4197: Error: instruction not supported in Thumb16 mode -- `subs pc,lr,#0'
        /tmp/ccxkPByw.s:4227: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in ARM mode
        /tmp/ccxkPByw.s:4228: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in ARM mode
        /tmp/ccxkPByw.s:4231: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in ARM mode
        /tmp/ccxkPByw.s:4232: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in ARM mode
        /tmp/ccxkPByw.s:4313: Error: invalid register list to push/pop instruction -- `pop {lr}'
        /tmp/ccxkPByw.s:4355: Error: selected processor does not support `movw r0,#:lower16:hw_breakpoints' in Thumb mode
        /tmp/ccxkPByw.s:4356: Error: selected processor does not support `movt r0,#:upper16:hw_breakpoints' in Thumb mode
        /tmp/ccxkPByw.s:4358: Error: selected processor does not support `movw r1,#:lower16:hw_breaks' in Thumb mode
        /tmp/ccxkPByw.s:4359: Error: selected processor does not support `movt r1,#:upper16:hw_breaks' in Thumb mode
        /tmp/ccxkPByw.s:4360: Error: selected processor does not support `movw r4,#:lower16:debug_disable_ints' in Thumb mode
        /tmp/ccxkPByw.s:4361: Error: selected processor does not support `movt r4,#:upper16:debug_disable_ints' in Thumb mode
        /tmp/ccxkPByw.s:4365: Error: selected processor does not support `movw r2,#:lower16:debug_registers' in Thumb mode
        /tmp/ccxkPByw.s:4366: Error: selected processor does not support `movt r2,#:upper16:debug_registers' in Thumb mode
        /tmp/ccxkPByw.s:4373: Error: unshifted register required -- `orr r4,r4,#(1<<11)'
        /tmp/ccxkPByw.s:4380: Error: Thumb does not support this addressing mode -- `str r4,[r3,#4]!'
        /tmp/ccxkPByw.s:4381: Error: Thumb does not support this addressing mode -- `str r5,[r2,#4]!'
        /tmp/ccxkPByw.s:4394: Error: lo register required -- `ldm sp,{r0-r12}'
        /tmp/ccxkPByw.s:4396: Error: instruction not supported in Thumb16 mode -- `subs pc,lr,#0'
        /tmp/ccxkPByw.s:3698: Error: invalid immediate for address calculation (value = 0x00000001)
        /tmp/ccxkPByw.s:3775: Error: invalid offset, value too big (0x00000088)
        /tmp/ccxkPByw.s:3777: Error: invalid offset, value too big (0x00000088)
        /tmp/ccxkPByw.s:3779: Error: immediate value out of range
        /tmp/ccxkPByw.s:3780: Error: immediate value out of range
        /tmp/ccxkPByw.s:3897: Error: invalid immediate for address calculation (value = 0x00000001)
        /tmp/ccxkPByw.s:3974: Error: invalid offset, value too big (0x00000088)
        /tmp/ccxkPByw.s:3976: Error: invalid offset, value too big (0x00000088)
        /tmp/ccxkPByw.s:3978: Error: immediate value out of range
        /tmp/ccxkPByw.s:3979: Error: immediate value out of range
        /tmp/ccxkPByw.s:4096: Error: invalid immediate for address calculation (value = 0x00000001)
        /tmp/ccxkPByw.s:4173: Error: invalid offset, value too big (0x00000088)
        /tmp/ccxkPByw.s:4175: Error: invalid offset, value too big (0x00000088)
        /tmp/ccxkPByw.s:4177: Error: immediate value out of range
        /tmp/ccxkPByw.s:4178: Error: immediate value out of range
        /tmp/ccxkPByw.s:4295: Error: invalid immediate for address calculation (value = 0x00000001)
        /tmp/ccxkPByw.s:4372: Error: invalid offset, value too big (0x00000088)
        /tmp/ccxkPByw.s:4374: Error: invalid offset, value too big (0x00000088)
        /tmp/ccxkPByw.s:4376: Error: immediate value out of range
        /tmp/ccxkPByw.s:4377: Error: immediate value out of range
        [1436/1531] Compiling cpukit/libdebugger/rtems-debugger-arm.c
        /tmp/ccSUlaYU.s: Assembler messages:
        /tmp/ccSUlaYU.s:3078: Error: selected processor does not support requested special purpose register -- `mrs r1,spsr'
        /tmp/ccSUlaYU.s:3082: Error: selected processor does not support requested special purpose register -- `mrs r2,cpsr'
        /tmp/ccSUlaYU.s:3084: Error: selected processor does not support requested special purpose register -- `msr cpsr,r1'
        /tmp/ccSUlaYU.s:3087: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3101: Error: selected processor does not support requested special purpose register -- `mrs r1,spsr'
        /tmp/ccSUlaYU.s:3103: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3125: Error: selected processor does not support requested special purpose register -- `msr cpsr,r1'
        /tmp/ccSUlaYU.s:3157: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3171: Error: selected processor does not support requested special purpose register -- `msr cpsr,r1'
        /tmp/ccSUlaYU.s:3174: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3175: Error: selected processor does not support requested special purpose register -- `msr spsr,r6'
        /tmp/ccSUlaYU.s:3284: Error: selected processor does not support requested special purpose register -- `mrs r1,spsr'
        /tmp/ccSUlaYU.s:3288: Error: selected processor does not support requested special purpose register -- `mrs r2,cpsr'
        /tmp/ccSUlaYU.s:3290: Error: selected processor does not support requested special purpose register -- `msr cpsr,r1'
        /tmp/ccSUlaYU.s:3293: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3307: Error: selected processor does not support requested special purpose register -- `mrs r1,spsr'
        /tmp/ccSUlaYU.s:3309: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3331: Error: selected processor does not support requested special purpose register -- `msr cpsr,r1'
        /tmp/ccSUlaYU.s:3363: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3377: Error: selected processor does not support requested special purpose register -- `msr cpsr,r1'
        /tmp/ccSUlaYU.s:3380: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3381: Error: selected processor does not support requested special purpose register -- `msr spsr,r6'
        /tmp/ccSUlaYU.s:3490: Error: selected processor does not support requested special purpose register -- `mrs r1,spsr'
        /tmp/ccSUlaYU.s:3494: Error: selected processor does not support requested special purpose register -- `mrs r2,cpsr'
        /tmp/ccSUlaYU.s:3496: Error: selected processor does not support requested special purpose register -- `msr cpsr,r1'
        /tmp/ccSUlaYU.s:3499: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3513: Error: selected processor does not support requested special purpose register -- `mrs r1,spsr'
        /tmp/ccSUlaYU.s:3515: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3537: Error: selected processor does not support requested special purpose register -- `msr cpsr,r1'
        /tmp/ccSUlaYU.s:3569: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3583: Error: selected processor does not support requested special purpose register -- `msr cpsr,r1'
        /tmp/ccSUlaYU.s:3586: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3587: Error: selected processor does not support requested special purpose register -- `msr spsr,r6'
        /tmp/ccSUlaYU.s:3696: Error: selected processor does not support requested special purpose register -- `mrs r1,spsr'
        /tmp/ccSUlaYU.s:3700: Error: selected processor does not support requested special purpose register -- `mrs r2,cpsr'
        /tmp/ccSUlaYU.s:3702: Error: selected processor does not support requested special purpose register -- `msr cpsr,r1'
        /tmp/ccSUlaYU.s:3705: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3719: Error: selected processor does not support requested special purpose register -- `mrs r1,spsr'
        /tmp/ccSUlaYU.s:3721: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3743: Error: selected processor does not support requested special purpose register -- `msr cpsr,r1'
        /tmp/ccSUlaYU.s:3775: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3789: Error: selected processor does not support requested special purpose register -- `msr cpsr,r1'
        /tmp/ccSUlaYU.s:3792: Error: selected processor does not support requested special purpose register -- `msr cpsr,r2'
        /tmp/ccSUlaYU.s:3793: Error: selected processor does not support requested special purpose register -- `msr spsr,r6'
        Edited 10 months ago by Amar Takhar


        project size : medium (175 hours)

        ~~~~~~~~~~

        Add RSB for LLVM targeting RTEMS
        Open
        Issue
        created
        3 years ago
        by
        Joel Sherrill
        Background
        LLVM support for RTEMS has been included in the tools shipped by Gaisler (e.g. their RCC). RTEMS itself should now have all modifications needed to not be tied to GCC. This project is to add an RSB recipe to build an LLVM toolchain.

        Information from Daniel Hellstrom:

        RCC-1.3 has not converted into using the RSB. However I believe we have upstreamed every change to the RTEMS kernel tree which was related to LLVM/Clang support for SPARC. The RCC-1.3 section 2.2.4 includes some information what is compiled with GCC in our LLVM toolchain:

        https://www.gaisler.com/anonftp/rcc/rcc-1.3/1.3.1/rcc-1.3.1.pdf
        https://www.gaisler.com/anonftp/rcc/rcc-1.3/1.3.1/sparc-rtems-5-llvm-8.0.0-1.3.1-linux.txz
        For NOEL-V/RISC-V we only provide GCC toolchain today.

        After building the tools with the RSB, those tools must be used to build at least one BSP from an architecture which is not currently supported by LLVM. ARM, RISC-V, or x86_64 are likely first architectures to consider with testing on a BSP which can run on a simulator. Test results are necessary for GCC (baseline) and LLVM (objective).

        There are multiple tickets related to llvm. Finishing this project may close one or more of them. Any work on this ticket should see if the others need updating or closing.

        Knowledge/Skills
        Python, C, build systems

        Possible Mentors
        @gedare

        project size : medium (175 hours)

        ~~~~~~~~~~

        Codeql Static Analyzer and RTEMS
        Open
        Codeql Static Analyzer and RTEMS
        Open
        Issue
        created
        3 years ago
        by
        Joel Sherrill
        Background
        Codeql [https://codeql.github.com/\\\] is a open source static analysis tool. Broadly speaking, the goal of this project is to use Codeql to analyze RTEMS source code.

        See also #64

        Approach
        Build and install Codeql
        Configure Codeql to analyze RTEMS source code and get reports
        Document procedure
        Evaluate Codeql output and usefulness for RTEMS Project
        If Codeql proves useful, then Codeql will need some work to be more integrated into the project. The following are bare minimum:

        A recipe will need to be added to the RTEMS Source Builder.
        Scripting to generate reports
        To be more effectively used, issues like the following need to be considered:

        Can files or directories be ignored?
        Flagging issues to ignore.
        Can certain issue be turned off?
        Are MISRA rules supported? Can RTEMS use a subset of MISRA rules that are supported by this tool?
        Comparison of one run to the next. History.
        Think creatively, can we run Codeql periodically and email everyone who committed if the number of issues go up?
        etc.
        Knowledge/Skills
        Python

        Possible Mentors
        @gedare @joel



        project size : medium (175 hours)

        ~~~~~~~~~~

        Cobra Static Analyzer and RTEMS
        Open
        Cobra Static Analyzer and RTEMS
        Open
        Issue
        created
        3 years ago
        by
        Joel Sherrill
        Background
        Cobra [https://github.com/nimble-code/Cobra] is a static analysis tool with heritage to JPL. Broadly speaking, the goal of this project is to use Cobra to analyze RTEMS source code.

        See also #63

        Approach
        Build and install Cobra
        Configure Cobra to analyze RTEMS source code and get reports
        Document procedure
        Evaluate Cobra output and usefulness for RTEMS Project
        If Cobra proves useful, then Cobra will need some work to be more integrated into the project. The following are bare minimum:

        A recipe will need to be added to the RTEMS Source Builder.
        Scripting to generate reports
        To be more effectively used, issues like the following need to be considered:

        Can files or directories be ignored?
        Flagging issues to ignore.
        Can certain issue be turned off?
        Can RTEMS use a subset of MISRA rules that are supported by Cobra?
        Comparison of one run to the next. History.
        Think creatively, can we run Cobra periodically and email everyone who committed if the number of issues go up?
        etc.
        Knowledge/Skills
        Python

        Possible Mentors
        @gedare @joel



        project size : medium (175 hours)

        ~~~~~~~~~~

        Continue support for renode.io Simulator
        Open
        Issue
        created
        3 years ago
        by
        Joel Sherrill
        Background
        [Renode.io] is a simulator geared toward System on Chips and testing. The set of supports boards can be viewed in the source code at https://github.com/renode/renode/tree/master/platforms. This ticket can turn into multiple projects. Some work was done on this in GSoC'23. See the student's final report to see what progress has been made, and what remains to be done. https://www.mazaya.id/blogs/gsoc-final-blog. Some cleanup work still needs to be done from that effort, please inquire.

        Approach
        The first type of project is testing support for existing BSPs which have renode.io hardware support.

        Find a board supported by renode.io that has a corresponding BSP.
        Develop support for the RTEMS Tester to run RTEMS tests on that.
        Ensure this simulator can be run without a GUI
        If needed, provide patches for the RTEMS BSP and/or renode.io.
        It may be necessary to add a BSP variant for renode.io if there are small differences that need to be accounted for at BSP build time.
        An alternative project is writing a BSP for a renode.io simulation that does not yet have an RTEMS BSP.

        In either case, once a specific BSP and simulation configuration has been identified, a new ticket for that specific work should be created. The size of the project depends on how well the BSP works on the simulator at the starting point. For example, leon3 is claimed to work very well so the focus would be just on RTEMS Tester configuration and support.

        This ticket is a general description of multiple projects related to renode.io and RTEMS. The size of any specific project for a BSP would vary based on what is required to be done. Scoping the effort for renode.io support for a specific BSP/hardware combination should be part of the project proposal.

        Possible Mentors
        @gedare @joel



        project size : medium (175 hours)

        ~~~~~~~~~~

        Package Micro Python
        Open
        Package Micro Python
        Open
        Issue
        created
        3 years ago
        by
        Trac Migrate
        Original author: eshandhawan51

        Background
        MicroPython (https://micropython.org/) is supported in RTEMS for a long time but isn't packaged well. Packaging it would mainly involve the following:

        Ensure MicroPython builds and works
        Construct an RSB Recipe
        Implement access to REPL
        Provide simple script examples
        Provide documentation.
        Approach
        MicroPython has a new embed port that can be used to build a library using the [RSB](rtems/tools/rtems-source-builder()

        https://github.com/micropython/micropython/tree/master/ports/embed
        There is also a Zephyr port that could be used as an example of what may be required to add fully functional support for I/O and other features to RTEMS

        https://github.com/micropython/micropython/tree/master/ports/zephyr
        A good example project would get MicroPython working under RTEMS with either serial or networking access to the REPL in order to run scripts for testing and debugging.

        ARM BSPs are preferred using either a BeagleBone or Raspberry PI hardware though any BSP could be used to get an initial version running.

        Knowledge/Skills
        C, Python

        Possible Mentors
        @joel @chris @amar



        project size : medium (175 hours)

        ~~~~~~~~~~

        ibbsd: Reduce footprint of minimal buildset
        Open
        Issue
        created
        4 years ago
        by
        Trac Migrate
        Original author: Christian Mauderer

        Overview
        The RTEMS libbsd is now the default network stack for a lot of BSPs. But it's footprint is quite a bit larger then the one of the "legacy" network stack. In 2018 we introduced buildsets that allow to disable features. Currently only a few features can be disabled (OpenSSL, IPv6). Target of this project would be to find more non-essential features that are always linked in and allow to disable them.

        As a general guideline: The minimal buildset of libbsd should provide about the functionality of the legacy network stack.

        The work must not increase the testing effort that is necessary for a release. That should not be a big problem as long as no new buildsets or new build options are necessary. If something like this is necessary, it will need a discussion on the mailing list first.

        Requirements
        A target where libbsd can be used. That can be either real hardware or a simulator with network support (for example xilinx_zynq_a9_qemu).
        If you have a real hardware target, you'll most likely need some JTAG debugger for it. On a simulator you can use gdb. You have to know how to use the debugger.
        Basic C coding skills and very good skills to read C code. You'll have to dig through FreeBSD code which can be quite complex!
        Quite a bit of knowledge how to analyze generated elf files. You should at least be able to use objdump and read linker map files.
        Ability to build your own RTEMS application outside of the normal test tree to test stuff during development.
        Possible Mentors
        @c-mauderer @chris





        project size : medium (175 hours)

        ~~~~~~~~~~

        MIPS Malta BSP Qemu Support
        Open
        Issue
        created
        5 years ago
        by
        Joel Sherrill
        Description
        This project involves updating the MIPS Malta BSP exists to be a first class citizen. There are multiple issues to address and together this should be enough for an SoC project.

        Approach
        The project is a set of tasks to improve the MIPS Malta BSP status. It includes at least the following:

        Ensure BSP works on Qemu
        Add support to RTEMS Tester for this BSP on Qemu
        Make Thread Local Storage (TLS) work on MIPS
        Fix any other bugs
        Add support for this BSP to RTEMS libbsd
        Skills and Knowledge
        C programming language.
        MIPS Assembly.
        Knowledge of host software and building packages such as simulators.
        Knowledge of debugging and debuggers.
        Possible Mentors
        @joel @gedare



        project size : medium (175 hours)

        ~~~~~~~~~~


        Add Filesystem Benchmarking tools to RTEMS
        Open
        Issue
        created
        6 years ago
        by
        Trac Migrate
        Original author: madaari

        Mentors
        Gedare Bloom
        Christian Mauderer
        Skills and Knowledge Required
        C and Python
        Description
        Adding benchmarking tools to RTEMS will provide great insight of system performance and allows comparison between filesystem types, device drivers etc. It will provide several numerical results which in turn provides the developers with some rudimentary feedback on future changes in the system.

        As an IO benchmarking tool, FIO has been ported to RTEMS in a prior GSoC effort. See also: https://gedare.github.io/pdf/agarwal_comparison_2019.pdf

        Currently the following ioengines are working(tested on BeagleBone Black):

        psync,vsync,sync,null,filecreate,ftruncate
        Work remaining:

        Fix remaining memory leakages
        Test Fio on other platforms too, especially the ones with lower memory
        Get the generated code, merged upstream to fio's main repository
        Fix other ioengines like cpuio,falloc too.
        Invoke FIO build with RSB
        Automate testing in rtems-tools



        project size : medium (175 hours)

        ~~~~~~~~~~

        Improve PC386 BSP
        Open
        Improve PC386 BSP
        Open
        Issue
        created
        8 years ago
        by
        Trac Migrate
        Original author: tokencolour

        Introduction:

        This project involves addressing a few deficiencies in the existing pc386 BSP as well as improving it so it supports non-legacy hardware configurations.

        Goal:

        To have a functioning pc386 BSP that can operate on PCs without legacy BIOS or peripherals. It needs to support all features of RTEMS including SMP and Thread Local Storage.

        Requirements:

        Knowledge of x86 ASM, C Programming language.
        Run on non-legacy hardware configurations.
        Share code as possible with new x86_64 BSP (when exists).
        Add Thread Local Storage support to x86 (rtems/rtos/rtems#2468 (closed))
        Thread migration is broken on SMP on x86 (rtems/rtos/rtems#2183)
        See also rtems/rtos/rtems#2901 Emulate i386 (x86) BIOS for VESA Support
        There are at least the following tasks identified related to support of non-legacy PC configurations. A non-legacy PC appears to be one in which at least EFI is used instead of BIOS.

        Support video on non-legacy systems. Probe for video is known to fail on non-legacy systems.
        Support PCI on non-legacy systems. Probe for PCI BIOS is known to fail on non-legacy systems. It is expected that PCI bus access routines will need to be provided for non-legacy configurations.
        Support for APIC rather than legacy PIC.
        It is a requirement for code to be shared with x86_64 when that is supported. It is also a requirement for the pc386 BSP to support both legacy and non-legacy and decide what to do at run-time.

        Resources:

        Current RTEMS developers.
        Do not reinvent the wheel and use existing code instead, e.g. from FreeBSD.
        Possible Mentors
        @joel @gedare   

        project size : medium (175 hours)

        ~~~~~~~~~~

        Remove set_vector() across all architectures and BSPs
        Open
        Remove set_vector() across all architectures and BSPs
        Open
        Issue
        created
        4 weeks ago
        by
        Joel Sherrill
        Background
        The set_vector is an unsafe interface and needs to be obsoleted. Before that can happen, the uses of set_vector need to be replaced with appropriate calls to rtems_interrupt_catch.

        Approach
        Issue #4171 is specific to the SPARC architecture but includes a detailed description of the solution. This solution needs to be applied to every use of set_vector() and then the various implementations removed. In rtems itself, this reports 60 references to be evaluated and updated:

        rtems]$ grep -rl set_vector cpukit/ bsps testsuites/ | wc -l
        60
        These references are spread across at least 6 architectures and some common code.

        There may also be references in other repositories and at least a grep must be done to ensure that no code or documentation references this function any longer.

        Where possible, BSP test results should be posted.

        As a minimum, successful runs of rtems-bsp-builder using gcc 14 or later must be posted. This is because GCC 14 is pickier about many warnings and its new errors are what bumped the priority of deleting use of set_vector().

        Knowledge/Skills
        C

        Potential Mentors
        If this is used as a student project, then the pool of possible mentors includes all core developers. @joel, @gedare, @opticron, or @chris are likely to be the primary mentor with assistance as needed based on the BSP or architecture.





        project size : small(90 hours)

        ~~~~~~~~~~

        Tooling Support Needed to Ease Updates to RSB Bset files
        Open
        Issue
        created
        1 month ago
        by
        Joel Sherrill
        Description
        Some RSB buildsets that reference versions as a hash are still updated manually. Adding automation for the listed buildsets would be appreciated. This work is to add new configuration file to the sb-rtems-pkg command. The work may require moving the existing dictionary from the source to an external JSON or YAML file.

        The buildsets for edge tooling rely on a variety of configuration files having hashes which need to be updated periodically. Some of these hashes are for the development head, while others are hashes for various development branches. The new additional configurations which need to have hashes periodically updated are currently:

        rtems-gdb-head.cfg
        rtems-binutils-2.36.cfg
        rtems-gdb-10.cfg
        rtems-gcc-head-newlib-head.cfg
        rtems-gcc-10-newlib-head.cfg
        rtems-gcc-12-newlib-head.cfg
        rtems-gcc-13-newlib-head.cfg
        rtems-gcc-*-newlib-head.cfg
        It is possible that some of these are used by configurations which can be removed now that rtems 6 is released. But that clean up is another challenge.

        In either case, there needs to be a way to easily update these.

        What frequency should the leading edge tools be updated and what test expectations are required before they are changed is another discussion entirely.

        Knowledge/Skills
        Python

        Possible Mentors
        @joel @chris     



        project size : small(90 hours)

        ~~~~~~~~~~

        Add glibc malloc family extension malloc_usable_size()
        Open
        Issue
        created
        3 years ago
        by
        Joel Sherrill
        Background
        See https://man7.org/linux/man-pages/man3/malloc_usable_size.3.html https://www.freebsd.org/cgi/man.cgi?query=malloc_usable_size

        Approach
        RTEMS already has this functionality so it should not be hard to implement this.

        The prototype may need to be added to the appropriate newlib header file with the same guard as Linux and FreeBSD.

        Add implementation and test code to the malloc family in libcsupport/. The required functionality should already be in the underlying score/ capability used.

        The method would need to be fully tested.

        The method would need to be documented.

        Knowledge/Skills
        C

        Possible Mentors
        @joel @gedare



        project size : small(90 hours)

        ~~~~~~~~~~


        New APIs Added to POSIX Standard (Issue 8)
        Open
        New APIs Added to POSIX Standard (Issue 8)
        Open
        Issue
        created
        4 years ago
        by
        Joel Sherrill
        Background
        POSIX Issue 8 was released in 2024. These new (POSIX says addiitonal) APIs are listed in this page from the HTML published version of Issue 8:

        https://pubs.opengroup.org/onlinepubs/9799919799/xrat/V4_xsh_chap01.html

        The draft set of new APIs which were to be added is incomplete versus the published standard.

        The HTML page cited above from Issue 8 is the definitive list of what APIs were added for Issue 8. Some of the APIs like strlcat() have been around for ages. Others are new like pthread_cond_clockwait() and similar "clockwait" methods for many (all?) concurrency primitives. Most of these additions will likely be implemented in Linux and/or FreeBSD and the POSIX specification usually aligns with those implementations.

        Approach
        This ticket is to perform the analysis to identify the list of methods and constants that are added per the document above or a newer version if available. Then determine if RTEMS, newlib, libbsd currently supports that, and file tickets as appropriate to add them to the RTEMS environment.

        The analysis can be done as part of a GSoC project proposal effort. The GSoC project itself would consist of adding missing methods. There appear to be groups of related methods and the resulting tickets should reflect what would be added as a set. Identifying potential permissive open source implementations that might be appropriate to incorporate should be done. There is a "csv file in rtems-docs/posix-compliance. It has a column for POSIX Issue 8 along with what RTEMS supports with and without libbsd. Check that it is correct while making your plan.

        Update: 14 March 2025 (@joel). I have updated the CSV used to generate the POSIX Compliance Guide. Hopefully it is correct now for Issue 8 and C11. It not, file an issue and assign it to me.

        I have also identified the new functions which are likely to be supportable on RTEMS and attempted to group them by a mix of ease of implementation and what I think the priority to the RTEMS Project is. This is open for discussion and updates. When determining if the function is present in an existing library (usually libc.a, libm.a libbsd.a, or librtemscpu.a for a specific BSP), something like this will show .

        If they are in the newlib libc.a installed with the tool chain, something like this will show it:

        nm -f ${PREFIX}/sparc-rtems7/lib/libc.a | grep SYMBOL

        Similar for other libraries.

        In Newlib winsup/, possibly move to newlib/
        These functions are implemented in the newlib-cygwin repository "windows support" directory. It should be possible to move them into the newlib subdirectory for use by all targets. They are in C++ and hopefully really just C compiled as C++. Move and write a test for RTEMS.

        mbrtoc8() c8rtomb() c16rtomb() c32rtomb()
        In Newlib, check if enabled
        These appear to already be implemented in newlib per my check. Verify and write a test for RTEMS which uses them.

        at_quick_exit() quick_exit()
        Could be added to RTEMS
        Some of the methods that are new in POSIX Issue 8 will need to be implemented in RTEMS itself. These will all need tests.

        dladdr() - could be added to cpukit/libdl
        pthread_cond_clockwait() pthread_mutex_clocklock() pthread_rwlock_clockrdlock() pthread_rwlock_clockwrlock() sem_clockwait() - add in cpukit/posix/src
        timespec_get() - This is a C11 specific function. It could go in cpukit/posix/src or cpukit/libstdthreads
        posix_getdents() - POSIX standardization of non-portable getdents(). RTEMS has getdents() in cpukit/libcsupport/src. Adding the new variant may be just a matter of refactoring and testing.
        Should be in libbsd but check
        If RTEMS supports this method, it is via libbsd support. Check there.

        ppoll()
        If it is not currently supported, it likely could be imported into libbsd from FreeBSD.

        Could be added to RTEMS (low priority)
        These methods appear to APIs RTEMS could support but they should be treated as low priority. Tests will be needed.

        getresgid() getresuid() setresgid() setresuid() - These may be easy calls to existing methods.
        posix_close() - requires missing capability
        Supported already by Newlib (no work)
        These methods are already supported by newlib. There should be no implementation work although tests are likely needed.

        str2sig()
        sig2str()
        Supported already by RTEMS (no work)
        This method is supported by RTEMS to the extent possible by the target hardware.

        getentropy()
        Internationalization (text domains) libintl
        Requires porting a permissive licensed implementation.

        bind_textdomain_codeset() bindtextdomain() dcgettext() dcgettext_l() dcngettext() dcngettext_l() dgettext() dgettext_l() dngettext() dngettext_l() getlocalename_l() gettext() gettext_l() ngettext() ngettext_l()
        Atomics already provided by GCC (no work)
        All of the C11 atomics are provided by GCC with RTEMS support.

        atomic_fetch_add() atomic_fetch_add_explicit() atomic_fetch_and() atomic_fetch_and_explicit() atomic_fetch_or() atomic_fetch_or_explicit() atomic_fetch_sub() atomic_fetch_sub_explicit() atomic_fetch_xor() atomic_fetch_xor_explicit()
        NA for RTEMS (requires multiple processes)
        _Fork() - NA for RTEMS (multiple processes)

        Knowledge/Skills
        C

        Possible Mentors
        @joel

        Edited 4 hours ago by Joel Sherrill




        project size : small(90 hours)

        ~~~~~~~~~~

        Add support for sigaction SA_RESETHAND
        Open
        Issue
        created
        4 years ago
        by
        Joel Sherrill
        Background
        RTEMS needs to support the SA_RESETHAND sigaction().

        https://pubs.opengroup.org/onlinepubs/9699919799/functions/sigaction.html

        Approach
        Design and implement some test cases according to the specification, and then implement using test-driven development. During the proposal period you will need to work closely with the mentors to determine where/how to design the implementation for this support. Please ask on Discord in #gsoc for more guidance.

        Knowledge/Skills
        C

        Possible Mentors
        @joel

        Edited 1 month ago by Gedare Bloom





        project size : small(90 hours)

        ~~~~~~~~~~

        Export Issues from Coverity Scan
        Open
        Issue
        created
        4 years ago
        by
        Joel Sherrill
        Background
        It appears as though there is a way to export Coverity issues as xml or csv. See https://stackoverflow.com/questions/36471467/extracting-coverity-csv-file-from-coverity-server for some details.

        Approach
        Give a good export which can feed into follow up work of creating tickets.

        Then figure out how to account for only new issues being flagged and turned into tickets.

        We would like to have a tool that can automate this process.

        Knowledge/Skills
        Python

        Possible Mentors
        @gedare @joel

        project size : small(90 hours)

        ~~~~~~~~~~

        RISC-V libbsd support
        Open
        Issue
        created
        4 years ago
        by
        Trac Migrate
        Original author: heshamelmatary

        Background
        Hesham worked on RISC-V libbsd and may have some patches as soon as I can. Basic applications can build with GCC and internal networking apps (i.e., no ethernet) do seem to be passing. I have on-going Clang/LLVM WIP as well.

        Hesham should looped in to get work in process. Inquire on discord.

        Possible Mentors
        @c-mauderer @chris   



        project size : small(90 hours)

        ~~~~~~~~~~

        Tests needed for CLOCK_MONOTONIC
        Open
        Issue
        created
        5 years ago
        by
        Joel Sherrill
        Background
        The timer_create() method can use CLOCK_MONOTONIC but there is no test for this.

        https://pubs.opengroup.org/onlinepubs/9699919799/functions/timer_create.html

        The clock_nanosleep() method can use CLOCK_MONOTONIC but there is no test for this.

        https://pubs.opengroup.org/onlinepubs/9699919799/functions/clock_nanosleep.html

        This test or set of tests should create a timer based on CLOCK_MONOTONIC and ensure that it works properly based on that clock. It is likely possible to leverage existing tests for CLOCK_REALTIME as examples/baselines for copying. There may be more tests to consider adding.

        Possible Mentors
        @joel @gedare



        project size : small(90 hours)

        ~~~~~~~~~~

        Code Formatting and Style Check for RTEMS score
        Open
        Code Formatting and Style Check for RTEMS score
        Open
        Issue
        created
        5 years ago
        by
        Trac Migrate
        Original author: Christian Mauderer

        Background
        For the core parts of RTEMS the coding style is defined in the documentation (https://docs.rtems.org/branches/master/eng/coding-conventions.html). Ongoing work has been adding this style to the clang-format tool https://clang.llvm.org/docs/ClangFormat.html. Some work remains to be done on the support in clang-format, and also on the automation/tools of integrating this in to RTEMS.

        Approach
        Please contact the mentors to discuss the status of this task. There is active development work in this area.

        Knowledge/Skills
        C++, Python

        Possible Mentors
        @gedare

        project size : small(90 hours)

        ~~~~~~~~~~


        BSP Buildset for EPICS
        Open
        BSP Buildset for EPICS
        Open
        Issue
        created
        5 years ago
        by
        Gedare Bloom
        BSP Buildset for EPICS
        Possible Mentors
        Gedare Bloom, Chris Johns

        Skills
        Python

        Introduction =
        The EPICS project uses RTEMS. EPICS version 3.15 uses RTEMS-4.10. EPICS version 7 is intended to use RTEMS version 5. Compiling and using EPICS 3.15 with RTEMS-4.10 is relatively straightforward. The compilation of current RTEMS master with EPICS 7 is more difficult, and currently only works for some (expensive) hardware targets. The goal of this project is to create RTEMS Source Builder packages for compiling EPICS together with RTEMS that can be run on a simulator. To achieve this end, an RTEMS-5/EPICS-7 build that can run on a simulated target needs to be completed.

        Goal
        To create a vertically integrated BSP Build Set capable of creating a bootable BSP image with EPICS7+RTEMS5 that can run in a simulator.

        A secondary goal could be to provide build set support for RTEMS-4.10+EPICS3.15. However, the RSB master branch does not currently support RTEMS-4.10, and the 4.10 branch does not currently support BSP Build Sets.

        Prerequisites
        Ability to read/write Python programs with OOP.
        Ability to read/write C programs (pointer-based data structures).
        Resources
        https://epics.anl.gov/base/RTEMS/tutorial/tutorial.html



        project size : small(90 hours)

        ~~~~~~~~~~


        Add Classic API Barrier "get number waiting" Service
        Open
        Issue
        created
        5 years ago
        by
        Joel Sherrill
        Background
        Given that a barrier can be set to manually release, it would be useful to know how many threads are waiting at it. An extension to the barrier API could be useful.

        Approach
        Talk to the mentors. Tests and documentation are required.

        Knowledge/Skills
        C
        Synchronization primitives
        Possible Mentors
        @joel @gedare




        project size : small(90 hours)

        ~~~~~~~~~~

        rtems-test needs a --version option or similar
        Open
        Issue
        created
        6 years ago
        by
        Trac Migrate
        Background
        Original author: sebastian.huber

        It should be possible to set the RTEMS version via the command line to allow using non-standard tools, e.g.

        rtems-test --rtems-bsp=erc32 --rtems-tools=/opt/rtems/6 /home/user/build/b-erc32
        RTEMS Testing - Tester, 5.0.not_released
        Command Line: /opt/rtems/6/bin/rtems-test --rtems-bsp=erc32 --rtems-tools=/opt/rtems/6 /home/user/build/b-erc32
        Python: 2.7.12 (default, Oct 29 2016, 13:38:04) [GCC 4.2.1 Compatible FreeBSD Clang 3.8.0 (tags/RELEASE_380/final 262564)]
        Host: FreeBSD-11.1-RELEASE-p1-amd64-64bit-ELF (FreeBSD FreeBSDBuild 11.1-RELEASE-p1 FreeBSD 11.1-RELEASE-p1 #0: Wed Aug  9 11:55:48 UTC 2017 root@amd64-builder.daemonology.net:/usr/obj/usr/src/sys/GENERIC amd64 amd64)
        [  3/589] p:0   f:0   u:0   e:0   I:0   B:0   t:0   i:0   W:0   | sparc/erc32: whetstone.exe
        [  6/589] p:0   f:0   u:0   e:0   I:0   B:0   t:0   i:0   W:0   | sparc/erc32: fsdosfsformat01.exe
        [  1/589] p:0   f:0   u:0   e:0   I:0   B:0   t:0   i:0   W:0   | sparc/erc32: dhrystone.exe
        [  2/589] p:0   f:0   u:0   e:0   I:0   B:0   t:0   i:0   W:0   | sparc/erc32: linpack.exe
        [  5/589] p:0   f:0   u:0   e:0   I:0   B:0   t:0   i:0   W:0   | sparc/erc32: fsclose01.exe
        [  4/589] p:0   f:0   u:0   e:0   I:0   B:0   t:0   i:0   W:0   | sparc/erc32: fsbdpart01.exe
        [  8/589] p:0   f:0   u:0   e:0   I:0   B:0   t:0   i:0   W:0   | sparc/erc32: fsdosfsname02.exe
        [  7/589] p:0   f:0   u:0   e:0   I:0   B:0   t:0   i:0   W:0   | sparc/erc32: fsdosfsname01.exe
        error: gdb exec: /opt/rtems/6/bin/sparc-rtems5-gdb: No such file or directory
        Possible Mentors
        @chris @gedare

        project size : small(90 hours)

        ~~~~~~~~~~

        IMFS - Add configurable allocator support
        Open
        Issue
        created
        6 years ago
        by
        Joel Sherrill
        Description
        The IMFS currently is hard-coded to use malloc/free. It would be a desirable enhancement to be able to configure the allocator and deallocator. A comparable example of allowing the user to configure a custom allocator and deallocator is the stack memory allocator/deallocator configuration parameters.

        This may be combined with #15 for a broader scope.

        Knowledge/Skills
        C

        Possible Mentors
        @joel @gedare

        project size : small(90 hours)

        ~~~~~~~~~~

        IMFS - Improve Bytes Per Block Handling
        Open
        Issue
        created
        6 years ago
        by
        Joel Sherrill
        Description
        This ticket involves improvements to the IMFS bytes per block behavior. These changes will also need to be reflected in user facing documentation.

        Currently, the behavior when presented when an invalid configuration value for bytes per block is to silently use the default. It is likely preferable to have a fatal error.
        Allow for larger block sizes. When implemented, a block size of 512 which resulted in a maximum file size of 1GB was near unimaginable for an embedded system. Allowing for a maximum of at least 1K and possibly 2K seems reasonable now. Note that adding new block size options requires calculating the corresponding maximum file sizes and updating imfs.h and user facing documentation.
        May be combined with #16 for a larger scope.

        Knowledge/Skills
        C

        Possible Mentors
        @joel @gedare

        project size : small(90 hours)

        ~~~~~~~~~~

        POSIX Compliance
        Open
        POSIX Compliance
        Open
        Issue
        created
        7 years ago
        by
        Trac Migrate
        Possible Mentors
        Joel Sherrill

        Description
        Increase the POSIX functions supported by RTEMS and Newlib. This is a long-standing and ongoing effort. Several tasks may be composed to create a larger project scope.

        RTEMS POSIX Compliance is achieved via a combination of methods and .h files in RTEMS and the newlib C Library. Newlib also provides the math library.

        Disclaimer: The order in which methods/issues are presented here should not be taken as the priority with which they should be addressed. It is also quite likely this list is incomplete. A more complete view of the situation is in the RTEMS POSIX Compliance Guide available at https://docs.rtems.org. That document was created from a spreadsheet which is a .csv file available in the rtems-docs repository. RTEMS compliance is tracked against multiple versions of POSIX, C Language versions, and embedded standards which profile the POSIX standard.

        Knowledge/Skills
        C

        Approach
        Before planning to implement anything on this list, please review rtems, newlib, rtems-libbsd, and the .h files newlib installs. These four are the sources for RTEMS POSIX support. Each is a moving target. Request updates to the spreadsheet when you find places that need updating.

        Active Tasks
        The following are the open tickets that are sub-tasks of this project. If you work on a part of this project please make a ticket and add the tag POSIX-Compliance.

        Open Issues

        Closed Tasks
        Closed Issues

        Tasks without Issues
        RTEMS itself is missing a few methods and may have issues with others. These methods may have outstanding POSIX compliance issues:

        Improved support at the API level for CLOCK_MONOTONIC (may have ticket)
        This impacts timer_create() and at least pthread_condvar_timedwait
        List IO
        Are all methods in signal.h possible provided?
        Newlib also has some known issues:

        sys/statvfs.h is missing
        Implementation would likely be in RTEMS
        some random number related calls are missing
        fstatvfs is missing at least a prototype in the right place
        Others will be impossible to implement without multiple processes, and so we'll have to determine which methods make sense to support and in what manner.

        Testing
        Functional unit testing as needed
        Additions to psxhdrs test to ensure methods can be invoked per Open Group specification
        FACE Consortium Conformance Test Suite. The FACE Consortium has defined four POSIX profiles. RTEMS can support most of the methods in the largest profile (General Purpose).
        References
        Single UNIX Specification
        http://www.opengroup.org/testing/downloads.html
        FACE Consortium

        project size : small(90 hours)

      
        




        


     
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/rtems-project/
    idea_list_url: https://projects.rtems.org/gsoc/

  - organization_id: 133
    organization_name: Rizin
    no_of_ideas: 10
    ideas_content: |
      
      Cutter
      Improving usability and user experience (175 hour project)
      The Cutter’s backend provides many features that are not exposed or exposed in Cutter efficiently. The goal of this task would be to figure out the users’ biggest pain points and address them by improving or reworking the interface. Some of the issues are already in our GitHub, while others might be figured during the cross-comparison with other tools.
      Task
      Add a scrollbar to the disassembly and hexdump widgets
      Better syntax highlight and theming
      Managing window/widget overlays
      Add information about status of the analysis, signature searching, and other operations
      Address various small UI problems that make user’s life harder than necessary
      Skills
      The participant should be comfortable with the C++ and be familiar with Qt framework. Basics of the design/UX would be a plus.
      Difficulty
      Advanced
      Benefits for the participant
      The participant will gain an experience of creating comfortable and efficient user interface with C++/Qt.
      Benefits for the project
      It will make interface and user experience more consistent, on par with Rizin itself, and other tools.
      Assess requirements for midterm/final evaluation
      1st term: Add scrollbar to necessary widget, improve theming and syntax highlight
      Final term: Managing widgets layouts, docking; provide action status information
      Mentors
      thestr4ng3r
      xvilka
      Megabeets
      Links/Resources
      User Experience project for Cutter
      User Experience project for Rizin

      ~~~~~~~~~~

      Plugins and Python High Level API (175 hour project)
      Our current public API to be used by plugin authors is somewhat limited. We need to improve a lot of things about our Plugins support and take it few steps ahead. This task is only about improving the public C++ and Python interface of Cutter, specifically its graphical user interface components. For a task about exposing Rizin’s API for disassembly, analysis and other purposes, see the Rizin bindings task above.
      Task
      Expose everything Cutter can offer for plugin authors. This includes high level API, integration of the plugin management etc.
      Accessing everything from Python (like Blender) - see issue #1662
      Python integration and IPython console.
      Skills
      The participant should be comfortable with the C++ and Python languages, and be familiar with Qt framework
      Difficulty
      Advanced
      Benefits for the participant
      The participant will gain an experience of creating a suitable API for scripting graphical interface programs.
      Benefits for the project
      It will greatly improve the scripting experience, will make API more consistent and will ease creating Cutter plugins by the community. Moreover, it will simplify testing of the Cutter features.
      Assess requirements for midterm/final evaluation
      1st term: Design of the high level API and required Rizin changes. Review and implement all missing API functions that are accessible as interface controls.
      Final term: Implement the way to show the API when hovered over some interface control, create documentation.
      Mentors
      thestr4ng3r
      Megabeets
      Links/Resources
      SDB Module/API for Cutter Python/Jupyter integration
      Jupyter plugin for Cutter

      ~~~~~~~~~~


      Multi-Tasking and Event-driven architecture (350 hour project)
      The information Cutter gets about functions, strings, imports, and the analysis are all performed in Rizin and only displayed in Cutter. Currently, it is pulling most information from Rizin only on demand. This is problematic because sometimes the user performs changes (via plugins, the console widget, and more) that are affecting the information from Rizin, but Cutter doesn’t know about these changes to apply the to the UI. For example, if a user will define a new function in a Python script or via the console widget by using the Rizin command af @ <addr>, Cutter will not show this new function in the Functions widget until the user will refresh the interface manually (Edit -> Refresh Contents). The goal of this task is to use an event-driven architecture to overcome this limitation.
      In addition, this task will also handle the analysis in the background feature, to allow the analysis performed by Rizin to happen while the interface is active.
      Tasks
      The overall implementation of this task should start from Rizin by adding events to many of the functions. This can be done using rz_events. For example, add an even for function creating, for section creation, for flag deletion, for name changed, and more
      Add events to all the relevant functions inside Rizin
      Add support for these events in Cutter and refresh and update the relevant widgets per each event
      Support analysis in the background and allow the user to start its session while Rizin is analyzing (see #1856, #1574)
      Skills
      The participant should be comfortable with the C++ for Cutter and C for Rizin. They should also be familiar with Qt framework. Experience in GUI code architecture, for example using functional reactive programming or Elm-like approaches is a plus.
      Difficulty
      Advanced
      Benefits for the participant
      The participant will gain an experience of creating complex event-driven software in both C and C++ languages.
      Benefits for the project
      It will allow to work on big files effortlessly in Cutter, will improve analysis quality as well.
      Assess requirements for midterm/final evaluation
      1st term: Implement events everywhere in the relevant places across Rizin code and event-driven interaction with Cutter.
      Final term: Add support for the Cutter interface refresh based on the events from Rizin, implement analysis in background.
      Mentors
      thestr4ng3r

      ~~~~~~~~~~
      Heap viewer completion (175 hour project)
      Thanks to the work that was done in the previous GSoC, Cutter and Rizin have nice visualizations of the heap and memory maps. We would like to expand on this feature with performance improvements to the heap parsers and support more memory allocators.
      Task
      Complete Cutter’s implementation of the windows heap widget #2723
      Improve the performance of the Windows heap parser
      Fix Windows heap parsing errors
      Make the implementation work with remote debugging modes
      Skills
      The participant should be comfortable with the C++, and be familiar with Qt framework
      Difficulty
      Medium
      Benefits for the participant
      The participant will gain the understanding on how modern runtimes provide the heap for various programs, which will be beneficial for the binary exploitation skills.
      Benefits for the project
      It will greatly improve the debugging and reverse engineering experience for complex programs, also provides the way to design the exploitation techniques with the help of Rizin/Cutter.
      Assess requirements for midterm/final evaluation
      1st term: Design and implement heap visualization widgets, add Rizin test and fixes
      Final term: Various bugfixes related to the heap inspection support on various platforms and allocators, tests and documentation.
      Mentors
      xvilka
      Megabeets
      Links/Resources
      Issue #1041
      Heap Viewer plugin for IDA Pro
      Heap parsing for MacOS, tmalloc, jmalloc
      Dynamic Allocator Detection
      “heap”-marked Rizin issues

      ~~~~~~~~~~
      Diffing mode (175 hour project)
      Binary diffing is one of the most common tasks for the reverse engineer. There are many tools available, but most of them are either detached from the main RE toolbox or poorly integrated. Rizin provides basic diffing features out of the box with rz-diff tool, but Cutter has no interface to represent similar functionality.
      Task
      Expose basic rz-diff features in the Cutter
      Create the interface to choose two files for diffing
      Create the way to show the differences in all main widgets:
      Hexadecimal view
      Disassembly view
      Graph view
      Pseudocode view
      Skills
      The participant should be comfortable with the C++ language, and be familiar with Qt framework
      Difficulty
      Medium
      Benefits for the participant
      The participant will gain an experience of creating efficient graphical interfaces.
      Benefits for the project
      It will greatly benefit the project since Cutter will be the only FOSS RE tool to provide this feature out of the box.
      Assess requirements for midterm/final evaluation
      1st term: Expose the rz-diff features in the Cutter core and create the interface for opening files for diffing. Implement the diff modes for hexadecimal and disassembly views.
      Final term: Implement the diff modes for graph and pseudocode views, create the documentation.
      Mentors
      xvilka
      deroad
      Links/Resources
      Issue #1104
      BinDiff
      Diaphora

      ~~~~~~~~~~
      Rizin
      Classes analysis for C++/ObjectiveC/Swift/Dlang/Java (350 hour project)
      Analysis classes, accessible under the ac command, is a relatively new feature of rizin. They provide a way to both manually and automatically manage and use information about classes in the binary. But their support is only bare bones, without supporting various analysis integration, as well as display in the disassembly output.
      Consider the following call: call dword [eax + 0x6c] Let’s assume eax is the base pointer of a vtable we have saved in class analysis and we want to find out the actual address of the called method.
      So there should be a command that takes the offset (in this case 0x6c) and looks up the actual destination. It should be possible to call this command with a specific class, so it only looks into its vtable, or without a class, so it gives a list of possible destinations for all vtables that are not too small for the offset.
      When that is implemented, one could also add a command that does the same thing, but automatically takes the offset from the opcode at the current seek.
      Task
      Connecting classes with their methods
      Class inheritance - nesting data structs
      Constructors and destructors autorecognition
      try/catch/finally recognition and marking
      arguments recognition
      ASCII/graphviz graph of class inheritance/structure inheritance
      Tests with sources for C++, FreePascal, D language, ObjC and Swift, for rizin-testbins
      Classes list via Vb. It already supports browsing bin classes. The same thing should be implemented for classes from analysis.
      Skills
      Good knowledge of the C language
      Good knowledge of the C++ language (other languages, like ObjC, Swift, D, etc are a plus)
      Difficulty
      Hard
      Benefits for the participant
      Participant will understand how OOP languages work under the hood, and will master technique of detecting various high level (classes, methods) abstractions in the binary code.
      Benefits for the project
      It will greatly benefit the project to allow efficient reverse engineering of the programs written in C++ and other OOP languages.
      Assess requirements for midterm/final evaluation
      1st term: implement classes integration into the analysis, type inference; detect constructors and destructors, try/catch blocks.
      Final term: Class inheritance recognition, virtual methods detection, building class inheritance graphs, visual mode to inspect classes and methods relationships.
      Mentors
      xvilka
      deroad
      Links and resources
      Improve vtable detection for C++, ObjectiveC, Dlang and Swift binaries - issue #416
      Devirtualize method calls using class vtables - issue #414

      ~~~~~~~~~~
      Debugger improvements and portability (175 hour project)
      Rizin debugger already supports most of the platforms, including native and remote debugging. Nevertheless, for most platforms it’s limited mostly to the x86/x86_64 and ARMv8, often lacking the tests. The task would be to add missing architectures to the native debugger, e.g. MIPS to the Linux Native, ARMv7/ARMv8 to the FreeBSD, System Z debugger for Linux, HPPA debugger for Linux, VAX debugger for NetBSD, and so on. Moreover, some information isn’t available during the debugging mode, e.g. source-level breakpoints or names, it would be necessary to make sure debug commands understand those.
      With the help of emulators like QEMU and OpenSIMH we could extend our CI to automatically test these debuggers.
      Task
      Integrated source-level information loaded from DWARF or PDB into debug commands and print p commands
      Support for missing architectures that are supported by Rizin statically in the Linux native debugger
      Support for missing architectures that are supported by Rizin statically in the BSD native debugger
      Cover more platforms supported by the debugger with automated tests, with CI whenever it’s possible
      Fix the bugs in debuggers, minor refactorings of the code
      Skills
      Good knowledge of the C language
      Some experience in debugging with GDB or LLDB
      Difficulty
      Hard
      Benefits for the participant
      Participant will understand how debugging works on the low level, and will gain experience with variety of different platforms and operating systems.
      Benefits for the project
      It will allow efficient low-level debugging on various supported platforms, not only the mainstream ones, greatly improving Rizin’s usefulness in reversing some domain-specific software.
      Assess requirements for midterm/final evaluation
      1st term: `SystemZ, MIPS, HPPA support in Linux native, remote GDB debuggers
      Final term: ARM and SPARC support in *BSD debuggers, VAX support in NetBSD
      Mentors
      xvilka
      thestr4ng3r
      ret2libc
      Links/Resources
      Debug-labeled issues
      RzDebug-labaled issues
      New Platform support
      New Architecture support

      ~~~~~~~~~~
      FRIDA integration (175 hour project)
      FRIDA is the famous dynamic instrumentation toolkit that is immensely popular among mobile device researches. Rizin could be easily integrated with Frida by creating a plugin that will allow to connect to the Frida instance, receive traces, set breakpoints, get information and events from it.
      Task
      Create the basic plugin that allows attaching, spwaning, launching processes within Frida loco ally
      Support remote connection
      Add feature to receive information from the Frida instanced
      Add breakpoints and run/step/continue feature’s
      Support calling functions and scripts in the context of the instrumented process
      Skills
      Participant should know C as well as have the experience of working with debuggers.
      Difficulty
      Hard
      Benefits for the participant
      Participant will understand and learn how to use Frida toolkit, also the internals of the debugging and instrumentation processes.
      Benefits for the project
      It will allow easy dynamic code instrumentation right from the Rizin or Cutter session, allowing tracing and code inspection.
      Assess requirements for midterm/final evaluation
      1st term: Implement core of the FRIDA plugin, allowing local and remote debugging features
      Final term: Add support for extended features like calling functions or scripts within the context
      Mentors
      xvilka
      thestr4ng3r
      wargio
      Links/Resources
      FRIDA
      FRIDA (GitHub)
      r2frida

      ~~~~~~~~~~
      Exploitation capabilities improvements (175 hour project)
      Since modern architectures are now enforcing W^X, exploiters are using ROP. (Un)fortunately, building ROP chain by hand can be tedious, this is why some tools can be used to ease this construction: ImmunityDBG has mona.py, there is also ROPgadget and dropper.There exist even tools that can generate ROP chains automatically, for example exrop. It’s a shame that despite having RzIL, Rizin doesn’t have something similar yet. One of the possible solutions would be to build an external plugin or tool which will reuse power of librz and rz-gg. Moreover it makes sense to think about SROP, COOP and BROP support.
      The last year (GSoC'24) one of our participants started implementing this feature, but it wasn’t finished. You could check the rz-solver repository for more details.
      Also, the rz-gg tool while has the ability to create a custom shellcode but there is still a lot of work required.
      Task
      Fix rz-gg issues
      Write a compiler which uses SMT solver (like Z3 for example) to produce the ropchain: #4563.
      Support main architectures - x86, ARM, MIPS, PowerPC at the very least
      Skills
      The participant should be comfortable with the C language, know some assembly and a high-level language. Also, knowing a little bit of automatic binary analysis wouldn’t hurt.
      Difficulty
      Advanced
      Benefits for the participant
      The participant will improve their skills in software exploitation and solvers.
      Benefits for the project
      This feature would greatly help during exploits development, and people would be able to ditch mona.py for Rizin ;)
      Assess requirements for evaluation
      1st term: Creating the language for defining the ROP chain semantics and integrating it with SMT solver
      Final term: Working ropchain compiler, covered by tests and documented in the Rizin book.
      Mentors
      xvilka
      ret2libc
      Links/Resources
      ROPGadget
      Ropper
      Angrop
      ROPC
      exrop
      roper2
      mona.py from corelan
      Hunting for ROP Gadgets in Style (2012)
      dropper a BARF-based rop chain generator
      Materials about the exloitation workshop at Hack.lu 2014
      Slides for the exploitation part of workshop at Hack.lu 2015
      RzEgg related bugs

      ~~~~~~~~~~
      Binary case reduce tool (175 hours project)
      Similar to Csmith/Creduce but operating on the binary files, to reduce the size of the test and to avoid sharing proprietary/classified files.
      It can perform these operations:
      cut bytes
      shift
      zero/0xFF/mask bytes
      remove section
      Since it requires some knowledge of the file format, existing libraries like LIEF could be used.
      Task
      Make a tool to reduce the size of ELF using specified operations
      Extend it to other formats - PE, MachO
      Create tests for this tool
      Research the possibility of minimizing some testcases that are already in the Rizin repository.
      Skills
      The participant should be comfortable with the C language, as well as the high-level language of a choice (Python or Rust).
      Difficulty
      Advanced
      Benefits for the participant
      The participant will improve their understanding in file formats and their mutation.
      Benefits for the project
      This feature would greatly help in minimizing and anonimizing testcases for the Rizin and any other binary analysis tool.
      Assess requirements for evaluation
      1st term: Create the simple tool to reduce the ELF size
      Final term: Extend it to other formats, improve the “compression” rate, cover with tests.
      Mentors
      xvilka
      deroad
      Links/Resources
      https://github.com/rizinorg/ideas/issues/52
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/rizin/
    idea_list_url: https://rizin.re/gsoc/2025/

  - organization_id: 134
    organization_name: Rspamd
    no_of_ideas: 4
    ideas_content: |
     
      Multi-Class Bayesian Classifier
      Description: Extend Rspamd’s Bayesian classifier to support multiple categories (beyond spam/ham) and integrate AI-driven learning via a GPT plugin for dynamic model updates.
      Difficulty: Medium/Hard
      Timeline: 22 weeks
      Skills: Machine Learning (Bayesian methods), Lua, Python (for GPT integration)
      Mentors: Vsevolod Stakhov, Andrew Lewis
      Benefits: Gain expertise in AI/ML integration, probabilistic classifiers, and large-language model APIs.
      Evaluation:
      Midterm: Basic multi-class support in Bayes module; GPT plugin prototype.
      Final: Full integration with GPT for automated learning; performance benchmarks.

      ~~~~~~~~~~
      Full Telegram Support (Bot for Spam Filtering)
      Description: Implement integration of with Telegram bot for spam filtering, including rule-based automation (e.g., user reports, admin moderation).
      Difficulty: Medium
      Timeline: 12 weeks
      Skills: Rust (Telegram Bot API), Lua, Rule Engine Design
      Mentors: Andrew Lewis, Anton Yuzhaninov
      Benefits: Learn real-time bot development, protocol integration, and spam rule optimization.
      Evaluation:
      Midterm: Functional Telegram bot with basic spam reporting.
      Final: Advanced rules (e.g., rate limiting, user reputation), moderation UI, and documentation.

      ~~~~~~~~~~
      Settings Manager (UI + Rust Backend)
      Description: Build a user-friendly UI for managing Rspamd settings and a Rust-based backend for storing configurations in MySQL/PostgreSQL.
      Difficulty: Medium
      Timeline: 12 weeks
      Skills: Rust, JavaScript/TypeScript (React/Vue), SQL
      Mentors: Andrew Lewis, Vsevolod Stakhov
      Benefits: Master full-stack development, Rust database integration, and secure UI design.
      Evaluation:
      Midterm: Rust backend with CRUD operations; UI prototype.
      Final: Full UI feature set (import/export, versioning), performance optimizations.

      ~~~~~~~~~~
      GnuPG Signing and Verification Support
      Description: Enhance Rspamd’s GnuPG support for signing/verifying emails, including key management and policy enforcement.
      Difficulty: Hard
      Skills: C, Cryptography (PGP/GnuPG), Lua
      Timeline: 22 weeks
      Mentors: Vsevolod Stakhov
      Benefits: Deepen knowledge of cryptographic protocols and secure C programming.
      Evaluation:
      Midterm: Basic message signing/verification workflow.
      Final: Key rotation policies, WebUI integration, and attack-resistance testing.

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/rspamd/
    idea_list_url: https://rspamd.com/gsoc2025_ideas.html

  - organization_id: 135
    organization_name: SQLancer
    no_of_ideas: 8
    ideas_content: |
    
      Adding Grammars to Test New Database Systems
      SQLancer supports close to 20 database systems (see the subdirectories with the relevant database names at src/sqlancer). Adding support for a new database system involves developing generators that generate SQL statements specific to the database system under test. The process of adding a new database system is described in the CONTRIBUTING.md guide.
      Recently, we have developed a new domain-specific language called SQL Generation Language (SGL) which should be used to aid you with this process. SGL takes in a grammar file that describes syntaxes of the target SQL dialect. The language is designed based on ANTLR which describes context-free grammars (to be exact, parser expression grammars) for parsing, on top of which language constructs for maintaining fuzzing contexts and enforcing semantic constraints are added.
      Required skills: Experience with using Git as well as basic SQL knowledge is expected
      Expected size: Either 175 or 350 hour
      Difficulty: Medium
      Expected outcomes: Support for one (or multiple) new database systems as well as reporting of bugs found in that system
      Potential mentors: @albertZhangTJ
      Various additional hints:
      Most implementations use JDBC, which is well-supported by SQLancer.
      To get an idea of what database systems you could consider supporting, the DB-Engines ranking or the Database of Databases might be useful.
      It would be useful to first contact the developers of the database system to check whether they would welcome a testing effort of their system.
      
      
      ~~~~~~~~~~
      Adding a Feedback-guided Fuzzing Approach
      Currently, the main approach used by SQLancer to generate test cases is generation-based and black-box. The goal of this project is to add mutation-based fuzzing support to SQLancer. To this end, random decisions in the generators (mostly implemented in the Randomly class) should be recorded as seed inputs (so-called decision seeds), and further mutated. Different ways of measuring whether a test input triggers an interesting behavior should be tried and experimented with; for example, query plans are one potential feedback signal.
      Required skills: Strong Java skills are essential and experience with using Git as well as basic SQL knowledge is expected
      Expected size: Either 175 or 350 hour
      Difficulty: Medium
      Expected outcomes: Initial prototype that can be merged into the main SQLancer repository
      Potential mentors: @albertZhangTJ


      ~~~~~~~~~~
      Adding support for latest Postgres version
      Today, SQLancer only supports Postgres version 12, which became End-of-Life in Nov 2024. The goal of this project is to advance SQLancer to support the latest version of Postgres, which would involve not just modifying generators to address deprecations and new features launched.
      Changes in a Postgres version can be reviewed in the release notes (for e.g. in order to make SQLancer support version 17 of Postgres, the v17 release notes would highlight the key changes). A stretch goal would be to add support for features, such as additional data-types (JSON), procedural extensions, etc. Additionally, for databases that are already supported by SQLancer, it would be beneficial to extend support to their latest versions.
      Required skills: Strong Java skills are essential and experience with using Git as well as basic SQL knowledge is expected
      Expected size: Either 175 or 350 hour
      Difficulty: Medium
      Expected outcomes: Support the latest version of Postgres (HEAD branch)
      Potential mentors: @robins

      ~~~~~~~~~~
      Architecture redesign for SQLancer
      SQLancer has undergone efforts to redesign its architecture to improve reusability of test oracles across different database management systems (DBMSes). However, this effort faced challenges due to incorrect assumptions regarding the DBProvider and DBConnection components. For example, the majority of DBMSes have a JDBC implementation, but CnosDB does not, requiring the development of a custom client. This means that common test oracle will not work in such cases.
      The goal of this project is to design and implement a common connection mechanism that will standardize how oracles send and receive data from DBMSes. By doing so, we aim to reduce code duplication, simplify the integration of new DBMSes, and facilitate further development in SQLancer. Additionally, we aim to continue the creation of common test oracles, particularly by expanding on the subtypes of Ternary Logic Partitioning (see implementation for Postgres).
      Required skills: Moderate Java programming skills and Unix/Linux familiarity. SQL knowledge is not necessary
      Expected size: 175 hours
      Difficulty: Medium
      Expected outcomes: A unified connection component and more implementations of common test oracles
      Potential mentors: @malwaregarry

      ~~~~~~~~~~
      Supporting Automated Scripts for DBMS Deployment
      SQLancer is a tool to automatically test Database Management Systems, but setting up the corresponding DBMS instances for testing demands significant manual effort. Beginners often find it challenging to navigate the process, which involves carefully reading documentation to build and start the server, followed by configuring SQLancer to initiate fuzzing.
      The goal of this project is to develop a suite of automation scripts that streamline the entire process: automatically building DBMSs, starting them, configuring SQLancer, and launching tests. Docker is a potential solution. Additionally, providing these unified deployment scripts can make the bug reproduction both simpler and more reliable.
      Required skills: Moderate Docker and Unix/Linux familiarity. SQL or Java knowledge is not necessary
      Expected size: Either 90 or 175 hours
      Difficulty: Easy
      Expected outcomes: Scripts to deploy the DBMS and start SQLancer testing
      Potential mentors: @suyZhong

      ~~~~~~~~~~
      Automating Testing Workflow of SQLancer
      SQLancer supports close to 20 database systems (see the subdirectories with the relevant database names at src/sqlancer); however, testing a new DBMS demands manual tasks such as building the system, starting the DBMS server, running SQLancer to execute tests, and subsequently reporting any discovered bugs.
      To address these challenges, the project will design and implement an intelligent automation tool--potentially leveraging a large language model (LLM) agent--that delivers a push-button testing procedure. This tool will automatically build and initiate the DBMS server according to its documentation, run SQLancer tests, and generate bug reports automatically.
      Required skills: Moderate Python programming skills, Docker and Unix/Linux familiarity. SQL or Java knowledge is not necessary
      Expected size: 350 hours
      Difficulty: Hard
      Expected outcomes: An LLM agent that can automatically deploy the DBMS and start SQLancer testing
      Potential mentors: @suyZhong

      ~~~~~~~~~~
      Integrating Published Testing Approaches into SQLancer
      Various effective automated testing approaches for database systems such as Differential Query Execution (DQE) have been published, but not integrated into SQLancer. The goal of this project is to integrate DQE and potentially also other testing approaches into SQLancer.
      The integration should happen while minimizing invasive changes to the existing architecture and aiming to make it easier to integrate future approaches. Thus, this project will require understanding SQLancer's architecture and how existing approaches could be elegantly integrated.
      Required skills: Java programming skills. SQL knowledge is not necessary
      Expected size: 175 hours
      Difficulty: Medium
      Expected outcomes: Integration of DQE and potentially other automated testing approaches
      Potential mentors: @JensonSung

      ~~~~~~~~~~
      Enhancing SQLancer with External Reducer Support
      This project aims to improve SQLancer’s test reduction framework by enabling seamless integration of external reducers. Currently, SQLancer includes an experimental delta-debugging approach using StatementReducer and ASTBasedReducer, but these components are tightly coupled, making it difficult to incorporate alternative reducers. Previously, SQLancer used C-Reduce, which required specifying the test oracle in a script.
      To address these limitations, this project will introduce a flexible interface that allows different test reducers to be easily integrated and configured. This will enable SQLancer to support a wider range of database engines while allowing users to switch between reduction strategies as needed. Additionally, the project will refine both the Delta Debugging (DD) and AST-Based Reducer by incorporating Hierarchical Delta Debugging (HDD) as a preprocessing step. This will enable an initial hierarchical grouping of test cases to simplify the input space before applying both DD and AST-based reductions, improving the efficiency and effectiveness of the bug-reduction process.
      Objectives:
      Develop a modular interface for integrating external reducers.
      Improve SQLancer’s existing AST-based reduction and DD with HDD preprocessing.
      Enable seamless integration of reducers like C-Reduce and Perses.
      Required Skills: Strong Java and SQL skills are essential and experience with using Git.
      Expected size: Either 175 or 350 hour
      Difficulty: Medium
      Expected Outcome: A flexible and efficient test reduction system in SQLancer, enabling easy integration of external reducers and improving both DD and AST-based reductions through Hierarchical Delta Debugging (HDD).
      Potential mentor: @kabilanma
      Additional links:
      Using C-Reduce with SQLancer: https://www.youtube.com/watch?v=vkfdYyn40Qw
      HDD: https://users.cs.northwestern.edu/~robby/courses/395-495-2009-fall/hdd.pdf
      C-Reduce: https://github.com/csmith-project/creduce
      Perses: https://github.com/uw-pluverse/perses
      DD: https://www.debuggingbook.org/html/DeltaDebugger.html
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/sqlancer/
    idea_list_url: https://github.com/sqlancer/sqlancer/wiki/GSoC-2025-Ideas


  - organization_id: 136
    organization_name: SW360
    no_of_ideas: 7
    ideas_content: |
     
      License Change Detection
      Goal: Understand the changes in licensing between two versions of a software package.
      This would be combined effort between SW360 and FOSSology.
      As the software evolves in time, so does their licensing. A scenario where a package (say “mylib-v1.2”) was scanned by FOSSology and cleaned by a clearing team. The new version of the package (say “mylib-v1.5”) was released and uploaded again to FOSSology for clearing. Now, another metric can be generated showing the files from both packages against the change in licensing per file (addition, removal, change of license or new file).
      This either can be shown in FOSSology itself, but also when doing an initial scan report (ISR), triggered from SW360. Then it would be very visible for the requester if there are changes in the new version of the release or not. Also, the diff could be shown in the CLI files.
      It can generate a table like:
      File path mylib-v1.2 mylib-v1.5
      path/to/file MIT MIT
      path/to/file2 MIT,BSD MIT
      path/to/file3 GPL-2.0 GPL-3.0
      path/to/new-file BSD
      Category Rating
      Low Hanging Fruit **
      Risk/Exploratory *
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure **
      Project size Medium
      Preferred contributor Student/professional
      Skills needed XML, Java
      Contact @EttingerK @GMishx

      ~~~~~~~~~~

      Improve integration with FOSSology
      Goal: Use extended REST API of FOSSology to improve the “Send to FOSSology” feature
      SW360 already have ways to interact with FOSSology, however the interaction as of now is very limited. The idea is to expand on this interaction and make use of extended REST API of FOSSology and have features like:
      Upload source to FOSSology
      Search and link to existing sources with checksum match
      Reuse previous version of release uploaded/existing in FOSSology
      Provide option to select agents for scanning in FOSSology
      Fetch different kind of reports from FOSSology, not just SPDX
      Relevant information:
      FOSSology REST API: https://github.com/fossology/fossology/blob/master/src/www/ui/api/documentation/openapiv2.yaml
      SW360 existing endpoints: releases/{id}/checkFossologyProcessStatus
      SW360 existing endpoints: releases/{id}/triggerFossologyProcess
      Category Rating
      Low Hanging Fruit ***
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development **
      Project Infrastructure **
      Project size Large
      Preferred contributor Student/professional
      Skills needed Java, REST & HTTP libraries
      Contact @GMishx, @rudra-superrr

      ~~~~~~~~~~
      Thrift layer removal
      Goal: Remove thrift layer for communication with Database
      Remove thrift layer which is used to interact with DB as it is not required and makes the installation process of SW360 unnecessarily complex. This change will help project moving forward with modern architectures like microservices.
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory ***
      Fun/Peripheral **
      Core Development ***
      Project Infrastructure **
      Project size Large
      Preferred contributor Student/professional
      Skills needed Java, CouchDB
      Contact @GMishx @smrutis1 @heliocastro

      ~~~~~~~~~~
      Improve tests for all REST API endpoints
      Goal: Improve existing tests for all REST API endpoints and write new tests
      Write unit and integration tests for all REST API endpoints. This will help in improving the code quality and make the project more robust.
      Category Rating
      Low Hanging Fruit ***
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development ***
      Project Infrastructure **
      Project size Medium
      Preferred contributor Student/professional
      Skills needed Java, JUnit, REST API
      Contact @GMishx @heliocastro @keerthi-bl

      ~~~~~~~~~~
      SBOM based recommendation
      Goal: Recommendation of packages based on SBOM of a project
      When a user imports a SBOM file, the tool will share the information about the cleared & uncleared packages used in that project based on existing knowledge available in SW360. In addition to that if any package is uncleared,
      The tool will recommend equivalent package, which is already cleared in SW360, which in turn will reduce the project clearing time.
      If the user still wants to use the same uncleared package, the tool will give an estimated time to clear the package as well as the project using reports like ISR.
      Category Rating
      Low Hanging Fruit **
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development **
      Project Infrastructure **
      Project size Large
      Preferred contributor Student/professional
      Skills needed Java, Python, AI/ML
      Contact @amritkv @GMishx

      ~~~~~~~~~~
      Creating Project as a Service
      Goal: Separate out the Project and related modules as a separate microservice
      The idea is to separate the Project related modules as a separate microservice which can then be customized independently for different organizations while still reusing the common Component repository.
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory ***
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure ***
      Project size Large
      Preferred contributor Student/professional
      Skills needed Java, Spring, Microservices, REST
      Contact @keerthi-bl @GMishx @heliocastro

      ~~~~~~~~~~
      Update Official Documentation Page
      Goal: Separate out the Project and related modules as a separate microservice
      Motivation
      The current official documentation page (https://eclipse.dev/sw360/) lacks clear instructions regarding environment configurations and upgrade procedures for recent software versions. This discrepancy often confuses users and negatively affects productivity during installation or updating processes. Keeping the official documentation accurate and up-to-date helps attract new users and fosters an active user community. Moreover, documentation updates do not require direct changes to the software source code, allowing contributors to undertake this task concurrently with other development or testing activities, thus lowering the barriers for OSS contributions.
      Proposed Changes
      Clearly document environment setup instructions and upgrade procedures corresponding to the latest software versions.
      Complement missing details in documentation, such as updates to dependencies and version compatibility, reducing user confusion.
      Enhance visual clarity by adding practical examples and screenshots illustrating the updated procedures.
      Notes
      This task involves no source code modifications, making it easy to execute alongside other development tasks or community activities.
      Documentation updates are valuable contributions to OSS projects and serve as excellent entry points for new contributors.
      It is advisable to explicitly recognize documentation maintenance as a significant and formally acknowledged form of OSS contribution.
      Category Rating
      Low Hanging Fruit ***
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development *
      Project Infrastructure ***
      Project size Medium
      Preferred contributor Student/professional
      Skills needed Markdown, Hugo
      Contact @GMishx @heliocastro @KoukiHama
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/sw360/
    idea_list_url: https://eclipse.dev/sw360/gsoc/gsoc-projects-2025/


  - organization_id: 137
    organization_name: SageMath
    no_of_ideas:
    ideas_content: |
      This website is down for maintenance, please come back later (~7h expected downtime, until 20:00 Europe/Paris).
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/sagemath/
    idea_list_url: https://wiki.sagemath.org/GSoC/2025

  - organization_id: 138
    organization_name: Scala Center
    no_of_ideas: 22
    ideas_content: |

      Doodle Bitmap Convolutions
      Title Doodle Bitmap Convolutions
      Link to Project creativescala/doodle#94
      Brief Description Add support for bitmap convolutions to Doodle. The link has more, including a Github project laying out the steps.
      Expected Outcome Working code and documentation.
      Prerequisites Some Scala knowledge.
      Ideal Prerequisites Basic knowledge of bitmap convolutions, some understanding of tagless final.
      Expected Difficulty Easy – straightforward task, path for execution visible right now, very little uncertainty
      Expected Time Commitment Medium project – 175 hours
      Mentor Noel Welsh (GitHub: @noelwelsh, Email: noel@noelwelsh.com)
      Co-mentor

      ~~~~~~~~~~
      Doodle Skia Backend
      Title Doodle Skia Backend
      Link to Project creativescala/doodle#175
      Brief Description Add a Skia backend for Doodle, using the Skiaj bindings.
      Expected Outcome Working code and documentation.
      Prerequisites Some Scala knowledge.
      Ideal Prerequisites Some understanding of type classes or tagless final.
      Expected Difficulty Easy – straightforward task, path for execution visible right now, very little uncertainty
      Expected Time Commitment Medium project – 175 hours
      Mentor Noel Welsh (GitHub: @noelwelsh, Email: noel@noelwelsh.com)
      Co-mentor

      ~~~~~~~~~~
      Krop Template Engine
      Title Krop Template Engine
      Link to Project creativescala/krop#14
      Brief Description Create an HTML template engine for the Krop web framework.
      Expected Outcome Working code and documentation.
      Prerequisites Intermediate Scala knowledge and basic HTML knowledge.
      Ideal Prerequisites An understanding of parsing.
      Expected Difficulty Medium – some design decisions need to be made and the implementation is not straightforward.
      Expected Time Commitment Medium project – 175 hours
      Mentor Noel Welsh (GitHub: @noelwelsh, Email: noel@noelwelsh.com)
      Co-mentor

      ~~~~~~~~~~
      Business4s: Workflows4s Web UI
      Title Workflows4s Web UI
      Link to Project https://github.com/business4s/workflows4s
      Brief Description Implement web user interface for Workflows4s. Design the API and implement both server and web side using scala and scala.js. See business4s/workflows4s#19 for details.
      Expected Outcome Proof of concept of the UI that can present progress of a workflow instance.
      Prerequisites Basic scala skills, basic frontend skills, basic knowledge of HTTP APIs (e.g. REST).
      Expected Difficulty Medium
      Expected Time Commitment Large project - 350 hours
      Spoken Language English
      Mentor Voytek Pituła (GitHub: @Krever, Email: w.pitula@gmail.com)
      Co-mentor Dave Smith (Github: @davesmith00000, Email: david.smith@purplekingdomgames.com)

      ~~~~~~~~~~
      Business4s: ChatOps4s Prototype
      Title ChatOps4s Prototype
      Link to Project To be created under https://github.com/business4s
      Brief Description Prototype of library/toolkit allowing to easily send messages and receive input from chat platforms (e.g. Slack)
      Expected Outcome Prototype that allows getting information in and out Slack with as little effort as possible. Research on how hard will it be to support other platforms.
      Prerequisites Ability to research and consume external APIs. Basic exposure to some chat platform (Slack, Discord, MS Teams)
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Voytek Pituła (GitHub: @Krever, Email: w.pitula@gmail.com)
      Co-mentor -

      ~~~~~~~~~~
      Play Framework Support in Metals
      Title Play Framework Support in Metals
      Link to Project scalameta/metals-feature-requests#50 scalameta/metals-feature-requests#89
      Brief Description Add support for Play Framework specific files in Metals language server
      Expected Outcome Working code and documentation.
      Prerequisites Intermediate Scala knowledge and basic HTML knowledge.
      Ideal Prerequisites An understanding of parsing and language server protocol.
      Expected Difficulty Medium – some design decisions need to be made and the implementation is not straightforward.
      Expected Time Commitment Medium project – 175 hours
      Mentor Tomasz Godzik (GitHub: @tgodzik, Email: tomek.godzik@gmail.com)
      Co-mentor

      ~~~~~~~~~~
      Cyfra: Support for basic GPU computations on data streams with fs2 integration
      Title
      Link to Project https://github.com/ComputeNode/cyfra
      Brief Description Cyfra is a GPU runtime and a DSL that makes Scala a viable choice for GPU programming. Goal of the project is to implement support for GPU computations on data streams with focus on usability.
      Expected Outcome Cyfra should enable developers that do not have background in GPU programming to write a simple data processing pipeline in Cyfra that performs compute on GPU and efficiently manages memory. The pipeline should be interoperable with fs2.
      Prerequisites Some experience with Scala, and interest to learn a bit about GPUs.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Szymon Rodziewicz (LinkedIn, Github: szymon-rd, Email: szymonrodant@gmail.com)
      Co-mentor -

      ~~~~~~~~~~
      Cyfra: Real-time rendering pipeline
      Title
      Link to Project https://github.com/ComputeNode/cyfra
      Brief Description Cyfra is a GPU runtime and a DSL that makes Scala a viable choice for GPU programming. Goal of the project is to implement a basic real-time Vulkan rendering pipeline.
      Expected Outcome Cyfra should enable developers to create programs that will render scenes from a basic one-step Vulkan pipeline in real time. It should support rendering to a window, a data stream, and a file.
      Prerequisites No Scala experience is required, but basic experience with GPU programming would be helpful.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Szymon Rodziewicz (LinkedIn, Github: szymon-rd, Email: szymonrodant@gmail.com)
      Co-mentor -

      ~~~~~~~~~~
      Cyfra: Real time SDF editor
      Title
      Link to Project https://github.com/ComputeNode/cyfra
      Brief Description Cyfra is a GPU runtime and a DSL that makes Scala a viable choice for GPU programming. Goal of the project is to implement a real-time SDF (signed distance fields) editor as a VSCode extension.
      Expected Outcome Cyfra vscode extension should be tool that would allow its users to render 3D SDF-based scenes and see changes in their code reflected in the output in real time.
      Prerequisites Some experience with Scala or TypeScript, and interest to learn a bit about GPUs, Scala, and VSCode extension development.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Szymon Rodziewicz (LinkedIn, Github: szymon-rd, Email: szymonrodant@gmail.com)
      Co-mentor -

      ~~~~~~~~~~
      Cyfra: Scala Native MVP
      Title
      Link to Project https://github.com/ComputeNode/cyfra
      Brief Description Cyfra is a GPU runtime and a DSL that makes Scala a viable choice for GPU programming. Goal of the project is to make it run on Scala Native.
      Expected Outcome Fundamental features of the cyfra library should run on Scala Native and make it possible to build efficient real-time rendering and data processing applications.
      Prerequisites Some experience with Scala, and interest to learn a bit about GPUs.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Szymon Rodziewicz (LinkedIn, Github: szymon-rd, Email: szymonrodant@gmail.com)
      Co-mentor -

      ~~~~~~~~~~
      Scala Native / Scala.js Projects
      Title Scala Bazel Rules for Scala.js and Scala Native
      Link to Project https://github.com/bazelbuild/rules_scala
      Brief Description This project aims to develop Bazel build rules for Scala.js and Scala Native, enabling efficient and reproducible builds for both platforms. The project will provide first-class support for Scala projects within the Bazel ecosystem, improving integration and developer experience.
      Expected Outcome Functional and well-documented Bazel rules that allow compiling, testing, and packaging Scala.js and Scala Native projects. Demonstration projects showcasing usage.
      Prerequisites Experience with Scala, build tools (SBT, Bazel), and Scala.js/Scala Native basics. Some familiarity with Bazel rule definitions is a plus.
      Expected Difficulty Medium
      Expected Time Commitment Large project - 350 hours
      Mentor Wojciech Mazur (GitHub: @WojciechMazur, Email: wmazur@virtuslab.com)
      Co-mentor TODO

      ~~~~~~~~~~
      Title JMH-Compliant Benchmarking Framework for Scala Native & Scala.js
      Link to Project Scala Native / Scala.js
      Brief Description This project aims to implement a benchmarking framework similar to JMH (Java Microbenchmark Harness) allowing for accurate and reliable performance measurements on non JVM platforms. Both Scala Native and Scala.js cannot consume a modified JVM bytecode emitted by JMH framework. The goal is to create a runtime implementation for executing microbenchmarks and a Scala compiler plugin performing required transformations of Scala.js / Scala Native code based on JMH framework compiletime annotations.
      Expected Outcome A benchmarking framework that mimics JMH APIs and produces reliable results for Scala Native and Scala.js. Demonstration benchmarks showcasing usage.
      Prerequisites Good understanding of benchmarking principles, Scala Native, Scala.js, and Scala compiler plugins. Some knowledge of JMH is beneficial.
      Expected Difficulty Hard
      Expected Time Commitment Medium project - 175 hours
      Mentor Wojciech Mazur (GitHub: @WojciechMazur, Email: wmazur@virtuslab.com )
      Co-mentor Sébastien Doeraene (GitHub: @sjrd, Email: sjrdoeraene@gmail.com )

      ~~~~~~~~~~
      Scala Native Projects
      Title Incremental Optimization of Scala Native IR
      Link to Project Scala Native
      Brief Description This project aims to implement incremental optimization for Scala Native’s Intermediate Representation (IR), improving compilation speed by reusing results from previous compilation runs instead of optimizing the entire program from scratch.
      Expected Outcome A working prototype of an incremental optimization pipeline for Scala Native IR, with measurable speedups over full optimizations.
      Prerequisites Strong understanding of compilers, Scala Native IR, and optimization techniques. Knowledge of LLVM and incremental compilation strategies is a plus.
      Expected Difficulty Hard
      Expected Time Commitment Large project - 350 hours
      Mentor Wojciech Mazur (GitHub: @WojciechMazur, Email: wmazur@virtuslab.com )
      Co-mentor Sébastien Doeraene (GitHub: @sjrd, Email: sjrdoeraene@gmail.com )

      ~~~~~~~~~~
      Difflicious UI
      Title Difflicious UI
      Link to Project https://github.com/jatcwang/difflicious
      Brief Description Implement a Web UI for Difflicious which allows users to explore diffs (test failures) reported by Difflicious. The UI should allow the user to expand and minimize section of the diff output in an interactive manner.
      Expected Outcome Working UI and documentation
      Prerequisites Good working knowledge of Scala and web technologies (Javascript, CSS, HTML). The project will be implemented in Scala.js (most likely with Laminar
      Expected Difficulty Hard
      Expected Time Commitment Large project - 350 hours
      Spoken Language English
      Mentor Jacob Wang (GitHub: @jatcwang, Email: jatcwang@gmail.com)

      ~~~~~~~~~~
      Difflicious: Differ for Json type
      Title Difflicious: Differ for Json type
      Link to Project https://github.com/jatcwang/difflicious
      Brief Description Implement a differ which supports JSON types from popular Scala libraries (e.g. Circe). The current sealed trait Differ will be completely reworked to support any general disjoint union.
      Expected Outcome A differ that can diff two two io.circe.Json values
      Prerequisites Good working knowledge of Scala
      Expected Difficulty Hard
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Jacob Wang (GitHub: @jatcwang, Email: jatcwang@gmail.com)

      ~~~~~~~~~~
      A Pandas Experience
      Title One line CSV import in scala
      Link to Project https://github.com/Quafadas/scautable
      Brief Description Python through Pandas has a great data import experience. This project aims to replicate parts of that by parsing parts of the datasource at compile time, i.e. bringing knowledge of the structure and headers of your datasource inside the compilers knowledge. It's goal is to help you discover your data, rather than force to you to write out it's metadata in advance. It's target audience will be writing non production, data sciency type scripts. Many of the motivating examples come from kaggle.com
      Expected Outcome Can be measured in the increased number of successful test cases. I believe the "fundamental" idea has legs, but is currently limited to a small number of scenarios explored in my free time. The goal of the project is to expand the set of scenarios in which it is useful. Initial easy issues surround details such as correctly parsing headers, checking special characters, improving error messages and writing data back to (e.g. CSV). From there it should be possible to graduate to adding more datasources, for example SQL (hopefully simple - or harder, for example exploring apache parquet.) Stretch goals could include exploring strategies for streaming statistics, deriving visualisations, critiquing the design vs e.g. Kantan.csv, and / or attempting to help the consumer identify the "types" of the data at compile time.
      Prerequisites Basic scala / java knowledge. The barrier to "getting started" ought to be rather low. The initial issues are largely detail driven rather than design driven. Basic experience with testing (munit), CI (GHA) and scala standard library would be enough to contribute.
      Expected Difficulty Easy
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Simon Parten (GitHub: @quafadas, Email: quafadas@gmail.com)
      Co-mentor Volunteers wanted here too I guess :-)


      ~~~~~~~~~~
      
      Scalus – Scala 3 compiler backend and DApps development platform for Cardano
      Title
      Link to Project https://github.com/nau/scalus
      Brief Description Scalus is a platform for developing full-stacke decentralized applications (DApps) on the Cardano blockchain using a single language, Scala 3, tools and code for frontend, backend and smart contracts development. Scalus implements a Scala 3 compiler backend that compiles Scala to Cardano Plutus Core – a lambda calculus inspired smart contracts language.
      Expected Outcome Enable more Scala 3 features to be compiled to Plutus Core: arbitrary size Tuples, better pattern-matching conversion algorithm. Improvements in our code generator, and various lambda calculus optimizations: inliner, common subexpression eliminator etc. We also expect improvements in Scalus standard library, test coverage and documentations.
      Prerequisites Basic Scala knowledge. Basic understanding of compiler theory and blockchain technology is a plus.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Alex Nemish Github, Email: anemish@gmail.com
      Co-mentor Ruslan Shevchenko. Github Email: ruslan@shevchenko.kiev.ua

      ~~~~~~~~~~
      Scaladex: Support for Compiler Plugins
      Title Scaladex: Support for Compiler Plugins
      Link to Project https://github.com/scalacenter/scaladex/
      Brief Description Add support for compiler plugins in Scaladex, the index website of open source Scala artifacts. Adapt the UI of the front page, search page and project page to allow searching, and browsing compiler plugins and their versions. See full description in scalacenter/scaladex#865
      Expected Outcome Scaladex should index compiler plugin artifacts, such as org.typelevel:kind-projector_2.13.16:0.13.3. It should show them as a separate platform on the front page, search page and project page.
      Prerequisites Some experience with Scala and SQL. Good knowledge about HTML and css
      Ideal Prerequisites Some knowledge of the Scala ecosystem, such as Scala platforms and binary versions
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Kannupriya Kalra (LinkedIn, Email: kannupriyakalra@gmail.com)
      Co-mentor Adrien Piquerez (GitHub: @adpi2, Email: adrien.piquerez@gmail.com)

      ~~~~~~~~~~
      LLM4S - Implement an agentic toolkit for Large Language Models
      Title LLM4S - Implement an agentic toolkit for Large Language Models
      Link to Project https://github.com/rorygraves/llm4s
      Brief Description LLM4S is creating a Large Language Model (LLM) toolkit for Scala. This project uses the power of Scala to make building LLM based applications easier. LLMs can be used in an agentic style where the LLM is allowed to call provided tools to access resources (such as reading a webpage, or calling an API service to perform a task). The goal of this project is to implement an agentic loop and basic tools supporting infrastructure within the toolkil.
      Expected Outcome LLM4S should have an agentic LLM toolkit wtih, documentation, examples and basic tools such as file and webbrower usage to allow users to immediately start building agentic style applications.
      Prerequisites Some exerience of Scala and LLMs.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Kannupriya Kalra (LinkedIn, Email: kannupriyakalra@gmail.com)
      Co-mentor Rory Graves (LinkedIn, Email: rory.graves@fieldmark.co.uk)

      ~~~~~~~~~~
      LLM4S - RAG in a box
      Title LLM4S - RAG in a box
      Link to Project https://github.com/rorygraves/llm4s
      Brief Description LLM4S is creating a Large Language Model (LLM) toolkit for Scala. This project uses the power of Scala to make building LLM based applications easier. Beyond simple chat use cases we want to make it easy to build LLM based apps. One of the most common facilities is RAG (Retrieval Augmented Generation) where documents are chunked and embedded and then retrieved to provide context to the question being asked. The goal is to extend the LLM framework with RAG tools to make building RAG Search easy.
      Expected Outcome LLM4S should have a RAG framework which allows integration with an embedding store. The framework should support pushing documents into external stores (e.g. Postgress with pgVector or Azure AI Search Service) and implement RAG search over the top of the store, and include documentation, examples.
      Prerequisites Some exerience of Scala and LLMs.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Kannupriya Kalra (LinkedIn, Email: kannupriyakalra@gmail.com)
      Co-mentor Rory Graves (LinkedIn, Email: rory.graves@fieldmark.co.uk)

      ~~~~~~~~~~
      LLM4S - Support image, voice and other LLM modalites
      Title LLM4S - Support image, voice and other LLM modalites
      Link to Project https://github.com/rorygraves/llm4s
      Brief Description LLM4S is creating a Large Language Model (LLM) toolkit for Scala. This project uses the power of Scala to make building LLM based applications easier. LLMs support a number of modalities other than chat, e.g., image generation, voice and embeddings. The goal of this project is to extend the API created in LLM4S to create APIs for calling these other use cases.
      Expected Outcome As well as chat, LLM4S LLM interface should now have support for image, voice (speech to text and text to speech) and embeddeding, giving users access to more usecases. As well as the API, we will provide examples and documentation.
      Prerequisites Some exerience of Scala and LLMs.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Kannupriya Kalra (LinkedIn, Email: kannupriyakalra@gmail.com)
      Co-mentor Rory Graves (LinkedIn, Email: rory.graves@fieldmark.co.uk)

      ~~~~~~~~~~
      LLM4S - Tracing Support
      Title LLM4S - Tracing support
      Link to Project https://github.com/rorygraves/llm4s
      Brief Description LLM4S is creating a Large Language Model (LLM) toolkit for Scala. This project uses the power of Scala to make building LLM based applications easier. As LLM based apps grow it becomes harder to understand the application and LLM interaction flow. We want to add tracing support into the application and a UI allowing exploration of the application traces, showing the calls, spans, timing and other information to help understand the flow.
      Expected Outcome An exampling tracing feature within the core of LLM5S that emits tracing data consumable by a created UI to allow a user to follow the execution flow of a user developed application.
      Prerequisites Some exerience of Scala and LLMs.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Kannupriya Kalra (LinkedIn, Email: kannupriyakalra@gmail.com)
      Co-mentor Rory Graves (LinkedIn, Email: rory.graves@fieldmark.co.uk)

    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/scala-center/
    idea_list_url: https://github.com/scalacenter/GoogleSummerOfCode

  - organization_id: 139
    organization_name: ScummVM
    no_of_ideas: 13
    ideas_content: |
     
      Macromedia Director
      Technical contacts: sev
      Difficulty level: Medium. You'll need a reasonable level of programming experience, and probably some Director games.
      Size: 175 or 350 hours
      Many 90s-era adventure games were developed using the Macromedia (now Adobe) Director tool. We added so far support for Director 3 and Director 4, but there is much more work related to the specific Xtras, increasing compatibility and working on Director 5 support.
      These days, due to the relatively high compatibility our approach is taking an interesting Director title, trying to play it and fix any issues along the way, thus making the process pretty fun. During playback, we often compare the titles and behaviors with the original.
      Often, we implement stubs for XObjects, which are extensions for Director functionality.
      Besides the core engine development, there is a lot of work on the visual source level debugger, written with use of ImGUI.
      
      ~~~~~~~~~~

      
      Amnesia: The Dark Descent and A Machine for Pigs (HPL2 engine)
      Technical contacts aquadran or sev
      Difficulty level: Hard. OpenGL knowledge is required
      Size: 350 hours
      Frictional Games has released full sources for their HPL2 engine under GPLv3 license. In 2022 we added HPL1 engine and now we could consider adding HPL2. The size of the task is huge since the engines are 275k and 240k lines of code respectively, but we already have experience from working on Penumbra.
      The purpose of this project is to port the HPL2 engine to ScummVM, with the goal of supporting Amnesia: The Dark Descent and Amnesia: A Machine for Pigs.
      
      ~~~~~~~~~~
      Finishing implementation of incomplete engines
      Technical contacts: sev or strangerke
      Difficulty level: Medium or High
      Size: 175 hours or 350 hours
      ScummVM currently has a number of engines that are very close to completion. Many of them were parts of previous GSoCs. For them, we need a playthrough and slight bug fixing, or additional portability fixes.
      Some of the engines are:
      MacVenture, based on a JavaScript reimplementation. Very close to completion, playthrough is missing and rechecking ties to our Mac GUI emulation.
      Avalanche, some engine parts like Outro are not finished. Complete list is here
      DM
      Comprehend, finishing support for Transylvania (V2), and adding support for the 16-color Apple IIgs versions
      
      ~~~~~~~~~~
      Porting ADL to ScummVM
      Technical contacts: sev
      Difficulty level: Medium or High
      Size: 350 hours
      ADL (Adventure Definition Language, not to be confused with Sierra's ADL) was created in 1987 by Tim Brengle and Ross Cunniff and released as freeware. Subsequent modifications to the engine have been made since and released under GPL. Documentation as well as a compiler and interpreter can be found at this link.
      Only one commercial game is known to have been released using ADL: Transylvania III. The previous 2 entries in the series use the Comprehend engine.
      The purpose of this task is to port this engine to ScummVM's Glk engine.
      
      ~~~~~~~~~~
      Porting ACK engine to ScummVM
      Technical contacts: sev
      Difficulty level: Medium
      Size: 350 hours
      ACK (Adventure Creation Kit) was a Pascal-written game development system. Its sources were released under Public Domain, and there is a port to Free Pascal. The whole solution is mid-size, around 16k lines of code, but it must be converted to C++ before porting. A program such as p2c (Pascal-to-C) converter could be used for the initial code conversion, but then, the manual work on making things work will follow.
      There are several RPG-like games build on the engine, the most notable one is Ultima-like games.
      The purpose of this task is to port this engine to ScummVM as a separate engine engine.
      
      
      ~~~~~~~~~~
      Porting Ambermoon/Amberstar engine to ScummVM
      Technical contacts: sev
      Difficulty level: Hard / Very Hard
      Size: 350 hours
      Ambermoon and Amberstar were nice Amiga RPGs created by Thalion Software GmbH, a German company in early 90s. There are complete sources released for both games: here and [here. It is technically possible to rewrite them in C++.
      The task will require learning or knowledge of the beautiful Motorola Assembly language and some knowledge on how Amiga worked with graphics and sound.
      
      ~~~~~~~~~~
      Porting FITD (Alone in the Dark) engine to ScummVM
      Technical contacts: sev, somaen
      Difficulty level: Hard
      Size: 350 hours
      FITD is an engine for playing Alone in the Dark 1-3 games. It is a mid-size engine with 23k lines of code, not in active development now.
      The goal of this project is porting the engine code to ScummVM's OSystem framework. o
      The goal of this project is to rewrite/convert all of this into C++ and add to ScummVM.
      
      ~~~~~~~~~~
   
      Add Keymapper to more games
      Technical contacts: sev
      Difficulty: Easy
      Size: 175 or 350 hours, depending on the number of games
      ScummVM includes a global fully configurable keymapper, but this requires engines to be adapted to use it. The feature documentation: Keymapper, some reference implementations: Wintermute has per-game keymaps; a pull request with adding keymapper to HDB engine; a commit with adding Keymapper to a simpler engine, Griffon.
      The current status can be found at Keymapper_and_TTS_status page.

      ~~~~~~~~~~
      
      Add Text-to-Speech to more games
      Technical contacts: sev
      Difficulty: Easy
      Size: 175 or 350 hours, depending on the number of games
      ScummVM has Text-to-Speech (TTS) functionality that we are using for the games that have no speech (or limited options for speech). That improved the usability of the games and, obviously, their accessibility.
      The current status per engine can be found on the Keymapper_and_TTS_status page.
      For each engine, the task varies from straightforward to a mid-complexity:
      Identify routines that show text on the screen
      Potentially, clean up text from things like colors and fonts
      Feed this text to TTS
      Define GUI options for triggering the option
      
      ~~~~~~~~~~
      Implementing minigame interface in qdEngine
      Technical contacts: sev
      Difficulty level: Medium
      Size: 175 hours
      Last year, we successfully ported qdEngine to ScummVM. However, there are a few smaller tasks left:
      Implementing interface for advanced mini-games
      Fixing pathfinding
      Fixing actor lighting in some circumstances
      Adding more features to the debugger, written in ImGui
      This could be a good introductory task into general engine development for a well-established engine codebase.
      If you can understand Russian, you may also help with playtesting the rest of the games and perhaps fixing any issues that we discover.
      
      ~~~~~~~~~~
      Porting ALIS engine to ScummVM
      Technical contacts: sev
      Difficulty level: Medium
      Size: 175 hours
      ALIS (Actor Language Integrated System) is an engine that was used by Simlarils for most of their games and about 17 of them are expected to work on this engine. There is an engine that is almost complete, it is pretty small, less than 10k lines of code and is distributed under MIT license. Engline and we also have Ghidra projects for the engine.
      The purpose of this task is to port this engine to ScummVM as a separate engine engine.
      
      ~~~~~~~~~~
      
      YAGA engine
      Technical contacts: sev or strangerke
      Difficulty level: Medium.
      Size: 175 hours
      This engine was used for two later Humongous Entertainment games, Pajama Sam: Life is Rough When You Lose Your Stuff and Putt-Putt: Pep's Birthday Surprise. The engine is basically an extension of Python 2.2. There exists an almost complete reimplementation by cyx on GitHub (which we have permission to use) that can be used as a base, and we also have the complete source code for the original game.
      The task is relatively straightforward, the only difficulty with it is adding Python as an external dependency, but a mentor is there to help. Implementing the missing "Lip Sync" feature will be the main part of this task.
      The goal is to bring cyx's code to ScummVM and use the original code as a reference later.
      
      
      ~~~~~~~~~~
      System for checking the game files integrity
      Technical contacts: sev
      Languages: Python, optionally C++
      Difficulty: Medium
      Size: 175 hours
      ScummVM requires game data files to operate. Very often, especially when copying from the old media, the files could be damaged. Thus, we need a system that could let the end-users compute all the checksums and compare them with the reference.
      The solution consists of two parts: server and additional functionality within ScummVM. In order to avoid any potential problems with the copyrighted material, only checksums could be passed to the server.
      We already have a bulk of this task implemented but not yet fully integrated with ScummVM. There are two parts: Server, written in Python, and the original ScummVM Pull Request.
      We need to complete this task and make it fully functional.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/scummvm/
    idea_list_url: https://www.scummvm.org/gsoc-2025-ideas


  - organization_id: 140
    organization_name: Society for Arts and Technology (SAT)
    no_of_ideas: 11
    ideas_content: |

      Compute-Agnostic Compilation of Audio and Media Processing Objects for FPGA Acceleration
      Jean-Michaël Celerier 2025-02-20 Source
      Project title/description
      Compute-Agnostic Compilation of Audio and Media Processing Objects for FPGA Acceleration

      More detailed description of the project
      Media creation utilizes a variety of audio and media processing objects for interactive performances. This project aims to enable the offloading of computationally intensive processing tasks to heterogeneous hardware, such as FPGAs or GPUs, by leveraging compute-agnostic programming models like SYCL or AdaptiveCpp. The project will involve creating a compilation pipeline that transforms existing audio and media processing objects into code suitable for execution on FPGAs, using AdaptiveCpp to abstract away the underlying hardware details. This allows for targeting different platforms with minimal code changes and enables significant performance gains through hardware acceleration and offloading. The project would explore optimizing data transfer between the host system and the FPGA and developing efficient implementations of common audio and media processing algorithms in AdaptiveCpp.

      Expected outcomes
      Development of a compilation pipeline that translates audio and media processing objects through AdaptiveCpp compiler or an equivalent technology.
      Implementation of any required portability shim to enable compilation of the existing library of objects (e.g., filters, FFTs, convolution).
      Performance evaluation of the FPGA-accelerated processing objects compared to CPU-based implementations.
      Documentation of the compilation pipeline and its usage within ossia score.
      Proof-of-concept implementation on a target FPGA platform.
      Skills required/preferred
      Required: Strong C++ programming skills.
      Required: Understanding of audio and media processing algorithms.
      Required: Experience with parallel programming concepts.
      Preferred: Experience with SYCL or AdaptiveCpp.
      Preferred: Familiarity with FPGA development tools and hardware architectures.
      Preferred: Knowledge of hardware acceleration techniques.
      Preferred: Understanding of compiler design principles.
      Possible mentors
      Jean-Michaël Celerier
      Edu Meneses
      David Ledoux
      Expected size of project
      350 hours

      Rating of difficulty
      hard

      ~~~~~~~~~~


      Exploration of Advanced Rendering Pipelines in ossia score with Raytracing for Fulldome Content
      Jean-Michaël Celerier 2025-02-20 Source
      Project title/description
      Exploration of Advanced Rendering Pipelines in ossia score with Raytracing for Fulldome Content

      More detailed description of the project
      This project aims to explore and integrate cutting-edge rendering pipelines into ossia score, with a particular focus on using raytracing APIs to improve the efficiency and visual quality of fulldome content rendering. Fulldome rendering traditionally requires multiple render passes to project onto a dome, which can be computationally expensive. Raytracing offers the potential to render content for the entire dome in a single pass, significantly reducing overhead. The project will investigate various advanced rendering techniques including HDR rendering, meshlet-based rendering, volumetric/voxel-based rendering, and SDF-based rendering. Furthermore, a graphical composer for SDF-based 3D content might be developed. The student will benchmark and compare different rendering pipelines, identifying the most suitable options for various types of content and performance targets within ossia score.

      Expected outcomes
      Implementation of at least one advanced rendering pipeline (HDR, Meshlet, Volumetric/Voxel, SDF) within ossia score.
      Investigation and integration of a raytracing API (e.g., Vulkan Ray Tracing, DirectX Raytracing) for fulldome rendering.
      Development of a prototype raytracing-based fulldome rendering solution within a Qt RHI example, demonstrating single-pass rendering.
      Performance analysis and comparison of different rendering pipelines, including benchmarks for fulldome content.
      Documentation of the implemented rendering pipelines and their usage within ossia score.
      Skills required/preferred
      Required: Strong C++ programming skills.
      Required: Solid understanding of 3D graphics principles and rendering techniques.
      Required: Experience with at least one modern graphics API (OpenGL, Vulkan, DirectX).
      Preferred: Experience with raytracing APIs and algorithms.
      Preferred: Familiarity with HDR rendering, meshlet rendering, volumetric rendering, or SDF-based rendering techniques.
      Preferred: Knowledge of fulldome rendering techniques and projections.
      Preferred: Experience with performance profiling and optimization of graphics code.
      Possible mentors
      Jean-Michaël Celerier
      Manuel Bolduc
      Expected size of project
      350 hours

      Rating of difficulty
      hard






      ~~~~~~~~~~


      GPU-Independent Pipeline for Large-Scale Point Cloud and Gaussian Splat Rendering
      Jean-Michaël Celerier 2025-02-20 Source
      Project title/description
      GPU-Independent Pipeline for Large-Scale Point Cloud and Gaussian Splat Rendering

      More detailed description of the project
      This project focuses on developing a robust and GPU-independent C++ rendering pipeline for large-scale point clouds and potentially Gaussian splats: some approaches exist but are restricted to CUDA-based systems. The goal is to enable media arts software to visualize and interact with datasets containing millions or even billions of points efficiently, while maintaining visual quality. The pipeline will be drawing inspiration from approaches such as used by Magnopus and in the Skye project. It will prioritize interactive frame rates, effective occlusion handling, and high-quality visual representation, avoiding performance bottlenecks associated with naive point rendering methods. The project will involve exploring techniques such as compute-based rendering, progressive rendering, and efficient data management to handle massive point cloud datasets.

      Expected outcomes
      Implementation of a GPU-independent rendering pipeline for point clouds, based on a GPU RHI.
      Potential extension to Gaussian Splats.
      Support for loading, sorting, processing and visualizing large-scale point cloud datasets (millions to billions of points).
      Implementation of efficient occlusion culling and level-of-detail (LOD) techniques to optimize rendering performance.
      Exploration and implementation of progressive rendering techniques for improved visual quality and responsiveness (similar to Skye).
      Performance profiling and optimization to achieve interactive frame rates.
      Documentation of the rendering pipeline and its usage.
      Skills required/preferred
      Required: Strong C++ programming skills.
      Required: Deep understanding of GPU rendering principles and techniques (OpenGL, Vulkan, DirectX).
      Required: Experience with compute shaders and GPU data management.
      Preferred: Experience with point cloud processing and rendering algorithms.
      Preferred: Familiarity with Gaussian splatting techniques.
      Preferred: Knowledge of performance profiling and optimization tools.
      Preferred: Familiarity with linear algebra and 3D graphics concepts.
      Possible mentors
      Jean-Michaël Celerier
      Bruno Colpron
      Expected size of project
      350 hours

      Rating of difficulty
      medium




      ~~~~~~~~~~

      GPU rendering for the score GUI
      Jean-Michaël Celerier 2025-02-20 Source
      Project title/description
      GPU Rendering for ossia score's GUI using the Qt RHI

      More detailed description of the project
      ossia score's current GUI relies on the older QGraphicsScene API in Qt, which can be a performance bottleneck, especially with complex scores and interactive elements in 4K or greater resolutions. This project aims to modernize the rendering pipeline by leveraging Qt's Rendering Hardware Interface (RHI) for GPU-accelerated rendering. Specifically, the project will involve integrating a library such as QNanoPainter (with the RHI backend) to replace the QGraphicsScene implementation. This will improve performance, enable smoother animations, and unlock possibilities for more advanced visual effects in the score interface such as direct rendering of GPU content. The challenge lies in migrating the existing QGraphicsScene-based rendering to the RHI-based solution while maintaining compatibility and ensuring visual fidelity as well as support on lower-end platforms such as Raspberry Pi.

      Useful links:

      https://github.com/QUItCoding/qnanopainter
      https://github.com/alpqr/qrhinanovg/
      Expected outcomes
      Integration of a GPU rendering library (e.g., QNanoPainter) into ossia score.
      Migration of key GUI elements (score timeline, objects and widgets within) to be rendered using the new RHI-based pipeline.
      Improved performance and responsiveness of the ossia score GUI, especially with complex scores.
      Optimization of GPU resource usage to ensure efficient rendering.
      Thorough testing and debugging to ensure visual fidelity and stability.
      Documentation of the RHI integration and any necessary code changes.
      Skills required/preferred
      Required: Strong C++ programming skills.
      Required: Understanding of GPU rendering concepts and pipelines.
      Preferred: Experience with Qt and its graphics APIs, including QGraphicsScene and QPainter.
      Preferred: Experience with Qt's RHI (Rendering Hardware Interface) or any other similar RHI such as Unreal Engine RHI, WebGPU or SDL3's GPU API.
      Preferred: Knowledge of performance profiling and optimization techniques for GPU rendering.
      Possible mentors
      Jean-Michaël Celerier
      Sarah Al Mamoun
      Expected size of project
      350 hours

      Rating of difficulty
      hard


      ~~~~~~~~~~

      A library-content-manager
      Jean-Michaël Celerier 2025-02-20 Source
      Project title/description
      A library Content Manager for Media Software

      More detailed description of the project
      This project aims to create a robust and versatile library content manager tailored for large-scale media software. The core challenge is efficiently managing diverse media types (audio, video, VST plugins, presets, etc.) and their associated metadata. The library manager will provide tools for automated scanning, categorization based on customizable rules, and serving media content. It should also feature background processing for media information extraction (duration, etc.) and a system for handling arbitrary metadata. Special attention should be paid to performance and concurrency to ensure responsiveness even with very large media collections. The system could potentially share the content over the network or at least over local sockets in an API that would enable it to be useable across a wide range of software.

      Expected outcomes
      A command-line tool and/or library and/or server backend for scanning media files and plugins based on user-defined rules.
      A system for extracting and storing media metadata (duration, codec, etc.) in a performant manner.
      A mechanism for defining and managing arbitrary metadata associated with media items (e.g., DSP include paths, shader dependencies).
      An API for accessing and querying the library content, including filtering by category, tag, and metadata.
      A prototype implementation integrating the library content manager with ossia score.
      Skills required/preferred
      Required: C++ programming skills.
      Required: Experience with file system operations and data structures.
      Required: Familiarity with database systems (e.g., SQLite) or alternative persistent storage solutions.
      Preferred: Knowledge of media formats (audio, video, VST, etc.).
      Preferred: Experience with multithreading and concurrency.
      Possible mentors
      Jean-Michaël Celerier
      Edu Meneses
      Expected size of project
      350 hours

      Rating of difficulty
      medium

      ~~~~~~~~~~

      CLAP Audio Plug-in Integration in ossia score
      Jean-Michaël Celerier 2025-02-20 Source
      Project title/description
      CLAP Audio Plug-in Integration in ossia score

      More detailed description of the project
      ossia score, as a DAW for interactive audiovisual performances, benefits from a wide range of audio plug-ins. This project aims to integrate the CLAP (CLEVER Audio Plug-in) format into ossia score, providing a modern and efficient alternative to existing plug-in standards like VST2/3 or LV2. CLAP offers several advantages, including improved stability, thread safety, and parameter modulation capabilities, leading to a better overall experience for users creating complex audio-visual compositions. The project involves implementing the CLAP host API within ossia score, allowing users to load, control, and process audio through CLAP plug-ins directly within the score environment, by using as starting point the existing audio plug-in backends for LV2, VST2, VST3, JSFX and Faust. This will expand the sonic palette available to artists and enhance the interactive audio capabilities of ossia score.

      Expected outcomes
      Implementation of a CLAP host within ossia score.
      Ability to load and instantiate CLAP plug-ins within ossia score.
      Cross-platform display of CLAP plug-in GUIs.
      Mapping of CLAP parameters to ossia score automation lanes and interactive controls.
      Support for CLAP's thread-safe audio processing in ossia score's engine.
      Testing and documentation of the CLAP integration.
      Skills required/preferred
      Required: C++ programming skills.
      Required: Experience with audio programming and signal processing.
      Preferred: Familiarity with the CLAP API and its features or at least one audio plug-in API.
      Preferred: Experience with GUI programming using Qt or similar frameworks (as ossia score uses Qt).
      Preferred: Knowledge of DAW architecture and audio routing concepts.
      Possible mentors
      Jean-Michaël Celerier
      Vincent Berthiaume
      Expected size of project
      350 hours

      Rating of difficulty
      medium

      ~~~~~~~~~~

      A cross-platform API for GPU texture sharing
      Jean-Michaël Celerier 2025-02-20 Source
      Project title/description
      A cross-platform API for GPU texture sharing

      More detailed description of the project
      Every desktop operating system provides a way to share GPU textures between multiple processes. This is especially useful in the media arts field: a software can be specialized in particles rendering, another in video mapping, and both can then be combined at run-time with no CPU performance cost for inter-process sharing. On Windows, Spout is the standard way to use these OS APIs and share a texture across applications ; on macOS, it is Syphon, and on Linux, this is achievable through PipeWire which wraps DMA-BUF. This means that cross-platform applications wanting to provide texture sharing have to implement multiple different backends, each matching the different platform APIs which leads to a lot of code duplication. This project is about providing a zero-cost cross-platform abstraction over these useful APIs, which would allow software authors to interoperate with Spout / Syphon / PipeWire without having to duplicate shared abstraction code, in particular by extracting the existing code from ossia score and wrapping it in a separate library.

      Expected outcomes
      An open-source library which allows to share a GPU texture across applications.
      The library should be able to import / export the texture multiple graphics APIs, for instance OpenGL, Vulkan, Metal, D3D.
      The open-source media arts ecosystem will become more cross-platform-friendly :-)
      Skills required/preferred
      C++20
      Graphics programming experience in at least one modern GPU API.
      Cross-platform experience
      Possible mentors
      Jean-Michaël Celerier
      Manuel Bolduc
      Expected size of project
      350 hours

      Rating of difficulty
      hard


      ~~~~~~~~~~

      Improving collaborative & distributed interactive scoring
      Sarah Al Mamoun 2025-02-12 Source
      Project title/description
      Improving collaborative & distributed interactive scoring

      The goal is to make remote collaboration in ossia score more intuitive and efficient, making it easier for artists, musicians, and developers to create interactive media compositions in real-time, across multiple locations.

      More detailed description of the project
      With "Teleprescene" being an important area of our research at the SAT, we are interested in improving the open source tools we develop / use / offer to artists at during residencies. The idea of this project would be to make remote collaboration more intuitive in ossia score, a feature that’s already experimental in release 3.0.11, where score introduced experimental collaborative features.

      This involves some backend (c++) and frontend (Qt/QML) improvements to the exisiting iscore-addon-network ossia score plugin. The software is built around a modular architecture where most of its functionality comes from plug-ins. To support different kinds of plugins, score offers two APIs that allow for customization of the software. More on developing in score here.

      Expected outcomes
      Backend and frontend improvements
      Adding feedback/alerts on which machine is handling what part of the score_,_ basically the UX of editing conflicts.
      For example, “participant x is currently editing [ ] ” // “participant x applied X transformation”
      Shareable links and invitations + saved sessions to quickly connect back
      ex: Generate session link (copy) 127.0.0.1:12345
      New features implementation
      Embedded Device support
      Support a mode where a desktop instance controls an embedded device (with the host as the source of truth for I/O devices), in the case of an installation or residency where artists are using/developing embedded systems.
      Integration of a chat system
      If artists are working remotely on a piece, it would be important if they have a way of communicating in-App
      Skills required/preferred
      required:
      C/C++
      git, source control
      preferred:
      Qt/QML
      embedded systems design
      Possible mentors
      @jmcelerier @salmamoun

      Expected size of project
      350 hours

      Rating of difficulty
      medium

      ~~~~~~~~~~

      A Media-over-QUIC C++ implementation
      Jean-Michaël Celerier 2025-02-06 Source
      Project title/description
      A Media-over-QUIC C++ implementation

      More detailed description of the project
      QUIC has been introduced by major industry members (Google, Microsoft, etc.) as a new protocol to replace and improve efficiency of web communications.

      The Media-over-QUIC initiative aims to provide an alternative to WebRTC, based on QUIC.

      While many QUIC implementations in C++ exist, none so far cover the Media-over-QUIC protocol specification. We propose the following work for this internship:

      Choose an existing QUIC implementation in C++
      Implement Media-over-QUIC on it to stream e.g. audio-visual media in the lowest possible latency.
      If the Media-over-QUIC specification proves too unwieldy, it is acceptable to implement a custom protocol for unicast media streaming over QUIC.
      Expected outcomes
      A C++ library allowing to stream audiovisual media over the QUIC protocol.
      A sample web page able to receive QUIC audio & video feeds.
      Skills required/preferred
      required: C++ skills
      required: experience with networking & media
      preferred: knowledge of asynchronous I/O mechanism, for instance with boost.asio or C++ senders / receivers
      Possible mentors
      @jmcelerier @ogauthier_sat

      Expected size of project
      350 hours

      Rating of difficulty
      hard

      ~~~~~~~~~~

      Object Detection on Point Cloud Streams
      Manuel Bolduc 2025-02-06 Source
      Project title/description
      Object Detection on Point Cloud Streams

      More detailed description of the project
      LivePose is a command-line tool for detecting skeletons using Human Pose Estimation (HPE) models on video streams and streaming output data on the network, so that it can be used in interactive applications. The basic architecture of LivePose could be adapted to accommodate for different types of input data, such as point cloud streams.

      The first objective of this project is therefore to prototype a pipeline in Python language for applying deep learning models in real-time on streaming point cloud data. The second objective, if time allows, is to implement such a pipeline as an additional feature of the LivePose software.

      Expected outcomes
      Familiarization with techniques for point cloud streaming in Python using libraries such as Open3D, OpenCV
      Conceiving a Python pipeline using the ONNX framework for object detection on point clouds
      Evaluation of the pipeline for real-time performance
      Feature request for integration of the pipeline in the LivePose software
      Skills required/preferred
      required: openness to read and learn about new stuff
      required: willingness to ask questions when stuck
      preferred: some experience with programming (but not a prerequisite!)
      Possible mentors
      Manuel Bolduc Jean-Michaël Celerier Bruno Colpron

      Expected size of project
      350 hours

      Rating of difficulty
      hard

      ~~~~~~~~~~

      Porting Puara-gestures to Avendish and creating ossia score objects for each gestural descriptor
      Edu Meneses 2025-01-29 Source
      Project title/description
      Porting Puara-gestures to Avendish and creating ossia score objects (processes) for each gestural descriptor

      More detailed description of the project
      Puara-gestures is a library for creating and managing high-level gestural descriptors using data from various sensors such as accelerometers, gyroscopes, and magnetometers. It helps instrument designers and ioT developers extract meaningful data from sensors and use them to control anything via the network. Porting (wrapping) the library classes to Avendish will allow the creation of VST/LV2 plugins for audiovisual/artistic projects and the compilation of those classes as individual objects. Further, adding them as objects in ossia score will open possibilities for orchestrating and automating both physical and virtual elements using data gathered from a distributed network of sensors and actuators.

      Expected outcomes
      A wrapper for each puara-gestures class in Avendish
      An object created from each wrapper
      At least one test case of a VST plugin created from Avendish
      Skills required/preferred
      required:
      C/C++
      preferred:
      Qt
      Possible mentors
      Edu Meneses
      Jean-Michaël Celerier
      Expected size of project
      350 hours

      Rating of difficulty
      medium




      
 
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/society-for-arts-and-technology-(sat)/
    idea_list_url: https://sat-mtl.gitlab.io/collaborations/google-summer-of-code/categories/ideas/
  

  - organization_id: 141
    organization_name: Software and Computational Systems Lab at LMU Munich
    no_of_ideas: 8
    ideas_content: |
     
      CPAchecker (website)
      CPAchecker is an award-winning open-source framework for software verification. It is written in Java and based on a highly modular architecture that allows to develop and combine a wide range of different analyses. CPAchecker is used for verification of the Linux kernel and has helped to find hundreds of bugs in the kernel. To get started with CPAchecker you can take a look at its Tutorial Paper.
      Exporting and Validating Correctness Witnesses for Memory Safety in CPAchecker
      Automatic Software Verifiers like CPAchecker, while great at finding bugs may also contain some bugs themselves. In order to increase the confidence in the results of the verifiers, they export an argument for their result in a machine-readable format called a witness. A witness can be validated independently by another tool, increasing the confidence in the result of the tool which exported them. Currently CPAchecker does not export relevant information when it finds a proof about memory safety properties. As a GSoC student, you will have the opportunity to extend CPAchecker by a new witness export to provide relevant information about memory safety proofs. Additionally you will be implementing the validation of these witnesses inside CPAchecker in order to evaluate the correctness of the exported witnesses. Your work will involve learning about the existing analyses for memory safety, the witness export and the witness validation in CPAchecker in order to develop the required components.
      Expected outcome: An prototype for the export and validation of correctness witnesses for memory safety in CPAchecker.
      Requirements: Programming in Java, reading C code, basic understanding of software verification
      Difficulty: intermediate
      Project size: large (~350 hours)
      Mentor: Marian Lingsch-Rosenfeld

      ~~~~~~~~~~
      Infrastructure for Software Verification
      Automated software verifiers are powerful tools to find bugs in programs, but they are often complex and difficult to use. Our team aims to simplify this and make it easy to integrate software verifiers into the software-development process.
      Design and Implementation of Behavior-driven Tests
      CPA-Daemon is a gRPC-based microservice that enables users to run the award-winning verifier CPAchecker in a cloud setup. It focuses on ease of use and continuous verification.
      You will improve the maintainability and reliability of our tests in CPA-Daemon. We plan to do this in two dimensions: First, you improve the maintainability of our tests through behavior-driven tests with Cucumber. You analyze the existing tests (written with plain JUnit), design an improved test architecture on the foundation of Cucumber, and implement that.
      Issue related to this project: CPA-Daemon#33
      Expected outcome: A running integration-test suite for CPA-Daemon based on Cucumber that reaches the same or more branch coverage than the existing integration tests that are based on basic JUnit. The test suite lists features and test cases with a granularity similar to the existing tests.
      Requirements: Experience in Java and on the command line. Strong knowledge on the concepts of microservices.
      Project size: small (90 hours)
      Mentor: Thomas Lemberger
      Difficulty: easy
      Chat room for communication at Matrix: #sosylab-gsoc:matrix.org

      ~~~~~~~~~~
      Design and Implementation of a Web Application for the Visualization of Analysis Work in Distributed Summary Synthesis
      Distributed Summary Synthesis (DSS) is a technique to distributed an expensive software verification task in the cloud. DSS decomposes the program-under-analysis into individual blocks, and then analyzes each block separately and in parallel. Whenever a block analysis is finished, the produced result is communicated to strengthen the analysis of the other blocks. DSS uses a microservice architecture with a central coordinator service that composes individual block analyses from the available results. Worker services are then responsible to handle individual block analyses. The produced result can be post-conditions or violation conditions: A post-condition is produced when the analysis proves the block safe (under the currently available information). It represents all possible program states that are possible at the end of the block. A violation condition is produced when the analysis finds a potential error (under the currently available information). It represents a condition that, if it holds at the block entry, leads to an error. Conditions are communicated as logical formulas in the SMT-Lib format. (Scientific paper on the concept of DSS).
      You will implement a new web application that visualizes the work done by the worker services in DSS. The coordinator already uses a database to store basic information about each block analysis, like the start-time and end-time, and the produced messages. Your web application will connect to this database and render the performed analyses (for a single verification run) in a graph-based visualization. The user should be able to toggle different layers of visualization (for example a visualization of the individual run times, or a visualization of the code-block size that was analyzed). The visualization should provide a high-level overview of the analysis work, and enable a drill-down into the statistics of individual runs. A prototype of the microservice is implemented here. The final implementation should be in Javascript (with next.js and react).
      Expected outcomes:
      Implementation of the described web application
      Automated integration tests for the backend of the web application
      Extensive documentation
      Issue related to this project: Distributed Summary Synthesis#30
      Requirements: Experience in Javascript (next.js/react), foundational knowledge of formal software verification.
      Project size: large (350 hours)
      Mentor: Akshay Warrier and Thomas Lemberger
      Difficulty: medium
      Chat room for communication at Matrix: #sosylab-gsoc:matrix.org

      ~~~~~~~~~~
      Design and Implementation of a Microservice for AI-based, Formal Code-Summary Synthesis
      Distributed Summary Synthesis (DSS) is a technique to distributed an expensive software verification task in the cloud. DSS decomposes the program-under-analysis into individual blocks, and then analyzes each block separately and in parallel. Whenever a block analysis is finished, the produced result is communicated to strengthen the analysis of the other blocks. DSS uses a microservice architecture with a central coordinator service that composes individual block analyses from the available results. Worker services are then responsible to handle individual block analyses. The produced result can be post-conditions or violation conditions: A post-condition is produced when the analysis proves the block safe (under the currently available information). It represents all possible program states that are possible at the end of the block. A violation condition is produced when the analysis finds a potential error (under the currently available information). It represents a condition that, if it holds at the block entry, leads to an error. Conditions are communicated as logical formulas in the SMT-Lib format. (Scientific paper on the concept of DSS).
      You will implement a new worker service that uses LLMs to produce post-conditions or violation conditions for a given code block. The worker service receives a C code block, a program specification, a set of pre-conditions that are known to hold at the block entry (in SMT-Lib), and violation conditions that are known at the block exit. The worker service then uses LLMs to produce a new post-condition or violation condition. Before sending the result back to the coordinator, the worker performs some validity checks on the expected properties of the logical formulas to increase the chance of correctness. For communication, the worker uses gRPC. It must be implemented in Python.
      Expected outcomes:
      Implementation of the described Python microservice.
      Automated integration tests for the microservice
      Extensive documentation
      Requirements: Experience in Python. Strong knowledge on the concepts of microservices.
      Project size: large (350 hours)
      Mentor: Thomas Lemberger
      Difficulty: hard
      Chat room for communication at Matrix: #sosylab-gsoc:matrix.org

      ~~~~~~~~~~
      Finding initial Predicates for Predicate Analysis using AI
      To proof a program correct, usually the most difficult task is to come up with invariants which show its correctness. Nowadays there are multiple approaches which try to find invariants using AI, for example Code2Inv, Neural Termination, using LLMs, refining invariants using LLMs, between many others. While invariants are very useful tools to proof software correct, it is sometimes difficult to find them, since they need to fulfill strict correctness criteria. Another very successful approach in software verification is predicate analysis. In contrast to invariants, the predicates used by the analysis to proof the program correct, do not need to fulfill strict correctness criteria to be useful. But still coming up with good predicates is very difficult, in particular since good predicates are invariants. As a GSoC student, you will have the opportunity to implement an open-source tool which using ML techniques provides initial predicates for CPAchecker to improve its performance.
      Expected outcome: An open-source tool which takes a program and uses machine learning techniques to synthesize candidates for initial predicates encoded as C-Expressions.
      Requirements: Programming in Python, reading C code, basic understanding of software verification and ML
      Difficulty: intermediate
      Project size: large (~350 hours)
      Mentor: Marian Lingsch-Rosenfeld

      ~~~~~~~~~~
      Verifier Selection using LLMs
      With the rise of LLMs, there have been large advances in code summarization, coding assistance, between many others. In particular it has now become possible to get good low dimensional embeddings of code, for example NV-Embed or LLM2Vec. These embeddings offer the possibility to improve the selection of best performing verifiers for a task. Current approaches, like Pesco or Graves usually either compute program features manually or train a custom ML algorithm for the selection. As a GSoC student, you will have the opportunity to create your own open-source tool which uses LLMs to encode the task passed to a verifier and predicts which verifier will perform the best on it.
      Expected outcome: An open-source tool which takes a program and returns the verifier which is likely to perform the best on the given verification task.
      Requirements: Programming in Python, reading C code, basic understanding of software verification and LLMs
      Difficulty: intermediate
      Project size: large (~350 hours)
      Mentor: Marian Lingsch-Rosenfeld


      ~~~~~~~~~~
      Reimplementing MetaVal in MetaVal++
      MetaVal is a tool and approach to validate witnesses using verifiers by instrumenting the program with the witness. Its current implementation uses deprecated technology and a re-implementation is necessary. In particular the approach could only handle witnesses in version 1.0, while the current standard for witnesses is version 2.0. As a GSoC student, you will have the opportunity to reimplement MetaVal in a new tool called MetaVal++ for witnesses in version 2.0.
      Expected outcome: An implementation of the MetaVal algorithm adapted to witnesses version 2.0 in MetaVal++.
      Requirements: Programming in Python, reading C code, basic understanding of software verification
      Difficulty: intermediate
      Project size: Medium (~175 hours)
      Mentor: Marian Lingsch-Rosenfeld

      ~~~~~~~~~~
      BenchExec (website)
      BenchExec is a benchmarking framework for Linux (written in Python) that is aimed at a high reliability of the results. It can measure the CPU-time and peak memory usage of whole groups of processes. To do so, it makes use of modern Linux features such as cgroups and namespaces, effectively creating a benchmarking container whose resource usage is measured. The concepts and architecture of BenchExec are described in a paper (open access).
      Timestamps in logs
      During benchmarking runs, BenchExec collects the output of the benchmarked tool into files. In some use cases, it would be beneficial if each produced line would be prefixed with a timestamp. For this we need to pipe the tool output through the BenchExec process instead of writing it directly (GitHub issue). While implementing this it might be possible to solve some related issues as well: #408, #535, and #536.
      Requirements: Python, Linux
      Skill level: intermediate to advanced
      Mentor: Philipp Wendler
      Project size: small (90h) or medium (175h) depending on whether the additional issues are worked on
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/software-and-computational-systems-lab-at-lmu-munich/
    idea_list_url: https://www.sosy-lab.org/gsoc/gsoc2025.php

  - organization_id: 142
    organization_name: St. Jude Children's Research Hospital
    no_of_ideas: 3
    ideas_content: |


        Extend Sprocket language server protocol and extension.
        Length: 350 hours, Difficulty: Medium to hard (stretch)

        Description

        Our developer tools and experience project focuses largely on Sprocket’s LSP integration within VSCode and the VSCode extension itself (linked above). During this track, you’ll utilize the existing wdl-lsp packages in the wdl crates repository linked above to expose things like lookup definition, go to definition, references, snippets, and semantic code highlighting. For a stretch goal, we would like to continue optimizing and refining the internal workings of the LSP (and the associated AST/CST). Along the way, you’ll learn about fundamentals of writing a programming language from scratch, how and LSP implementation works, Rust itself, and you’ll contribute to Workflow Description Language developers everywhere being more productive because of your efforts.

        Outcomes

        Lookup definition, go to definition, references, snippets, and semantic code highlighting integrated within the Sprocket VSCode extension (linked above) (Project).
        Improved latency, memory use, cpu use, and reliability for the LSP engine (Project, stretch goal).
        Seamless WDL development experience for workflow authors (End users).
        A deeper understanding of programming language tooling and Rust (Contributor) .

        Relevant Skills

        Fluency with Rust or another equivalent high performance language (C, C++, Go) with a desire to learn Rust is a must. Experience building developer tools and extensions is slightly preferred.

        Potential Mentors

        Clay McLeod, Director of Product Development and Engineering

        Proposal Advice

        First, we recommend following Visual Studio Code’s guide on building your first extension (link). This will give you a sense of what it’s like to build a Visual Studio Code extension without too much time investment. Next, we recommend reading and understanding at a high-level what the Language Server Protocol (LSP) is (link). The protocol is incredibly detailed with many corners so to speak—you don’t need to understand everything. It’s just important to understand generally how it works and what problems it solves. Last, we recommend downloading and trying to load up the Sprocket VSCode extension (link)—the instructions to do so are in the project README.md (link). All of the information you end up learning from this exercise should be included in the final application.
        
        
        ~~~~~~~~~~
        
        Real-time monitoring dashboard and terminal user interface (TUI) for Crankshaft.
        Length: 175 hours to 350 hours, Difficulty: Medium to Hard

        Description

        Running petabyte-scale genomics analyses is only tenable when you know what’s actually going on with your workflows. In this track, you’ll work to develop real-time monitoring tools for Crankshaft (that eventually will surface in Sprocket) to ensure that end users know what’s going on with thousands of their workflows. Interactions with jobs, such as killing jobs or interrogating their logs, is a stretch goal but not required. Along the way, you’ll learn about cloud analysis at scale, how a workflow execution engine is built, how to develop a terminal-user interface, and Rust itself.

        Outcomes

        A clear, easy to use and interpret terminal user interface (very similar to tokio-rs/console) that allows for interpretation, monitoring, and some lightweight interaction with jobs. The extent of the interactions with the jobs depends on how far we get with the initial monitoring and displaying of statuses (Project).
        Hands on experience with building the inner workings of a petabyte-scale engine using Rust. This includes building expertise in the Rust programming language and tokio-related crates (Contributor).

        Relevant Skills

        Fluency with Rust or another equivalent high performance language (C, C++, Go) with a desire to learn Rust is a must.

        Potential Mentors

        Clay McLeod, Director of Product Development and Engineering

        Proposal Advice

        We’d highly recommend you go and explore what has been created for tokio-console (link) as a starting point. This will give you a good sense of a similar project that aims to describe the inner workings of a complex system using a TUI. Further, you could check out the ratatui crate (link), as that’s a leading library for creating such TUIs (though, if you have a different library you want to use, that’s totally okay too). Last, if you’re feeling up to it, it would be great to write a small program using a TUI just to make sure you understand generally how they work. All of the information you end up learning from this exercise should be included in the final application. 
        
        ~~~~~~~~~~
        
        Integrated end-to-end workflow testing framework within Sprocket. 
        Length: 350 hours, Difficulty: Medium to Hard (stretch)

        Description

        Within Sprocket, we’d like to build out a first-class testing framework that workflow authors can depend on to end-to-end test their workflow throughout development. This subcommand will be designed with continuous integration and deployment in mind, and will use the St. Jude Cloud Workflows repository as a baseline for implementing this scheme. As a stretch goal, generating fake data for genomics workflows themselves might be compelling to start on (check out the ngs generate command (link) to get an idea of what this might look like. Along the way, you’ll learn a bit about genomics, how workflows are written and deployed at scale, how to robustly test scientific workflows, and Rust itself.

        Outcomes

        A end-to-end testing framework for reproducible workflows using Sprocket that can be integrated into the CI/CD workflows of tool developers using WDL (Project, end users).
        (Stretch Goal) New fake data generation tools, geared towards generating fake genomics data, for use within these testing workflows (Project, end users).
        A better understanding of Rust, genomics software engineering, and what it takes to scale the development of genomics workflow analyses (Contributor).

        Relevant Skills

        Fluency with Rust or another equivalent high performance language (C, C++, Go) with a desire to learn Rust is a must. Fluency in genomics is not required, but you must be willing to spend a significant amount of time learning if you don’t already understand it (ergo, you must want to learn genomics).

        Potential Mentors

        Clay McLeod, Director of Product Development and Engineering

        Proposal Advice

        First, we recommend reading through and understanding the general idea behind the Workflow Description Language standard (link). This will give you a good idea of how workflows are expressed in Sprocket. Next, we recommend you take a look at St. Jude’s repository for workflows (link) to get a sense of what a real-life repository of these workflows where testing should occur looks like. You can take a look at the tools folder to see the individual WDL tasks and the workflows folder see the WDL workflows. The rnaseq-standard pipeline is a particularly good example (link). Last, we recommend looking at the state of the art approach today for doing this, which is a project called pytest-workflow (link). There are several things we think this library got right alongside several things we would change, so just take the inspiration as a grain of salt, not as a template of something we want to redo in Rust.  All of the information you end up learning from this exercise should be included in the final application.

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/st.-jude-children's-research-hospital/
    idea_list_url: https://docs.google.com/document/d/1ze8OpsltCbAkksjmhd3hCeS6VDqAaolAhWAQQRJZBpc/edit?tab=t.0

  - organization_id: 143
    organization_name: Ste||ar group
    no_of_ideas: 28
    ideas_content: |
      
      Annotate HPX with Contracts
      Abstract: Recent standardization developments indicate that C++26 will introduce contracts P2900. Their primary use is to increase language safety by providing developers with ergonomic tools to handle false assertions. They can be used to give defined behavior to pre-condition and post-condition violations of functions. The companion proposal to contracts: P3471 introduces the notion of a hardened STL, which implements the expected conditions to standard library functions (e.g. vector.front() has a precondition that vector.empty() is false). HPX provides multiple debugging mechanisms, and a rich test suite. Annotating the HPX library functions would further safety and debugging ability.
      Additional References:
      Proposal P2900 (Contracts)
      Proposal P3471 (Hardened STL)
      Difficulty: Medium/Advanced
      Expected result: Annotate a significant portion of HPX's public facing API with contracts.
      Knowledge Prerequisite: C++, Git
      Mentor: Hartmut Kaiser (), Isidoros Tsaousis-Seiras (tsa.isidoros [at] gmail.com)
      Project Size: 350 hour (medium project)

      ~~~~~~~~~~
      Integrate HPX algorithms with Nvidia CCCL (Thrust)
      Abstract: Nvidia provides C++ abstractions for CUDA developers in their CUDA Core Compute Libraries (CCCL). Specifically, Thrust implements C++ parallel algorithms that match those in the C++ Standard. Integrating Thrust with HPX would allow calling GPU Thrust algorithms through HPX parallel algorithms API, perhaps even taking advantage of HPX facilities for asynchronous execution (e.g. futures).
      Difficulty: Medium/Advanced
      Expected result: Integrate Thrust with the HPX algorithms API
      Knowledge Prerequisite: C++, Git
      Mentor: Hartmut Kaiser (), Panagiotis Syskakis (pansysk75 [at] gmail.com)
      Project Size: 350 hour (large project)

      ~~~~~~~~~~
      Expose HPX using C++ Modules
      Abstract: Modules were introduced in C++20 as an alternative to header files for sharing declarations and definitions across translation units. C++ Modules can improve compilation times and code isolation. There are several differences when using C++ Modules, mainly they cannot export macros, and declarations have to be explicitly exported using the export keyword. We are interested in exposing HPX using C++ Modules (in addition to header files).
      Additional References: Rubén Pérez on bringing C++ Modules to the Boost library: Part 1, Part 2, Part 3
      Difficulty: Medium/Advanced
      Expected result: Make HPX available to users through C++ Modules
      Knowledge Prerequisite: C++, Git
      Mentor: Hartmut Kaiser (), Panagiotis Syskakis (pansysk75 [at] gmail.com)
      Project Size: 350 hour (large project)

      ~~~~~~~~~~
      Implement the make_receiver_for optimization for HPX Senders
      Abstract: The Senders/Receivers (P2300) framework is constantly evolving to become more optimized and user-friendly. One of the papers accelerating this evolution is P3425 It proposes that since chained operations have a known byte-size and are stacked contiguously in memory, we can avoid holding pointers to each of them, and we can calculate their addresses on the fly based on the offsets. This presents a massive object size reduction and also aids the compiler in optimizing the code. HPX's senders would greatly benefit from implementing the proposed interface to support this feature.
      Additional References:
      Proposal P2300
      Proposal P3425
      Difficulty: Medium/Advanced
      Expected result: Implement the make_receiver_for interface for hpx::bulk as described in P3425.
      Knowledge Prerequisite: C++, Git, Concurrency
      Mentor: Hartmut Kaiser (), Isidoros Tsaousis-Seiras (tsa.isidoros [at] gmail.com)
      Project Size: 175 hour (medium project)
      ~~~~~~~~~~
      Implement hpx::system_scheduler as described in P2079 (System Execution Context)
      Abstract: C++26 Has evolved to include a modern API for parallelism and task scheduling (P2300). HPX implements the proposed interface, as well as multiple schedulers. Proposal (P2079) proposes a generic scheduler to OS-provided threads. hpx::system_scheduler is the HPX analogue that maps to hpx::threads instead, and an excellent way to expose an HPX scheduler with a Sender/Receiver interface.
      Additional References:
      Proposal P2300
      Proposal P2079
      Difficulty: Medium/Advanced
      Expected result: Implement system_scheduler as described in P2079.
      Knowledge Prerequisite: C++, Git, Concurrency
      Mentor: Hartmut Kaiser (), Isidoros Tsaousis-Seiras (tsa.isidoros [at] gmail.com)
      Project Size: 350 hour (large project)

      ~~~~~~~~~~
      Integrate HPX with the Tracy profiler
      Abstract: HPX is already integrated with the Intel VTune and APEX profilers. Adding support for using Tracy to HPX will extend the available set of introspective and embedded profiling tools for HPX applications. The integration would include annotating key functions, mutexes, thread scheduling, etc. The work would also require implementing a CMake based build system integration to simplify using Tracy with HPX and its applications.
      Additional References:
      Tracy
      Difficulty: Medium/Advanced
      Expected result: Integrate the Tracy profiler with HPX.
      Knowledge Prerequisite: C++, Git, CMake
      Mentor: Hartmut Kaiser ()
      Project Size: 350 hour (large project)

      ~~~~~~~~~~
      Use C++26 reflection for HPX serialization
      Abstract: HPX has already a serialization framework that allows to turn any C++ object into a byte stream for transmission over the network. Obviously this framework can turn a byte stream back into the corresponding C++ object instance. The current implementation of serialization n the general case relies on the user providing intrusive serialization functionality to the types that have to be sent over the wire. With C++26 reflection becoming available, we should add support for serializing arbitrary type (including lambdas with captures) that relies on using these new language facilities.
      Additional References:
      C++ 26 Reflecton
      Difficulty: Medium/Advanced
      Expected result: Arbitrary C++ types can be serialized.
      Knowledge Prerequisite: C++, Git, CMake
      Mentor: Hartmut Kaiser ()
      Project Size: 350 hour (large project)

      ~~~~~~~~~~
      Implement parallel hpx::uninitialized_relocate_* algorithms for overlapping ranges
      Abstract: HPX implements the full set of the C++ standard algorithms. This includes algorithms that copy data (e.g. hpx::copy copies the elements from a source range to a destination range). Recent proposals (see additional references below) suggest the addition of a new type trait (std::is_trivially_relocatable) that defines a new group of types that can benefit from trivial relocation. When relocating an object, the relocation algorithms will determine if it is valid to reduce the move-constructor and destructor call to a single memcpy(). In that way, relocation improves performance and increases safety. The relocation algorithms are: A) relocate, relocate_at, to operate on single objects and B) uninitialized_relocate, uninitialized_relocate_backward to operate on ranges of elements. These were added to HPX in a GSoC 2023 Contribution. However, the parallel versions of hpx::uninitialized_relocate and hpx::uninitialized_relocate_backward cannot handle overlapping ranges properly, as the forward and backward order of the algorithms is not preserved when running in parallel. The contributor is expected to correct the parallelization of these algorithms for overlapping ranges, as well as benchmark, write tests, and evaluate their solution.
      Additional References:
      P1144 Object relocation in terms of move plus destroy
      C++Now 2019: "Trivially Relocatable"
      GSoC 2023: Relocation Semantics in HPX
      Possible choice for a parallelization method
      Difficulty: Medium/Advanced
      Expected result: Parallel implementations of uninitialized_relocate and uninitialized_relocate_backward that work on overlapping ranges, as well as written tests and benchmarks.
      Knowledge Prerequisite: C++, Git, parallel algorithms
      Mentor: Hartmut Kaiser () and Isidoros Tsaousis-Seiras (tsa.isidoros [at] gmail.com)
      Project Size: 175 hour (Medium/Advanced project)

      ~~~~~~~~~~
      Async I/O using Coroutines and S/R
      Abstract: Coroutines along with S/R make a really good use case for async I/O Ref 1. Using the recently added HPX S/R facilities to develop an interface for a relatively faster I/O example would be the goal of this project. Additionally for Linux based platforms with io_uring support can have even more performance benefits.
      Additional References:
      https://github.com/L-v-M/async
      https://pabloariasal.github.io/2022/11/12/couring-1/
      Difficulty: Easy/Medium
      Expected result: Develop a non-trivial use case using the above described tools and HPX.
      Knowledge Prerequisite: C++, CMake
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com) and Shreyas Atre (Discord: Shreyas)
      Project Size: 175 hour (Easy/Medium project)

      ~~~~~~~~~~
      "Green out" our Continuous Integration tests
      Abstract: There are tests in our Continuous Integration (CI) that are currently failing. These are mainly under our tests.regressions, tests.segmented_algorithms targets, performance tests and certain new compilers tests (clang-13/14, gcc-12). One can see all the tests that are failing if they randomly select an open PR and scroll down to check the list items indicated with a red 'X'. Fixing those tests would include a wide range of bug hunting tasks and creativity from the student side in order to reproduce them locally until they figure out and fix the errors.
      Difficulty: Easy/Medium
      Expected result: All tests in our CI pass (are green).
      Knowledge Prerequisite: C++, CMake, slurm
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com)
      Project Size: 175 hour (Easy/Medium project)

      ~~~~~~~~~~
      Port HPX to iOS and Mac (M1 architecture)
      Abstract: HPX has already proven to run efficiently on ARM-based systems. This has been demonstrated with an application written for Android tablet devices. A port to handheld devices running with iOS would be the next logical step! On top of that since the new Apple M1 ARM-based processors have proven to be very efficient the student should consider providing an HPX version for this architecture as well. To run HPX efficiently on there, we need to adapt our build system to be able to cross-compile for iOS and Mac and add a code to interface with the iOS GUI and other system services. A preexisting Mac support infrastructure exists but the student will need to adapt and update it to current releases.
      Difficulty: Easy/Medium
      Expected result: Provide a prototype HPX application running on an iPhone or iPad.
      Knowledge Prerequisite: C++, Objective-C, iOS
      Mentor: Hartmut Kaiser () and Thomas Heller ()
      Project Size: 350 hour (large project)

      ~~~~~~~~~~
      Study the performance of Halide applications running on HPX threads.
      Abstract: Halide is a programming language designed to facilitate developing high-performance array-based code with regular access to memory on a wide range of modern architectures. Halide also makes it possible to use custom runtimes, such as HPX, in situ of the native runtime. A preliminary work has shown promising results for the HPX runtime in code generated by Halide. The goal of this project is to investigate the effectiveness of code generated by Halide in libraries that use HPX as a backend. We are notably interested in improving the performance of level 2, and 3 BLAS operations in the Blaze math library.
      Difficulty: Medium
      Expected result: Comprehensive performance analysis of Halide code in Blaze and other stencil-like applications.
      Knowledge Prerequisite: C++
      Mentor: Hartmut Kaiser () and Rod Tohid (rtohid [at] cct.lsu.edu)
      Project Size: 175 hour (medium project)

      ~~~~~~~~~~
      Bring the HPX distributed algorithms up to date
      Abstract: Along with the standard parallel algorithms provided by the C++ standard, HPX extends its infrastructure by providing (some of) the corresponding distributed versions of those algorithms that run on multiple nodes and on top of that they take care of communication. The set of the implemented algorithms can be found here. Due to lack of maintainance these algorithms do not compile properly to some systems according to our latest continuous integration tests and they are considered the last missing piece for HPX to be a fully integrated and portable library. Part of this project is to investigate the reasons that the tests of these algorithms fail (either on the algorithm source code side or on the integration tests side) and "repair" them. Providing further implementations of the remaining algorithms could facilitate as an extension of the project for the prospective students that are interested in a long-term project. Here you can find the corresponding ticket.
      Difficulty: Easy
      Expected result: Repair the segmented algorithms so continuous integration does not fail on them and implement the remaining segmented algorithms.
      Knowledge Prerequisite: C++, CMake, CircleCI, Jenkins
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com)
      Project Size: 175 hour (medium sized)

      ~~~~~~~~~~
      Fix libCDS broken dependency
      Abstract: libCDS is a Concurrent Data Structures library which provides containers that alleviate the user from taking care of synchronization. HPX provides an integration with libCDS which is currently broken. We are looking for a prospective developer that will bring that libCDS up to date with the current version of HPX and provide testing and benchmarking with the contemporary results.
      Difficulty: Easy
      Expected result: libCDS current version full integration with the latest HPX.
      Knowledge Prerequisite: CMake, Data Parallelism, C++.
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com)
      Project Size: 350 hour (large project)

      ~~~~~~~~~~
      (Re-)Implement executor API on top of sender/receiver infrastructure
      Abstract: P2300 will most likely be accepted for C++26. Our executor API (customization points) currently dispatch to an executor interface defined by wg21.link/p0443R3. All HPX facilities related to scheduling tasks (algorithms, future, dataflow, async, etc.) rely on the executor customization points to perform their operations. Although major steps have been taken for the integration of the executors proposal to HPX there is still many facilities that need to be implemented. The project can be correlated with the Coroutine-like interface project project and the P2300 proposed awaitables.
      Difficulty: Medium
      Expected result: The result should be functioning executor customization points built upon senders/receivers.
      Knowledge Prerequisite: Parallel algorithms.
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com)
      See issue #5219 on HPX bug tracker and the corresponding Pull Request that's on the works already.
      Project Size: 350 hour (large project)

      ~~~~~~~~~~
      Coroutine-like Interface
      Abstract: HPX is an excellent runtime system for doing task-based parallelism. In its current form, however, the results of tasks can only be expressed in terms of returning from a function. However, there are scenarios where this is not sufficient. One example would be lazy ranges of integers (for example, Fibonacci, 0 to n, etc.). For those, a generator/yield construct would be perfect (more on coroutines)! Additionally, an option would be to rely on top of the senders/receivers proposed facilities, a completely new interface for execution in standard C++ that may (or not) revolutionize the way we implement concurrency.
      Difficulty: Medium
      Expected result: Implement yield and demonstrate on at least one example
      Knowledge Prerequisite: C++
      Mentor: Hartmut Kaiser () and Thomas Heller ()
      Project Size: 350 hour (large project)

      ~~~~~~~~~~
      Update Build System to automatically fetch HPX dependencies when not available
      Abstract: HPX currently depends on three libraries. Although our build system supports a CMake flag to fetch and use a default Asio version, there are no analogous options for Boost and HWLOC. Adding these options would make building HPX easier and would attract more prospective users. The idea is to fetch and install these dependencies with HPX if the user does not have them installed. Further improvements and automation on the build system may be proposed. Updates to the HPX documentation wrt build changes are expected. Feel free to check on the related issues #3440, #5728.
      Difficulty: Medium
      Expected result: Provide a renewed user-friendly build system environment.
      Knowledge Prerequisite: CMake
      Mentor: Nikunj Gupta (nikunj [at] illinois.edu), Hartmut Kaiser (), and Giannis Gonidelis (gonidelis [at] hotmail.com)
      Project Size: 175 hour (medium sized)

      ~~~~~~~~~~
      Explicit Visualization of Accelerators for HPX Trace Visualization
      Abstract: HPX traces are collected with APEX and written in as OTF2 files with extensions. These trace files are typically visualized using a Gantt chart or collection of timelines. Presently, there is no differentiation between tasks executed on an accelerator versus other hardware. This project requires (1) investigation regarding what data can be collected about accelerators through HPX and APEX, and (2) design and implementation of how accelerator data is implemented in Traveler. Collection will require C++, while the Traveler alterations will also require Python (backend) and Javascript (frontend).
      Difficulty: Medium-Hard
      Expected result: Traveler trace visualization includes query support and visual indicators of data regarding accelerators.
      Knowledge Prerequisite: C++, Python, Javascript.
      Mentor: Kate Isaacs ()
      Project Size: Could be 175 hour (medium sized) or 350 hour (large sized) depending on proposal

      ~~~~~~~~~~
      Improved Scalability for HPX OTF2 Trace Visualization
      Abstract: HPX traces are collected with APEX and written in as OTF2 files with extensions. These trace files are typically visualized using a Gantt chart or collection of timelines in Traveler. The present implementation reads the entirety of the trace file before generating the visualization using one of the older APIs to do so. However, the OTF2 interface has support for partial reading of the file and a parallel backend. This project would modify the Gantt chart backend (C++/Python) to utilize these features, thus supporting larger files. The project could also modify the front end to use WebGL (Javascript) when the number of data items is large.
      Difficulty: Medium-Hard
      Expected result: Files that require more memory than on a single machine can be run from that machine. The time from program-start to visualization is decreased due to the use of large file features.
      Knowledge Prerequisite: C++, Python, Javascript.
      Mentor: Kate Isaacs ()
      Project Size: 175 hour (medium sized)

      ~~~~~~~~~~
      Multiple File Load in HPX Trace Visualization
      Abstract: HPX traces are collected with APEX and written in as OTF2 files with extensions. These trace files are typically visualized using a Gantt chart or collection of timelines. We want to load multiple of these files at the same time and align the views between the like-charts for comparison in Traveler. Traveler alterations will also require Python (backend) and Javascript (frontend).
      Difficulty: Medium-Hard
      Expected result: Traveler trace visualization can open multiple files and arranges views so performance can be compared across files.
      Knowledge Prerequisite: Python, Javascript.
      Mentor: Kate Isaacs ()
      Project Size: Could be 175 hour (medium sized)

      ~~~~~~~~~~
      Past Year Projects
     
      Add Vectorization to par_unseq Implementations of Parallel Algorithms
      Abstract: Our parallel algorithms currently don't support the par_unseq execution policy. This project is centered around the idea to implement this execution policy for at least some of the existing algorithms (such as for_each and similar).
      Difficulty: Medium/Hard
      Expected result: The result should be functioning parallel algorithms when used with the par_unseq execution policy. The loop body should end up being vectorized.
      Knowledge Prerequisite: Vectorization, parallel algorithms.
      Mentor: Hartmut Kaiser (), Srinivas Yadav (vasu.srinivasvasu.14 [at] gmail.com), Nikunj Gupta (nikunj [at] illinois.edu), Giannis Gonidelis (gonidelis [at] hotmail.com)
      See issue #2271 on HPX bug tracker
      Project Size: 350 hour (large project)
      ~~~~~~~~~~
      Add HPX to Compiler Explorer (godbolt.org)
      Abstract: Compiler Explorer https://godbolt.org/ is a widely popular web based application which provides easy access to multiple C++ compilers and environments allowing their users to write, test and share anything from small C++ scripts to large CMake-based projects quickly. Given its versatility we thought that it would be a convenient for HPX to have an integration with Compiler Explorer in some way. A preliminary idea is that we will maintain our own fork of Compiler Explorer (which is open source) and experiment with the HPX integration locally before making the integration public through a Pull Request to Compiler Explorer. The result could even be constrained to an environment somewhat similar to Compiler Explorer just for HPX where prospective users would experiment with quick HPX scripts before downloading, building and running the whole library.
      Difficulty: Medium/Hard
      Expected result: Develop a fork of Compiler Explorer (or application with similar basis) where HPX is integrated and available for quick testing and scripting.
      Knowledge Prerequisite: C++, CMake, Compilers, Node.js
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com)
      Project Size: 175 (Medium project)

      ~~~~~~~~~~
      Conflict (Range-Based) Locks
      Abstract: Some multi-threaded algorithms may require resources that must be held using a lock, but the locking mechanism may be range-based rather than absolute. Consider a large array of N items where a task requires some small subset of the items to be locked while a second task requires a second range. If these tasks are placed into a DAG so that task2 can only run once task1 has been completed, it will be inefficient when the range of items used by task2 does not overlap the range from task1. When many tasks operate on the range, with randomly overlapping or non-overlapping regions, DAG-based task scheduling leads to a highly inefficient strategy. We need a range based lock that can be templated over <items>, and that can then be locked/unlocked on ranges (of those items) and interact with our future<> based scheduling so that items will become ready when the range they need has no locks outstanding, and so that when a task releases a lock, any other tasks that overlap the range are in turn signaled as possibly ready. (For an example of how this is used in conventional HPC programming, look up Byte Range locks in MPI for Parallel IO to a single file). A successful implementation can be extended to multi-dimensional locking *2D/3D etc., ideally templated over dimensions and types).
      Difficulty: Medium/Hard
      Expected result: A test application that creates arrays of items and randomly assigns tasks to operate on regions of those items with locking and schedules the tasks to operate in a non-conflicting way.
      Knowledge Prerequisite: Thread-safe programming. Futures.
      Mentor: John Biddiscombe ()
      Project Size: 350 hour (large project)

      ~~~~~~~~~~
      Standardize and Visualize HPX Benchmarks
      Abstract: HPX, as a high-performance computing framework, includes various benchmarks to measure the performance of its algorithms and runtime system. However, these benchmarks lack a standardized format and a comprehensive visualization tool that can help in analyzing performance trends over time and across different computing environments. This project aims to standardize the benchmark formats within HPX using third party benchmarking tools (recommendations below) and develop a visualization tool that can display benchmark results in an intuitive manner. The tool will used in conjunction with CI/CD to track and display performance regressions or improvements, and provide insights into the scalability and efficiency of new components.
      Additional References:
      Recommended Benchmarking Frameworks: Google Benchmark, Nanobench
      Nanobench in HPX
      Google Benchmark in HPX
      Difficulty: Medium/Advanced
      Expected result: 1) A unified format for HPX benchmarking using chosen benchmarking framework. 2) Automating the installation of the chosen benchmarking framework in the HPX build system. 3) A visualization tool (suggestion: a python script) to display the results.
      Knowledge Prerequisite: C++, Git, Python or plotting framework of your choice
      Mentor: Hartmut Kaiser () and Isidoros Tsaousis-Seiras (tsa.isidoros [at] gmail.com).
      Project Size: 350 hour (Advanced project)

      ~~~~~~~~~~
      Rustize HPX!
      Abstract: Rust is an increasingly widely adopted language used because of it's performance and apparent safety. Providing performant HPX functionality written in C++ with Rust APIs would facilitate both safety and ease of learning HPX. The student shall design and implement Rust bindings for HPX, exposing all or parts of the HPX functionality with a Rust API.
      Difficulty: Medium
      Expected result: Demonstrate functioning bindings by implementing small example scripts for different simple use cases
      Knowledge Prerequisite: C++, Rust
      Mentor: Hartmut Kaiser ()
      Project Size: 350 hour (large project)

      ~~~~~~~~~~
      Pythonize HPX!
      Abstract: Python is a widely adopted language due to its simplicity. Providing performant HPX functionality written in C++ with Pythonic APIs would facilitate both usage and ease of learning HPX. The student shall design and implement Python bindings for HPX, exposing all or parts of the HPX functionality with a 'Pythonic' API. This should be possible as Python has a much more dynamic type system than C++. Using Boost.Python and/or Pybind11 seem to be good choices for this.
      Difficulty: Medium
      Expected result: Demonstrate functioning bindings by implementing small example scripts for different simple use cases
      Knowledge Prerequisite: C++, Python
      Mentor: Hartmut Kaiser ()
      Project Size: 350 hour (large project)

      ~~~~~~~~~~
      Create Generic Histogram Performance Counter
      Abstract: HPX supports performance counters that return a set of values for each invocation. We have used this to implement performance counters collecting histograms for various characteristics related to parcel coalescing (such as the histogram of the time intervals between parcels). The idea of this project is to create a general-purpose performance counter which collects the value of any other given performance at given time intervals and calculates a histogram for those values. This project could be combined with Add more arithmetic performance counters.
      Difficulty: Medium
      Expected result: Implement a functioning performance counter which returns the histogram for any other given performance counter as collected at given time intervals.
      Knowledge Prerequisite: Minimal knowledge of statistical analysis is required.
      Mentor: Hartmut Kaiser () and Mikael Simberg ()
      See issue #2237 on HPX bug tracker
      Project Size: 350 hour (large project)

      ~~~~~~~~~~
      HPX User Projects
      These are projects that improve code that uses HPX. In general, the primary goal with these projects is to improve user uptake of HPX by demonstrating its use in other projects, and only minor fixes/changes/extensions should be necessary for the main HPX library itself.
      Implement your favorite Computational Algorithm in HPX
      Abstract: This is an open project for prospective students who don't want to get their hands dirty into core HPX development. The student shall utilize HPX to implement a short independent project that will utilize HPX for performance boost. The program can implement any given problem that requires heavy computational effort from the literature. Efficient matrix multiplication, sorting, stencil variations or any AI, Physics related problem would be a good candidate. An extensive list of use-case examples is already available in our source code. The goal of this project is for the student to get acquainted with HPX development and contribute to our vast range of applications.
      Difficulty: Easy
      Expected result: Implement a standalone program that utilizes HPX for performance.
      Knowledge Prerequisite: C++
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com)
      Project Size: 175 hour (medium sized)

      ~~~~~~~~~~
      Conduct a thorough Performance Analysis on HPX Parallel Algorithms (and optimize)
      Abstract: HPX implements all the C++ standard algorithms along with their ranges counterparts. Conducting extensive performance analysis on the existing implementations and coming up with possible optimizations would improve the efficiency of our parallel algorithms and boost HPX performance in general. The student shall expect to work both on top of HPX by writing custom benchmarks for weak and strong scaling, evaluate the results and perform source optimizations under the hood (core development).
      Difficulty: Medium
      Expected result: Boost the performance of at least one C++ standard algorithm in HPX.
      Knowledge Prerequisite: C++
      Mentor: Giannis Gonidelis (gonidelis [at] hotmail.com) and Hartmut Kaiser ()
      Project Size: 350 hour (large project)

     
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/steororar-group/
    idea_list_url: https://github.com/STEllAR-GROUP/hpx/wiki/Google-Summer-of-Code-%28GSoC%29-2025#2025-hpx-project-ideas

  - organization_id: 144
    organization_name: Stichting SU2
    no_of_ideas: 6
    ideas_content: |
      
      
      
      Project 1: Adding pressure-based solver
      
      Project Description (max. 5 Sentences)
      The pressure-based solver has been requested for a long time. This solver is an important addition to the CFD solvers, especially for low Mach and incompressible flows. People have worked on it (detailed documentation available), and there is a branch that contains a working version, but this was never finalized and added to the main SU2 branch. Hence, the project's objective is to evaluate the current status of attempts, and propose a strategy for getting the pressure-based solver in the latest version of SU2.
      Expected Outcome (deliverables): Finalize pressure-based solver, validate with test cases, tutorial and merge the PR.
      Skills Required: C++, experience with CFD and numerical methods
      Possible Mentors: Nitish Anand and Edwin van der Weide
      Expected Project Size: 175 hrs/medium
      Difficulty rating: medium-hard (needs experience with Computational Fluid Dynamics)

      ~~~~~~~~~~
      
      
      Project 2: Using data-driven, physics-informed machine learning to model fluid properties in computational fluid dynamics.
      
      Project Description (max. 5 Sentences)
      The properties of complex fluids can be modeled in SU2 by using a data-driven method that uses physics-informed neural networks (PINNs). This method is very efficient and accurate, but is sometimes not robust when it comes to inverse regression. The main goals of this project are:
      Develop and implement a smart method for choosing the starting point of inverse regression.
      Indicate in the flow solution where predictions of the fluid properties may be unreliable (due to phase transition or inaccurate inverse regression).
      Improve the efficiency of the neural network evaluation algorithm.
      Expected Outcome (deliverables): Validation of regression algorithm robustness and validation study of algorithmic efficiency of neural network evaluation algorithm. Addition of tutorial to SU2 tutorial library and merge changes with a PR.
      Skills Required: C++, python, SU2
      Possible Mentors: Evert Bunschoten (lead)
      Expected Project Size: 175 hrs/medium
      Difficulty rating: easy-medium (experience in CFD or fluid modeling preferred)

      ~~~~~~~~~~
      
      
      
      
      Project 3: Graphical User Interface: coupling to python wrapper and json validation
      
      Project Description (max. 5 Sentences)
      In GSoC 2024 we improved the SU2 GUI and made it suitable for basic use. We would like to keep the momentum and focus in this project on two main things: 1. coupling with the python wrapper so users are able to write python scripts inside the GUI, and export the GUI setup in python format; and 2. Write a json validation for the configuration file. The goal is also that the json validation will replace the hardcoded c++ validation that we have in the main SU2 solver.
      Expected Outcome (deliverables): SU2-GUI (python+trame library), availability on github, json validation scheme, python coupling for initialization and boundary condition.
      Skills Required: Python, Paraview, SU2, Trame, json
      Possible Mentors: Nijso Beishuizen, Ujjawal Agrawal (2024 GSoC Alumnus)
      Expected Project Size: 175 hrs/medium
      Difficulty rating: medium

      ~~~~~~~~~~
      
      
      Project 4: Make it easy to add and update unit tests
      
      Project Description (max. 5 Sentences)
      One of the most important requirements for a CFD code is that users trust the outcome. This trust is gained by performing Unit Tests, as well as Verification and Validation tests. We need more online tests, and these tests should be 1. Easy to add and 2. Complete in their testing. We therefore need to automate the creation, adding and maintaining of these tests.
      Expected Outcome (deliverables) Templated and Automated unit and V&V tests, putting current tests in the new system, regeneration of the results (figures, data, etc.), possible creation of new results.
      Skills Required: python, C++
      Possible Mentors: Nijso Beishuizen (lead)
      Expected Project Size (90 hrs/ small , 175 hrs/medium, 350 hrs/large): 90hrs, small
      Difficulty rating (easy (little experience/background), medium (some experience/background), hard (experienced)): easy
      
      
      ~~~~~~~~~~
      
      Project 5: Continuation of GPU acceleration in SU2
      
      Project Description (max. 5 Sentences)
      The SU2 code relies heavily on sparse linear algebra. In this area, there is significant speed-up potential with the adoption of GPU-based processing, as was demonstrated in the GSOC 24 project that applied CUDA to sparse matrix-vector multiplications in SU2. The objective of this project is to move more linear algebra operations to GPU in order to avoid host-device communication bottlenecks within the sparse linear system solver.
      Expected Outcome (deliverables) Make SU2’s sparse linear solver GPU-native, i.e. minimal host-device communication after the initial setup of the system.
      Skills Required C++
      Possible Mentors: Pedro Gomes (lead), Ole Burghardt
      Expected Project Size (90 hrs/ small , 175 hrs/medium, 350 hrs/large): 175 hrs (medium)
      Difficulty rating (easy (little experience/background), medium (some experience/background), hard (experienced)): medium
      
      
      ~~~~~~~~~~
      Project 6: Extending turbomachinery geometry handling for mixed-flow applications
      
      Project Description (max. 5 Sentences)
      Mixed-flow turbomachinery components, such as NASA’s High Efficiency Centrifugal Compressor, combine the properties of both axial and radial machines. Such geometries can be difficult to simulate due to their complex geometric dependencies. This project aims to refactor SU2’s current turbomachinery geometry handling and extend it to be able to handle mixed-flow machinery.
      Expected Outcome (deliverables) Merged PR containing the new, flexible axes of rotation, and validation of the NASA HECC testcase
      Skills RequiredC++, SU2
      Possible Mentors: Josh Kelly
      Expected Project Size (90 hrs/ small , 175 hrs/medium, 350 hrs/large):175 hrs (medium)
      Difficulty rating (easy (little experience/background), medium (some experience/background), hard (experienced)): easy/medium
     
       
      
      
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/stichting-su2/
    idea_list_url: https://www.cfd-online.com/Forums/su2-news-announcements/259420-gsoc-2025-projects.html

  - organization_id: 145
    organization_name: Sugar Labs
    no_of_ideas: 17
    ideas_content: |
     

      Git backend for Turtle Blocks and Music Blocks
      Prerequisites
      Experience with Git
      Experience with JavaScript
      Experience with Music Blocks and Turtle Blocks
      Description
      Portfolio creation, reflection, and collaboration are important parts of the educational philosophy at Sugar Labs, and Git version control is a great way to explore all these things.
      At Sugar Labs, we've created some initial designs](https://drive.google.com/file/d/15G0vtr-1JyzCorwmgjvXE-37vwZMLgJD/view?usp=sharing) for a couple approaches to introducing Git version control to young learners. This proposal focuses on introducing Git version control through our existing web-based programs, namely Turtle Blocks and Music Blocks. Both these programs have a feature to publish projects to a server called the "Planet". Currently the Planet just stores projects that users have made, without any sort of version control features like fork, history, or checkout.
      This project requires a contributor to work closely with Sugar Labs mentors to implement a system of Git version control features, running on a backend server, that are exposed to the user.
      References:
      https://drive.google.com/file/d/15G0vtr-1JyzCorwmgjvXE-37vwZMLgJD/view?usp=sharing
      Project Length
      350 hours
      Difficulty
      Hard
      Coding Mentors
      Walter Bender Sumit Srivastava
      Assisting Mentors
      Devin Ulibarri

      ~~~~~~~~~~
      Color sensor for Music Blocks for photos and real-time video
      Prerequisites
      Experience with JavaScript
      Experience with Music Blocks
      Description
      Music Blocks has a feature to detect the color of pixels generated from drawing within the program, but it cannot detect the color of pixels from images that are either uploaded or from a webcam. By adding a feature to detect color from both uploaded images and a live webcam stream, users would be able to implement Lego music notation for the blind and similarly interactive programs.
      The goal of the project is to develop extended functionality to our existing tools of turtle/mouse glyph movement and limited color detection to sense color from uploaded images, as well as the real-time feed from a webcam. Upon successful implementation, the turtle/mouse glyph will be able to detect the color of pixels underneath it, regardless of whether those pixels were drawn by the turtle/mouse itself, part of an uploaded image stamped to the canvas, or part of a live webcam video feed into Music Blocks. One test of success is to run our Lego music notation for the blind project with a live feed. The result should be able to playback and record the abstract brick notation based on its contrasting colors.
      References:
      https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c
      https://vimeo.com/983707992
      https://vimeo.com/983697295
      Project Length
      175 hours
      Difficulty
      Medium
      Coding Mentors
      Walter Bender
      Assisting Mentors
      Devin Ulibarri

      ~~~~~~~~~~
      AI-powered Debugger for Music Blocks
      Prerequisites
      Experience with Python
      Experience with Music Blocks
      Experience with LLMs/Chatbots
      Experience with AWS
      Experience with FastAPI
      Description
      The idea is to enhance Music Blocks with an AI-powered debugger. This feature aims to bridge the gap between users' creative ideas and their ability to troubleshoot or fully utilize the platform's features. This AI-powered debugger will provide real-time assistance by answering questions, explaining features, and offering creative suggestions. It will help users quickly identify and resolve issues in their projects or block connections This enhancement would make the platform more accessible for beginners while streamlining the debugging and experimentation process for advanced users.
      Specifically, we aim to achieve the following:
      Train an open-source LLM to understand Music Blocks projects and develop the ability to debug them effectively.
      Implement robust Retrieval-Augmented Generation (RAG) for the LLM model to enhance contextual understanding.
      Integrate the AI chatbot and debugger into the Music Blocks platform.
      Develop FastAPI endpoints to deploy the model efficiently.
      Work on techniques to minimize hallucinations and improve accuracy.
      Project Length
      350 hours
      Difficulty
      Hard
      Coding Mentors
      Walter Bender Sumit Srivastava
      Assisting Mentors
      Devin Ulibarri
      ~~~~~~~~~~
      Improve synth and sample features in Music Blocks
      Prerequisites
      Experience with JavaScript
      Experience with Music Blocks
      Experience with Tone.JS
      Description
      Users have two main methods within Music Blocks to play with sound: synths and samples. For our synth, we use tone.js. For samples, we use .wav binaries and transpose the sound to different pitches. While these features work "well enough," there is still more that can been to make them useful. For this project, a contributor would work closely with their mentors to 1) update the sampler widget, 2) port a list of free/libre/open samples into Music Blocks, and 3) add to the Set Instrument feature and Sampler Widget the ability to assign multiple samples for the same instrument with criteria (e.g. high and low, short and long) for a more natural sound.
      Updating the sampler widget will involve updating tone.js to its current version, debugging any issues that updates may cause, and making improvements to the UI/UX of the widget itself. Improvements include adding a tuner feature in Sampler Widget, just like https://www.musicca.com/tuner and adding a way to do micro adjustments in cents.
      Porting samples into Music Blocks will require following the directions specified in the Music Blocks documentation to convert a curated list of samples. After completing this, the user-facing menus showing the samples will need to be updated and organized based on instrument type. There is some room to get creative with the presentation of the instruments, perhaps adding icons for each instrument.
      The final part of the project is perhaps the most challenging. It will require adding additional functionality so that a user can either upload or record multiple samples of an instrument or voice to be assigned to a custom instrument in Music Blocks. Doing this will make the overall tone of the instruments more persuasive. For example, if the Music Blocks project has short, staccato sounds, the playback can use the short sample created by a recorded instrument.
      References:
      https://github.com/sugarlabs/musicblocks/tree/master/sounds/samples
      "Processing for pitched (non-percussion) samples" section of https://wiki.sugarlabs.org/go/Music_Blocks/2025-02-09-meeting
      A professionals guide to creating "virtual instruments": https://www.nicolastiteux.com/en/blog/making-a-virtual-instrument-a-guide-to-sampling/
      Possible samples: https://philharmonia.co.uk/resources/sound-samples/
      Possible samples: https://github.com/sonic-pi-net/sonic-pi/tree/dev/etc/samples
      Possible samples: https://freesound.org/people/MTG/
      Project Length
      350 hours
      Difficulty
      Hard
      Coding Mentors
      Walter Bender
      Assisting Mentors
      Devin Ulibarri

      ~~~~~~~~~~
      Generative AI Instrument Sample Generation for Music Blocks
      Prerequisites
      Experience with JavaScript and Python
      Experience with Music Blocks
      Experience with Tone.JS
      Experience with LLMs/neural-networks
      Description
      For this project, a contributor would work closely with their mentors create an API to a gen-AI to generate samples based on a user prompt.
      In order to give users (nearly) limitless options for samples, we are adding to the project's scope a gen-AI-enabled sample generator. A user should be able to prompt a sound font, such as "something between a heavy metal guitar and a lion roar" or "something between a clarinet and a human singing 'ah'" additionally, a user should be able to play an instrument or upload recorded audio of an instrument and prompt modifications for the gen-AI to make to the sound, such as "make this recording of my acoustic cello sound like an electric cello with heavy distortion and get a result that they can use in their project's code. A contributor will need to extend our sample widget (which currently records audio) to accept a user prompt, create an API to call an LLM/neural-network backend, and test/tweak the gen-AI backend to create an appropriate sample for the user. The results of this part of the project need not be "perfect" by the end of the summer. A solid proof of concept will be sufficient.
      In particular, our focus will be on achieving the following objectives:
      Extend the sample widget to support user prompts for AI-generated sound samples.
      Develop an LLM-based generative AI backend to produce high-quality, relevant sound samples.
      Build a high-performance API using FastAPI to streamline interactions between the widget and the LLM.
      Project Length
      350 hours
      Difficulty
      Hard
      Coding Mentors
      Walter Bender Sumit Srivastava
      Assisting Mentors
      Devin Ulibarri

      ~~~~~~~~~~
      AI Code generation for lesson plans and model abstraction layer
      Prerequisites
      Experience with Python
      Experience with Music Blocks
      Experience with LLMs/Chatbots
      Experience with Fine tuning methods and RAG.
      Description
      Develop and train an open-source Large Language Model to generate Music Blocks project code, enabling the integration of code snippets into the lesson plan generator for better understanding of the projects. Additionally, by implementing a model abstraction layer, the AI system will remain flexible and model-agnostic, allowing seamless integration of different AI models while maintaining consistent code generation capabilities. This approach ensures long-term sustainability and adaptability as AI technology evolves while keeping the core functionality of Music Blocks accessible and extensible.
      Specifically, we would be working toward accomplishing the following:
      Train open source LLM to generate code to create new Music Blocks projects.
      Implement model abstraction layer to make the AI system model agnostic and robust.
      Increase database size by including more lesson plans and projects' data to get better response related to the projects.
      Implement Approximate Nearest Neighbor (ANN) algorithms for faster retrieval.
      Develop FastAPI endpoints to deploy the model.
      Work on and implement techniques to minimize hallucination.
      Project Length
      350 hours
      Difficulty
      Hard
      Coding Mentors
      Walter Bender Sumit Srivastava
      Assisting Mentors
      Devin Ulibarri

      ~~~~~~~~~~
      AI tools for reflection
      Prerequisites
      Experience with Python/JavaScript
      Experience with LLMs/Chatbots
      Description
      While off-the-shelf Generative AI tools are great at helping a learner to create, they offer little in regard to reflecting upon those creations. But reflection is a critical (and too often overlooked) part of the Constructionist learning pedagogy. With some prompting -- something LLMs are quite good at -- we can engage the learner in a quality relfective practice. The dialog could occur when exiting any Sugar activity as part of the journaling process or whenever a Music Blocks or Turtle Blocks project is saved to the Planet. Rather than just being presented with an empty form, the learner will be prompted to talk about what they did, why they did it, what they learned and what they might do next.
      Specifically, we would be working toward accomplishing the following:
      Research different approaches to reflective practice
      Train open source LLM to generate code to prompt the learn with a multitude of these approaches to reflection
      Develop FastApi endpoints to deploy the model.
      Deploy this model in either the Music Blocks Planet or the Sugar Journal or the Sugarizer Journal to be triggered whenever a project is paused or saved
      Project Length
      350 hours
      Difficulty
      Hard
      Coding Mentors
      Walter Bender Sumit Srivastava
      Assisting Mentors
      Devin Ulibarri

      ~~~~~~~~~~
      Music Blocks 4 Masonry Module
      Prerequisites
      Proficiency in TypeScript
      Proficiency in JavaScript DOM API
      Experience with React Functional Components and Hooks
      Familiarity with Storybook and Vitest
      Familiarity with SVG paths and groups
      Description
      Music Blocks programs are designed to be built interactively by connecting program constructs, which are visually represented as snap-together, Lego-like graphical bricks. The goal is to develop a module for Music Blocks (v4) that enables the creation of Music Blocks programs.
      The project will begin with the development of a framework for generating individual brick components that represent various program syntax constructs. This will be followed by the creation of utilities to represent any program structure through visual connections between the bricks. Next, a component will be built to display all available program bricks, organized into categories, sections, and groups. Finally, a workspace will be developed where users can drag-and-drop, as well as connect and disconnect the program bricks to create their programs.
      To draw the bricks, we will use SVG paths, so a solid understanding of SVG path commands is crucial. The development will follow an Object-Oriented Programming approach in TypeScript, with the rendering and management of visual states handled using React Functional Components. A strong understanding of both TypeScript and React is expected.
      This project began last year, and you will be expected to build upon the progress made and complete the module.
      The overall objectives are as follows:
      Collaborate with project maintainers to create a design document outlining functional requirements, UI considerations, both high-level and low-level designs, and a technical specification.
      Develop utilities to generate SVG paths for the bricks based on configurations.
      Build utilities to represent and manipulate Music Blocks programs in-memory.
      Develop the four individual submodules outlined above.
      Write Storybook stories to document and showcase UI components.
      Implement unit tests for functions and classes using Vitest.
      Focus on optimizing processing performance.
      Export a minimal API for integration with other parts of the application.
      Project Length: 350 hours
      Difficulty: Hard (★ ★ ★ ★ ★)
      Tech Stack
      TypeScript 5, React 18, Sass, Storybook, Vitest, Vite
      Mentors
      Anindya Kundu
      Assisting Mentors
      Walter Bender
      Devin Ulibarri

      ~~~~~~~~~~
      Music Blocks 4 Program Engine
      Prerequisites
      Proficiency in TypeScript and Object-Oriented Programming
      Experience with writing unit tests using Jest/Vitest
      Good understanding of the JavaScript Event Loop
      Understanding of Abstract Syntax Trees (AST)
      Tech Stack
      TypeScript 5, Vitest, Vite
      Description
      Music Blocks is a programming platform, and at its core is the execution engine responsible for running Music Blocks programs. This project will focus on building the execution engine and the necessary components to represent and execute Music Blocks programs in-memory.
      The project will begin by refining the Object-Oriented program syntax constructs. These constructs will encapsulate the logic for each syntax element and will serve as the foundation for developing a framework to represent Abstract Syntax Trees (ASTs) for Music Blocks programs. Additional utilities will be built to manage instances of these syntax constructs, thus completing the static pieces.
      Next, several components will need to be developed to execute the program ASTs, forming the dynamic pieces of the project. Key components include:
      Parser: Responsible for parsing the nodes of the ASTs in inorder traversal.
      State Manager: Manages the program state at any given point during execution.
      Interpreter: Executes individual expressions and instructions.
      It’s important to note that Music Blocks programs combine both imperative and declarative constructs. Additionally, some instructions in the programs execute over a time duration, and the programs themselves are multi-threaded. These threads must run concurrently while ensuring proper synchronization.
      We currently have a work-in-progress on github.com/sugarlabs/musicblocks-v4-lib, but some design decisions need to be revisited. This project will involve understanding and refining these design choices and completing the remaining components.
      The overall objectives are as follows:
      Collaborate with project maintainers to define all expected functionalities and behaviors, and write a technical specification.
      Collaborate with project maintainers to develop a concrete execution algorithm, addressing time-based instructions, concurrency, and synchronization.
      Refine and complete the static components responsible for program representation.
      Refine and complete the dynamic components responsible for program execution.
      Write comprehensive unit tests for all components.
      Focus on optimizing runtime performance.
      Project Length: 350 hours
      Difficulty: High (★ ★ ★ ★ ☆)
      Mentors
      Anindya Kundu
      Assisting Mentors
      Walter Bender
      Devin Ulibarri

      ~~~~~~~~~~
      Add an AI-assistant to the Write Activity
      Prerequisites
      Experience with Python
      Experience with Sugar activities
      Experience with LLMs/Chatbots
      Description
      Sugar pioneered peer editing in its Write Activity. However, the Write Activity has never had any serious support for grammar correction (just spell check) and none of the more recent developments around AI-assisted writing. The goal of this project is to add AI-assistance to the writing process: both in the form of providing feedback as to what has been written and making suggestions as to what might be written.
      The challenge will be both in terms of workflow integration and UX.
      Project Length
      350 hours
      Difficulty
      High
      Coding Mentors
      Walter Bender Ibiam Chihurumnaya
      Assisting Mentors

      ~~~~~~~~~~
      Refactor the Infoslicer Activity to generate plain-language summaries
      Prerequisites
      Experience with Python
      Experience with Sugar activities
      Experience with LLMs/Chatbots
      Description
      The Infoslicer Activity is designed to help teachers extract content from the Wikipedia in order to create lesson plans. This is currently a manual, extractive process. It is well suited to generative AI. The goal would be to have a teacher type in a theme for a lesson and have the AI create a simple lesson plan, which the teacher can then edit.
      The biggest challenge to summarization using generative AI is hallucinations. A work-around for this is to include a validation step that surfaces evidence (or lack of evidence) for each assertion in the lesson plan. This will introduce some workflow and UX challenges.
      Project Length
      350 hours
      Difficulty
      High
      Coding Mentors
      Walter Bender Ibiam Chihurumnaya
      Assisting Mentors

      ~~~~~~~~~~
      Refactor the chatbot in the Speak Activity to use gen-AI
      Prerequisites
      Experience with Python
      Experience with Sugar activities
      Experience with LLMs/Chatbots
      Description
      The Speak Activity is one of most popular Sugar activities. It allows someone just beginning to familiarize themselves with reading to interact with synthetic speech. It has both chat and chatbot capabilities, so that learners can share what they type with others, often using invented spelling. It would be a nice improvement if there were a chatbot option to allow a learner to have a conversation with a more modern chatbot -- LLM-based. This would contextualize the learner's experience with writing -- a tool for both self expression and communication.
      The project would entail both enabling the LLM chatbot and doing some tuning in order to accommodate invented spelling. Finally, it will be important to create the proper persona, in this case, an adult explaining to a young child.
      Project Length
      175 hours
      Difficulty
      Medium
      Coding Mentors
      Ibiam Chihurumnaya
      Assisting Mentors
      Walter Bender

      ~~~~~~~~~~
      GTK4 Exploration
      Prerequisites
      Experience with C
      Experience with Python
      Experience with GTK
      Good understanding of Sugar Core architecture
      Description
      Sugar 0.120 runs on GTK3 and needs to be ported to GT4, we need to port Sugar and its core activities to support GTK4 before GTK3 gets to its EOL.
      Project Task Checklist
      Migrate minimal sugar-toolkit-gtk3 components to support Hello World activity, in particular the activity and graphics classes.
      Migrate Hello World activity.
      Document migration strategy based on extending any existing upstream GTK3 to GTK4 porting documentation.
      Migrate remaining toolkit components.
      Extend Hello World to use remaining toolkit components, and rename as a Toolkit Test activity,
      Migrate Sugar.
      Migrate the Fructose activity set, as time permits.
      Steps to start
      Plan migration.
      Setup a live build development environment.
      See the GTK4 migrating doc.
      Project length
      350 hours
      Difficulty:
      High
      Coding Mentors
      Ibiam Chihurumnaya

      ~~~~~~~~~~
      JS internationalization
      Prerequisites
      Experience with JavaScript
      Description
      Our JavaScript activities are using a somewhat antiquated mechanism for internationalization, the webL10n.js library. It does not even support plurals or any language-specific formatting. i18next looks like a well-maintained and promising alternative.
      This project involves: (a) researching the state of art of language localization for JavaScript, keeping in mind that we are currently maintaining PO files; (b) making a recommendation as to the framework; (c) proposing a path to implementation; and (d) implementing the solution in Music Blocks. (Other JS projects can follow along.)
      Project Task Checklist
      research
      recommendation
      plan
      coding
      Project length
      175 hours
      Difficulty:
      Medium
      Coding Mentors
      Walter Bender
      ~~~~~~~~~~
      Sugarizer Human Activity pack
      Prerequisites
      Experience with JavaScript/HTML5 in VanillaJS or with Vue.js
      Experience with three.js 3D framework
      Knowledge of 3D tools, capacity to create/combine 3D assets
      Description
      The objective of this project is to:
      Finalize the 3D Human Body activity
      Create a new activity named Stickman Animation
      
      
      3D Human Body activity
      The human Body activity has been started on https://github.com/llaske/sugarizer/tree/feature/humanbody.
      Tasks to do:
      Identify the missing assets for the body layer and the organs layer (only skeleton layer is here today)
      Integrate these layers in the activity and the way to change layer
      Implement the shared mode for doctor mode
      Review the UI for toolbar and popups
      Localize the activity
      Suggest other improvements
      
      Stickman Animation activity
      Create a new activity to allow creation of animated sequence of a stickman.
      The idea of the activity is a "keyframe animation" tool that lets you pose and program a stick figure to rotate, twist, turn, tumble, and dance. The new activity can be integrated into many school subject areas such as creative writing, art, drama, geometry and computer programming. Students can make figures that relate to a subject the class is studying, and share them with peers using collaboration feature. It helps children develop spatial and analytical thinking skills and to express ideas that they might not have words for yet.
      Features expected:
      Put the stickman figure in different poses by moving dots
      Create and order frames with the different poses created
      Play/Pause the whole frames
      Change speed
      Share and collaborate
      Export as a video
      Access to a list of existing fun templates
      Import a photo of an human body to create a stickman figure in the same pose
      Inspirations:
      https://activities.sugarlabs.org/en/sugar/addon/4044
      https://www.spatial.io/g/stick-animator
      https://flipanim.com/
      https://pivotanimator.net/
      https://drawastickman.com
      https://stickfigure-recorder.web.app/
      First steps to starts
      Complete the Sugarizer Vanilla Javascript activity development tutorial or the Sugarizer Vue.js activity development tutorial. Publish on Discord a video of the Pawn activity running.
      Start working of tasks listed for Human Body activity
      Create a mockup of the Stickman Animation activity
      Project length
      175 hours
      Difficulty: ★ ★ ☆ (medium)
      Coding Mentors
      Lionel Laské
      Assisting Mentors
      Samarth Bagga

      ~~~~~~~~~~
      Pippy Debugger
      Prerequisites
      Experience with Python
      Experience with Sugar activities
      Experience with LLMs/Chatbots
      Description
      Many LLM programs for coding are almost exclusively marketed as "helping you write code for you". However, we believe that LLMs can also assist learners to debug their code. This project proposal is to create an LLM-powered debugger for Pippy, the Sugar Activity for creating code in Python.
      The proposed Pippy Debugger integrates with the existing Pippy Activity. The LLM-powered debugger should be able to read a learner's code and offer suggestions for improvement when prompted. It should also help engage the learning in a conversation about how to discover where to look to find bugs and how to think about resolving them -- in other words, take the learning on a debugging journey as opposed to just spoon-feeding a solution. And since we work with youth, we need to make sure that the debugger's output is age-appropriate. The Pippy interface will also be updated to expose the new feature to a user.
      Project Length
      175 hours
      Difficulty
      Medium
      Coding Mentors
      Walter Bender Ibiam Chihurumnaya Kshitij Shah

      ~~~~~~~~~~
      Math Games
      Prerequisites
      Experience with Python
      Experience with Sugar activities
      Interest in math puzzles and games
      Description
      While Sugar has lots of activities, you can never have enough math games and puzzles.This project would be to develop 8 new maths activities.
      These are some of the tentative Maths games of interest:
      Four Color map game
      Broken Calculator
      Soma cubes,
      Fifteen Puzzle.
      Euclid's Game
      Odd Scoring
      Make An Identity
      Number Detective - Number Detective is a fun math game that teaches pattern recognition and AI basics.
      User input a number sequence, and the AI predicts the next number.
      If the AI is wrong, the user corrects it, helping it learn over time!
      The game uses simple rule-based logic and machine learning for predictions.
      Sorting Hat AI - Sorting Hat AI is an interactive game that teaches how AI classifies objects.
      User label animals, shapes, or numbers, and the AI learns to classify new ones.
      If the AI makes a mistake, kids correct it, improving its learning over time!
      The game uses Decision Trees or k-Nearest Neighbors (k-NN) for classification.
      Note: These are some tentative ideas for math games. Further updates, additions, or modifications can be made through discussions with mentors to develop the best possible games.
      Project Length
      350 hours
      Difficulty
      Medium
      Coding Mentors
      Ibiam Chihurumnaya
      Assisting Mentors
      Walter Bender
     
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/sugar-labs/
    idea_list_url: https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md


  - organization_id: 146
    organization_name: Swift
    no_of_ideas: 13
    ideas_content: |

      Re-implement property wrappers with macros
      Project size: 350 hours (large)
      Estimated difficulty: Intermediate
      Recommended skills
      Proficiency in Swift and C++
      Description
      Property wrappers feature is currently implemented purely within the compiler but with the addition of Swift Macros and init accessors it’s now possible to remove all ad-hoc code from the compiler and implement property wrappers by using existing features.
      This work would remove a lot of property wrapper-specific code throughout the compiler - parsing, semantic analysis, SIL generation etc. which brings great benefits by facilitating code reuse, cleaning up the codebase and potentially fixing implementation corner cases. Macros and init accessors in their current state might not be sufficient to cover all of the property wrapper use scenarios, so the project is most likely going to require improving and expanding the aforementioned features as well.
      Expected outcomes/benefits/deliverables
      The outcome of this project is the complete removal of all property wrappers-specific code from the compiler. This benefits the Swift project in multiple areas - stability, testability and code health.
      Potential mentors
      Pavel Yaskevich

      ~~~~~~~~~~
      Improve the display of documentation during code completion in SourceKit-LSP
      Project size: 175 hours (medium)
      Estimated difficulty: Intermediate
      Recommended skills
      Proficiency in Swift and C++
      Description
      The Language Server Protocol (LSP) offers two rich ways of displaying documentation while invoking code completion: Every code completion item can have documentation associated with it and while completing a function signature, the editor can display the available overloads, parameter names and their documentation through signature help. Currently, SourceKit-LSP only displays the first line of an item’s documentation in the code completion results and does not provide any signature help.
      This project would implement functionality to return the entire documentation for all code completion items and also implement the LSP signature help request. Both of these will require functionality to be added in SourceKit-LSP and the compiler’s code base, which determines the list of feasible code completion results.
      Expected outcomes/benefits/deliverables
      SourceKit-LSP will display more information and documentation about the code completion items it offers, allowing developers to pick the item that they are interested in more easily.
      Potential mentors
      Alex Hoppen

      ~~~~~~~~~~
      Refactor sourcekitd to use Swift Concurrency
      Project size: 175 hours (medium)
      Estimated difficulty: Intermediate
      Recommended skills
      Proficiency in Swift, including Swift 6’s concurrency model
      Basic proficiency in C++
      Description
      sourcekitd is implemented in the Swift compiler’s repository to use the compiler’s understanding of Swift code to provide semantic functionality. It is currently implemented in C++. By refactoring its request handling and AST manager to Swift, we can take advantage of Swift’s concurrency safety, improving its data race safety, making it easier to reason about and maintain.
      On macOS, sourcekitd is run as an XPC service, while on all other platforms, sourcekitd is run in the sourcekit-lsp process. As a stretch goal, refactoring the request handling would allow us to run sourcekitd in a separate process on Linux and Windows as well improving SourceKit-LSP’s resilience as crashes inside sourcekitd would not cause a crash of the LSP process itself.
      Expected outcomes/benefits/deliverables
      Improved concurrency-safety of sourcekitd and better maintainability.
      Potential mentors
      Alex Hoppen

      ~~~~~~~~~~
      Add more refactoring actions to SourceKit-LSP
      Project size: 90 hours (small)
      Estimated difficulty: Intermediate
      Recommended skills
      Proficiency in Swift
      Description
      Refactoring actions assist a developer by automatically performing repetitive and mechanical tasks, such as renaming a variable. SourceKit-LSP already provides refactoring actions and this project would add new actions to SourceKit-LSP. A few new refactoring actions have already been proposed but this project is not necessarily limited to those ideas.
      Expected outcomes/benefits/deliverables
      A richer set of refactorings in SourceKit-LSP that aid developers in performing mechanical tasks.
      Potential mentors
      Alex Hoppen

      ~~~~~~~~~~
      Qualified name lookup for swift-syntax
      Project size: 350 hours (large)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Description
      Qualified name lookup is the process by which a compiler resolves a reference A.f into a lookup for entities named f within A. In Swift, this can mean looking into the type A and all of its extensions, superclass, protocols, and so on to find visible members. The project involves building a new library to be integrated into the swift-syntax package that implements Swift’s qualified name lookup semantics, making it easy to build source tools that resolve names. The library will likely include a symbol table implementation that provides efficient lookup of a given name within a given type. It should also integrate with last year’s unqualified name lookup library project, to provide complete support for name lookup on Swift code processed with swift-syntax.
      Expected outcomes/benefits/deliverables
      Swift library providing APIs for qualified name lookup in swift-syntax
      Documentation and tutorial for the library
      Integration of the Swift library with the SwiftLexicalLookup library that implements unqualified name lookup
      Potential mentors
      Doug Gregor

      ~~~~~~~~~~
      Swiftly Integration in VS Code
      Project size: 175 hours (medium)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Basic proficiency in TypeScript.
      Basic proficiency in VS Code extension development.
      Description
      Swiftly is a toolchain manager written in and built for Swift. In order to aid adoption in the Swift community, it would be beneficial to provide a rich editor integration with the existing Swift extension for VS Code. This editor integration should aid the user in installing Swiftly itself as well as with installing and selecting Swift toolchains. This will require some effort in Swiftly itself to provide a machine readable interface that any editor could use to manage Swift toolchain installations.
      Expected outcomes/benefits/deliverables
      Editor integration API in Swiftly for querying available toolchains
      VS Code should be able to install Swiftly for the user
      VS Code should be able to install Swift toolchains via Swiftly
      VS Code should be able to select the active Swift toolchain via Swiftly
      VS Code should show the version of the Swift toolchain in use
      Potential mentors
      Chris McGee
      Matthew Bastien

      ~~~~~~~~~~
      DocC Language Features in SourceKit-LSP
      Project size: 90 hours (medium)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Description
      SourceKit-LSP has recently added a feature to support DocC Live Preview for editors such as VS Code. This feature could be further improved by providing language features such as go to definition as well as diagnostics for invalid/missing symbol names.
      Expected outcomes/benefits/deliverables
      Syntax highlighting for DocC markdown and tutorial files
      Go to definition for symbols that appear in DocC documentation
      Diagnostics that report missing/invalid symbol names in DocC documentation
      Potential mentors
      Matthew Bastien
      Alex Hoppen

      ~~~~~~~~~~
      Tutorial mode for the VS Code Swift extension
      Project size: 90 hours (small)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift
      Basic proficiency in TypeScript
      Basic proficiency in VS Code extension development
      Description
      This project can possibly be combined with the Swiftly Integration in VS Code project and the Tutorial mode for Swift project. When submitting project application for both together, please then mark it as a medium (175 hours) project.
      Right now there isn’t a whole lot of guidance on how to use the Swift extension for VS Code once it is installed. Apart from reading an article about it and the “Details” tab of the Swift extension in VS Code it’s up to the user to realize that a Swift toolchain will have to be installed and figure out the workflow to Build, Run, Test and Debug code. As well, people who are installing the extension could be new to programming and Swift in general. A tutorial mode that will show the features of the extension will be greatly beneficial for first time users.
      The feature can possibly be implemented with VS Code Walkthrough mode or something similar to the CodeTour extension.
      Expected outcomes/benefits/deliverables
      A better onboarding experience for first time users of the VS Code Swift extension
      Users learn about the features of the extension
      Potential mentors
      Either Adam Ward or Paul Lemarquand or Matthew Bastien
      Rishi Benegal

      ~~~~~~~~~~
      Tutorial mode for Swift in the VS Code Extension
      Project size: 90 hours (small)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift
      Basic proficiency in TypeScript
      Basic proficiency in VS Code extension development
      Description
      This project can possibly be combined with the Swiftly Integration in VS Code project and the Tutorial mode for VS Code Swift project.
      Many users who install the VS Code swift extension could be new to Swift and programming in general. A tutorial mode that will show features of the programming language could allow users to experiment with their programs interactively and greatly enhance their learning experience. This tutorial mode can include examples from the Swift Book, a VS Code version of the DocC tutorials, swift-testing tutorials and code formatting tutorials using swift-format.
      The feature can possibly be implemented with VS Code Walkthrough mode or something similar to the CodeTour extension.
      Expected outcomes/benefits/deliverables
      A better onboarding experience for users who want to learn more about Swift
      Users learn about the features of the Swift programming language
      Potential mentors
      Either Adam Ward or Paul Lemarquand or Matthew Bastien
      Rishi Benegal
      ~~~~~~~~~~
      Improved console output for Swift Testing
      Project size: 175 hours (medium)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Description
      Enhance Swift Testing’s reporting of test results to the console/terminal. Consider adding features like live progress reporting, nested output reflecting suite hierarchy, test metadata (display names, tags), parameterized test arguments, and more terminal colors. Perhaps include user-configurable options. If time allows, implement several alternatives and present them to the community (and the Testing Workgroup) for consideration. Factor code as portably as possible to support many platforms, and so it could be incorporated into a supervisory “harness” process in the future.
      Expected outcomes/benefits/deliverables
      Add a new component in the swift-testing repository which receives events from the testing library and decides how to reflect them in console output.
      Modify supporting tools such as Swift Package Manager to allow enabling or configuring this functionality.
      Land the changes behind an experimental feature flag initially.
      Submit a proposal to the community and the Testing Workgroup to formally enable the feature.
      Summarize your effort with a demo of the new functionality including screenshots or recordings.
      Potential mentors
      Stuart Montgomery
      ~~~~~~~~~~
      Improved command line tool documentation
      Project size: 175 hours (medium)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Description
      Swift Argument Parser recently added a command plugin to generate documentation markup for a command line tool. This plugin could be improved by providing support for generating separate pages for each command and by leveraging additional markdown syntax to organize command line flags into sections and display possible values and default values.
      Beyond the markdown output, this plugin could be further improved by generating a “symbol graph” that describe each command and its flags, options, and subcommands. By describing the commands’ structure, tools like Swift DocC can further customize the display of command line tool documentation, support links to individual flags, and allow developers to extend or override the documentation for individual flags in ways that isn’t overwritten when regenerating the documentation markup from the plugin. If time allows, prototype some enhancement to command line documentation in Swift DocC that leverage the information from the command symbol graph file.
      Expected outcomes/benefits/deliverables
      A richer markdown output from the plugin.
      Support for generating separate pages for each command.
      Output a supplementary symbol graph file that describe the commands’ structure.
      Potential mentors
      David Rönnqvist

      ~~~~~~~~~~
      Documentation coverage
      Project size: 90 hours (small)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Description
      Enhance Swift DocC’s experimental documentation coverage feature to write coverage metrics in a new extensible format that other tools can read and display. Define a few types of metrics—for example Boolean (has documentation: true/false), Fraction (2/3 parameters are documented), Percentage, etc.—for this format. Explore ideas for what documentation coverage information would be useful to emit. Explore ideas for how another tool could display that coverage information.
      Expected outcomes/benefits/deliverables
      Land the documentation coverage output format changes for the experimental feature in DocC.
      Submit a pitch to the community and the Documentation Workgroup to formally enable the documentation coverage feature in DocC.
      Summarize your effort with a demo of the new metrics and examples of how another tool could display that information.
      Potential mentors
      David Rönnqvist
      ~~~~~~~~~~
      OpenAPI integration with DocC
      Project size: 350 hours (large)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Basic knowledge in HTTP APIs.
      Description
      OpenAPI is a standard for documenting HTTP services. It allows creating documents in YAML or JSON format that can be utilized by various tools to automate workflows, such as generating the required code for sending and receiving HTTP requests.
      OpenAPI is known for its tooling to generate documentation, but in the Swift ecosystem, developers are already familiar with how DocC renders documentation for Swift and Objective-C APIs. To enhance consistency and improve the developer experience, we aim to extend DocC’s support to OpenAPI documents.
      Expected outcomes/benefits/deliverables
      As part of the Google Summer of Code project, the student will develop a library/tool that can generate DocC documentation from an OpenAPI document.
      Strech goals:
      Integrate the tool into the Swift OpenAPI Generator.
      Create OpenAPI Doc to DocC Live Preview plugin for VS Code.
      Potential mentors
      Sofía Rodríguez
      Si Beaumont
      Honza Dvorsky
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/swift/
    idea_list_url: https://www.swift.org/gsoc2025/


  - organization_id: 147
    organization_name: SymPy
    no_of_ideas: 37
    ideas_content: |
      
      High Priority
      Polynomial GCD
      Idea
      Add new algorithms for computing the greatest common divisor (GCD) of polynomials in the sparse representation. This would improve the speed of many parts of sympy such as matrices, solvers, integration and so on.
      The issues and potential solutions along with many references are discussed in this issue: https://github.com/sympy/sympy/issues/23131
      Status
      There is plenty of work that can be done in this area so this is effectively an open-ended area for improvement in sympy.
      Involved Software
      Difficulty
      Medium to high difficulty
      Prerequisite Knowledge
      Python, some understanding of abstract algebra and of algorithms.
      Project Length
      175 or 350 hours, depending on the scope of the project.

      ~~~~~~~~~~
      Benchmarks and performance
      Idea
      Speed is important for SymPy. One issue is that it's difficult to tell what is too slow, and, more importantly, if a given change makes things faster or slower.
      SymPy needs more benchmarks. It also needs an automated system to run them. That way, when someone adds some code that slows things down in an unexpected way, we will know about it.
      There are already some benchmarks at https://github.com/sympy/sympy_benchmarks, and some others in the main SymPy repo. But not all benchmarks are in the sympy_benchmarks repo. Also, the repo uses asv, but the results are run and hosted ad hoc, as we don't have a dedicated machine to run the benchmarks.
      This project should do the following:
      Move benchmarks from the sympy repo to the sympy_benchmarks repo.
      Add new benchmarks as needed.
      Work with the community to set up a dedicated machine that can constantly run asv to warn about benchmarks. It would also be nice if this could be set up to warn for performance regressions on PRs.
      Make improvements to SymPy to improve performance issues found throughout the project.
      Improve the usability of the current GitHub Actions bot that adds benchmarks outputs to pull requests.
      Some prior art:
      ASV (what we are using now)
      PyPy benchmarks page
      See https://www.youtube.com/watch?v=d65dCD3VH9Q for some ideas/warnings about setting up benchmarking.
      See this issue for ways to run benchmarks on GitHub Actions https://github.com/sympy/sympy/issues/21374.
      Status
      We currently have a benchmarking suite and run the benchmarks on GitHub Actions, but this is limited and is often buggy.
      Involved Software
      Difficulty
      Medium to low difficulty
      Prerequisite Knowledge
      Python
      Project Length
      175 hours or 350 hours, depending on the scope of the project.

      ~~~~~~~~~~
      Assumptions
      Idea
      The project is to completely remove our old assumptions system, replacing it with the new one. The difference between the two systems is outlined in the first two sections of this blog post.
      This project is challenging. It requires deep understanding of the core of SymPy, basic logical inference, excellent code organization, and attention to performance. It is also very important and of high value to the SymPy community.
      Numerous related tasks are mentioned in the "Ideas" section.
      Status
      There has been a significant amount of merged and unmerged work on this topic. A list of detailed issues can be found at this issue. You should take a look at the work started at https://github.com/sympy/sympy/pull/2508.
      This mailing list post by Aaron Meurer outlines the status of the project and some ideas of what to do. It is from 2015 but most of what is written there is still true. The main thing that is new is that the new assumptions call the old assumptions (ask(Q.real(Symbol('x', real=True)))). See also the prior GSoC projects on assumptions, including this one, which was accepted, but there may be parts of it that were not completed, and https://github.com/sympy/sympy/wiki/GSoC-2013-Application-Tom-Bachmann:-Removing-the-old-assumptions-module, which was not accepted (the student chose to do another project), but contains some good ideas.
      Involved Software
      None
      Difficulty
      Advanced
      Prerequisite Knowledge
      Number theory, Boolean algebra, etc.
      Project Length
      350 hours

      ~~~~~~~~~~
      Mathematics Projects
      Solvers
      Idea
      SymPy already has a pretty powerful solve function. But it has a lot of major issues
      It doesn't have a consistent output for various types of solutions It needs to return a lot of types of solutions consistently:
      single solution : x == 1
      Multiple solutions: x**2 == 1
      No Solution: x**2 + 1 == 0; x is real
      Interval of solution: floor(x) == 0
      Infinitely many solutions: sin(x) == 0
      Multivariate functions with point solutions x**2 + y**2 == 0
      Multivariate functions with non point solution x**2 + y**2 == 1
      System of equations x + y == 1 and x - y == 0
      Relational x > 0
      And the most important case "We don't Know"
      The input API is also a mess, there are a lot of parameter. Many of them are not needed and they makes it hard for the user and the developers to work on solvers.
      There are cases like finding the maxima and minima of function using critical points where it is important to know if it has returned all the solutions. solve does not guarantee this.
      Salient Features of solveset
      solveset has a cleaner input and output interface: solveset returns a set object and a set object take care of all the types of the output. For cases where it doesn't "know" all the solutions a NotImplementedError is raised. For input only takes the equation and the variables for which the equations has to be solved.
      solveset can return infinitely many solutions. For example solving for sin(x) = 0 returns {2⋅n⋅π | n ∊ ℤ} ∪ {2⋅n⋅π + π | n ∊ ℤ} Whereas solve only returns [0, π]
      There is a clear code level and interface level separation between solvers for equations in complex domain and equations in real domain. For example solving exp(x) = 1 when x is complex returns the set of all solutions that is {2⋅n⋅ⅈ⋅π | n ∊ ℤ} . Whereas if x is a real symbol then only {0} is returned.
      solveset returns a solution only when it can guarantee that it is returning all the solutions.
      Status
      GSoC 2014 Project: Harsh Gupta During the summer of 2014 Harsh Gupta worked to improve solvers as part of his GSoC project. Instead of making changes in the current solve function a new submodule named solveset was written.
      GSoC 2015 Project: Amit Kumar In the summer of 2015 Amit Kumar worked on this project to improve solveset, implement complex sets as a part of his GSoC project.
      GSoC 2016 Project: Kshitij SaraogiKshitij Saraogi | GSoC 2016 Project: Shekhar Rajak In the summer of 2016, two projects were selected to participate in Google Summer of Code to work on the Solvers. New solver helper functions such as solve_decomposition and nonlinsolve were implemented to facilitate the porting from solve to solveset. Also, the inequality solver solve_univariate_inequality was refactored and added to solveset. Several methods related to functional analysis, such as periodicty, continuous_domain and function_range were implemented.
      GSoC 2018 Project: Yathartha Joshi In the summer of 2018, Yathartha worked on the project to implement transcendental equation solver for solveset. transolve alongwith its helper solvers was implemented as a result of it.
      TODOs
      Extending transolve: As part of the work done in the summer of 2018, transolve is fully designed and is now able to handle logarithmic and exponential equations for solveset. To make solveset fully fledged and replace solve completely we expect it to handle equations like:
      Lambert type equations (PR #14972)
      Handling modular equations (#13178)
      Solving transcendental equations in complex domain.
      There may be other types of equations that transolve can be made to handle. It's still under development!! Feel free to propose any of your ideas.
      Integrating helper solvers with solveset: Currently, solveset only solves a single equation for a single variable. In the future, we expect it to be capable of solving a system of equations and for more than one variable. linsolve: Solves a system of linear equations nonlinsolve: Solves a system of non-linear equations solve_decomposition: Solves a varied class of equations using the concept of Rewriting and Decomposition These are the helper functions that have been implemented in solveset during the past few years. We would like to have all these solvers(including transolve) to be integrating in solveset so as to increase its power.
      Build the set infrastructure: This includes implementing functions to handle multidimensional ImageSet etc., This part must go hand in hand with the improvements in the solvers as set module can be a universe in itself. Also there can be fundamental limits on the things you can do.
      nonlinsolve is not able to handle system having trigonometric/transcendental equations correctly all the time. Improve solveset's trigonometric solver and handle trig system of equations separately in nonlinsolve.
      References There had been a lot of discussion during and before the project and you should know why we did what we did. Here are some links:
      Discussion on the mailing list
      Action Plan on solvers
      Harsh Gupta's proposal for GSoC 2014
      Harsh's blog for GSoC
      solveset pull request
      Amit's blog for GSoC
      Solveset Documentation
      GSoC 2016 Solvers Progress and blog links
      Yathartha's blog for GSoC
      transolve pull request
      GSoC 2018 Solvers Progress
      Involved Software
      SymPy
      Difficulty
      This project is difficult because it requires a good deal of thought in the application period. You should have a clear plan of most of what you plan to do in your application: waiting until the Summer to do the designing will not work.
      #10006 and #8711 can be good entry points.
      Prerequisite Knowledge
      Algebraic and differential equations
      Potential mentor - Co-mentor: Shekhar (@Shekharrajak)
      Project Length
      350 hours.

      ~~~~~~~~~~
      Optimize floating point expressions
      Idea
      Optimize floating point expressions (à la https://herbie.uwplse.org/). The user will supply a SymPy expression and an optional range of "x" (and other variables) and the module would determine which symbolic simplifications make sense to make things more accurate and/or faster.
      Part of this project would also be to provide faster implementations of special functions, say if it is determined that "x" in sin(x) is in the range [0, 1e-3], then there are much faster polynomial approximations that give the same accuracy (the same is possible for other finite ranges, e.g., [1.5, 1.7]).
      One mode is to concentrate on accuracy (possibly with larger/slower expression). Another mode is to concentrate on speed, and this mode can have a user prescribed accuracy, say 1e-16 for machine precision, or 1e-3 for lower accuracy. For lower accuracies one can replace functions like sin(x) with a much faster polynomial approximation.
      Difficulty
      Intermediate, Advanced
      Project Length
      350 hours, although you may propose a 175 hour project with a more limited scope.
      
      ~~~~~~~~~~
      Group theory
      Idea
      Continue developing the group theory functionality of the combinatorics module. You should take a look at the GAP library, as this is the canonical group theory computation system right now.
      Algorithms to think about implementing:
      Computation of various subgroups of infinite finitely presented groups
      Computation of Galois groups for a given polynomial
      Finding kernels of homomorphisms with infinite domains
      Extend functionalities of polycyclic groups
      Quotient groups
      Automorphism groups
      Status
      Previous projects on the topic include:
      GSoC 2012 Aleksandar Makelov: Computational Group Theory
      GSoC 2016 Gaurav Dhingra: Computational Group Theory
      GSoC 2017 Valeriia Gladkova: Computational Group Theory
      GSoC 2018 Ravi Charan: Computational Group Theory
      GSoC 2019 Divyanshu Thakur: Computational Group Theory
      A good amount of work has been done on polycyclic groups, polycyclic presentation with the base class collector were introduced in 2019 GSoC project but still there are a lot of things to be added for e.g. polycyclic orbit stabilizer and canonical polycyclic sequence to check if two polycylic subgroups are equal or not could be implemented. In addition, few other algorithms like abelian invariants and composition series implemented in 2019 GSoC project can be extended for infinite groups.
      Some major algorithms for finitely presented groups include coset enumeration (there's been work on modified Todd-Coxeter in the 2018 GSoC project: see this PR), low index subgroup search and Reidemeister-Schreier algorithm for subgroup presentation. Rewriting systems together with the Knuth-Bendix completion algorithm are available but could be made more efficient.
      Additionally, the 2017 project implemented group homomorphisms and the 2018 project implemented the computation of the isomorphism between 2 groups, an automaton for word reduction and a few additional algorithms. Find the complete work done during 2018 in the project report in the link below.
      See the 2016, 2017 and 2019 reports for suggestions on where the work could continue.
      Quite a lot of work has been done on permutation groups, but still, some things remain (some of those mentioned in GSoC 2012 Report by Aleksandar Makelov are still relevant, e.g. subgroup intersection). Some work is already done on discrete groups. Nonetheless, there is still much that can be done both for discrete groups and for Lie groups.
      Difficulty: Medium/Difficult
      Resources: Handbook of Computational Group Theory by Derek F. Holt, Bettina Eick and Eamonn A. O'Brien
      Prerequisite Knowledge: Basic knowledge of Abstract Algebra
      Potential mentor - Co-mentor: Divyanshu Thakur (@divyanshu132)
      Project Length
      350 hours.
      
      ~~~~~~~~~~
      Risch algorithm for symbolic integration
      Idea
      The Risch algorithm is a complete algorithm to integrate any elementary function. Given an elementary function, it will either produce an antiderivative, or prove that none exists. The algorithm described in Bronstein's book deals with transcendental functions (functions that do not have algebraic functions, so log(x) is transcendental, but sqrt(x) and sqrt(log(x)) are not).
      Status
      The project is to continue where Aaron Meurer left off in his 2010 GSoC project, implementing the algorithm from Manuel Bronstein's book, Symbolic Integration I: Transcendental Functions. If you want to do this project, be sure to ask on the mailing list or our IRC channel to get the status of the current project.
      The algorithm has already been partially implemented, but there is plenty of work remaining to do. Contact Aaron Meurer for more information. There was also work done in 2013, which hasn't been completely merged yet. A good place to start would be to look at finishing this work: https://github.com/sympy/sympy/pulls/cheatiiit. See https://groups.google.com/forum/#!msg/sympy/bYHtVOmKEFs/UZoyDX81eP4J for some more details on this project (nothing has changed since that email thread).
      Involved Software
      Difficulty
      Prerequisite Knowledge
      You should have at least a semester's worth of knowledge in abstract algebra. Knowing more, especially about differential algebra, will be beneficial, as you will be starting from the middle of a project. Take a look at the first chapter of Bronstein's book (you should be able to read it for free via Google Books) and see how much of that you already know. If you are unsure, discuss this with Aaron Meurer (asmeurer).
      Project Length
      350 hours.
      
      ~~~~~~~~~~
      Rule-based symbolic integration
      Idea
      Symbolic integration can also be performed with a "rule-based" system, which pattern matches the integrand against a set of known integrals uses them to return a result. This is a different approach to the Risch algorithm discussed in the previous approach, and is generally seen as complementary to it. For instance, the Risch algorithm can handle very complex expressions but it can only work with elementary integrals. Rule-based systems are limited to expressions that can match the given set or rules, but it can work with a large set of special functions.
      Status
      The main work here is a software called RUBI, which is a rule-based integration system written in Wolfram Language. Several previous GSoC projects have worked on integrating RUBI in SymPy, but this work has not yet been successfully completed.
      See
      GSoC-2017-Report-Abdullah-Javed-Nesar:-Rule-based-Integrator
      GSoC 2018 Rubi Final Report
      Improving-Rule-Based-Integrator
      Tracking issue #12233
      The RUBI code that has been written is now at https://github.com/sympy/rubi. The primary issue with it is that RUBI is very large and the Python translation is too slow to be useful.
      RUBI also involves using MatchPy (see Enhancing the flexibility of MatchPy), which enables the sort of Mathematica-style pattern matching needed for integration.
      Because previous projects have failed to integrate the entirety of RUBI due to its size, a project working on RUBI should focus on integrating parts of it at a time.
      SymPy also has a separate module called manualintegrate which implements a pattern-based integration system. It only has a limited of patterns right now, but could be extended. A potential project could just be to extend manualintegrate and not involve RUBI.
      Involved Software
      MatchPy
      RUBI
      Difficulty
      Intermediate to difficult
      Prerequisite Knowledge
      If working on RUBI knowledge of Mathematica code will be useful, but not required. Prior knowledge of special functions will be useful, but can also quite easily be learned.
      Project Length
      For anything involving RUBI, this should be 350 hours.
      Smaller 175 or even 90 hour projects to just improve manualintegrate are possible. Discuss with us.
      
      ~~~~~~~~~~
      ODE ideas
      You also might want to look at Manuel Bronstein's sumit.
      "Solving Differential Equations in Terms of Bessel Functions" by Ruben Debeerst. (basic idea is already implemented.)
      Webpage: http://rubendebeerst.de/master/
      Master Thesis: http://rubendebeerst.de/master/master.pdf
      Corresponding ISSAC 08 paper: http://rubendebeerst.de/master/paper_issac2008.pdf
      Lie groups and symmetry related:
      "Integrating factors for second order ODEs" by E.S. Cheb-Terrab and A.D. Roche
      "Abel ODEs: Equivalence and Integrable Classes" by E.S. Cheb-Terrab and A.D. Roche Note: Original version (12 pages): July 1999. Revised version (31 pages): January 2000
      Status
      Involved Software
      Difficulty
      Medium
      Prerequisite Knowledge
      Differential equations
      Project Length
      175 hours or 350 hours, depending on the project details (discuss with us).
      
      ~~~~~~~~~~
      Improving Series Expansions & Limit Computations
      Idea
      This includes numerous smaller subprojects and is more of a bug burn down project than implementing things from scratch. Hence we should aim at solving as many bugs and possible issues having the label series or limits on them. There are around 146 open issues with the series label & around 26 open issues with the limits label with some overlap and the proposal should have a comprehensive list of ideas to fix a significant portion of these issues.
      improve series expansions
      relevant issues
      improve limit computations
      relevant issues
      improve formal power series
      asymptotic series (for instance aseries for gamma, bessel, error type functions)
      issue 1, issue 2, issue 3, issue 4
      Better support for Order term arithmetic (for example, expression of the order term of the series around a point that is not 0, like O((x - a)**3)).
      issue 1
      Read through discussion & comments for fixing issue
      Fix _eval_subs method to hanlde issue 1, issue 2, issue 3, issue 4
      Fix limit computations for piecewise functions
      revamp work on PR and test properly, relevant issue
      All other problems, which are described in wiki page about series and current situation
      Status
      There is already a fast implementation called rs_series in SymPy. This project would extend it to work for all functions and then make it the default series expansion in SymPy.
      SymPy now has support for Formal Power Series (series.formal). The algorithm is more or less complete. The module should be made faster. There are also a lot of XFAIL tests that can be made to pass.
      A new algorithm for computing limits of sequences has also been added (series.limitseq). There are still XFAIL tests that can be made to pass.
      Some references
      "Formal Power Series" by Dominik Gruntz and Wolfram Koepf
      "A New Algorithm Computing for Asymptotic Series" by Dominik Gruntz
      "Computing limits of Sequences" by Manuel Kauers
      "Symbolic Asymptotics: Functions of Two Variables, Implicit Functions" by Bruno Savly and John Shackell
      "Symbolic Asymptotics: Multiseries of Inverse Functions" by Bruno Savly and John Shackell
      Involved Software
      SymPy
      Difficulty
      Medium
      Prerequisite Knowledge
      Calculus
      Project Length
      175 hours or 350 hours, depending on the project details (discuss with us).
      
      ~~~~~~~~~~
      Cylindrical algebraic decomposition
      Idea
      Implement the Cylindrical algebraic decomposition algorithm
      Use CAD to do quantifier elimination
      Provide an interface for solving systems of polynomial inequalities
      Some references:
      Cylindrical Algebraic Decomposition http://mathworld.wolfram.com/CylindricalAlgebraicDecomposition.html
      "Algorithms in Real Algebraic Geometry" http://perso.univ-rennes1.fr/marie-francoise.roy/bpr-ed2-posted1.html (useful background resource, but contains much more information)
      "Cylindrical Algebraic Decomposition I: The Basic Algorithm" by Dennis S. Arnon, George E. Collins, Scot McCallum
      "Computing Cylindrical Algebraic Decomposition via Triangular Decomposition" by Marc Moreno Maza, Changbo Chen, Bican Xia, Lu Yang
      "Simple CAD Construction and its Applications" by Christopher W. Brown
      "Improved Projection for Cylindrical Algebraic Decomposition" by Christopher W. Brown
      "Symbolic Computation for Inequalities" by Manuel Kauers http://www.sfb013.uni-linz.ac.at/uploads/media/SymCompIneq.pdf
      "How To Use Cylindrical Algebraic Decomposition" by Manuel Kauers
      Status
      Involved Software
      Difficulty
      Prerequisite Knowledge
      Project Length
      350 hours
      
      ~~~~~~~~~~
      Efficient Groebner bases and their applications
      Idea
      Groebner bases computation is one of the most important tools in computer algebra, which can be used for computing multivariate polynomial LCM and GCD, solving systems of polynomial equations, symbolic integration, simplification of rational expressions, etc. Currently there is an efficient version of Buchberger algorithm implemented and of the F5B algorithm, along with naive multivariate polynomial arithmetic in monomial form. There is also the FGLM algorithm converting reduced Groebner bases of zero-dimensional ideals from one ordering to another.
      Improve efficiency of Groebner basis algorithm by using better selection strategy (e.g. sugar method) and implement Faugere F4 algorithm and analyze which approach is better in what contexts. Implement the generic Groebner walk converting between Groebner basis of finite-dimensional ideals; there are efficient algorithms for it, by Tran (2000) and Fukuda et al. (2005).
      Apply Groebner bases in integration of rational and transcendental functions and simplification of rational expressions modulo a polynomial ideal (e.g. trigonometric functions).
      Status
      There was a project last year relating to Groebner bases. Please take a look a the source and discuss things with us to see what remains to be done.
      Some Groebner bases algorithms, in particular F4, require strong linear algebra. Thus, if you want to do that, you may have to first improve our matrices (see the ideas relating to this above).
      Involved Software
      Difficulty
      Prerequisite Knowledge
      Project Length
      350 hours
      
      ~~~~~~~~~~
      Multivariate polynomials and factorization
      Idea
      Factorization of multivariate polynomials is an important tool in algebra systems, very useful by its own, also used in symbolic integration algorithms, simplification of expressions, partial fractions, etc. Currently multivariate factorization algorithm is based on Kronecker's method, which is impractical for real life problems. Undergo there is implementation of Wang's algorithm, the most widely used method for the task.
      Start with implementing efficient multivariate polynomial arithmetic and GCD algorithm. You do this by improving existing code, which is based on recursive dense representation or implement new methods based on your research in the field. There are many interesting methods, like Yan's geobuckets or heap based algorithms (Monagan & Pearce). Having this, implement efficient GCD algorithm over integers, which is not a heuristic, e.g. Zippel's SPMOD, Musser's EZ-GCD, Wang's EEZ-GCD. Help with implementing Wang's EEZ factorization algorithm or implement your favorite method, e.g. Gao's partial differential equations approach. You can go further and extend all this to polynomials with coefficients in algebraic domains or implement efficient multivariate factorization over finite fields.
      Status
      Some work on this may already be done. Take a look at sympy/polys/factortools.py in the SymPy source code.
      Involved Software
      Difficulty
      Advanced
      Prerequisite Knowledge
      Project Length
      350 hours
      
      ~~~~~~~~~~
      Univariate polynomials over algebraic domains
      Idea
      Choose a univariate polynomial representation in which elements of algebraic domains will be efficiently encoded. By algebraic domains we mean algebraic numbers and algebraic function fields. Having a good representation, implement efficient arithmetic and GCD algorithm. You should refer to work due to Monagan, Pearce, van Hoeij et. al. Having this, implement your favorite algorithm for factorization over discussed domains. This will require algorithms for computing minimal polynomials (this can be done by using LLL or Groebner bases). You can also go ahead and do all this in multivariate case.
      Status
      Currently SymPy features efficient univariate polynomial arithmetic, GCD and factorization over modular rings and integers (rationals). This is, however, insufficient in solving real life problems, and has limited use for symbolic integration and simplification algorithms. For example, the support for finite fields GF(p^n) is missing.
      Involved Software
      Difficulty
      Advanced
      Prerequisite Knowledge
      Project Length
      350 hours
      
      ~~~~~~~~~~
      Concrete module: Implement Karr algorithm, a decision procedure for symbolic summation
      Idea
      Algorithm due to Karr is the most powerful tool in the field of symbolic summation, which you will implement in SymPy. There are strong similarities between this method and Risch algorithm for the integration problem. You will start with implementing the indefinite case and later can extend it to support definite summation (see work due to Schneider and Kauers). Possibly you will also need to work on solving difference equations.
      Some references:
      "A=B" by Marko Petkovsek, Herbert S. Wilf, Doron Zeilberger
      "Symbolic Summation with Radical Expressions" by Manuel Kauers and Carsten Schneider
      "An Implementation of Karr's Summation Algorithm in Mathematica" by Carsten Schneider
      Manuel Kauers, webpage: http://www.risc.jku.at/home/mkauers
      Carsten Schneider, webpage: http://www.risc.jku.at/people/cschneid
      "Algorithmen für mehrfache Summen", by Torsten Sprenger
      Status
      SymPy currently features Gosper algorithm and some heuristics for computing sums of expressions. Special preference is for summations of hypergeometric type. It would be very convenient to support more classes of expressions, like (generalized) harmonic numbers etc. There is already an complete algorithm rational expression summation.
      Involved Software
      Difficulty
      Advanced
      Prerequisite Knowledge
      Project Length
      350 hours

      ~~~~~~~~~~
      Physics Projects
      Symbolic Control Systems (sympy.physics.control)
      Idea
      A Control Systems subpackage (sympy.physics.control) was added to SymPy in the summer of 2020, by Naman Gera. This was built upon further by Akshansh Bhatt in 2021 and Anurag Bhat in 2023. It would be great to continue its development and make it more accessible to the public. Since the users are mostly students and researchers in the field of Control theory, a set of problems from a textbook can be solved in the documentation, as the development proceeds.
      https://www.cds.caltech.edu/~murray/amwiki/Second_Edition.html can be used as a reference.
      Status
      The functionalities of the project can be viewed here:
      https://docs.sympy.org/latest/modules/physics/control/lti.html#module-sympy.physics.control.lti
      Future Work (can be modified after discussion):
      Refactor the old plots - All the plots that were implemented previously namely - Pole Zero, Step Response, Impulse Response, Ramp Response, Bode Magnitude and Bode Phase plot use numpy and matplotlib. The numerical methods were used for speed but they sacrifice on precision. Sympy's symbolic methods are used in the first place to the precision they provide, hence these numerical methods should be replaced by algebraic methods.
      Davide, a fellow contributor has been revamping the plotting module. I would like to point out this roadmap, according to which SymPy will soon have it's own plot_list function after which this refactoring could be done with ease.
      Complete newly implemented plots - The plots added in this GSoC project namely - Root Locus, Nichols and Nyquist plot are draft pull requests. The have clear ideas to follow and some comments which can be addressed once SymPy no longer depends upon matplotlib and numpy.
      Implementations for the StateSpace class -
      Solve examples mentioned in #25502 and add them to the control_problems file . The required functionality is already supported in the pull request.
      Add a symbolic solver (and a numeric solver if required) with the help of the ODE module to solve x' = Ax + Bu form.
      Make the class more feature rich:
      Read about Laub's or Horner's method to evaluate system transfer function at complex frequency. This will be the equivalent of eval_frequency for Transfer Functions.
      Add Feedback interconnection between 2 state space LTI systems.
      Other features can be picked up on comparison with MATLAB and python-control.
      Adding a Discrete time model - A Discrete-time TransferFunction and Discrete-time StateSpace model. Discussing the API and making things compatible with the current implementation is a challenging task. It has already been a component of the MATLAB CST package from the beginning. As a control module, we have to realize that all signals in practical real life use are always discrete in nature. This is my motivation for wanting this model, so that users can have extensive use of SymPy’s CST package in their projects.
      It is best to follow the final report and blog to know more about the status.
      Involved Software
      Python, Git
      Difficulty
      Intermediate
      Prerequisite Knowledge
      Undergraduate level Control Systems knowledge will suffice. Otherwise, one can complete the project if they self-learn required topics and then contribute voraciously.
      Project Length
      350 hours.

      ~~~~~~~~~~
      Symbolic quantum mechanics (sympy.physics.quantum)
      
      In the past, Brian Granger was the maintainer of the sympy.physics.quantum subpackage. He has stepped down from this position. Until someone takes over the maintenance of this subpackage, we will not be able to mentor any GSoC projects in this area. If you have questions about this, please contact Ondřej Čertík.
      
      ~~~~~~~~~~
      Continuum Mechanics: Create a Rich 2D Beam Solving System
      Idea
      Singularity functions are a popular tool for solving beam bending stress and deflection problems in mechanical design. This is traditionally done by hand calculations and can be very tedious and error prone. This process could be improved greatly by a CAS implementation of the functions and some high level abstractions for constructing beam loading profiles.
      The deliverable would be a unit tested and documented sub-package for SymPy 2D and 3D beams that can solve many beam problems, add in arbitrary cross sections, plotting, be robust, and add any other relevant features.
      Status
      Sampad Saha implemented Singularity Functions in 2016. The 2017 and 2018 GSoC projects created the functionality shown here:
      https://docs.sympy.org/dev/modules/physics/continuum_mechanics/beam_problems.html
      The next steps involve making it easier to define complex cross sectional geometry via the geometry package, developing the 3D Beam into a well tested and robust class, and polishing to the plotting for 2D and 3D beams. Adding a large set of example problems that exercise the functionally.
      Involved Software
      Python, Git
      Difficulty
      Intermediate
      Prerequisite Knowledge
      No specific prerequisite knowledge is necessary but it would help if the student had some knowledge of beam stress/strain analysis methods.
      Project Length
      350 hours.

      ~~~~~~~~~~
      Classical Mechanics
      The following project ideas are in approximate order of priority.
      Classical Mechanics: Generalize the Equations of Motion System Output
      Idea
      We would like an ecosystem in which you can define/create your mechanical system in a general way using joints, bodies, forces, torques, etc., compute the equations of motion based on different methods like LagrangesMethod and KanesMethod, to be used in numerical purposes, like simulations and optimizations.
      The above is the general picture for which a lot of work has been done over the years on the different parts. However, some parts are disjoint while other parts are still missing or should almost be entirely replaced.
      Note that defining/creating the mechanical system falls into two other projects, namely:
      Classical Mechanics: Constructing Systems From Bodies and Joints
      Classical Mechanics: Implement Specific Forces and Torques
      Classical Mechanics: Implement and Benchmark Equations of Motion Methods
      Status
      Previous work covers quite a few different parts, which can be improved and extended, but mostly require to be tied together more properly:
      An abstract base class as an interface to the different equations of motion generation methods has been introduced in #21778.
      Refer to the project Classical Mechanics: Constructing Systems From Bodies and Joints for the status of bodies and joints.
      Refer to the project Classical Mechanics: Implement Specific Forces and Torques for the status of implementing specific loads.
      In #25560 a System class was introduced as a general frontend to define a mechanical system and generate the equations of motion using either of the implemented methods, i.e. LagrangesMethod and KanesMethod.
      In #11431 as SymbolicSystem was introduced as a data class to store all information about a system and its equations of motion in a general format.
      In PyDy there also exists a System class, which can be used to simulate a system that was solved using KanesMethod.
      The goal of this project is to implement a class to function as a general interface of a system from which the equations of motion can be used for numerical purposes. This class would be an extension or replacement of sympy.physics.mechanics.system.SymbolicSystem. Some of the features it should offer are:
      A general representation of the equations of motion and the algebraic constraints.
      Methods to code generate the functions to be used in simulation purposes, like with scipy.integrate.solve_ivp and scikits.odes.dae.
      It should use sympy.physics.mechanics.system.System for the basic system information. It could possibly have multiple methods to be instantiated, like a normal __init__ where all equations and things need to be provided as is currently the case with SymbolicSystem, and a classmethod from_system, where it extracts most information from the System instance.
      Involved Software
      Python, Git
      Difficulty
      Advanced
      Prerequisite Knowledge
      This project requires basic understanding of dynamical systems and at least understanding of one method of generating the equations of motion for a multi-body system.
      Project Length
      350 hours.
      ~~~~~~~~~~
      Classical Mechanics: Implement and Benchmark Equations of Motion Methods
      Idea
      There are many methods to derive the equations of motion. Each method has its advantageous and disadvantageous when modeling different systems. SymPy currently contains only two methods: KanesMethod and LagrangesMethod. The idea of this project is to develop more methods to form the equations of motion and to benchmark them for different models to also give users more insight what model they should use for their application.
      Status
      An abstract base class as an interface to the different equations of motion generation methods has been introduced in #21778.
      This project could roughly entail the following steps:
      Improve the abstract base class, sympy.physics.mechanics.method._Methods of the equations of motion generation methods, e.g. KanesMethod.
      Improve the implementation of KanesMethod and LagrangesMethod.
      Implementing more methods to generate the equations of motion, like NetwonEulersMethod or HamiltonsMethod.
      Develop a benchmark suite deriving the equations of motion using the different methods and measure their performance. Examples could include a 5-DoF planar kinematic chain, a four-bar linkage, and the Carvallo-Whipple bicycle model.
      Involved Software
      Python, Git
      Difficulty
      Intermediate
      Prerequisite Knowledge
      This project requires basic understanding of dynamical systems and at least understanding of one method of generating the equations of motion for a multi-body system.
      Project Length
      175 or 350 hours.

      ~~~~~~~~~~
      Classical Mechanics: Efficient Equations of Motion Generation
      Idea
      Currently we have basic equation of motion generation with automated Kane's and Lagrange's methods. These methods work well but can take many minutes to complete for hard problems. The algorithms that derive these equations of motion can be improved in both speed of computation and the resulting simplification of the equations of motion. This project would involve profiling to find the slow functions and speeding up the slow parts. This may involve digging into the SymPy codebase for trigonometric simplification and other relevant function calls to speed up the EoM generation. These modification will help speed up both the entire SymPy codebase and the Mechanics package.
      Status
      There is no previous work on this topic.
      Involved Software
      Python, Git
      Difficulty
      Beginner
      Prerequisite Knowledge
      There are no prequisites to this project.
      Project Length
      175 or 350 hours.

      ~~~~~~~~~~
      Classical Mechanics: Implement Wrapping Geometry and Pathways for Musculoskeletal Modeling
      Idea
      SymPy Mechanics includes classes to manage how forces and torques act on connected bodies when the path of action is a complex pathway that wraps over geometric features. This is critical for accurate musculotendon force generation. The Biomechanical Model Example shows a simple cylindrical wrapping of a muscle around the elbow. This idea involves adding more wrapping surfaces and pathways that are useful for musculoskeletal modeling.
      Status
      Cylinder and sphere wrapping geometry exist
      Linear and obstacle pathway exist
      Involved Software
      Python, Git
      Difficulty
      Beginner to intermediate
      Prerequisite Knowledge
      This project requires basic understanding geometry, forces, and anatomy.
      Project Length
      90, 175, or 350 hours (depends on how many features you'd like to implement)

      ~~~~~~~~~~
      Classical Mechanics: Implement Specific Forces and Torques
      Idea
      Many forces and torques still have to be manually created by the user. It would be helpful if we had a set of typical and common forces and torques. Some possible examples:
      Actuator forces and torques
      Aerodynamic forces
      Contact force models
      Friction force models
      Linear and nonlinear springs and dampers
      Musculotendon models, like the Hill type muscle model
      Controller forces (like PID or full state feedback)
      Eardrum model
      Some kind of force and torque objects will likely be needed as well as symbolic mathematical descriptions of the force and torque models. The forces and torques should work with SymPy's code generation to generate efficient and robust numerical codes. Here is a soft introduction to forces and torques.
      Status
      Timo Stienstra introduced a Force and Torque class, refer to #24258 and #24641.
      Sam Brockie implemented an abstract base class to define actuators and implemented several types of actuators, like a LinearSpring and LinearDamper, refer to #25518.
      Sam Brockie implemented base classes for Musculotendon force generators, refer to the musculotendon API
      Hwayeon Kang implemented CoulombKineticFriction and DuffingSpring classes, refer to #26438 and #26412.
      Initial idea for the Hill muscle model is introduced in #26443 -- it will be helpful to refer to the DeGroote2016 classes in sympy.physics.biomechanics.activation together.
      Some load types that could be worked on are:
      Contact force models
      Aerodynamic forces
      Nonlinear springs and dampers
      Models involving biomechanics, refer to #24240 for ideas.
      Involved Software
      Python, Git
      Difficulty
      Beginner to intermediate
      Prerequisite Knowledge
      This project requires basic understanding of dynamics and numerical methods.
      Project Length
      90, 175, or 350 hours (depends on how many features you'd like to implement)

      ~~~~~~~~~~
      Classical Mechanics: Constructing Systems From Bodies and Joints
      Idea
      We'd like to be able to construct multibody systems by specifying descriptions of rigid bodies and the joints and constraints that connect them.
      Status
      Sahil Shekewat worked on implementing a joint-based descriptor for systems: https://github.com/sympy/sympy/pulls/sahilshekhawat
      Sudeep Sidhu completed Sahil's work and merged a functioning joint-based system that can solve open-chain problems. See his report: https://github.com/sympy/sympy/wiki/GSoC-2021-Report-Sudeep-Sidhu-:-Implement-JointsMethod
      Timo Steinstra furthered the work by enhancing the joint definition, adding new joints, and developing examples of using the joints framework.
      The next steps are, in order of priority:
      Fix any existing bugs with the joints.
      Add many different example problems to test the robustness of the implementation.
      Allow parsing constants as generalized coordinates to Joint, such as pi / 2 to the PinJoint, as if it is just a fixed pin.
      Implement and test quaternion rotations.
      Implement a Mobilizer joint or CustomJoint for describing complex motions, refer to (#23920 comment).
      Implement an option to choose the generalized speeds efficiently, refer to #24053 comment.
      Involved Software
      Python, Git
      Difficulty
      Intermediate to Advanced
      Prerequisite Knowledge
      This project requires familiarity with multibody dynamics. At the least, one should know how to form the equations of motion of complex systems with one method.
      Project Length
      90, 175, or 350 hours

      ~~~~~~~~~~
      Classical Mechanics: Implement an O(N) Equations of Motion Method
      Idea
      Roy Featherstone, Abhi Jain, and others developed recursive methods of forming the right-hand side of the differential equations for complex multibody systems that have an evaluation time of O(N) instead of O(N^3). This project would be dedicated to implementing a symbolic O(N) method to complement the LagrangesMethod and KanesMethod classes. This project would involve implementing 6D vectors and spatial operators, as well as the recursive methods. This would give a significant speed boost in numerical evaluation for systems with bodies greater than 20 or so.
      Status
      Brandom Milam made significant headway in this project in 2016. See:
      https://github.com/sympy/sympy/wiki/GSoC-2016-Application-James-Brandon-Milam:-Base-Class-and-Increased-Efficiency-for-Equation-of-Motion-Generators
      https://github.com/sympy/sympy/pulls/jbm950
      Involved Software
      Python, Git
      Difficulty
      Extremely Advanced
      Prerequisite Knowledge
      This project requires proficiency with multibody dynamics. At the least, one should know how to form the equations of motion of complex systems with one method. The ideal candidate will have experience forming the equations of motion with the aforementioned Featherstone or Jain methods.
      Project Length
      350 hours.

      ~~~~~~~~~~


      Computer Science, Graphics, and Infrastructure Projects
      Official LLM Tool Agent for SymPy
      Idea
      This project proposes developing an official LLM tool agent for SymPy. Large Language Models (LLMs) are increasingly used to interact with interfaces through function calling. While SymPy's extensive library interface offers powerful symbolic computation capabilities, it's not readily accessible to LLMs. This agent will bridge this gap by providing a structured interface that allows LLMs to discover and execute SymPy functions based on natural language user requests. This involves creating a machine-readable description of SymPy's public interface (function and class definitions, docstrings, usage examples) that LLMs can understand and use to construct valid function calls. The agent will be designed to be framework-agnostic, supporting popular LLM frameworks like LangChain, LlamaIndex, Haystack, and ell-ai. This project aims to:
      Create templates for LLM tools wrapping SymPy’s library interface.
      Implement integrations with multiple LLM frameworks (LangChain, llama-index, ...), demonstrating usability.
      Design a testing interface that evaluates and reports statistical metrics to assess the correctness of results.
      Develop an interface to facilitate debugging of LLM agent traces.
      Examples of Multi-Step SymPy Operations:
      A key motivation for this project is the ability to handle mathematical problems requiring multiple SymPy function calls. Here are some examples:
      Finding the minimum of a function subject to a constraint: This typically involves:
      Defining the function and the constraint using SymPy symbols.
      Calculating the derivative of the function using diff().
      Solving the system of equations formed by setting the derivative to zero and applying the constraint using solve().
      Potentially evaluating the second derivative using diff() again to confirm that the solution is a minimum (second derivative test).
      For example: "Find the minimum of x^2 + y^2 subject to x + y = 1."
      Solving a differential equation and then evaluating it at a point: This requires:
      Defining the differential equation using Eq() and Function().
      Solving the differential equation using dsolve().
      Substituting a specific value for the independent variable into the solution using subs().
      For example: "Solve dy/dx = y with y(0) = 1 and evaluate the solution at x = 2."
      Calculating the area under a curve and then finding the centroid of that area: This involves:
      Defining the function using SymPy symbols.
      Integrating the function using integrate().
      Calculating the moments of the area using integrate() again (with appropriate weighting functions).
      Calculating the centroid coordinates by dividing the moments by the area.
      For example: "Find the area under the curve y = x^3 from x = 0 to x = 2 and then find the x-coordinate of the centroid of that area."
      These examples demonstrate the need for an LLM agent that can orchestrate multiple function calls within SymPy to solve more complex mathematical problems. The agent needs to understand the dependencies between different operations and handle intermediate results effectively. This capability is beyond the scope of simple one-to-one function call mappings and requires the more sophisticated approach proposed in this project.
      Status
      Currently, there is no official, structured approach for LLMs to interact with SymPy. While users can attempt to use LLMs to generate SymPy code, this approach is unreliable and prone to errors due to the LLM's limitation for code generation.
      Involved Software
      Libraries for LLM interaction/frameworks (LangChain, LlamaIndex, Haystack, LLM-AI)
      An LLM available. If no APIs
      Difficulty
      Intermediate to Advanced. This project requires:
      Familiarity with SymPy’s library interface and codebase.
      Understanding of LLM concepts and function calling.
      Prerequisite Knowledge
      Python programming.
      LLM agents and tool calling.
      Self-host an LLM with tool support.
      Project Length
      This project is suitable for both 175-hour and 350-hour GSoC projects.

      ~~~~~~~~~~
      Enhancing the flexibility of MatchPy
      Idea
      MatchPy, a Python library, provides associative-commutative pattern matching and replacement rules for expression trees. This functionality enhances the usability of computer algebra systems, simplifying the formulation of transformation rules for mathematical formulas.
      In essence, MatchPy expressions can be likened to "regular expressions with an awareness of commutative and associative properties”. MatchPy also supports the simultaneous execution of multiple matches, contributing to its exceptional efficiency.
      However, the current requirement for expression trees and wildcards to be subclasses of MatchPy objects presents a significant inflexibility. This constraint forces SymPy to delve into metaclass intricacies to function, limiting the ability to work with expression trees whose node type lacks identification by an object.
      This proposal seeks to enhance MatchPy by restructuring its node type identification, the iteration criteria and wildcard definitions. This involves replacing type checks with custom node identification and iteration rules, fostering greater flexibility in working with various expression tree structures.
      Since MatchPy is currently under a separate project and has experienced a period of inactivity, forking MatchPy becomes necessary for the progress of this project.
      Additionally, if time allows it, this project also envisions exploring the possibility of a Rust implementation of MatchPy, aiming to enhance its speed and efficiency.
      Status
      An experimental connector to MatchPy has been successfully implemented and can be found in sympy.utilities.matchpy_connector. For a comprehensive understanding of the algorithm that drives MatchPy, refer to the paper authored by its creators, available at https://arxiv.org/abs/1710.06915. Furthermore, it's worth noting that MatchPyCpp, an integral submodule of SymEngine, features a translation of the main MatchPy algorithms into C++. However, its performance is presently constrained by the absence of support for coroutines.
      Involved software
      Python, MatchPy
      Difficulty
      Advanced.
      This project very likely requires the MatchPy library to be forked.
      This project necessitates proficiency in executing tree-visiting algorithms.
      Project Length
      350 hours.

      ~~~~~~~~~~
      Code Generation
      Idea
      There are quite a few potential projects for codegen.
      The code generation system in SymPy has been overhauled to use AST nodes from sympy.codegen.ast, there are however lot of more nodes that can be added for e.g. Fortran in sympy.codegen.fnodes. It could also be useful if the code printers could output parallel code using OpenMP directives (e.g. parallel for loops for C and Fortran, including use of reduction). Most printers do not yet support the new AST nodes, it would be useful if those were extended so that they can express ASTs created e.g. by functions in sympy.codegen.algorithms.
      Another idea for codegen is to add more support for directly working with matrices. For instance, matrix expressions (sympy.matrices.expressions objects) should print LAPACK calls.
      Status
      We have support for a number of backends and basic code gen classes in place. There is work on updating the system ongoing. Please ask on the mailing list.
      You can check out the work done by Ankit Pandey to extend codegen to support matrix operations at Extending Codegen GSoC 2019
      Involved Software
      Fortran, C, C++, Julia, Rust, Python, LLVM, Javascript, Octave, Matlab, etc.
      Difficulty
      Intermediate to Advanced
      Prerequisite Knowledge
      Project Length
      175 hours or 350 hours, depending on the project details (discuss with us).
      ~~~~~~~~~~
      Code Generation: Efficient Jacobian and Hessian Evaluation for Optimization and ODE Integration
      Idea
      When solving optimization problems with gradient based solutions, you typically need to evaluate the function to optimize along with its Jacobian and/or Hessian (or the Lagrangian of the Hessian). SciPy offers many optimization routines, many which accept three functions for evaluating the function, the Jacobian, and the Hessian. If you create a function in SymPy, then having the ability to do something like:
      rosenbrock_expr = (a - x)**2 + b*(y - x**2)**2
      eval_f, eval_j, eval_h = generate_minimize_derivative_funcs(expr, (x, y), extra_args=(a, b))
      result = minimize(eval_f, x0, jac=eval_j, hess=eval_h)
      would make it very easy to solve optimization problems from functions defined in SymPy. If the expression is very large, the computational cost of evaluating those three functions needs to be minimized. With careful use of lambdify, autorwrap, and shared common sub expressions, SymPy can generate very efficient versions of these functions.
      Similarly, when numerically integrating ordinary differential equations, the Jacobian of the integrand (and its sparsity information) can be useful for the integration algorithms.
      rhs = [
          v(t),
          (-sign(v(t))*B*v(t)**2 - k*x(t) - c*v(t) + A*sin(w*t))/m
      ]
      eval_f, eval_j, sparsity = generate_ode_derivative_funcs(rhs, (x(t), v(t)), extra_args=(A, B, m, c, k))
      result = solve_ivp(eval_f, (0.0, 1.0), y0, jac=eval_j, jac_sparsity=sparsity)
      Once again, for very large expressions, generating computationally efficient code becomes very important for fast integration performance.
      Status
      There are existing tools where these basic ideas have been implemented outside of SymPy. For example:
      pyodesys: integrates ODEs defined with SymPy
      symopt: optimizes functions defined with SymPy
      opty: generates a numerical function and its sparse jacobian
      simple stackoverflow question
      optimization problem that doesn't quite connect sympy to scipy
      symjit has a simple API for generated numerical functions on-the-fly.
      Riccardo added a new Jacobian function in 2024 that efficiently computes Jacobians of very large expressions in #26773. We should be able to use this, at least optionally, for computing derivatives.
      See the SciPy documentation:
      SciPy Optimization
      solve_ivp
      Involved Software
      None
      Difficulty
      Intermediate to Advanced
      Prerequisite Knowledge
      Knowledge of optimization and ODE integration and their associated numerical methods.
      Project Length
      175 or 350

      ~~~~~~~~~~
      Parsing
      Idea
      SymPy has the ability to generate Python, C, and Fortran code from SymPy expressions.
      It would be very interesting to go the other way, to be able to parse Python, C, and Fortran code and produce SymPy expressions. This would allow SymPy to easily read in, alter, and write out computational code. This project would enable many other projects in the future. Ideally, this project would create a general framework for parsers and then use this system to implement parsers for a few of the languages listed above. See the other parsing ideas on this page, as well as Parsing.
      Status
      SymPy currently has a parsing module that supports parsing LaTeX and autolev using ANTLR, C, and Fortran. The parsing module also supports a Python parser, with special extensions to support things like implicit multiplication (2a -> 2*a) and implicit function application (sin x -> sin(x)), which uses the Python tokenize module.
      You can check out the work done on the C and Fortran parsers at Creating a C and Fortran Parser GSoC 2019
      The existing parsers could be improved by adding support for more features of the programming languages, or new parsers could be added for other languages like Julia, Octave, MATLAB, etc.
      Involved Software
      Fortran, C, C++, Julia, Rust, Python, LLVM, Octave, Matlab, etc.
      Difficulty
      Intermediate to Advanced
      Prerequisite Knowledge
      Project Length
      175 hours or 350 hours, depending on the project details (discuss with us).

      ~~~~~~~~~~
      Improve the plotting module
      Idea
      A new plotting module sympy-plot-backends has been written, which is planned to replace the existing sympy.plot module (see https://github.com/sympy/sympy/issues/23036).
      The idea is to merge this module into SymPy, also implementing substantial improvements and possibly new functionalities.
      A very approximate guesstimate is given.
      medium/hard: Refactoring of *Series classes in order to reduce code repetition and allow the implementation of new features.
      easy/medium: Improve numerical evaluation.
      medium/hard: implement custom theming for interactive applications and fix a behaviour affecting the current interactive module.
      easy/medium: Implement new functionalities:
      2D and 3D linear operators (the effect of a matrix on a plane/3D space)
      Phase portrait for Ordinary Differential Equations.
      Improve plot_parametric_region to better visualize complex maps.
      Animations.
      easy/medium: Packaging: while the main plotting functionalities work just with sympy, numpy and matplotlib, the full plotting module relies on several other packages. It has been observed that building a conda package with the full dependencies is difficult: most of the time the build succeed but the installation fails. Debug and fix it.
      easy/medium: Implement a intelligent routine that automatically determines the regions of interest for plotting.
      Fix related things/bugs in SymPy
      More detailed information can be found on this page.
      Status
      Currently, the new plotting module lives on an external repository: sympy-plot-backends
      Involved Software
      Python, HTML, Javascript, CSS
      Difficulty
      Intermediate to Advanced: working with several different packages can be overwhelming.
      Prerequisite Knowledge
      Project Length
      350 hours.

      ~~~~~~~~~~
      Documentation tooling
      Idea
      SymPy's documentation makes use of Sphinx and several Sphinx extensions. The idea here is to improve the tooling around the docs by developing some Sphinx extensions. Some ideas here
      Write a Sphinx extension that improves the way autodoc cross references work (see https://github.com/sympy/sympy/issues/23081)
      Add autosummary to our docs so that each function is on a separate page. This may require writing a Sphinx extension or some other tooling. See https://github.com/sympy/sympy/pull/22589 for why default autosummary does not work.
      Implement linters for various parts of markup so that people can avoid common mistakes. Mistakes include:
      Using the wrong type of markup for math, code, and cross-references (see also https://github.com/sympy/sympy/issues/13519)
      Common mistakes in LaTeX
      m
      a
      t
      h
      (see for instance https://github.com/sympy/sympy/issues/17803)
      Various things outlined in the documentation style guide
      Improved tooling to make sure every docstring is included in Sphinx and every docstring has a doctest (see the bin/coverage_doctest script in the SymPy repo, which needs improvement)
      Some way to make it so that headers in docstrings can be easily linked to and cross-referenced https://github.com/sympy/sympy/issues/17599
      Allow subheaders in docstrings https://github.com/sympy/sympy/issues/17618
      Several other small issues, mostly relating to the way autodoc generates documentation. See these issues for some additional ideas https://github.com/sympy/sympy/labels/GSoD.
      NOTE: Google requires that any GSoC project be primarily coding. This project is not primarily about writing documentation, as such a project is not allowed. It is instead about developing tooling to improve the SymPy documentation system.
      Status
      Some things are already implemented, for instance, we have an extension that lets us use dollar signs for math in RST https://github.com/sympy/sphinx-math-dollar. See the above issues for the status of any specific item.
      Involved Software
      This would primarily involve working with Sphinx and building Sphinx extensions or modifying existing ones. If relevant, we may prefer to upstream changes to Sphinx itself (although the Sphinx developers will not be mentors on this project, so we should not rely on this happening).
      Difficulty
      Intermediate to advanced (working with Sphinx can often be difficult)
      Prerequisite Knowledge
      Prior experience with RST and using autodoc is recommended.
      Project Length
      A project to implement all or the majority of the above ideas would require a 350 hours project, but a 175 hours or even 90 hours project can also be done that only implements a subset of the above ideas.
      
      ~~~~~~~~~~
      
      Hypothesis testing
      Idea
      Hypothesis is a Python library for property-based testing. Hypothesis tests work by specifying properties that a function should satisfy, and automatically generating inputs to test it. There are more details of the idea of adding hypothesis to SymPy in this issue.
      The idea is to explore adding hypothesis testing to SymPy. We should start small, ideally with a function that is already well tested and has relatively easy to generate inputs. From there we can expand the testing.
      Some work has begun on this but hypothesis is currently only used in a couple of tests (search the sympy codebase for "hypothesis" to see where it is currently used). However, we would like for much larger fractions of the tests to use hypothesis.
      Work on this project will involve adding tests to more functions, adding more hypothesis strategies for different kinds of inputs, and reporting and potentially fixing any SymPy bugs that you find along the way.
      It's expected that throughout this process you will find many bugs in SymPy. You may end up spending a lot of time in this project debugging failures, fixing bugs, or working around bugs that are not so easily fixed.
      Status
      SymPy has some basic hypothesis tests, which demonstrate a proof-of-concept of using it. However, the usage could be expanded significantly, as only a handful of functions currently have hypothesis tests.
      Involved Software
      The hypothesis testing library.
      Difficulty
      Intermediate to Advanced.
      Hypothesis testing is simple in principle, but using it in practice can be difficult because it will uncover many bugs in SymPy. It will also not be straightforward to use hypothesis to test symbolic expressions (there are some ideas on how to do this outlined in the issue).
      Prerequisite Knowledge
      Prior experience with using hypothesis would be a huge plus, but it is not a hard requirement. If you have not used hypothesis before it is recommended that you play around with it and perhaps try adding some simple tests for something (in SymPy or somewhere else) to get familiar with it.
      Project Length
      350 hours (175 hours is possible, but the longer is preferred since there will be many things to do for this project).
      
  
      ~~~~~~~~~~
      SymPy -> Fortran Code Generation and JIT
      Idea
      Code generation from SymPy -> ASR, and then have two options: ASR -> AST -> source code, or ASR -> LLVM -> JIT and load it from Python to test it out.
      Down the road the LLVM route might even be producing better (faster) code than using SymEngine->LLVM, because one can do optimizations on the ASR itself and before it is lowered to LLVM (as part of LFortran down the road), especially if one starts using do loops and arrays, because one knows more semantic information at the Fortran level than the LLVM level. And one can at least see the high level Fortran code (for debugging), as opposed to the relatively low level LLVM IR.
      Currently SymPy represents Fortran code as a SymPy AST which is a combination of sympy.codegen.ast and sympy.codegen.fnodes. The sympy.printing.fcode module then has a visitor pattern that transforms this ast/fnodes AST into Fortran source code.
      As a first step, one would change fcode() to transform this SymPy AST to LFortran's ASR. That will greatly simplify the printing, as LFortran will take care of transforming ASR -> AST (adding variable definitions mostly) and AST->source code. So SymPy code will get simplified. But also this will enable to then use LFortran to just in time compile this ASR and execute it from Python, thus allowing to interactively test the generated code.
      One would port all the features from fcode() into LFortran, where it makes sense. SymPy should only do things which are SymPy specific.
      After this is done, one can implement more features. For example it could be useful if the code printers could output parallel code using OpenMP directives (e.g. parallel for loops for C and Fortran, including use of reduction). Most printers do not yet support the new AST nodes, it would be useful if those were extended so that they can express ASTs created e.g. by functions in sympy.codegen.algorithms.
      Another idea for codegen is to add more support for directly working with matrices. For instance, matrix expressions (sympy.matrices.expressions objects) should print LAPACK calls.
      Project Length
      350 hours.
      
      ~~~~~~~~~~
      Parsing Fortran code to SymPy
      Idea
      LFortran can parse Fortran source code to AST and then convert AST to ASR. This ASR will then get inspected and Fortran expressions identified and converted to SymPy expressions. This would allow SymPy to easily read in, alter, and write out computational Fortran code. This project would enable many other projects in the future.
      This would be a general framework, some applications of this (some of which can be part of this project):
      load the right hand side expressions and generate manufactured solution
      check that a special function (e.g., spherical harmonics) Fortran implementation has the right expressions in it
      Part of this project can also be to implement a capability in LFortran to track the values of variables ("x") that go into an expression when you actually run the code on production data.
      A separate project idea is to:
      optimize floating point expressions (à la https://herbie.uwplse.org/)
      Based on the range of "x" (and other variables), determine which symbolic simplifications make sense to make things more accurate --- and to provide faster implementations of special functions, say if it is determined that "x" in sin(x) is in the range [0, 1e-3], then there are much faster polynomial approximations that give the same accuracy (the same might be possible if the range is say [1.5, 1.7], or any other finite range).
      See https://github.com/sympy/sympy/wiki/GSoC-Ideas#optimize-floating-point-expressions for the expansion of this idea, as this capability is independent of LFortran.
      Project Length
      350 hours.



     
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/sympy/
    idea_list_url: https://github.com/sympy/sympy/wiki/GSoC-Ideas

  - organization_id: 148
    organization_name: Synfig
    no_of_ideas: 4
    ideas_content: |
    
      macOS app bundle (175 or 350 hrs)
      Description:
      We are currently using a script to create a macOS app bundle, but it has some issues (This script can be found at: https://github.com/synfig/synfig/blob/master/3-package-osx-dmg.sh). Generation takes a long time (could be greatly improved), it uses incorrect paths in some places and does not sign files.
      Requirements: macOS or access to macOS command-line (so you can test your script)
      add script/program to collect executable/library dependencies (python/c++ preferred) to SynfigStudio.app folder
      add support for signing binary files (this should be done in reverse order, files without dependencies should be signed first, SynfigStudio.app should be signed last)
      remove the macOS launcher script, add the code to set up the required macOS environment from the synfig/synfigstudio apps
      add cpack support to build installer on macOS
      add python and lxml packaging to .app (with signing))
      interface/menu improvements for more native macOS support
      Where to begin:
      create prototype script/program to collect executable/library dependencies
      Expected outcome:
      175 hours
      CMake/CPack builds SynfigStudio.app ready for distribution
      350 hours
      Synfig Studio is better adopted to macOS guidelines
      Difficulty: Medium
      Skills required/preferred: Python/C++
      Possible mentor(s): Dhairya Bahl, Rodolfo Ribeiro Gomes
      Expected size of project: 175 or 350 hours

      ~~~~~~~~~~

      Synfig Android Version (350hrs)
      Description: This project aims at providing a solid ground for a Synfig Android version. It aims to do so through two main parts.
      1- Prototype UI (Using Qt for android) that uses synfigapp and -in turn- synfig-core
      There are two main goals here: 1. To have a basic android UI for synfig working. 2. While making this prototype certain parts of the synfig api would be fixed. Which would make SynfigApp and Synfig-Core able to be used with any other UI not just the current gtkmm UI (synfig-studio).
      2- Add more features to the UI Synfig is quite a huge application. Most likely this app would start with only very basic needed synfig features added. Then gradually adding more features from synfig-studio to the new prototype UI.
      Where to begin:
      Start out by understanding and gathering the basic features for animation in synfig. In your proposal include these features and expand on how you plan to include them.
      Research the available mobile/tablet animation apps and prototype a ui design using any ui design software (e.g. canva). This is not required but it will definetly help your proposal.
      Expected outcome
      Prototype Synfig Android Version
      Improved synfig-app and (possibly) synfig-core that can work with any other UI.
      Difficulty: Medium/High
      Skills required/preferred: C++, gtkmm, Qt, using Qt for Android
      Possible mentor(s): Mohamed Adham , Rodolfo Ribeiro Gomes
      Expected size of project: 350 hours

      ~~~~~~~~~~
      Brush tool (175hrs)
      Description:
      Synfig is primarily designed for vector-based animation, but it also supports the use of raster images within animations. However, the current functionality only allows for the use of raster images imported from external files (usually BMP, JPG or PNG), limiting users from drawing directly within the application. The goal of this project is to implement the missing Brush tool for raster drawing, allowing users to draw raster content directly in the app. An early attempt to implement this feature, called 'Brush,' exists, but it is entirely nonfunctional. Users are unable to make even a single stroke with the tool.
      Where to begin:
      Look for the code of how tools are implemented in Synfig. As they are coded as a finite state machine, the correspondent files are name as state_
      2. synfigapp is responsible for handling the interface between the graphical user interface (GUI) and the underlying core engine of Synfig (which handles the animation and rendering processes). There are some synfigapp::Actions trying to implement it, as in synfig-studio/src/synfigapp/actions/layerpaint.h
      Expected outcome
      A working tool that allows users to freely hand-draw their artwork, which can then be animated within Synfig, with undo/redo functionality while drawing and features like brush selection, coloring options, and erasing.
      Difficulty: Medium/High
      Skills required/preferred: C++, gtkmm, 2D-drawing
      Possible mentor(s): Rodolfo Ribeiro Gomes , Mohamed Adham
      Expected size of project: 175 hours

      ~~~~~~~~~~
      Exporter to Spine file format (175hrs)
      Description:
      The goal of this project is to implement a feature in Synfig Studio that enables exporting skeleton-based animations to the Spine file format. This would allow users to seamlessly transfer their Synfig animations, those created using bone-based rigs and skeleton systems, to Spine for additional refinement or game engine integration. This would involve creating an export function in Synfig that outputs the necessary JSON or binary format that Spine can read. The project will ensure that all essential animation data, such as bone movements, and keyframe timing, are accurately preserved during the export. Thus, users can leverage Synfig's powerful animation tools while taking advantage of Spine's advanced features, such as runtime support in various game engines.
      Where to begin:
      Check Synfig skeleton layer code
      Check Spine JSON format (https://en.esotericsoftware.com/spine-json-format)
      Try to add new menu option "Export to Spine format" to Skeleton layer, which should create basic Spine JSON file.
      Expected outcome * A fully functional export tool in Synfig Studio capable of converting skeleton-based animations into the Spine file format. * The exported Spine file should retain all key elements of the animation, including bones, mesh deformation, and animation keyframes. * The ability to open and refine the exported Spine animation in Spine's editor or integrate it directly into a game engine.
      Difficulty: Medium
      Skills required/preferred: Python (or C++), XML and JSON, understanding of Synfig's animation system, especially skeleton-based animation and bone rigs, and Synfig file format.
      Possible mentor(s): Rodolfo Ribeiro Gomes , Mohamed Adham
      Expected size of project: 175 hours
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/synfig/
    idea_list_url: https://github.com/synfig/synfig-docs-dev/blob/master/docs/gsoc/2025/ideas.rst

  - organization_id: 149
    organization_name: TARDIS RT Collaboration
    no_of_ideas: 8
    ideas_content: |
      
   
      Rewrite the TARDIS visualisation module using Panel
      Panel
      Visualisation
      Project Length: 350 Hours
      Difficulty: Hard
      Mentors: Abhinav Ohri, Andrew Fullard, Atharva Arya, James Gillanders
      Description: TARDIS has a collection of visualisation tools and widgets to interactively explore TARDIS simulations which run inside Jupyter Notebooks. A lot of these modules currently depend on dependencies like IPython and Qgrid which do not work well with our Sphinx documentation. We want to migrate our tools to depend entirely on Panel instead of these tools and want to showcase their interactivity on our documentation.
      Visualisation Module- https://tardis-sn.github.io/tardis/pull/2872/io/visualization/index.html#tardis-widgets-graphical-user-interfaces
      First Objective: Use Panel to show any hierarchical dataset as 2 interlinked tables, where selecting a row in the first table updates the 2nd table with the data corresponding to the selected row. Bonus points for using TARDIS’ SimulationShellInfo to make the 1st table display shell data and the 2nd table display element abundances.
      Expected Outcomes:
      All visualisation modules moved to Panel.
      Dependencies like qgrid/qgridnext removed.
      Visualisation tools and widgets can be embedded on the website allowing users to interact with them.
      Comprehensive documentation and tests for all code written.

      ~~~~~~~~~~

      Line Identification Plotting Functionality
      Visualisation
      Plotly
      Matplotlib
      Project Length: 350 hours
      Difficulty: Medium
      Mentors: Abhinav Ohri, Andrew Fullard, James Gillanders
      Description: TARDIS and STARDIS produce spectra that contain information about the elements and molecules that are part of the simulation. Both software record information about which elements produce which parts of the output spectrum. For TARDIS and STARDIS, you will access the information about where lines originate and plot the frequencies or wavelengths of the originating elements or molecules as requested by the user. This functionality will be incorporated into any of the existing spectral visualizations in TARDIS and STARDIS, so it must be modular.
      First Objective: Produce a table of energy packets that can be filtered by the originating element. Provide a Jupyter notebook showing a plot of the table with labels and style that matches other TARDIS visualizations.
      Expected Outcomes:
      Visualisation Module that builds the plot using existing dependencies.
      Comprehensive documentation and tests for all code written.
      
      ~~~~~~~~~~
      Regression Data Dashboard
      Data Visualisation
      Dashboards
      Python
      Git
      HDF
      Project Length: 350 Hours
      Difficulty: Hard
      Mentors: Abhinav Ohri, Andrew Fullard, Atharva Arya
      Description: TARDIS implements a regression testing framework that compares current output to an already saved version to validate code. The goal of this project is to develop a dashboard to see exactly where the values of the files changed. Other than this, this project will also improve TARDIS HDF writing capabilities and add functionality to restore simulations from HDF and to create simulation checkpoints which work with the regression data.
      TARDIS Regression Data: https://github.com/tardis-sn/tardis-regression-data
      First objective:
      Run the comparison notebook for the past 10 TARDIS commits and share a graph of how any file changed over the course of these commits. Hint: Each TARDIS commit will generate its own regression data that you need to compare to the data the previous commit produced.
      Expected Outcomes:
      Dashboard preferably using existing TARDIS dependencies(see Conda environment)
      Visualisation that allows seeing how regression data files changed over a large commit range. Commits which produce large changes are recorded permanently.
      Flexible code that works with changes in the TARDIS environment.
      Comprehensive documentation and tests for all code written.
      
      ~~~~~~~~~~
      Adding HDF Writing Capabilities to TARDIS Modules
      Data Storage
      HDF5
      Python
      Project Length: 350 Hours
      Mentors: Andrew Fullard, Atharva Arya, Abhinav Ohri
      Difficulty: Hard
      Description: This project will improve TARDIS HDF writing capabilities and add functionality to restore simulations from HDF and to create simulation checkpoints which work with the regression data.
      TARDIS Regression Data: https://github.com/tardis-sn/tardis-regression-data
      First objective: Add a method to the spectrum class that allows restoring the class from an HDF. Share the notebook in a pull request.
      Expected Outcomes:
      Modular code that allows recreating TARDIS modules from HDF files exactly the way they were before.
      Comprehensive documentation and tests for all code written.
      
      
      ~~~~~~~~~~
      Benchmark Optimization
      Performance
      Benchmarking
      Python
      Airspeed Velocity
      Project Length: 350 Hours
      Mentors: Andrew Fullard, Atharva Arya, Abhinav Ohri
      Difficulty: Hard
      Description: TARDIS commits are monitored by a benchmarking framework to detect performance regressions. But the current framework only tests 5 commits at a time and not with much detail. The goal of this project is to improve the benchmarking framework by adding more benchmarks. This project will also add more benchmarks to STARDIS, a related code. The second stage of the project will use the benchmarks to investigate possible performance improvements to TARDIS and STARDIS.
      TARDIS Benchmarks: https://tardis-sn.github.io/tardis-benchmarks/
      STARDIS Benchmarks: https://tardis-sn.github.io/stardis-benchmarks/
      First objective: Benchmark the Plasma solver factory and share the ASV results for the last 5 commits along with the code in a pull request.
      Expected Outcomes:
      Exhaustive benchmarks that time important TARDIS modules like plasma, transport, visualisation to name a few.
      Larger history of benchmarks(currently only 5) and regenerating benchmarks for failed commits to avoid losing benchmark history.
      Comprehensive documentation and tests for all code written.
      
      ~~~~~~~~~~
      Metadata for atomic data
      Data Management
      Atomic Data
      Pandas
      Project Length: 350 Hours
      Mentors: Andreas Flörs, Andrew Fullard
      Difficulty: Easy
      Description: Carsus provides atomic data to astrophysicists. It would be useful to provide additional data, “metadata”, along with the atomic data, so that users know the source and details of how the data were processed. For this project, you will add metadata to the Carsus atomic data output. This metadata will include physical units, git commit hashes, article citations, and more. You will also work on TARDIS to enable reading of this metadata.
      Carsus- https://tardis-sn.github.io/carsus/
      First objective: add a metadata table to an existing Carsus output, with a DOI link to a journal article of your choice, some physical units (e.g. Hertz, meters, erg). The output could be the Carsus HDF file, or a Pandas DataFrame. Some form of automation is a bonus.
      Expected Outcomes:
      Metadata for all Carsus outputs.
      Comprehensive documentation and tests for all code written.
      
      ~~~~~~~~~~
      Continuum opacity source reader
      Data Processing
      Scientific Data
      Project Length: 350 Hours
      Mentors: Andrew Fullard, Josh Shields
      Difficulty: Hard
      Description: There’s a lot of literature with useful tables for the TARDIS codebase and other scientific codes in pdfs ( example ), or often in dataproducts. Carsus currently reads in data from standard sources and archives( Chianti , CMFGEN ), but does not flexibly read data from sources in the literature. The goal of this project is to expand Carsus to read datatables like ones in this work, with potential expansion for a future-proof workflow (new opacity tables). These could all go in a new tardis repository called “carsus-literature-tables” or something along those lines. You can look at this for a preprocessed datatables ready to be ingested by Carsus might look.
      Carsus- https://tardis-sn.github.io/carsus/
      First objective: Read one of the datatables from the linked paper here (try s92.201.gz, under ftp) and process it into a pandas dataframe. Look to do this in a programmatic way that could be reused for similar files, like the other tables found here. See section 6.4 for more details on table contents and formatting if desired.
      Expected Outcomes:
      Code that reads in the new dataproducts and integrates with Carsus.
      Comprehensive documentation and tests for all code written.
      
      ~~~~~~~~~~
      CARSUS Dashboard
      GitHub Actions
      Python Scripting
      Pandas
      Notebooks
      Project Length: 350 Hours
      Mentors: Josh Shields
      Difficulty: Hard
      Description: Carsus is a package to manage atomic datasets. It can read data from a variety of sources and output them to file formats readable by radiative transfer codes like TARDIS. The goal of this project is to build python APIs and Jupyter Notebook scripts to investigate different atomic datasets from various sources. The scripts help researchers analyze key components of atomic data files, including metadata, lines/levels structure and element composition, while enabling web access to examine and compare different atomic datasets.
      Regression Data Repository: https://github.com/tardis-sn/tardis-regression-data
      Carsus: https://github.com/tardis-sn/carsus
      First objective: Use Jinja2 to generate an HTML Report that investigates an atomic file. Display top 50 rows of levels and lines dataframes from the atomic file for Silicon. Here are a few example notebooks-
      Quickstart Notebook
      Compare atomic files . You can find atomic files in the TARDIS regression data repository
      Expected Outcomes:
      Python APIs and notebooks that investigate custom atomic data files from external parameters and can be triggered using GitHub Actions.
      Modular code that is compatible with both legacy atom data files and is future-proof.
      Comprehensive documentation and tests for all code written.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/tardis-rt-collaboration/
    idea_list_url: https://tardis-sn.github.io/summer_of_code/ideas/


  - organization_id: 150
    organization_name: The Apache Software Foundation
    no_of_ideas: 38
    ideas_content: |
      
      
      Airavata
      Streamline Grouping and Filtering in the Experiment Browser UI
      Embed a researcher-focused dashboard to group and preview experiments in the Django portal. The goal is to improve how past experiment runs can be tracked, grouped, and arranged for faster lookup and insights.
      Proposed Improvements:
      Group submitted experiments by project, application, allocation, etc.
      Clean, customizable dashboard elements (e.g., charts) to preview past experiments.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Yasith Jayawardana, mail: yasithmilinda (at) apache.org
      Project Devs, mail: dev (at) airavata.apache.org

      ~~~~~~~~~~

      Update Airavata Django Portal to a Supported Python Version
      The Airavata Django Portal currently runs on Python 3.6, which reached its end-of-life (EOL) in 2022. Continuing to use an unsupported Python version poses security risks and limits access to new features and package updates. Upgrading to a supported version (Python 3.12 or later) will ensure long-term maintainability, security, and compatibility with modern dependencies.
      Status of Python versions
      Impact:
      • Improved security and stability
      • Access to the latest language features and performance improvements
      • Compatibility with actively maintained third-party packages
      Proposed Solution: Update the codebase and dependencies for compatibility with Python 3.12+, and ensure everything works as expected post-upgrade.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Yasith Jayawardana, mail: yasithmilinda (at) apache.org
      Project Devs, mail: dev (at) airavata.apache.org

      ~~~~~~~~~~

      Migrate Apache Airavata Deployment from Ansible to OpenTofu
      Objective
      Replace existing Ansible deployment scripts with OpenTofu configurations to improve deployment efficiency and maintainability for bare-metal environments.
      Requirements
      Assessment of Current Ansible Scripts
      Review Existing Playbooks: Analyze the current Ansible playbooks located in the Airavata GitHub repository to understand the deployment processes and dependencies.
      Identify Core Components: Determine the essential services and configurations managed by Ansible, such as Kafka, RabbitMQ, Zookeeper, MariaDB, etc.
      Development of OpenTofu Configurations
      Define Infrastructure as Code (IaC): Utilize OpenTofu's declarative language to codify the infrastructure components identified in the assessment phase.
      Module Creation: Develop reusable modules for each service (e.g., Kafka, RabbitMQ, Zookeeper) to promote consistency and ease of management.
      Testing and Validation
      Simulate Deployments: Use OpenTofu's planning capabilities to simulate deployments, ensuring configurations align with the desired infrastructure state.
      Iterative Refinement: Address any discrepancies or issues identified during testing to refine the OpenTofu configurations.
      Documentation
      Update Deployment Guides: Revise existing documentation to reflect the new OpenTofu-based deployment process, providing clear instructions for users.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Lahiru Jayathilake, mail: lahirujayathilake (at) apache.org
      Project Devs, mail: dev (at) airavata.apache.org

      ~~~~~~~~~~
      Develop an Integrated Feature Test Environment for Apache Airavata
      Objective
      Enhance the current development workflow by incorporating a simulated High-Performance Computing (HPC) environment into Apache Airavata's existing Integrated Development Environment (IDE) integration. This will enable developers to test and validate features locally without relying on physical HPC resources.
      Requirements
      Simulated HPC Environment Integration
      Dockerized Slurm Simulation: Develop a Docker container that emulates an HPC environment using Slurm, facilitating the testing of job scheduling and execution.
      Seamless IDE Integration: Ensure that this simulated environment integrates smoothly with the existing IDE setup, allowing developers to initiate and monitor jobs as they would in a real HPC setting.
      Development of Comprehensive Test Scenarios
      Job Submission Tests: Create scripts to test various job submission scenarios, including successful executions, intentional failures, and long-running processes.
      Feature Validation: Ensure that all features exposed by Apache Airavata can be tested within this simulated environment.
      User-Friendly Setup
      Simplified Configuration: Design the setup process to require minimal configuration, enabling developers to initiate the environment and execute tests with just a few commands
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Lahiru Jayathilake, mail: lahirujayathilake (at) apache.org
      Project Devs, mail: dev (at) airavata.apache.org
      ~~~~~~~~~~
      A Central Admin Dashboard to Inspect Health + Logs of Airavata Services
      Develop a devops dashboard to monitor Apache Airavata services, enabling real-time tracking of service health, uptime, and logs independent of the science gateway(s).
      This centralized tool will help administrators efficiently monitor service performance and troubleshoot issues. The dashboard will feature a user-friendly monitoring UI that displays real-time status updates and logs for each service.
      Proposed Solution:
      A logging subproces alongside each service, pushing logs to an external service.
      A devops dashboard that aggregates the logs and provides a unified view into the system.
      API calls from devops dashboard to each service, for proactive health-checking.
      Ability to monitor multiple gateways from the same dashboard.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Yasith Jayawardana, mail: yasithmilinda (at) apache.org
      Project Devs, mail: dev (at) airavata.apache.org

      ~~~~~~~~~~
      Containerized Deployment of Airavata Services
      Currently, all Airavata services are packaged and deployed as Java bundles. The goal is to containerize each service by wrapping it within a Dockerfile, allowing seamless deployment on container-enabled resources while also enabling local execution for development purposes.
      This enhancement has potential to improve deployment consistency, simplify dependency management, and provide greater flexibility in running Airavata services across different environments, for both testing and production use cases.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Yasith Jayawardana, mail: yasithmilinda (at) apache.org
      Project Devs, mail: dev (at) airavata.apache.org

      ~~~~~~~~~~
      Apache Dubbo
      GSoC 2025 - Service Discovery
      Background and Goal
      Service Discovery
      Well organized logs
      Actuator endpoints
      Tools
      Relevant Skills
      Familiar with Java
      Familiar with Microservice architecture
      Potential Mentors
      Jun Liu, Apache Dubbo PMC Chair, junliu@apache.org
      dev@dubbo.apache.org
       
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Jun Liu, mail: liujun (at) apache.org
      Project Devs, mail:
      ~~~~~~~~~~
      GSoC 2025 - Add more traffic management rule support for Dubbo Proxyless Mesh
      Background and Goal
      The concept of[ Proxyless Mesh|https://istio.io/v1.15/blog/2021/proxyless-grpc/] was first introduced in this blog. Please read it to learn more concept details.
      We have started the development of Dubbo Proxyss Mesh for a while, so that means you don't have to start the project from scratch, anyone who gets involved can start with a specific task at hand. 
      In this specific GSoC project, we need developers to mainly focus on implementing more traffic management features of Istio for Dubbo.
      Relevant Skills
      Familiar with Java
      Familiar with Service Mesh, istio and Microservice architectures
      Familiar with Kubernetes
      Potential Mentors
      Jun Liu, Apache Dubbo PMC Chair, junliu@apache.org
      
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Jun Liu, mail: liujun (at) apache.org
      Project Devs, mail:
      ~~~~~~~~~~
      GSoC 2025 - Dubbo Admin traffic management feature
      Background and Goal
      Dubbo is an easy-to-use, high-performance microservice framework that provides both RPC and rich enterprise-level traffic management features.
      The community has been working on the improvement of Dubbo's traffic management abilities, to make it support rich features like traffic spliting, canary release, a/b testing, circuit breaker, mocking, etc. The complete traffic management architecture in Dubbo consists of two major parts, Control Plane and Data Plane. In Dubbo, Control Plane refers to Dubbo Admin, with source code in apache/dubbo-kubernetes. Dubbo Data Plane is implemented by Dubbo sdk (Java, Go, etc)
      The traffic management rules Dubbo ueses now is compatible with the rules in Istio. That means the rules generated by Dubbo Admin and sent to SDK is Istio compatible rules. In this project, we need developers to work mainly on Dubbo Admin to make sure it generates and sends those rules correctly.
      
      Relevant Skills
      Familiar with Golang
      Familiar with Service Mesh, istio and Microservice architectures
      Familiar with Kubernetes
      Potential Mentors
      Jun Liu, Apache Dubbo PMC Chair, junliu@apache.org
      dev@dubbo.apache.org
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Jun Liu, mail: liujun (at) apache.org
      Project Devs, mail:
      ~~~~~~~~~~
      GSoC 2025 - Enhancing Dubbo Python Serialization
      Background and Goal
      Currently, Dubbo Python exposes a serialization function interface that requires users to implement their own serialization methods. For commonly used serialization formats such as JSON and Protobuf, users must manually configure them each time. To streamline this process, we aim to build a built-in serialization layer that provides support for these common serialization formats by default.
      Goal
      We recommend using Pydantic to achieve this. Therefore, we expect the implementation to:
      1. an internal serialization layer based on Pydantic, with support for at least JSON and Protobuf.
      2. Leverage Pydantic's additional features, including data validation and other useful functionalities.
      Relevant Skills
      1. Familiar with Python
      2. Familiar with RPC
      Potential Mentors
      Albumen Kevin, Apache Dubbo PMC, albumenj@apache.org
      dev@dubbo.apache.org
        
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Albumen Kevin, mail: albumenj (at) apache.org
      Project Devs, mail:

      ~~~~~~~~~~
      GSoC 2025 - Dubbo triple protocol for go language implementation
      Background and Goal
      Dubbo is an easy-to-use, high-performance microservice framework that provides both RPC and rich enterprise-level traffic management features.
      keep-alive
      connection management
      programming api
      error code
      Relevant Skills
      Familiar with Golang
      Familiar with RPC
      Familiar HTTP/1/2/3 protocol
      Potential Mentors
      Jun Liu, Apache Dubbo PMC Chair, junliu@apache.org
      dev@dubbo.apache.org
        Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Jun Liu, mail: liujun (at) apache.org
      Project Devs, mail:

      ~~~~~~~~~~
      GSoC 2025 - Dubbo Gradle IDL Plugin
      Background and Goal
      In the API-First design paradigm, IDL (Interface Definition Language) and its corresponding generation tools have become essential. IDL files are the specifications for defining service interfaces, and generation tools can convert IDL files into executable code, thereby simplifying the development process and improving efficiency.
      Currently, Apache Dubbo only provides a Maven IDL generation plugin, lacking a Gradle plugin. This brings inconvenience to developers using Gradle to build projects.
      Necessity
      Unify Build Tools: Gradle is the preferred build tool for Android projects and many Java projects. Providing a Dubbo Gradle IDL plugin can maintain the consistency of build tools and reduce the cost for developers to switch between different build tools.
      Simplify Configuration: Gradle plugins can simplify the configuration and generation process of IDL files. Developers only need to add plugin dependencies and simple configurations in the `build.gradle` file to complete the generation of IDL files without manually executing complex commands.
      Integrate Development Process: Gradle plugins can be better integrated with IDEs (Integrated Development Environments). Developers can directly execute Gradle tasks in the IDE, thereby realizing the automatic generation of IDL files and improving development efficiency.
      Implementation Plan
      Plugin Development: Develop a Gradle plugin that encapsulates the Dubbo IDL generation tool and provides a concise configuration interface.
      Configuration: In the `build.gradle` file, developers can configure parameters such as the path of the IDL file and the directory of the generated code.
      Task: The plugin provides a Gradle task for executing the generation of IDL files. Developers can execute the task through the command line or the IDE.
      Dependency Management: The plugin can automatically manage the dependencies of the Dubbo IDL generation tool, ensuring that developers do not need to manually download and configure it.
      Expected Results
      Developers can use Gradle to build Dubbo projects and easily generate the code corresponding to the IDL.
      Simplify the configuration and generation process of IDL files, and improve development efficiency.
      Better integration with IDEs to achieve automatic generation of IDL files.
      Potential Mentors
      Albumen Kevin, Apache Dubbo PMC, albumenj@apache.org
      dev@dubbo.apache.org
        
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Albumen Kevin, mail: albumenj (at) apache.org
      Project Devs, mail:

      ~~~~~~~~~~
      DolphinScheduler
      Enhancing Apache DolphinScheduler with Generalized OIDC Authentication
      Background
      Apache DolphinScheduler is a distributed and extensible workflow scheduler platform designed to orchestrate complex data processing tasks. It provides a user-friendly interface for defining, scheduling, and monitoring workflows, making it easier to manage and automate data pipelines. DolphinScheduler supports various types of tasks, including shell scripts, SQL queries, and custom scripts, and integrates seamlessly with popular big data ecosystems.
      Currently, the Apache DolphinScheduler system supports user login via Password, LDAP, Casdoor SSO, and OAuth. However, as a data platform, it frequently needs to integrate with enterprise - internal user accounts to achieve unified identity authentication, which is crucial for ensuring system security and unified user account management. The existing implementation of Casdoor has a high degree of dependence on the Casdoor project, and the OAuth implementation lacks universality and flexibility.
      Our objective is to implement a more generalized OIDC (OpenID Connect) login authentication mechanism. This will enable users to make better use of unified login authentication. Moreover, popular open source login authentication projects like Dexidp, Keycloak, and OAuthProxy all support OIDC. By supporting OIDC, users can integrate with both internal and third-party login authentication methods, such as Feishu Login and WeChat Work Login.
      Relevant Skills
      Strong proficiency in Java development.
      Experience in modern frontend technologies and frameworks.
      Highlevel expertise in Spring Boot development.
      Thorough familiarity with OIDC and OAuth2 protocols.
      Keen interest in opensource projects and eagerness to learn and adapt.
      Tasks
      Initiate and conduct experiments with Apache DolphinScheduler to comprehensively understand its current functionalities.
      Implement and support a more generalized OIDC (OpenID Connect) login authentication mechanism.
      Compose corresponding E2E test cases.
      Create corresponding documentation for third-party login integrations, covering Keycloak, Dexidp, OAuthProxy, as well as Feishu Login and WeChat Work Login.
      Optimize the UI of the Apache DolphinScheduler login page.
      Ensure compatibility with the existing functionalities of Apache DolphinScheduler during the process of focusing on enhancements.
      Learning Material
       
      Apache DolphinScheduler HomePage: https://dolphinscheduler.apache.org
      Apache DolphinScheduler GitHub Repository: https://github.com/apache/dolphinscheduler
      Sprint OAuth 2.0 Client: https://docs.spring.io/spring-security/reference/reactive/oauth2/client/index.html
      pac4j OIDC: https://www.pac4j.org/docs/clients/openid-connect.html
      OIDC (OpenID Connect): https://openid.net/developers/how-connect-works/
      Mentor
      Gallardot, Apache DolphinScheduler committer, gallardot@apache.org
      SbloodyS, Apache DolphinScheduler PMC, zihaoxiang@apache.org
      Difficulty: Medium
      Project Size: ~150 hours (medium)
      Difficulty: Major
      Project size: ~175 hour (medium)
      Potential mentors:
      Hengliang Tan, mail: gallardot (at) apache.org
      Project Devs, mail: dev (at) dolphinscheduler.apache.org

      ~~~~~~~~~~
      Lucene.NET
      Apache Lucene.NET Replicator and Dependency Injection Enhancements
      Background and Goal
      Apache Lucene.NET is a .NET port of the Apache Lucene search engine (originally written in Java). This powerful library enables indexing and searching of documents with custom queries, making it a core component in many production environments. With over 100 million NuGet downloads, Lucene.NET is utilized in diverse scenarios, from local search functionality in mobile apps to supporting large-scale cloud infrastructures.
      Lucene.NET already provides a foundation for replicating a search index from a primary node to one or more replica nodes, enabling High Availability (HA) and scalability through load balancing. Currently, our Lucene.Net.Replicator.AspNetCore project offers minimal replication support for ASP.NET Core servers, but it remains unpublished on NuGet and lacks the robustness required for most use cases. Your focus for this project will be to enhance and finalize the ASP.NET Core library, ensuring a seamless user experience by adhering to best practices and making replication setup as straightforward as possible – ideally requiring just one line of code.
      Additionally, users may need replication support for applications outside ASP.NET Core, such as cloud-based distributed architectures, Windows services, or command-line tools running on Linux. To address this, we propose creating modular intermediate libraries using Microsoft.Extensions.DependencyInjection.Abstractions, enabling flexible and reusable replication configurations. This approach should also ensure that essential components like IndexWriter and IndexReader are configured in a straightforward and user-friendly manner.
      Your task will also include creating one or more sample projects that demonstrate how to effectively use the enhanced replication functionality. These projects should serve as practical, real-world examples for the community, showcasing best practices and ease of use. Additionally, you will be responsible for thoroughly testing the code changes to ensure they work as intended in real-world scenarios. This includes writing comprehensive unit tests to guarantee the reliability and quality of the solution.
      We plan for this to be a hands-on mentorship, and we will set up any infrastructure for you. As a contributor, your responsibilities will include analyzing the problem, developing a detailed plan, refining it with input from the project team, and collaborating regularly to implement the solution through pull requests and code reviews.
      Relevant Skills
      Familiarity with C# and unit testing
      Strong grasp of design patterns and practices, such as dependency injection and i.e. the fluent builder and abstract factory patterns
      Basic understanding of HTTP(S) and networking
      Not required, but good to have:
      Familiarity with ASP.NET Core 5 or later
      Understanding of distributed architectures
      Familiarity with Lucene(.NET) search indexes
      Difficulty: Normal
      Project size: ~175 hour (medium)
      Potential mentors:
      Paul Irwin, mail: paulirwin (at) apache.org
      Project Devs, mail: dev (at) lucenenet.apache.org

      ~~~~~~~~~~
      CloudStack
      Apache CloudStack DRS improvements
      As a Operator I would like to have the loads on my systems more evenly/centrally distributed. At the moment there is a simple DRS for clusterwide distribution of loads, this is however not applying zone wide distribution or based on automated queries/improvements.
      In addition we should add historic data for the VM in planning possible migrations.
      At the moment allocated metrics are used. An first improvement would be to use actual metrics.
      
      ref: cloudstack issue: https://github.com/apache/cloudstack/issues/10397
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org

      ~~~~~~~~~~
      verification of LDAP connection
      When a new ldap connection is added there is no diagnostics to verify the validity/usability of the connection, making trouble shooting troublesome. This issue aims to facilitate ldap configuration.
      ref. cloudstack issue: https://github.com/apache/cloudstack/issues/6934
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org
      ~~~~~~~~~~
      SSL - LetsEncrypt the Console Proxy
      New Global Option For Letsencrypt enable on console proxy. Letsencrypt domain name option for letsencrypt ssl auto renew
      ref. cloudstack issue: https://github.com/apache/cloudstack/issues/3141
      Difficulty: Major
      Project size: ~175 hour (medium)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org

      ~~~~~~~~~~
      Autodetect IPs used inside the VM on L2 networks
      With regards to IP info reporting, Cloudstack relies entirely on it's DHCP data bases and so on. When this is not available (L2 networks etc) no IP information is shown for a given VM.
      I propose we introduce a mechanism for "IP autodetection" and try to discover the IPs used inside the machines by means of querying the hypervisors. For example with KVM/libvirt we can simply do something like this:
       {{root@fedora35 ~]# virsh domifaddr win2k22 --source agent
      Name MAC address Protocol Address
      -------------------------------------------------------------------------------
      Ethernet 52:54:00:7b:23:6a ipv4 192.168.0.68/24
      Loopback Pseudo-Interface 1 ipv6 ::1/128
      - ipv4 127.0.0.1/8}}
       
      The above command queries the qemu-guest-agent inside the Windows VM. The VM needs to have the qemu-guest-agent installed and running as well as the virtio serial drivers (easily done in this case with virtio-win-guest-tools.exe ) as well as a guest-agent socket channel defined in libvirt.
      ref. cloudstack issue: https://github.com/apache/cloudstack/issues/7142
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org

      ~~~~~~~~~~
      [GSoC] [CloudStack] Improve CloudMonkey user experience by enhancing autocompletion
      Summary
      Currently a lot of API parameters do not get auto-completed as cloudmonkey isn't able to deduce the probable values for those parameters based on the list APIs heuristics. A lot of these parameters are enums on CloudStack end and by finding a way to expose these and consume them on cloudmonkey side, we could improve the usability of the CLI greatly.
      Benefits to CloudStack
      Improved end user experience when using CLI
      Reduce incorrect inputs
      Deliverables
      Expose enums and all other relevant information that can be used to enhance auto-completion of parameters on CloudStack end -
      May require framework level changes and changes to APIs
      Consume these exposed details on Cloudmonkey end
      Dependent projects
      https://github.com/apache/cloudstack-cloudmonkey/
      Ref CloudStack Issue: https://github.com/apache/cloudstack/issues/10442
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Pearl Dsilva, mail: pearl11594 (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org

      ~~~~~~~~~~
      add securitata integration to cloudstack
      Currently, Cloudstack only has ACLs (in Advanced Networks) that as a layer of securing access to the networks (VPCs). However, these only operate in the Layer 3 and 4 of OSI Layer.
      In todays day and age, where Cybersecurity threats become more advanced, complex and operate in Layer 7 OSI layer, there needs to be a way for Cloudstack to allow its own tenants to implement its own form of mature cybersecurity solution.
      The problem all this while is that if a user is using a VPC or L2 Networks, 3rd party firewalls such as PFsense, FortinetVM Firwall etc cant be implemented effectively due to a lack of being able to set static routes that stays with the VR after it is recreated.
      There needs to be a better option for users of cloudstack to implement a deeper form of cybersecurity to protect their workloads.
      ref. github issue:  https://github.com/apache/cloudstack/issues/10445
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org

      ~~~~~~~~~~
      eBPF-based Network Observability for CloudStack
      CloudStack’s network monitoring is mostly based on logs and external agents, making real-time traffic analysis difficult. This project will integrate eBPF-based network observability to capture per-VM traffic metrics, detect anomalies, and improve tenant isolation.
      Benefits to CloudStack
      Enhanced security: Detect suspicious activity at the kernel level.
      Real-time traffic monitoring: Gain deep insights into VM networking.
      Better tenant isolation: Identify cross-tenant traffic issues.
      Deliverables
      Develop eBPF probes to capture:
      Per-VM network traffic metrics (packets, bytes, latency)
      Connection tracking for detecting unauthorized access patterns
      Packet drops and retransmission rates
      Expose network metrics via CloudStack’s API.
      Provide visualization through Prometheus/Grafana.
      Document setup, usage, and performance benchmarks.
      Expected Outcome
      An eBPF-based solution that improves network observability in CloudStack, providing security and performance insights with minimal resource usage.
      
      Difficulty: Major
      Project size: ~175 hour (medium)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org

      ~~~~~~~~~~
      Enhancing CloudStack Monitoring with eBPF
      Apache CloudStack currently relies on traditional monitoring tools, which may lack deep visibility into kernel-level events and networking performance. This project aims to integrate eBPF-based monitoring into CloudStack to provide lightweight, real-time performance analysis and security auditing.
      Benefits to CloudStack
      Improved observability: Gain fine-grained insights into VM performance metrics.
      Lower overhead: eBPF runs in the kernel and avoids the performance penalties of user-space monitoring tools.
      Enhanced security auditing: Detect and log anomalies in system behavior.
      Deliverables
      Implement eBPF programs to track:
      VM CPU usage
      Memory consumption
      Disk I/O metrics
      Network traffic analysis
      Develop a CloudStack-compatible API or CLI for retrieving eBPF-generated insights.
      Provide visualization support using Prometheus/Grafana.
      Write documentation for setup and usage.
      Expected Outcome
      A robust eBPF-based monitoring solution integrated into CloudStack, offering real-time performance insights with minimal overhead.
      ref. cloudstack issue: https://github.com/apache/cloudstack/issues/10415
      
      This project is marked as part-time, but the scope can be extended to full-time. This depends largely on whether the full amount of metrics to track is implemented or only one, as a proof of concept.
      Difficulty: Major
      Project size: ~175 hour (medium)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org

      ~~~~~~~~~~
      StreamPipes
      Extend visualization capabilities of Apache StreamPipes
      Background
       
      Apache StreamPipes is a self-service Industrial IoT toolbox which helps users to connect, analyze and exploit industrial data streams. StreamPipes offers a variety of tools which help users to interact with data from industrial sources such as PLCs. An adapter library allows to get real-time data from industrial controllers or other systems, a pipeline editor allows to build stream processing pipelines using either graphical or code-based flow modeling, and a data explorer allows to quickly create visualizations based on connected adapters.
       Current Challenges
      The StreamPipes data explorer consists of a chart view, where users can create charts based on live data, and a dashboard view, where users can create live dashboards based on charts.
      The data explorer provides a set of charts, which are mainly based on Apache ECharts. The currently available chart library includes time-series line/bar charts, heatmaps, scatter plots, density charts and others. To improve the user experience and add additional capabilities, we plan to extend this chart library with additional charts that are useful for industrial data analytics. 
       Objectives
      The primary objectives of this project are as follows:
      Explore the Apache ECharts library and identify useful additional charts for industrial data analytics
      Improve the StreamPipes data explorer by adding new chart types using Apache ECharts
      Add a more advanced table visualization
      Extend existing charts with additional configurations (e.g., axis configurations, labels, data transformations)
      Add a data preview for all charts, which is shown below the actual chart in the chart view
      Design and implement end-to-end-tests using Cypress
       Recommended Skills
      
      Proficiency in TypeScript programming + testing 
      Proficiency in Angular
      Excellent logical thinking and problem-solving skills.
      Good sense for beautifully looking user interfaces 
      
      Mentor
      
      Dominik Riemer, Apache StreamPipes PMC, riemer@apache.org
      Difficulty: Major
      Project Size: ~350 hours (large)
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Dominik Riemer, mail: riemer (at) apache.org
      Project Devs, mail: dev (at) streampipes.apache.org

      ~~~~~~~~~~
      Kvrocks
      [GSOC][Kvrocks] Improve the controller UI
      Background
      Apache Kvrocks is a distributed key-value NoSQL database that uses RocksDB as its storage engine and is compatible with Redis protocol.
       
      In the past, basic Web UI capabilities have been provided for Apache Kvrocks Controller, including features such as cluster creation and migration. In the future, we aim to offer a better and more modern UI experience, also enhancing centralized visualization capabilities.
      Objectives
      The key objectives of the project include the following:
      Refactor the existing UI pages
      Enhance the visualization capabilities for cluster migration
      Provide a cluster Overview dashboard
      
      Recommend Skills
      Familiar with next.js & tailwind
      Have a basic understanding of RESTFul
      Have an experience of Apache Kvrocks
      
      Mentor: Hulk Lin, Apache Apache Kvrocks PMC,  hulk@apache.org
      Mailing List: dev@kvrocks.apache.org
      Please leave comments if you want to be a mentor
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Hulk Lin, mail: hulk (at) apache.org
      Project Devs, mail: dev (at) kvrocks.apache.org

      ~~~~~~~~~~
      [GSOC][Kvrocks] Support database backup to cloud storage
      Backgroud:
      Kvrocks is a key-value database that provides a Redis-compatible API on top of RocksDB. Currently, Kvrocks lacks a built-in mechanism for database backup to cloud storage, which is crucial for data durability, disaster recovery, and scalability in cloud environments.
      This project aims to implement a robust backup system that allows users to store Kvrocks backups directly in cloud storage services such as Amazon S3, Google Cloud Storage, and/or Azure Blob Storage. The solution will integrate with the existing Kvrocks backup and restore mechanisms while ensuring efficient and secure data transfer.
      Deliverables:
      Cloud Storage Integration: Implement backup storage support for Amazon S3, Google Cloud Storage, and Azure Blob Storage using SDKs, REST APIs or libraries (e.g. Apache OpenDAL).
      Backup & Restore Commands: Extend Kvrocks’ backup functionality to allow exporting and importing database snapshots from cloud storage.
      Configuration & Authentication: Provide user-configurable options to specify storage credentials and backup parameters.
      Incremental Backup Support (Stretch Goal): Optimize storage usage by implementing differential or incremental backup capabilities.
      Documentation & Tests: Comprehensive documentation and test coverage to ensure reliability and ease of use.
      Recommended Skills:
      Good at coding in C++;
      Knowledge about database internals and cloud storage;
      Knowledge about Kvrocks or Redis.
      Mentor: Mingyang Liu, Apache Kvrocks PMC member,  twice@apache.org
      Mailing List: dev@kvrocks.apache.org
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Mingyang Liu, mail: twice (at) apache.org
      Project Devs, mail: dev (at) kvrocks.apache.org

      ~~~~~~~~~~
      Beam
      Simplify management of Beam infrastructure, access control and permissions via Platform features
      This project consists in a series of tasks that build a sort of 'infra platform' for Beam. Some tasks include:
      Automated cleaning of infrastructure: [Task]: Build a cleaner for assets in the GCP test environment #33644
      Implement Infra-as-code for Beam infrastructure
      Implement access permissions using IaC: [Task]: Build a cleaner for assets in the GCP test environment #33644
      Implement drift detection for IaC resources for Beam
      Implement 'best-practice' key management for Beam (i.e. force key rotation for service account keys, and store in secret manager secrets)
      
      A quality proposal will include a series of features beyond the ones listed above. Some ideas:
      Detection of policy breakages, and nagging to fix
      Security detections based on cloud logging
      others?
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Pablo Estrada, mail: pabloem (at) apache.org
      Project Devs, mail: dev (at) beam.apache.org

      ~~~~~~~~~~
      Enhancing Apache Beam JupyterLab Sidepanel for JupyterLab 4.x and Improved UI/UX
      The Apache Beam JupyterLab Sidepanel provides a valuable tool for interactive development and visualization of Apache Beam pipelines within the JupyterLab environment. This project aims to significantly enhance the sidepanel by achieving full compatibility with the latest JupyterLab 4.x release and implementing substantial UI/UX improvements. This will ensure seamless integration with modern JupyterLab workflows and provide a more intuitive and user-friendly experience for Apache Beam developers.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      XQ Hu, mail: xqhu (at) apache.org
      Project Devs, mail: dev (at) beam.apache.org

      ~~~~~~~~~~
      Enhance lineage support in Beam
      Apache Beam provides a powerful way to define data processing pipelines. However, it is increasingly important for users to be able to track how their data is moving through Beam so that they can make informed choices on how they manage their data at the source or sink of their pipeline. To solve for this, we have recently introduced data lineage in Beam - https://en.wikipedia.org/wiki/Data_lineage - to this point support is still relatively limited though.
      
      For this project, the focus would be on adding broader lineage support to Beam. This could include:
      
      adding column level lineage to more transforms
      adding direct runner support for lineage graphs (https://github.com/apache/beam/issues/33980)
      Integrating Beam with Open Lineage (https://github.com/apache/beam/issues/33981)
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Danny McCormick, mail: damccorm (at) apache.org
      Project Devs, mail: dev (at) beam.apache.org

      ~~~~~~~~~~
      Beam ML Vector DB/Feature Store integrations
      Apache Beam's Python SDK provides a powerful way to define data processing pipelines. In particular, many users want to use Beam for machine learning use cases like feature generation, embedding generation, and retrieval augmented generation (RAG). Today, however, Beam integrates with a relatively limited set of feature stores and vector DBs for these use cases. This project aims to build out a rich ecosystem of connectors to systems like Pinecone and Tecton to enable these ML use cases.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Danny McCormick, mail: damccorm (at) apache.org
      Project Devs, mail: dev (at) beam.apache.org

      ~~~~~~~~~~
      Beam YAML ML, Iceberg, and Kafka User Accessibility
      Apache Beam's YAML DSL provides a powerful and declarative way to define data processing pipelines. However, its adoption for complex use cases like Machine Learning (ML) and Managed IO (specifically Apache Iceberg and Kafka) is hindered by a lack of comprehensive documentation and practical examples. This project aims to significantly improve the Beam YAML documentation and create illustrative examples focused on ML workflows and Iceberg/Kafka integration, making these advanced features more accessible to users.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      XQ Hu, mail: xqhu (at) apache.org
      Project Devs, mail: dev (at) beam.apache.org

      ~~~~~~~~~~
      RocketMQ
      Refactoring the RocketMQ Dashboard UI and Enhancing Usability
      Background
      
      Apache RocketMQ is renowned as a cloud-native messaging and streaming platform, enabling the creation of event-driven applications with simplicity and flexibility. The RocketMQ Dashboard is a crucial component that provides users with insight into system performance and client interactions through intuitive graphs and statistical data. Despite its fundamental role, the current user interface (UI) of the RocketMQ Dashboard is outdated, affecting user experience and interaction efficiency. Additionally, while the Dashboard offers valuable functionalities, there is a pressing need to enhance its usability and ensure robust security. This project aims to refactor the RocketMQ Dashboard by redesigning its UI with a more contemporary and user-friendly approach, improving overall usability, and introducing effective security measures to safeguard data and user interactions.
      Relevant Skills
      Strong Java development skills.
      Experience with modern front-end technologies and frameworks
      Proficiency in Spring Boot development.
      Understanding of UX/UI design principles. - Knowledge of security best practices in web applications.
      A keen interest in open-source projects and a willingness to learn and adapt.
      Tasks
      
      Launch and experiment with the RocketMQ Dashboard to understand current functionalities.
      Refactor the UI of the RocketMQ Dashboard to align with modern user interface standards, ensuring it is intuitive and visually appealing.  
      Improve usability by streamlining workflows, enhancing navigation, and incorporating responsive design. 
      Integrate security features to protect user data, prevent unauthorized access, and mitigate potential vulnerabilities.
      Maintain compatibility with existing RocketMQ functionalities while focusing on enhancements. 
      Learning Material
      
      RocketMQ HomePage: https://rocketmq.apache.org([https://rocketmq.apache.org|https://rocketmq.apache.org/])
      RocketMQ GitHub Repository: https://github.com/apache/rocketmq([https://github.com/apache/rocketmq]) 
      RocketMQ Dashboard GitHub Repository: https://github.com/apache/rocketmq-dashboard([https://github.com/apache/rocketmq-dashboard]) 
      
      Mentor
      Rongtong Jin, Apache RocketMQ PMC, jinrongtong@apache.org
      Potential Mentor
      Juntao Ji, 3160102420@zju.edu.cn
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Rongtong Jin, mail: jinrongtong (at) apache.org
      Project Devs, mail: dev (at) rocketmq.apache.org

      ~~~~~~~~~~
      Optimizing Apache RocketMQ's POP Orderly Consumption Process
      Background
       
      Apache RocketMQ is a distributed messaging and streaming platform that supports various messaging protocols. One of the key features of RocketMQ is its orderly message consumption capability, which guarantees that messages are processed in the order they are sent. However, there are existing issues with the POP Orderly consumption process that need to be addressed to enhance its reliability and performance.
       Current Challenges
      
      Currently, the POP Orderly feature faces several shortcomings, particularly in scenarios where network instability leads to the loss of the attemptId carried by the consumer from the previous round. This issue can result in message consumption getting stuck until the acknowledgment response (ack) for the previous message pull times out. Such situations hinder the efficient processing of messages and reduce the overall effectiveness of the messaging system.
       Objectives
      The primary objectives of this project are as follows:
      ●Refactor the POP Orderly Code: Analyze and redesign the existing codebase to improve its structure, maintainability, and performance.
      ●Optimize Performance: Implement performance enhancements that allow the POP Orderly feature to cope with network fluctuations and reduce the likelihood of consumption halting.
      ●Elegant Process Resolution: Develop a more graceful approach to handling the issue of consumption stalling, ensuring that the system can recover more smoothly from failures.
       Recommended Skills
      
      1. Proficiency in Java programming.
      2. Strong understanding of concurrent programming.
      3. Excellent logical thinking and problem-solving skills.
      4. Familiarity with message queue systems, particularly Apache RocketMQ.
       
       Mentor
      
      Rongtong Jin, Apache RocketMQ PMC, jinrongtong@apache.org
      Potential Mentor
      Juntao Ji, 3160102420@zju.edu.cn
      
      Difficulty: Major
      Project Size: ~350 hours (large)
      
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Rongtong Jin, mail: jinrongtong (at) apache.org
      Project Devs, mail: dev (at) rocketmq.apache.org

      ~~~~~~~~~~
      SkyWalking
      SkyWalking BanyanDB Extend remote.FS with Object Storage Support for AWS, Google Cloud, and Azure
      Overview:
      The current implementation of the remote.FS interface only supports a local file system (via the implementation in local.go). This GSOC2025 project proposes to extend remote.FS with popular object storage services—namely AWS S3, Google Cloud Storage, and Azure Blob Storage. This enhancement will allow the project to support robust cloud-based backup and restore operations in addition to local storage.
      Proposed Features:
      AWS S3 Implementation:
      Implement methods for Upload, Download, List, and Delete operations using the AWS S3 API.
      Google Cloud Storage Implementation:
      Provide a module that integrates with Google Cloud Storage to perform similar operations.
      Azure Blob Storage Implementation:
      Develop functionality to access and manage Azure Blob Storage via the remote.FS interface.
      Implementation Details:
      Interface Compliance:
      Each object storage implementation must adhere to the remote.FS interface defined in remote.go.
      Error Handling & Resilience:
      Implement robust error handling, logging, and retry mechanisms to ensure reliable operations across different cloud services.
      Testing:
      Develop comprehensive unit and integration tests to cover edge cases and guarantee compatibility and stability.
      Documentation:
      Update the project documentation to detail configuration, deployment, and usage of each cloud storage option.
      
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Hongtao Gao, mail: hanahmily (at) apache.org
      Project Devs, mail: dev (at) skywalking.apache.org

      ~~~~~~~~~~
      Seata
      GSoC 2025 - Apache Seata(Incubating) Extend multi-raft cluster mode
      Description
      Synopsis
      The current Apache Seata Server supports the Raft cluster mode, but the performance and throughput of the cluster are significantly limited due to the single leader in a single Raft group. Therefore, the goal is to extend Seata Server to support multi-raft capability.
      
      Benefits to Community
      Due to the characteristics of Raft, requests are processed on the leader node and the results are submitted to the followers through the Raft consensus protocol. As a result, a significant amount of computational load is placed on the leader node, while followers only need to receive the final computed result. This causes the CPU, memory, and other metrics of the leader to be much higher than those of the followers. Additionally, the throughput of a single leader is limited by the machine configuration of the highest-spec node in the cluster, making it difficult to balance the traffic effectively. Therefore, supporting multi-raft would make the load distribution more balanced across all nodes in the cluster, improving throughput and performance, while also reducing the waste of machine resources.
      
      Deliverables
      The expected delivery goal is to apply the multi-raft capability of the sofa-jraft component to Seata Server through detailed learning and practice
      
      The step expected are the following:
      Learning and using the sofa-jraft component
      Understanding and practicing the transaction grouping capability in Seata
      Gaining a certain level of understanding of Seata's communication protocol
      Gaining a certain level of understanding of Seata's storage model, especially the Raft mode
      Ensuring compatibility between different versions
      Useful links
      seata-raft-detailed-explanation
      transaction-group
      sofa-jraft
      Mentor
      Mentor: Jianbin Chen, Apache Seata(Incubating) PPMC Member jianbin@apache.org
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Jianbin Chen, mail: jianbin (at) apache.org
      Project Devs, mail: dev (at) seata.apache.org

      ~~~~~~~~~~
      GSoC 2025 - Apache Seata(Incubating)Unlocking the Power of Metadata in Apache Seata From Load Balancing to Advanced Routing
      Synopsis
      Currently, Apache Seata relies on a registry (e.g., Nacos, Zookeeper, Eureka, Etcd3, Consul, Seata Naming Server) for service discovery and load balancing. However, the existing registry mechanism lacks support for custom metadata, which limits the flexibility of client-side load balancing strategies. For example, clients cannot dynamically adjust traffic distribution based on server-side metadata such as weight, region, or version. This project aims to enhance the registry module in Apache Seata by adding metadata support and enabling clients to implement advanced load balancing strategies based on this metadata.
      Benefits to Community
      Improved Load Balancing Flexibility: By allowing Seata Server instances to register custom metadata (e.g., weight, region, version), clients can implement more sophisticated load balancing strategies, such as weighted round-robin, zone-aware routing, or version-based routing. This ensures better resource utilization and improved system performance.
      Enhanced Scalability: With metadata-driven load balancing, Seata can better handle large-scale deployments by distributing traffic more intelligently across server instances. For example, high-traffic regions can be assigned more resources, while low-traffic regions can operate with minimal overhead.
      Better Resource Utilization: Metadata such as server weight or capacity can help clients avoid overloading specific instances, leading to more balanced resource usage across the cluster.
      Extensibility: The addition of metadata support opens the door for future enhancements, such as dynamic traffic shaping, A/B testing, or canary deployments.
      
      Deliverables
      The expected deliverables for this project include:
      Registry Metadata Support:
      Extend the registry module (e.g., Nacos, Zookeeper, Eureka, Etcd3, Consul, Seata Naming Server) to allow Seata Server instances to register custom metadata (e.g., weight, region, version).
      Ensure backward compatibility with existing registry implementations.
      Client-Side Load Balancing Enhancements:
      Implement a metadata-aware load balancing mechanism in the Seata client (TM/RM).
      Provide built-in load balancing strategies (e.g., weighted random, zone-aware) and allow users to plug in custom strategies via SPI.
      Documentation and Testing:
      Update the Seata documentation to explain how to configure and use metadata for load balancing.
      Write unit tests and integration tests to validate the new functionality
      
      Steps Expected
      1.Understand Seata's Registry Mechanism:
      Study how Seata integrates with various registries (e.g., Nacos, Zookeeper, Eureka, Etcd3, Consul, Seata Naming Server).
      Identify the current limitations in metadata support and load balancing.
      2.Extend Registry Module:
      Modify the registry module to allow Seata Server instances to register custom metadata.
      Ensure the metadata is propagated to clients during service discovery.
      3.Implement Metadata-Aware Load Balancing:
      Enhance the client-side load balancing logic to consider metadata (e.g., weight, region) when selecting a server instance.
      Provide built-in strategies (e.g., weighted random, zone-aware) and support custom strategies via SPI.
      4.Ensure Compatibility and Performance:
      Test the new functionality with different registry implementations (e.g., Nacos, Zookeeper, Eureka, Etcd3, Consul, Seata Naming Server).
      Optimize performance to minimize the overhead of metadata processing.
      5.Documentation and Testing:
      Write clear documentation on how to configure and use the new metadata and load balancing features.
      Develop comprehensive unit tests and integration tests.
      
      Useful Links
      Apache Seata Documentation
      Nacos
      Zookeeper
      Eureka
      Consul
      Etcd3
      Seata Naming Server
      Load Balancing Strategies
      Mentor
      Mentor: Jiangke Wu, Apache Seata(Incubating) PPMC Member xingfudeshi@apache.org
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Jiangke Wu, mail: xingfudeshi (at) apache.org
      Project Devs, mail: dev (at) seata.apache.org

      ~~~~~~~~~~
      GSoC 2025 - Apache Seata(Incubating) Enhancing Connection Pool Management for Apache Seata AT/XA Transaction Modes
      Project Overview
      Title
      Enhancing Connection Pool Management for Apache Seata AT/XA Transaction Modes
      
      Abstract
      Apache Seata(incubating) is a popular distributed transaction solution, providing solutions like AT, TCC, and XA for ensuring data consistency in microservice architectures. This project aims to enhance the connection pool management for Seata's AT/XA transaction modes by integrating a comprehensive monitoring and configuration management system within the Seata console. The enhanced functionality will facilitate better resource management and operational efficiency for organizations utilizing Seata.
      
      Detailed Description
      Objectives
      1. Console Metrics Visualization: Develop functionality to view various metrics related to the connection pool in the Seata console. The metrics should be displayed based on IP/connection pool granularity, helping users easily identify resource allocation and utilization.
      2. Metrics Control via Console: Allow users to control various aspects of the connection pools directly from the Seata console. This includes the ability to adjust minimum and maximum connection counts, configure connection acquisition timeout, and manage connection pool keep-alive settings.
      
      Deliverables
      1. Connection Pool Metrics Monitoring:
      Visual display of connection pool metrics including current connections, idle connections, active connections, etc.
      Granular view based on IP and connection pool, enabling detailed monitoring and management.
      Connection Pool Configuration Management:
      2. Implement functions in the Seata console to change connection pool settings:
      Adjust minimum and maximum connection thresholds.
      Set and modify the timeout for obtaining connections.
      Configure keep-alive settings for maintaining active pool connections.
      3. Comprehensive Documentation:
      Provide documentation on how to use the new connection pool features.
      Include developer notes for future contributions and improvements.
      
      Implementation Plan
      Phase 1: Requirement Analysis and Design
      Collaborate with mentors to finalize requirements and design a detailed architecture plan.
      Explore existing Seata console features and connection pool management libraries.
      Phase 2: Development of Monitoring Features
      Implement backend logic to gather connection pool metrics.
      Develop Seata console UI components for metric visualization.
      Phase 3: Development of Control Features
      Integrate functionality to dynamically adjust connection pool configurations via the console.
      Ensure robust validation and error-handling mechanisms are in place.
      Phase 4: Testing and Documentation
      Conduct thorough testing to ensure reliability and performance.
      Write user and developer documentation explaining features, usage, and configuration.
      
      Required Skills
      Passion for Open Source: Enthusiasm to contribute consistently to open-source projects, with a curiosity for technology.
      Understanding of Seata Architecture: Basic knowledge of Apache Seata’s architecture and transaction models.
      Java Proficiency: Strong command of Java programming for backend development.
      
      Benefits to Apache Seata
      The project will enhance Apache Seata’s usability by providing detailed insights and management capabilities for connection pools. This will lead to more efficient resource utilization, aiding organizations in maintaining system performance and reliability within their distributed transactions.
      
      Conclusion
      This project represents an opportunity to significantly improve the operational capabilities of Seata AT/XA transaction modes by enriching the connection pool management features. With rigorous execution, it will provide valuable resources for both users and developers within the Apache Seata community.
      
      Useful Link
      [Apache Seata website](https://seata.apache.org/)
      
      Contact Information
      Mentor Name: [Min Ji](jimin@apache.org) , Apache Seata(incubating) PPMC member
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Min Ji, mail: jimin (at) apache.org
      Project Devs, mail: dev (at) seata.apache.org

      ~~~~~~~~~~
      HugeGraph
      [GSoC][HugeGraph] Implement Agentic GraphRAG Architecture
      Apache HugeGraph(incubating) is a fast-speed and highly-scalable graph database/computing/AI ecosystem. Billions of vertices and edges can be easily stored into and queried from HugeGraph due to its excellent OLTP/OLAP ability.
       
      Website: https://hugegraph.apache.org/
      GitHub:
      https://github.com/apache/incubator-hugegraph/
      https://github.com/apache/incubator-hugegraph-ai/
       Description
      Currently, we have implemented a basic GraphRAG that relies on fixed processing workflows (e.g., knowledge retrieval & graph structure updates using the same execution pipeline), leading to insufficient flexibility and high overhead in complex scenarios. The proposed task introduces an Agentic architecture based on the principles of "dynamic awareness, lightweight scheduling, concurrent execution," focusing on solving the following issues:
      Rigid Intent Recognition: Existing systems cannot effectively distinguish between simple retrievals (e.g., entity queries) and complex operations (e.g., multi-hop reasoning), often defaulting to BFS-based template subgraph searches.
      Coupled Execution Resources: Memory/computational resources are not isolated based on task characteristics, causing long-tail tasks to block high-priority requests.
      Lack of Feedback Mechanisms: Absence of self-correction capabilities for erroneous operations (e.g., automatically switching to similar vertices/entities after path retrieval failures).
      The task will include three core parts:
      1. Dynamic Awareness Layer
      Implement an LLM-based real-time (as of February 14, 2025) intent classifier that categorizes tasks (L1 simple retrieval/L2 path reasoning/L3 graph computation/L4+ etc.) based on semantic features (verb types/entity complexity/temporal modifiers).
      Build a lightweight operation cache to generate feature hashes for high-frequency requests, enabling millisecond-level intent matching.
      2. Task Orchestration Layer
      Introduce a suitable workflow/taskflow framework emphasizing low coupling, high performance, and flexibility.
      Adopt a preemptive scheduling mechanism allowing high-priority tasks to pause non-critical phases of low-priority tasks (e.g., suspending subgraph preloading without interrupting core computations).
      3. Concurrent Execution
      Decouple traditional RAG pipelines into composable operations (entity recall → path validation → context enhancement → result refinement), with dynamic enable/disable support for each component.
      Implement automatic execution engine degradation, triggering fallback strategies upon sub-operation failures (e.g., switching to alternative methods if Gremlin queries timeout).
      Recommended Skills
      Proficiency in Python and familiarity with at least one open/closed-source LLM.
      Experience with one LLM RAG/Agent framework like LangGraph/RAGflow/LLamaindex/Dify.
      Knowledge of LLM optimization techniques and RAG construction (KG extraction/construction experience is a plus).
      Strong algorithmic engineering skills (problem abstraction, algorithm research, big data processing, model tuning).
      Familiarity with VectorDB/Graph/KG/HugeGraph read-write workflows and principles.
      Understanding of graph algorithms (e.g., community detection, centrality, PageRank) and open-source community experience preferred.
      Task List
      Develop a hierarchical triggering mechanism for the intent classifier to categorize L1~LN tasks within milliseconds (accuracy >90%).
      Semi-automatically generate Graph Schema/extraction prompts.
      Support dynamic routing and query decomposition.
      Design an execution trace tracker to log micro-operation resource consumption and generate optimization reports.
      Enhance retrieval with graph algorithms: Apply node importance evaluation, path search, etc., to optimize knowledge recall.
      Implement a dialogue memory management module for context-aware state tracking and information reuse.
      Size
      Difficulty: Hard
      Project size: ~350 hours (full-time/large)
      Potential Mentors
      Imba Jin: jin@apache.org (Apache HugeGraph PPMC)
      Simon: ming@apache.org (Apache HugeGraph PPMC)
       Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Imba Jin, mail: jin (at) apache.org
      Project Devs, mail:

      ~~~~~~~~~~
      Mahout
      Apache Mahout Refactoring the Website
      Synopsis
      Apache Mahout has been evolving, with a recent shift in focus toward Quantum Computing (Qumat). However, the official website does not currently reflect this transition, making it difficult for developers and contributors to engage with Mahout’s new direction. Additionally, legacy components like MapReduce and Samsara are no longer actively developed but still occupy prominent space on the website.
      This project aims to refactor the Apache Mahout website to:
      Bring Quantum Computing (Qumat) front and center as the new core focus of the project.
      Deprecate outdated technologies (MapReduce and Samsara) while keeping the documentation intact with clear deprecation warnings.
      Improve website structure, navigation, and content organization to enhance accessibility and usability.
      By executing these changes, this project will ensure that new and existing users can quickly access relevant information while keeping historical documentation available in a structured manner.
      Benefits to the Community
      A well-organized and up-to-date website is essential for any open-source project. This proposal offers multiple benefits to the Apache Mahout community:
      1. Highlighting Quantum Computing (Qumat)
      Restructure the website so that Qumat-related content is the primary focus.
      Ensure that all documentation, blogs, and tutorials related to Qumat are easily discoverable from the homepage.
      2. Deprecating MapReduce and Samsara
      Add clear deprecation warnings to pages related to MapReduce and Samsara.
      Ensure these technologies remain accessible for historical reference but indicate that they are no longer actively maintained.
      3. Improved Navigation and Accessibility
      Design a more intuitive navigation system for easy exploration of different sections.
      Ensure smooth access to documentation, blogs, and learning resources.
      4. Updating Outdated Content
      Perform a full website audit to identify obsolete articles, guides, and references.
      Refresh and rewrite content where necessary, focusing on Mahout’s latest advancements.
      5. Engaging New Contributors
      A modern, user-friendly website will attract more developers, researchers, and open-source contributors to the project.
      Deliverables
      1. Website Restructuring
      Modify the homepage and navigation bar to prominently feature Quantum Computing (Qumat) as the main focus.
      Ensure Qumat-related documentation and blog posts are front and center.
      2. Deprecation of MapReduce and Samsara
      Add banner notifications on all MapReduce and Samsara pages marking them as deprecated.
      Ensure clear explanations so users understand these technologies are no longer in active development.
      3. Content Review & Updates
      Perform a recursive LS audit to identify outdated and redundant content.
      Update old blogs and articles to align with Mahout’s latest developments.
      4. Improved Website Navigation
      Implement a modern, responsive, and mobile-friendly navigation system.
      Optimize loading speed and ensure smooth user experience.
      5. Documentation Enhancement
      Ensure all essential documentation is accessible from the homepage.
      Improve the readability and structure of the docs.
      Technical Details
      The project will utilize:
      HTML, CSS, JavaScript for website front-end improvements.
      Modern front-end frameworks (if required) to enhance UX/UI.
      Shell scripting or Python to perform a recursive LS audit of the website structure.
      Version control via GitHub for tracking changes and ensuring collaboration.
      Expected Outcomes
      ✅ A refactored website that clearly emphasizes Quantum Computing (Qumat).
      ✅ A deprecated but accessible archive for MapReduce and Samsara.
      ✅ An updated and well-structured content repository for Mahout users and contributors.
      ✅ An intuitive, user-friendly website that engages both new and existing users.
      Timeline (12+ Weeks, Full-Time Commitment - 30 hrs/week)
      Community Bonding (Weeks 1-2)
      Engage with mentors and the Mahout community.
      Gather feedback on website restructuring priorities.
      Set up the development environment and review existing website architecture.
      Phase 1: Planning & Initial Development (Weeks 3-6)
      Redesign homepage and navigation bar to prioritize Qumat.
      Identify and start modifying MapReduce and Samsara pages with deprecation warnings.
      Conduct a recursive LS audit to locate outdated files and redundant content.
      Phase 2: Implementation & Testing (Weeks 7-10)
      Implement the new website navigation and homepage.
      Update and restructure documentation and blog content.
      Optimize the website’s file structure based on LS audit findings.
      Conduct extensive testing for responsiveness, accessibility, and performance.
      Phase 3: Content Finalization & Refinement (Weeks 11-12+)
      Finalize deprecation notices for MapReduce and Samsara.
      Ensure all Qumat-related content is easily accessible.
      Perform last-minute optimizations and bug fixes.
      Gather final feedback from the community and document all changes.
      🔹 Total Timeline: 350+ hrs
      Why This Should Be a GSoC Project
      This project directly aligns with Google Summer of Code’s mission to enhance open-source software. By modernizing the Apache Mahout website, we ensure that its new focus on Quantum Computing (Qumat) is clearly reflected, making it easier for developers and researchers to engage with Mahout’s latest advancements.
      Additionally, this project is well-scoped for GSoC, combining front-end development, content management, and structured auditing—all crucial aspects for a website overhaul.
      Mentorship & Feasibility
      The project has clear, well-defined goals and structured milestones.
      It will be mentored by an experienced Apache Mahout maintainer who is applying for the mentor role.
      The tasks are technically feasible within the GSoC timeframe.
      Conclusion
      Refactoring the Apache Mahout website is essential for reflecting its new focus on Quantum Computing (Qumat) while ensuring historical documentation remains accessible. By modernizing the site, we enhance usability, improve accessibility, and help new users quickly understand Mahout’s direction.
      This project will significantly enhance Mahout’s online presence and ensure the community stays well-informed and engaged.
      
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Trevor Grant, mail: rawkintrevo (at) apache.org
      Project Devs, mail: dev (at) mahout.apache.org

      ~~~~~~~~~~
      Doris
      Apache DorisEvaluating Column Encoding and Optimization
      Synopsis
      Apache Doris is a real-time data warehouse that utilizes columnar storage. Currently, Doris applies default encoding methods based on column data types. This project aims to evaluate the efficiency of these default encodings (e.g., encoding/decoding time and compression ratios) using benchmark datasets like TPC-DS, HTTP logs, and TPC-H. The findings will guide optimizations to improve performance.
      Key Objectives
      A. Develop a tool to evaluate encoding efficiency. The tool will take a column of data and an encoding method as input and output metrics such as compression ratio and processing speed.
      B. Optimize dictionary encoding for string columns. Current implementations apply dictionary encoding by default without evaluating data suitability, leading to inefficiencies for non-dictionary-friendly data.
      C. Assess the effectiveness of BitShuffle encoding for enhancing downstream compression.
      Benefits to the Community
      
      Improve data compression efficiency in Apache Doris.
      Enhance query performance through optimized encoding/decoding.
      Technical Details
      Languages/Tools: C++ for encoding logic, GitHub for version control.
      Methodology:
      
      Benchmark existing encoding methods (e.g., dictionary, BitShuffle).
      
      Develop an evaluation framework to measure compression ratios and processing overhead.
      Implement optimizations for specific data types and use cases.
      Timeline (12+ Weeks, Full-Time Commitment - 30 hrs/week)
      Community Bonding (Weeks 1-2)
      
      Engage with mentors and the Doris community.
      
      Set up the development environment and study the codebase.
      
      Document current column encoding strategies for all data types.
      Phase 1: Planning & Initial Development (Weeks 3-6)
      
      Build a tool to evaluate encoding schemes across data types.
      
      Run benchmarks using TPC-DS, HTTP logs, and TPC-H datasets.
      Phase 2: Analysis & Optimization (Weeks 7-10)
      Optimize Dictionary Encoding: Automatically detect and skip non-dictionary-friendly data (e.g., high-cardinality strings).
      BitShuffle Evaluation: Quantify its impact on compression ratios and processing speed.
      
      Address additional optimization opportunities identified during analysis.
      Phase 3: Finalization & Refinement (Weeks 11-12+)
      
      Refine code and documentation based on community feedback.
      Submit PRs and ensure their merge into the Doris master branch.
       
      🔹 Total Effort: 350+ hours
      Expected Outcomes
      
      A tool to evaluate encoding efficiency for all Doris column types.
      
      Optimized dictionary encoding logic with automated suitability checks.
      
      Improved BitShuffle integration for enhanced compression.
      Additional optimizations identified during the project.
      This project will strengthen Apache Doris’s performance in real-time analytics scenarios while fostering collaboration within the open-source community.
      Contact Information *
      Mentor Name: [Yongqiang Yang](dataroaring@apache.org) , Apache Doris PMC member
      
      Mentor Name:[Chen Zhang](zhangchen@apache.org) Apache Doris Committer
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Calvin Kirs, mail: kirs (at) apache.org
      Project Devs, mail: dev (at) doris.apache.org

      ~~~~~~~~~~
      Apache Doris Enhancing Group Commit Functionality
      Synopsis
         The current Group Commit mechanism in Apache Doris batches data until a predefined size or time threshold is met before committing. This project aims to improve flexibility and control over data visibility by introducing the following enhancements: #
      Trigger Immediate Flush After a Specified Number of Imports: Allow data to be committed automatically after accumulating a configurable number of import operations.
      SYNC TABLE Syntax Support: Enable users to explicitly trigger Group Commit for a table via SQL (e.g., SYNC TABLE table_name), ensuring the command returns only after the commit completes.
      System Table for Monitoring: Add an information_schema.group_commit system table to track Group Commit status, including columns such as BE host, table ID, and commit metadata (e.g., batch size, latency).
      Technical Details
      Languages: C++ (core) and Java (SQL syntax integration).
      Tools: GitHub for version control and collaborative development.
      Timeline (12+ Weeks, Full-Time Commitment - 30 hrs/week)
      Community Bonding (Weeks 1-2)
      
      Collaborate with mentors and the Apache Doris community.
      
      Set up the development environment and review the existing Group Commit implementation.
      
      Document the current Group Commit workflow and proposed optimizations.
      Phase 1: Implementation & Testing (Weeks 3-6)
      
      Develop support for flushing data after a configurable number of imports.
      
      Implement the SYNC TABLE syntax to trigger manual Group Commit.
      
      Design and integrate the information_schema.group_commit system table.
      
      Conduct performance benchmarking and rigorous testing.
      Phase 2: Refinement & Integration (Weeks 7+)
      
      Address feedback from code reviews and community testing.
      
      Finalize documentation and ensure backward compatibility.
      Submit pull requests (PRs) and work toward merging changes into the master branch.
      🔹 Total Effort: 210+ hours
      Expected Outcomes
      
      Enhanced flexibility in Group Commit with configurable flush triggers (size, time, or import count).
      
      A user-friendly SYNC TABLE SQL command for explicit commit control.
      
      A monitoring system table (information_schema.group_commit) for real-time visibility into commit operations.
      Robust performance validation and integration into Apache Doris’s core workflow.
      This project will empower users with finer control over data ingestion and visibility while maintaining Doris’s high-throughput capabilities.
       
      Contact Information *
      Mentor Name: [Yongqiang Yang](dataroaring@apache.org) , Apache Doris PMC member
      
      Mentor Name:[Yi Mei](zhangchen@apache.org) Apache Hbase Committer
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Calvin Kirs, mail: kirs (at) apache.org
      Project Devs, mail: dev (at) doris.apache.org

      ~~~~~~~~~~
      HertzBeat
      [GSOC][HertzBeat] AI Agent Based on the MCP Protocol for Monitoring Info Interaction
      Website: https://hertzbeat.apache.org/
      Github: http://github.com/apache/hertzbeat/
      *Background*
      Apache HertzBeat is an open-source real-time monitoring tool that supports a wide range of monitoring targets, including web services, databases, middleware, and more. It features high performance, scalability, and security.
      With the advancement of artificial intelligence (AI) technologies, integrating AI with monitoring systems can significantly enhance their usability and interactivity. By developing an AI Agent based on the Model Context Protocol (MCP), we aim to enable conversational interaction for querying monitoring information, adding new monitoring tasks, and retrieving monitoring metrics. This will provide a more user-friendly and intelligent monitoring management experience.
      *Objectives*
      1. Research and Implementation: Develop an AI Agent based on Apache HertzBeat and the MCP protocol to enable conversational interaction with users.
      2. Functional Implementation:
      Query Monitoring And Alarm Information: Allow users to query the status of monitoring targets (e.g., normal, abnormal) and retrieve metrics data (e.g., CPU usage, memory usage, response time), alarm data through conversational commands.
      Add New Monitoring Tasks: Enable users to add new monitoring targets (e.g., web services, databases, middleware) and configure alert thresholds via conversational commands.
      Retrieve Monitoring Metrics Data: Allow users to obtain metrics data for specific monitoring targets and support data visualization via conversational commands.
      *Requirements Analysis*
      Apache HertzBeat: As the core backend for the monitoring system, it provides functions for data collection, storage, and management.
      MCP Protocol: An open protocol that enables seamless integration between LLM applications and external data sources and tools.
      Front-end Interaction: Develop a user-friendly interface that supports voice or text input and displays monitoring information and interaction results.
      *Recommended Skills*
      Java + TypeScript: Apache HertzBeat is developed based on this technology stack. Therefore, mastering these technologies is crucial for integrating with HertzBeat.
      SpringAi: It is recommended to use SpringAi to build the AI agent.
      LLM + MCP: You need to have an understanding of LLM (Large Language Models) and the MCP protocol. SpringAi seem supports the MCP protocol or consider use the mcp-sdk directly.
      *Size*
      Difficulty: Hard
      Project size: ~350 hours
      *Potential Mentors*
      Chao Gong: gongchao@apache.org 
       Shenghang Zhang: shenghang@apache.org
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Chao Gong, mail: gongchao (at) apache.org
      Project Devs, mail: dev (at) hertzbeat.apache.org
      No labels
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-apache-software-foundation/
    idea_list_url: https://s.apache.org/gsoc2025ideas
  

  - organization_id: 151
    organization_name: The FreeBSD Project
    no_of_ideas: 22
    ideas_content: |
      
      Kernel Projects
      mac_do(4) improvements
      [last updated: 2025-01-28]
      Mentor
      Olivier Certner <olce AT FreeBSD DOT org>
      Skills
      C (intermediate), Parallel programming (intermediate preferred), Security (intermediate preferred)
      Duration
      90 hours
      Difficulty
      Medium
      Expected Outcome
      Support per-jail configuration of application paths. Support for traditional and standard credentials-changing system calls. If possible, add authorization logging.
      Please see also the related project mdo(1) improvements. To interested students: Please consider combining both in a single medium-duration project (175 hours).
      mac_do(4) is a kernel module that can enable controlled process credentials transitions, such as changing the user IDs or group IDs to particular values. Processes that make such requests and are authorized by mac_do(4) do not need to be root, in particular not to have been spawned from an executable tagged with the setuid bit.
      For more information about mac_do(4), please consult the 2024 Q3's status report. Note that all the changes evoked in this report have been completed and are now in the tree.
      (Remark: The online manual page for mac_do(4) (from man.freebsd.org) has not been updated to the current in-tree version. The latter's source can be found at https://cgit.freebsd.org/src/tree/share/man/man4/mac_do.4.)
      Currently, mac_do(4) only authorizes processes spawned from the /usr/bin/mdo executable, and this is not configurable. By contrast, credentials transition rules are configurable and per-jail (via the sysctl(8) knob security.mac.do.rules and the mac.do.rules jail parameter). We would like to enable mac_do(4) to support a list of executable that are authorized to request credential transitions (with the aim to leverage mac_do(4) with user applications in the future), and to be able to specify a specific list for each jail (to accomodate thin or custom jail scenarios). The framework to do that basically already exists, as it has been developed to implement the above-mentioned handling of rules. This task thus consists in leveraging it, changing some of the internal structures that are associated to jails to hold the allowed paths list, modifying the code that needs to read the list in order to support parallel accesses, and coding accessors so that an administrator can control the list via sysctl(8) and jail parameters.
      mac_do(4) currently can only authorize credential transitions that are requested via the companion setcred(2) system call. The reason for the need of this specific system call is explained in more details in the 2024 Q3's status report but, in a nutshell, as mac_do(4) only authorizes configured credential transitions, it needs to see both the current process credentials state unmodified and the requested final one. However, each call to traditional and/or standard credentials-changing functions, such as setuid(2), seteuid(2), etc., can be considered as a (limited) full transition on its own, which mac_do(4) could decide upon. This functionality could allow to control transitions to root and, combined with that of the previous point, to install credentials-granting programs without the setuid bit set. An earlier version of mac_do(4) used to hook some of these calls, and lead to developing an infrastructure that helps to code fine-grained checks on top of the MAC framework interfaces, which are too limited for a straigtforward implementation, and in a safe manner with respect to parallel changes (e.g., to configured rules). (In mac_do(4)'s code, see in particular struct mac_do_data_header and struct mac_do_setcred_data.) Leveraging this infrastructure, the student is expected to code in mac_do(4) the appropriate MAC hooks for all traditional and/or standard credentials-changing functions.
      While mac_do(4) can log diagnostics on failure to set rules (because of syntax errors), it currently does not log whether it denies or accepts credentials transition requests. Having this functionality to diagnose rule problems and/or unauthorized accesses would be desirable. If time permits, we could consider adding audit logging in mac_do(4) proper, in addition to what is already present in the various credentials-changing system calls.
      
      ~~~~~~~~~~
      
      Port FreeBSD to QEMU MicroVM
      [last updated: 2025-01-24]
      Mentor
      Co-Mentor
      Tom Jones (willing to co-mentor) <thj AT FreeBSD DOT org>
      Skills
      C, intermediate
      Mid-term deliverable
      Drivers and kernel configuration to boot on QEMU MicroVM
      Duration
      175 or 350 hours
      Difficulty
      Medium
      Expected Outcome
      Stable port to QEMU MicroVM which is able to run some stress tests
      Example tasks:
      Write device drivers for QEMU MicroVM
      Create kernel configuration
      Create FreeBSD boot images for MicroVM
      There is an existing POC of this port, by thj@, but it is unstable and needs further investigation. A log of this effort is here: https://adventurist.me/posts/00320
      
      ~~~~~~~~~~
      Implement a new VLAN filtering software bridge
      [last updated: 2025-01-24]
      Mentor
      -
      Skills
      C (intermediate), networking (intermediate)
      Mid-term deliverable
      Dynamic interface creation and destruction, addition and removal of member interfaces, static forwarding + unknown destination flooding
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      The new pseudo driver can replace if_bridge(4) for jail and bhyve hosts
      The existing if_bridge(4) driver impedes FreeBSD suitability as a host for virtual machines and vnet enabled jails in design and implementation. Its configuration interface encourages misconfigurations by being too permissive, yet it lacks expected features.
      Other operating systems have encountered similar design problems with their respective bridge drivers. After two attempts, OpenBSD came up with a clean design we can learn from: veb(4) and vport(4).
      Our bridge member interfaces remain usable as IP capable interfaces which violates IP's (both v4 and v6) interface scope rules. Several bhyve and jail managers attempt to use this to add already configured network interfaces as member to bridges they manage with minimal changes to the host network configuration resulting in unreliable IPv4 and completely broken IPv6 processing. The new driver should restrict member interfaces to be only switch ports refusing to add member interfaces with configured IP addresses and prevent adding IP addresses to members.
      In its current state the if_bridge(4) driver does not support VLAN filtering between member interfaces. Neither adding the (untagged) network interfaces nor creating one bridge per VLAN nor and using vlan(4) interfaces as members provides the correct semantics needed. Using IPFW express VLAN filtering between member interfaces or a member interface and a bridge interface is both slow and error prone. The new bridge driver should perform per member port VLAN and MAC address filtering.
      Unlike if_bridge(4) the new driver should not be an IP capable network interface. Instead virtual member ports should be created to connect the host to the bridge, acting similar to one half on an if_epair(4).
      Such a bridge would also provide the groundwork to improve bhyve(8)'s para-virtualised networking with an if_tap(4) like member port supporting multiple bidirectional packet transfers with a single system call.
      
      ~~~~~~~~~~
      Testing and CI Integration for Rust Device Drivers
      [last updated: 2025-02-12]
      Mentor
      George Neville-Neil <gnn AT FreeBSD DOT org>
      Co-Mentor
      Skills
      C and Rust programming, intermediate; Experience with testing frameworks and CI systems is a plus
      Mid-term deliverables
      1. A test suite for an existing Rust-based FreeBSD kernel module. 2. Basic integration of tests into FreeBSD’s CI infrastructure
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      A framework for testing Rust-based FreeBSD kernel modules, ensuring correctness and stability. This includes writing tests for existing Rust driver code, validating behavior, and integrating the tests into FreeBSD’s continuous integration (CI) system.
      Example tasks:
      Identify and analyze existing Rust-based kernel modules and related work
      Develop unit tests for core components of a Rust driver
      Implement kernel-space testing techniques (e.g., fault injection, performance benchmarking)
      Integrate tests with FreeBSD’s CI system to ensure automated validation
      Explore and document best practices for writing and testing Rust drivers in FreeBSD
      Reference: https://wiki.freebsd.org/Rust#Rust_in_the_FreeBSD_Kernel
      
      
      ~~~~~~~~~~
      Implement native OpenBFS for FreeBSD
      [last updated: 2025-03-03]
      Mentor
      Pedro Giffuni <pfg AT FreeBSD DOT org>
      Skills
      C (intermediate), filesystems (intermediate)
      Mid-term deliverable
      Basic read-only support
      Duration
      350 hours
      Difficulty
      Hard
      Expected Outcome
      BeOS file system support
      The Be File System was developed by Dominic Giampaolo and Cyril Meurillon to provide BeOS with a modern 64-bit-capable journalling file system. For basic documentation on the filesystem, the Practical File System Design book is available. The project would be to bring BFS support for FreeBSD, perhaps considering some reuse of the open implementation made by Haiku-OS.
      
      ~~~~~~~~~~
      Unified kernel tracing interface
      [last updated: 2024-03-15]
      Mentor
      George Neville-Neil <gnn AT FreeBSD DOT org> (willing to co-mentor)
      Skills
      C (advanced), Kernel
      Mid-term deliverable
      Implementation available for amd64
      Duration
      350 hours
      Difficulty
      Hard
      Expected Outcome
      Existing consumers converted to use the new interface
      Description
      The FreeBSD kernel contains several subsystems which add hooks to core pieces of the kernel. For example, the context switch code in the scheduler contains this snippet:
              if (td != newtd) {
      #ifdef  HWPMC_HOOKS
                      if (PMC_PROC_IS_USING_PMCS(td->td_proc))
                              PMC_SWITCH_CONTEXT(td, PMC_FN_CSW_OUT);
      #endif
                      SDT_PROBE2(sched, , , off__cpu, newtd, newtd->td_proc);
      
      #ifdef KDTRACE_HOOKS
                      /*
                       * If DTrace has set the active vtime enum to anything
                       * other than INACTIVE (0), then it should have set the
                       * function to call.
                       */
                      if (dtrace_vtime_active)
                              (*dtrace_vtime_switch_func)(newtd);
      #endif
                      td->td_oncpu = NOCPU;
                      cpu_switch(td, newtd, mtx);
                      cpuid = td->td_oncpu = PCPU_GET(cpuid);
      
                      SDT_PROBE0(sched, , , on__cpu);
      #ifdef  HWPMC_HOOKS
                      if (PMC_PROC_IS_USING_PMCS(td->td_proc))
                              PMC_SWITCH_CONTEXT(td, PMC_FN_CSW_IN);
      #endif
      There are three hooks that may be called before switching into the new thread, and two hooks that may be called after the switch. They are used by DTrace and HWPMC to collect information about context switch events. These hooks are disabled most of the time, but each hook introduces overhead even when disabled since we must check whether it is enabled each time the code is executed.
      The goal of the project is to identify useful kernel tracepoints, and design and implement a unified interface that can be used by different consumers to collect information about the event corresponding to a particular tracepoint. This would make it easier for new subsystems to collect information from existing tracepoints, rather than modifying the core kernel to add more hooks. An additional aim would be to ensure that such tracepoints have minimal overhead, probably by using hot-patching to enable and disable a particular tracepoint. FreeBSD-CURRENT now uses clang 10.0, which implements the "asm goto" construct that could be useful here.
      
      ~~~~~~~~~~
      Add IPv6 scoped-address support in in-kernel ONC RPC and NFS
      [last updated: 2024-01-31]
      Mentor
      Hiroki Sato <hrs AT FreeBSD DOT org>
      Skills
      C (intermediate), Kernel (intermediate)
      Duration
      175 hours
      Difficulty
      Medium
      Expected Outcome
      NFS works with IPv6-scoped addresses
      FreeBSD’s NFS and other implementations relying on ONC RPC do not work with non-global IPv6-scoped addresses (e.g., link-local) because the RPC universal address format specified in RFC 5665 is used and it does not include the scope ID. This project aims to eliminate this limitation. The required steps are as follows:
      Implement a function handling text representation of an IPv6 address with the scope ID and replace inet_ntop() with it.
      Add support for IPv6-scoped address format to conversions between a taddr and a uaddr in the kernel.
      
      ~~~~~~~~~~
      Implement MPLS support for FreeBSD
      [last updated: 2023-01-27]
      Mentor
      Alexander Chernikov <melifaro AT FreeBSD DOT org>
      Skills
      C (intermediate), networking (intermediate)
      Mid-term deliverable
      MPLS forwarding works on static labels
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      MPLS forwarding, encap/decap works, MPLS labels can be programmed via Netlink
      Multiprotocol Label Switching (MPLS) is an overlay network technology based on labels instead of IP addresses. The project would be to bring basic MPLS support for FreeBSD. Roughly, the implementation can be split into the following chunks:
      create MPLS routing tables, analogous to AF_INET[6] routing tables
      add the logic to handle MPLS packets (mpls_input(), mpls_forward(), mpls_output()) at various stages
      add the code to perform MPLS encap for IPv4/IPv6 routes, extending nexthops functionality
      add Netlink support for working with IP-MPLS, MPLS-MPLS and MPLS-IP routes
      Add userland support for working with MPLS routes to route(8) and netstat(8)
      [stretch] add fast fib lookup module to enable high-performance concurrent label lookups
      The OpenBSD's MPLS stack or the NetBSD's MPLS stack overviews of other *BSD implementations can provide more datapoints.
      
      ~~~~~~~~~~
      
      Improve netgraph concurrency
      [last updated: 2023-01-27]
      Mentor
      Alexander Chernikov <melifaro AT FreeBSD DOT org>
      Skills
      C (intermediate), networking (intermediate)
      Mid-term deliverable
      Traffic is able to pass in a lockless fashion in 2-node netgraph topology
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      Traffic is able to pass in a lockless fashion between ng_<ppp|car|tee|iface>, compatibility retained with non-converted nodes
      Netgraph is a traffic-processing subsystem based on the dynamically configured graph of nodes and directed edges. Each node apply a single specific manipulation to the packet. The core idea is similar to VPP. Currently netgraph uses topology lock and node/hook atomic refcounts to ensure safe passing of the packets between the nodes. The goal of the project is to make passing data between the nodes lockless. The necessary primitives like epoch-based object reclamation and lockless datastructures are available in the base system. The rough implementation sketch may look like the following:
      Enable delayed reclamation of netgraph hooks and nodes under existing NET_EPOCH
      Make core API like ng_address_hook() leverage existing NET_EPOCH and avoid taking topology locks / refcounts
      Test the implementation with a number of stateless nodes like ng_patch or ng_tee and ng_ipfw
      Evaluate and convert nodes on per-node basis on their reliance on the topology lock
      
      ~~~~~~~~~~
      Userland projects
      mdo(1) improvements
      [last updated: 2025-01-28]
      Mentor
      Olivier Certner <olce AT FreeBSD DOT org>
      Skills
      C (intermediate), Security (intermediate preferred)
      Duration
      90 hours
      Difficulty
      Medium
      Expected Outcome
      New arguments to specify target groups. New mode to output mac_do(4) rules.
      Please see also the related project mac_do(4) improvements. To interested students: Please consider combining both in a single medium-duration project (175 hours). This related project's proposal provides an overview of what mac_do(4) is, and is recommended reading anyway.
      mdo(1) is the companion userland program to mac_do(4). It currently can run another program as a different user, either keeping the calling process' groups or replacing them with the new user's ones.
      Since the recent revamp of mac_do(4), an administrator can authorize fine-grained transitions of both user and group IDs. However, mdo(1) has not yet been updated to provide the required functionality. In particular, mdo(1) should be able to:
      Specify any list of target groups (primary or supplementary), possibly based on user names (an implicit list would be constructed from the related content of both /etc/passwd and /etc/group) but also allowing some tweaks (such as excluding a particular group in the final credentials).
      Allow changes of groups only in an easier way than the current interface (requires specifying the current user if it isn't root).
      Grow a mode producing the target part of mac_do(4) rules corresponding to the requested transition.
      If time permits, ponder on an architecture and implementation for requesting a password before calling setcred(2) in certain cases.
      
      ~~~~~~~~~~
      Port virtual_oss to base
      [last updated: 2025-01-27]
      Mentor
      Christos Margiolis <christos AT FreeBSD DOT org>
      Co-mentor
      Robert Clausecker <fuz AT FreeBSD DOT org>
      Skills
      C (advanced), FreeBSD programming environment (intermediate), DSP/maths (moderate), kernel (basic)
      Duration
      175 hours
      Difficulty
      Medium
      Expected Outcome
      virtual_oss part of the base system
      virtual_oss is an audio server written by Hans Petter Selasky for FreeBSD's sound system, OSS (Open Sound System), which provides support for (de-)multiplexing audio devices, switching audio devices on the fly, as well as bluetooth sound, among other features. FreeBSD currently lacks a built-in audio server, since virtual_oss is only provided as a port.
      The goal of the project is to successfully port virtual_oss to the base system and integrate it in programs and scripts that might benefit from using it.
      Even though this project is largely about integration, virtual_oss uses third-party libraries, namely libsamplerate and fftw3, which will most likely need to be replaced by rolling our own code in order to make virtual_oss completely standalone.
      
      ~~~~~~~~~~
      sockstat UI improvements
      [last updated: 2025-01-24]
      Mentor
      Alan Somers <asomers AT FreeBSD DOT org>
      Skills
      C (beginner)
      Duration
      90 hours
      Difficulty
      Easy
      Expected Outcome
      Rewrite sockstat's CLI with libxo and automatically sized tables
      Sockstat is a utility that prints details about any connected socket on the system. It's useful, but the current user interface is lacking. It could greatly benefit from libxo output, and it's also a good candidate for a C++ conversion. The entire -w option is an avoidable hack, if output were printed more intelligently. Most ambitiously of all, this program is fairly begging for some kind of "xo_print_table" function, that would automatically size the columns.
      
      ~~~~~~~~~~
      Network Configuration Libraries
      [last updated: 2024-01-29]
      Mentor
      Allan Jude <allanjude AT FreeBSD DOT org>
      Co-Mentor
      Christos Margiolis <christos AT FreeBSD DOT org>
      Skills
      C (intermediate), knowledge of networking and NAT
      Mid-term deliverable
      Library to configure IPFW NAT to allow a bhyve VM guest to reach the Internet
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      A library to manage NAT configuration for VMs and Jails
      Deliverables: A simple tool to configure the network on a laptop to allow a bhyve VM to access the internet.
      Use Cases:
      A bhyve VM running on a laptop NAT'd out the laptop's wifi connection
      A bhyve VM bridged to the hosts Ethernet network
      Stretch goal: Extend the tool to support configuring network access for standard and VIMAGE jails
      Build a libipfw to enable programmatic configuration of the firewall, implement basic functionality to add rules and configure NAT instances.
      Optional: relocate most functionality available in the command line interface into the library and replace the replace the command line interface with a thin wrapper around the new library.
      Build a libbsdnat that can be used by bhyve VM managers and Jail management tools to configure NAT on the host to allow the guest access to the internet via the host's network. This library will then be extended to handle creating 'port forwarding' rules to expose services in the guest to the public network via the host. Network mappings will be ephemeral and will need to be recreated by the management tools when the VM or jail is restarted.
      Possible design for final tool:
      libifconfig - used to create and manage bridge interface for bhyve, epairs for jails
      libbsdnat - Configure NAT for outbound, and port forward rules for inbound.
      libipfw - Used to insert rules routing traffic via above NAT instances.
      netlink - Used for network stack configuration
      
      ~~~~~~~~~~
      IPv6 support and cleanup of address family dependency in userland utilities
      [last updated: 2024-02-11]
      Mentor
      Hiroki Sato <hrs AT FreeBSD DOT org>
      Skills
      C (intermediate), networking (intermediate)
      Duration
      175 hours
      Expected Outcome
      More userland utilities with better IPv6 support
      Many of our tools are not IPv6 "clean", such as these tools:
      rwhod(8)
      Various yp(8) daemons
      rpc.rquotad(8)
      This project could also include a broader survey of other network services in /usr/bin and /usr/sbin to make sure they're all IPv6 clean. Other possible work could involve
      remove/rework the about 200 gethostby*() calls all in the base system and contrib to use getaddrinfo().
      make more code to conditionally compile in INET or INET6 support.
      
      ~~~~~~~~~~
      Speed up the FreeBSD boot process
      [last updated: 2024-01-12]
      Mentor
      Colin Percival <cperciva AT FreeBSD DOT org>
      Skills
      C (intermediate), sh (intermediate), kernel (beginner)
      Mid-term deliverable
      Targets for boot speedup identified and some addressed
      Duration
      175 hours
      Difficulty
      Medium
      Expected Outcome
      FreeBSD will boot faster
      Using the TSLOG framework and one or more systems running FreeBSD, profile the boot process and identify targets for improving boot performance. This is likely to involve delving into multiple different parts of FreeBSD, ranging from the kernel to daemons launched from rc.d scripts; there are likely a large number of places where improvements can be made, and work will be guided by the amount of time which could potentially be saved and the likely complexity of making improvements. In many cases, a student will need to collaborate with other FreeBSD developers familiar with different parts of the system.
      
      ~~~~~~~~~~
      syzkaller improvements
      [last updated: 2020-03-04]
      Mentors
      Skills
      golang (intermediate), kernel (intermediate)
      Duration
      350 hours
      Difficulty
      Hard
      Expected Outcome
      Complete FreeBSD syzkaller extenstions described below
      syzkaller is a suite of tools that performs coverage-guided system call fuzzing. Originally targeting Linux, it can now fuzz many different operating system kernels and has been extremely effective at finding bugs, many with security implications. It creates, monitors and fuzzes a set of virtual machines running the target kernel. More information can be found in its documentation, and in these slides. Google kindly runs a public syzkaller instance targeting FreeBSD.
      For a while it has been possible to run syzkaller on FreeBSD; that is, fuzz FreeBSD on FreeBSD. syzkaller makes use of ZFS and bhyve (or QEMU) to do so. This makes development and testing of FreeBSD-specific syzkaller features much easier.
      Though syzkaller has found quite a few bugs in FreeBSD, it does not cover as much as it does on Linux, so it is virtually guaranteed that there are plenty of bugs waiting to be found. This project consists of several subtasks that would improve FreeBSD's coverage:
      Extend syzkaller's FreeBSD system call descriptions. For each system call, syzkaller requires a set of annotations that describe the system call's arguments. It is missing many of FreeBSD's system calls. syzkaller similarly needs to be taught about device-specific ioctls.
      Support fuzzing of FreeBSD's Linux system call compatibility layer. Since syzkaller can of course fuzz Linux natively, it should be straightforward to run a Linux fuzzer on FreeBSD.
      Support external injection of USB traffic.
      Support running the fuzzer in a jail, optionally with various resource limits in place.
      Test syzkaller with a ZFS root filesystem instead of UFS. Work with the syzkaller developers to get a FreeBSD+ZFS target running in syzbot.
      Port support for automated patch testing and crash bisection to FreeBSD. Some details are listed here.
      Work with the project mentor to triage and possibly fix any kernel bugs found in the process.
      Note: contributing to syzkaller requires signing the Google CLA. Please make sure that this is acceptable before attempting this project. Note also that working with syzkaller is probably easiest on a dedicated hardware system with a reasonably large amount of disk space (several hundred GB should be sufficient), ideally running FreeBSD on ZFS. syzkaller can instantiate VMs on Google Compute Engine and fuzz them, so this may be an option as well. Please contact the project mentors for details.
      
      ~~~~~~~~~~
      Capsicumization of the base system
      [last updated: 2020-03-02]
      Mentor
      Mariusz Zaborski <oshogbo AT FreeBSD DOT org>
      Co-Mentor
      Mark Johnston <markj AT FreeBSD DOT org>
      Skills
      C (intermediate), familiarity with the UNIX programming environment
      Mid-term deliverable
      Sandbox a few of the target applications
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      Sandbox the complete list of target applications
      Capsicum is a sandboxing technology used in FreeBSD. It is complemented by Casper, a framework for defining application-specific capabilities. A large number of utilities in the FreeBSD base system have been converted to run under Capsicum and Casper, but many programs have yet to be converted. The project would consist of identifying several high-profile daemons and utilities in the base system or ports, and modifying them to run in capability mode. One good candidate is syslogd, the system logging daemon.
      As part of this work it may be necessary or useful to add additional Casper services to the base system. For example, we do not yet have a Casper service which allows an application to make outbound network connections.
      Note: Converting applications to run under Capsicum/Casper can take a lot of effort, especially when they are large or when they are not designed with privilege separation in mind. Some applications, like a shell, can't really be run in capability mode at all. Before attempting to sandbox a given application, take care to study the ways in which it interacts with the system. For example, does the application need to open any files? If so, are the file names statically defined or are they derived from user input? This will provide insight into the difficulties that will arise when sandboxing the application.
      
      ~~~~~~~~~~
      Add QCOW2 compressed image support to mkimg(1)
      [last updated: 2025-02-04]
      mkimg(1) is a FreeBSD tool used for creating disk images in various formats, such as raw images, QCOW/QCOW2, VHD/VHDX, and VMDK. However, it currently lacks support for creating compressed QCOW2 (QEMU Copy-On-Write v2) images. QCOW2 is widely used in virtualization due to features like snapshot support, compression, and efficient disk space utilization through sparse file support.
      Integrating QCOW2 compression into mkimg(1) would extend its utility, allowing FreeBSD users to generate smaller QCOW2 images directly without relying on external tools. This enhancement will benefit those deploying FreeBSD in virtualized environments.
      There are (currently) two QCOW2 versions: v2 and v3. v2 supports only deflate (zlib) compression; v3 adds support for zstd. mkimg currently implements v2 support, without compression. The minimum scope for this project is implementing zlib compression, but the project may be made larger by support for QCOW2 v3 and zstd compression.
      This project will also include improvements to the mkimg test suite, in order to properly test the new functionality.
      References: QCOW2 spec https://github.com/qemu/qemu/blob/master/docs/interop/qcow2.txt
      Mentor
      Ed Maste <emaste AT FreeBSD DOT org>
      Skills
      C (Intermediate)
      Duration
      175 hour
      Difficulty
      Medium
      Expected Outcome
      mkimg can produce a compressed QCOW2 image, which can be successfully used with QEMU
      
      ~~~~~~~~~~
      Tools
      Improve LLDB on FreeBSD
      [last updated: 2024-03-12]
      Co-Mentors
      Ed Maste <emaste AT FreeBSD DOT org> , Moin <bofh AT FreeBSD DOT org>
      Skills
      shell scripting (intermediate), Lua (intermediate), debugger use (basic)
      Mid-term deliverable
      crashinfo invokes LLDB and extracts backtrace, subset of Lua bindings enabled
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      LLDB Lua bindings at feature parity with Python bindings, crashinfo script successfully uses in-tree debugger, lldb
      The LLVM debugger, lldb, is part of the FreeBSD base system. This project aims to extend lldb on FreeBSD in two ways.
      1. Improve lldb Lua bindings
      lldb supports scripting in C++, Python, and Lua. The Lua bindings are a more recent addition, and some features that would make them much more usable on FreeBSD are missing. The first goal of this project is to improve Lua binding support, add documentation, and bring the Lua bindings to parity with the Python bindings.
      Example tasks:
      Enable Lua bindings to create new LLDB commands
      Generate Lua documentation similar to the Python documentation
      Write a tutorial for scripting LLDB with Lua
      Add convenience methods to support common FreeBSD kernel debugging tasks from Lua, such as those described in https://freebsdfoundation.org/wp-content/uploads/2019/01/Debugging-the-FreeBSD-Kernel.pdf
      2. Integration lldb into crashinfo
      FreeBSD provides a script, /usr/sbin/crashinfo, which runs after a system (kernel) crash and extracts information from the core dump to store in a text file. See the crashinfo man page for more information. crashinfo currently makes use of the GNU debugger, gdb, which must be installed from the package collection or ports tree. The second goal of this project will be to add lldb support to crashinfo, providing the same information that crashinfo's gdb integration provides. (gdb support should be retained in the script and used when gdb is available).
      
      ~~~~~~~~~~
      GEOM management UI
      [last updated: 2025-01-30]
      Mentor
      Robert Clausecker <fuz AT FreeBSD DOT org>
      Co-Mentor
      Joe Mingrone <jrm AT FreeBSD DOT org>
      Skills
      UI development, disk management
      Mid-term deliverable
      partially functional tool
      Duration
      175 or 350 hours
      Difficulty
      Medium
      Expected Outcome
      a working GUI/TUI manager for GEOMs, especially partitions
      On Linux, many users use the graphical gparted utility for disk and partition management. Such a utility is currently missing on FreeBSD; users have to make use of somewhat unintuitive command line utilities to set up disks. It would be great if that hole could be filled.
      The goal of this project is to have a partition management utility similar to gparted, but for FreeBSD. It could also mean porting gparted to FreeBSD. If this project is taken as a long (350 hours) project, it might be interesting to extend the utility to more GEOM classes, such as gstripe(8), geli(8), glabel(8), and gmirror(8). The management tool will be developed in a separate repository. It can be written in any programming language supported on FreeBSD, though ideally one that works on all architectures we support. The interaction with GELI can be done through libgeom(3) or by wrapping the various GEOM command line utilities. The project could be done either as a curses-based TUI or a GUI for X11/Wayland.
      Once a viable prototype (mid-term deliverable) is complete, the project is added to the FreeBSD ports collection. If a TUI and free of third-party dependencies, it could later be added to the base system.
      
      ~~~~~~~~~~
      WiFi Management UI
      [last updated: 2025-01-31]
      Mentor
      Getz Mikalsen <getz AT FreeBSD DOT org>
      Co-Mentor
      Aymeric Wibo <obiwac AT FreeBSD DOT org>
      Skills
      C (intermediate), familiarity with the UNIX programming environment
      Mid-term deliverable
      List networks and interact with them
      Duration
      175 hours
      Difficulty
      Medium
      Expected Outcome
      A new UI for easy connection to Wi-Fi networks
      Many new users install FreeBSD on their laptops but miss utilities common on other systems like Linux, our current tools are a bit obtuse. This project aims to bring some of those niceties to FreeBSD. This project proposes a tool that can act as nice single entry point to list available networks and connect and save configurations.
      The tool could be implemented as a REPL like iwctl on linux or as a TUI although the latter is preferred. The project can be completed in any programming language supported on FreeBSD (C, Rust, etc.) although some knowledge of C is expected. Once a viable prototype (mid-term deliverable) is complete, the project can be added to the FreeBSD ports collection. If free of third-party dependencies, it could later be added to the base system.
      PS. We are also very open to other project ideas revolving around things that makes life easier when using a laptop.
      
      ~~~~~~~~~~
      Power profiling tool
      [last updated: 2025-02-04]
      Mentor
      Aymeric Wibo <obiwac AT FreeBSD DOT org>
      Co-mentor
      Tom Jones <thj AT FreeBSD DOT org>
      Skills
      C (intermediate), kernel (intermediate)
      Mid-term deliverable
      Be able to roughly determine which processes are waking the CPU from idle the most.
      Duration
      175 or 350 hours
      Expected Outcome
      Expected outcome for final term is to have a tool equivalent to powertop on Linux.
      Currently, the only power statistics you can get on FreeBSD is the whole system's power consumption (reported by ACPI). If a certain process is using up a lot of power or something else is causing high power consumption, it can be difficult to debug this. This project aims to either port powertop from Linux to FreeBSD or write a wholly new tool.
      If we go the route of porting powertop as-is, this could be made into a port, but ideally we'd have a tool in the base system for doing this. It might also be interesting for this tool to run a suspend test and report common issues similar to what the amd_s2idle.py script does for AMD Linux systems.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-freebsd-project/
    idea_list_url: https://wiki.freebsd.org/SummerOfCodeIdeas

  - organization_id: 152
    organization_name: The Honeynet Project
    no_of_ideas: 8
    ideas_content: |
     
      #1 - BuffaLogs: new alert notifications
      Mentor: Federico Foschini
      Project type: Improving an existing tool
      URL: https://github.com/certego/BuffaLogs
      Expected Project hours: 90 - 175 based on received proposal
      
      BuffaLogs currently does not support alert notification. We are expanding the system to allow alert be sent to various destinations.
      Project Objectives:
      Developing alert notifications for one or more of the following sources, depending on the project timeline:
      Email
      Http request
      Slack
      Additional sources to be considered based on project scope
      Technical Requirements:
      Develop modular and maintainable Python code for each implemented connector
      Create comprehensive unit tests and integration tests
      Provide detailed documentation

      ~~~~~~~~~~
      #2 - BuffaLogs: new ingestion sources
      Mentor: Federico Foschini
      Project type: Improving an existing tool
      URL: https://github.com/certego/BuffaLogs
      Expected Project hours: 90 - 175 based on received proposal
      
      BuffaLogs currently supports data ingestion exclusively from Elasticsearch. To enhance its functionality and versatility, we are expanding the system to accommodate multiple data sources.
      Project Objectives:
      Developing connectors for one or more of the following sources, depending on the project timeline:
      Relational Databases (MySQL, Postgres, etc.)
      File-based Data Sources (CSV, JSON)
      AWS CloudTrail Logs
      Additional sources to be considered based on project scope
      Technical Requirements:
      Develop modular and maintainable Python code for each implemented connector
      Create comprehensive unit tests and integration tests
      Provide detailed documentation
      
      ~~~~~~~~~~
      #3 - IntelOwl improvements: analyzers and integrations
      Mentor: Matteo Lodi, Daniele Rosetti, Federico Gibertoni
      Project type: Improving an existing tool
      URL: https://github.com/intelowlproject/IntelOwl
      Expected Project hours: 175
      
      This projects aims to improve the tests implemented in IntelOwl, in particular the ones regarding the Analyzers.
      Right now, the actual implementation is kinda limited due to the inheritance of a framework built years ago, based on monkeypatching the tests.
      The goal is to refactor this framework in a way that is easier to use and, at the same time, that it allows better tests implementation.
      A thorough explanation of the problem and deliverables is described here.
      This is a time-consuming project that requires focus and attention. We expect the contributor to refactor most of the analyzers’ tests and write additional checks.
      The ideal candidate for this project is someone who understand how IntelOwl’s framework works and knows testing frameworks like unittest very well.
      
      ~~~~~~~~~~
      #4 - Extending the Artemis scanner
      Mentor: Krzysztof Zając
      Project type: Improving an existing tool
      URL: https://github.com/CERT-Polska/Artemis
      Expected Project hours: 175 or 350 hours
      
      Artemis is a modular vulnerability scanner that checks multiple aspects of website security and builds easy-to-read messages to send to organizations to get the vulnerabilities fixed. Multiple national-level CSIRTs use it to improve the security of their constituencies - for example, since 2023, CERT PL has used Artemis to find and report more than half a million vulnerabilities.
      The goal is to improve the number and quality of detected vulnerabilities. There may be multiple ways of achieving this goal:
      Extend Artemis with modules detecting new types of vulnerabilities (for example, by integrating existing open-source tools),
      Improve Artemis in other aspects such as performance or ease of use.
      The primary required skills are Python programming and familiarity with Linux and Docker. Familiarity with web security topics is also desired.
      
      ~~~~~~~~~~
      #5 - IntelOwl improvements: analyzers and integrations
      Mentor: Matteo Lodi, Daniele Rosetti, Federico Gibertoni
      Project type: Improving an existing tool
      URL: https://github.com/intelowlproject/IntelOwl
      Expected Project hours: 90 - 175 based on received proposal
      
      Right now we have a lot of Analyzers implemented in IntelOwl.
      But they are not enough! They are one of the core parts of the application so we want to add even more of them!!!! :)
      This project aims to increment the number of available Analyzers and adjusting the old ones that are not working anymore as intended. We have about 10 different Analyzers that has been requested by the community members in Github and are still not implemented. Plus we have other analyzers that requires intervention, like Yara, YETI, DNS Detectors and so on.
      Plus, we would like this project to carry additional non-Analyzer related work, like the addition of new Ingestors or Playbooks for instance, which are pretty similar components.
      Another optional and very different task could be to add support for Podman for the overall project as an alternative of Docker. This would require working more with the documentation and the core parts of the projects.
      The ideal candidate for this project is someone who understand how IntelOwl’s framework works and already tried to implement some Analyzers.
      
      ~~~~~~~~~~
      #6 - Improving the SweetCam IP camera honeypot
      Mentor: Emmanouil Vasilomanolakis, Dario Maddaloni, Artur Cordeiro Urbano
      Project type: Improving an existing tool
      URL: https://github.com/Agachily/sweetcam
      Expected Project hours: 175 or 350 hours
      
      SweetCam is an open-source honeypot designed to emulate IP camera behaviors with minimal setup while offering robust modularity for extending functionality. It is built to support the emulation of key protocols commonly used by IP cameras, including SSH, RTSP, and HTTP. A distinguishing feature of SweetCam is its ability to create a realistic web interface resembling an IP camera’s dashboard. This includes a login page and a simulated camera interface that can be customized using user-defined 360-degree video streams and images, making it highly adaptable to various use cases. The modular architecture of SweetCam ensures flexibility, allowing users to easily integrate support for new camera models and configurations. By providing a realistic medium-interaction environment, SweetCam effectively lures and studies attackers targeting IP cameras, offering valuable insights for cybersecurity research and network defense strategies.
      GSoC 2025
      Outcomes
      template-based device emulation
      new protocol support
      enhance Docker Usability (Automation & Base setup)
      Various improvements: Error based handling on HTTP page, Language Button at HTTP page, forgot password, implementation of sound, day/night configurations
      Skills Preferred
      Basic Linux/Command Line skills
      Docker
      Shell, JavaScript

      ~~~~~~~~~~
      #7 - Improving the DICOMHawk medical honeypot
      Mentor: Emmanouil Vasilomanolakis, Karina Elzer, Georgios Theodoridis
      Project type: Improving an existing tool
      URL: https://github.com/gtheodoridis/DICOMHawk
      Expected Project hours: 175 or 350 hours
      
      DICOMHawk is a powerful and efficient honeypot for DICOM servers, designed to attract and log unauthorized access attempts and interactions. Built using Flask and pynetdicom, DICOMHawk offers a streamlined web interface for monitoring and managing DICOM interactions in real-time.
      Features
      DICOM Server Simulation: Supports C-ECHO, C-FIND, and C-STORE operations to simulate a realistic DICOM server environment.
      Logging: Detailed logging of DICOM associations, DIMSE messages, and event-specific data to track and analyze potential attacks.
      Web Interface: A user-friendly web interface to view server status, active associations, and logs.
      Custom Handlers: Easily extendable to support additional DICOM services and custom logging or handling requirements.
      GSoC 2025
      Outcomes
      Examine a potential integration with TPot
      Improve Docker usage (Security & Automation)
      Improve logging capabilities
      Integrate CanaryToken Webhook
      Potentially add additional protocol
      Documentation of the Implementations
      Testing
      Skills Preferred
      Basic Linux/Command Line skills
      Docker
      Python

      ~~~~~~~~~~
      #8 - Implementing Protocol Parsers for Glutton Using Spicy
      Mentor: Muhammad Bilal Arif
      Project type: Improving an existing tool
      URL: https://github.com/mushorg/glutton
      Expected Project hours: 175 or 350 hours
      
      Glutton is a powerful Generic Low Interaction Honeypot designed to emulate various network services and capture malicious activity for security analysis. Its strength lies in its generic nature, supporting a wide range of network protocols.
      The goal of this project is to:
      Develop a Go wrapper to integrate Spicy with Glutton.
      Implement protocol parsers for HTTP and DNS as initial examples.
      Provide documentation to explain the implementation.
      The primary required skill is proficiency in Go programming and familiarity with Linux networking.
      An understanding of network monitoring tools like Spicy or similar is a nice-to-have skill.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-honeynet-project/
    idea_list_url: https://www.honeynet.org/gsoc/gsoc-2025/google-summer-of-code-2025-project-ideas/

  - organization_id: 153
    organization_name: The JPF team
    no_of_ideas: 6
    ideas_content: |
  
      Support Java 11/17 for JPF extensions
      Description: jpf-core is essentially a JVM that currently fully supports only Java 8 and Java 11 (with limitations on bootstrap methods). Bootstrap methods are currently interpreted, which works for common usage but may not work for advanced cases. The goal of this project is to generate the call site code on the fly so bootstrap methods work as on the host JVM.
      Difficulty: Hard
      Scope: 350 hours
      Required skills: Knowledge of Java bytecode
      Preferred skills: Knowledge of private Java APIs Possible Mentors: Cyrille
      
      ~~~~~~~~~~
      Support for Java 17 for jpf-core
      Related to the project above, there are also some new features in Java 17 that are not yet supported by JPF. We have work in progress on branch java-17. Currently unsupported Java features include language features that are not supported at run time (e.g., records) and Java language features that are not fully analyzed (e.g., sealed classes). In this project, you would identify such unsupported features and extend JPF (jpf-core) to support them.
      Difficulty: Medium
      Scope: 175 hours
      Required skills: Knowledge of Java internals
      Possible Mentors: Cyrille

      ~~~~~~~~~~
      Robustify String solving for SPF
      Description: The goal of this project is to test SPF integration with Z3 string constraint solving; adding support cvc5 is a plus. This project will extend SPF branch sv-comp.
      Difficulty: Hard
      Scope: 350 hours
      Required skills: Knowledge of Symbolic Pathfinder
      Preferred skills: Knowledge of String constraint solving.
      Possible Mentors: Corina, Elena, Soha

      ~~~~~~~~~~
      Support runtime exception in SPF
      Description: The main goal of this project is to support throwing a runtime exception for some of the summarized functions such as String.substring. Also, this project should build on SPF Java 11 Gradle support, which implies fixing existing issues. This project will extend SPF branch sv-comp.
      Difficulty: Meduim
      Scope: 175 hours
      Required skills: Knowledge of Symbolic Pathfinder
      Possible Mentors: Soha

      ~~~~~~~~~~
      Support portfolio of solvers in SPF
      Description: The main goal of this project is to enable the simultaneous invocation of multiple solvers, terminating the wait as soon as any solver returns a satisfiable result. This approach is expected to enhance SPF's ability to handle a broader range of constraints. This project will extend SPF branch sv-comp.
      Difficulty: Hard
      Scope: 350 hours
      Required skills: Knowledge of Symbolic Pathfinder
      Preferred skills: Expeirence with various solvers
      Possible Mentors: Soha

      ~~~~~~~~~~
      Use LLM to generate sound reduction rules in SPF
      Description: Solver constraints can become very complex, and very large. In this project, we will use LLM in SPF to identify sound reduction rules that can be applied to the constraints before sending them to the solver, ideally improving its performance. See this paper for reference. This project will extend SPF branch sv-comp.
      Difficulty: Hard
      Scope: 350 hours
      Required skills: Knowledge of Symbolic Pathfinder
      Preferred skills: LLM
      Possible Mentors: Soha
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-jpf-team/
    idea_list_url: https://github.com/javapathfinder/jpf-core/wiki/GSoC-2025-Project-Ideas

  - organization_id: 154
    organization_name: The Julia Language
    no_of_ideas: 76
    ideas_content: |

      
      
      ClimaExplorer: An Interactive Visualizer of Climate Model Outputs
      Visualizing simulation output is crucial for both scientific understanding and outreach. This project involves developing ClimaExplorer, an interactive visualizer for the output of the CliMA Earth system model. ClimaExplorer will leverage the Makie ecosystem and web technologies, providing a user-friendly interface for exploring complex climate data. This will enable researchers to more easily analyze and interpret simulation results, accelerating scientific discovery. Furthermore, the web-based component will facilitate broader dissemination of results to a wider audience.

      Desired Skills: Familiarity with front-end web development (HTML, JavaScript, and CSS), Julia, and Makie.

      Difficulty: Medium

      Duration 175 hours

      Expected Results: ClimaExplorer, a new module for interactive visualization of simulation output (with tests and documentation).

      Mentor: Gabriele Bozzola

      Contact: Feel free to ask questions via email or Julia Slack (DM to Gabriele Bozzola).

      Interested in other aspects of climate modeling in Julia but not this particular project? Get in touch—we have many more projects!

      
      ~~~~~~~~~~
      
      

      Better debug information output for variables (175 hours)
      We have part of the infrastructure in place for representing DWARF information for our variables, but only from limited places. We could do much better since there are numerous opportunities for improvement!

      Expected Outcomes: Ability to see more variable, argument, and object details in gdb

      Recommended Skills: Most of these projects involve algorithms work, requiring a willingness and interest in seeing how to integrate with a large system.

      Difficulty: Medium

      Mentors: Jameson Nash, Gabriel Baraldi

      ~~~~~~~~~~

      Improving test coverage (175 hours)
      Code coverage reports very good coverage of all of the Julia Stdlib packages, but it's not complete. Additionally, the coverage tools themselves (–track-coverage and https://github.com/JuliaCI/Coverage.jl) could be further enhanced, such as to give better accuracy of statement coverage, or more precision. A successful project may combine a bit of both building code and finding faults in others' code.

      Another related side-project might be to explore adding Type information to the coverage reports?

      Recommended Skills: An eye for detail, a thrill for filing code issues, and the skill of breaking things.

      Contact: Jameson Nash

      ~~~~~~~~~~

      Tensor network contraction order optimization and visualization – Summer of Code
      OMEinsum.jl is a pure Julia package for tensor network computation, which has been used in various projects, including

      GenericTensorNetworks.jl for solving combinatorial optimization problems,

      YaoToEinsum.jl for simulating large scale quantum circuit and

      TensorInference.jl for Bayesian inference.

      Unlike other tensor contraction packages such as ITensors.jl and TensorOperations.jl, it is designed for large scale tensor networks with arbitrary topology. The key feature of OMEinsum.jl is that it can automatically optimize the contraction order of a tensor network. Related features are implemented in OMEinsumContractionOrders.jl.

      We are looking for a student to work on the following tasks:

      Implement a better contraction order optimizer based on Tamaki's algorithm.

      Implement a hyper-graph visualization tool based on arXiv:2308.05043

      Port the contraction order optimizers to TensorOperations.jl

      Recommended skills: familiarity with tensor networks, graph theory and high performance computing.

      Expected results:

      new features added to the package OMEinsumContractionOrders.jl along with tests and relevant documentation.

      a new package about hyper-graph visualization, and relevant feature added to OMEinsum.jl.

      a pull request to TensorOperations.jl for better contraction order optimization.

      Mentors: Jin-Guo Liu, Jutho Haegeman and Lukas Devos

      Project difficulty: Medium to Hard

      Project length: 350 hrs

      Contact: feel free to ask questions via email or the Julia slack (user name: JinGuo Liu).
  
      ~~~~~~~~~~
      
      Documentation tooling – Summer of Code
      Documenter.jl
      The Julia manual and the documentation for a large chunk of the ecosystem is generated using Documenter.jl – essentially a static site generator that integrates with Julia and its docsystem. There are tons of opportunities for improvements for anyone interested in working on the interface of Julia, documentation and various front-end technologies (web, LaTeX).

      Here are some features or areas that are looking for contributions:

      User-contributed notes and examples to documentation (e.g. backed by GitHub Discussions).

      One-page-per-function documentation listings (prototype for main Julia manual). See JuliaDocs/Documenter.jl#2133.

      JuliaSyntax-based code highlighter for Julia code that can be re-used for both the HTML and LaTeX/PDF output.

      Rework Documenter's page layout and navigation. See JuliaDocs/Documenter.jl#2177.

      Improve or rework Documenter's search index.

      Work on any of the ideas that have been marked as plugins, as they offer self-contained features to work on.

      If any of these sound interesting, please reach out to the mentors to ask for more details and to narrow down the project for a proposal. The possible projects vary in difficulty and size, depending on the project and the ultimate scope.

      Recommended skills: Depends on the project, but the work would generally involved both Julia programming, but also basic web development (HTML, CSS, JS).

      Mentors: Morten Piibeleht, Fredrik Ekre

      Contact
      Best way to reach out is to message in the #documentation channel on the JuliaLang Slack!

      
      ~~~~~~~~~~
      
      FastDifferentiation.jl – Summer of Code
      FastDifferentiation.jl is a Julia package for computing very efficient symbolic derivatives of Julia functions and for compiling the derivatives into efficient executables. It can differentiate much larger expressions than other symbolic systems, such as Symbolics.jl, and the resulting derivatives are also much more efficient, rivaling hand computed derivatives in some cases (see the website for benchmark examples).

      FastDifferentiation.jl also computes the exact sparsity patterns of Jacobians and Hessians (and any other order derivative) and detects common terms in derivatives of Rⁿ->Rᵐ functions for large n,m. As a consequence computation time of Jacobians generally scales sub-linearly as a function of n,m.

      However, the current system has several weaknesses. It is not currently possible to differentiate through conditional expressions so many commonly used Julia functions cannot be differentiated. Derivatives of any order can be computed but orders above 3 or 4 become increasingly inefficient. These projects aim to address these weaknesse.

      Add Conditionals to FastDifferentiation.jl
      FastDifferentiation supports conditionals in function definitions but cannot yet compute derivatives of functions with conditionals:

      julia> @variables x y

      julia> f = if_else(x>y,x^2,y^2)
      (if_else  (x > y) (x ^ 2) (y ^ 2))

      julia> derivative(f,x)
      ERROR: Your expression contained a if_else expression. FastDifferentiation does not yet support differentiation through this functionCopy
      The goal of this project is to modify the derivative graph analysis code so that it detects conditional subgraphs and then generates run time code to evaluate conditionals and branches to correct derivative expressions.

      Medium difficulty, 175 hours.

      Recommended Skills: Julia programming experience, previous work with graph algorithms helpful but not required.

      Expected Outcome: Well-tested and well-documented support for conditionals.

      Mentor: BrianGuenter

      ~~~~~~~~~~

      Add higher order derivatives to FastDifferentiation.jl
      FastDifferentiation.jl produces extremely efficient first derivatives. But, higher order derivatives become increasingly less efficient since they are computed by repeatedly applying the differentiation algorithm.

      The fundamental cause of this behavior is that repeated higher order intermediate derivative terms are not detected and reused; instead they are computed from scratch. The goal of this project is to extend the FastDifferentiation algorithm to detect these common higher order terms and to reuse, rather than recompute them.

      This will require a rewrite of the graph factorization code as well as some theoretical work to determine which higher order terms can be reused.

      Hard, 350 hours.

      Recommended Skills: Julia programming experience, previous work with graph algorithms helpful but not required. Understanding of Faa Di Bruno's and Leibniz's rule.

      Expected Outcome: Well-tested and well-documented support for higher order derivatives.

      Mentor: BrianGuenter

      ~~~~~~~~~~

      Integrate FastDifferentiation.jl into Symbolics.jl
      FastDifferentiation.jl uses a new symbolic algorithm for automatic differentiation that can be orders of magnitude faster than conventional symbolic differentiation methods. Symoblics.jl could compute derivatives much faster using the FastDifferentiation algorithm. However implementation and data structure differences between the two systems make it difficult to add FastDifferentiation capabilities to Symbolics.jl.

      For example, Symbolics.jl allows you to define a function 
      q
      (
      t
      )
      q(t) and then to compute a symbolic derivative 
      q
      ˙
      (
      t
      )
      q˙​(t) without defining 
      q
      q. Adding this capability to FastDifferentiation.jl requires a change in the graph representation of derivatives.

      The goal of this project is to first analyze the sources of the incompatibilities between the two systems and then to modify FastDifferentiation.jl, and perhaps Symbolics.jl, so that they interoperate.

      See this page for a more detailed description of tasks.

      Medium difficulty, 175 hours.

      Recommended Skills: Julia programming experience, previous work with graph algorithms helpful but not required.

      Expected Outcome: Well-tested and well-documented integration of FastDifferentiation into Symbolics.jl.

      Mentor: BrianGuenter


      ~~~~~~~~~~

      

      
      Fluid-Structure Interaction Example
      Difficulty: Easy-Medium (depending on your specific background)

      Project size: 150-300 hours

      Problem: Ferrite.jl is designed with the possibility to define partial differential equations on subdomains. This makes it well-suited for interface-coupled multi-physics problems, as for example fluid-structure interaction problems. However, we currently do not have an example showing this capability in our documentation. We also do not provide all necessary utilities for interface-coupled problems.

      Minimum goal: The minimal goal of this project is to create a functional and documented linear fluid-structure interaction example coupling linear elasticity with a stokes flow in a simple setup. The code should come with proper test coverage.

      Extended goal: With this minimally functional example it is possible to extend the project into different directions, e.g. optimized solvers or nonlinear fluid-structure interaction.

      Recommended skills:

      Basic knowledge the finite element method

      Basic knowledge about solids or fluids

      The ability (or eagerness to learn) to write fast code

      Mentors: Dennis Ogiermann and Fredrik Ekre

      ~~~~~~~~~~

      Investigation of Performant Assembly Strategies
      Difficulty: Medium

      Project size: 250-350 hours

      Problem: Ferrite.jl has an outstanding performance in single-threaded finite element simulations due to elaborate elimination of redundant workloads. However, we recently identified that the way the single-threaded assembly works makes parallel assembly memory bound, rendering the implementation for "cheap" assembly loops not scalable on a wide range of systems. This problem will also translate to high-order schemes, where the single-threaded strategy as is prevents certain common optimization strategies (e.g. sum factorization).

      Minimum goal: As a first step towards better parallel assembly performance it is the investion of different assembly strategies. Local and global matrix-free schemes are a possibility to explore here. The code has to be properly benchmarked and tested to identify different performance problems.

      Extended goal: With this minimally functional example it is possible to extend the project into different directions, e.g. optimized matrix-free solvers or GPU assembly.

      Recommended skills:

      Basic knowledge the finite element method

      Basic knowledge about benchmarking

      The ability (or eagerness to learn) to write fast code

      Mentors: Maximilian Köhler and Dennis Ogiermann

      ~~~~~~~~~~

      

      Efficient classical simulations of linear combinations of Gaussian quantum states
      Non-Gaussian quantum states cannot be simulated via their first- and second-order statistical moments in the phase space representation like Gaussian states. However, there exist fast classical algorithms for simulating superpositions of Gaussian states, which are non-Gaussian in nature. This project involves implementing such algorithmic support for analyzing certain classes of non-Gaussian states.

      Recommended skills: In-depth understanding of the quantum phase space formalism. This paper and also this paper are useful references.

      Mentors: Andrew Kille and Stefan Krastanov.

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Medium

      ~~~~~~~~~~

      Matrix product state representations of Gaussian and non-Gaussian quantum states
      A matrix product state (MPS) is a valuable tensor network method for simulating quantum many-body systems. In particular, large continuous variable quantum systems that contain low entanglement can be simulated extremely fast with the MPS method. This project involves implementing support for MPS representations of Gaussian and non-Gaussian systems.

      Recommended skills: In-depth understanding of the quantum phase space formalism. In addition, familiarity with tensor network methods and software such as ITensors.jl. For this project, this paper and also this paper are useful references.

      Mentors: Andrew Kille and Stefan Krastanov.

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Hard


      ~~~~~~~~~~

      Gaussian cluster states
      Due to the technological maturity of quantum measurement schemes for photons, one-way quantum computation is an attractive approach for photonic quantum processing. In the continuous variable formalism, Gaussian cluster states serve as an important piece of the measurement-based quantum computation model. This project involves the creation of conversion tools between phase space representations of Gaussian bosonic systems and Gaussian cluster states in the graph formalism.

      Recommended skills: Understanding of the quantum phase space formalism and the measurement-based quantum computation model. This review article and recent paper is a useful reference.

      Mentors: Andrew Kille and Stefan Krastanov.

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Easy

      

      ~~~~~~~~~~

      Adding models and examples
      As part of the documentation and for bootstrapping new projects, we want to add fully worked-out examples and applications of graph neural networks. We can start with entry-level tutorials and progressively introduce the reader to more advanced features.

      Duration: 175h.

      Expected difficulty: easy.

      Expected outcome: A few pedagogical and more advanced examples of graph neural network applications.

      
      ~~~~~~~~~~
      
      Adding graph datasets
      Provide Julia-friendly wrappers for common graph datasets in MLDatasets.jl. Create convenient interfaces for the Julia ML and data ecosystem.

      Duration: 175h.

      Expected difficulty: easy.

      Expected outcome: A large collection of graph datasets easily available to the Julia ecosystem.

      ~~~~~~~~~~
      
      Improving performance using sparse linear algebra
      Many graph convolutional layers can be expressed as non-materializing algebraic operations involving the adjacency matrix instead of the slower and more memory-consuming gather/scatter mechanism. We aim at extending as far as possible and in a gpu-friendly way these fused implementation. The project will involve fixing some outstanding issues in CUDA.jl that are blocking sparse adjacency matrix support on GPU.

      Duration: 350h.

      Expected difficulty: hard.

      Expected outcome: A noticeable performance increase for many graph convolutional operations.

      ~~~~~~~~~~
      
      Support for AMDGPU and Apple Silicon
      We currently support scatter/gather operation only on CPU and CUDA hardware. We aim to extend this to AMDGPU and Apple Silicon leveraging KernelAbstractions.jl, AMDGPU.jl, and Metal.jl.

      Duration: 175h.

      Expected difficulty: medium.

      Expected outcome: Graph convolution speedup for AMD GPU and Apple hardware, performance roughly on par with CUDA.

      Mentors
      Carlo Lucibello (author of GraphNeuralNetworks.jl). Feel free to contact me on the Julia Slack Workspace or by opening an issue in the GitHub repo.

      ~~~~~~~~~~

      Improving GPU Stack Portability
      Difficulty: Medium

      Duration: 175 or 350 hours (the scope of functionality to port can be adjusted accordingly)

      Description: The Julia GPU stack consists of several layers, from low-level vendor-specific packages like CUDA.jl to high-level abstractions like GPUArrays.jl. While the high-level packages aim to be vendor-agnostic, many optimized operations are still implemented in vendor-specific ways. This project aims to improve portability by moving these implementations to GPUArrays.jl using KernelAbstractions.jl.

      The project will involve:

      Identifying vendor-specific kernel implementations in packages like CUDA.jl

      Porting these kernels to KernelAbstractions.jl in GPUArrays.jl

      Improving KernelAbstractions.jl where needed to support these kernels

      Ensuring performance remains competitive with vendor-specific implementations

      Adding tests to verify correctness across different GPU backends

      Required Skills:

      Experience with Julia programming

      Familiarity with GPU programming concepts

      Experience with GPU programming in Julia is a plus

      Understanding of performance optimization

      Expected Results: A set of optimized GPU kernels in GPUArrays.jl that are vendor-agnostic and performant across different GPU backends. This will improve the portability of the Julia GPU stack and make it easier to support new GPU architectures.

      Mentors: Tim Besard, Valentin Churavy

      ~~~~~~~~~~

      Project 1: Optimizations
      Difficulty: Medium

      Estimated Duration: 350 hours

      Project Overview: Herb.jl has an outstanding performance in enumerating programs. Every generated program also needs to be evaluated, making evaluation the main bottleneck in finding a suitable program. We want to improve this aspect by leveraging various well-engineered projects from the Julia community.

      First, we have so far lessened the burden of evaluation by developing custom interpreters. This is time-consuming and error-prone, so we would like to avoid it. The core challenge here is that the explore programs don't have a fixed structure and are constructed during synthesis; therefore, they cannot be compiled ahead of time. The Julia package DynamicExpressions.jl is developed to overcome this exact problem, allowing for "ridiculously fast symbolic expressions". We would like to integrate DynamicExpressions.jl into our ecosystem and get a faster evaluation of Julia programs for free.

      Second, Herb is limited to Julia so far. Our goal is, however, to make Herb a language agnostic program synthesis library. We would like to extend Herb with connections to other interpreters for common languages like Python, Java, Prolog, et cetera. This would make it possible for Herb users to use any programming language that fits their needs.

      Third, another crucial aspect of every program synthesis engine is the construction of candidate programs. State-of-the-art program synthesis tools, like CVC5, have invested significant time into optimizing the program construction step, resulting in significantly improved performance. We want to map these ideas into Herb.

      Minimum goal: Connect DynamicExpressions.jl to Herb.jl. This involves implementing the expression interface from DynamicExpressions.jl for Herb.jl’s expression tree formulation.

      Extended goal: Add support for at least one non-Julia program interpreter or add tricks from CVC5 to Herb.

      Recommended skills:

      basic knowledge of data structures

      interest in program optimization

      the eagerness to learn to write and optimize code

      Mentors: Reuben Gardos-Reid, Tilman Hinnerichs and Sebastijan Dumancic

      Some literature:

      The Program Synthesis book (by Gulwani et al., link

      CVC4SY paper: link

      DynamicExpression.jl: link

      Our website: link

      ~~~~~~~~~~

      Project 2: HerbLearn Integration
      Difficulty: Medium

      Estimated Duration: 350h

      Problem description: Neurally-guided program synthesizers form a popular class of synthesizers, which learn a heuristic to guide program generation. Following Herb's paradigm to unify the field, we want to reach the same goal for this sub-field. Specifically, learning guiding policies comprise the same building blocks of 1. program sampling, 2. program-data-encoding, 3. policy learning with respect to a loss function, and 4. deploying that strategy.

      In this project, we want to implement these building blocks to allow researchers to reuse the modules directly. To guide this project, we implemented a template structure to follow and extend.

      Minimum goal: Implement a naive but modular strategy for all four steps. To allow for easy integration of with existing models, we aim to implement the machine learning part using Flux.jl.

      Extended goal: The extended goal is to deepen one or more of these modules that fit the student's interests. The literature provides numerous ideas on how to make all four steps smarter individually. Concretely, this could include

      smarter program-sampling,

      different program encoding strategies from the literature,

      implementing and applying different loss functions, and

      incorporating this with different search procedures.

      Recommended skills:

      Basic knowledge of machine learning principles (neural networks, model training, ...)

      Preferably prior experiences with Flux.jl

      Mentors: Tilman Hinnerichs, Reuben Gardos-Reid and Sebastijan Dumancic

      Some literature:

      The Program Synthesis book (by Gulwani et al., link

      Our website: https://herb-ai.github.io/

      BUSTLE: Bottom-up Program Synthesis through learning-guided exploration: link

      DeepCoder link

      DreamCoder link

      ~~~~~~~~~~

      
      Dynamic Scheduling for Mixture of Experts using Dagger.jl
      Difficulty: Hard (350h)

      Dynamic scheduling for Mixture of Experts (MoE) in LLM faces significant challenges due to the irregular computation patterns induced by expert routing, leading to load imbalances, underutilization of compute resources, and high communication overhead. Each token in MoE is routed to only a subset of experts, causing varying batch sizes and unbalanced workload distribution across experts. The traditional static scheduling approach does not efficiently handle these dynamic task assignments. By using Dagger.jl, we can implement a more dynamic, task-based scheduling system that assigns tokens to experts based on real-time compute availability, ensuring a more balanced workload. Dagger’s asynchronous scheduling allows for efficient parallel execution by dynamically distributing the tasks across multiple devices or compute units, improving GPU utilization and reducing bottlenecks. Furthermore, optimizations such as load balancing algorithms, soft routing mechanisms, and fine-grained task prioritization could be applied to maximize resource utilization and minimize execution time. Solving these optimization problems will not only enhance performance but also improve scalability, making MoE models more efficient and suitable for large-scale deployments.

      Skills: Familiarity with GPU, representing execution models as Flux.jl, DAGs, and CUDA.jl

      Mentors: Julian Samaroo, and Rabab Alomairy

      ~~~~~~~~~~

      Distributed Training
      Difficulty: Hard (350h)

      Add a distributed training API for Flux models built on top of Dagger.jl. More detailed milestones include building Dagger.jl abstractions for UCX.jl, then building tools to map Flux models into data parallel Dagger DAGs. The final result should demonstrate a Flux model training with multiple devices in parallel via the Dagger.jl APIs. A stretch goal will include mapping operations with a model to a DAG to facilitate model parallelism as well.

      There are projects now that host the building blocks: DaggerFlux.jl and Distributed Data Parallel Training which can serve as jumping off points.

      Skills: Familiarity with UCX, representing execution models as DAGs, Flux.jl, CUDA.jl and data/model parallelism in machine learning

      Mentors: Julian Samaroo, and Dhairya Gandhi

      ~~~~~~~~~~

      Optimizing GPU scheduler in Dagger.jl with Multistreams
      Difficulty: Hard (350h)

      This project aims to explore and enhance GPU performance by integrating Dagger.jl, Julia’s high-performance parallel computing framework, with GPU multistream capabilities. Dagger.jl enables task-based parallelism, allowing complex computations to be broken down into smaller, manageable tasks that can be efficiently scheduled across computing resources. By incorporating GPU multistreams, students will investigate how multiple streams can be used to overlap data transfers with kernel executions, enabling concurrent operations on the GPU. This overlapping reduces idle times, as data movement and computations occur simultaneously, thus maximizing GPU resource utilization. The project will focus on designing and implementing parallel workflows where independent tasks are executed concurrently, leveraging Dagger’s dynamic task scheduling and GPU’s ability to manage multiple streams effectively. Students will experiment with different workload patterns, measure performance improvements, and analyze the impact of multistream execution on throughput and latency. Through performance benchmarking and optimization, this project will provide hands-on experience in GPU programming, parallel algorithm design, and high-performance computing, equipping students with valuable skills for tackling real-world scientific and data-intensive applications.

      There are projects now that host the building blocks: DaggerGPU.jl and Dagger.jl which can serve as jumping off points.

      Skills: Familiarity with GPU, representing execution models as DAGs, CUDA.jl

      Mentors: Julian Samaroo, and Rabab Alomairy

      ~~~~~~~~~~

      Distributed Linear Algebra
      Difficulty: Hard (350h)

      Add distributed linear algebra capabilities to Dagger.jl. This project will involve building abstractions for distributed linear algebra operations, such as matrix multiplication, matrix factorizations, and different data distribution schemes (cyclic, block-cyclic, 2D, 3D). The student will build on top of Dagger.jl to enable distributed linear algebra operations across multiple devices. The final result should demonstrate a linear algebra operation running across multiple devices in parallel via the Dagger.jl APIs.

      Skills: Familiarity with distributed computing, numerical linear algebra, Dagger.jl

      Mentors: Felipe Tomé, and Rabab Alomairy

      ~~~~~~~~~~

      Optimizing MPI integration in Dagger.jl
      Difficulty: Hard (350h)

      This project aims to enhance the performance of the already implemented MPI integration in Dagger.jl. The student will investigate and optimize the communication patterns between ranks, focusing on reducing communication overhead and latency. The project will involve profiling and benchmarking different communication schemes, such as point-to-point, collective and Random Memory Access (RMA) strategies, and analyzing their impact on performance. Through performance benchmarking and optimization, this project will provide hands-on experience in parallel algorithm design and , distributed computing, equipping students with valuable skills for tackling real-world scientific and data-intensive applications.

      Skills: Familiarity with MPI, representing execution models as DAGs, Dagger.jl, RMA

      Mentors: Felipe Tomé, and Julian Samaroo

      ~~~~~~~~~~

      Dynamical systems, complex systems & nonlinear dynamics – Summer of Code
      Agents.jl
      Difficulty: Medium to Hard.

      Length: 175 to 350 hours depending on the project.

      Agents.jl is a pure Julia framework for agent-based modeling (ABM). It has an extensive list of features, excellent performance and is easy to learn, use, and extend. Comparisons with other popular frameworks written in Python or Java (NetLOGO, MASON, Mesa), show that Agents.jl outperforms all of them in computational speed, list of features and usability.

      In this project, contributors will be paired with lead developers of Agents.jl to improve Agents.jl with more features, better performance, and overall higher polish. We are open to discuss with potential candidate a project description and outline for it!

      Possible features to implement are:

      GPU and/or HPC support in Agents.jl by integrating existing ABM packages (Vanaha.jl or CellBasedModels.jl) into Agents.jl API.

      Integrating Agents.jl with ReinforcementLearning.jl

      Differentiation / parameter fitting of ABMs in Agents.jl by utilizing StochasticAD.jl or similar frameworks.

      Pre-requisite: Having already contributed to a Julia package either in JuliaDynamics or of sufficient relevance to JuliaDynamics.

      Recommended Skills: Familiarity with agent based modelling, Agents.jl and Julia's Type System, and achieving high-end computational performance within Julia. Research background in complex systems, sociology, agent based modelling, or nonlinear dynamics is not required but would be advantageous.

      Expected Results: Well-documented, well-tested useful new features for Agents.jl.

      Mentors: George Datseris.


      ~~~~~~~~~~

      DynamicalSystems.jl
      Difficulty: Easy to Medium to Hard, depending on the project.

      Length: 175 to 350 hours, depending on the project.

      DynamicalSystems.jl is an award-winning Julia software library for dynamical systems, nonlinear dynamics, deterministic chaos, and nonlinear time series analysis. It has an impressive list of features, but one can never have enough. In this project, contributors will be able to enrich DynamicalSystems.jl with new algorithms and enrich their knowledge of nonlinear dynamics and computer-assisted exploration of complex systems.

      Here is a list of high-impact, Hard (350 hours) projects that we want to prioritize.

      Local and global continuation in dynamical systems combined in one. This will be a ground-breaking feature, combining cutting edge research on multistable dynamical systems with the established bifurcation-continuation analysis.

      Other than that, we do not outline more possible projects here, and instead we invite interested candidates to explore the documentation and list of open features of any of the subpackages of DynamicalSystems.jl. Then the candidates can reach out to one of the developers of the subpackage to devise a project outline. We strongly welcome candidates that already have potential project ideas in mind already irrespectively of the open list of issues.

      Pre-requisite: Having already contributed to a Julia package either in JuliaDynamics or of sufficient relevance to JuliaDynamics.

      Recommended Skills: Familiarity with nonlinear dynamics and/or differential equations and/or timeseries analysis based on the Julia language.

      Expected Results: Well-documented, well-tested new algorithms for DynamicalSystems.jl.

      Mentors: George Datseris


      ~~~~~~~~~~

      
      Project 1: Supporting Patient Level Prediction Pipelines within JuliaHealth
      Description: Patient level prediction (PLP) is an important area of research in observational health research that involves using patient data to predict outcomes such as disease progression, response to treatment, and hospital readmissions. JuliaHealth is interested in developing supportive tooling for PLP that utilizes historical patient data, such as patient medical claims or electronic health records, that follow the OMOP Common Data Model (OMOP CDM), a widely used data standard that allows researchers to analyze large, heterogeneous healthcare datasets in a consistent and efficient manner. For this project, we are looking for students interested in developing supportive PLP tooling within JuliaHealth.

      Mentor: Jacob S. Zelko (aka TheCedarPrince) [email: jacobszelko@gmail.com]

      Difficulty: Medium

      Duration: 175 hours

      Suggested Skills and Background:

      Experience with Julia

      Exposure to machine learning concepts and ideas

      Familiarity with some of the following Julia packages would be a strong asset:

      DataFrames.jl

      OMOPCDMCohortCreator.jl

      MLJ.jl

      ModelingToolkit.jl

      Comfort with the OMOP Common Data Model (or a willingness to learn)

      Outcomes:

      This project will be very experimental and exploratory in nature. To constrain the expectations for this project, here is a possible approach students will follow while working on this project:

      Review existing literature on approaches to PLP

      Familiarize oneself with tools for machine learning and prediction within the Julia ecosystem

      Develop infrastructure needed for doing PLP within the JuliaHealth ecosystem such as:

      Consistent DataFrames.jl interface

      Data harmonization methods

      Sampling considerations for large scale patient data

      Document findings and novel software

      In whatever functionality that gets developed for tools within JuliaHealth, it will also be expected for students to contribute to the existing package documentation to highlight how new features can be used. Another perspective of this project is that its intended goal is to provide the foundational support needed within JuliaHealth to better accommodate multiple modalities of data available within public health settings. The long term goal is to use the development of foundational tooling with JuliaHealth to better support patient level prediction workflows across observational health data and additional information such as survey data, social determinants of health data, and climate data.

      Additionally, depending on the success of the package, there is a potential to run experiments on actual patient data to generate actual patient population insights based on a chosen research question. This could possibly turn into a separate research paper, conference submission, or poster submission. Whatever may occur in this situation will be supported by project mentors.

      
      ~~~~~~~~~~
      
      Medical Imaging Subecosystem Projects
      Julia Radiomics
      Project Title: Julia Radiomics Difficulty: Medium Duration: 375 hours (22 Weeks) Mentor: Jakub Mitura

      Description
      Radiomic features are quantitative metrics extracted from medical images using data-characterization algorithms. These features capture tissue and lesion characteristics, such as heterogeneity and shape, which may provide valuable insights beyond what the naked eye can perceive.

      This project aims to implement algorithms for extracting radiomic features from 2D and 3D medical images, similar to PyRadiomics, using Julia. The implementation will include Gray Level Co-occurrence Matrix (GLCM), Gray Level Size Zone Matrix (GLSZM), Gray Level Run Length Matrix (GLRM), Neighborhood Gray Tone Difference Matrix (NGTDM), and Gray Level Dependence Matrix (GLDM). The extracted features will be validated against PyRadiomics and applied to medical imaging data, such as the AutoPET dataset, to demonstrate the methodology.

      Deliverables
      Implementation of Radiomic Feature Extraction Algorithms
      First Group: GLCM, GLSZM, GLRM

      Second Group: NGTDM, GLDM

      Feature Extraction Pipeline
      Extract all features from segmented lesions in PET and CT modalities.

      Use MedImages.jl for image handling.

      Leverage KernelAbstractions.jl for performance optimization where possible.

      Validation
      Compare extracted features against PyRadiomics outputs.

      Ensure statistical equivalence in extracted features.

      Final Report & Code Repository
      Methodology, results, benchmarking.

      Public GitHub repository under an MIT license.

      Success Criteria and Timeline
      Literature Review and Setup (3 Weeks)

      Review PyRadiomics documentation, MedImages.jl, KernelAbstractions.jl APIs, and AutoPET dataset structure.

      Success Criteria: Understanding of feature definitions, dataset access, and GPU kernel design.

      Feature Implementation (6 Weeks)

      Implement GLCM, GLSZM, GLRM, NGTDM, and GLDM matrices.

      Validate outputs against PyRadiomics (>90% similarity in unit tests).

      Success Criteria: GPU-accelerated implementation for 3D volumes.

      Feature Extraction Pipeline (4 Weeks)

      Build a pipeline to process AutoPET lesions using MedImages.jl.

      Success Criteria: Extraction of 100+ features per lesion, support for batch processing.

      Validation (3 Weeks)

      Compare Julia feature extraction results with PyRadiomics.

      Success Criteria: Statistical equivalence (e.g., t-test p > 0.05), with documented discrepancies <5%.

      Documentation and Packaging (4 Weeks)

      Write documentation for the Julia-based radiomics library.

      Write automated tests for the proper functioning of the library.

      Register the package in the Julia package registry.

      Success Criteria: The final working library is successfully available in the Julia ecosystem.

      Reporting (2 Weeks)

      Document methodology, results, and benchmarking.

      Success Criteria: Reproducible code, Jupyter notebooks, open-source repository.

      Stretch Goals
      Implementation of additional radiomic features such as:

      Wavelet Features (Transform-based texture analysis)

      Fractal Analysis (Estimating complexity in medical images)

      Laplacian of Gaussian (LoG) Features (Edge detection-based feature extraction)

      Optimized parallel computation using GPU acceleration in KernelAbstractions.jl.

      Implementation of an interactive Julia-based visualization tool for extracted radiomic features.

      Clarification
      This implementation will be done entirely in Julia, and Python will not be used in any part of the implementation. Any cross-validation with PyRadiomics is purely for benchmarking purposes.

      Importance and Impact
      Technical Impact
      Julia Ecosystem Growth: First native Radiomics toolkit in Julia.

      GPU Acceleration: Utilizes KernelAbstractions.jl for efficient 3D feature extraction.

      Reproducibility: Open-source implementation ensures transparency in radiomics research.

      Clinical Impact
      Cancer Differentiation: Model insights may aid in non-invasive cancer subtyping.

      Standardization: Cross-tool validation enhances study comparability across different platforms.

      Community Impact
      Foundation for Future Work: Enables Julia-based radiomics pipelines for projects like TCIA.

      Educational Value: Demonstrates GPU-accelerated medical image processing in Julia for researchers and students.

      References
      PyRadiomics Documentation

      AutoPET Dataset

      MedImages.jl

      KernelAbstractions.jl

      Radiomics Research: Various studies on the clinical relevance of radiomics in medical imaging.

      Kumar, V., et al. "Radiomics: the process and the challenges." Magnetic Resonance Imaging, 2012.

      Gillies, R.J., et al. "Radiomics: images are more than pictures, they are data." Nature Reviews Cancer, 2016.

      Lambin, P., et al. "Radiomics: extracting more information from medical images using advanced feature analysis." European Journal of Cancer, 2012.




      ~~~~~~~~~~
      Enhancing MedPipe3D: Building a Comprehensive Medical Imaging Pipeline in Julia
      Description
      MedPipe3D was created to improve integration between other parts of the small ecosystem (MedEye3D, MedEval3D, and MedImage). Currently, it needs to be expanded and adapted to serve as the basis for a fully functional medical imaging pipeline.

      Mentor: Jakub Mitura [email: jakub.mitura14@gmail.com]

      Project Difficulty and Timeline
      Difficulty: Medium Duration: 12 weeks

      Required Skills and Background
      Strong knowledge of the Julia programming language is required.

      Experience with the following Julia packages is highly desirable:

      MedPipe3D.jl

      MedEye3D.jl

      MedEval3D.jl

      MedImage.jl

      Familiarity with the following packages would be a valuable asset:

      Lux.jl

      TensorBoard

      Logging.jl

      Potential Outcomes
      Implement comprehensive logging with TensorBoard Integration and Error and Warning Logs with Logging.jl for better tracking and debugging.

      Improve the performance of augmentations.

      Enable per-layer memory usage inspection of Lux models.

      Enable gradient checkpointing of chosen layers to save memory.

      Support loading tabular data (e.g., clinical data) together with the image into the supplied model.

      Enhance documentation with in-depth tutorial, code examples, and a refined README for easy onboarding.

      This set of changes, although time-consuming to implement, should not pose a significant issue to anyone with experience with the Julia programming language. Each feature will be implemented using existing Julia libraries and frameworks where possible. However, implementing these changes will be a huge step in making the Julia language a good alternative to Python for developing end-to-end medical imaging segmentation algorithms.

      Success Criteria and Time Needed
      Logging: Implement logging to track the progress and debug issues - 2 weeks.

      Performance Improvements: Optimize the performance of augmentations to ensure efficient processing - 2 weeks.

      Memory Usage Inspection: Enable per-layer memory usage inspection of Lux models to monitor and optimize memory consumption - 2 weeks.

      Gradient Checkpointing: Enable gradient checkpointing of chosen layers to save memory during training - 4 weeks.

      Tabular Data Support: Support loading tabular data (e.g., clinical data) together with the image into the supplied model - 1 week.

      Documentation: Improve documentation to provide clear instructions and examples for users - 1 week.

      Total estimated time: 12 weeks.

      Why Implementation of These Features is Important
      Implementing these features is crucial for advancing medical imaging technology. Enhanced logging with TensorBoard integration will allow for better insight into model training. Performance improvements ensure reliable and efficient processing of large datasets. Improved documentation and memory management make the tools more accessible and usable for medical professionals, facilitating better integration into clinical workflows. Supporting tabular data alongside imaging allows for comprehensive analysis, combining clinical and imaging data to improve diagnostic accuracy and patient outcomes.

      For each point, the mentor will also supply the person responsible for implementation with examples of required functionalities in Python or will point to the Julia libraries already implementing it (that just need to be integrated).

      
      ~~~~~~~~~~
      
      Project Title: A Digital Twin Approach for Advanced Supervoxel Visualization for Multi-Image View in Medical Imaging
      General Idea
      This project aims to develop visualization and interaction software for advanced supervoxel visualization on multi-image views. Building on the experiences from MedEye3D, the project will focus on creating a tool that allows users to interact with and visualize supervoxels across different imaging modalities (e.g., CT and MRI) simultaneously. The software will highlight corresponding supervoxels in different images when the user hovers over them, facilitating reliable analysis even in the presence of natural elastic deformations.

      Potential Outcomes
      Enhanced Visualization: A software tool that provides side-by-side views of different imaging studies, displaying supervoxel borders and highlighting corresponding supervoxels across images.

      Improved Interaction: An interactive interface allowing users to manually correct supervoxel associations by clicking and highlighting supervoxels in both images.

      Control Points Annotation: Support for annotating and displaying control points to aid in registration and user orientation.

      User Feedback Integration: Mechanisms for users to indicate incorrect supervoxel associations, improving the reliability of the tool.

      Success Criteria and Time Needed
      Software Development: [10 Weeks]

      Develop the core visualization tool with side-by-side image views.

      Implement supervoxel border display and highlighting functionality.

      Integrate control points annotation and display features.

      User Interaction Features: [6 Weeks]

      Develop interactive features for manual correction of supervoxel associations.

      Implement user feedback mechanisms for indicating incorrect associations.

      Testing and Validation: [2 Weeks]

      Conduct extensive testing with sample medical imaging data.

      Validate the tool's accuracy and reliability in highlighting corresponding supervoxels.

      Documentation and User Training: [2 Weeks]

      Create comprehensive documentation for the software.

      Develop training materials and conduct user training sessions.

      Final Review and Deployment: [2 Weeks]

      Review the project outcomes and make necessary adjustments.

      Deploy the software for use by the scientific community.

      The total estimated time for the project is approximately 22 weeks. Success will be measured by the tool's ability to accurately highlight corresponding supervoxels, ease of use, and positive feedback from users in the medical imaging community.

      Technical Requirements and Expected Expertise
      Strong programming skills in Julia/C++

      Experience with medical imaging libraries (ITK, SimpleITK, NIfTI)

      Familiarity with GUI development (preferably ModernGL.jl)

      Understanding of 3D visualization techniques

      Basic knowledge of medical image processing concepts

      Experience with version control (Git)

      Tools and Technologies
      Primary Language: Julia

      GUI Framework: ModernGL.jl/ Vulkan.jl

      Image Processing: ITK/SimpleITK

      Visualization: OpenGL

      Building upon: MedEye3D framework

      User Interaction Examples
      Hovering Over Supervoxels: When the user hovers the mouse over a supervoxel in one image (e.g., CT scan), the corresponding supervoxel in the other image (e.g., MRI scan) will be highlighted automatically.

      Manual Correction: If the user identifies an incorrect supervoxel association, they can click on the supervoxel in one image to freeze it, then manually find and click the correct supervoxel in the other image to establish the correct association.

      Control Points: Users can annotate control points by clicking on corresponding anatomical areas in both images. These points will be saved and displayed to assist in image registration and orientation.

      Importance and Impact
      This project is significant because it addresses the challenges of non-rigid registration in medical imaging, which is crucial for accurate diagnosis and treatment planning. By providing a reliable tool for visualizing and interacting with supervoxels across different imaging modalities, the project has the potential to:

      Enhance the accuracy of image registration and subsequent measurements.

      Reduce the time required for manual registration by radiologists and nuclear medicine specialists.

      Enable the development of new algorithms and methods in the medical imaging field.

      Improve clinical decision-making by providing more reliable imaging data.

      While various medical image visualization tools exist, there is currently no software solution that specifically addresses supervoxel-based visualization across multiple imaging modalities with interactive correction capabilities. This project builds upon MedEye3D as an independent extension, enhancing its capabilities with new features for supervoxel visualization and interaction.

      Visual Examples
      2 Different Patient's MRI and CT Studies on Transversal plane with supervoxels

      MRI and CT Supervoxels

      Highlighting the same anatomical region in both images with supervoxel display

      MRI and CT Supervoxels with same anatomical regions highlighted

      Overall, this project aims to contribute to the advancement of medical imaging technology, ultimately benefiting both the scientific community and patient care. Additionally, it will serve as a support tool for digital twin projects, enhancing the reliability of image registration and subsequent measurements.

      ~~~~~~~~~~

      MIDIfication of music from wave files
      Difficulty: Medium.

      Length: 350 hours.

      It is easy to analyze timing and intensity fluctuations in music that is the form of MIDI data. This format is already digitalized, and packages such as MIDI.jl and MusicManipulations.jl allow for seamless data processing. But arguably the most interesting kind of music to analyze is the live one. Live music performances are recorded in wave formats. Some algorithms exist that can detect the "onsets" of music hits, but they are typically focused only on the timing information and hence forfeit detecting e.g., the intensity of the played note. Plus, there are very few code implementations online for this problem, almost all of which are old and unmaintained. We would like to implement an algorithm in MusicProcessing.jl that given a recording of a single instrument, it can "MIDIfy" it, which means to digitalize it into the MIDI format.

      Recommended Skills: Background in music, familiarity with digital signal processing.

      Expected results: A well-tested, well-documented function midify in MusicProcessing.jl.

      Mentors: George Datseris.

      ~~~~~~~~~~

      

      Efficient symbolic-numeric set computations
      Difficulty: Medium.

      Description. LazySets is the core library of JuliaReach. It provides ways to symbolically compute with geometric sets, with a focus on lazy set representations and efficient high-dimensional processing. The library has been described in the article LazySets.jl: Scalable Symbolic-Numeric Set Computations.

      The main interest in this project is to implement algorithms that leverage the structure of the sets. Typical examples include polytopes and zonotopes (convex), polynomial zonotopes and Taylor models (non-convex) to name a few.

      Expected Results. The goal is to implement certain efficient state-of-the-art algorithms from the literature. The code is to be documented, tested, and evaluated in benchmarks. Specific tasks may include (to be driven by the interets of the candidate): efficient vertex enumeration of zonotopes; operations on polynomial zonotopes; operations on zonotope bundles; efficient disjointness checks between different set types; complex zonotopes.

      Expected Length. 175 hours.

      Recommended Skills. Familiarity with Julia and Git/GitHub is mandatory. Familiarity with LazySets is recommended. Basic knowledge of geometric terminology is appreciated but not required.

      Mentors: Marcelo Forets, Christian Schilling.

      ~~~~~~~~~~

      Reachability with sparse polynomial zonotopes
      Difficulty: Medium.

      Description. Sparse polynomial zonotopes are a new non-convex set representation that are well-suited for reachability analysis of nonlinear dynamical systems. This project is a continuation of GSoC'2022 - Reachability with sparse polynomial zonotopes, which implemented the basics in LazySets.

      Expected Results. It is expected to add efficient Julia implementations of a reachability algorithm for dynamical systems in ReachabilityAnalysis which leverages polynomial zonotopes. A successful project should:

      Replicate the results from the article [Reachability Analysis for Linear Systems with Uncertain Parameters using Polynomial Zonotopes

      ](https://dl.acm.org/doi/abs/10.1145/3575870.3587130).

      The code shall be documented, tested, and evaluated extensively in benchmarks.

      For ambitious candidates it is possible to draw connections with neural-network control systems as implemented in ClosedLoopReachability.jl.

      Expected Length. 175 hours.

      Recommended Skills. Familiarity with Julia and Git/GitHub is mandatory. Familiarity with the mentioned Julia packages is appreciated but not required. The project does not require theoretical contributions, but it requires reading a research literature, hence a certain level of academic experience is recommended.

      Literature and related packages. This video explains the concept of polynomial zonotopes (slides here). The relevant theory is described in this research article. There exists a Matlab implementation in CORA (the implementation of polynomial zonotopes can be found in this folder).

      Mentors: Marcelo Forets, Christian Schilling.

      ~~~~~~~~~~

      Improving the hybrid systems reachability API
      Difficulty: Medium.

      Description. ReachabilityAnalysis is a Julia library for set propagation of dynamical systems. One of the main aims is to handle systems with mixed discrete-continuous behaviors (known as hybrid systems in the literature). This project will focus on enhancing the capabilities of the library and overall improvement of the ecosystem for users.

      Expected Results. Specific tasks may include: problem-specific heuristics for hybrid systems; API for time-varying input sets; flowpipe underapproximations. The code is to be documented, tested, and evaluated in benchmarks. Integration with ModelingToolkit.jl can also be considered if there is interest.

      Expected Length. 175 hours.

      Recommended Skills. Familiarity with Julia and Git/GitHub is mandatory. Familiarity with LazySets and ReachabilityAnalysis is welcome but not required.

      Mentors: Marcelo Forets, Christian Schilling.

      

      Reinforcement Learning Environments
      Time: 175h

      Develop a series of reinforcement learning environments, in the spirit of the OpenAI Gym. Although we have wrappers for the gym available, it is hard to install (due to the Python dependency) and, since it's written in Python and C code, we can't do more interesting things with it (such as differentiate through the environments).

      Expected Outcome
      A pure-Julia version of selected environments that supports a similar API and visualisation options would be valuable to anyone doing RL with Flux.

      Mentors: Dhairya Gandhi.

      ~~~~~~~~~~

      Molecular Simulation
      Much of science can be explained by the movement and interaction of molecules. Molecular dynamics (MD) is a computational technique used to explore these phenomena, from noble gases to biological macromolecules. Molly.jl is a pure Julia package for MD, and for the simulation of physical systems more broadly. The package is currently under development with a focus on proteins and differentiable molecular simulation. There are a number of ways that the package could be improved:

      Machine learning potentials (duration: 175h, expected difficulty: easy to medium): in the last few years machine learning potentials have been improved significantly. Models such as ANI, ACE, NequIP and Allegro can be added to Molly.

      Better GPU performance (duration: 175h, expected difficulty: medium): custom GPU kernels can be written to significantly speed up molecular simulation and make the performance of Molly comparable to mature software.

      Constraint algorithms (duration: 175h, expected difficulty: medium): many simulations keep fast degrees of freedom such as bond lengths and bond angles fixed using approaches such as SHAKE, RATTLE and SETTLE. A fast implementation of these algorithms would be a valuable contribution.

      Electrostatic summation (duration: 175h, expected difficulty: medium to hard): methods such as particle-mesh Ewald (PME) are in wide use for molecular simulation. Developing fast, flexible implementations and exploring compatibility with GPU acceleration and automatic differentiation would be an important contribution.

      Recommended skills: familiarity with computational chemistry, structural bioinformatics or simulating physical systems.

      Expected results: new features added to the package along with tests and relevant documentation.

      Mentor: Joe Greener

      Contact: feel free to ask questions via email or #juliamolsim on the Julia Slack.

   
      ~~~~~~~~~~
      Matrix functions
      Matrix functions map matrices onto other matrices, and can often be interpreted as generalizations of ordinary functions like sine and exponential, which map numbers to numbers. Once considered a niche province of numerical algorithms, matrix functions now appear routinely in applications to cryptography, aircraft design, nonlinear dynamics, and finance.

      This project proposes to implement state of the art algorithms that extend the currently available matrix functions in Julia, as outlined in issue #5840. In addition to matrix generalizations of standard functions such as real matrix powers, surds and logarithms, contributors will be challenged to design generic interfaces for lifting general scalar-valued functions to their matrix analogues for the efficient computation of arbitrary (well-behaved) matrix functions and their derivatives.

      Recommended Skills: A strong understanding of calculus and numerical analysis.

      Expected Results: New and faster methods for evaluating matrix functions.

      Mentors: Jiahao Chen, Steven Johnson.

      Difficulty: Hard

      ~~~~~~~~~~

      Better Bignums Integration
      Julia currently supports big integers and rationals, making use of the GMP. However, GMP currently doesn't permit good integration with a garbage collector.

      This project therefore involves exploring ways to improve BigInt, possibly including:

      Modifying GMP to support high-performance garbage-collection

      Reimplementation of aspects of BigInt in Julia

      Lazy graph style APIs which can rewrite terms or apply optimisations

      This experimentation could be carried out as a package with a new implementation, or as patches over the existing implementation in Base.

      Expected Results: An implementation of BigInt in Julia with increased performance over the current one.

      Require Skills: Familiarity with extended precision numerics OR performance considerations. Familiarity either with Julia or GMP.

      Mentors: Jameson Nash

      Difficulty: Hard

      ~~~~~~~~~~

      

      Special functions
      As a technical computing language, Julia provides a huge number of special functions, both in Base as well as packages such as StatsFuns.jl. At the moment, many of these are implemented in external libraries such as Rmath and openspecfun. This project would involve implementing these functions in native Julia (possibly utilising the work in SpecialFunctions.jl), seeking out opportunities for possible improvements along the way, such as supporting Float32 and BigFloat, exploiting fused multiply-add operations, and improving errors and boundary cases.

      Recommended Skills: A strong understanding of calculus.

      Expected Results: New and faster methods for evaluating properties of special functions.

      Mentors: Steven Johnson, Oscar Smith. Ask on Discourse or on slack

      ~~~~~~~~~~
      
      A Julia-native CCSA optimization algorithm
      The CCSA algorithm by Svanberg (2001) is a nonlinear programming algorithm widely used in topology optimization and for other large-scale optimization problems: it is a robust algorithm that can handle arbitrary nonlinear inequality constraints and huge numbers of degrees of freedom. Moreover, the relative simplicity of the algorithm makes it possible to easily incorporate sparsity in the Jacobian matrix (for handling huge numbers of constraints), approximate-Hessian preconditioners, and as special-case optimizations for affine terms in the objective or constraints. However, currently it is only available in Julia via the NLopt.jl interface to an external C implementation, which greatly limits its flexibility.

      Recommended Skills: Experience with nonlinear optimization algorithms and understanding of Lagrange duality, familiarity with sparse matrices and other Julia data structures.

      Expected Results: A package implementing a native-Julia CCSA algorithm.

      Mentors: Steven Johnson.

      ~~~~~~~~~~

      

      Machine learning for nowcasting and forecasting
      This project involves developing scalable machine learning time series regressions for nowcasting and forecasting. Nowcasting in economics is the prediction of the present, the very near future, and the very recent past state of an economic indicator. The term is a contraction of "now" and "forecasting" and originates in meteorology.

      The objective of this project is to introduce scalable regression-based nowcasting and forecasting methodologies that demonstrated the empirical success in data-rich environment recently. Examples of existing popular packages for regression-based nowcasting on other platforms include the "MIDAS Matlab Toolbox", as well as the 'midasr' and 'midasml' packages in R. The starting point for this project is porting the 'midasml' package from R to Julia. Currently Pythia has the sparse-group LASSO regression functionality for forecasting.

      The following functions are of interest: in-sample and out-of sample forecasts/nowcasts, regularized MIDAS with Legendre polynomials, visualization of nowcasts, AIC/BIC and time series cross-validation tuning, forecast evaluation, pooled and fixed effects panel data regressions for forecasting and nowcasting, HAC-based inference for sparse-group LASSO, high-dimensional Granger causality tests. Other widely used existing functions from R/Python/Matlab are also of interest.

      Recommended skills: Graduate-level knowledge of time series analysis, machine learning, and optimization is helpful.

      Expected output: The contributor is expected to produce code, documentation, visualization, and real-data examples.

      References: Contact project mentors for references.

      ~~~~~~~~~~

      Time series forecasting at scales
      Modern business applications often involve forecasting hundreds of thousands of time series. Producing such a gigantic number of reliable and high-quality forecasts is computationally challenging, which limits the scope of potential methods that can be used in practice, see, e.g., the 'forecast', 'fable', or 'prophet' packages in R. Currently, Julia lacks the scalable time series forecasting functionality and this project aims to develop the automated data-driven and scalable time series forecasting methods.

      The following functionality is of interest: forecasting intermittent demand (Croston, adjusted Croston, INARMA), scalable seasonal ARIMA with covariates, loss-based forecasting (gradient boosting), unsupervised time series clustering, forecast combinations, unit root tests (ADF, KPSS). Other widely used existing functions from R/Python/Matlab are also of interest.

      Recommended skills: Graduate-level knowledge of time series analysis is helpful.

      Expected output: The contributor is expected to produce code, documentation, visualization, and real-data examples.

      References: Contact project mentors for references.

      ~~~~~~~~~~

      GPU accelerated simulator of Clifford Circuits.
      Simulation of Clifford circuits involves significant amounts of linear algebra with boolean matrices. This enables the use of many standard computation accelerators like GPUs, as long as these accelerators support bit-wise operations. The main complications is that the elements of the matrices under consideration are usually packed in order to increase performance and lower memory usage, i.e. a vector of 64 elements would be stored as a single 64 bit integer instead of as an array of 64 bools. A Summer of Code project could consist of implement the aforementioned linear algebra operations in GPU kernels, and then seamlessly integrating them in the rest of the QuantumClifford library. At a minimum that would include Pauli-Pauli products and certain small Clifford operators, but could extend to general stabilizer tableau multiplication and even tableau diagonalization. Some of these features are already implemented, but significant polish and further improvements and implementation of missing features is needed.

      Recommended skills: Basic knowledge of the stabilizer formalism used for simulating Clifford circuits. Familiarity with performance profiling tools in Julia and Julia's GPU stack, including KernelAbstractions and Tullio.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it to a longer project by including work on GPU-accelerated Gaussian elimination used in the canonicalization routines)

      Difficulty: Medium if the applicant is familiar with Julia, even without understanding of Quantum Information Science (but applicants can scope it to "hard" by including the aforementioned additional topics)

      ~~~~~~~~~~
      
      A Zoo of Quantum Error Correcting codes and/or decoders
      Quantum Error Correcting codes are typically represented in a form similar to the parity check matrix of a classical code. This form is referred to as a Stabilizer tableaux. This project would involve creating a comprehensive library of frequently used quantum error correcting codes and/or implementing syndrome-decoding algorithms for such codes. The library already includes some simple codes and interfaces to a few decoders – adding another small code or providing a small documentation pull request could be a good way to prove competence when applying for this project. The project can be extended to a much longer one if work on decoders is included. A large part of this project would involve literature surveys. Some suggestions for codes to include: color codes, higher-dimensional topological codes, hyper graph product codes, twists in codes, newer LDPC codes, honeycomb codes, Floquet codes. Some suggestions for decoders to work on: iterative, small-set flip, ordered statistical decoding, belief propagation, neural belief propagation.

      Recommended skills: Knowledge of the stabilizer formalism used for simulating Clifford circuits. Familiarity with tools like python's ldpc, pymatching, and stim can help. Consider checking out the PyQDecoders.jl julia wrapper package as well.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer, depending on the list of functionality they plan to implement)

      Difficulty: Medium. Easy with some basic knowledge of quantum error correction

      
      ~~~~~~~~~~
      
      Left/Right multiplications with small gates.
      Applying an n-qubit Clifford gate to an n-qubit state (tableaux) is an operation similar to matrix multiplication, requiring O(n^3) steps. However, applying a single-qubit or two-qubit gate to an n-qubit tableaux is much faster as it needs to address only one or two columns of the tableaux. This project would focus on extending the left-multiplication special cases already started in symbolic_cliffords.jl and creating additional right-multiplication special cases (for which the Stim library is a good reference).

      Recommended skills: Knowledge of the stabilizer formalism used for simulating Clifford circuits. Familiarity with performance profiling tools in Julia. Understanding of C/C++ if you plan to use the Stim library as a reference.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan for other significant optimization and API design work)

      Difficulty: Easy

      ~~~~~~~~~~
      
      Generation of Fault Tolerant ECC Circuits, Flag Qubit Circuits and more
      The QuantumClifford library already has some support for generating different types of circuits related to error correction (mostly in terms of syndrome measurement circuits like Shor's) and for evaluating the quality of error correcting codes and decoders. Significant improvement can be made by implementing more modern compilation schemes, especially ones relying on flag qubits.

      Recommended skills: Knowledge of the variety of flag qubit methods. Some useful references could be a, b, c, and this video lecture.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Hard

      ~~~~~~~~~~
      
      Measurement-Based Quantum Computing (MBQC) compiler
      The MBQC model of quantum computation has a lot of overlap with the study of Stabilizer states. This project would be about the creation of an MBQC compiler and potentially simulator in Julia. E.g. if one is given an arbitrary graph state and a circuit, how is this circuit to be compiled in an MBQC model.

      Recommended skills: Knowledge of the MBQC model of quantum computation. This paper and the related python library can be a useful reference. Consider also this reference.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Hard

      ~~~~~~~~~~
      
      Implementing a Graph State Simulator
      The graph states formalism is a way to work more efficiently with stabilizer states that have a sparse tableaux. This project would involve creation of the necessary gate simulation algorithms and conversions tools between graph formalism and stabilizer formalism (some of which are already available in the library).

      Recommended skills: Understanding of the graph formalism. This paper can be a useful reference.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Medium

      ~~~~~~~~~~
      
      Simulation of Slightly Non-Clifford Circuits and States
      There are various techniques used to augment Clifford circuit simulators to model circuits that are only "mostly" Clifford. Particularly famous are the Clifford+T gate simulators. This project is about implementing such extensions.

      Recommended skills: In-depth understanding of the Stabilizer formalism, and understanding of some of the extensions to that method. We have some initial implementations. This IBM paper can also be a useful reference for other methods.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Hard

      ~~~~~~~~~~
      
      Magic State Modeling - Distillation, Injection, Etc
      Magic states are important non-stabilizer states that can be used for inducing non-Clifford gates in otherwise Clifford circuits. They are crucial for the creation of error-corrected universal circuits. This project would involve contributing tools for the analysis of such states and for the evaluation of distillation circuits and ECC circuits involving such states.

      Recommended skills: In-depth understanding of the theory of magic states and their use in fault tolerance.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Hard

      ~~~~~~~~~~
      
      

      GPU accelerated operators and ODE solvers
      Much of the internal representation of quantum states in QuantumOptics.jl relies on standard dense arrays. Thanks to the multiple-dispatch nature of Julia, much of these objects can already work well with GPU arrays. This project would involve a thorough investigation and validation of the current interfaces to make sure they work well with GPU arrays. In particular, attention will have to be paid to the "lazy" operators as special kernels might need to be implemented for them.

      Recommended skills: Familiarity with performance profiling tools in Julia and Julia's GPU stack, potentially including KernelAbstractions.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumOptics.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Medium

      ~~~~~~~~~~

      Autodifferentiation
      Autodifferentiation is the capability of automatically generating efficient code to evaluate the numerical derivative of a given Julia function. Similarly to the GPU case above, much of this functionality already "magically" works, but there is no detailed test suite for it and no validation has been done. This project would involve implementing, validating, and testing the use of Julia autodiff tools in QuantumOptics.jl. ForwardDiff, Enzyme, Zygote, Diffractor, and AbstractDifferentiation are all tools that should have some level of validation and support, both in ODE solving and in simple operator applications.

      Recommended skills: Familiarity with the Julia autodiff stack and the SciML sensitivity analysis tooling. Familiarity with the difficulties to autodiff complex numbers (in general and specifically in Julia). Understanding of the AbstractDifferentiation.jl package.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumOptics.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Easy-to-Medium

      ~~~~~~~~~~

      Closer Integration with the SciML Ecosystem
      SciML is the umbrella organization for much of the base numerical software development in the Julia ecosystem. We already use many of their capabilities, but it would be beneficial to more closely match the interfaces they expect. This project would be heavily on the software engineering side. Formal and informal interfaces we want to support include: better support for DiffEq problem types (currently we wrap DiffEq problems in our own infrastructure and it is difficult to reuse them in SciML); better support for broadcast operations over state objects (so that we can treat them closer to normal arrays and we can simply provide an initial state to a DiffEq solver without having to wrap/unwrap the data); relying more heavily on SciMLOperators which have significant overlap with our lazy operators.

      Recommended skills: Familiarity with the SciML stack.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumOptics.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Easy

      ~~~~~~~~~~

      Ab-Initio Quantum Chemistry with Rimu.jl
      Difficulty: Easy to medium (if the recommended skills are available)

      Project size: 175 - 350 hours

      Problem: Rimu.jl provides an interface for defining a custom quantum many-body Hamiltonian and currently implements a selection of model Hamiltonians (e.g. variants of the Hubbard model and the Fröhlich polaron model). The high-level goal of the project is to implement the required functionality to solve ab-initio quantum chemistry problems with Rimu.jl and embed the package into the JuliaMolSim ecosystem, in particular with ElemCo.jl.

      Minimum goal: A minimum goal would be to enable reading in the relevant information about the molecular orbital basis set and integrals that define the molecular Hamiltonian from a file (in the standard FCIDUMP format) and defining an appropriate Hamiltonian type for Rimu.jl that enables its usage for exact diagonalisation and FCIQMC.

      Extended goal: An extended goal would be to make the molecular Hamiltonian efficient for FCIQMC, e.g. by finding and implementing an appropriate strategy for an excitation generator, e.g. a variant of (precomputed) heat-bath sampling. Another worthwhile extension would be to implement variants of the Configuration Interaction (CI) method by filtering the configurations to a relevant subspace (e.g. CI-SD, selctive CI, etc.) for the exact-diagonalisation part of Rimu.jl.

      Recommended skills:

      prior exposure to or strong interest in quantum chemistry

      good to excellent Julia coding skills

      Mentors: Joachim Brand, Daniel Kats, Elke Pahl

      If you are interested please get in touch by email.

      ~~~~~~~~~~

      Load balancing Rimu.jl for multi-node (HPC) calculations
      Difficulty: Medium to hard

      Project size: 175 - 350 hours

      Problem: Rimu.jl parallelises the workload of FCIQMC by making extensive use of native threading for shared-memory parallelism. In high-performance computing environments the primary data structure containing information about the sampled configurations and their amplitudes can further be distributed across nodes, which communicate using the MPI protocol in every time step (making use of MPI.jl). In the current implementation the distribution of configurations to nodes is done passively (in a pseudo-random fashion using a hashing algorithm). While this is fast and easy and usually leads to a fairly even distribution of data and work across the nodes, it does not scale very well when employing hundreds of nodes as every MPI rank has to wait for the slowest one to complete the work done at each time step.

      Minimum goal: Implement an active load-balancing approach where load information of each MPI rank is monitored and work load is shifted between nodes to even out the workload.

      Extended goal: Explore other load-balancing strategies like agent-based approaches, possibly even exploring algorithmic alternatives (e.g. continuous-time Monte Carlo). Design communication protocols that take into account the network topology.

      Recommended skills:

      experience with HPC environments and MPI-style programming

      good to excellent Julia coding skills

      Mentors: Matija Čufar, Joachim Brand

      If you are interested please get in touch with Matija or Joachim.

      ~~~~~~~~~~

      TopOpt Projects – Summer of Code
      TopOpt.jl is a topology optimization package written in pure Julia. Topology optimization is an exciting field at the intersection of shape representation, physics simulations and mathematical optimization, and the Julia language is a great fit for this field. To learn more about TopOpt.jl, check the following JuliaCon talk.

      The following is a tentative list of projects in topology optimization that you could be working on in the coming Julia Season of Contributions or Google Summer of Code. If you are interested in exploring any of these topics or if you have other interests related to topology optimization, please reach out to the main mentor Mohamed Tarek via email.

      ~~~~~~~~~~
      
      Testing and benchmarking of TopOpt.jl
      Project difficulty: Medium

      Work load: 350 hours

      Description: The goal of this project is to improve the unit test coverage and reliability of TopOpt.jl by testing its implementations against other software's outputs. Testing and benchmarking stress and buckling constraints and their derivatives will be the main focus of this project. Matlab scripts from papers may have to be translated to Julia for correctness and performance comparison.

      Knowledge prerequisites: structural mechanics, optimization, Julia programming

      ~~~~~~~~~~
      
      Machine learning in topology optimization
      Project difficulty: Medium

      Work load: 350 hours

      Description: There are numerous ways to use machine learning for design optimization in topology optimization. The following are all recent papers with applications of neural networks and machine learning in topology optimization. There are also exciting research opportunities in this direction.

      DNN-based Topology optimization: Spatial Invariance and Neural Tangent Kernel

      NTopo: Mesh-free Topology Optimization using Implicit Neural Representations

      TONR: An exploration for a novel way combining neural network with topology optimization

      TOuNN: Topology Optimization using Neural Networks

      In this project you will implement one of the algorithms discussed in any of these papers.

      Knowledge prerequisites: neural networks, optimization, Julia programming

      
      ~~~~~~~~~~
      Optimization on a uniform rectilinear grid
      Project difficulty: Medium

      Work load: 350 hours

      Description: Currently in TopOpt.jl, there are only unstructured meshes supported. This is a very flexible type of mesh but it's not as memory efficient as uniform rectilinear grids where all the elements are assumed to have the same shape. This is the most common grid used in topology optimization in practice. Currently in TopOpt.jl, the uniform rectilinear grid will be stored as an unstructured mesh which is unnecessarily inefficient. In this project, you will optimize the finite element analysis and topology optimization codes in TopOpt.jl for uniform rectilinear grids.

      Knowledge prerequisites: knowledge of mesh types, Julia programming

      ~~~~~~~~~~
      
      Adaptive mesh refinement for topology optimization
      Project difficulty: Medium

      Work load: 350 hours

      Description: Topology optimization problems with more mesh elements take longer to simulate and to optimize. In this project, you will explore the use of adaptive mesh refinement starting from a coarse mesh, optimizing and only refining the elements that need further optimization. This is an effective way to accelerate topology optimization algorithms.

      Knowledge prerequisites: adaptive mesh refinement, Julia programming

      
      ~~~~~~~~~~
      Heat transfer design optimization
      Project difficulty: Medium

      Work load: 175 or 350 hours

      Description: All of the examples in TopOpt.jl and problem types are currently of the linear elasticity, quasi-static class of problems. The goal of this project is to implement more problem types and examples from the field of heat transfer. Both steady-state heat transfer problems and linear elasticity problems make use of elliptic partial differential equations so the code from linear elasticity problems should be largely reusable for heat transfer problems with minimum changes.

      Knowledge prerequisites: finite element analysis, heat equation, Julia programming

      ~~~~~~~~~~

      Advanced visualization and in-situ visualization with ParaView
      Difficulty: Medium

      Project size: 175 hours or 350 hours, depending on the chosen subtasks

      Visualizing and documenting results is a crucial part of the scientific process. In Trixi.jl, we rely for visualization on a combination of pure Julia packages (such as Plots.jl and Makie.jl) and the open-source scientific visualization suite ParaView. While the Julia solutions are excellent for visualizing 1D and 2D data, ParaView is the first choice for creating publication-quality figures from 3D data.

      Currently, visualization with ParaView is only possible after a simulation is finished and requires an additional postprocessing step, where the native output files of Trixi.jl are converted to VTK files using Trixi2Vtk.jl. This extra step makes it somewhat inconvenient to use, especially when the current state of a numerical solution is to be checked during a long, multi-hour simulation run.

      The goal of this project is therefore to make such visualizations easier by introducing two significant improvements:

      Add the capability to write out native VTKHDF files directly during a simulation, in serial and parallel.

      Enable parallel in-situ visualization of the results, i.e., to visualize results by connecting ParaView to a currently running, parallel Trixi.jl simulation using the Catalyst API.

      Both tasks are related in that they require the student to familiarize themselves with both the data formats internally used in Trixi.jl as well as the visualization pipelines of VTK/ParaView. However, they can be performed independently and thus this project is suitable for either a 175 hour or a 350 hour commitment, depending on whether one or both tasks are to be tackled.

      This project is good for both software engineers interested in the fields of visualization and scientific data analysis as well as those students who are interested in pursuing graduate research in the field of numerical analysis and high-performance computing.

      Recommended skills: Some knowledge of at least one numerical discretization scheme (e.g., finite volume, discontinuous Galerkin, finite differences) is helpful; initial knowledge about visualization or parallel processing; preferably the ability (or eagerness to learn) to write fast code.

      Expected results: Scalable, production quality visualization of scientific results for Trixi.jl.

      Mentors: Michael Schlottke-Lakemper, Benedict Geihe, Johannes Markert

      
      ~~~~~~~~~~
      
      Asynchronous computing for communication blocking MPI and multi-GPU computing using Trixi.jl
      Difficulty: Medium

      Project size: 175 hours or 350 hours, depending on the chosen subtasks

      The high performance of modern scientific software is built on parallel computing using MPI and GPUs. The communication speed has not kept up with the exponential increase in compute speed and algorithms are often communication bound, leading to underutilization of hardware capabilities. Asynchronous computing avoids communication bottlenecks by performing non-blocking sends and using algorithms that can give reliable results using the currently available data. This approach gives great scalability on parallel computing systems.

      Trixi.jl currently performs distributed memory parallelization using MPI.jl, and has experimental GPU capabilities using CUDA.jl and KernelAbstractions.jl. The goal of this project is to implement a subset of features of Trixi.jl that can perform parallel simulations asynchronously.

      The possible subtasks in this project include:

      Explore and implement a simple code for asynchronous algorithms for solving the 1D advection equation or 1D compressible Euler equations using the API of Trixi.jl.

      Taking the simple code as a prototype, explore and implement an asynchronous algorithm starting with the basic TreeMesh type in Trixi.jl and potentially extending up to P4estMesh.

      Explore and implement asynchronous algorithms for a multi-GPU setup, in the 1D prototype and in Trixi.jl.

      Explore and implement asynchronous algorithms using Remote Memory Access Programming using MPI.jl.

      Optimize and compare the performance of the above implementations across different hardwares.

      This project is good for both software engineers interested in the fields of scientific computing, machine learning and numerical analysis as well as those students who are interested in pursuing graduate research in the field.

      Recommended skills: Some knowledge of GPU or MPI programming. Knowledge of any numerical analysis (e.g., finite differences) will help, but is not strictly required.

      Expected results: Draft of a working subset of the functionality of Trixi.jl efficiently using asynchronous computing.

      Mentors: Arpit Babbar, Hendrik Ranocha, Michael Schlottke-Lakemper

      
      ~~~~~~~~~~
      
      Adaptive mesh refinement on GPUs with CUDA dynamic parallelism
      Difficulty: Hard

      Project size: 175 hours or 350 hours, depending on the chosen subtasks

      Dynamic parallelism is designed for applications with either a variation of work across space or a dynamically varying workload over time. It is perfect for tasks like mesh refinement. When a thread discovers that an area needs to be refined, it can launch a new grid to perform computations on the refined area without the overhead of terminating the current grid, reporting to the host, and launching the new grid from the host.

      Adaptive mesh refinement (AMR) is applied in Trixi.jl to dynamically refine the mesh during simulations, ensuring finer resolution in critical regions for improved accuracy. Currently, the mesh refinement process is performed on CPUs using parallelism with MPI.jl. The goal of this project is to migrate AMR to GPUs using dynamic parallelism for acceleration with CUDA.jl.

      The possible subtasks in this project include:

      Implementing the abstract tree initialization process on GPUs.

      Exploring the TreeMesh initialization processes on GPUs based on the implementation of the first task and combining them.

      Integrating the above into AMRCallback in the simulation using dynamic parallelism (via CUDA.jl).

      Optimizing the code for data transfer, kernel launch overhead, occupancy, etc.

      Starting the above work in 1D and then expanding it to 2D and 3D problems.

      (Optional) Try similar work for P4estMesh in 2D and 3D.

      This project is good for people who are interested in GPU programming, parallel computing, parallel algorithm optimization, and scientific computing.

      Recommended skills: GPU programming, knowledge of CUDA dynamic parallelism, and familiarity with mesh refinement. (For beginners or those unfamiliar with dynamic parallelism, it is recommended to start with the CUDA quadtree example.)

      Expected results: A working example of AMR running on GPUs.

      Mentors: Huiyu Xie, Jesse Chan, Hendrik Ranocha

      

      

      ~~~~~~~~~~
      
      Mooncake.jl Performance Optimization
      Difficulty: Medium

      Duration: 350 hours

      Description: Mooncake.jl is a reverse-mode AD package written entirely in Julia, which addresses many of limitations of the popular ReverseDiff.jl and Zygote.jl libraries. While the library is typically fast, performance is not tested as systematically as it could be, meaning that there are probably a range of performance bugs waiting to be uncovered. Additionally, there are a range of known performance limitations which need to be addressed. This project aims to resolve known performance problems, to find new ones, and fix them too!

      Skills: familiarity with Julia programming, how to make Julia code performant, and a strong desire to make existing Julia code more performant! An understanding of AD is helpful, but not essential.

      
      ~~~~~~~~~~
      
      R and Python Interfaces for JuliaBUGS
      Difficulty: Medium

      Duration: 175 hours or 350 hours

      JuliaBUGS is a Julia implementation of the BUGS probabilistic programming language. It emphasizes interoperability and modularity. JuliaBUGS gives users familiar with BUGS access to Hamiltonian Monte Carlo (HMC), Automatic Differentiation (AD), and Julia’s powerful scientific computing tools. This Google Summer of Code (GSoC) project aims to create easy-to-use R and Python interfaces for JuliaBUGS.

      Project Tasks:

      Interface Design: Develop R and Python packages similar to existing and widely used R packages like R2OpenBUGS and rjags, making it easy for users to adopt.

      Interoperability Development: Use Julia's existing packages (JuliaCall and PythonCall) to create the interfaces. This will allow smooth data transfer and function calls between Julia, R, and Python.

      Integration with Tools (Large Project): Integrate these new interfaces seamlessly with popular Bayesian visualization and diagnostics tools—such as bayesplot, posterior, and coda in R, and ArviZ in Python.

      Documentation and Tutorials (Large Project): Create clear and practical documentation, including tutorials, to support users in understanding and effectively using the interfaces.

      Participants will gain hands-on experience in Bayesian statistics, software engineering, computational methods, and developing software that works across multiple programming languages. This will prepare them well for future academic and professional opportunities.

      
      ~~~~~~~~~~
      Jaxprs in Julia
      Difficulty: Hard

      Duration: TBD

      The Turing.jl team is looking for a student to implement a lightweight Julia library to work with Jaxprs. If this could be you, get in touch and we can discuss the details.

      ~~~~~~~~~~
      VS Code extension
      We are generally looking for folks that want to help with the Julia VS Code extension. We have a long list of open issues, and some of them amount to significant projects.

      Required Skills: TypeScript, Julia, web development.

      Expected Results: Depends on the specific projects we would agree on.

      Mentors: David Anthoff

      ~~~~~~~~~~

      Package installation UI
      The VSCode extension for Julia could provide a simple way to browse available packages and view what's installed on a users system. To start with, this project could simply provide a GUI that reads in package data from a Project.toml/Manifest.toml and show some UI elements to add/remove/manage those packages.

      This could also be extended by having metadata about the package, such as a readme, github stars, activity and so on (somewhat similar to the VSCode-native extension explorer).

      Expected Results: A UI in VSCode for package operations.

      Recommended Skills: Familiarity with TypeScript and Julia development.

      Mentors: Sebastian Pfitzner

      Also take a look at Pluto - VS Code integration!

      ~~~~~~~~~~

      

      Code generation improvements and async ABI
      Because Julia relies on an asynchronous task runtime and WebAssembly currently lacks native support for stack management, Julia needs to explicitly manage task stacks in the wasm heap and perform a compiler transformation to use this stack instead of the native WebAssembly stack. The overhead of this transformation directly impacts the performance of Julia on the wasm platform. Additionally, since all code Julia uses (including arbitrary C/C++ libraries) must be compiled using this transformation, it needs to cover a wide variety of inputs and be coordinated with other users having similar needs (e.g. the Pyodide project to run python on the web). The project would aim to improve the quality, robustness and flexibility of this transformation.

      Recommended Skills: Experience with LLVM.

      
      ~~~~~~~~~~
      Wasm threading
      WebAssembly is in the process of standardizing threads. Simultaneously, work is ongoing to introduce a new threading runtime in Julia (see #22631 and replated PRs). This project would investigate enabling threading support for Julia on the WebAssembly platform, implementing runtime parallel primitives on the web assembly platform and ensuring that high level threading constructs are correctly mapped to the underlying platform. Please note that both the WebAssembly and Julia threading infrastructure is still in active development and may continue to change over the duration of the project. An informed understanding of the state of these projects is a definite prerequisite for this project.

      Recommended Skills: Experience with C and multi-threaded programming.

      ~~~~~~~~~~
      
      High performance, Low-level integration of js objects
      WebAssembly is in the process of adding first class references to native objects to their specification. This capability should allow very high performance integration between julia and javascript objects. Since it is not possible to store references to javascript objects in regular memory, adding this capability will require several changes to the runtime system and code generation (possibly including at the LLVM level) in order to properly track these references and emit them either as direct references to as indirect references to the reference table.

      Recommended Skills: Experience with C.

      ~~~~~~~~~~
      
      DOM Integration
      While Julia now runs on the web platform, it is not yet a language that's suitable for first-class development of web applications. One of the biggest missing features is integration with and abstraction over more complicated javascript objects and APIs, in particular the DOM. Inspiration may be drawn from similar projects in Rust or other languages.

      Recommended Skills: Experience with writing libraries in Julia, experience with JavaScript Web APIs.

      ~~~~~~~~~~
      
      Porting existing web-integration packages to the wasm platform
      Several Julia libraries (e.g. WebIO.jl, Escher.jl) provide input and output capabilities for the web platform. Porting these libraries to run directly on the wasm platform would enable a number of existing UIs to automatically work on the web.

      Recommended Skills: Experience with writing libraries in Julia.

      ~~~~~~~~~~
      
      Native dependencies for the web
      The Julia project uses BinaryBuilder to provide binaries of native dependencies of julia packages. Experimental support exists to extend this support to the wasm platform, but few packages have been ported. This project would consist of attempting to port a significant fraction of the binary dependencies of the julia ecosystem to the web platform by improving the toolchain support in BinaryBuilder or (if necessary), porting upstream packages to fix assumptions not applicable on the wasm platform.

      Recommended Skills: Experience with building native libraries in Unix environments.

      ~~~~~~~~~~
      
      Distributed computing with untrusted parties
      The Distributed computing abstractions in Julia provide convenient abstraction for implementing programs that span many communicating Julia processes on different machines. However, the existing abstractions generally assume that all communicating processes are part of the same trust domain (e.g. they allow messages to execute arbitrary code on the remote). With some of the nodes potentially running in the web browser (or multiple browser nodes being part of the same distributed computing cluster via WebRPC), this assumption no longer holds true and new interfaces need to be designed to support multiple trust domains without overly restricting usability.

      Recommended Skills: Experience with distributed computing and writing libraries in Julia.

      Deployment
      Currently supported use cases for Julia on the web platform are primarily geared towards providing interactive environments to support exploration of the full language. Of course, this leads to significantly larger binaries than would be required for using Julia as part of a production deployment. By disabling dynamic language features (e.g. eval) one could generate small binaries suitable for deployment. Some progress towards this exists in packages like PackageCompiler.jl, though significant work remains to be done.

      Recommended Skills: Interest in or experience with Julia internals.



      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-julia-language/
    idea_list_url: https://julialang.org/jsoc/projects/

  - organization_id: 155
    organization_name: The Linux Foundation
    no_of_ideas: 25
    ideas_content: |

      Qt Print Dialog: Modernize the user interface
      1 contributor full-size (350 hours), Level of difficulty: Hard

      The print dialog of Qt, which is also the print dialog used by KDE applications has still the user interface of 20 years ago, when I told the Qt and KDE developers that a CUPS-supporting print dialog is needed and they made this print dialog in response.

      Now, after the internals of the dialog being up-to-date (Support for the Common Print Dialog Backends added in GSoC 2022) we need to make the user interface of the Qt print dialog cute.

      The modernization should at least be a UI similar to the one of the GTK print dioalog. This should not require any extensions of the API between the print dialog and the applications and so the new dialog can replace the old one without modifications on existing applications needed.

      Optionally, depending on the time left, a dialog with built-in preview (Like in LibreOffice, Chromium, Firefox, Thunderbird) could be created. This requires more UI design work and most probably also additions to the API. The migration of a simple application (like text editor or document viewer) to the new print dialog would demo it and make the developers of other applications switch over.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Qt developers, TBD

      Desired knowledge: C/C++, Qt, UI Design

      Code License: LGPL-3 and GPL-2

      ~~~~~~~~~~

      GTK Print Dialog: Modern dialog with built-in preview in main view
      1 contributor full-size (350 hours), Level of difficulty: Hard

      Are you using LibreOffice, Firefox, Thunderbird, or Chromium with their nice, modern preview-centric print dialogs and got somewhat disappointed with GNOME apps like the Text Editor, Evince, or similar because of their more conventional GTK print dialog? Note that GTK's dialog has also a preview, but it is awkward to use, one has to click a button to get a preview, but there is no button to return to the main dialog to do adjustments.

      Then you should make an end to this problem, by modernizing the user interface (UI) of GTK's print dialog!

      Investigate the workflow of the modern preview-centric print dialogs and also have a look into their code (the mentioned apps are all open source). Also have a look into the code base of GTK's print dialog. Then design a similar UI, with embedded preview for the print dialog and implement it in GTK.

      Try to conserve the API between the application and the print dialog, so that the new print dialog can just replace old one in all applications. If this is not possible, try to keep the API additions a minimum, and for applications which are not (yet) adapted to the new print dialog, try to make as much as possible working in your print dialog (and as last resort display the old dialog).

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), GTK/GNOME developers, TBD

      Desired knowledge: C, GTK/GNOME, UI Design

      Code License: LGPL-2 or later and LGPL-2.1 or later

      ~~~~~~~~~~

      

      KDE Print Manager vs. CUPS 3.x
      1 contributor full-size (350 hours), Level of difficulty: Hard

      As we have made the “Printers” module of the GNOME Control Center supporting CUPS 3.x in several GSoC projects we need to do the same for the KDE Print Manger. And this is what this project is about.

      For the local server of CUPS 3.x the main view does not need to display CUPS queues as defined in `/etc/cups/printers.conf` with PPD files any more but instead, it has to display IPP print destinations (driverless network and IPP-over-USB printers, Printer Applications, shared remote CUPS queues) as on all these we can print, without a CUPS queue needing to be created, as CUPS creates a temporary one when needed. The destinations have to be grouped, when they come from the same device, server, or Printer Application, and the IPP destinations are configured by their admin web interfaces, so we have to add buttons to open these interfaces.

      The “Add Printer” dialog will continue to exist, but to list non-driverless (legacy or specialty) printers and assign Printer Applications instead of PPD files to them.

      Actually we will only add the new functionality and not remove the old one, meaning displaying both IPP destinations and classic CUPS queues, and in the “Add Printer” part allow for assigning both PPD files and Printer Applications (latter preferred), so that once the new Print Manager in place we can make a smooth transition from CUPS 2.x to CUPS 3.x at any time, and also, CUPS 2.x already supports IPP print destinations without permanent CUPS queue, so also for CUPS 2.x users modern, driverless printers will just appear and they do not try to unecessarily create queues for them.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Mike Noe (noeerover at gmail dot com), KDE developers, TBD

      Desired knowledge: C/C++, KDE/Qt, UI Design

      Code License: GPL 2.0 or later and LGPL 2.0 or later

      ~~~~~~~~~~

      Port pyCUPS to CUPS 3.x API + Apply the new pyCUPS to system-config-printer
      1 contributor full-size (350 hours), Level of difficulty: Intermediate

      Most software with print functionality or print administration functionality uses the CUPS library (libcups, 2.x, 3.x) to communicate with CUPS. This is easy when the software is written in C or C++ as the library is written in C.

      If the software is written in other languages, we need some connection between the library and the client code, the so-called bindings. For Python we have bindings for libcups, pyCUPS. This works well with libcups 2.x already for years. system-config-printer is principal user of pyCUPS.

      What we need now is to extend pyCUPS for the use with libcups 3.x of the new CUPS 3.x, so that pyCUPS will live on and continue to allow writing software which interacts with CUPS in Python.

      The contributor's task is to go through the APIs of libcups3 and compare them with libcups2 to see what has to be added. If there is a way to automate the creation of Python bindings, it can be used and old (libcups2) and new (libcups3) has to be merged, so that pyCUPS can be used for any version of libcups.

      It should be also taken into account that libcups2 of CUPS 2.5.x got some functions of libcups3 backported.

      system-config-printer was already updated for CUPS 3.x in last year's GSoC. Here we want system-config-printer use the new pyCUPS now, for optimization and minimization of code duplication.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Zdenek Dohnal, Printing Maintainer at Red Hat (zdohnal at redhat dot com), TBD

      Desired knowledge: Python, C, CUPS

      Code License: GPL-2+ (GPL 2 or any later version)

      ~~~~~~~~~~

      Extend PDFio to be a PDF renderer/displayer
      1 contributor full-size (350 hours), Level of difficulty: Hard

      Like CUPS, libcupsfilters is principally written in regular C and not in C++. We want to avoid C++ as it has often problems with binary compatibility and the mechanism with which the Debian/Ubuntu build services auto-detect dependencies between Debian packages get very awkward with C++.

      In libcupsfilters we now succeeded to eliminate use of C++, by replacing the use of the C++ library QPDF for PDF manipulation by Michael Sweet's PDFio and also by not using libpoppler any more but using Poppler's command line utilities instead. This was done as a GSoC project last year.

      As the call of Poppler via command line utilities and Ghostscript having a license which makes it unsuitable in vertain cases, we are looking into a PDF rasterizer which is written in straight C and has a more friendly (permissive) license. PDFio is written in C and has the same license as CUPS and libcupsfilters themselves, but it is only a PDF manipulation library, not a renderer.

      But as PDFio is able to do the “dirty work” of PDF file reading, especially navigating through the file's object structure we can make use of it to create a PDF renderer, ideally to extend the PDFio library to provide this functionality or to create the renderer library using PDFio.

      This renderer should be aimed for printing, it should be principally called from libcupsfilters, or from Printer Applications, so the goal of this project is to get in this direction and not design a fancy GUI document viewer, but a simple screen display facility would be helpful for development and debugging.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Michael Sweet, author of CUPS and PAPPL (msweet at msweet dot org), Ira McDonald (blueroofmusic at gmail dot com), TBD

      Desired knowledge: C/C++, CUPS

      Code License: Apache 2.0


      ~~~~~~~~~~

      Utilizing OSS-Fuzz-Gen to Improve Fuzz Testing for OpenPrinting Projects
      Security- and AI-related project

      1 contributor full-size (350 hours), Level of difficulty: Hard

      Recent vulnerabilities (including CVE-2024-47175, CVE-2024-47176, CVE-2024-47177) reported in OpenPrinting projects have underscored the critical need for robust security measures. Given that most of the projects of OpenPrinting are developed in C/C++, which are prone to memory violation bugs. To address these challenges, OpenPrinting has engaged with Google's OSS-Fuzz, a service designed to support open-source communities by providing large-scale fuzz testing and bug reporting, and maintains the fuzz harnesses in the separate OpenPrinting fuzzing repository.

      Current Integration with OSS-Fuzz: OpenPrinting has successfully integrated three key projects into the OSS-Fuzz workflow, with two additional projects currently in progress. Although the integration has already yielded significant results, which have reported 21 critical fixed bugs leading to more than 5,000 lines of code fixes, it remains insufficient. The testing coverage for critical components is still lacking, and the severity of potential issues within OpenPrinting projects demands further action.

      For now, OpenPrinting has integrated projects into the OSS-Fuzz workflow:

      cups
      libcups (of CUPS 3.x)
      cups-filters
      The following projects are under construction:

      libcupsfilters
      cups-browsed
      With Google's introduction of OSS-Fuzz-Gen, which leverages Large Language Models (LLMs) to enhance fuzz testing for open-source software, it has demonstrated exceptional potential in facilitating the integration of high-quality fuzz testing (Google Blog). Therefore, we aim to utilize the OSS-Fuzz-Gen framework to further improve the existing quality of OSS-Fuzz harnesses

      Project Goals for GSoC 2025: The primary objective for this Google Summer of Code project is to refine and expand our existing fuzz testing harnesses. Specifically:

      Enhancing Existing Harnesses: Improve the quality of dictionaries, configurations, and seed data for current integrations, adhering to OSS-Fuzz best practices.
      Expanding Harness Integration: Utilize OSS-Fuzz-Gen to develop and implement additional harnesses, targeting high-value, difficult-to-reach code sections with the support of LLMs.
      Contributor Responsibilities:

      Master OSS-Fuzz best practices to provide high-quality seeds and corpus for existing integrations. Employ OSS-Fuzz-Gen to create and integrate new harnesses, adopting diverse strategies to enhance code coverage.
      Collaborate with OpenPrinting developers to identify and patch vulnerabilities uncovered through fuzz testing.
      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Jiongchi Yu, PhD Candidate at Singapore Management University (jiongchiyu at gmail dot com), George-Andrei Iosif, Security Engineer at Snap Inc. (hi at iosifache dot me).

      Desired knowledge: C, Python, fuzz-testing

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      
      
      ~~~~~~~~~~
      
      Integrating OSS-Fuzz for Go-Based and Python-Based OpenPrinting Projects
      Security-related project

      1 contributor medium-size (175 hours), Level of difficulty: Intermediate

      OpenPrinting hosts many polyglot projects, which are developed not limited to languages of C/C++. We also host software written in languages like Python and Golang, which function as crucial printing APIs and often interface with C/C++ libraries to deliver comprehensive printing services. The integration of multiple programming languages into our ecosystem underscores the necessity for a broad and inclusive testing approach. Given the diversity of development environments, it is crucial to extend the testing for these projects, specifically for integration of OSS-Fuzz.

      To this end, we plan to extend the capabilities of the existing OSS-Fuzz frameworks to include projects developed in languages other than C/C++. This initiative will target Python and Golang projects, ensuring that our fuzz testing encompasses the full spectrum of development environments within OpenPrinting.

      Project Goals for GSoC 2025: The primary objective for this Google Summer of Code project is to integrate the polyglot projects in OpenPrinting into OSS-Fuzz framework and refine existing unit tests for these projects. The targeting projects include:

      Golang
      ipp-usb
      goipp
      Python
      pycups
      pyppd
      Contributor Responsibilities:

      Evaluate and Improve Testing Approaches: The contributor needs to understand existing testing strategies within the project and evaluate their effectiveness. Where there are gaps, particularly in areas that are under-tested, the contributor should develop and improve tests to cover these functionalities.
      Integrate Projects into OSS-Fuzz Workflow: The contributor should also integrate these projects into OSS-Fuzz framework, following previous integrations for C/C++ projects in OpenPrinting fuzzing repository with appropriate fuzzing corpus.
      Triage and Report Vulnerabilities: The contributor should work closely with developers from OpenPrinting to identify and report any vulnerabilities that are discovered through the testing process.
      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Jiongchi Yu, PhD Candidate at Singapore Management University (jiongchiyu at gmail dot com), George-Andrei Iosif, Security Engineer at Snap Inc. (hi at iosifache dot me).

      Desired knowledge: Python, Go, fuzz-testing

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      ~~~~~~~~~~
      
      System/Fuzz Testing of Printing Protocols
      Security-related project

      1 contributor full-size (350 hours), Level of difficulty: Hard

      As OpenPrinting advances driverless printing services, the corresponding standardized printing protocols, such as the Internet Printing Protocol (IPP), have become more and more important. The protocol is fundamental to achieving generalized printing services and thus requires rigorous security testing to prevent vulnerabilities.

      Effective testing of printing protocols and Domain-specific languages (DSL) like IPP and PostScript demands precise input pairs and well-regulated testing environments/contexts. Given the complexity and technical specifications of these protocols, creating universal testing suites that can be applied across various platforms and languages is essential. Such suites will support the consistent functionality and specification adherence necessary for secure and efficient printing operations.

      Project Goals for GSoC 2025: The primary objective for this Google Summer of Code project is to develop comprehensive testing suites designed for the printing protocols used in OpenPrinting projects (e.g., IPP). Specifically, the suites encompass: (1) unit tests and differential tests for IPP, detailing test inputs and expected outputs within the appropriate printing contexts, and (2) fuzzing enhanced by a custom validator to verify the correctness of outputs against the specifications. These suites will incorporate unified testing drivers and oracles (validated test input and output pairs) to ensure accurate and reliable results.

      Contributors are expected to achieve:

      Thoroughly understand and summarize the key aspects of printing protocols used in OpenPrinting, such as IPP and PostScript.
      Develop tailored testing strategies for these protocols, referencing standards such as RFC 8011, and OpenPrinting's 17 IPP specifications
      Implement high-quality unit tests, differential tests, and fuzzing drivers along with protocol-tailed testing oracles within OpenPrinting projects. Contributors will also be responsible for identifying any discrepancies or bugs, reporting them, and coordinating with developers to facilitate necessary fixes.
      The outputs of this project will not only serve as a valuable reference for generalizing testing across all OpenPrinting projects but also the documented progress can also lead to potential academic contributions, such as technical reports or research papers.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Jiongchi Yu, PhD Candidate at Singapore Management University (jiongchiyu at gmail dot com), George-Andrei Iosif, Security Engineer at Snap Inc. (hi at iosifache dot me).

      Desired knowledge: C/C++, security/testing

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      
      ~~~~~~~~~~
      
      Security Auditing for OpenPrinting Projects
      Security-related project

      1 contributor full-size (350 hours), Level of difficulty: Intermediate

      OpenPrinting projects play a critical role in the printing infrastructure of countless systems, making their security paramount. Inspired by security auditing reports from other open source communities (CNCF: Security Audit for Karmada, Security Audit for Kubernetes and Security Audit for OpenSSF), we believe a comprehensive security auditing report could significantly enhance the robustness and reliability of these projects. This initiative will leverage advanced software analysis methods to conduct thorough security audits.

      The audit process includes scoring OpenPrinting projects using OpenSSF’s Security Scorecard and examining the projects and their dependencies with respect to testing status, which encompasses adherence to continuous integration (CI) test best practices and test coverage assessments. Furthermore, dynamic testing should also be considered, for example, end-to-end fuzzing techniques such as AFLplusplus, which assists in the successful detection of CVE-2024-47076. Static analysis tools including cppcheck and flawfinder, Valgrind can be employed for checking the implementation flaws. The overall security audit should include dynamic software analysis methodologies to cover more extensive aspects of OpenPrinting projects.

      Project Goals for GSoC 2025: The primary objective of this Google Summer of Code project is to complete a systematic security audit report for OpenPrinting. This comprehensive process includes maximizing the scores provided by the OpenSSF Security Scorecard and scanning dependencies using existing SADT tools. In addition to static analysis, incorporating dynamic testing methodologies will provide an exhaustive overview of security across the entire network of projects. The project aims to identify and mitigate potential vulnerabilities effectively, ensuring that a robust defense mechanism is in place to protect the integrity of the OpenPrinting infrastructure.

      Contributors are expected to: Use or implement dynamic testing/auditing tools for analyzing OpenPrinting projects, which includes examining OpenSSF Scorecard of OpenPrinting projects and preparing detailed security auditing reports outlining discovered vulnerabilities. The contributor should also coordinate with security experts to address these issues effectively.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Jiongchi Yu, PhD Candidate at Singapore Management University (jiongchiyu at gmail dot com), George-Andrei Iosif, Security Engineer at Snap Inc. (hi at iosifache dot me).

      Desired knowledge: C/C++, code auditing

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      ~~~~~~~~~~
      
      Behavior-accurate simulation of multi-function printers (printer + scanner)
      1-3 contributors full-size (350 hours), Level of difficulty: Hard

      Although driverless printing and scanning are governed by standards and specifications, real hardware implementations often have unique details that can deviate from these specifications, impacting the accuracy of our printing and scanning implementations.

      We currently have the “ippeveprinter” tool, which implements an “abstract” IPP 2.x printer. However, we lack a behavior-accurate simulation of real printers and do not have any simulation for eSCL/WSD scanners.

      The goal is to create a behavior-accurate simulator for multi-function printers (MFPs) that supports at least IPP 2.x for printing, eSCL and WSD for scanning, and DNS-SD and WS-Discovery for device discovery. We aim to build a growing collection of models representing various specific devices.

      This simulator will consist of a core simulation engine that provides reference implementations of the aforementioned protocols, along with a customization engine that allows for the expression of implementation details specific to individual devices without the need to reimplement common functionalities repeatedly.

      One of our key objectives is to make the process of creating MFP models semi-automated. For instance, printer attributes and scanner capabilities can be automatically obtained, while accurately simulating behavioral features may require manual testing and analysis to identify these details, along with scripting to express them in the simulator. We anticipate that actual device behavior will not deviate significantly from the “ideal” model implemented by the simulation core, allowing models to remain relatively straightforward. Ideally, the model creation process should be simple enough for mid-level technical personnel and qualified users to undertake independently.

      This initiative opens up several new avenues:

      Remote debugging of printing/scanning issues without needing to connect to the device or engage extensively with the device owner
      The ability to test software changes without physical access to the relevant hardware
      Full-stack automated testing of printing and scanning against simulated hardware
      Initially, our collection of models will be small and may contain inaccuracies. However, as we expand our model collection, we will be able to automatically detect most regression cases during the development of the entire printing and scanning stack.

      The implementation of the simulation core has already started, what we need from the contributor(s) is to develop the initial collection of the printer models. During this phase, we will evaluate and refine the overall concept, establishing and assessing the methodology for creating MFP models.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), TBD

      Desired knowledge: Familiarity with relevant protocols (IPP, eSCL, WSD, DNS-SD), knowledge of the Linux printing and scanning stack, programming in C, and proficiency in Python or JavaScript (for scripting MFP models).

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      
      ~~~~~~~~~~
      
      Image output evaluation for testing of print/scan job processing
      1 contributor full-size (350 hours), Level of difficulty: Hard

      We do a lot of testing for quality assurance and security of our software, especially also tests of the data processing when printing and scanning. For now our only criteria to consider a test failed is a processing error, a crash, an infinite loop, or the output being empty. We do not verify whether the content of the output is actually what we have expected.

      Evaluating the correctness of the content of the output is not easy, as we cannot compare it pixel by pixel, we rather need to determine whether a human being would see the content which they have sent to the printer. This means to recognize text, structures, colors, but with a certain tolerance.

      There is free software work at GNOME for the CI testing of their GUI, which requires to analyse graphical screen content to evaluate whether the response of GUI apps to given user input is as expected, and this should be fully automated. This is the openQA project.

      To compare graphical content they use the free software computer vision library OpenCV and also the universal file comparison tool diffoscope is used to check output.

      With this we could for example take a PDF file, rasterize it in high quality, then “print” it/send it through a filter chain and afterwards compare the images. We can also OCR raster output to check whether the complete text of the input (plain text or PDF file) is conserved in the output, not having anything cut off at the borders and no glyphs missing or replaced by squares/placeholders for missing glyphs.

      See also my report from the GUADEC 2024, the section “Workshop: openQA testing for your GNOME app, module or service”.

      Tests which benefit from this are not only our CI testing in libcupsfilters, but also 2 of our other projects on this list:

      Behavior-accurate simulation of multi-function printers
      Fuzz-based testing of printing protocols
      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), TBD

      Desired knowledge: C, Go, image processing and evaluation, computer vision, OCR

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      ~~~~~~~~~~
      Port CUPS and Printer Applications to Zephyr
      Probably many of you have already thought about that one can take an SBC, install Linux and CUPS or a Printer Application on it, and connect this to an old printer which is still mechanically perfect but needs a driver which is not available any more for some operating systems. Suddenly the printer turns into a modern, driverless IPP printer which can be used with any operating system.

      But it is a little awkward having a little box dangling behind the printer which also occupies a power outlet. Also one can perhaps also make use of much cheaper SBC.

      Imagine you could buy a tiny board for a few dollars and put it somewhere inside the printer and grab its power from the printer's power supply.

      Such tiny boards are often not powerful enough to run Linux, but there is also the much more lightweight Zephyr operating system. This is a system for IoT applications on low-footprint hardware.

      And this scenario does not only serve for cheap DIY solutions to save old printers, it also can be a base for cost-effective printer firmware development.

      This project is about investigating whether one could run the components of the free software printing stack, as CUPS, PAPPL, libcupsfilters, … under the Zephyr operating system, and actually let this tiny print server execute printer drivers and print on legacy printers. Also the handling of print data and the need of resources here needs to be investigated. Can we hold several pages? Can we use Ghostscript? Or do we have to stream raster print data from the client to the printer?

      Most desirable is to do this with PAPPL (Printer APPlication Library), as it is designed to emulate a driverless IPP printer in software, including the so-called “Gadget” mode to appear as an IPP-over-USB device when connecting the power supply USB port of the SBC with the client computer's USB.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Iuliana Prodan (iuliana dot prodan at nxp dot com), Zephyr developers TBD

      Desired knowledge: C, Zephyr, USB, network

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      ~~~~~~~~~~
      Rust bindings for libcups2/3
      1 contributor full-size (350 hours), Level of difficulty: Hard

      Most software with print functionality or print administration functionality uses the CUPS library (libcups, 2.x, 3.x) to communicate with CUPS. This is easy when the software is written in C or C++ as the library is written in C. If the software is written in other languages, we need some connection between the library and the client code, the so-called bindings.

      A programming language which gets more and more used nowadays is Rust, due to its memory-safety, eliminating the number-one source of crashes and vulnerabilities. Unfortunately, we do not have Rust bindings for libcups. And getting them is subject of this project.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), TBD

      Desired knowledge: Python, C, CUPS

      Code License: GPL-2+ (GPL 2 or any later version)

      ~~~~~~~~~~
      Error response pop-up support for CPDB
      1 contributor medium-size (175 hours), Level of difficulty: Intermediate

      It often happens that a print job, sent to a network printer or to a remote CUPS queue does not get printed and a "cups-pki-invalid" error will get logged. This is due to the fact that the locally saved certificate does not match the printer (any more).

      To prevent man-in-the-middle attacks between a client and a network IPP printer with encrypted connection, the first time when a new network printer is accessed, the printer's certificate is loaded from the printer and saved locally. On subsequent accesses the printer's certificate is compared to the locally saved one and on mismatch the error is logged and the printing does not happen.

      often this happens without an attack, just on a change of the printer configuration or a printer firmware update. Then the user screams on internet platforms, when they are lucky finds information about this problem and how to remove the old certificate to make the CUPS replace it by the current one and the printer print again.

      To solve this nasty problem, we came to the conclusion to pop up a dialog which allows to remove the certificate file ("Reset certificte") by clicking a button..

      The contributor's task here is to create such a dialog and make it pop up in the right situation. The pop-up should also be used for other common error scenarios which could be solved by a simple dialog.

      The communication between the pop-up and CUPS should be done by the Common Print Dialog Backends (CPDB), extending the D-Bus interface and implementing the error handling in the CPDB CUPS backend.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Gaurav Guleria (gaurav dot gen3 at gmail dot com), Kushagra Sharma (b20251 at students dot iitmandi dot ac dot in), TBD

      Desired knowledge: C/C++, GTK or Qt, DNS-SD/Avahi, CUPS/IPP

      Code License: MIT, GPL-2+ and LGPL-2+

      ~~~~~~~~~~
      CI Testing programs for libpappl-retrofit and libppd
      1 contributor full-size (350 hours), Level of difficulty: Intermediate

      To protect a free software project worked on by several contributors against regressions caused by a committed change, one needs frequent, automated testing of the code, base, ideally triggered by every commit into the repository. This is called Continuous Integration (CI).

      What is triggered on each commit is usually some static analysis of the code using common, specialized tools and also build and execution tests, usually doing `./configure; make; make test` on different system platforms.

      This naturally requires test scripts/programs which are compiled and run by the `make test` step. For CUPS for example the daemon is started (on an unprivileged port so that it does not need root), queues created and listed, jobs sent, the logs checked whether everything went OK, … For Ghostscript a large collection of input files (gathered from bug reports) is processed and converted into raster formats.

      The contributor's task here is to write test programs for the OpenPrinting projects libppd and pappl-retrofit so that `make test` does something useful, being efficient to catch regressions. They should exercise important functionality of the software with different parameters and analyse logs and output files to check whether the program did the expected work.

      Test programs are also needed for the so-called 'autopkgtest' tests which are added to Debian packages and executed whenever the package is uploaded to Debian or Ubuntu.

      In addition, instruction files and shell scripts are needed to build the software on different platforms/environments, run tests, create GitHub Actions (for the automatic triggering on each commit …).

      This subject got discussed on the OpenPrinting micro-conference on Linux Plumbers 2022: (Summary, Slides, Video)

      Here you can see what we already have in terms of CI, and what is missing …

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Michael Sweet, author of CUPS and PAPPL (msweet at msweet dot org), TBD

      Desired knowledge: C, Shell, PAPPL, CUPS, CI

      Code License: Apache 2.0

      ~~~~~~~~~~
      cups-filters: Create OCR filter to deliver scans as searchable PDFs
      1 contributor medium-size (175 hrs), Level of difficulty: Intermediate

      Scanning with IPP Scan gives the user the possibility to request the scanned image in PDF format. If the IPP Scan server is a Scanner Application, a filter function from cups-filters would convert the the raster image coming from the scanner into PDF.

      Now such PDF files are simply raster images in a PDF frame, not high-level graphics with text and fonts, as PDFs produced by office applications are. Especially one cannot search text in a PDF coming from a scanning process.

      Ghostscript has a new “pdfocr8” device with which Ghostscript takes raster graphics PDFs (or PostScript files) as input, applies OCR (Optical Character Recognition) to the raster image, and creates a PDF which contains the raster image to visually show the scan but adds data about the contained text and where it is located, so that you can find text with the search facility of a PDF viewer.

      Here the contributor's task is to write a filter function (or extend the ghostscript() filter function) to make the “pdfocr8” output device of Ghostscript being used so that a searchable PDF is obtained.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Sahil Arora (sahilarora dot 535 at gmail dot com), Dheeraj Yadav (dhirajyadav135 at gmail dot com), TBD

      Desired knowledge: C/C++, CUPS

      Code License: Apache 2.0



      Task #1 (large/350h): Extend AGL's demo control panel
      The AGL demo control panel is a pyQt (qml) application that is able to control the AGL demo homescreen. It can replay can messages.

      Task: Extend the demo control panel to drive more signals and exercise more advanced features in AGL.

      Level of difficulty: intermediate

      Requirements: QT, pyQT, QML, grpc, kuksa.val

      Contact: jsmoeller (at) linuxfoundation.org

      ~~~~~~~~~~

      Task #2 (large/350h): Extend AGL's speech recognition app (Flutter app) with AI features
      The AGL speech recognition app is a Flutter app that uses a speech recognition engine (vosk/whisper + intent engine) for the audio processing.

      Task: Extend the demo using AI models to allow more complex interactions and reactions. Requirement is to use open-source technologies.

      Level of difficulty: intermediate

      Requirements: python, flutter+dart

      Contact: jsmoeller (at) linuxfoundation.org


      ~~~~~~~~~~

      Task #3 (large/350h): meta-ros
      Task: Work on meta-ros integration. (Robotic framework). Goal is a demo image integrating ROS + AGL .

      Level of difficulty: intermediate/difficult

      Requirements: python, …

      Contact: jsmoeller (at) linuxfoundation.org


      ~~~~~~~~~~

      Create a Linux IIO driver for Analog Devices, Inc.'s ADE9113 Isolated, Sigma-Delta Analog to Digital Converter
      Project Size: 1 contributor medium (175 hours), Level of difficulty: Intermediate

      Desired knowledge: C, Bash, operating systems elementary concepts

      The driver should be tested on the real hardware. The proposed setup is Raspberry Pi 3 Model B and EVAL-ADE9113 evaluation board.

      The goal of the project is to provide support for ADE9113 chips within Linux which will require writing device tree documentation for ADE9113 and developing an IIO device driver. The desired final project state is to have ADE9113 driver and associated device tree documentation merged with upstream IIO tree.

      We are also open to suggestions for different ADI's components. If no suggestions are made, or they are not suitable for a GSoC project, we will choose one component for the accepted student(s).

      Mentors: Marcelo Schmitt, Dragos Bogdan

      Code repository: https://git.kernel.org/pub/scm/linux/kernel/git/jic23/iio.git/

      Code License: GPLv2

 

      ~~~~~~~~~~


      Project 1: Enhancing the SOF Demo GUI for Improved Usability and Functionality
      1 contributor medium-size (175 hours)

      Level of difficulty: Intermediate

      Sound Open Firmware (SOF) is an open source audio digital signal processing (DSP) firmware and an SDK that together provide infrastructure and development tools for developers working on audio or signal processing. More on this, you can find here: https://thesofproject.github.io/latest/introduction/index.html

      SOF has support for NXP, Intel, AMD and Mediatek targets.

      SOF comes with a set of runtime tools - command line applications that can be used to exchange data with running firmware and a demo GUI.

      The current GUI, while functional, lacks some modern usability features and doesn’t fully exploit the potential of SOF’s advanced capabilities.

      This project aims to improve and enhance the SOF Demo GUI, which is used to demonstrate and control SOF components on hardware. The goal is to add new features, improve the user interface, and enhance the overall usability and functionality of the GUI.

      This project will focus on creating a new version of the GUI with the following key improvements:

      Redesign the GUI to make it more intuitive and user-friendly;
      Implement a modern and responsive design using the latest GTK features;
      Display a real-time frequency spectrum to visualize the audio signal's frequency content;
      Provide step-by-step tutorials to guide new users through the features of the GUI.
      This will involve working with the existing codebase, implementing new features, and optimizing the current functionalities.

      This project will provide a more powerful and user-friendly tool for demonstrating and controlling SOF components, benefiting developers and users in the audio processing community. The enhancements will make it easier for new users to get started with SOF, while providing advanced features for experienced users.

      Expected Outcomes:

      A significantly improved SOF Demo GUI with enhanced usability and functionality.
      Comprehensive documentation and tutorials to help users understand and utilize the new features.
      A robust and well-tested codebase that can be easily maintained and extended in the future.
      Submit all enhancements back to SOF
      Skills Required:

      Python programming
      C programming
      GTK and GUI development
      Familiarity with version control systems (e.g., Git)
      Mentors:

      Iuliana Prodan iuliana.prodan@nxp.com
      George Stefan george.stefan@nxp.com


      ~~~~~~~~~~
      Project 2: Add Virtual DAI component to SOF
      1 contributor medium-size (175 hours)

      Level of difficulty: Intermediate

      We want to have a Virtual DAI for two reasons:

      debugging and rapid prototyping. We want to be able to create a quick audio pipeline without using a real DAI device.
      first step in implementing a software loopback pipeline that will help implement a memory to memory processing pipeleline
      The DAI should have two directions:

      playback → just get the data from source and do 'consume' it. Similar with /dev/null.
      capture → generate data (zeroes or some patterns) and send it to sink. Similar with /dev/zero or /dev/urandom
      Expected Outcomes:

      SOF Virtual DAI component implemented and merged upstream
      Simple pipeline with playback and record working
      Virtual DAI will log output frames and throw them out
      Record will generate frames filled with zeroes
      Skills Required:

      C programming
      Familiarity with version control systems (e.g., Git)
      Mentors:

      Daniel Baluta daniel.baluta@nxp.com


      ~~~~~~~~~~

      Project Idea: patch-hub v.1.0.0
      Details
      Project Size: 1 contributor full-size (350 hours)
      Level of Difficulty: Hard
      Helpful Experience: FLOSS development and Rust
      Description
      As mentioned before, in the GSoC 2025 edition, we intend to focus on a single project on the kw sub-project patch-hub. Linux kernel development is done via electronic mail and mailing lists, so instead of submitting pull requests on GitHub through the web, contributions, reviews, and the like are done by sending emails to other developers and mailing lists.

      Software development based on email may seem a little confusing, especially if you have never heard of it, but the important point is that even though there are some arguments in favor of it, there are many inefficiencies and complexities that come with it.

      patch-hub, following the kw spirit of simplifying workflows, aims to simplify the workflows of kernel developers when consuming from the development mailing lists. The tool is constructed as a Terminal UI (TUI), so it is a little less “roots” than a fully CLI system like the rest of kw, but still no graphical interface 8-)

      Below is a video of a simple demo of the tool. From listing the available development lists to consulting the flow of patchsets (a set of related patches, similar to a PR or an MR), their individual contents, and running actions on them, the tool aims to completely cover this part of kernel development.

      patch-hub demo video

      Don't forget to check out the patch-hub GitHub repo.

      Getting to Version 1
      As you can see in the demo video, patch-hub isn't in its initial stages, but there is a lot of work to be done. Currently, the latest released version is v0.1.4, and we are close to v0.2.0, which will be its beta.

      With that being said, between the beta and v1.0.0, there are many tasks to be made, which we can highlight:

      Redesign the architecture, as the technical debt is getting bigger
      Implement custom kernel build
      Implement inline review
      Make patchset reply with git send-email not teardown the UI
      Expand the unit test coverage, which is (being nice) small
      Enhance UI and UX
      And much more…
      The idea is not to strictly get to v1.0.0 by the end of the program but to get as near as possible. At least, we need a solid and robust base that will streamline the rest of the work!

      Interact with the kw/patch-hub community!
      Interacting with kw and patch-hub as a system/tool and a free software project is critical to grasping the dynamics and technical challenges you will face in your GSoC. This means it's nice to use kw and patch-hub to understand its purposes and functionalities while also reporting bugs and suggesting enhancements (take a look at patch-hub reported issues). Don't be afraid to open pull requests addressing them! We really encourage you to do it!

      As this edition focuses on patch-hub, we ask that you also focus the interaction on patch-hub. So, please open PRs, discuss issues, and the like on the [[https://github.com/kworkflow/patch-hub|patch-hub repo]]

      ~~~~~~~~~~


      Project 1: Running Open-Source ML Models on HiFi4 DSP with Zephyr RTOS
      Machine-Learning-related project

      1 contributor medium-size (175 hours)

      Level of difficulty: Intermediate

      Zephyr is an open-source, real-time operating system (RTOS) optimized for resource-constrained devices, making it ideal for IoT and embedded systems. It supports multiple architectures and has a modular design.

      For machine learning (ML) with Zephyr, developers can integrate frameworks like TensorFlow Lite for Microcontrollers (TFLM) or Edge Impulse. These allow small, efficient ML models to run on devices with limited CPU and memory resources.

      The i.MX series from NXP features powerful DSP cores that can offload computational workloads from the main CPU.

      This project will focus on leveraging Zephyr RTOS to manage ML workloads on these DSPs efficiently. It will require porting or optimizing existing ML frameworks for the DSP, designing APIs for seamless integration, and demonstrating an end-to-end ML pipeline running on Zephyr. Potential deliverables include support for TFLM on the DSP, and a sample application showcasing the implementation.

      Expected Outcomes:

      Integration of ML inference frameworks (such as TFLM) on NXP DSPs running Zephyr
      Sample applications demonstrating ML inference (e.g., speech recognition, anomaly detection)
      Documentation and tutorials for deploying ML workloads on NXP DSPs
      Submit pull requests to Zephyr’s upstream repository
      Skills Required:

      C/C++ programming
      Embedded systems and real-time operating systems (Zephyr)
      Familiarity with TensorFlow Lite Micro or similar lightweight ML frameworks
      Familiarity with version control systems (e.g., Git)
      Mentors:

      Iuliana Prodan iuliana.prodan@nxp.com
      George Stefan george.stefan@nxp.com
      Daniel Baluta daniel.baluta@gmail.com
      Laurentiu Mihalcea laurentiu.mihalcea@nxp.com



      ~~~~~~~~~~
      Project 2: Port CUPS and Printer Applications to Zephyr
      1 contributor full-size (350 hours)

      Level of difficulty: Intermediate

      Probably many of you have already thought about that one can take an SBC, install Linux and CUPS or a Printer Application on it, and connect this to an old printer which is still mechanically perfect but needs a driver which is not available any more for some operating systems. Suddenly the printer turns into a modern, driverless IPP printer which can be used with any operating system.

      But it is a little awkward having a little box dangling behind the printer which also occupies a power outlet. Also one can perhaps also make use of much cheaper SBC.

      Imagine you could buy a tiny board for a few dollars and put it somewhere inside the printer and grab its power from the printer's power supply.

      Such tiny boards are often not powerful enough to run Linux, but there is also the much more lightweight Zephyr operating system. This is a system for IoT applications on low-footprint hardware.

      And this scenario does not only serve for cheap DIY solutions to save old printers, it also can be a base for cost-effective printer firmware development.

      This project is about investigating whether one could run the components of the free software printing stack, as CUPS, PAPPL, libcupsfilters, … under the Zephyr operating system, and actually let this tiny print server execute printer drivers and print on legacy printers. Also the handling of print data and the need of resources here needs to be investigated. Can we hold several pages? Can we use Ghostscript? Or do we have to stream raster print data from the client to the printer?

      Most desirable is to do this with PAPPL (Printer APPlication Library), as it is designed to emulate a driverless IPP printer in software, including the so-called “Gadget” mode to appear as an IPP-over-USB device when connecting the power supply USB port of the SBC with the client computer's USB.

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      Skills Required:

      C/C++ programming
      Embedded systems and real-time operating systems (Zephyr)
      Familiarity with version control systems (e.g., Git)
      Mentors:

      Till Kamppeter till@linux.com (Project lead OpenPrinting)
      Iuliana Prodan iuliana.prodan@nxp.com
      Zephyr Developes TBD

      ~~~~~~~~~~

      SBOM Conformance Checker

      Create a web accessible tool for validating SPDX 3.0 documents.

      Size: Medium (175 hours)

      Level of Difficulty: Hard

      Skills Needed:

      Software development skills for Web based applications
      Good user interface design skills
      Understanding of SBOM conformance and related standards/regulations such
      has CISA Common Software Bill of Materials or EU AI Act

      Background Information:

      An online form which allows the uploading, parsing, and validation of SPDX 3.0 would provide immediate benefit to the SPDX community. There is no specific programming language requirement, but there is an existing Java and Python libraries which could be used in the project. Some of the technical challenges for this project include having to handle long running operations and implementing a very robust parser implementation able to handle any input.

      Available Mentors: John Speed Meyers, Gary O'Neall (gary at sourceauditor dot com)

      




      
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-linux-foundation/
    idea_list_url: https://wiki.linuxfoundation.org/gsoc/google-summer-code-2025


  - organization_id: 156
    organization_name: The Mifos Initiative
    no_of_ideas: 40 
    ideas_content: |

      Migrate Android Client to Kotlin Multiplatform 
      Mentors
      @Rajan Maurya @Chinmay Kulkarni @Shashank Priyadarshi 
      Length
      Large - 350 hours
      Category
      Mobile - Android SDK | Kotlin Multiplatform
      Overview & Objectives
      The goal of this project is to migrate Android field officer kotlin multi-module application to Kotlin Multiplatform and rewrite network layer by adopting fineract-client-kmp-sdk, make all the network calls are working as expected. The Android client will be the first of the Mifos mobile apps which consume the SDK, reducing repeated network layer code in mobile apps, improving developer experience, and making it easier to migrate to newer versions of Apache Fineract 1.x and Student would work on designing offline sync functionality in background.
      This year we are totally focusing on migrating to Kotlin Multiplatform, writing Unit and Instrumentation test and writing github actions to automate release process using fastlane.
      Description
      In 2025, The student will be working on implementing the following things:
      Update the Android client to latest dependencies
      Rewrite Network layer of Android client to consume fineract SDK using coroutines instead of RxJava implemented code.
      Migrate kotlin multi-module codebase to Kotlin Multiplatform
      Write appropiate unit and integration tests.
      Update CI/CD to build APK and analyses code quality
      Implemented Playstore release github action pipeline
      Integrate google playstore API for better and faster release flow.
      Update corresponding documentation for building the app.
        Helpful Skills
      Android, Kotlin Multiplatform, Kotlin, Jetpack compose, navigation-compose, MVVM, coroutines, Flow, multi-module architecture.
      Impact
      High performance using jetpack compose
      Clean code and easy understandable code because of multi-module and coroutines implementation. 
      Kotlin Multiplatform support to build application for Android, IOS, Desktop, Web.
      Overall stability by increased testing coverage through a more stable and error-free codebase. 
      Improved developer experience through faster build time. 
      More seamless release management and upstream contribution 
      Reduction of time to upgrade 
      Other Resources
      QA & Testing - 
      QA & Testing - Fineract - Apache Software Foundation  
      2024 GSOC Final Report (Aditya Gupta): 
      GSoC'24_Final_Report_Android_client.md 
      Github
      GitHub - openMF/android-client: An android client for the MifosX platform 
      GitHub - apache/fineract: Apache Fineract 
      GitHub - openMF/fineract-client: Mifos Fineract Client is a Java based library that provides a simple interface to interact with the Apache Fineract 1.x Platform APIs 
      GitHub - openMF/fineract-android-sdk: This is architecture repository for mifos-android-sdk 
      
      
      ~~~~~~~~~~

      
      Making Mobile Wallet Deployment-Ready for G2P and Merchant Use Cases
      Mentors
      @Rajan Maurya @Avinash Vijayvargiya 
      Length
      Large - 350 hours
      Category
      Mobile - Mifos X | Core Development
      Overview & Objectives
      2025 development will focus on refining our current Mobile Wallet to be a strong reference implementation of feature-rich and secure mobile wallet application for G2P use cases. While our mobile wallet is a powerful tool for all fintechs and financial institutions, we want to powerfully and simply demonstrate the ability for governments to disburse G2P Payments to highly functional mobile wallet and then be able to transact with that wallet by paying for bills, sending transfers, and paying for goods and services via merchants. We provide a reference mobile wallet application for consumers and merchants that has been developed by our Google Summer of Code interns from 2017 to 2024. The mobile wallet provides an extensible mobile wallet framework to support the basic use cases of a mobile wallet as documented in the Level One Project mobile wallet requirements. This extensible framework should support both merchant and client use cases as well as be capable of integrating with a Fineract back-end 
      Over time, we would like Mifos X to be more generically a wallet management system and this reference application is a powerful tool to support that. 
      In 2025, we will also focus on enabling real-world merchant flows based on requirements from in-country users using the wallets for consumer to merachnt transactions. 
      Description
      The initial mobile wallet framework along with 2 reference apps, PixieCollect and MifosPay, were developed in 2017. Later we decided to continue with MifosPay application only which as mentioned uses the mobile wallet framework.
      In 2019, these functionalities were extended further by Shivansh including improving user experience and redesigning the app, support for Kotlin, integration with two Mojaloop transaction flows via the Paymeht Hub, adding improving Deeplinks, support for standing instructions and more well-rounded support for merchant transactions.
      In 2020, Devansh Aggarwal further added complete support for standing instructions, integrated with Fineract CN for core use cases by mapping Fineract back-office APIs to Fineract CN APIs, added multi-theme support, completed integration with Payment Hub EE, added support for Hover, and converted Java code to Kotlin (in progress). For more details refer this
      In 2021, Kinar Sharma, worked on developing a new multiplatform mobile wallet application using Kotlin multi-platform. This new application consumes FineractCN APIs and is built upon clean architecture. Kinar completed the data, domain and presentation layer (only for Android) for usecases available in FineractCN.
      In 2022, Prashant Singh continued to evolve the app.
      In 2023, Rachit focused on refining the architecture, streamlining the design and implementing some of the G2P use cases.
      In 2024, Pratyush focused on migrating codebase from single module app into kotlin multi-module application by migrating xml to jetpack compose.
      In 2025, we are targeting to make production-ready our cases for G2P, update dependencies, consume more uniformly our SDKs fix pending issues and introduce new features. Functional enhancements include:
      Integrate latest version of Payment Hub EE
      Integrate Mifos' notifications framework to provide support for usecases like merchant request to pay.
      Implemented Apple Store and Desktop apps release github action pipeline
      Update wallet framework to be make use of Mifos' Android SDK
      Improving the security framework to integrate more seamlessly with middlewares, API gateway, and identity management software
      Exploring proof of concept architecture or redesigns to align with movements like the Open Wallet Foundation.
      Write end to end Unit and Instrumentation test suite.
      Helpful Skills
      Android, Kotlin, Kotlin Multiplatform, Jetpack compose, Ktor, Room, Git
      Impact
      By providing an extensible mobile wallet framework, allow partners a complete reference stack of back and front-end applications to offer digital financial services to clients.
      Other Resources
      2024 Mobile Wallet Final Report (Pratyush Singh): 
      GSoC'24_Final_Report_Mobile_Wallet.md | Aditya Kumdale: 
      GSoC'24 Final Report - The Mifos Initiative | Functional Enhancements to Mobile Wallet for G2P Use Cases 
      2023 Mobile Wallet Final Report: 
      GSoC 2023: Final Work Submission 
      2020 Mobile Wallet Progress: https://gist.github.com/devansh-299/e2041c07d9ab55a747391951e9090df4
      Mobile Wallet Framework: Source Code | Issue Tracker  | Slack
      See 
      Mifos Wallet 

      ~~~~~~~~~~
      Integrate Mifos X with Workflow Engine/Process Automation Tool 
      Mentors
      @Aleksandar Vidakovic @Victor Romero 
      Length
      Large - 350 hours
      Category
      Back-end Platform | Modules 
      Overview & Objectives
      Users of Mifos have long had a need to have greater control and flexibility over creating loan and customer onboarding workflows that incorporate internal processes/steps as well processes involving external systems. This project would center around creating an external integration with a workflow engine such as Flowable or jBPM using the Mifos X REST API as the glue. The auto-generated client library from the back-end enforces the contract between the workflow engine and core banking system. The core banking and its REST API act as the glue. The result would be a UI-driven workflow engine to allow non-technical users to define these new custom workflows where they could drag and drop the different steps of the process. 
      Description
      Assumptions:
      BPMN should be adopted as a standard so which can make the workflow engine independent of the technology stack. 
      BPMN editors allow end users to sketch the workflow and generate a machine readable and executable output. 
      Workflow actions or business logic would be written in Java as part of Fineract so adapters will be need to be created on the workflow engine to execute actions on our side. 
      External processes would be sub-flows that could be used like lego bricks and included in the parent workflow context. 
       Steps:
      Intern would select a workflow engine to integrate with and then build adapters to trigger and transfer fm BPMN form data into specific core banking back-office REST API calls. 
      Currently business logic such as creating a customer is triggered by an API call in Fineract. For this project, the intern would define a BPMN form with all the data that is needed which could be defined as a human task. Proceeding through each step triggers an adapter that transforms the generic BPMN form data into specific core banking back-office REST API calls
      Intern would go through the entire REST API building these adapters to trigger transformation of BPMN into core banking back-office REST API callsCurrently when creating a customer, API by API, the intern would define 
      Once all the calls in Mifos X have been transformed, the integration could provide for triggering any external  customer-specific action/workflow/API call/ system integration
      Helpful Skills
      Java, BPMN
      Impact
      UI-Driven interface based on BPMN standard to allow for non-technical users to define customer onboarding and application workflows via a drag and drop interface.
      Other Resources
      Flowable 
      jBPM Business Automation Toolkit 
      BPMN Specification - Business Process Model and Notation 
      Transforming ICT4D: OpenFn's Workflow Automation Platform 
      n8n.io - a powerful workflow automation tool  

      ~~~~~~~~~~ 
      Build new Modern Web UI for Mifos X using ShadCN Reusable Components 
      Mentors
      @Aleksandar Vidakovic 
      Length
      Large - 350 hours
      Category
      Front-End - Web
      Overview & Objectives
      This project would extend up on existing efforts to create a micro front-end approach for our UIs. As the userbase for Mifos/Fineract extends beyond just microfinance and financial inclusion we need to enable developers to easily build front-end user experiences that align with the wide variety of back-end use cases supported by our platform being used by MFIs, credit unions, banks, fintechs and governments. Additionally, many of the flow and screens used by staff as well as customers are common across mobile and web application. 
      Right now the look and feel and the overal UI development experience is very limited by using Angular and Material Design. 
      Description
      This project would aim to build both the micro front-end framework and leverage a set of res-usable UI components that can be deployed as individual flows or end to end applications. Growing in popularity for its flexibility, ease of development, efficient performance, modular design is the ShadCN UI Library which contains unstyle components offering a higher degree of customizability. 
      The current standard UI for Mifos X is still the Web App which is the only one that covers 100% of the feature set. While based on Angular and more modern than our previous Community App, the project hard to maintain and - apart from the occasional color change - hard to customize let alone integrate in other web applications. Developers should be able to pick any number of standalone components and integrate them in custom UI projects (where Fineract is one among multiple backends). All Mifos X UI components should be published for easy consumption by other developers.
      Intern would aim to replicate the current Web UI which is in Angular using the Material Design library using ShadCN components built on ReactJS. 
      This project would use the official typescript API client for Fineract. 
      Tooling should help with consistency and reduce handwritten code as much as possible. Using Monorepos is strongly suggested.
      Helpful Skills
      JavaScript, JSX , React, Tailwind CSS 
      Impact
      Developers can more rapidly build out user interfaces for different financial service use cases with a greater degree of design flexibility in terms of customizability of the look and feel  
      Other Resources
      Build your component library - shadcn/ui 
      What is Shadcn UI and why you should use it? 
      Tailwind CSS - Rapidly build modern websites without ever leaving your HTML. 
      Radix UI 

      ~~~~~~~~~~
      Extend and Evolve UI Library of common components across all Mobile Apps
      Mentors
      @Chinmay Kulkarni  @Devansh Aggarwal @raul.sibaja
      Length
      Large - 350 hours
      Category
      Mobile - Mifos X | Core Development | Infrastructure 
      Overview & Objectives
      For 2025, our efforts this project will focus on delivering components that can be utilized as part of Compose Multiplatform and in conjunction with resuable components like ShadCN. 
       In 2022, Rahul Gill, created and completed the first iteration of our UI library for our mobile apps. Our suite of customer-facing mobile applications include our mobile wallet framework, and mobile banking apps for Fineract 1.x and Fineract CN. These are designed to serve as reference implementations for demonstration purposes but also to act as secure and robust starting dough that can be extended and enhanced and white-labeled.
      With the move towards more digital financial services, these reference solutions are ever more important and critical and must appear highly polished, clean, and professional. We are working with a designer to provide a set of clean, consistent and professional UI designs and workflows to implement across our customer-facing apps. 
      This project would focus on implementing these new designs across the customer-facing apps providing a consistent and familiar look and feel. It will build off of efforts in 2020 and 2021 implementing the UI designs previously proposed during GCI. 
      Across all our mobile apps, there are common screens and workflows  with a lot of redundant and inconsistent design and development from scratch. The creation of a UI library of common shared components and design standards and guidelines would enable the following: 
      Improve developer experience and ease of development
      Consistent look and feel of UIs for all apps
      Defined process for updating apps.
      Develop common UI library to ensure consistency of all apps
      Design guidelines, principles, and standards
      Could potentially be a valuable upstream project in and of itself to create mobile fintech apps
      Description
      In 2025, with leadership of our mentors, this project would focus on extening the initial shared components of the UI library based off of the common screens and workflows identified across the various mobile apps. These common flows will be broken down into their-base-level elements and components.  This components should be built to be compatible with Compose Multiplatform for re-usability across mobile, web, and desktop. 
      Design enhancements to customer-facing apps include: 
      Break down common workflows into base-level components
      Refine and update design standards and guidelines
      Create and set up repository to house elements, components, and designs using jetpack compose.
      Design core ui component for our fintech app using jetpack compose. 
      Develop and create base-level elements and components accoring to UI design standards and guidelines
      Implement screens and workflows to test out on reference open banking fintech app
      Documentation to ensure how to use UI library and update mobile app when UI library is updated. 
      Helpful Skills
      Android Development, Kotlin, Java, Jetpack Compose, XML, Git, Compose Multiplatform
      Impact
      A clean and simple UI is key for our low-tech audience and professional and consistent look and feel enhances credibility of our stack. 
      Other Resources
      Recap on 2022 GSOC Project from Rahul Gill: 
      GSoC '22 Report | The Mifos Initiative | Mifos Android UI library 
      Mobile App UI Library 
      2020 UI Enhancements: https://gist.github.com/ShivangiSingh17/67b6041387c1e281caa7df23347f549e
      Mobile Wallet Framework: Source Code | Issue Tracker | Slack
      Mifos Mobile - Android Mobile Banking App: Source Code | Issue Tracker | Gitter Chatroom
      See https://openmf.github.io/mobileapps.github.io/
      
      ~~~~~~~~~~
      
      Mifos Gazelle: Postman Coverage
      Mentors
      @David Higgins + TBC
      Length
      Large - 350 hours 
      Category
      Platform | DevOps  | Mifos Gazelle
      Overview & Objectives
      Mifos Gazelle brings together multiple components and DPG’s into a single deployment process. A key objective for Gazelle is ease of deployment and ease of use.  To that end Mifos Gazelle needs to maintain good documentation and Postman collections of all its API’s (including those of components).
      Description
      This project would focus on gathering together all the API’s within Gazelle components into a single Postman collection.
      Mifos Gazelle users and PHEE, MifosX and vNext users and learners would benefit greatly from a targeted and well tested postman collection and associated environment.  This would draw heavily from the existing postman tests for MifosX PaymentHub and vNext perhaps a subset from each and would be specifically customised and organised for a Mifos gazelle deployment of all 3 initial components.  This collection would be included in the Mifos Gazelle repository and would also be well documented perhaps with a step by step guide for a number of test scenarios (Mifos Partylookup, vNext PartyLookuop, Bulk Payment etc ) 
      The collection could be very specific for instance hostnames could be set in the environment which are aligned with the Mifos gazelle deployment scripts and well known data (tenants, parties etc) would be utilised. 
      The folder structure of the collection would also be customised to reflect the Mifos Gazelle deployment 
      The design needs to be extendable beyond the initial 3 components as Mifos Gazelle grows.
      Helpful Skills
      Docker, Kubernetes, Jenkins, Bash, REST APIs , Postman.
      Impact
      DevOps and Sys Admins running our projects would experience a more simplified deployment with greater degree of control, improved quality of their builds and greater reliability and ease of testing through a qualified and reliable Postman collection
      Other Resources
      GAZ-13 - create Mifos Gazelle specifc postman collection TO DO

      ~~~~~~~~~~  
      Voice-Driven Banking via Large Acoustic Models (LAMs) (AI)
      Mentors
       @Lalit Mohan S @Akshat sharma 
      Length
      Large - 350 hours 
      Category
      AI | Platform - Modules  | Exploratory
      Overview & Objectives
      The "Voice-Driven Banking via Large Acoustic Models (LAMs)" project develops a voice-based banking platform to enable financial transactions in low-resource languages and dialects. The system will support tasks like balance inquiries, fund transfers, credit applications, and more using voice commands, removing barriers of literacy and technical skills. This initiative targets rural and underserved populations, promoting financial inclusion through innovative AI solutions.
      Objectives
      Technical: Build and deploy LAMs for regional languages and accents, integrated with NLP for intent recognition and voice biometrics for secure authentication.
      Business: Expand access to banking services, improve customer engagement, and reduce service costs via automation.
      Social: Empower non-literate users in underserved areas with seamless access to financial tools.
      Impact and Outcome
      Impact
      Technical: Robust voice recognition for low-resource languages, secure voice authentication, and modular scalability for future enhancements.
      Business: Increased customer base, lower operational costs, and improved satisfaction.
      Social: Enhanced financial access for marginalized groups and improved digital literacy.
      Outcome
      Application: Mobile/web app supporting voice-driven banking in multiple regional languages.
      Capabilities: Voice-initiated transactions (balance checks, payments, loans) with real-time processing.
      Security: Voice biometrics and encrypted transactions for data integrity.
      Analytics: Dashboards to monitor usage and improve language support.
      The final product will simplify banking for rural users, bridging the digital divide and boosting financial inclusion effectively.
      The idea behind this project is to use a LLM to give command/prompts and have those commands fulfilled via selenium
      Description
      The "Voice-Driven Banking via LAMs" project focuses on creating a voice-based banking platform supporting low-resource languages and dialects. The intern will:
      Research: Identify target languages and user needs for voice-based banking tasks.
      Develop Core Features:
      Train/optimize Large Acoustic Models (LAMs) for voice recognition.
      Build NLP pipelines for multilingual intent recognition.
      Integrate voice biometrics for secure authentication.
      System Integration: Design a scalable backend and integrate workflows (e.g., balance checks, payments) with banking systems.
      Testing & Optimization: Conduct accuracy and reliability testing, refine models, and ensure accessibility on low-end devices.
      Documentation: Deliver technical documentation, user guides, and training materials in target languages.
      Expected Deliverables
      A functional voice-based banking app supporting multiple languages.
      Secure voice-enabled workflows for key banking operations
      Documentation and guides for system use and maintenance.
      
      Helpful Skills
      Python, TensorFlow, PyTorch, Natural Language Processing (NLP), Large Acoustic Models (LAMs), speech-to-text systems, voice biometrics, API development
      Impact
      This project will have a significant impact by promoting financial inclusion, especially for underserved and rural populations. By enabling voice-driven banking in multiple low-resource languages, it empowers individuals who may be illiterate or lack digital skills to manage their finances independently. From a business perspective, it opens new customer segments, reduces operational costs through automation, and drives customer loyalty. Technically, the project advances voice recognition, natural language processing, and secure authentication systems, pushing the boundaries of AI in financial services. Ultimately, this initiative fosters social equality, digital literacy, and economic stability, while innovating how banking can be made accessible to all.
      Other Resources
      Documentation on Speech-to-Text and Voice Recognition
      DeepSpeech GitHub(
      GitHub - mozilla/DeepSpeech: DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers. ) – Mozilla’s speech-to-text model that may be useful for voice recognition tasks.
      Kaldi(
      Kaldi ASR ) – An open-source toolkit for speech recognition, widely used in research.
      Large Acoustic Models (LAMs) and NLP Resources
      Speech Recognition with Deep Learning – A tutorial on speech recognition using TensorFlow.
      Transformers by Hugging Face – A popular NLP library that could be adapted for multilingual NLP tasks.
      Voice Biometrics and Security
      Voice Authentication System (API) – Twilio API for implementing voice biometrics in applications.
      General AI and Machine Learning for Banking
      AI in Financial Services – An article detailing AI applications in the financial sector.
      Financial Services AI – A report from Accenture on the future of AI in banking.
      
      ~~~~~~~~~~
      LAM (Large Action Model) for Fineract (AI)
      Mentors
      @jeremy engelbrecht 
      Length
      Large - 350 hours 
      Category
      AI | Platform - Modules  | Exploratory
      Overview & Objectives
      The idea behind this project is to use a LLM to give command/prompts and have those commands fulfilled via selenium
      Description
      Following the similar types of commands/actions that can be executed in Fineract via our chatbot, this project would use LLMs to determine the intent of a user and fulfill those actions in the Mifos/Fineract applications using a tool like Selenium. 
      Helpful Skills
      Python, LLM(Llama2 or similar), Selenium
      Impact
      This would dramatically change the way individuals interact with financial services. It goes well beyond a chatbot by being able to engage with a tool that can apply for and initiate financial transactions via prompts. 
      Other Resources
       XGBoost Documentation — xgboost 2.1.3 documentation 

      ~~~~~~~~~~
      Generative AI to Improve Mifos Documentation 
      Mentors
      @jeremy engelbrecht @Lalit Mohan S @David Higgins 
      Length
      Large - 350 hours 
      Category
      AI | Platform - Modules  | Exploratory
      Overview & Objectives
      Mifos & Apache Fineract provide a suite of core banking applications which are highly complex applications both from a technical and domain knowledge perspective. 
      Maintaining updated documentation around installing, configuring and using the application is challenging and presents a steep learning curve.
      The goal of this project is to use Generative Pretrained Transformer (GPTs) (which is a family of large language models (LLMs) based on a transformer deep learning architecture) for providing answers  to most common questions and for organizing documentation. It is important to ingest data for training this GPT using the manuals, source code repositories, Wiki, ReadMes, mailing list posts, forum posts, slack discussion, and documentation hosted on our project sites, it would greatly simplify the experience for any implementer looking to use the software.
      Description
      In 2025 the Intern would develop/train a GPT using all the sources of technical and user documentation across our project such that implementers could interact with the documentation in a Q&A style format.
      In 2024 in an initial increment of this project an LLM was created that was trained on a specific subset of documentation.
      In 2025 focus needs to be on how this can be scaled across the full documentation set, how to resolve conflicts in answers when you look at large scale documentation.  
      AI tools have changed significantly in the last year that the approach should be changed so then the interaction with them can be implemented using agents.
      An alternative focus of this project could be how to use AI to generate or update documentation at the point of release.
      Helpful Skills
      Hugging Face, LlaMA, Colab, GPT, N8N.
      Impact
      This would greatly simplify the process of configuring, deploying and using our core banking software across various use cases making the software and documentation more maintainable for the project and more usable for the customer base. 
      Other Resources
      What is Generative AI?  | IBM  
      What is a Transformer Model? | IBM  
      Generative AI: Answering Your Frequently Asked Questions | Synechron  
       https://huggingface.co/docs/transformers/model_doc/llama2 
      2024 Mifos Summer Intern Final Showcase -  GSOC - Shubham Pal  - Generative AI for Community Support 
      
      
      ~~~~~~~~~~
      Fraud & Risk Management & Transaction Monitoring POC (Tazama) (AI) 
      Mentors
      @jeremy engelbrecht @Lalit Mohan S @Aleksandar Vidakovic 
      Length
      Large - 350 hours 
      Category
      AI | Platform - Modules  | Exploratory
      Overview & Objectives
      With continually growing adoption of Payment Hub EE to connect fiancial institutions using or not using Fineract into real-time payment systems, the likelihood of fraud is ever-growing. With all of this transactional data flowing into and out of Fineract, there is now also a wealth of data to analyze using rule-based and AI-based methods to detect transactional patterns and identify fraud. A lot of fraud detection and transaction monitoring happens centrally at the level of the payment switch but there’s quite a bit of value in analyzing this at the level of each individual DFSP and sharing this on-us transaction data back to the central payment switch or system
      Goal of this project would be to work on a proof of concept integration between Mifos/Fineract and Payment Hub EE with a FRMS solution for fraud detection and transaction monitoring. Given the power and potential of generative AI for financial services, project shoudl explore the use of generative AI for the following areas as documented by Newron:
       Anomaly Detection: Generative AI models can create synthetic data that mimics legitimate transactions. By training on both genuine and synthetic data, models become adept at detecting unusual patterns indicative of fraud.
      Adaptability: Unlike rule-based systems, Generative AI models can adapt to new fraud patterns. As fraudsters evolve, the model evolves with them, improving detection rates.
      Data Augmentation: Generative AI can augment imbalanced datasets by creating synthetic examples of rare events (fraudulent transactions), making the model more robust.
      Unsupervised Learning: Generative AI models, like Variational Autoencoders (VAEs) or Generative Adversarial Networks (GANs), learn patterns in an unsupervised manner, reducing the need for manual labeling of fraudulent cases.
      Behavioural Analysis: Generative AI can analyze transaction behaviours, such as user interactions or purchasing habits, to identify deviations from the norm
      Project could be integrated with Tazama which although rule-based and not AI-based provides a powerful FRMS solution. 
      Description
      Intern would work on a POC integration to monitor and analyze data from real-time payment system flowing via Payment Hub EE into Fineract. Project could utilize generative AI to improve effectiveness of solutiona and can leverage existing efforts in the community to collaborate with eKuta solution. 
      Helpful Skills
      Hugging Face transformer, Llama2 or similar, Colab
      Impact
      Real-time payments make the challenges and consequences of fraud ever more steep and severe. Using Generative AI to combat it and integrating with FRMS solutions will help the user base using Payment Hub EE and Fineract. 
      Other Resources
       Revolutionising Fraud Detection with Generative AI 
      Open Source Solution FRMS Solution - Tazama - 
      Home 

      ~~~~~~~~~~
      Kotlin Multiplatform App Template Framework 
      Mentors
      @Rajan Maurya 
      Length
      Large - 350 hours
      Category
      Mobile, Kotlin Multiplatform, Compose Multiplatform
      Overview & Objectives
      Throughout 2024, we continued migrating all of our mobile apps to Kotlin Multiplatform and in the processed developed some valuable generic tools and templates to help with building out applications using Kotlin Multiplatform. This project would continue to refine and extend these frameworks. 
      Description
      The focus for 2025 on this project would be the following: 
      Write Material Design3 component layer that can be customizable on top level so anyone forking the repo and creating a project can just add the theme configuration and rest is maintainable in template.
      Write base configuration for Android, Ios, Desktop, Web so whoever is creating project out of template will only adding configuration that will replace the default one.
      Write release github actions for all the platform Android, Ios, Desktop, web using Github Actions.
      Write network, database, datastore etc base layer so it will act like external component can be or can’t be added in the project.
      Write Gradle plugin for dependencies like Room, datastore, ktor, compose etc so it can behave as component and we can have introduce Amper as an alternative for build system.
      Make sync common directories more generic.
      Helpful Skills
      Android, Kotlin, Kotlin Multiplatform, Jetpack compose, Ktor, Room, Git
      Impact
      Streamling the developer experience and reducing the learning curve for building cross-platform apps with native user experiences on top of Kotlin Multiplatform. 
      Other Resources
      Source Code
      GitHub - openMF/kmp-project-template: The Kotlin Multiplatform Multi-module Template generator simplifies cross-platform development by enabling shared business logic and UI components across Android, iOS, Desktop, and Web, while retaining native platform functionality. 
      
      ~~~~~~~~~~
      
      Kotlin Multiplatform App Health Framework 
      Mentors
      @Rajan Maurya 
      Length
      Large - 350 hours
      Category
      Mobile, Kotlin Multiplatform, Compose Multiplatform
      Overview & Objectives
      Throughout 2024, we continued migrating all of our mobile apps to Kotlin Multiplatform and in the processed developed some valuable generic tools and templates to help with building out applications using Kotlin Multiplatform. We realized over past experience that we need a Kotlin Multiplatform tool that checks and take care of app health and give out summary of app breaking points and manage whole thing locally and as well as pushes to firebase logging so we can know where exactly the problem lies instead of walking to crash analytics.
      Description
      The focus for 2025 on this project would be the following: 
      Designing a plan and Product specs.
      Write a local database layer that will store all data required to debug the crash, issue etc.
      Write a sync layer for Kotlin Multiplatform that gives ability to pull issues and debug stream data to fix the issue.
      Design a frame work that will take write in firebase events and manage in such a manner so we can find where issue lies.
      Write a layer that will look for memory leak in the code and analyze and suggest fixes using AI
      Give ability user to expose or keep whole thing locally.
      Write logging layer that will be annotation based and log things for debugging.
      Helpful Skills
      Android, Kotlin, Kotlin Multiplatform, Jetpack compose, Ktor, Room, Git
      Impact
      Streamling the developer experience and reducing the learning curve for building cross-platform apps with native user experiences on top of Kotlin Multiplatform. 
      Other Resources
      Source Code: 
      openMF/app-health-kmp 

      ~~~~~~~~~~
      Open Banking/PISP Fintech App Framework Version 3.0 (GovTech)
      Mentors
      @Shashank Priyadarshi 
      Length
      Large - 350 hours
      Category
      Mobile, Exploratory
      Overview & Objectives
      The 2025 focus for this project would be extending upon the work that was done during Code for GovTech in 2024. Across our ecosystem we're seeing more and more adoption and innovation from fintechs. A huge democratizing force across the financial services sector is the Open Banking movement providing Open Banking APIs to enable third parties to directly interact with customers of financial institutions. We have recently started providing an Open Banking API layer that will allow financial institutions using Mifos and Fineract to offer third parties access to requesting account information and initiating payments via these APIs. Most recently the Mojaloop community, led by Google, has led the development of a centralized PISP API
      To demonstrate these Open Banking APIs and use cases that third parties and fintechs can provide we have developed a cross-platform reference mobile app on Kotlin to showcase a number of these features. It currently connects with the Open Bank Project that adheres to the UK Open Banking API standard. The API Gateway to connect to is still being chosen (WS02, Gravitee, etc.)
      The breadth and variety of apps that could be built leveraging these APIs from region to region is endless. We would like this app to be built in an extensible and modular fashion such that core libraries and components could be re-used across different use cases with this framework as the foundation and multiple reference apps on top. Applications include personal financial management apps aggregating information from multiple bank accounts in one place, wallet apps allowing payments to be made from different banks, lending apps, leveraging data and insight from multiple accounts, savings apps, etc.
      Description
      Intern would work on refining the initial architecture of the framework, the UI and user experience, core use cases including customer authentication and onboarding that was implemented in 2020 and integrating with the Fineract Open Banking APIs and Mojaloop PISP APIs to demonstrate use cases around account information request and payment initiation. 
      This would be a continuation of the project worked on a couple year’s back but essentially the idea is the same to have a stand-alone reference third party fintech app that demonstrates 3rd party initiation/ Open Banking APIs so the app itself would need its own separate user managment, etc but then it would pull in data by authorizing consnet via open banking api to pull in transactional data from a mifos/fineract account (could extend exiting open banking adapter and map additional fineract apis to UK open banking api standard and most importantly we’d want to use this reference fintech app to demonstrate the use of Mojaloop/Google 3PPI PISP APIs whereby a user could authorize and establish consent across any bank participating in a mojaloop switch to the fintech to initiate transactions through mojaloop via their accounts managed in Mifos/Fineract
      Aggregating account information across multiple banks/financial institution
      Initiating payments across multiple financial institutions
      Integrate with additional Fineract Open Banking APIs
      Integrate with Mojaloop PISP APIs. 
      Leverage completed components of UI library 
      Helpful Skills
      Android development, SQL, Java, Javascript, Git, Spring, OpenJPA, Rest, Kotlin, Mojaloop
      Impact
      By providing an extensible open banking fintech app framework, allow partners a complete stack of Open Banking APIs and reference front-end application to rapidly build innovation via Open Banking APIs.   
      Other Resources
      Source code: 
      GitHub - openMF/pisp-app: Repository for app for third party payment initiation use cases (PISP, Open Banking, 3PPI) 
      Figma Design Mockups: 
      Mifos PISP App 
      Previous Development:
      2023 Mifos Summer of Code Final Report - 
      MSoC'23-pisp-app-report.md 
      2020 Google Summer of Code Final Report - 
      Google Summer of Code 2020: Mifos Open Banking App | Report by Ankur Sharma 
      Google Whitepaper on 3PPI: https://static.googleusercontent.com/media/nextbillionusers.google/en//tools/3PPI-2021-whitepaper.pdf
      UK Open Banking API Standard: 
      Standards Home - Open Banking Standards 
      Open Banking Developer Zone: 
      Developer Zone 
      Examples of Open Banking Apps: https://www.ft.com/content/a5f0af78-133e-11e9-a581-4ff78404524e 
      See 
      Mobile Applications


      ~~~~~~~~~~ 
      Micro Front-ends Proof of Concept for Fineract 1.x  & Mifos X 
      Mentors
       @Jose Hernandez @Aleksandar Vidakovic @Ed Cable 
      Category
      Web - Mifos X Web App/Fineract 
      Overview & Objectives
      Originally this idea was sparked by looking at what Moov has around UI drops - 
      Drops: Prebuilt UI components for beautiful payment experiences  and 
      Moov Drops Many different goals, directions, use cases emerge but they would all share in helping make UI more maintainable, more pluggable and having more of a toolkit for builders/developers that would align with Fineract being used for various core banking use cases outside of just financial inclusion as well as the need supporting a variety of fintech use cases with common elementsIn conversation with others, some different directions could emerge:
      @Nayan Ambali and seeing how Finflux has separated out UIs for different personas
      With @Victor Romero  serving the need to help others do custom/specific page view for certain functionality
      Ability to more pluggable components especially for customer-facing operations/use cases
      Have micro-front-ends be brought together to create a monolithic application like the web-app
      @aleksvidakovic suggestion on the real value being in how these components are used in other frameworks/portals and not a full complete application like we currently have.
      For this round of GSOC I’d like us to define a project where we could do a micro front-end around a certain domain/functionality and pick a framework/design/architectural approach that we’d follow. (edited) 
      Our 2022 intern, Ramveer Singh made substantial progress in completing the development of our new web app such that the Web App is now part of the Mifos X release distribution and we’ve fully deprecated our older Community App.  Our Angular Web App is the standard application on the Mifos X distribution that provides all the core functionality for the most common methods of financial inclusion and products and services. It's also the starting point for any partners looking to customize or extend the UI. It's constantly being improved based on user feedback, better performance, and to integrate new design standards.
      The focus for 2025 will be on continuing to optimize the design of key flows, improving app localization, adding in better context-sensitive help, improving dashboards and visualizations, and refactoring of the web app to consume a type-script client for better maintainability. 
      Description
      Given this project is in it infancy, this would really be a proof of concept design the proper archiecture, learn which use cases are best candidates for pluggable and modular UI components and then choosing a framework in which to deploy multiple micro front-end as a single applicaiton with a unified user experience for end users. 
      Propse and design architecture for Micro Front End approach
      Determine best front-end language or javascript framewor to use - leaning towards Angular
      Identify which existing screens or new screens should be implemented as seaprate microservice UIs. 
      Primary efforts center around:
      Fixing remaining issues
      Redesigning customer and account dashboard pages
      Refactor web app to consume typescript client
      Enhance look and feel of app. 
      Implement third party library for proper internationalization. 
      The remaining issues can be found: https://github.com/openMF/web-app/issues 
      The progress is being tracked here: 
      Mifos Web App Task List 
      Some additional work also includes adding in comprehensive keyboard shortcuts to enable power-users of the app and to ensure that the tabs and arrow keys work appropriately for navigating through the app, localization support, additional dashboards, adding of tooltips, etc. 
      Helpful Skills
      Javascript, SCSS, HTML5, Angular 9, Angular Material, Flex Layout
      Impact
      More pluggable, faster to develop, modular UI that better supports variety of use cases of Fineract.
      Reduced dependency on using entire monolithic app. 
      Other Resources
      Usability and Design
      Moov UI Drops - 
      Drops: Prebuilt UI components for beautiful payment experiences  and 
      Moov Drops
      Article on Angular & Micro Front-ends using Module Federation - 
      Micro Frontends with Angular, Module Federation | Auth0 

      ~~~~~~~~~~
      Usability Improvements for Mifos X Web App
      Mentors
        @Bharath Gowda @Pushpendra Kumar @Ramveer 
      Category
      Web - Mifos X Web App
      Overview & Objectives
      Our Angular Web App is the standard application on the Mifos X distribution that provides all the core functionality for the most common methods of financial inclusion and products and services. It's also the starting point for any partners looking to customize or extend the UI. It's constantly being improved based on user feedback, better performance, and to integrate new design standards. Our 2024 interns, Omar Nabil, progress our implementation of translations, redefined styling in the app and implemented a number of usability improvements. This built upon the work of our 2023 intern, Pushpendra who completed the remaining work on the web app to fully deprecate our Community App. 
      2025 focus will be on continuing to optimize the design of key flows, continued improvements to  app localization, adding in better context-sensitive help, improving dashboards and visualizations, and completing the refactoring of the web app to consume a type-script client for better maintainability. 
      Description
      Our legacy community app is now fully deprecated so we must continue to refine the Mifos X web app including updating core dependencies. We must upgrade Angular to its latest stable verison and implement a number of critical design and usability enhancements to the core customer account and dashboard pages. In order to synchronize the UI with the version of each release of the back-end platform we need to complete the refactoring of the interaction layer to consume the auto-generated typescript client, and deepend the integration and seamless user experience with Apache Superset for dashboards and visualizations. 
      Primary efforts center around:
      Update Angular to latest stable version
      Fix identified usability improvements prioritized by community 
      Redesign customer and account dashboard pages
      Implement UI screens for new features contributed by commumity 
      Implement authentication framework to fully integrate Superset for dashboards. 
      Finalize refactoring of web app to consume typescript client
      Enhance look and feel of app. 
      Continued Improvements of  translations 
      Usability Issues and Improvements can be found: 
      https://mifosforge.jira.com/jira/software/c/projects/WEB/boards/62Can't find link
      Some additional work also includes adding in comprehensive keyboard shortcuts to enable power-users of the app and to ensure that the tabs and arrow keys work appropriately for navigating through the app, localization support, additional dashboards, adding of tooltips, etc. 
      Helpful Skills
      Javascript, SCSS, HTML5, Angular, Angular Material, Flex Layout
      Impact
      Enhanced User Experience, Intuitive application design
      Other Resources
      2024 Progress (Omar): 
      GSoC'24 Report - Mifos X Web App Enhancements 
      2023 Progress: 
      Final Report of GSOC'23 
      2022 Progress: 
      GSOC_2022_Ramveer_Final_Submission.md 
      2020 Progress: 
      Final Work Product Submission for Google Summer of Code'20 at The Mifos Initiative - Karan Takalkar(@karantakalkar) 
      Final Work Product Submission for Google Summer of Code'20 at The Mifos Initiative - Muskan Khedia(@muskankhedia) Usability and Design
      ~~~~~~~~~~
      
      Mifos Gazelle: Profile/Demo Creator (NEW!)
      Mentors
      @David Higgins + @Abhinav Kumar 
      Length
      Large
      Category
      Platform - DevOps | Infrastructure
      Overview & Objectives
      Over the past 2 years we have developed a Deployment Tool for DPI infrastructure called Mifos Gazelle.  This aligns to DPI as a packaged Solution (DaaS) toolkit approach.  It currently (as of v1.0.0) deploys 3 DPG components a Payment Orchestration (Mifos Payment Hub EE) a core banking solution (Mifos X including Fineract as a backend) and a payment switch (vNext Beta 1.0).  There is a roadmap to include other DPGs and by the start of this project there may be a 4th DPG included.
      Description
      Currently the Mifos Gazelle deployment does not have an easy way to create demos or profiles although there has been alot of thought and discussion around this see  GAZ-17 - Profile/Demo creator TO DO  .
      This project would look into this area research the options, agree the approach with the mentors and community and develop the first profile/demo creator tool for Mifos Gazelle.
      This project would suit someone who wants to explore and define a new element to a project rather than just follow a set of tasks.
      Helpful Skills
      Docker, Kubernetes, Jenkins, Bash, Java - Spring, PostgreSQL, MariaDB, Cassandra, TDD With JUnit 4, Gradle, CircleCI, Helm, UI , Angular, Research + other soft skills
      Impact
      Provide an easy way for institutions considering DPI to deploy and develop use cases and demos on Mifos Gazelle.
      Other Resources
      Helm Chart for Fineract deployment - 
      fineract-env/helm/fineract at master · fynarfin/fineract-env 
      Helm Charts for Payment Hub EE deployment  - 
      ph-ee-env-labs/helm at master · openMF/ph-ee-env-labs 
      Docker Compose for Mifos - (Fineract Back-End + Web App) - 
      GitHub - openMF/mifos-x-containers: Quick Deployment tool for having a running, non persistent Mifos X environment for demonstration purpose 
      Docker Hub Image of Fineract - https://hub.docker.com/u/openmf 
      https://hub.docker.com/r/apache/fineract 
      Fineract Technical Documentation - 
      Fineract Platform Documentation 
      Miniloop -  
      GitHub - mojaloop/mini-loop: Deployment utilities for Mojaloop 
      Payment Hub EE - 
      Welcome - Mifos Payment Hub EE 
      Lab Environment Overview - 
      Lab environment | Mifos Docs 
      GAZ-17 - Profile/Demo creator TO DO  

      ~~~~~~~~~~



      Mifos Gazelle: Support for ARM
      Mentors
       @tom daly 
      Length
      Large
      Category
      Platform - DevOps | Infrastructure
      Overview & Objectives
      Over the past 2 years we have developed a Deployment Tool for DPI infrastructure called Mifos Gazelle.  This aligns to DPI as a packaged Solution (DaaS) toolkit approach.  It currently (as of v1.0.0) deploys 3 DPG components a Payment Orchestration (Mifos Payment Hub EE) a core banking solution (Mifos X including Fineract as a backend) and a payment switch (vNext Beta 1.0).  There is a roadmap to include other DPGs and by the start of this project their may be a 4th DPG included.
      Description
      Currently the Mifos Gazelle deployment does not support ARM although the vNext already runs and builds docker images for ARM.  This project would primarily focus on updating all the OpenMF pipelines for MifosX and Payment Hub  EE such that it can be built for ARM.  This may included the 4th DPG at that point.
      This would allow for running on Apple devices or Raspberry Pi.
      We would like to be able to run Mifos Gazelle on a couple of Raspberry Pi devices (we call this DPI in a Box).  This project could extend to include this depending on time.
      The Intern must be able to problem solve. We expect during this exercise to hit challenges especially around dependencies that will need to be resolved (especially for Payment Hub EE) and this may result in upstream contributions to these DPGs.
      Helpful Skills
      Docker, Kubernetes, Jenkins, Bash, Java - Spring, PostgreSQL, MariaDB, Cassandra, TDD With JUnit 4, Gradle, CircleCI, Helm
      Impact
      Provide an easy to deploy package to help institutions considering DPI to deploy and develop use cases.
      Other Resources
      Helm Chart for Fineract deployment - 
      fineract-env/helm/fineract at master · fynarfin/fineract-env 
      Helm Charts for Payment Hub EE deployment  - 
      ph-ee-env-labs/helm at master · openMF/ph-ee-env-labs 
      Docker Compose for Mifos - (Fineract Back-End + Web App) - 
      GitHub - openMF/mifos-x-containers: Quick Deployment tool for having a running, non persistent Mifos X environment for demonstration purpose 
      Docker Hub Image of Fineract - https://hub.docker.com/u/openmf 
      https://hub.docker.com/r/apache/fineract 
      Fineract Technical Documentation - 
      Fineract Platform Documentation 
      Miniloop -  
      GitHub - mojaloop/mini-loop: Deployment utilities for Mojaloop 
      Payment Hub EE - 
      Welcome - Mifos Payment Hub EE 
      Lab Environment Overview - 
      Lab environment | Mifos Docs 
      GAZ-10 - ARM support for all Gazelle components TO DO  


      ~~~~~~~~~~



      Self Service Middleware SDK for Mifos X/Apache Fineract (Mifos Mobile, Mobile Wallet, Online Banking App)
      Mentors
      @Victor Romero @Avinash Vijayvargiya 
      Length
      Large - 350 hours
      Category
      Mobile/Platform
      Overview & Objectives
      A powerful and compelling use case of Mifos X is to power any type of customer-facing digital experience (mobile wallet, mobile banking, etc). However we must enable these digital experiences to connect securely to the back-end. We currently have a self-service API layer which is valuable for demonstrating customer-facing actions that can be performed via mobile banking and online banking apps but these APIs were not intended for deployment in live production environment and are being deprecated for a more secure option.
      This project would focus on building out the self-service middleware SDK for Mifos X and Apache Fineract by defining a subset of the APIs to secure expose such that external users can inititate transactions and interact with accounts within Fineract. 
      Victor Romero has created a design for implementation of this middleware layer and would mentoring the intern to implement this design. 
      Some of these effort will also align with previous efforts around Open Banking APIs. Across our ecosystem we're seeing more and more adoption and innovation from fintechs. A huge democratizing force across the financial services sector is the Open Banking movement providing Open Banking APIs to enable third parties to directly interact with customers of financial institutions. We have started providing an Open Banking API layer that will allow financial institutions using Mifos X to offer third parties access to requesting account information and initiating payments via these APIs. This also aligsn with the centralized PISP API introduced within Mojaloop by Google.  
      Tremendous impact can be had at the Base of the Pyramid by enabling third parties to establish consent with customers authorize transactions to be initiated or information to be accessed from accounts at their financial institution. This  Open Banking API layer would enable any instituion using Mifos or Fineract to provide a UK Open Banking API layer  to third parties and fintechs.  
       The API Gateway to connect to is still being chosen (WS02, Gravitee, etc.)
      Description
      In 2025, Intern would need to familiarize with the proposed design and initial codebase contributed by Victor. This design follows the existing architectural patterns of our SDKs and client, exposin the appropriate APIs using coroutines and publishes them in a secure manner. The APIs that are consumed by the mobile banking applications have been documented in the spreadsheet below. The APIs have also been categorized according to whether they are an existing self-service API or back-office API and if they have an equivalent Open Banking API and if so, a link to the corresponding Open Banking API.
      For example: 
      Submit Loan Application (Self-ServiceAPIwith EquivalentOpenBankingAPI)
      https://demo.mifos.io/api-docs/apiLive.htm#loans_create Used by Mifos Mobile
      ImagesAPI(Back-OfficeAPIwith No EquivalentOpenBankingAPI)
      https://demo.mifos.io/api-docs/apiLive.htm#client_images Used by Mifos Mobile and Mobile Wallet 
      Fetch Identification CardAPI(Fineract CNAPIwith no equivalentOpenBankingAPI)
      https://docs.google.com/document/d/15LbxVoQQRoa4uU7QiV7FpJFVjkyyNb9_HJwFvS47O4I/edit?pli=1#heading=h.xfl6jxdpcpy1
      Sample APIs to be Documented
      -------------------------------------------
      Mifos Mobile API Matrix (completed by Ashwin)
      https://docs.google.com/spreadsheets/d/1gR84jZzLF-mM0iRw5JyeMAsHMK6RQPK0vyDmNAY9VhE/edit#gid=0
      MIfos Mobile API Matrix (completed by Shivangi)
      https://docs.google.com/spreadsheets/d/1exTv68v1IW_ygS7mSj0_ySFWGTj06NcxPZeNLjNIy6Y/edit?pli=1#gid=0
      Helpful Skills
      Android development, SQL, Java, Javascript, Git, Spring, OpenJPA, Rest, Kotlin, Gravitee, WSO2
      Impact
      By providing a secure middleware layer we can enable both trusted first party apps to allow customers to autheniticate and access their accounts as well as an API layer for third party fintechs to securely access FIneract and request information or initiate transactions with the consent of customers.
      Other Resources
      Self-Service Middleware Layer/Plugin (Designed Implemented by Victor): 
      GitHub - openMF/selfservice-plugin: Self Service Plugin for Apache Fineract 
      CGAP Research on Open Banking: https://www.cgap.org/research/publication/open-banking-how-design-financial-inclusion
      Docs: https://mifos.gitbook.io/docs/wso2-1/setup-openbanking-apis
      Self-Service APIs: https://demo.mifos.io/api-docs/apiLive.htm#selfbasicauth
      https://cwiki.apache.org/confluence/display/FINERACT/Customer+Self-Service+Phase+2
      Open Banking Adapter: https://github.com/openMF/openbanking-adapte
      Transforms Open Banking API to Fineract API | Can connect to different API gateways and can transform against different API standards.
      Reference Open Banking Fintech App:
      Backend: https://github.com/openMF/openbanking-tpp-server | GUI: https://github.com/openMF/openbanking-tpp-client
      Google Whitepaper on 3PPI: https://static.googleusercontent.com/media/nextbillionusers.google/en//tools/3PPI-2021-whitepaper.pdf
      UK Open Banking API Standard: https://standards.openbanking.org.uk/
      Open Banking Developer Zone: https://openbanking.atlassian.net/wiki/spaces/DZ/overview
      Examples of Open Banking Apps: https://www.ft.com/content/a5f0af78-133e-11e9-a581-4ff78404524e
      See https://openmf.github.io/mobileapps.github.io/
      
      
      ~~~~~~~~~~

      Reactive Loan Risk Assessment Engine for Mifos
      Mentors
      @Ed Cable 
      Length
      Large - 350 hours 
      Category
      Back-end Platform - Modules & Integration (Mifos X)
      Overview & Objectives
      Provides financial institutions with real-time insights into loan risk, helping them make better lending decisions.
      A reactive backend ensures the system can handle a growing number of requests as Mifos deployments expand.
      Improved risk assessment can lead to more responsible lending practices, ultimately benefiting underserved communities.
      Description
      In 2025 the Intern would:
      Create a dedicated microservice in Java that handles loan risk assessment asynchronously.
      Utilize reactive programming paradigms to ensure scalability and high throughput.
      Design and implement a configurable risk scoring model that can incorporate multiple factors such as client financial history, repayment behavior, and external credit ratings.
      Allow for model tuning via configuration, so institutions can adapt the scoring criteria to local requirements.
      Helpful Skills
      Java, Spring Boot, Microservices, Gradle,  testing, SQL
      Impact
      This project will significantly enhance the Mifos X and Apache Fineract platforms by improving the scalability, performance, and reliability of backend services. By transitioning to a reactive microservices architecture using modern Java technologies like Spring
      Other Resources
      [FINERACT-2021] Type-safe REST API layer - ASF JIRA 
      [FINERACT-2022] Type-safe native SQL queries - ASF JIRA 
      Querydsl - Unified Queries for Java 
      
      
      ~~~~~~~~~~
      
      Mobile Check Deposit Proof of Concept Using Moov Image Cash Letter 
      Mentors
      @Victor Romero 
      Length
      Large - 350 hours
      Category
      Mobile | Platform - Integrations
      Overview & Objectives
      As more and more implementers of Mifos X, use the platform for digital and neobank use cases, the ability to remotely capture check (i.e. mobile check deposit) becomes necessary. There are many proprietary solutions to achieve this but this project would aim to create a Proof of Concept that is completely open source to enable a neobank or any financial institution to offer to its members mobile check deposit capability. This would especially be relevant for the credit unions, community banks and smaller financial institutions that are adopting MIfos and Fineract as their core system.
      Description
      This project would be built as a new module that is easily embedded or integrated into our Mifos Mobile self-service mobile banking app. It would consist of an open source tool for actually scanning or capturing the check deposit and use the Moov open source Image Cash Letter library to parse, create, and validating ICL files.
      Image Cash Letter (ICL) specifications provide Check 21 services and are designed to enable banks to handle more checks electronically, which should make check processing faster and more efficient. Traditionally, banks often physically move original paper checks from the bank where the checks are deposited to the bank that pays them. The overall process of translating physical checks to electronic messages is called Check Truncation.
      Helpful Skills
      Java, Android,Kotlin, Compose, Go
      Impact
      Ease of use for end user - enabling small financial institutions like credit unions to offer mobile check deposit at lower cost. 
      Other Resources
      Moov Image Cash Letter Library - 
      Overview 
      Demo of ICL Library - 
      ICL | Moov 
      Github of ICL Library: 
      GitHub - moov-io/imagecashletter: X9’s Specifications for ICL (Image Cash Letter) to provide Check 21 services. The HTTP server is available in a Docker image and the Go package is available. 
      Proprietary Remote Check Capture applications - 
      10 Remote Cheque Deposit Applications in the US from Non-Banks 
      
      ~~~~~~~~~~
      
      POC for Integration with Loan Decisioning (Lokyata, Begini, nTropy)
      Mentors
      @Victor Romero @Aleksandar Vidakovic 
      Length
      Large - 350 hours
      Category
      Platform - Modules
      Overview & Objectives
      Mifos/Fineract is a very robust and highly functional Loan Management System of Record. Typically adopters of the system will build their own or implement a third party tool to score their borrowers, analyze credit risk, and do their loan decisioning as part of their origination processes. Once this decisioning engine has determined eligbiility of the borrower, the customer and loan and ensuing lifecycle can then be managed in Mifos/Fineract. Mifos/Fineract can easily receive information from this decisioning engine and send information to the decisioning/scoring engine to faciilitate this analysis.
      There are a number of different best practice alternative and traditional credit scoring/decisioning tools that Mifos/Fineract could more tightly integrate with. By providing a working integration of plugin framework for integrating with decisioning, our community can have better access to decisioning tools to improve the health of their portfolios.   This project would extend up on existing efforts to create a micro front-end approach for our UIs. As the userbase for Mifos/Fineract extends beyond just microfinance and financial inclusion we need to enable developers to easily build front-end user experiences that align with the wide variety of back-end use cases supported by our platform being used by MFIs, credit unions, banks, fintechs and governments. Additionally, many of the flow and screens used by staff as well as customers are common across mobile and web application. 
      Description
      This project endeavors to create a plugin framework for integration with external decisioning engines. It should identify, design, and build out the points of integration and interaction for inbound and outbound data flows at both the back and front-end for decisioning/scoring tools of both traditional as well as alternative sources of data. This work would include leveraging Fineract data tables for storing and displaying this external data, the respective webhooks, APIs, and events that are called or triggered during the scoring process. Likewise this project would dovetail well with our workflow engine integration as flows would be calling both of these systems. Traditional providers we could potentially build integrations with include Lokyata which provides more out of the box scoring or tools like nTropy which allow data enrichment to build ones one model. On the alternative side, we are exploring integration with Begini which provides pyschometric assesment data as well as behavioral and usage data from the phone to assess credit worthiness. 
      Work would be be on both the back and front-end.
      Helpful Skills
      Java, Spring, Angular, PostgreSQL, MySQL/MariaDB, REST
      Impact
      Cost-effective and modern decisioning to improve the health and creditworthineess of a loan portfolio. More replicable integration points with external systemn that can be followed for other integrations. 
      Other Resources
      Lokyata | Future of underwriting powered by AI. 
      Ntropy | Accurate Data Enrichment API 
      Home 
        
      ~~~~~~~~~~
      
      Digital Bank UI using Compose Multi-Platform Micro Front-End for Web and Mobile Apps 
      Mentors
      @Pushpendra Kumar b20 122 
      Length
      Large - 350 hours
      Category
      UI, Mobile
      Overview & Objectives
      This project would extend up on existing efforts to create a micro front-end approach for our UIs. As the userbase for Mifos/Fineract extends beyond just microfinance and financial inclusion we need to enable developers to easily build front-end user experiences that align with the wide variety of back-end use cases supported by our platform being used by MFIs, credit unions, banks, fintechs and governments. Additionally, many of the flow and screens used by staff as well as customers are common across mobile and web application. 
      Description
      This project would aim build both the micro front-end framework and set of UI components that can be deployed as individual flows or end to end applications across both web and mobile. Recently emerging is the Compose Multiplatform which extends Jetpack Compose to work beyond just mobile devices. 
      The current standard UI for Mifos X is still the Web App which is the only one that covers 100% of the feature set. While based on Angular and more modern than our previous Community App, the project hard to maintain and - apart from the occasional color change - hard to customize let alone integrate in other web applications. Developers should be able to pick any number of standalone components and integrate them in custom UI projects (where Fineract is one among multiple backends). All Fineract UI components should be published for easy consumption by other developers.
      Documentation of the project could follow latest best practices (aka “Storybook”)
      Tooling should help with consistency and reduce handwritten code as much as possible. Using Monorepos is strongly suggested.
      Helpful Skills
      JS, Android, React, CSS 
      Impact
      Developers can more rapidly build out user interfaces for different financial service use cases with a greater degree of design flexibility 
      Other Resources
      Compose Multiplatform UI Framework | JetBrains 
      GitHub - JetBrains/compose-multiplatform: Compose Multiplatform, a modern UI framework for Kotlin that makes building performant and beautiful user interfaces easy and enjoyable. 
      
      ~~~~~~~~~~
      
      OpenG2P  - Digital Identity Proof of Concept with MOSIP (GovTech)
      Mentors
      @Ed Cable @Manoj VM 
      Length
      Large - 350 hours
      Category
      Platform & Modules - Digital ID, Exploratory, Bleeding Edge
      Overview & Objectives
      Digital Identity is a pressing topic and for both generations of Fineract (1.x and CN), we'd like to have integration with emerging KYC and digital identity solutions.
      KYC (Know your customer) is a fundamental banking concept. It refers to the process of identifying a new customer at the time of account opening, in compliance with law and regulation. The identification requirements may be lower for low value accounts ("Tiered KYC"). The term is also used in connection with regulatory requirements for a provider to understand, on an ongoing basis, who their customer is and how they are using their account. Most of the banks are mandated to perform basic/extensive KYC, before they can serve their customers.
      Traditionally KYC is done in a centralised fashion where a central agency has the control over all the data. For example consider each bank like SBI, Deutsche, JP Morgan, etc. when creating a bank account, each of them requires a separate KYC process to be completed and all this data gets stored in their respective databases. Even the systems like Aadhar or social security number, etc. have the data stored in a central manner and maintained by the government. However, in recent times all these centralised identity servers continue to be hacked and the important and private data being stolen regularly.
      Omidyar Network along with Gates Foundation have developed the MOSIP project which provides an open source digital ID platform. Integration between Mifos along with Mojaloop can provide an end to end reference architecture for a digital cash transfer system built on open source digital public goods. 
      Decentralised system means that no one person has control over sensitive data.
      It enables the re-use of KYC, i.e. each financial institution or in our case each customer using Fineract may not have to perform its own complete KYC, but re-use the KYC already performed by others (those who have the power as issuing authority for any kind of claim).
      Cryptographic security is the heart of blockchain technologies enhancing privacy.
      Claim-based system where the end user/customer has the control over his data.
      Description
      Integration between Mifos and digital identity systems and KYC protocols could be deepened. This project would focus on an initial proof of concept integration with MOSIP APIs for digital identity including
      ID Repository
      ID authentication
      Biometric Integration 
      Registration 
      Registering a client with a MOSIP-powered Digital Identity in a Mifos system and verifying that digital identity to perform transactions. 
      
      Helpful Skills
      HTML, Spring, Hibernate, REST, Java, AngularJS, Javascript, SQL, 
      MOSIP 
      Impact
        Other Resources
      MOSIP https://www.mosip.io/
      MOSIP Docs: https://docs.mosip.io/platform/
      
      ~~~~~~~~~~
      
      Machine Learning Scorecard for Credit Risk Assessment Phase 7 (AI)
      Mentors
      @Lalit Mohan S  @Nasser Kaze @Victor Romero 
      Length
      Large - 350 hours
      Category
      AI, Platform - Modules, Bleeding Edge
      Overview & Objectives
      Financial Organizations using Mifos/Fineract are depending on external agencies or their past experiences for evaluating credit scoring and identification of potential NPAs. Though information from external agencies is required, financial organizations can have an internal scorecard for evaluating loans so that preventive/proactive actions can be done along with external agencies reports. In industry, organizations are using rule based, Statistical and Machine learning methods for credit scoring, predicting potential NPAs, fraud detection and other activities. This project aims to implement a scorecard based on statistical and ML methods for credit scoring and identification of potential NPAs.
      Description
      in 2025 the approach should improve last year's GSOC work on Features/Characteristics, Criteria and evaluation. The design and implementation of the screens should follow Mifos Application standards. Should implement statistical and ML methods with explainability on decision making. Should also be extensible for adding other functionalities such as fraud detection, cross-sell and up-sell, etc.
      The system should be able to connect to external sources/providers(e.g. Credit Bureaus) to obtain a credit history that should weigh for the credit worthiness. The scorecard should be able to self update with increase and changes in data. This requires an ML pipeline to continually improve the scorecard models.
      Priorities:
      Further optimize the ML and statistical models.
      Improve the Rule Based scoring system by fine-tuning the features.
      Setup ML pipeline to refresh dataset and models using Federated Learning techniques
      Implement Synthetic Data using SDV or any other open source synthetic data
      Extend the approach beyond Credit Scoring such as Fraud detection
        Helpful Skills
      JAVA, Integrating Backend Service, MIFOS X, Apache Fineract, AngularJS, ORM, ML, Statistical Methods, Django
      Impact
      Streamlined Operations, Better RISK Management, Automated Response Mechanism
      Other Resources
      Source Code: 
      GitHub - apache/fineract-credit-scorecard: Fineract Credit Scorecard - A credit scoring module for Apache Fineract (https://github.com/apache/fineract) 
      Previous GSOC Progress
      2024 Project (Parth Kaushal): 
      GitHub - openMF/scorecard-ai 
      2022: 
      fineract-federatedLearning-research/READEME.md at main · Zavier-opt/fineract-federatedLearning-research Suchit’s Final Report - 
      GSoC '22 for Mifos Submission 
      2021: 
      Google Summer of Code 2021 Final Report.md 
      2020: https://gist.github.com/humbletechy/43e7322913af561fdd7db5d4962d59a7 
      2019: 
      GSoC'19 Final Report 
      Documentation
      Fineract Credit Scorecard - Fineract - Apache Software Foundation 
      lalitsanagavarapu’s gists 
      
      ~~~~~~~~~~
      
      Mifos Mobile 7.0 - Mobile Banking App
      Mentors
      @Ahmad Jawid Muhammadi @Garvit Agarwal @Saksham Handu @Paras Dhama @Rajan Maurya 
      Length
      Large - 350 hours
      Category
      Mobile - Mifos X | Core Development
      Overview & Objectives
      In 2025, we are making a big push around shared infrastructure to provide modern core banking infrastructure the many SACCOs, MFIs and Credit Unions that go the last mile. We are prioritizing providing a more robust and feature-rich self-service mobile banking experience to be offered to their members and customers. Mifos Mobile is a reference mobile banking app which enables clients to authenticate themselves, view and edit their account details. and make repayments or transactions between their own accounts. It is now possible for any financial institution using Mifos to provide an omni-channel banking experience including smartphone-based mobile banking, USSD-based mobile banking, and online banking via a web app.
      Over the years our interns extended our mifos mobile banking app, completing a mix of functional, architectural, and design improvements including improving the outbound notification system by migrating from GCM to FCM, initial integration with RocketChat for direct customer support between staff and clients, a dark theme and better support for skinning, and phase 1 of integration with Mojaloop via the payment hub. In 2020 Shivangi revamped the UI and Ashwin began the migration to Kotlin for mutli-module development and last year Avneet finished the kotlin multi-module migration and whole project get migrated xml to Jetpack compose.
      With the payment hub and API Gateway now in place, next we look to add additional mobile money and payment system integrations into the app as well as having the app connect via the Open Banking API rather than the self-service APIs. This exercise of mapping the Fineract self-service APIs to the Open Banking APIs will be the major focus of this project.
      It was built on top of the Apache Fineract 1.x client-facing APIs to enable self-service channels for clients to interact with their own data and transact in a self-service manner. 
      Description
      In 2025, Work will involve both development of the Mobile application as well as work to connect the app securely via self-service middleware layer. 
      Replace API layer from self-service Fineract APIs to self-service middleware layer 
      Implement new look and feel based on modular UI components. 
      Integration with an external payment system (Mojaloop, mPesa) via  our PH-EE
      Complete migrate Kotlin multi-module to Kotlin Multiplatform.
      Make sure fineract-client-kmp-sdk implemented properly and have no bugs.
      Continue adding unit tests for Data Layer and UI Layer
      Cover all the screens with UI tests
      Implemented Playstore release github action pipeline
      Improve Githhub workflows and add jobs to run Unit and UI tests
      Add CI to build APK and code analysis.
      Helpful Skills
      Android, Kotlin, Kotlin Multiplatform, Jetpack compose, Coroutines, Koin, MVVM, Unit, Instrumentation Testing, Room, Git, OpenJPA, Rest, WS02 API Gateway
      Impact
      By providing an extensible mobile banking app, allow a member/client in having a self-service channel allowing them more direct control and visibility into their financial livelihood.
      Other Resources
      User Stories - https://goo.gl/3xuUko
      Wireframes - https://goo.gl/3xuUko
      Customer Self Service APIs - https://cwiki.apache.org/confluence/display/FINERACT/Customer+Self-Service
      UK Open Banking API Standard: https://standards.openbanking.org.uk/
      Source Code: https://github.com/openMF/mifos-mobile
      See: https://openmf.github.io/mobileapps.github.io/
      Mifos Webinar on Open Banking API: 
      Mifos Open Banking API Documentation: https://app.gitbook.com/@mifos/s/docs/
      GsoC 2020 work progress final report: 
      GSoC'20 - Mifos Mobile - Final Report 
      GSOC 2023 Final Report (Pratyush Singh): 
      GSoC'23 Final Report - Mifos Mobile 
      GSOC 2024 final report (Avneet Singh): 
      Summary of my work in GSoC 2024 
      
      ~~~~~~~~~~
      
      Payment Hub EE - Replicable Mobile Money Connectors for  Mifos Payment Hub EE
      Mentors
       @Subham Pramanik @Paras Dhama @Manoj VM 
      Category
      Platform - Payments Integrations
      Overview & Objectives
      While we didn’t have an intern working on this in 2024 it’s very much a priority to both enable the ecosystem to independently adopt and extend PH-EE as well as to enable PH-EE to be utilized within the regions we’re deploying shared infrastructure to allow members to transaction digitally via mobile money.
      Mobile money is rapidly transforming financial inclusion by providing more immediate, impactful, affordable, and secure financial services to the client. Providers like MFS Africa and Beyonic provide a set of cross-border payment rails to enable remittances across Africa terminating in mobile money wallets. Mobile money platforms like M-Pesa offer the client unparalleled value in terms of convenience, security and the possibility of new services and products that are more in line with real-world financial habits.  For financial institutions and their clients to fully scale mobile money and leverage its potential, it needs to be fully integrated with their core-banking system.
      We designed and implemented Payment Hub EE as a highly flexible integration engine and orchestration layer to allow the ease of connecting to new mobile money APIs by simply building new connectors. Across the ecosystem, PH-EE has been deployed in production for multiple mobile money networks including M-Pesa via Safaricom and other connectors. However it is challenging for others to easily build new connectors. This project would help to make the process for building a new mobile money connector more replicable.  
      Description
      This project would focus on making the process of building a connector more replicable, defining and templating the BMPN flows for inbound and outbound mobile transactions, properly documenting the process, creating a set of helm charts for deployment of Payment Hub EE for the mobile money integration use case. 
      The Payment Hub EE has been built out as an integration layer between Fineract and real-time payment systems like Mojaloop. Built around the Zeebe as an orchestration engine, it's built with an extensible architecture with a set of connectors for additional core banking systems, channels, and payment systems. We have a connector built for Mojaloop and the GSMA mobile money API and would like to build additional ones for the most widely used payment rails across our community. As part of our DIAL-funded project to integrate Mifos with the open source Mojaloop payments platform the team from DPC consulting built out a middleware component called the payment hub to enable the integration with the Mojaloop APIs. This middleware has also served as the point of integration for all other external payment systems - the payment hub is extendable by additional payment connectors. 
      Helpful Skills
      Web Services, Java, SQL , JavaScript , Git, Sprint
      Impact
      Great efficiency, reduced risk for clients, more impactful and relevant products & services.
      Other Resources
      2020 Progress: https://gist.github.com/SubhamPramanik/905ea87b83dd0b6af62af18ca0c0c1ea
      Research & Data on Various Mobile Money Platforms  - http://goo.gl/XkSbdl
      Payment Hub EE Docs: https://mifos.gitbook.io/docs/payment-hub-ee/overview/payment-hub-apis 
      Overview of Payment Hub and How to Configure (See Section 5.6.3): https://docs.google.com/document/d/1XnAuWxmX-Fof7-o69IyU9ilwcmigqQ6dNHc9uNRx1r4/edit?usp=sharing
      Functional and Technical Specification on the Payment Hub: https://docs.google.com/document/d/1iVTgqljj5jW1eczpUcN_qykvWGh9bPKalxDayW8ZGcU/edit?usp=sharing
      Beyonic APIs: https://apidocs.beyonic.com/
      
      ~~~~~~~~~~
      
      Online Banking App 5.0 - Customer Loan Management Portal 
      Mentors
      @Ed Cable  @Victor Romero 
      Length 
      Large - 350 hours
      Category
      Web - Mifos X Online Banking App | Core Development 
      Overview & Objectives
      It’s been a number of years since we have had an intern work on our online banking app but it’s a very high priority given the need for customers to interact with their own loan accounts. The online banking app is overdue for refactoring and could now follow the same Compose Multiplatform architecture as our mobile apps. It is currently an Angular web app powered by self-service APIs so would also follow the progress being made with self-service middleware layer. The app currently allows for account creation, logging in, viewing of account details, transferring between savings accounts, repaying loans via savings accounts, applying for new loans, and more.
      Given the high amount of adoption of Mifos X for loan management use cases, for this year’s project we’d like to create a version of the online banking app which is solely focused lending use cases so Mifos can provide a customer-facing loan management portal. This will be a valuable community resource that others can use for demonstrations or to white-label to provide their customers to log into the self-service portal and view their existing active loans, view transaction details, repayment history, repayment schedules, etc, view details of previous loans, initiate repayments on their loans, calculate the payoff amount of their loans, apply for new loans, view loan account statements, etc. 
      LoanPro provides a valuable resources on what a simple loan management portal could offer at https://help.loanpro.io/article/fcflgkwnxn-customer-website 
      Description
      Focus for 2025 includes:
      Redesign and Refactoring of Online Banking App to Compose Multiplatform
      Align and enhancing overall user experience and design of application 
      Creation of a new repository that contains only the loan management self-service capabilities
      Refine and implement the self-service loan management features listed above: 
      Incorporate better visuals and charts and dashboards around loan history
      View their existing active loans
      View transaction details, repayment history, repayment schedules, etc
      View details of previous loans
      Initiate repayments on their loans
      Calculate the payoff amount of their loans
      Apply for new loans
      View loan account statements, etc. 
      Deploy the APIs (back-office or self-service APIs) securely (i.e. API Gateway)
      Implement capabilities to configure a more customized look and feel of the app (upload logo, etc.)
      Leverage ongoing security enhancements in Fineract to provide better self-service user management
      Ensure the app can easily be embedded or integrated into existing tools of institutions using this.
      Bonus: Enabling self-service external transactions through Payment Hub EE integratio
      Bonus: Adding new support features to make app more user friendly.
      Helpful Skills
      Angular development, SQL, Java, Javascript, Git, HTML, CSS
      Impact
      Allows a member/client in having a self-service channel allowing them more direct control and visibility into their financial livelihood.
      Other Resources
      Previous GSOC Efforts:
      2020 Progress: 
      Online Banking App 4.0 Report 
      2019 Progress: 
      GSOC 2019 Final Work Product Report  
      LoanPro Customer Loan Website: https://help.loanpro.io/article/fcflgkwnxn-customer-website 
      Self Service APIs - https://cwiki.apache.org/confluence/display/FINERACT/Customer+Self-Service
      Source Code - https://github.com/openMF/web-self-service-app and https://github.com/openMF/online-banking-app
      Complete Details can be found here: Self Service Web Application
      UK Open Banking API Standard: https://standards.openbanking.org.uk/
      Mifos Webinar on Open Banking API: 
      Mifos Open Banking API Documentation: https://app.gitbook.com/@mifos/s/docs/
      Further Ideas: https://docs.google.com/document/d/1KXDSrBkuYA9g694-DE4qf1QKFcAhWwA-HNnn9YAucbk/edit?usp=sharing
      
      
      ~~~~~~~~~~
      
      Ad Hoc Reporting Module/Business Analytics (OLAP) 
      Mentors
      @Bharath Gowda @Victor Romero 
      Overview & Objectives
      Business insights are not just raw data; they are the outcome of a thorough analysis that transforms data into valuable information. By examining data from multiple sources, such as sales records, customer feedback, and market research, organizations can gain a comprehensive understanding of their business landscape.
      Through the application of analytical techniques, such as data mining, statistical analysis, and machine learning, organizations can uncover hidden patterns and correlations within their data. These insights provide a deeper understanding of customer behavior, market trends, and operational efficiency.
      During previous GSoC Interms have developed ETL scripts to create OLAP cubes (fact and dimension tables on MySQL). This allowed managers to perform ad hoc slicing and dicing of their data to answer important questions about their operations.
      Created ETL scripts and tests
      Created a Mondrian schema to work with Saiku Analytics
      This previous project would extend off of the work of a previous GSOC intern in building out integration with Saiku.
      The proposed work is looking to use MPP-based real-time data warehouse (like Apache Doris) for ingesting data from Mifos X and the Analytics can be implemented as Dashboards using Apache Superset. 
      
      Description
      The data and information housed in the centralized Mifos database is critical to the operations and management of a financial institution. While Mifos X ships with more than five dozen standard report and has multiple ways to build custom reports, non-technical staff who don’t know SQL queries nor the structure of the database struggle to be able to access new reports on the fly. Integration with Saiku would allow for ad-hoc reporting or more simply a drag and drop interface for management and non-technical staff to easily slice and dice and create reports on the fly.
      Nowadays using near real time data is critical for Decisioning systems and the core banking solutions are a crucial component for any financial institution. And the use of modern open source technologies can give Business Insights on the ever-changing business landscape for taking informed decisions.
      At a later time the data lake could be used for using another AI tools for data analysis.
      Helpful Skills
      Database Management Systems, MDX, SQL,
      Impact
      Data drives a microfinance institution - the more powerful and robust analytical tools management has, the better they can tailor their services and outreach to impact the poor most effectively.
      Other Resources
      Apache Doris - 
      Apache Doris: Open source data warehouse for real time data analytics - Apache Doris 
      Apache SuperSet 
      Welcome | Superset  
      TiDB - HTAP Database - 
      TiDB, Powered by PingCAP  
      Saiku Analytics Demo - demo.analytical-labs.com
      Wikipedia OLAP Article - http://en.wikipedia.org/wiki/Olap
      Introduction to OLAP - http://www.db-class.org/course/video/preview_list
      Gentle Introduction to MDX - http://www.iccube.com/support/documentation/mdx_tutorial/gentle_introduction.html
      Apache Fineract 1.0 Github Repo
      Saiku Github Repo
      https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=73632010
      Ad Hoc Reporting Builder Tool
      GSOC Idea Description
      Demo of Integration from 2014
      Saiku Website - http://community.meteorite.bi/
      Documentation on Work led by Oleg in 2014
      JIRA Issue for Oleg’s Work: https://mifosforge.jira.com/browse/MIFOSX-1448
      Source Code from Oleg’s Work
      Discussion on Saiku and Challenges to Overcome
      Discussion on Saiku
      Demo of Mifos with Salesforce Reporting
      MIFOSX-1448 - 3rd party query builder | SAIKU DEVELOPMENT IN PROGRESS
      


      ~~~~~~~~~~
      Basic CRM Functionality - Inquiries/Complaints Module
      Mentors
      @Ed Cable 
      Category
      Back-end Platform | Modules
      Overview & Objectives
      Right now Mifos X contains core client management functionalities including tracking basic demographic information, know your customer information, document management, and survey collection through data tables. As financial institutions, serving the poor begin to offer a more in-depth and diverse range of financial inclusion products, the need for more robust client management and in-depth client understanding has grown. Their core system needs to provide more and more CRM-type functionality that compliment the portfolio management and financial/social reporting that the Mifos X provides.
      This project will work to deliver the initial set of customer relationship management functionalities including a module for tracking inquiries, complaints. Primarily it will focus around customer support desk type functionality. 
      Description
      This module will have a request management functionality. A request can be of 2 types: Complaints and Service Requests. Each request must be against a customer and optionally against an account of the customer. Each request will go through a simple workflow.
      Actions that can be performed on a request:
      Assign -> will change status to "assigned"
      Start Work --> will change status to "in progress"
      Close --> will change status to "closed" (with a sub-reason code)
      At each step user can enter comments.
      The customer summary screen will have a link to view the requests of the customer - along with a summary and current status - with options to click-through to get the complete history of each request.
      Helpful Skills
      familiarity with Mifos X tech architecture, angular js,node js, java,Spring, Backend Integration
      Impact
      Deepening the client relationship and ensuring fair, responsible, and transparent financial services to the poor is a core piece of the industry's roadmap for financial inclusion. Providing customers the ability to voice their concerns and feedback about the services they're receiving provides a simple yet powerful tool to protect the client. Empowering the financial institution with the ability to track these inquiries and overall maintain a more holistic relationship tracking entire lifecycle of their clients gives them a much better ability to understand their clients and respond to their needs with appropriately designed services and products.
      Other Resources
      Odoo Open Source Business Apps Github Repo
      Odoo Third-party API And Demo
      Wikipedia Article on CRM
      What Is CRM ? 
      CRM
      Medium Projects
      These projects are of a 175 hour duration.


      ~~~~~~~~~~
       AI-Driven Architectural Test for Mifos Payment Hub EE (AI)
      Mentors
      Kerlyn Manyi,   Oreoluwa Oluwasina
        Length
      Medium - 175 hours
        Category 
      Platform | DevOps | PH-EE
        Overview & Objectives
      Mifos Payment Hub EE is a critical financial transaction platform that facilitates seamless payments across different banking and financial services. Given its complexity, ensuring the system's long term resilience, scalability, and security is vital. This project aims to perform AI-driven architectural testing to analyze the system’s performance, identify bottlenecks, predict failures, and enhance its overall robustness. 
        Description
      By leveraging machine learning and automation, the project aims to create an intelligent testing framework that can proactively detect issues before they impact operations. This will result in improved performance, enhanced security, and better fault tolerance for Mifos Payment Hub EE. 
      Intern will;
      Develop machine learning models for anomaly detection, load testing, and vulnerability scanning. 
      Implement AI-driven load and stress testing to identify system bottlenecks and optimize performance. 
      Utilize AI-based security scanning tools to analyze authentication mechanisms, APIs, and transaction flows. Detect potential fraud patterns using machine learning techniques. 
      Design an AI-driven test automation framework to reduce manual testing efforts. Implement predictive analytics to forecast potential system failures. 
      Document testing processes, findings, and recommendations.
        Helpful Skills
      Python, Java, TensorFlow, Scikit-learn, Git
        Impact
      The project will boost Mifos Payment Hub EE's long term reliability and security while enabling scalability, ultimately establishing it as a trusted choice for financial institutions.
        Other Resources

      ~~~~~~~~~~
      Bank Statement Analysis Phase 2 (AI)
      Mentors
      @jeremy engelbrecht @Akshat sharma 
      Length
      Medium - 175 hours
      Category 
      AI | Platform - Modules 
      Overview & Objectives
      Mifos is a powerful loan management system, but it has room to improve its loan origination and decision-making features. Phase 2 of the Bank Statement Analysis project enhances the system by integrating user personalization and expanding cross-platform compatibility. With this, the platform will not only analyze the credit risk of potential borrowers but also provide personalized financial advice based on the user’s spending habits, income, and goals. Additionally, this phase will improve integration with various financial platforms, creating a more comprehensive financial management experience for the user.
      Description
      In this phase,the system will build dynamic, personalized user profiles based on financial data. It will also integrate seamlessly with multiple financial platforms to aggregate data from various sources such as bank accounts, investment portfolios, and payment services. 
      Key features in Phase 2:
      Personalized Financial Advice: Provide tailored recommendations based on historical spending, income, and financial goals. These suggestions will include budgeting tips, savings strategies, and financial goal tracking
      Cross-Platform Integration:
      APIs & Data Standardization: Create robust APIs and standardized data formats for seamless data exchange between multiple financial systems. 
      Real-Time Synchronization: Enable real-time synchronization and data aggregation from various financial sources such as banking accounts, investment portfolios, and payment services.
      Uniform Interface: Provide a uniform interface for consolidating financial records across different platforms, ensuring a unified experience for users. 
      These features will be integrated within MIfos X, allowing users to access a comprehensive overview of their financial data and receive personalized advice, all while improving their loan eligibility assessment.
      Helpful Skills
      Python, XGBoost, NLP, Recommendation Systems, Cross-Platform Data Integration
      Impact
      Phase 2 will significantly improve the loan origination process by offering dynamic, personalized financial recommendations. It will also enhance the user experience by allowing real-time synchronization of financial data across multiple platforms, giving users a comprehensive view of their financial situation. The cross-platform compatibility will foster a more integrated financial management experience, helping users make informed decisions, optimize their finances, and improve their creditworthiness for loan eligibility
      Other Resources
      For similar work that has been worked on previously in the community, see: 
      Powered by Mifos – SoftiDoc 
      2024 GSOC Final Report (Akshat Sharma): 
      Final_Report.md 


      ~~~~~~~~~~
          Credit Bureau Integration Phase 5 
      Mentors
      @Nayan Ambali, @Ed Cable @Rahul Pawar 
      Length
      Medium - 175 hours
      Category 
      Platform - Modules | Core Development
      Overview & Objectives
      Mifos is a very strong loan management system but has room to improve around loan origination features. Credit Bureau integration is one of these key features to build upon. Because of regulatory reasons or to do background check of a client (risk management), MFIs depend on credit bureaus. As part of it, MFI must submit client details to credit bureau and also need to pull client information from credit bureau before approving any new loans to a client. Mifos X can be integrated with a popular CBs in India and from other regions (based on the demand).
      Description
      During the 2016, 2017, and 2020 Google Summer of Codes, Nikhil Pawar and Rahul Pawar completed the credit bureau integration module with integrations for the major credit bureaus in India and Myanmar. This project will continue extending the functionality of the module and work on integrations with the major credit bureaus in Latin America and Sub-Saharan Africa.
      The major functionality will be sending the data to CBs on regular intervals in the format CB expects. And option to pull the client’s information from CB whenever loan officer/branch manager/ user wants to view the information for a particular client.
      During 2025 it is expected to integrate a Credit Scoring standar which is the FICO® (Fair, Isaac, and Company). Although FICO® has many different scoring models, it uses relative percentage weights to help determine how much impact certain factors will have in helping determine a FICO® credit score. The main categories considered are a person’s payment history (35%), amounts owed (30%), length of credit history (15%), new credit accounts (10%), and types of credit used (10%).
      The Credit Burea information can be displayed while creating a new loan application because it will be used only during this process.
      Helpful Skills
       SQL, Java, Javascript, Git, Web Services, Big Data (Hadoop, Hive), API Rest,  
      Impact
      The credit report shows account information such as repayment record, defaults, type of loan, amount of loan, etc. of the customer. This information facilitates prudent decision-making when the credit underwriter processes the loan application. This help MFI to reduce the risk of bad loans and reduces the multiple lendings to same person from different MFIs.
      Other Resources
      For the scope of this project for 2024, see https://jira.apache.org/jira/browse/FINERACT-734
      Detailed requirements https://goo.gl/aZWMZa
      Mifos Credit bureau Integration. (Risk calibration Module -RCM)
      Source Code: 
      creditbureau configuration by nikpawar89 · Pull Request #215 · apache/fineract  
      FICO - 
      Puntuación de FICO® 
      EQUIFAX - 
      What is a FICO® Score, How is It Calculated | Equifax 
      Credit Scores - 
      Credit score in the United States 
      MyFico - 
      What is a Credit Score? | myFICO  
      
      ~~~~~~~~~~
      
      Optimize Payment Hub EE Operations UI with new Micro Front-Ends
      Mentors
      @Ed Cable @Mohit Bajoria @Jose Hernandez 
      Length
      Medium - 175 hours
      Category
      Web 
      Overview & Objectives
      For our Payment Hub EE integration layer and payment orchestration engine, we provide an operational user interface which allow staff of the financial institution participating in a real-time payment scheme to manage view detail of the incoming and outgoing transactions that are flowing through the switch, manually process refunds, complete reconciliations, view and take action on unsuccessful and disputed transactions, and more. 
      Description
      Intern will improve the operations app user interface for the following use cases.
      Transaction Details View
      Transaction Reconciliation
      Refund/Reverse transactions
      Operational Metrics and Dashhboards
      Business metrics and Dashboards Account Details
      Helpful Skills
      Javascript, CSS, HTML5. Angular and Bootstrap (CSS framework) is plus
      Impact
      Reference UI for microfinance institutions on Apache Fineract CN
      Other Resources
      Usability and Design
      Use Cases - 
      Use Cases & Requirements 
      Github
      GitHub - openMF/digital-bank-ui: Digital Bank user interface for staff on top of Fineract CN 
      https://github.com/openMF/digital-bank-ui/issues 
      
      ~~~~~~~~~~
      
      Security Penetration testing for Payment Hub EE 
      Mentors
      Godfrey Kutumela
      Length
      Medium - 175 hours
      Category
      Platform | Infrastructure
      Overview & Objectives
      Mifos Payment Hub EE is continuing to grow in its functional capbailities and breadth of use ceases being adopted for. We must ensure it  is super secure and impenetrable. Your mission, should you choose to accept it, is to prove us wrong, and help close gaps you may find.
      Description
      Beyond a one time exercise, you should integrate (some of) the tools you've used into our build chain so that, even after you've gone, tools flag up future newly introduced potential vulnerabilities.
      Helpful Skills
      Candidates applying for this project would ideally have prior experience in penetration testing, and document this in their application.
      Impact
      Re-assuring the more Entreprise-y type Mifos clients that they can safely bet on Mifos X as an MFI platform.
      Other Resources
      https://www.owasp.org/index.php/Main_Page
      https://code.google.com/p/zaproxy/
      http://wapiti.sourceforge.net
      Run FindBugs & related tools for some serious static code analysis
      http://en.wikipedia.org/wiki/Penetration_test
      
      
      ~~~~~~~~~~
      
      OpenG2P  - Digital Identity Proof of Concept on Sovrin & Hyperledger Indy
      Mentors
      Rachit Kansal
      Length
      Medium - 175 hours (Update)
      Category
      Platform & Modules - ID, Exploratory, Bleeding Edge
      Overview & Objectives
      Digital Identity is a pressing topic and for both generations of Fineract (1.x and CN), we'd like to have integration with emerging KYC and digital identity solutions.
      KYC (Know your customer) is a fundamental banking concept. It refers to the process of identifying a new customer at the time of account opening, in compliance with law and regulation. The identification requirements may be lower for low value accounts ("Tiered KYC"). The term is also used in connection with regulatory requirements for a provider to understand, on an ongoing basis, who their customer is and how they are using their account. Most of the banks are mandated to perform basic/extensive KYC, before they can serve their customers.
      Traditionally KYC is done in a centralised fashion where a central agency has the control over all the data. For example consider each bank like SBI, Deutsche, JP Morgan, etc. when creating a bank account, each of them requires a separate KYC process to be completed and all this data gets stored in their respective databases. Even the systems like Aadhar or social security number, etc. have the data stored in a central manner and maintained by the government. However, in recent times all these centralised identity servers continue to be hacked and the important and private data being stolen regularly.
      With the advent of blockchain concepts and technologies, it is not ideal but imperative that we shift from the traditional identity management to a more secure decentralised claim-based identity management system. This kind of system has multiple benefits:
      Decentralised system means that no one person has control over sensitive data.
      It enables the re-use of KYC, i.e. each financial institution or in our case each customer using Fineract may not have to perform its own complete KYC, but re-use the KYC already performed by others (those who have the power as issuing authority for any kind of claim).
      Cryptographic security is the heart of blockchain technologies enhancing privacy.
      Claim-based system where the end user/customer has the control over his data.
      Description
      See 
      Sovrin/Indy PoC for KYC in Fineract - Fineract - Apache Software Foundation  for details on the proof of concept 
      P0 requirements
      Setup and run an Hyperledger Indy Network with Stewards.
      Opening a bank account scenario.
      Applying for a loan scenario.
      P1 requirements
      Performing money transfer to a merchant online.
      Helpful Skills
      HTML, Spring, Hibernate, REST, Java, AngularJS, Javascript, SQL, Hyperledger Indy
      Impact
        Other Resources
      Sovrin: https://sovrin.org/
      Indy Getting Started: https://github.com/hyperledger/indy-sdk/blob/master/docs/getting-started/indy-walkthrough.md 
      Sovrin Whitepaper: https://sovrin.org/wp-content/uploads/2018/03/Sovrin-Protocol-and-Token-White-Paper.pdf
      Sovrin Stewards: https://sovrin.org/stewards
      
      
      ~~~~~~~~~~
      
      Mifos/Fineract Chatbot & Adapter 4.0 (AI)
      Mentors
      @raul.sibaja @Aleksandar Vidakovic @jeremy engelbrecht 
      Length
      Medium - 175 hours (Update to Large)
      Category
      Platform - Modules | AI | Exploratory
      Overview & Objectives
      For many of our users today, chat is a much more familiar form of user interface for them and it would be valuable to provide an extensible chatbot connected to Mifos/Fineract that could be used to both provide customer support as well as allow clients to directly interact with their accounts. See this post from ThitsaWorks for more: https://medium.com/@thitsaworks/chatbots-the-emergent-and-effective-tool-in-financial-education-f6e63baf9188
      Description
      This project will focus on building on the latest version of the chatbot. In 2019, our GSOC intern, Anshul extended the Mifos Chatbot and Adapter with better authentication, improved Natural Language Processing, and integration with the Slack, Telegram and Facebook messenger platforms. 
      The project will include both leveraging other open source libraries and components to build the chatbot and building the adapter to the chatbot for MIfos/Fineract which will act as the interaction between chatbot and Mifos. It will take the replies from chat and feed them into Mifos. The program will sit in between Mifos and Chat.
      Main components needed are:
      NLU (natural language understanding) /NLP (natural language processing) 
      This componentcomponent is probably a good candidate for integrating a suitable existing OS project. 
      Chat platform and/or protocols
      To establish the communication between user and the bot logic the project could either leverage (at least) one of the major chat platforms (e. g. Facebook messenger etc.) and/or use open source protocols like XMPP or IRC. It's probably best to evaluate existing chat frameworks/client libraries 
      Fineract adapter
      This is the part where most of the student's attention is needed (see use cases below). The student would have to evaluate to which extent a chatbot framework could be integrated or if there are better arguments to develop something Mifos specific.
      Note: only Apache license compatible libraries/frameworks/components can be used.
      It will cover the following use cases: 
      Enquiry of Loan Details
      Mifos/Chat adapter will allow authenticated user to enquiry details of loan based on loan ID.
      Check user/client authentication
      Get MFI name, 9-digits loan ID (xxxxxxxxx), 9-digits clients ID (xxxxxxxxx) if it is an authenticated user/client.
      Allow authenticated user/client to query loan details:
      Status of loan
      Outstanding principal and interest
      Next due date, due principal and interest
      Previous payment date, principal and interest (the last transaction of loan)
      Loan maturity date
      Overdue loan principal and interest (if have)
      Number of days in arrears for loan
      Penalty fees/charges
      Client activation date
      Loan disbursed date/amount/interest
      First repayment date
      Saving balance
      Saving interest (to date amount)
      Next meeting date
      Enquiry of Savings Details
      Saving activated date
      Saving balance
      Saving interest (to date amount)
      Last active transaction date
      Notifications through Chat Adapter
      Notification will be sent thru Mifos/Chat adapter to respective clients on the following events occur on their accounts. 
      Client account activation
      Client account rejection
      Loan disbursal
      Loan close
      Next due principal and interest (1/2 days in advance)
      Payment posted (there may have delay due to data entry)
      Next meeting date
      Saving deposit
      Saving withdrawal
      Saving close
      Update/delete details of clients (address, phone number, NRIC number)
      Update/delete details of group (group name, group leader, loan officer name)
      Upload documents
      Enquiry about Loan Products
      Check user/client authentication
      Get MFI name, 9-digits clients ID (xxxxxxxxx)
      (Provide a list of available loan products of MFI)
      Allow authenticated user/client to query loan product details based on selected product:
      Loan term
      Interest rate
      Max and min allowed amount to borrow
      Number of installments/repayments
      Enquiry about Group Information
      Mifos/Chat adapter will allow authenticated user (group leader) to enquiry on group member details.
      Check user/client authentication.
      Get MFI name, group leader name, group ID, center ID, branch name, (Is a group leader?)
      Allow authenticated client(group leader) to query group details:
      Next meeting date
      Clients who have overdue loan
      Enquiry about Branch Information
      Mifos/Chat adapter will allow authenticated user(branch manager) to enquiry on branch details.
      Check user/client authentication
      Get MFI name, branch manager Name, user id/name, Branch Name, (Is a branch manager?)
      Allow authenticated branch manager to query branch details:
      Number of clients of his/her branch
      Expected disbursement principal (today)
      Outstanding principal and interest
      Saving balance
      Number of clients awaiting for disbursal (today)
      New registered clients (today)
      Prospective clients (as of today)
      Number of clients (dormant) as of today
      Number of village/bloc/ward in a branch
        Helpful Skills
      SQL, Java, Git, Spring, OpenJPA, Rest
      Helpful: technical knowledge of (any) chat protocol (e. g. XMPP, IRC), experience with NPU/NLP
      Impact
        Other Resources
      2019 Progress: https://gist.github.com/iosdev747/2b7de87cd9b028bb97433ee2e26ad18d
      Source Code: https://github.com/openMF/mifos-chatbot
      AI/NLU services
      Google: https://dialogflow.com/
      Facebook: https://wit.ai/
      https://botkit.ai/
      https://www.ambiverse.com/
      https://github.com/ambi-verse/nlu-api-client-java
      Frameworks
      https://github.com/howdyai/botkit
      https://github.com/nitroventures/bot4j
      https://dev.botframework.com/
      Has a lot of information on integration with chat platforms/protocols: https://github.com/BotMill
      NLP/NLU components and tools
      https://opennlp.apache.org/
      https://deeplearning4j.org/java-ai
      https://github.com/AIMLang/aiml-java-interpreter
      https://nlu.rasa.ai/
      Tutorials
      https://dzone.com/articles/building-an-intelligent-chatbot-using-botkit-and-r
      https://dzone.com/articles/beginners-guide-to-creating-chatbots-using-dialogf-1
      https://tutorials.botsfloor.com/
      Other
      Extensive comparison: https://chatbotsjournal.com/25-chatbot-platforms-a-comparative-table-aeefc932eaff
      Seems outdated, maybe helps with some insights/inspiration: http://www.zionsoftware.com/products/jbuddy/botframework/
      
      
      ~~~~~~~~~~
      
      Community support through AI
      Mentors
      @David Higgins @Ed Cable 
      Length
      Medium - 175 hours
      Category
      Platform - Modules | AI | Exploratory
      Overview & Objectives
      The community for Mifos related applications has grown considerably over the past few years.  The applications are highly complex and implementors (especially those new to the projects) require support to be able to implement and develop these applications.
      Current support is via the Slack general channel and dispirate documentation, requests get different treatment depending who reads and responds.  As there is no dedicated resource for monitoring and response which means timescales can be elongated.
      The objectives of this project is to setup an initial AI bot and learning algorithm that can respond to questions and point users to the relevant answers or documentation.
      This would need to be across the range of Mifos/Fineract products that the slack channel currently accomodiates
      it would require some pre-training of the algorithms based on past questions
      Description
      Identify the best AI solution for the task.
      Create the AI PoC and train the algorithms
      Test its responses based on previous questions and answers.
      PoC could be limited to one product initially and have a breakout for additional assistance.
      Web integration e.g. chatbot could be added to websites.
      Helpful Skills
      HTML, Slack, AI
      Impact
        Other Resources


      ~~~~~~~~~~
     
      Small Projects
      These projects are of a 90 hour duration.
      Alignment with emerging Open Wallet Standards
      Integration with Open Banking and Open Payment Standards
      Design and Adoption of new frameworks like Compose Multi-platform
      End to End Demo in Mifos Gazelle 
      Alignment with Emerging Open Wallet Standards 
      Mentors
       @Ed Cable @David Higgins 
        Length
      Small - 90 hours
        Category 
      Mobile Development
        Overview & Objectives
      Mifos and Fineract are valuable Digital Public Goods critical to advancing the Sustainable Development Goal of No Poverty by providing both the core banking system of record to manage the store of value for a functional wallet/transactional account in which to send G2P payments to. Many different financial services can be layered on these accounts within Mifos and Fineract making them a powerful tool for financial inclusion. Apart from providing the back-end to manage these wallets, Mifos also provides a reference mobile wallet which can be extended to one’s local requirements.
      Recently there have been a number of cross-sector movements to establish standards and frameworks upon which any type of wallet could be built. These wallets could be used for financial use cases, identity use cases, health use cases, etc but standards and frameworks initial focus primarily centers around secure sharing of credentials and privacy of user data.  Mifos was a founding member of the Open Wallet Foundation and sits on the GovStack Wallet Building Block Working Group. 
        Description
      This project would consist of researching the different open wallet standards emerging from the Open Wallet Foundation, GovStack wallet building block, and could utilize other digital public goods for identity including Inji from MOSIP and the Gluu Project. 
      Research would include exploring the current status of the specifications, standards and designing a POC architecture for a mobile wallet that aligns with th standards and specifications in their current state. 
        Helpful Skills
      Java, Android, Kotlin, Mobile Development, Enterprise Architecture 
        Impact
      The OWF aims to set best practices for digital wallet technology through collaboration on standards-based OSS components that issuers, wallet providers and relying parties can use to bootstrap implementations that preserve user choice, security and privacy. (mission of Open Wallet Foundation)
        Other Resources
      Open Wallet Standards & Requirements
      OpenWallet Foundation – Linux Foundation Project 
      Why the World Needs an Open Source Digital Wallet Right Now 
      Payments | bb-payments 
      Open Source Tools for Identity & Credential Sharing
      Open Source Identity and Access Management 
      Overview | Inji 


      ~~~~~~~~~~
        Integration with Open Banking and Open Payment Standards 
      Mentors
       @Ed Cable @David Higgins 
        Length
      Small - 90 hours
        Category 
      Payments | Platform - Integrations 
        Overview & Objectives
      A huge democratizing force across the financial services sector is the Open Banking movement providing Open Banking APIs to enable third parties to directly interact with customers of financial institutions. We have recently started providing an Open Banking API layer that will allow financial institutions using Mifos and Fineract to offer third parties access to requesting account information and initiating payments via these APIs. Most recently the Mojaloop community, led by Google, has led the development of a centralized PISP API.  We have chosen to the folow the comprehensive UK Open Banking API standard which is being followed and adopted by a number of countriues through Sub-Saharan Africa and Latin America. The Interledger Foundation now also has an Open Payments Standard.
      All of these standard have great applicability to how our core banking and payment orchestration systems authorize, establish consent, access date, and initaite transactions via these third party APIs and standards for sharing information and initiating transactions 
        Description
      This project would consist of researching the all of the different open banking, open finance and open payment initiatives and their corresponding API specifications. The POC would consiste of designing and implementing ways in which Fineract could generate APIs that are compliant with these specifications and most importantly ways for Fineract and our Payment Hub EE to consume the APIs/standards for these initiatives.
        Helpful Skills
      Java, Android, Kotlin, Mobile Development, Enterprise Architecture 
        Impact
      More innovation, control, and access as they can securely enable third parties to access their data and initiate transactions on their behalf. 
        Other Resources
      Open Banking & Open Finance Standards & APIs
      Mojaloop Third Party API - 
      Third Party API | Mojaloop Documentation 
      Home - Open Banking 
      GitHub - interledger/open-payments: Protocol to setup payments between entities on the Web based on GNAP 
        
        
      ~~~~~~~~~~  
        NEW: End to End Demo within Mifos Gazelle 
      Mentors
        @David Higgins @Abhinav Kumar 
        Length
      Small - 90 hours
        Category 
      DevOps
        Overview & Objectives
      Mifos Gazelle deploys a number of components (DPGs) that can be used in end to end payment flows. The idea of Mifos Gazelle is that these can then have end to end demos run across them potentially linking to other systems external of the environment.
        Description
      This project would consist of researching a potential use-case. Defining the use-case and how it would flow within the environment. Identify any integrations with external components needed and using existing APIs to do this perhaps with the assistance of an external workflow system such as OpenFN. Creating the demo script, configurations for environment, demo data. Ensuring replicability e.g. that it could be repeated on a fresh install with low technical skill.  Documentation, presentation are key for this, this could be an idea webinar or demo/talk at a conference or event.
      Basically this project is limited by your imagination. 
      We can support multiple iterations of this project for different use-cases or it could be scaled up looking at multiple use cases to be a larger project.
        Helpful Skills
      Javascript, DevOps, Enterprise Architecture , soft skills such as research, impact understanding, presentation skills are as important.
        Impact
      This would enable DPI implementors to understand better the use cases within the Payments Ecosystem, accelerate the path to deployment increase adoption and increase financial inclusion
        Other Resources
      Mifos Gazelle : 
      Mifos Gazelle 
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-mifos-initiative/
    idea_list_url: https://mifosforge.jira.com/wiki/spaces/RES/pages/4271669249/Google+Summer+of+Code+2025+Ideas


  - organization_id: 157
    organization_name: The NetBSD Foundation
    no_of_ideas: 40 
    ideas_content: |

      Emulating missing linux syscalls (350h)
      Contact: tech-kern
      Duration estimate: 350h
      NetBSD has the capability to run binaries compiled for Linux under compat_linux. This is a thin in-kernel translation layer that implements the same ABI as the Linux kernel, translating Linux system calls to NetBSD ones.

      Not all Linux syscalls are implemented. This means some programs cannot run.

      This project is about identifying critical missing syscalls and adding support for them.

      In the course of this project, you should find at least one Linux binary that does not yet run on NetBSD using compat_linux to use as a test case (your mentor may have suggestions), trace the program to find the missing features it requires, make note of them, and begin implementing them in NetBSD's Linux compatibility layer.


      ~~~~~~~~~~

      Making a network driver MPSAFE (175h)
      Contact: tech-net
      Duration estimate: 175h
      Access to some hardware registers and other things can only be done by one CPU at a time.
      An easy way to do this is to make the entire network stack runs with a single lock held, so operations only take place on one core.
      This is inefficient, if you ever want to use more than one core, for faster performing cards.

      Adapting old drivers to be able to run with the rest of the network stack not having this lock will improve NetBSD networking.
      A large number of drivers must be adapted, and some of them can be emulated from virtual machines too, some examples:

      Realtek RTL8139 Gigabit Ethernet re(4) (supported by QEMU)
      AMD PCnet pcn(4) (supported by QEMU and VMware)
      Novell NE1000 ne(4) (supported by QEMU)
      Atheros/Killer Gigabit Ethernet alc(4)
      Attansic Gigabit Ethernet ale(4)
      Broadcom NetXtreme bnx(4)
      You may find others listed in pci(4). It is possible you have a computing device with a device for which the driver hasn't been converted yet.

      The file src/doc/TODO.smpnet in the NetBSD source tree contains a list of fully converted drivers that you may use an an example, as well as some general guidelines.

      When applying for this project, please note which driver you would like to work on.


      ~~~~~~~~~~

      Convert a Wi-Fi driver to the new Wi-Fi stack (175h)
      Contact: martin
      Mentors: martin
      Duration estimate: 175h
      The NetBSD Wi-Fi stack is being reworked to support newer protocols, higher speeds, and fine-grained locking using code from FreeBSD. As part of this work, all existing NetBSD Wi-Fi drivers need to be reworked to the new Wi-Fi code base.

      Successful completion of this project requires you to have access to hardware that is already supported by NetBSD but not yet converted. See the ?Driver state matrix for a list of devices to convert. Many older devices can be found cheap on sites like eBay.

      When applying for this project, please note which driver(s) you want to convert.



      ~~~~~~~~~~

      ALTQ Refactoring and NPF Integration (350h)
      Contact: tech-kern
      Mentors: Christos Zoulas
      Duration estimate: 350h
      ALTQ (ALTernate Queueing) is an optional network packet scheduler for BSD systems. It provides various queueing disciplines and other quality of service (QoS) related components required to control resource usage.

      It is currently integrated in pf(4) .

      Unfortunately it was written a long time ago and it suffers from a lot of code duplication, dangerous code practices and can use improvements both in the API and implementation. After these problems have been addressed it should be integrated with npf(4) .


      ~~~~~~~~~~

      RFC 5927 countermeasures against IPv6 ICMP attacks on TCP
      Contact: tech-kern
      Duration estimate: 1 month
      Assess and, if appropriate, implement RFC 5927 countermeasures against IPv6 ICMP attacks on TCP. Write ATF tests for any countermeasures implemented, as well as ATF tests for the existing IPv4 countermeasures.

      This project will close PR kern/35392.

      The IPv4 countermeasures were previously implemented here: https://mail-index.NetBSD.org/source-changes/2005/07/19/msg166102.html


      ~~~~~~~~~~

      auto create swap on memory pressure (175h)
      Contact: tech-kern
      Mentors: tech-kern
      Duration estimate: 175h
      When a system needs more memory but has free disk space it could auto create swap files and then delete them later.

      The ideal solution would be configurable for:

      thresholds for creation
      min/max (don't fill up the disk entirely)
      encryption settings
      The "listener" for the file creation should avoid thrashing, have timeouts, and handle disk space usage sanely.



      ~~~~~~~~~~

      Merge code from two Realtek Wifi Drivers (175h)
      Contact: tech-net
      Mentors: Jason R. Thorpe
      Duration estimate: 175h
      the urtwn and rtwn have a lot of duplicate code.
      Merging them will improve both.

      This project is on hold due to the conversion project needing to be completed first.

      ~~~~~~~~~~

      Userland PCI drivers (350h)
      Contact: tech-kern
      Mentors: Taylor R Campbell
      Duration estimate: 350h
      When developing device drivers inside the kernel, mistakes will usually cause the whole kernel to crash unrecoverably and require a reboot. But device drivers need not run inside the kernel: with rump, device driver code can be run as a process inside userland.

      However, userland code has only limited access to the hardware registers needed to control devices: currently, NetBSD supports only USB device drivers in userland, via ugen(4). NetBSD should additionally support developing PCI drivers in userland with rump -- at least one driver, iwm(4), was developed using rump, but on a Linux host!

      There are several milestones to this project:

      Implement enough of the bus_space(9) and pci_mapreg() (pci(9)) APIs to map device registers from PCI BARs, using a pci(4) device (/dev/pciN). A first approximation can be done using pci(3) and simply mmapping from mem(4) (/dev/mem), but it would be better to cooperate with the kernel so that the kernel can limit the user to mapping ranges listed in PCI BARs without granting privileges to read all physical pages in the system. Cooperation with the kernel will also be necessary to implement port I/O instead of memory-mapped I/O, without raising the I/O privilege level of the userland process, on x86 systems.

      Expose PCI interrupts as events that can be read from a pci(4) (/dev/pciN) device instance, and use that to implement the pci_intr(9) API in userland. For many devices, this may require a small device-specific shim in the kernel to acknowledge interrupts while they are masked -- but that is a small price to pay for rapidly iterating driver development in userland.

      Devise a scheme for userland allocate and map memory for DMA in order to implement bus_dma(9). Again, a first approximation can be done by simply wiring pages with mlock(3) and then asking the kernel for a virtual-to-physical translation to program hardware DMA registers. However, this will not work on any machines with an IOMMU, which would help to prevent certain classes of catastrophic memory corruption in the case of a buggy driver. Cooperation with the kernel, and maintaining a kernel-side mirror of each bus_dmamem allocation and each bus_dmamap.

      Inspiration may be found in the Linux uio framework. This project is not necessarily PCI-specific -- ideally, most of the code to manage bus_space(9), bus_dma(9), and interrupt event delivery should be generic. The focus is PCI because it is widely used and would be applicable to many drivers and devices for which someone has yet to write drivers.


      ~~~~~~~~~~

      VMWare graphical acceleration (350h)
      Contact: port-amd64
      Duration estimate: 350h
      VMWare provides an emulator that could use graphical acceleration, but doesn't on NetBSD.
      A DRM driver exists for linux which could be adapted, like other DRM drivers that were ported.

      ~~~~~~~~~~

      Real asynchronous I/O (350h)
      Contact: tech-kern
      Mentors: Taylor R Campbell
      Duration estimate: 350h
      The current asynchronous I/O (aio) implementation works by forking a background thread inside the kernel to do the I/O synchronously. This is a starting point, but one thread limits the amount of potential parallelism, and adding more threads falls down badly when applications want to have large numbers of requests outstanding at once.

      Furthermore, the existing code doesn't even work in some cases; this is not well documented but there have been scattered reports of problems that nobody had time to look into in detail.

      In order to make asynchronous I/O work well, the I/O path needs to be revised, particularly in the kernel's file system interface, so that all I/O operations are asynchronous requests by default. It is easy for high-level code to wait synchronously for lower-level asynchronous requests to complete; it is much more problematic for an asynchronous request to call into code that expects to be synchronous.

      The ?flow control project, which also requires substantial revisions to the I/O path, naturally combines with this project.



      ~~~~~~~~~~

      NPF user/group filtering
      Contact:
      tech-net
      Mentors: Christos Zoulas
      Duration estimate: 350h
      Add the ability to filter packets by user or group that owns the socket sending or receiving packets. This ability is available in other packet filters for example pf. The project involves modifying the parser to accept the syntax, passing the information to the kernel, and modifying the kernel packet filter code to process the user/group filtering options and allow/drop packets.


      ~~~~~~~~~~

      Tickless NetBSD with high-resolution timers (350h)
      Contact: tech-kern
      Mentors: Taylor R Campbell
      Duration estimate: 350h
      NetBSD configures a timer device to deliver a periodic timer interrupt, usually every 10 ms, in order to count time, wake threads that are sleeping, etc. This made sense when timer devices were expensive to program and CPUs ran at MHz. But today, CPUs run at GHz; timers on modern x86, arm, mips, etc. hardware are cheap to reprogram; programs expect greater than 10 ms resolution for sleep times; and mandatory periodic activity on idle machines wastes power.

      There are four main milestones to this project:

      Choose a data structure for high-resolution timers, and a way to request high-resolution vs low-resolution sleeps, and adapt the various timeout functions (cv_timedwait, etc.) to use it. The current call wheel data structure for callouts provides good performance, but only for low-resolution sleeps. We need another data structure that provides good performance for high-resolution sleeps without hurting the performance of the existing call wheel for existing applications.

      Design a machine-independent high-resolution timer device API, implement it on a couple machines, and develop tests to confirm that it works. This might be done by adapting the struct timecounter interface to arm it for an interrupt, or might be done another way.

      Convert all the functions of the periodic 10 ms timer, hardclock, to schedule activity only when needed.

      Convert the various software subsystems that rely on periodic timer interrupts every tick, or every second, via callout(9), either to avoid periodic work altogether, or to batch it up only when the machine is about to go idle, in order to reduce the number of wakeups and thereby reduce power consumption.

      Add a comment

      ~~~~~~~~~~

      Inetd enhancements -- Add new features to inetd (175h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 175h
      inetd is a classic method for launching network programs on-the-fly and some of its ideas are coming back into vogue. Enhancing this daemon should include investigations into other similar systems in other operating systems.

      Primary milestones:

      Prefork: Support pre-forking multiple children and keeping them alive for multiple invocations.
      Per service configuration file: Add a per-service configuration file similar to xinetd.
      Make the rate-limiting feature configurable on a per-service basis.
      Improve the logging and make logging modes configurable on a per-service basis.
      Nice to have:

      Add include directives to the configuration language to allow service definitions to be installed in /usr/share or /usr/pkg/share.
      Add a separate way to turn services on and off, so they can be defined statically (such as in /usr/share) and turned on and off from /etc.
      Allow non-privileged users to add/remove/change their own services using a separate utility.
      Integrate with the new blocklist daemon.
      Configuration compatibility for systemd socket activations

      ~~~~~~~~~~


      iscsictl(1) enhancement (175h)
      Contact: tech-net
      Mentors: Frédéric Fauberteau
      Duration estimate: 175h
      The iscsictl(1) program manages the iSCSI instances on the local computer. It communicates with the iscsid(8) daemon to send queries using iSCSI protocol.

      Possible enhancements:

      Review of iscsictl(1) manpage. For instance, the command add_target has no description, [target-opts] could be refered to "Target Options".
      Add a mode to iscsictl(1) program to log sessions at boot. It could be a batch command (the name could be discussed) that read a /etc/iscsi.conf file. Some parts of the iscsictl(1) from FreeBSD could be ported.
      Implement the find_isns_servers.
      The iscsi-target(8) server allows to setup iSCSI targets on a NetBSD host and to present block storage to the network. It can be used to test the iscsictl(1) implementation.




      ~~~~~~~~~~

      Test Linux emulation (350h)
      Contact: tech-userlevel
      Mentors: Stephen Borrill
      Duration estimate: 350h
      NetBSD has an extensive test suite that tests native kernel and userland code. NetBSD can run Linux binaries under emulation (notably on x86, but other platforms such as ARM have some support too). The Linux emulation is not covered by the test suite. It should be possible to run an appropriate subset of the tests when compiled as Linux binaries.

      The project could be completed in a number of steps:

      Determine tests that make sense to run under Linux emulation (e.g. syscalls)
      Compile tests on Linux and then run on NetBSD
      Add new/altered tests for Linux-specific APIs or features
      Build cross-compilation environment to build Linux binaries on NetBSD, to make the test-suite self-hosting
      Fix Linux emulation for tests that fail
      Use tests to add Linux emulation for syscalls missing (e.g.timer_*)
      It may also be instructive to look at the Linux Test Project.

      The project would initially be focussed on x86 (amd64 and i386)

      ~~~~~~~~~~

      Modern cryptographic algorithms to netpgp, netpgpverify (350h)
      Contact: Alistair G. Crooks, tech-crypto
      Mentors: Alistair G. Crooks
      Duration estimate: 350h
      Adapt existing ed25519 and salsa20 implementations to netpgp, netpgpverify
      Maintain compatibility and interoperability with gpg2's usage
      Maintain compatibility with openssh's keys
      Extend tests to cover new algorithms
      Extended goals:

      provide a standalone netpgp signing utility, to mirror the netpgpverify verification utility



      ~~~~~~~~~~

      Add UEFI boot options
      Contact: tech-install
      Currently NetBSD can be booted via UEFI firmware, but only offers the default boot loader setup so multi-boot environments are hard to create. This also causes cryptic displays in the firmware boot order menu or boot select menu, like "UEFI OS", instead of "NetBSD 10.0".

      The UEFI spec offers support to configure load options, which include a path to the bootloader and a description of the operating system, see the UEFI spec. This project is to implement setting up proper load option variables at least on x86 machines booting via UEFI.

      Part of the project is to find the best place to set this options up. Some integrations with sysinst might be needed, maybe sysinst is the right place to set this variables. If not, sysinst may simply be changed to use a different sub directory on the ESP for the NetBSD bootloader and the variables setup might happen elsewhere.

      Currently the kernel interface to access the SetVariable() and other EFI runtime callbacks exists, but there is no userland tool to operate it.

      It is not clear what the EFI path set in the variable should be, and mapping NetBSD disks/partitions to EFI path notation is not trivial. 

      ~~~~~~~~~~

      Audio visualizer for the NetBSD base system (350h)
      Contact: nia
      Mentors: nia
      Duration estimate: 350h
      NetBSD includes various simple, command-line audio tools by default, such as audioplay(1), audiorecord(1), mixerctl(1), aiomixer(1), audiocfg(1)...

      These tools are useful because they provide almost everything a user needs to test basic functionality of their audio hardware. They are critically important for basic diagnostics.

      It would be nice to have a tool to easily visualize audio input using a simple Curses interface. Some ideas for its possible functionality:

      Display basic live-updating frequency graph using bars
      Display channels separately
      'Echo' option (play back audio as it is input)
      pad(4) support (NetBSD has support for 'virtual' audio devices. This is useful because you can record the output of an application by having it output to the audio device that opening /dev/pad creates. This can also 'echo' by outputting the data read from the pad device.)
      You need NetBSD installed on physical hardware (older laptops work well and are cheaply available) and a microphone for this project. Applicants should be familiar with the C programming language.




      ~~~~~~~~~~

      Light weight precision user level time reading (350h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 350h
      Design and implement a mechanism that allows for fast user level access to kernel time data structures for NetBSD. For certain types of small data structures the system call overhead is significant. This is especially true for frequently invoked system calls like clock_gettime(2) and gettimeofday(2). With the availability of user level readable high frequency counters it is possible to create fast implementations for precision time reading. Optimizing clock_gettime(2) and alike will reduce the strain from applications frequently calling these system calls and improves timing information quality for applications like NTP. The implementation would be based on a to-be-modified version of the timecounters implementation in NetBSD.

      Milestones:

      Produce optimizations for clock_gettime
      Produce optimizations for gettimeofday
      Show benchmarks before and after
      start evolving timecounters in NetBSD, demonstrating your improvements

      ~~~~~~~~~~

      Query optimizer for find(1) (350h)
      Contact: tech-userlevel
      Mentors: David Holland
      Duration estimate: 350h
      Add a query optimizer to find(1).

      Currently find builds a query plan for its search, and then executes it with little or no optimization. Add an optimizer pass on the plan that makes it run faster.

      Things to concentrate on are transforms that allow skipping I/O: not calling stat(2) on files that will not be matched, for example, or not recursing into subdirectories whose contents cannot ever match. Combining successive string matches into a single match pattern might also be a win; so might precompiling match patterns into an executable match form (like with regcomp(3)).

      To benefit from many of the possible optimizations it may be necessary to extend the fts(3) interface and/or extend the query plan schema or the plan execution logic. For example, currently it doesn't appear to be possible for an fts(3) client to take advantage of file type information returned by readdir(3) to avoid an otherwise unnecessary call to stat(2).

      Step 1 of the project is to choose a number of candidate optimizations, and for each identify the internal changes needed and the expected benefits to be gained.

      Step 2 is to implement a selected subset of these based on available time and cost/benefit analysis.

      It is preferable to concentrate on opportunities that can be found in find invocations likely to actually be typed by users or issued by programs or infrastructure (e.g. in pkgsrc), vs. theoretical opportunities unlikely to appear in practice.

      ~~~~~~~~~~

      IKEv2 daemon for NetBSD (350h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 350h
      racoon(8) is the current IKEv1 implementation used in NetBSD. The racoon code is old and crufty and full of potential security issues. We would like to replace it. There are other implementations available, such as StrongSwan, openiked/isakmpd, racoon2.

      This project has two stages:

      Evaluate all 3 (or more) solutions, describe and document their pros and cons, and then settle into one of them.

      Port it to NetBSD to replace racoon.

      I have started working on that for racoon2 on https://github.com/zoulasc/racoon2/ (see the TODO file), and also have a build glue for NetBSD for it https://github.com/zoulasc/racoon2-glue/ and it works. I've also gotten openiked to compile (but not work).

      ~~~~~~~~~~

      Port launchd (350h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 350h
      Launchd is a MacOS/X utility that is used to start and control daemons similar to init(8), but much more powerful. There was an effort to port launchd to FreeBSD, but it seems to be abandoned. We should first investigate what happened to the FreeBSD effort to avoid duplicating work. The port is not trivial because launchd uses a lot of mach features.

      Milestones:

      report of FreeBSD efforts (past and present)
      launchd port replacing: init
      launchd port replacing: rc
      launchd port compatible with: rc.d scripts
      launchd port replacing: watchdogd
      Nice to have:

      launchd port replacing/integrating: inetd
      launchd port replacing: atd
      launchd port replacing: crond
      launchd port replacing: (the rest)



      ~~~~~~~~~~

      Add support for OpenCL and Vulkan to NetBSD xsrc (175h)
      Contact: nia
      Mentors: nia
      Duration estimate: 175h
      A core component of NetBSD is the 'xsrc' repository, which contains a 'classic' distribution of X11, all related programs, and libraries, as found on Unix systems from times of yore.

      xsrc uses the NetBSD build system and only BSD make to build, which means it builds extremely quickly, with minimal dependencies, and is easy to cross-compile. It currently includes an implementation of the OpenGL graphics API (Mesa), but not an implementation of the next-generation Vulkan graphics API, or OpenCL, the GPU-accelerated compute API, which can also be obtained from Mesa.

      Most of modern X.Org is built with Meson and Python, so some level of translation is required to integrate new components.

      This project involves making modifications to the Mesa Vulkan and OpenCL libraries in order to allow them to work on NetBSD (this part requires basic knowledge of the C programming language and Unix APIs), ideally submitting them upstream, until Vulkan and OpenCL support can be built on NetBSD, and then integrating the relevant components into the NetBSD build system using only BSD Make.

      The candidate should ideally have some knowledge of the C programming language and build systems.

      ~~~~~~~~~~

      Automatic tests for PAM
      Contact: tech-kern
      Mentors: Taylor R Campbell
      Duration estimate: 1-2 months
      Implement automatic tests with ATF for all the PAM modules under src/lib/libpam/modules.

      The modules, such as pam_krb5, are not currently automatically tested, despite being security-critical, which has led to severe regressions.




      ~~~~~~~~~~

      Efficient Package Distribution
      Contact: jkoshy
      Mentors: Joseph Koshy
      Duration estimate: 350h
      Implement efficient binary package updates by patching prior releases instead of downloading large packages afresh - please see: (jkoshy.net) Efficient Package Distribution

      Primary milestones:

      Define the patching protocol between the package manager client (i.e., pkgin) and the Patch server.
      Implement the 'Patch Server', defaulting to current behavior when binary patches are missing.
      Add patch protocol support to the pkgin package management client.
      On the 'Patch Server', implement a pipeline to generate binary patches whenever new package releases are added to it.
      Nice to have:

      Add file-format-specific (i.e., ELF-, JPEG-, PNG- specific) binary patch generation.



      ~~~~~~~~~~

      SASL-C implementation for the OpenLDAP client (350h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 350h
      OpenLDAP already has a SASL back-end for CYRUS-SASL.
      In NetBSD, we have our own SASL-C library which has similar functionality and can be used in OpenLDAP instead of CYRUS.
      Base postfix already does this.

      There is a cyrus.c file where all the work is done.
      We can make a saslc.c one that uses our library.
      This will allow different authentication schemes to be used for the client programs (so we will be able to run ldapsearch against an Active Directory server using GSSAPI.

      ~~~~~~~~~~

      Secure-PLT - supporting RELRO binaries (350h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 350h
      All architectures suffer from code injection issues because the only writable segment is the PLT/GOT. RELRO (RELocation Read Only) is a mitigation technique that is used during dynamic linking to prevent access to the PLT/GOT. There is partial RELRO which protects that GOT but leaves the PLT writable, and full RELRO that protects both at the expense of performing a full symbol resolution at startup time. The project is about making the necessary modifications to the dynamic loader (ld_elf.so) to make RELRO work.

      If that is completed, then we can also add the following improvement: Currently kernels with options PAX_MPROTECT can not execute dynamically linked binaries on most RISC architectures, because the PLT format defined by the ABI of these architectures uses self-modifying code. New binutils versions have introduced a different PLT format (enabled with --secureplt) for alpha and powerpc.

      Milestones:

      For all architectures we can improve security by implementing relro2.
      Once this is done, we can improve security for the RISC architectures by adding support for the new PLT formats introduced in binutils 2.17 and gcc4.1 This will require changes to the dynamic loader (ld.elf_so), various assembly headers, and library files.
      Support for both the old and new formats in the same invocation will be required.
      Status: * Added support to the dynamic loader (ld.elf_so) to handle protecting the GNU relro section. * Enabled partial RELRO by default on x86.



      ~~~~~~~~~~

      Research and integrate the static code analyzers with the NetBSD codebase (350h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 350h
      The NetBSD sourcecode is verified by a static analyzers like Coverity. Attempt to automate the process, report and if possible fix bugs.

      Milestones:

      Consult and research the available tools.
      Integrate the tools for the purposes of the NetBSD project.
      Scan the sources, report bugs, if possible fix the problems, or file bug reports



      ~~~~~~~~~~

      Sysinst alternative interface (350h)
      Contact: tech-install
      Mentors: Marc Balmer, Martin Husemann
      Duration estimate: 350h
      The goal of this project is to provide an alternative version of the NetBSD system installer with a simple, X based graphical user interface.

      The installer currently uses a "homegrown" (similar to CUA) text based interface, thus being easy to use over serial console as well as on a framebuffer console.

      The current installer code is partly written in plain C, but in big parts uses C fragments embedded into its own definition language, preprocessed by the "menuc" tool into plain C code and linked against libterminfo.

      During this project, the "menuc" tool is modified to optionally generate a different version of the C code, which then is linked against standard X libraries. The C stub fragments sprinkled throughout the menu definitions need to be modified to be reusable for both (text and X) versions. Where needed the fragments can just call C functions, which have different implementations (selected via a new ifdef).

      Since the end result should be able to run off an enhanced install CD, the selection of widgets used for the GUI is limited. Only base X libraries are available. A look & feel similar to current xdm would be a good start.

      Developement can be done on an existing system, testing does not require actuall installation on real hardware.

      An optional extension of the project is to modify the creation of one or more port's install CD to make use of the new xsysinst.

      Milestones include: * modify the "menuc" tool to support X * keep text/serial console installing * demonstrate a GUI install * demonstrate fallback to the text installer

      The candidate must have:

      familiarity with the system installer. You should have used sysinst to install the system.
      familiarity with C and X programming.
      The following would also be useful:

      familiarity with NetBSD.
      familiarity with user interface programming using in-tree X widgets.
      References:
      sysinst source (opengrok)
      vnconfig(8) manual page



      ~~~~~~~~~~

      Verification tool for NetBSD32 (350h)
      Contact: tech-toolchain
      Mentors: Jörg Sonnenberger
      Duration estimate: 350h
      NetBSD supports a number of platforms where both 32bit and 64bit execution is possible. The more well known example is the i386/AMD64 pair and the other important one is SPARC/SPARC64. On this platforms it is highly desirable to allow running all 32bit applications with a 64bit kernel. This is the purpose of the netbsd32 compatibility layer.

      At the moment, the netbsd32 layer consists of a number of system call stubs and structure definitions written and maintained by hand. It is hard to ensure that the stubs and definitions are up-to-date and correct. One complication is the difference in alignment rules. On i386 uint64_t has a 32bit alignment, but on AMD64 it uses natural (64bit) alignment. This and the resulting padding introduced by the compiler can create hard to find bugs.

      goals/milestones:

      replace the manual labour with an automatic tool
      This tool should allow both verification / generation of structure definitions for use in netbsd32 code allow generation of system call stubs and conversion functions. Generated stubs should also ensure that no kernel stack data is leaked in hidden padding without having to resort to unnecessary large memset calls.

      For this purpose, the Clang C parser or the libclang frontend can be used to analyse the C code.

      ~~~~~~~~~~

      Add KNF (NetBSD style) clang-format configuration (175h)
      Contact: tech-toolchain
      Duration estimate: 175h
      clang-format is a tool to format source code according to a set of rules and heuristics. Like most tools, it is not perfect nor covers every single case, but it is good enough to be helpful.

      clang-format can be used for several purposes:

      Quickly reformat a block of code to the NetBSD (KNF) style.
      Spot style mistakes, typos and possible improvements in files.
      Help to follow the coding style rules.
      Milestones:

      Create configuration file .clang-format that approximate the NetBSD coding style
      Patch LibFormat to handle missing coding style rules.
      Integrate .clang-format with the NetBSD distribution.

      ~~~~~~~~~~

      Integrate libFuzzer with the basesystem (350h)
      Contact: tech-userlevel
      Mentors: Kamil Rytarowski
      Duration estimate: 350h
      Integrate the LLVM libFuzzer with the basesystem framework. Build and execute base programs against libFuzzer.

      Milestones:

      Ensure completeness of the toolchain in the basesystem.
      Add a new option for building the basesystem utilities with libFuzzer.
      Finish the integration and report bugs.



      ~~~~~~~~~~

      Integrate LLVM/GCC Sanitizers with pkgsrc (350h)
      Contact: tech-pkg
      Mentors: Kamil Rytarowski
      Duration estimate: 350h
      Add support in the pkgsrc framework for building packages with sanitizers.

      Expected sanitizer options:

      Address (ASan),
      Memory (MSan),
      MemoryWithOrigin (MSan with tracking the origin)
      Undefined (UBSan),
      Thread (TSan),
      Address;Undefined (ASan & UBSan)
      "" (empty string) - the default option
      Milestones:

      Ensure the availability of the toolchain and prebuilt userland with the sanitizers.
      Add new option in pkgsrc to build the packages with a each sanitizer.
      Build the packages and report problems and bugs.

      ~~~~~~~~~~

      Integrate Scudo with the basesystem (350h)
      Contact: tech-userlevel
      Mentors: Kamil Rytarowski
      Duration estimate: 350h
      Integrate the LLVM Scudo with the basesystem framework. Build and execute base programs against Scudo.

      Milestones:

      Ensure completeness of the toolchain in the basesystem.
      Add a new option for building the basesystem utilities with Scudo.
      Finish the integration and report bugs.
      Research Scudo for pkgsrc.



      ~~~~~~~~~~

      Enhance the syzkaller support for NetBSD (350h)
      Contact: tech-userlevel
      Mentors: Kamil Rytarowski
      Duration estimate: 350h
      There is an initial functional support for syzkaller for NetBSD (as guest). Resume the porting effort, execute and report kernel bugs.

      Milestones:

      Ensure completeness of the current support.
      Execute the fuzzer and gather reports, narrow down problems, translate to C reproducers.
      Add missing features, fix bugs in the NetBSD support.

      ~~~~~~~~~~

      Improve UI/UX of pkgsrc MESSAGE (175h)
      Contact: Leonardo Taccari, tech-pkg
      Duration estimate: 175h
      The current UI/UX of pkgsrc MESSAGE has a couple of drawbacks:

      When installing a lot of packages via pkg_add or pkgin it is often get lost
      When updating packages via pkg_add or pkgin - also if the MESSAGE is not changed - it is printed anyway
      For possible inspirations please look at OpenBSD ports' pkg-readmes and/or other package systems.

      ~~~~~~~~~~

      Port the Enlightenment desktop environment to NetBSD (350h)
      Contact: nia
      Mentors: nia
      Duration estimate: 350h
      pkgsrc is NetBSD's native package building system. It's also used on other platforms, such as illumos. It includes numerous graphical environments, including Xfce, MATE, and LXQt, but support for Enlightenment has since bitrotted and been largely removed. Support for its related fork Moksha is missing entirely.

      Enlightenment is partiuclarly interesting for NetBSD because it's lightweight, BSD licensed, and suitable for mobile applications. We're not sure about the benefits of Moksha over Enlightenment proper, but it's worth investigating.

      Since Enlightenment is written in C, the applicant should ideally have a basic understanding of C and Unix system APIs. In order for the port not to bit-rot in the future, it should be done well, with patches integrated upstream where possible. They should have a laptop with NetBSD installed (older laptops are likely more representative of typical NetBSD uses and can be picked up cheap from local auctions sites).

      Integrating Enlightenment into pkgsrc will require a knowledge of build systems and make (pkgsrc in particuar is built on top of BSD make).

      Milestones:

      A basic port enables basic Enlightenment installation on NetBSD when installed from pkgsrc.
      A more advanced and ideal port has tight integration with NetBSD system APIs, supporting features like native audio mixing and reading from sensors.
      For extra brownie points, the pkgsrc package should work on illumos too.

      ~~~~~~~~~~

      pkgin improvements (350h)
      Contact: tech-pkg
      Mentors: Emile 'iMil' Heitor, Jonathan Perkin
      Duration estimate: 350h
      pkgin is aimed at being an apt-/yum-like tool for managing pkgsrc binary packages. It relies on pkg_summary(5) for installation, removal and upgrade of packages and associated dependencies, using a remote repository.

      While pkgin is now widely used and seems to handle packages installation, upgrade and removal correctly, there's room for improvement. In particular:

      Main quest

      Support for multi-repository
      Speed-up installed packages database calculation
      Speed-up local vs remote packages matching
      Implement an automated-test system
      Handle conflicting situations (MySQL conflicting with MySQL...)
      Better logging for installed / removed / warnings / errors
      To be confirmed / discussed:

      Make pkgin independent from pkg_install binaries, use pkg_install libraries or abstract them
      Bonus I

      In order to ease pkgin's integration with third party tools, it would be useful to split it into a library (libpkgin) providing all methods needed to manipulate packages, i.e., all pkgin's runtime capabilities and flags.

      Bonus II (operation "burn the troll")

      It would be a very nice addition to abstract SQLite backend so pkgin could be plugged to any database system. A proof of concept using bdb or cdb would fulfill the task.

      Useful steps:

      Understand pkgsrc
      Understand pkg_summary(5)'s logic
      Understand SQLite integration
      Understand pkgin's `impact.c' logic


      ~~~~~~~~~~

      Improve support for NetBSD sensors and audio APIs in third-party software (350h)
      Contact: nia
      Mentors: nia
      Duration estimate: 350h
      pkgsrc is NetBSD's native package building system It includes numerous graphical environments, including Xfce, MATE, and LXQt, but many have limited support for native NetBSD system APIs, e.g. support for reading battery levels, and audio volume.

      We really would like better desktop environment integeration, and this requires some work on the upstream projects in C and in some cases C++.

      An applicant should have basic familiarity with build systems, make, and C. They should be good at carefully reading documentation, as much of this stuff is documented in manual pages like audio(4) and envsys(4). They should have a laptop with NetBSD installed (older laptops are likely more representative of typical NetBSD uses and can be picked up cheap from local auctions sites).

      They should be able to investigate the current level of support in various third-party projects and identify priority targets where native code for NetBSD can be written.

      Nia is very experienced in writing native code for NetBSD audio and sensors and would be happy to answer questions.

      As the project continues, we might even be able to start porting more applications and applets.



      ~~~~~~~~~~

      Add dependency information to binary packages (350h)
      Contact: tech-pkg
      Mentors: Thomas Klausner
      Duration estimate: 350h
      Change infrastructure so that dependency information (currently in buildlink3.mk files) is installed with a binary package and is used from there

      This is not an easy project.

      pkgsrc currently handles dependencies by including buildlink3.mk files spread over pkgsrc. The problem is that these files describe the current state of pkgsrc, not the current state of the installed packages.

      For this reason and because most of the information in the files is templated, the buildlink3.mk files should be replaced by the relevant information in an easily parsable manner (not necessarily make syntax) that can be installed with the package. Here the task is to come up with a definitive list of information necessary to replace all the stuff that's currently done in buildlink3.mk files (including: dependency information, lists of headers to pass through or replace by buildlink magic, conditional dependencies, ...)

      The next step is to come up with a proposal how to store this information with installed packages and how to make pkgsrc use it.

      Then the coding starts to adapt the pkgsrc infrastructure to do it and show with a number of trivial and non-trivial packages that this proposal works.

      It would be good to provide scripts that convert from the current state to the new one, and test it with a bulk build.

      Of course it's not expected that all packages be converted to the new framework in the course of this project, but the further steps should be made clear.

      goals/milestones:

      invent a replacement for buildlink3.mk files, keeping current features
      demonstrate your new tool as a buildlink3.mk replacement including new features
      execute a bulk build with as many packages as possible using the new buildlink





    
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-netbsd-foundation/
    idea_list_url: https://wiki.netbsd.org/projects/gsoc/

  - organization_id: 158
    organization_name: The P4 Language Consortium
    no_of_ideas:
    ideas_content: |
     
      Project 1: Integrate p4-constraints frontend into P4C ⤴️
      Basic info
      Potential mentors
      Primary: Matthew Lam
      Support: Jonathan DiLorenzo, Fabian Ruffy
      Skills
      Required: Git, C++
      Preferred: CMake, Bazel, P4C
      Discussion thread: TBD
      Alternative qualification task
      Currently, the type checking function, InferAndCheckTypes, explicitly fails when called on an already type-checked expression. Ideally, this behavior should be idempotent; causing no change to an already type-checked expression, but also not causing an error. This would allow us to use it to ensure that expression were properly typed and had certain types.
      Create a PR under https://github.com/p4lang/p4-constraints with the fix.
      Project description
      p4-constraints is a useful extension of the P4 programming language that is currently architected as a standalone library separate from the P4 compiler, P4C.
      The goal of this project is to integrate the p4-constraints frontend, which parses and type checks the constraint annotations, into the P4C frontend. This architecture change provides the following benefits:
      For P4 programmers: Immediate feedback about syntax or type errors in constraints during P4 compilation.
      For P4C backend developers: Easy consumption of the parsed & type-checked constraints.
      P4TestGen is a concrete example of a P4C backend that needs to consume p4-constraints to work correctly, and it currently does this by implementing its own p4-constraints frontend, which is brittle and requires duplication of work for new p4-constraint features.
      Expected outcomes
      The p4-constraints frontend becomes part of P4C.
      Resources
      https://github.com/p4lang/p4-constraints
      https://github.com/p4lang/p4c
      p4lang/p4c#4387


      ~~~~~~~~~~

      Project 2: BMv2 packet trace support ⤴️
      Basic info
      Potential mentors
      Primary: Matthew Lam
      Support: Jonathan DiLorenzo, Bili Dong, Antonin Bas
      Skills
      Required: Git, C++
      Preferred: P4
      Discussion thread: TBD
      Alternative qualification task
      Currently, BMv2 uses some legacy code written in C with bf_lpm_trie.c being one of the instances.
      Create a PR under https://github.com/p4lang/behavioral-model that converts the C code to C++. Note that style and readability are key.
      Project description
      Having programmatic access to the trace of a packet going through a P4 pipeline (e.g. applied tables, actions, entries hit, etc) has many use cases from human comprehension to use by automated tools for test coverage measurement, automated test generation, automated root causing, etc.
      BMv2 currently does provide textual logs that can be used to manually track the packet as it goes through the pipeline. However there is no API to access the trace in a more structured and programmatic form (i.e. in a way that can potentially be digested by other tools).
      The goal of this project is to provide a mechanism for BMv2 to record the trace and provide it to the user in a structured format.
      Expected outcomes
      Structured packet trace outputs supported in BMv2.
      Resources
      BMv2: https://github.com/p4lang/behavioral-model

      ~~~~~~~~~~


      Project 3: BMv2 with all possible output packets ⤴️
      Basic info
      Potential mentors
      Primary: Matthew Lam
      Support: Jonathan DiLorenzo, Bili Dong, Antonin Bas
      Skills
      Required: Git, C++
      Preferred: P4
      Discussion thread: TBD
      Alternative qualification task
      Currently, BMv2 uses some legacy code written in C with bf_lpm_trie.c being one of the instances.
      Create a PR under https://github.com/p4lang/behavioral-model that converts the C code to C++. Note that style and readability are key.
      Project description
      There are many situations where it is more useful to have all possible outputs from a P4 simulation rather than only a single one. For example, we use this for diff testing, to determine whether the switch is doing something correct or something incorrect.
      Multiple allowed behaviors usually arise from various multi-path constructs (e.g. ECMP, WCMP, or perhaps LAGs) usually modeled as action profiles in P4. BMv2 currently allows users to set a mode determining action profile behavior, like round robin which means that every time you send in the same packet, it should result in the next possible outcome (eventually wrapping around).
      The goal of this project is to provide a new mode for BMv2 to instead output ALL possible behaviors. This will both require extending the action profile modes, and likely extending the notion of output from a set of packets to a set of sets of packets.
      Expected outcomes
      BMv2 has a modality where every possible outcome is generated instead of one possible outcome.
      Must interact correctly with multicast and punting.
      Resources
      BMv2: https://github.com/p4lang/behavioral-model

      ~~~~~~~~~~
      Project 4: Finalize Katran P4 and improve the eBPF backend! ⤴️
      Basic info
      Potential mentors
      Primary: Davide Scano
      Support: Fabian Ruffy
      Skills
      Required: eBPF
      Preferred: P4C, P4
      Discussion thread: TBD
      Alternative qualification task
      Please demonstrate your XDP eBPF skills through contributions to any of the following projects:
      Any existing XDP eBPF project.
      Any personal project that has used XDP eBPF.
      Please demonstrate your basic P4 knowledge through contributions to any of the following projects:
      Any existing P4 project, preferably P4 tutorials or P4C.
      Any personal project that incorporates P4.
      Project description
      Katran is designed to build a high-performance load balancer based on C and eBPF. The P4 open-source compiler, P4C, supports eBPF as one of its possible targets. This allows a P4 program to be converted into an eBPF program for packet processing. The maintenance of the eBPF backend relies on simple examples that are used to test the backend. The lack of complex programs makes developing and evaluating new features, as well as identifying regressions, more challenging.
      Finalize the implementation of Katran in P4 helps provide a complex program example imporve the test coverage of eBPF backend. Due to that possible bugs can be identifed and fixd together with new features can be implemented.
      Expected outcomes
      Document and complete the P4 implementation of Katran.
      Identify and/or resolve bugs in the P4C eBPF backend.
      If needed, update the P4C eBPF backend documentation.
      Resources
      Katran: https://github.com/facebookincubator/katran
      Katran P4: https://github.com/Dscano//P4-Katran
      P4C eBPF backend: https://github.com/p4lang/p4c/tree/main/backends/ebpf
      NIKSS: https://github.com/NIKSS-vSwitch/nikss

      ~~~~~~~~~~
      Project 5: P4Simulator: Enabling P4 Simulations in ns-3 ⤴️
      Basic info
      Potential mentors
      Primary: Mingyu Ma
      Support: Tommaso Pecorella, Davide Scano
      Skills
      Required: P4, C++
      Preferred: ns-3, BMv2
      Discussion thread: TBD
      Project description
      P4Simulator is a P4-driven network simulator that aims to combine P4—the state-of-the-art programmable data plane language—with ns-3, one of the most popular and versatile network simulators. While the current module already supports basic P4 functionality in ns-3, there remain numerous areas that require further development, as outlined in the Alternative qualification task. We also welcome discussions on any other ideas or improvements you may wish to propose for P4Simulator.
      To advance the development of P4Simulator, we invite contributions in several key areas, including but not limited to:
      Control Plane Enhancement: Improving control plane support for seamless interaction between P4 programs and ns-3.
      PSA Architecture Completion: Implementing full support for the Portable Switch Architecture (PSA) within P4Simulator.
      High-Speed Ethernet Link Module: Developing a high-performance Ethernet link model to simulate real-world network conditions.
      Other Enhancements & Extensions: Exploring additional improvements to expand the functionality and efficiency of P4Simulator.
      Furthermore, we encourage discussions on novel ideas and enhancements that could contribute to the evolution of P4Simulator, making it a more powerful and flexible tool for network simulation research.
      Expected outcomes
      Complete the development and submission of the corresponding project.
      Resources
      p4simulator
      p4sim
      Currently, the p4sim repository is private (Prepare the paper for ICNS3), but it will be made open-source on March 21, 2025, at 17:00 EST. This delay allows for ongoing research, refinement, and the preparation of related publications before public release.
      
      ~~~~~~~~~~
      
      Project 6: P4MLIR: MLIR-based high-level IR for P4 compilers ⤴️
      Basic info
      Potential mentors
      Primary: Anton Korobeynikov
      Support: Bili Dong, Fabian Ruffy
      Skills
      Required: MLIR
      Preferred: P4, P4C
      Discussion thread: TBD
      A bit more information: slides
      Alternative qualification task
      Please demonstrate your MLIR skills through contributions to any of the following projects:
      P4MLIR itself.
      Any other MLIR-based compiler project.
      Your personal project is also fine.
      Make sure your contributions could demonstrate your knowledge of MLIR concepts & internals.
      Project description
      P4C, being a reference compiler for the P4 language, struggles with some fundamental shortcomings of its internal code representation (IR). These issues result in increased running time of the compiler itself as well as unacceptable memory consumption of certain compiler passes.
      Since these problems lie at the foundation of the present IR, as an alternative to just fixing them (that would require some redesign of the IR and would require some invasive changes in the compiler codebase) we are aiming to explore alternative solutions that might at the same time open more opportunities for future growth and expansion of the compiler. One of such possibilities is to explore the adoption of the results of MLIR project to be used within P4C.
      In particular, we aim to develop a P4-specific MLIR dialect (P4HIR) that would allow reuse the infrastructure, code analysis, and transformation passes that have recently been developed within MLIR framework.
      Since P4MLIR is a moving target, the precise set of tasks within this project is TBD at the time of project proposal submission. This might include (but not limited to):
      Implementation of certain dialect operations corresponding to P4 constructs
      Implementation of some dialect interfaces allowing high-level transformations (e.g. Mem2Reg, SROA, data flow analyses)
      Reimplementation of P4C frontend / midend passes in MLIR
      Lowering to P4 high-level dialect to lower-level constructs:
      Perform CFG flattening
      Lowering to llvm and / or emitc dialects
      ...
      Implementing control plane metadata emission out of P4HIR
      The exact list of tasks is to be determined with mentors.
      Expected outcomes
      Implementation of the mentioned P4HIR advancements
      Document the changes made
      Resources
      P4MLIR: https://github.com/p4lang/p4mlir
      P4C: https://github.com/p4lang/p4c
      MLIR: https://mlir.llvm.org/

      ~~~~~~~~~~
      Project 7: P4MLIR BMv2 Dialect Prototype ⤴️
      Basic info
      Potential mentors
      Primary: Bili Dong
      Support: Anton Korobeynikov, Fabian Ruffy
      Skills
      Required: MLIR
      Preferred: BMv2, P4
      Discussion thread: TBD
      Alternative qualification task
      Please demonstrate your MLIR skills through contributions to any of the following projects:
      P4MLIR itself.
      Any other MLIR-based compiler project.
      Your personal project is also fine.
      Make sure your contributions could demonstrate your knowledge of MLIR concepts & internals.
      Project description
      BMv2 is a popular software simulator target for P4. In our current open source P4 compiler P4C, when targeting BMv2, a P4 program is converted to a JSON file, which BMv2 uses as a specification for processing packets. In P4MLIR, we plan to add a dialect specifically for modeling BMv2 JSON primitives, so that the BMv2 dialect -> BMv2 JSON transformation could be straightforward.
      In the longer term, we expect a compilation path like P4C frontend -> P4HIR dialect -> BMv2 dialect -> BMv2 JSON. For this GSoC project, we will concentrate on implementing a subset of BMv2 JSON primitives in the BMv2 dialect, and implementing the corresponding BMv2 dialect -> BMv2 JSON transformation.
      Expected outcomes
      A subset of BMv2 JSON primitives are defined in the BMv2 dialect.
      The BMv2 dialect -> BMv2 JSON transformation works for this subset of primitives.
      Resources
      P4MLIR: https://github.com/p4lang/p4mlir
      BMv2 JSON format: https://github.com/p4lang/behavioral-model/blob/main/docs/JSON_format.md
      P4C BMv2 backend: https://github.com/p4lang/p4c/tree/main/backends/bmv2
      
      ~~~~~~~~~~
      
      Project 8: Gigaflow: A Smart Cache for a SmartNIC! ⤴️
      Basic info
      Potential mentors
      Primary: Annus Zulfiqar, Ali Imran
      Support: Davide Scano, Ben Pfaff, Muhammad Shahbaz
      Skills
      Required: Xilinx Vivado SDK/FPGA Development
      Preferred: OVS, P4, DPDK
      Discussion thread: TBD
      Alternative qualification task
      Please demonstrate your FPGA skills through contributions to any of the following projects:
      Any existing Xilinx Open NIC or NetFPGA projects.
      Any personal project that has used Xilinx Vivao tools.
      Please demonstrate your basic P4 knowledge through contributions to any of the following projects:
      Any existing P4 project.
      Any personal project that incorporates P4.
      Please demonstrate your basic Virtual Networking knowledge through contributions to any of the following projects:
      Any existing OVS project.
      Any personal project that incorporates OVS.
      Project description
      Open vSwitch (OVS) is a widely-adopted virtual switch (vSwitch) in cloud deployments and data centers. Gigaflow (appearing at ASPLOS'25) is a recent advancement that massively improves OVS forwarding performance by offloading a novel multi-table cache architecture to SmartNICs, thereby reducing the CPU-bound cache misses and improving the end-to-end forwarding latency. This project aims to develop a P4-based SmartNIC backend for Gigaflow cache in OVS for P4-programmable FPGA SmartNICs, e.g., the Xilinx Alveo U55/U250 Data Center Accelerator, and modern off-the-shelf SmartNICs, such as AMD Pensando DPU.
      Expected outcomes
      OVS-to-P4 Compilation Pipeline: Improve the existing OVS → P4-SDNet → FPGA codebase to enable seamless compilation to FPGA-based SmartNICs.
      SmartNIC Backend Development: Extend support beyond FPGA-based SmartNICs to include Pensando DPUs as a backend target.
      Upstream Integration: Work towards making Gigaflow a mainstream OVS backend, ensuring maintainability and adoption.
      Resources
      Gigaflow ASPLOS-25 Artifact: https://github.com/gigaflow-vswitch
      Open vSwitch: https://github.com/openvswitch/ovs
      P4 Language: Tutorial-1, Tutorial-2
      
      ~~~~~~~~~~
      
      Project 9: SpliDT: Scaling Stateful Decision Tree Algorithms in P4! ⤴️
      Basic info
      Potential mentors
      Primary: Annus Zulfiqar, Ali Imran
      Support: Davide Scano, Walter Willinger, Muhammad Shahbaz, Murayyiam-Parvez
      Skills
      Required: P4, HyperMapper
      Preferred: Scikit-Learn, PyTorch, Tensorflow, P4Studio
      Discussion thread: TBD
      Alternative qualification task
      Please demonstrate your basic P4 knowledge through contributions to any of the following projects:
      Any existing P4 project.
      Any personal project that incorporates P4.
      Please demonstrate your basic ML and Decision Tree knowledge through contributions to any of the following projects:
      Any personal project that incorporates Scikit-Learn or PyTorch/Tensorflow.
      Project description
      Machine learning is increasingly deployed in programmable network switches for real-time traffic analysis and security monitoring. SpliDT is a scalable framework that removes traditional feature constraints in decision tree (DT) inference by dynamically selecting relevant features at runtime rather than requiring a fixed set per flow. The goal is to enhance accuracy and scalability in high-speed network environments. This project aims to implement and optimize SpliDT using P4, TensorFlow, scikit-learn, and HyperMapper.
      Expected outcomes
      Develop a P4-based implementation of the partitioned DT inference model for P4-programmable switches, leveraging recirculation to efficiently manage resources.
      Use TensorFlow and scikit-learn to enhance DT training and feature selection through a custom optimization framework based on HyperMapper and Bayesian Optimization.
      Evaluate performance across programmable data planes, optimizing the balance between accuracy, scalability, and switch resource efficiency.
      The project will target deployment on Tofino-based switches and other programmable switch architectures, ensuring practical applicability in real-world network monitoring and security scenarios.
      Resources
      P4 Language: Tutorial-1, Tutorial-2
      In-Network ML: Taurus Tutorial at SIGCOMM
      HyperMapper: https://github.com/luinardi/hypermapper
      Tensorflow: https://www.tensorflow.org/
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-p4-language-consortium/
    idea_list_url: https://github.com/p4lang/gsoc/blob/main/2025/ideas_list.md

  - organization_id: 159
    organization_name: The Palisadoes Foundation
    no_of_ideas: 8
    ideas_content: |
      
      Talawa Admin Plugins
      Description:
      Fix and enhance the Talawa plugin system for improved extensibility, usability, and support for additional functionalities such as payment system integration. The current plugin system does not allow for the upload of source code into a predefined directory structure, limiting external contributions. This needs to be refactored and standardized.
      Expected Outcomes:
      Plugin System:
      Replace the existing plugin system with a more robust architecture allowing contributors to upload source code into a predefined directory structure.
      Support multiple external contributors to the Talawa code base.
      Operate similarly to WordPress plugins, enabling flexible and modular integrations.
      (Plugin) Payment System Integration:
      Refactor the plugin system to allow selective uploads of code for integrating payment systems, on a per-provider basis.
      Examples:
      PayPal integration as one plugin.
      Razorpay integration as another plugin.
      Use the WordPress plugin methodology as a guide.
      Maintain separate repositories (e.g., Talawa-plugin-*) for different plugins to support this functionality.
      This plugin would be used to accept single, recurring or fundraising campaign donations. Think of other feature areas where payments could be applicable.
      (Plugin) AI for Usability:
      Primary Features:
      Implement AI-driven SPAM filtering.
      Use AI for fact-checking comments.
      Secondary Features:
      Suggest improvements to event attendance.
      Propose volunteers for events.
      Generate announcements that yield better response rates.
      Integrate AI functionality into a separate repository for scalability.
      Refactoring:
      Reduce technical debt in the API, Talawa Mobile and Talawa Admin codebases related to this feature. Other refactoring is out of scope.
      Improve security to meet modern standards.
      References:
      https://docs-admin.talawa.io/docs/docs/plugins/plugin-architecture
      Repos to update:
      Talawa
      Talawa-API
      Talawa-Admin
      Depends on Project: N/A
      Project Size: 350 hours (Large)
      Possible Mentors:
      Tasneem Koushar (Primary)
      Meetul Rathore (Secondary)
      Difficulty: Medium
      Impact Definition: Core development


      ~~~~~~~~~~

      Improved Usability & Hardening - Talawa Mobile
      Description:
      Refactor and enhance the security features of the Talawa Mobile code base to reduce technical debt, enhance performance, improve security, and optimize usability. Address specific issues related to notifications, event management, and UX improvements.
      Expected Outcomes: We require the following:
      Security Enhancements:
      Strengthen security, especially for file uploads, and implement measures to combat malicious content.
      This is external to the XSS and encryption improvement projects that are currently underway.
      Notifications:
      Build a robust notification system for Talawa Mobile.
      Event Guest Invitations:
      Introduce functionality to invite guests to events through the app.
      Semiotics for UX Improvement:
      Augment text with symbols to improve accessibility and usability for users with limited literacy.
      General:
      Refactor the Talawa Mobile codebase accordingly to reduce technical debt, enhance performance, improve security, and optimize usability related to these features.
      Maximize the use of reusable code.
      Optimize GraphQL queries to minimize the volume and type of unnecessary results
      Related Improvements:
      Consider any other improvements related to the overall goal
      Repos to update:
      Talawa
      Talawa-Mobile
      Depends on Project: N/A
      Project Size: 350 hours (Large)
      Possible Mentors:
      Parag Gupta (Primary / TBD)
      Md. Noman Khan (Secondary)
      Difficulty: Medium
      Impact Definition: Core development


      ~~~~~~~~~~
      Notification Improvements - Talawa Admin
      Description:
      Refactor the messaging and notifcation features of the Talawa Admin code base to reduce technical debt, enhance security, and introduce new features related to notifications. Focus on improving the features and related UI/UX while ensuring the code meets modern best practices.
      Expected Outcomes: These are the expected outcomes:
      Notifications: We need to implement a notification system to make the applications more usable.
      Notification Template:
      Admin created, stored in the DB
      Blueprint for creating notifications.
      Defines the content, type, title, and channel (e.g., email, SMS, or in-app notification).
      The possibility of dynamic variables being injected into the template for personalization.
      Notification Log:
      Maintains a structured DB log of all notifications sent to users or organizations.
      Includes details about the sender, recipient, status, and any dynamic data (variables)
      The ability to be queried for delivery statistics, status tracking, usage patterns.
      Delivery:
      Notifications routed to the appropriate channel (email, in-app, or SMS) based on the template.
      Additional features for possible frontend deep linking.
      Engines & Services:
      Sound scalable methodologies must be found to implement the feature.
      Example:
      A new event is created.
      An administrator creates a template: "Hello {{userName}}, a new event {{eventName}} is live!"
      The backend triggers notifications:
      Template: Event Update.
      Variables: { userName: "Alice", eventName: "Hackathon"}.
      The Notification Engine sends personalized messages to all users.
      Other: Other non notification features include
      Event Guest Invitations:
      Add functionality to invite guests to events from the admin panel.
      Chat Feature:
      Refactor the chat system for better performance and integration with other features.
      Code Quality
      Maximize the use of reusable code
      Optimize GraphQL queries to minimize the volume and type of unnecessary results
      Related Improvements:
      Consider any other improvements related to the overall goal
      Repos to update:
      Talawa
      Talawa-Admin
      Depends on Project: N/A
      Project Size: 350 hours (Large)
      Possible Mentors:
      Disha Talreja (Primary)
      Rishav Jha (Secondary)
      Difficulty: Medium
      Impact Definition: Core development

      ~~~~~~~~~~
      Talawa Accessibility for Blind Users (Mobile)
      Description:
      Enhance Talawa’s accessibility features to support blind and visually impaired users. This includes transcription for voice messages, text-to-speech functionality, screen reader integration, and voice-activated commands.
      Expected Outcomes:
      Transcription for Voice Messages:
      Convert voice messages to text using the Google Speech-to-Text API.
      Display transcriptions below voice messages.
      Implement optional language detection for user-preferred language transcription.
      Text-to-Speech for Transcription:
      Provide TTS functionality using the Flutter TTS plugin to read transcribed text aloud.
      Screen Reader Integration:
      Ensure all voice messages and transcriptions are properly read by screen readers (e.g., TalkBack for Android, VoiceOver for iOS).
      Ensure navigation compatibility with assistive technologies for seamless interactions.
      Voice-Activated Commands:
      Add support for voice commands to play recent messages, start recording, or access transcriptions without touch gestures.
      Media Playback:
      Implement a media player for seamless voice message playback with accessibility features.
      Repos to update:
      Talawa
      Talawa-Mobile
      Depends on Project: N/A
      Project Size: 350 hours (Large)
      Possible Mentors:
      Md. Noman Khan (Primary)
      Shekhar Patel (Secondary / TBD)
      Difficulty: Medium
      Impact Definition: Inclusive development

      ~~~~~~~~~~
      Talawa Enhanced Testing
      Description:
      Improve the testing strategy across all Talawa codebases to ensure high-quality, secure, and maintainable code. Address issues like memory leaks, poor business logic, and lack of comprehensive test coverage. Integrate AI-driven tools for testing automation and efficiency.
      Expected Outcomes:
      Unit Testing with AI:
      Use AI tools like CodeRabbit.ai to create unit tests for all modules in the Talawa application.
      Memory Management Improvements:
      Utilize tools like Keploy or Tramline to optimize memory usage and reduce application bloat.
      End-to-End Testing:
      Perform E2E tests for the Talawa Admin and Mobile codebases using tools like Puppeteer and Jest.
      Reference: Talawa Admin Pull Request #580.
      Prevent Bad Practices:
      Implement mechanisms to catch and prevent poor coding practices, improving the codebase’s robustness and maintainability.
      Repos to update:
      Talawa
      Talawa-Admin
      Talawa-Mobile
      Depends on Project: N/A
      Project Size: 350 hours (Large)
      Possible Mentors:
      Kevonia Tomlinson (Primary)
      Tasneem Koushar (Secondary)
      Md. Noman Khan (Secondary)
      Difficulty: Medium
      Impact Definition: Core development


      ~~~~~~~~~~
      Enhanced SwitchMap-NG Web Features
      Description: The current web UI/UX needs to be improved to increase the usage of SwitchMap-NG by the wider community.
      Expected Outcomes:
      Web UI/UX (Priority)
      The code uses deprecated python packages that prevent upgrading the rest to current versions. The flask-table package is the most notable one
      The UI looks dated because it uses the flask-table package for HTML tables. A more modern alternative is needed. This may or may not be written in Python.
      The latest version offers many new features. We are eager to add new web based capabilities based on these additions that will increase the usage of SwitchMap-NG by the wider community. For example:
      Using LLDP data to create network topology charts
      Showing the historical movement of devices across the network
      Bandwidth charting
      Repository Strategy
      We want to migrate from a monorepo to a polyrepo strategy. We feel this will:
      Allow optimization of each subsystem's code using the appropriate best practices.
      Reduce the learning curve to contribute.
      Your plan must include approaches to do this
      Installation (Priority)
      Use the containerized solution in the switchmap-ng repo as a guide to containerizing your work
      Interaction between the equivalent replacements for the daemons must only communicate via existing GraphQL API calls for data.
      We need an easy to use installation and configuration script for the web UI.
      The structure of the configuration files could be improved.
      Documentation (Priority)
      Create autogenerated markdown documentation for developers from the code base based on code comments.
      This is already done in our Talawa* repositories.
      GitHub actions must be created to ensure that the auto-generated documentation is formatted according to our standards.
      The site must be autoupdated whenever the markdown mentioned in this section is changed.
      Testing (Priority)
      We want to achieve 100% test code coverage for the repository using GitHub actions
      We also want GitHub actions to fail if codecov.io code coverage criteria are not met and coderabbit.io does not approve the PR.
      Repos to Update: SwitchMap-NG
      Skills Required: Proficiency in the code stacks related to the repository. Refer to the introduction section for more details.
      Depends on Project: Enhanced SwitchMap-NG Scalability
      Project Size: 350 hours (Large)
      Possible Mentors:
      Aashima Wadhwa (Primary)
      TBD (Secondary)
      Difficulty: Medium
      Impact Definition: Risky/Exploratory


      ~~~~~~~~~~
      Enhanced SwitchMap-NG Scalability
      For the purposes of this section, the term polling should be interpreted as periodic data gathering.
      Description: SwitchMap-NG has multi-site capabilities, but we need more functionality for it to scale from a few to thousands of pollers.
      Expected Outcomes:
      Operation (Priority)
      The app isn’t suitable for a distributed deployment with groups of pollers that may not have access to the central API server. There needs to be an intuitive way for:
      pollers to reliably store and forward data to an aggregator in their region.
      each regional aggregator to send data to the central API server
      configuring this.
      The solution must tolerate poor connectivity between the pollers, aggregators and the API though a store and forward mechanism without the loss of data for a configurable amount of time.
      For the sake of simplicity, the pollers must get their configurations from the API either directly or through intermediate aggregators.
      Asynchronous Polling (Priority)
      The current python EasySNMP package is very resource intensive and must be replaced.
      Consider replacing multiprocessing / threaded polling with a faster asynchronous polling mechanism using Python’s asyncio or aiohttp for better scalability. This would allow polling of larger networks without blocking and improve the overall speed and resource usage. This would facilitate faster data collection, more efficient resource utilization, and the ability to scale to large networks.
      Another option would be to use a purpose built high performance SNMP application like MRTG/RRDTool to poll and/or evaluate the available SNMP parameters on the target devices.
      Realtime data updates by zone
      The current approach stores posted data to disk with periodic database updates.
      The speed of processing the data may have optimization potential.
      Different data types may require different polling intervals, for example device performance data versus device status data.
      This may require optimized, separate, purpose specific data gathering approaches.
      Historical Data Storage
      Use the current state database to more effectively store and analyze historical network data, such as port utilization, interface bandwidth rates, device status, and ARP data over time. This would allow users to analyze trends and detect issues that may have developed gradually.
      Additional Data Collection
      Extend SNMP support by parsing additional OIDs (MIB translations can be slower) for more detailed device information, such as CPU usage, memory stats, or interface statistics. This would make the inventory system more comprehensive.
      Repository Strategy
      We want to migrate from a monorepo to a polyrepo strategy. We feel this will:
      Allow optimization of each subsystem's code using the appropriate best practices.
      Reduce the learning curve to contribute.
      Your plan must include approaches to do this
      Installation (Priority)
      Use the containerized solution in the switchmap-ng repo as a guide to containerizing your work
      Interaction between the equivalent replacements for the daemons must only communicate via existing API calls. The RESTful posting of data to the DB API server’s file system should remain to reduce the potential overload unless a suitable alternative can be found.
      We need an easy to use installation and configuration script for the web UI.
      The structure of the configuration files could be improved.
      Documentation (Priority)
      Create autogenerated markdown documentation for developers from the code base based on code comments.
      This is already done in our Talawa* repositories.
      GitHub actions must be created to ensure that the auto-generated documentation is formatted according to our standards.
      The site must be autoupdated whenever the markdown mentioned in this section is changed.
      Testing (Priority)
      We want to achieve 100% test code coverage for the repository using GitHub actions
      We also want GitHub actions to fail if codecov.io code coverage criteria are not met and coderabbit.io does not approve the PR.
      Repos to Update: SwitchMap-NG
      Skills Required: Proficiency in the code stacks related to the repository. Refer to the introduction section for more details.
      Depends on Project: Enhanced SwitchMap-NG Web Features
      Project Size: 350 hours (Large)
      Possible Mentors:
      Dominic Mills (Primary)
      TBD (Secondary)
      Difficulty: Medium
      Impact Definition: Risky/Exploratory


      ~~~~~~~~~~
     
      Hybrid
      Note: It's important that you append a brief 3-4 word description to the name of your Hybrid idea. This will make it uniquely identifiable. It could assist us in selecting one or more hybrid ideas. For example if your hybrid idea is to improve the deployment of foo, you could name your project Hybrid - Foo Deployment. The title must have the word Hybrid in it.
      Description: Do the ideas need something more? What completely new thoughts could be applied to the existing ideas? If you have answers to these questions then this section is for you.
      Expected Outcomes: Your proposal must meet the guidelines below. It must:
      Not depend on other participants. There should be minimal impact by other participants disappearing or doing a very bad or very good job.
      Add completely new features not previously stated in ideas.
      Create features that users will want or facilitate new features that will be the groundwork for features that they would want.
      Be suitable for use by most non-profit organization.
      We are not interested in membership subscriptions and any related financial management at this time.
      Justify 350 hours of work.
      Repos to update: Talawa, Talawa-API, Talawa-Admin
      Skills Required: Code stacks related to repos above. See introduction section.
      Depends on Project: N/A
      Project Size: 350 hours (Large)
      Possible Mentors:
      Shannika Jackson (Primary)
      Tyrone Taylor
      Difficulty: Medium
      Impact Definition: Risky/Exploratory
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-palisadoes-foundation/
    idea_list_url: https://developer.palisadoes.org/docs/internships/gsoc/gsoc-ideas


  - organization_id: 160
    organization_name: The Rust Foundation
    no_of_ideas: 21
    ideas_content: |

      Extend annotate-snippets with features required by rustc
      Description
      rustc currently has incomplete support for using annotate-snippets to emit errors, but it doesn't support all the features that rustc's built-in diagnostic rendering does. The goal of this project is to execute the rustc test suite using annotate-snippets, identify missing features or bugs, fix those, and repeat until at feature-parity.
      Expected result
      More of the rustc test suite passes with annotate-snippets.
      Desirable skills
      Knowledge of Rust.
      Project size
      Medium.
      Difficulty
      Medium or hard.
      Mentor
      David Wood (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Compiler team

      ~~~~~~~~~~
      Reproducible builds
      Description
      Recent OSS attacks such as the XZ backdoor have shown the importance of having reproducible builds.
      Currently, the Rust toolchain distributed to Rust developers is not very reproducible. Our source code archives should be reproducible as of this pull request, however making the actual binary artifacts reproducible is a much more difficult effort.
      The goal of this project is to investigate what exactly makes Rust builds not reproducible, and try to resolve as many such issues as possible.
      While the main motivation is to make the Rust toolchain (compiler, standard library, etc.) releases reproducible, any improvements on this front should benefit the reproducibility of all Rust programs.
      See Tracking Issue for Reproducible Build bugs and challenges for a non-exhaustive list of reproducibility challenges.
      Expected result
      Rust builds are more reproducible, ideally the Rust toolchain can be compiled in a reproducible manner.
      Desirable skills
      Knowledge of Rust and ideally also build systems.
      Project size
      Medium.
      Difficulty
      Hard.
      Mentor
      Jakub Beránek (GitHub, Zulip)
      Related links
      Idea discussion
      Prior art in Go

      ~~~~~~~~~~
      Bootstrap of rustc with rustc_codegen_gcc
      Description
      rustc_codegen_gcc used to be able to compile rustc and use the resulting compiler to successfully compile a Hello, World! program. While it can still compile a stage 2 rustc, the resulting compiler cannot compile the standard library anymore.
      The goal of this project would be to fix in rustc_codegen_gcc any issue preventing the resulting compiler to compile a Hello, World! program and the standard library. Those issues are not known, so the participant would need to attempt to do a bootstrap and investigate the issues that arises.
      If time allows, an optional additional goal could be to be able to do a full bootstrap of rustc with rustc_codegen_gcc, meaning fixing even more issues to achieve this result.
      Expected result
      A rustc_codegen_gcc that can compile a stage 2 rustc where the resulting compiler can compile a Hello, World! program using the standard library (also compiled by that resulting compiler).
      An optional additional goal would be: a rustc_codegen_gcc that can do a full bootstrap of the Rust compiler. This means getting a stage 3 rustc that is identical to stage 2.
      Desirable skills
      Good debugging ability. Basic knowledge of:
      Intel x86-64 assembly (for debugging purposes).
      rustc internals, especially the codegen part.
      libgccjit and GCC internals.
      Project size
      Medium-Large depending on the chosen scope.
      Difficulty
      Hard.
      Mentor
      Antoni Boucher (GitHub, Zulip)
      Zulip streams
      Idea discussion
      rustc_codegen_gcc

      ~~~~~~~~~~
      Refactoring of rustc_codegen_ssa to make it more convenient for the GCC codegen
      Description
      rustc_codegen_gcc uses rustc_codegen_ssa and implements the traits in this crate in order to have a codegen that plugs in rustc seamlessly. Since rustc_codegen_ssa was created based on rustc_codegen_llvm, they are somewhat similar, which sometimes makes it awkward for the GCC codegen. Indeed, some hacks were needed to be able to implement the GCC codegen with this API:
      Usage of unsafe transmute: for instance, this or this. Fixing this might require separating Value into RValue and LValue or using Function in place of Value in some places to better fit the GCC API.
      Usage of mappings to workaround the API: for instance, this or this.
      Some other improvement ideas include:
      Separate the aggregate operations (structs, arrays): methods like extract_value are generic over structures and arrays because it's the same operation in LLVM, but it is different operations in GCC, so it might make sense to have multiple methods like extract_field and extract_array_element.
      Remove duplications between rustc_codegen_gcc and rustc_codegen_llvm by moving more stuff into rustc_codegen_ssa. For instance:
      some debuginfo code is exactly the same
      ABI code
      the allocator code
      the dummy output type for inline assembly
      perhaps we could add a set_alignment method in rustc_codegen_ssa that asks the backend to set the alignment and is called in rustc_codegen_ssa in strategic places so that we don't have to worry as much about alignment in the codegens (not sure if this is possible).
      The goal of this project is to improve rustc_codegen_gcc by removing hacks, unnecessary unsafe code and/or code duplication with rustc_codegen_llvm by refactoring rustc_codegen_ssa. It would be important that this refactoring does not result in a performance degradation for rustc_codegen_llvm.
      Expected result
      A rustc_codegen_gcc that contains less hacks, unsafe code and/or code duplication with rustc_codegen_llvm.
      Desirable skills
      Knowledge of Rust and basic knowledge of rustc internals, especially the codegen part.
      Project size
      Small-Medium depending on the chosen scope.
      Difficulty
      Medium.
      Mentor
      Antoni Boucher (GitHub, Zulip)
      Zulip streams
      Idea discussion
      rustc_codegen_gcc

      ~~~~~~~~~~
      ABI/Layout handling for the automatic differentiation feature
      Description
      Over the last year, support for automatic differentiation ('autodiff') was added to the Rust compiler. The autodiff tool which we are using (Enzyme) operates on LLVM-IR, which is the intermediate representation of code, used by LLVM. LLVM is the default backend of the Rust compiler. Unfortunately, two layout related problems limit its usability.
      A) The Rust compiler has a set of ABI optimizations which can improve performance, but make it harder for autodiff to work. An example is the function fn foo(a: f32, b: f32) -> f32, which the compiler might optimize to fn foo(x: i64) -> f32. While this is fine from an LLVM perspective, it makes it hard for Enzyme, the LLVM based autodiff tool. More information about such optimizations can be found here. If a function has a #[rustc_autodiff] attribute, the Rust compiler should simply not perform such optimizations. We don't want to disable these optimizations for all functions, as they are generally beneficial. Multiple examples of function headers which will get handled incorrectly at the moment are listed here.
      B) Enzyme requires good information about the memory layout of types, both to be able to differentiate the code, and to do so efficiently. In order to help Enzyme, we want to lower more Type Information from MIR or even THIR into LLVM-IR metadata, or make better usage of existing debug info. If you are interested in this part and also have some LLVM experience, please have a look at the LLVM website for the related proposal.
      For both A) and B), the online compiler explorer here can be used to trigger both types of bugs, to get a feeling for existing problems.
      Expected result
      The Rust compiler should not perform ABI optimizations on functions with the #[rustc_autodiff] attribute. As a result, #[autodiff(..)] should be able to handle functions with almost arbitrary headers. If a general solution turns out tricky, it is ok to focus on the most common types like those listed in the issue above (e.g. combinations of floats, small arrays/structs/tuples, etc.). We care less about advanced types like those listed here. These changes can't have a performance impact on functions without the #[rustc_autodiff] attribute.
      Newly working testcases should be added to the rust test suite. The rustc_autodiff parsing in the autodiff frontend might need small bugfixes if the new testcases discover additional bugs, but those can also be solved by other contributors.
      Examples for code that currently is not handled correctly can be discussed in the project proposal phase.
      Desirable skills
      Intermediate knowledge of Rust. Familiarity with ABIs is a bonus, but not required.
      Project size
      Medium
      Difficulty
      Medium to hard.
      Mentor
      Manuel Drehwald (GitHub, Zulip)
      Oli (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Automatic differentiation working group


      ~~~~~~~~~~
      Improving parallel frontend
      Description
      Improving compiler performance has always been a focus of the Rust community and one of the main tasks of the compiler team. Parallelization of rust compiler is an important and effective approach. Currently, the backend end (codegen part) of the compiler has been parallelized, which has brought a huge improvement in the performance of the compiler. However, there is still much room for improvement in the parallelization of the rust frontend.
      The most important and valuable work in this area are two aspects:
      A) Diagnosing and fixing deadlock issues caused by the execution order of compiler queries in a multithreaded environment. Queries is a unique design of the Rust compiler, which is used to achieve incremental compilation process. It divides the compiler process into various parts and caches the execution results of each part. However, queries caching dependencies between multiple threads may cause deadlock. Work-stealing, a method used to improve parallelization performance, is the core reason.
      To solve these problems, we need to find the part of the compiler process that causes deadlock through diagnosing coredumps in issues, and adjusting the execution order of this part of code so that there will be no circular dependencies on the query caches between multiple threads. This PR is a good example of solving a deadlock problem.
      B) Improving the performance of the parallel frontend The parallel frontend has implemented parallelization in type checking, MIR borrow checking and other parts of the compiler. However, there is still a lot of room for improvement:
      HIR lowering. Modifying the array structure of tcx.untracked.definitions so that it can be accessed efficiently in multiple threads is likely to be the key.
      Macro expansion. How to deal with the order problem of name resolution during macro expansion is a difficult problem.
      Lexing and/or parsing.
      Achieving the above goals is of big significance to improving the performance of the Rust compiler.
      The project could choose either one of these two areas, or try to tackle both of them together.
      Expected result
      Parallel frontend will not cause deadlock issues. We can ensure usability through UI testing.
      The performance of the compiler will be improved, ideally at least by a couple of percentage points.
      Desirable skills
      Intermediate knowledge of Rust. A basic understanding of the implementation of the compiler process (such as typeck, hir_lowering, macro expansion) would be ideal.
      Project size
      Medium to hard (depending on the chosen scope).
      Difficulty
      Medium to hard.
      Mentor
      Sparrow Li (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Parallel frontend working group
      Parallel frontend project goal

      ~~~~~~~~~~
      C codegen backend for rustc
      Description
      rustc currently has three in-tree codegen backends: LLVM (the default), Cranelift, and GCC. These live at https://github.com/rust-lang/rust/tree/master/compiler, as rustc_codegen_* crates.
      The goal of this project is to add a new experimental rustc_codegen_c backend that could turn Rust's internal representations into C code (i.e. transpile) and optionally invoke a C compiler to build it. This will allow Rust to use benefits of existing C compilers (better platform support, optimizations) in situations where the existing backends cannot be used.
      Expected result
      The minimum viable product is to turn rustc data structures that represent a Rust program into C code, and write the output to the location specified by --out-dir. This involves figuring out how to produce buildable C code from the inputs provided by rustc_codegen_ssa::traits::CodegenBackend.
      A second step is to have rustc invoke a C compiler on these produced files. This should be designed in a pluggable way, such that any C compiler can be dropped in.
      Desirable skills
      Knowledge of Rust and C, basic familiarity with compiler functionality.
      Project size
      Large.
      Difficulty
      Hard.
      Mentor
      Trevor Gross (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Compiler team
      Previous discussion about this topic
      Rust standard library


      ~~~~~~~~~~
      Extend testing of std::arch intrinsics
      Description
      The std::arch module in the standard library provides architecture-specific intrinsic functions, which typically directly map to a single machine instruction.
      These intrinsics are based on the architecture-specific intrinsics in C, which are usually based on a vendor specification and then implemented by C compilers such as Clang or GCC.
      Rust supports thousands of intrinsics and we need to verify that they match the behavior of the equivalent intrinsics in C. A first step towards this has been the intrinsic-test which fuzz tests the ARM (AArch32 and AArch64) intrinsics by generating C and Rust programs which call the intrinsics with random data and then verifying that the output is the same in both programs.
      While this covers the ARM architectures, we have thousands of intrinsics for other architectures (notably x86) which are only lightly tested with manual tests. The goal of this project is to extend intrinsic-test to other architectures: x86, PowerPC, LoongArch, etc.
      Expected result
      By the end of this project intrinsic-test should be able to validate the behavior of intrinsics on multiple architectures. The primary goal is to support x86 since this is the most widely used architecture, but stretch goals could include support for other architectures such as PowerPC, LoongArch, WebAssembly, etc.
      Desirable skills
      Intermediate knowledge of Rust and C. Knowledge of intrinsics or assembly is useful but not required.
      Project size
      Small to Medium.
      Difficulty
      Medium.
      Mentors
      Amanieu d'Antras (GitHub, Zulip)
      Zulip streams
      Idea discussion
      t-libs/stdarch


      ~~~~~~~~~~
      Infrastructure
      Implement merge functionality in bors
      Description
      Various Rust repositories under the rust-lang organization use a merge queue bot (bors) for testing and merging pull requests. Currently, we use a legacy implementation called homu, which is quite buggy and very difficult to maintain, so we would like to get rid of it. We have started the implementation of a new bot called simply bors, which should eventually become the primary method for merging pull requests in the rust-lang/rust repository.
      The bors bot is a GitHub app that responds to user commands and performs various operations on a GitHub repository. Primarily, it creates merge commits and reports test workflow results for them. It can currently perform so-called "try builds", which can be started manually by users on a given PR to check if a subset of CI passed on the PR. However, the most important functionality, actually merging pull requests into the main branch, has not been implemented yet.
      Expected result
      bors can be used to perform pull request merges, including "rollups". In an ideal case, bors will be already usable on the rust-lang/rust repository.
      Desirable skills
      Intermediate knowledge of Rust. Familiarity with GitHub APIs is a bonus.
      Project size
      Medium.
      Difficulty
      Medium.
      Mentors
      Jakub Beránek (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Infra team

      ~~~~~~~~~~
      Improve bootstrap
      Description
      The Rust compiler it bootstrapped using a complex set of scripts and programs generally called just bootstrap. This tooling is constantly changing, and it has accrued a lot of technical debt. It could be improved in many areas, for example:
      Design a new testing infrastructure and write more tests.
      Write documentation.
      Remove unnecessary hacks.
      Expected result
      The bootstrap tooling will have less technical debt, more tests, and better documentation.
      Desirable skills
      Intermediate knowledge of Rust. Knowledge of the Rust compiler bootstrap process is welcome, but not required.
      Project size
      Medium or large.
      Difficulty
      Medium.
      Mentor
      AlbertLarsan68 (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Bootstrap team


      ~~~~~~~~~~
      Port std::arch test suite to rust-lang/rust
      Description
      The std::arch module in the standard library provides architecture-specific intrinsic functions, which typically directly map to a single machine instruction.
      Currently, it lives in its own repository outside the main Rust compiler repository (rustc). The rustc repository includes stdarch only as a submodule, and does not execute its testsuite on the compiler's CI. This sometimes causes contributor friction, because updates to the compiler can break stdarch (and vice versa) and it is not possible to change both the compiler and stdarch at once (in the same pull request).
      stdarch has a comprehensive test suite that tests the intrinsics on several hardware architectures and operating system platforms, and it also includes fuzz tests. It cannot be simply copied over to rustc, because that has its own (much more complex) set of CI workflows. The stdarch testsuite thus has to be adapted to the way workflows are executed in the compiler repository.
      The ultimate goal is to inline stdarch into rustc completely, and archive the stdarch repository. This can be incrementally achieved by the following two steps:
      Investigate the CI (continuous integration) test suite of stdarch, and port as much of it into rustc. This will involve implementing new testing and documentation steps for working with stdarch in the compiler's build system, bootstrap.
      Once a sufficient portion of the test suite has been ported, stdarch should be changed from a submodule to either a git or Josh subtree, so that compiler contributors are able to make changes to stdarch when they modify the compiler. This might involve creating some automation tooling to help with performing regular synchronizations from/to stdarch. See this page for more details.
      Expected result
      The most important parts of the stdarch test suite should be running in the CI of the Rust compiler. Ideally, stdarch should be included as a git/Josh subtree instead of a submodule, or in the best possible scenario moved completely into rust-lang/rust.
      Desirable skills
      Intermediate knowledge of Rust. Experience with GitHub Actions or CI workflows is a benefit.
      Project size
      Small to Medium.
      Difficulty
      Medium.
      Mentors
      Jakub Beránek (GitHub, Zulip)
      Zulip streams
      Idea discussion
      t-libs/stdarch

      ~~~~~~~~~~
      Cargo
      Prototype an alternative architecture for cargo fix
      Description
      Some compiler errors know how to fix the problem and cargo fix is the command for applying those fixes. Currently, cargo fix calls into the APIs that implement cargo check with cargo in a way that allows getting the json messages from rustc and apply them to workspace members. To avoid problems with conflicting or redundant fixes, cargo fix runs rustc for workspace members in serial. As one fix might lead to another, cargo fix runs rustc for each workspace member in a loop until a fixed point is reached. This can be very slow for large workspaces.
      We want to explore an alternative architecture where cargo fix runs the cargo check command in a loop, processing the json messages, until a fixed point is reached.
      Benefits
      Always runs in parallel
      May make it easier to extend the behavior, like with an interactive mode
      Downsides
      Might have issues with files owned by multiple packages or even multiple build targets
      This can leverage existing CLI and crate APIs of Cargo and can be developed as a third-party command.
      See cargo#13214 for more details.
      Expected result
      A third-party command as described above
      A comparison of performance across representative crates
      An analysis of corner the behavior with the described corner cases
      Desirable skills
      Intermediate knowledge of Rust.
      Project size
      Medium
      Difficulty
      Medium.
      Mentor
      Ed Page (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Cargo team

      ~~~~~~~~~~
      Prototype Cargo plumbing commands
      Description
      Cargo is a high-level, opinionated command. Instead of trying to directly support every use case, we want to explore exposing the building blocks of the high-level commands as "plumbing" commands that people can use programmatically to compose together to create custom Cargo behavior.
      This can be prototyped outside of the Cargo code base, using the Cargo API.
      See the Project Goal for more details.
      Expected result
      Ideal: a performant cargo porcelain check command that calls out to individual cargo plumbing <name> commands to implement its functionality.
      Depending on the size the participant takes on and their experience, this may be out of reach. The priorities are:
      A shell of cargo porcelain check
      Individual commands until cargo porcelain check is functional
      Performance
      Desirable skills
      Intermediate knowledge of Rust.
      Project size
      Scaleable
      Difficulty
      Medium.
      Mentor
      Ed Page (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Cargo team

      ~~~~~~~~~~
      Move cargo shell completions to Rust
      Description
      Cargo maintains Bash and Zsh completions, but they are duplicated and limited in features.
      A previous GSoC participant added unstable support for completions in Cargo itself, so we can have a single implementation with per-shell skins (rust-lang/cargo#6645).
      Final project report
      GSoC project annotation
      Project discussion on Zulip
      There are many more arguments that need custom completers as well as polish in the completion system itself before this can be stabilized.
      See
      Clap's tracking issue
      Cargo's tracking issue
      Expected result
      Ideal:
      A report to clap maintainers on the state of the unstable completions and why its ready for stabilization
      A report to cargo maintainers on the state of the unstable completions and why its ready for stabilization
      Desirable skills
      Intermediate knowledge of Rust. Shell familiarity is a bonus.
      Project size
      Medium.
      Difficulty
      Medium.
      Mentor
      Idea discussion
      Ed Page (GitHub, Zulip)

      ~~~~~~~~~~
      Build script delegation
      Description
      When developers need to extend how Cargo builds their package, they can write a build script. This gives users quite a bit of flexibility but
      Allows running arbitrary code on the users system, requiring extra auditing
      Needs to be compiled and run before the relevant package can be built
      They are all-or-nothing, requiring users to do extra checks to avoid running expensive logic
      They run counter to the principles of third-party build tools that try to mimic Cargo
      A developer could make their build script a thin wrapper around a library (e.g. shadow-rs) but a build script still exists to be audited (even if its small) and each individual wrapper build script must be compiled and linked. This is still opaque to third-party build tools.
      Leveraging an unstable feature, artifact dependencies, we could allow a developer to say that one or more dependencies should be run as build scripts, passing parameters to them.
      This project would add unstable support for build script delegation that can then be evaluated for proposing as an RFC for approval.
      See the proposal for more details.
      Expected result
      Milestones
      An unstable feature for multiple build scripts
      An unstable feature for passing parameters to build scripts from Cargo.toml, built on the above
      An unstable feature for build script delegation, built on the above two
      Bonus: preparation work to stabilize a subset of artifact dependencies.
      Desirable skills
      Intermediate knowledge of Rust, especially experience with writing build scripts.
      Project size
      Large.
      Difficulty
      Medium.
      Mentor
      Idea discussion
      Ed Page (GitHub, Zulip)


      ~~~~~~~~~~
      rust-analyzer
      Implement a new proc-macro server RPC API
      Description
      Today, rust-analyzer (and RustRover) expands proc-macros by spawning a separate proc-macro server process that loads and executes the proc-macro dynamic libraries. They communicate to this process via a JSON RPC interface that has not been given much thought when it was implemented, now starting to show its limitations.
      The goal is to replace this current implementation entirely in favor of a more performant format that also supports the more complicated needs of the proc-macro API, outlined in rust-lang/rust-analyzer#19205.
      Expected result
      There exists a new proc-macro server that is more efficient and allows for implementing the remaining proc-macro API. Ideally, it should be integrated within rust-analyzer.
      Desirable skills
      Intermediate knowledge of Rust.
      Project size
      Medium.
      Difficulty
      Medium.
      Mentor
      Lukas Wirth (GitHub, Zulip)
      Zulip streams
      Idea discussion
      rust-analyzer team
      Crate ecosystem

      ~~~~~~~~~~
      Modernize the libc crate
      Description
      The libc crate is one of the oldest crates of the Rust ecosystem, long predating Rust 1.0. Additionally, it is one of the most widely used crates in the ecosystem (#4 most downloaded on crates.io). This combinations means that the current version of the libc crate (v0.2) is very conservative with breaking changes has accumulated a list of things to do in a 1.0 release. Additionally, some of the infrastructure for lib is rather outdated.
      Most of the changes required for 1.0 are under the 1.0 milestone. Some of these come from the evolution of the underlying platforms, some come from a desire to use newer language features, while others are simple mistakes that we cannot correct without breaking existing code.
      The crate used for testing libc (ctest) uses an old syntax parser that cannot support modern Rust, so some of the changes will require rewriting ctest to use a newer parser (e.g. syn). This upgrade is tracked at rust-lang/libc#4289.
      The goal of this project is to prepare and release the next major version of the libc crate.
      Expected result
      The libc crate is cleaned up and modernized, and released as version 0.3.
      Desirable skills
      Intermediate knowledge of Rust.
      Project size
      Medium.
      Difficulty
      Medium.
      Mentor
      Trevor Gross (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Library team

      ~~~~~~~~~~
      Add more lints to cargo-semver-checks
      Description
      cargo-semver-checks is a linter for semantic versioning. It ensures that Rust crates adhere to semantic versioning by looking for breaking changes in APIs.
      It can currently catch ~120 different kinds of breaking changes, meaning there are hundreds of kinds of breaking changes it still cannot catch! The goal of this project is to extend its abilities, so that it can catch and prevent more breaking changes, by:
      adding more lints, which are expressed as queries over a database-like schema (playground)
      extending the schema, so more Rust functionality is made available for linting
      Expected result
      cargo-semver-checks will contain new lints, together with test cases that both ensure the lint triggers when expected and does not trigger in situations where it shouldn't (AKA false-positives).
      Desirable skills
      Intermediate knowledge of Rust. Familiarity with databases, query engines, or query language design is welcome but not required.
      Project size
      Medium or large, depends on how many lints will be implemented. The more lints, the better!
      Difficulty
      Medium to high, depends on the choice of implemented lints or schema extensions.
      Mentor
      Predrag Gruevski (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Related Links
      Playground where you can try querying Rust data
      GitHub issues describing not-yet-implemented lints
      Opportunities to add new schema, enabling new lints
      Query engine adapter


      ~~~~~~~~~~
      Make cargo-semver-checks run faster
      Description
      As more lints get added to cargo-semver-checks, its runtime grows longer. As a result, users' iteration loops and CI pipelines take longer as well, degrading the overall experience of using the tool.
      Figure out ways to speed up cargo-semver-checks, and find good ways to deploy them without degrading the maintainability of the codebase!
      Expected result
      The wall-clock runtime of running cargo-semver-checks on a large Rust crate gets cut by 50-80%, while still running the same lints as before.
      Desirable skills
      Interest in and at least a bit of experience with performance engineering. Understanding of how to apply techniques like:
      profiling and benchmarking
      parallel programming (e.g. with rayon)
      building and applying indexes (in the database sense)
      Strong attention to detail. Willingness to learn quickly and perform lots of experiments, even though many of them may prove to be dead ends. Discipline and thoughtfulness when writing and testing code, to ensure that code changes are not merely fast but also maintainable.
      Project size
      Ideally large, to have the biggest possible positive performance impact.
      Difficulty
      Medium to high. See the "desirable skills" section above.
      Mentor
      Predrag Gruevski (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Related Links
      Playground where you can try querying Rust data
      Past optimization work: Speeding up Rust semver-checking by over 2000x
      Conference talk: How Database Tricks Sped up Rust Linting Over 2000x
      Query engine adapter, where many of the optimizations may be deployed
      
      ~~~~~~~~~~
      
      Enable witness generation in cargo-semver-checks
      Description
      When cargo-semver-checks reports a breaking change, it in principle has seen enough information for the breakage to be reproduced with an example program: a witness program. Witness programs are valuable as they confirm that the suspected breakage did indeed happen, and is not a false-positive.
      Expected result
      Automatic witness generation is something we've explored, but we've only scratched the surface at implementing it so far. The goal of this project would be to take it the rest of the way: enable cargo-semver-checks to (with the user's opt-in) generate witness programs for each lint, verify that they indeed demonstrate the detected breakage, and inform the user appropriately of the breakage and the manner in which it was confirmed. If a witness program fails to reproduce breakage flagged by one of our lints, we've found a bug — the tool should then prepare a diagnostic info packet and offer to help the user open an auto-populated GitHub issue.
      Stretch goal: having implemented witness generation, run another study of SemVer compliance in the Rust ecosystem, similar to the study we completed in 2023. The new study would cover many more kinds of breaking changes, since cargo-semver-checks today has 2.5x times more lints than it did back then. It would also reveal any new false-positive issues, crashes, or other regressions that may have snuck into the tool in the intervening years.
      Desirable skills
      Intermediate knowledge of Rust. Interest in building dev tools, and empathy for user needs so we can design the best possible user experience. Familiarity with databases, query engines, or programming language design is welcome but not required.
      Project size
      Large
      Difficulty
      Medium
      Mentor
      Predrag Gruevski (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Related Links
      Playground where you can try querying Rust data
      Use of witness programs to verify breaking change lints
      
      ~~~~~~~~~~
      
      Wild linker with test suites from other linkers
      Description
      The Wild linker is a project to build a very fast linker in Rust that has incremental linking and hot reload capabilities.
      It currently works well enough to link itself, the Rust compiler, clang (provided you use the right compiler flags) and a few other things. However, there are various features and combinations of flags that don’t yet work correctly. Furthermore, we have a pretty incomplete picture of what we don’t support.
      The proposed project is to run the test suite of other linkers with Wild as the linker being tested, then for each failure, determine what the problem is. It’s expected that many failures will have the same root cause.
      Expected result
      Write a program, ideally in Rust, that runs the test suite of some other linker. Mold’s test suite is pretty easy to run with Wild, so that’s probably a good default choice. The Rust program should emit a CSV file with one row per test, whether the test passes or fails and if it fails, an attempt to identify the cause based on errors / warnings emitted by Wild.
      For tests where Wild doesn’t currently emit any error or warning that is related to the cause of the test failure, attempt to make it do so. Some of the tests might fail for reasons that are hard to identify. It’s OK to just leave these as uncategorised. Where tests fail due to bugs or differences in behaviour of Wild, automatic classification likely isn’t practical. A one-off classification of these would be beneficial.
      If time permits, pick something achievable that seems like an important feature / bug to support / fix and implement / fix it.
      Desirable skills
      Knowledge of Rust. Any existing knowledge of low-level details like assembly or the ELF binary format is useful, but can potentially be learned as we go.
      Project size
      Small to large depending on chosen scope.
      Difficulty
      Some of the work is medium. Diagnosing and / or fixing failures is often pretty hard.
      Mentor
      David Lattimore (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Further resources
      Wild linker
      Blog posts, most of which are about Wild
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-rust-foundation/
    idea_list_url: https://github.com/rust-lang/google-summer-of-code
  

  - organization_id: 161
    organization_name: The Tor Project
    no_of_ideas: 3
    ideas_content: |
   
      1. Project "Rewrite metrics-lib in Rust"
      Mentors:
      Hiro
      Sarthik
      Hours required: 350 hours
      Skills required: Rust + some Java
      Expected outcome: A library to process Tor network documents in Rust is available.
      Difficulty: medium
      Background
      Tor Metrics Library is a Java library that fetches and parses Tor descriptors.
      Metrics lib provides a Java API for processing Tor network data from the CollecTor service for statistical analysis and for building services and applications.
      Proposal
      The metrics pipeline is being restructured and is slowly moving away from a mostly JAVA codebase to a rust and python tool belt.
      This project would involve a complete re-implementation of the Tor metrics library in Rust.
      Metrics-lib is a JAVA based API that is used to parse and validate Tor network documents. The rust rewrite should provide the same parsing and validation functionalities provided by metrics-lib and in addition allow exporting of the documents in some external storage, like parquet files to be saved into object storage or a table on a postgresql database.
      Resources:
      https://gitlab.torproject.org/tpo/network-health/metrics/library
      https://metrics.torproject.org/metrics-lib.html
      https://gitlab.torproject.org/tpo/network-health/metrics/descriptorParser/
      https://gitlab.torproject.org/tpo/network-health/team/-/wikis/metrics/development/home
      
      
      ~~~~~~~~~~
      2. Project "Onion Service Support Tooling for Arti"
      Mentors:
      Gabi
      Wesley
      Hours required: 175 hours
      Skills required: Knowledge of Rust (experience with async programming is a plus); ability to use Git
      Expected outcome: the arti CLI is extended with more commands for key and state management; constructive discussions leading to changes to, or recommendations for, Arti's APIs and documentation.
      Difficulty: Medium
      Problem
      Arti has two state management subcommands, arti hss and arti hsc, for managing the state of onion services and onion service clients, respectively. These commands are currently very limited in functionality, and do not support many of the features onion service clients and operators will require.
      Proposal
      This project is about contributing to the tooling onion service clients and operators will need for managing the on-disk state and keys of their Arti onion services. It will involve extending the existing state management commands, as well as potentially adding new ones, and contributing to Arti's APIs and documentation.
      For example, the extra functionality we need includes but is not limited to:
      a subcommand for listing keys and certificates from the configured keystores
      a subcommand for performing consistency, validity, and integrity checks on the specified stores (this might also take an optional --fix flag, to fix the detected issues, if possible)
      an arti hss destroy-and-recreate subcommand, for generating a new identity (set of keys) for an existing onion service (this command will replace all the keys and state of the service)
      an arti hss destroy subcommand, for removing the persistent state and all the keys of a onion service.
      miscellaneous low-level "plumbing" subcommands, which deal with individual files from the keystore and state directories (for example. arti keys-raw remove-by-path)
      a C Tor to Arti key migration tool, which will enable onion service operators to seamlessly migrate from C Tor to Arti
      field-formatted output to be easily parseable by other programs (maybe enabled by a special flag) (when/if makes sense). Similar (but maybe better) functionality as gpg(1) --with-colons and many other CLI tools
      man pages for each CLI or subcommand
      A successful project will involve implementing some, or all, of the functionality described above.
      Resources
      The Arti repository: https://gitlab.torproject.org/tpo/core/arti
      About onion services: https://onionservices.torproject.org/technology/
      Table comparing the C Tor and Arti onion service implementations: https://onionservices.torproject.org/dev/implementations/
      The original state management CLI implementation plan: https://gitlab.torproject.org/tpo/core/arti/-/blob/main/doc/dev/notes/state-management-cli.md
      
      
      ~~~~~~~~~~
      
      3. Relay to relay connectivity in the Tor network
      mentors:
      juga
      gk
      hours: 175h
      skills:
      rust
      data analysis
      graph theory
      graph databases
      expected outcome:
      updated and streamlined partitioning detection tool (erpc)
      have a module to analyze the partitions in the Tor network and visualize it
      difficulty: medium
      Problem
      In an ideal world, any Tor relay would be able to reach any other Tor relay when trying to build paths through the network, as partitioning in the Tor network is bad for Tor's anonymity guarantees. During GSoC 2023 erpc got built, which is a tool implemented in Rust to check for partitions in the Tor network by building two hop circuits between all the relays.
      It stores the results in a graph database (neo4j). The graph vertices are the fingerprints of the relay and the edges are the relay pairs involved in the circuit. Also stored is the message obtained building the circuit and the timestamp.
      This data needs to be analyzed to find partitions in the Tor network and present them in a meaningful way.
      Proposal
      This project would involve updating and optimizing erpc to keep our dataset manageable. Additionally, it needs research into which algorithms are most suitable to find the partitions in the Tor network. Since the network is currently stored as a directed graph, we can apply community detection and clustering algorithms. Neo4j already offers several clustering algorithms within its Graph Data Science (GDS) library.
      The project would also involve writing the code to apply the partitioning algorithms and present the results. For example, a first approach could be listing the relay fingerprints and the number of other relays they're able to build a circuit to. This can be further improved in several ways, for instance by adding properties to the vertices like country, ASN, flags, family, etc. This would allow it to analyze separately the cyclic non-exits subgraphs and the acyclic exits subgraphs. It'd also be possible to detect whether some subgraphs are not connected because of families, ASN or other reasons.
      During the analysis and implementation it would be helpful to visualize parts of the graph, therefore the project would also involve to select some open source graph visualization tool and also implement the code to automaticaly analyze and visualize subgraphs.
      Resources:
      https://gitlab.torproject.org/tpo/team/-/wikis/gsoc-previous-years#1-relay-to-relay-connectivity-in-the-tor-network
      https://en.wikipedia.org/wiki/Graph_partition
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-tor-project/
    idea_list_url: https://gitlab.torproject.org/tpo/team/-/wikis/GSoC

  - organization_id: 162
    organization_name: The ns-3 Network Simulator Project
    no_of_ideas: 16
    ideas_content: |
     
      Small sized projects (90 hours)
      NTN example for 5G NR
      Mentors: Gabriel Ferreira, Amir Ashtari Gargari, Biljana Bojovic and Katerina Koutlia
      The objective of this project is the creation of a 5G NR example for the NTN use case. The example should provide a typical NTN topology, with a set of cells served by Low-Earth Orbit (LEO) satellites (e.g. Starlink, Kuiper), hence maybe an NTN topology helper could be created as a part of this project. The example should use the ns-3 3GPP NTN channel model. If handover is already functional, satellites should move at orbital speeds in their orbital planes, handing off users to the upcoming cell with LOS. We could explore scenarios (dense urban and urban).
      For starters, we would suggest adding the CTTC 5G-LENA (nr module) to ns-3, in the typical way (as a module in the contrib/ directory), and building and running the examples. Documentation is available from here: https://5g-lena.cttc.es/. There is an overview tutorial video available here: https://acmse.net/2021/tutorials-offered/#tut-work03. That is the background information.
      Required Experience: C++ programming, understanding of 5G NR, LTE, and wireless networks
      Interests: 5G NR simulations
      Difficulty: Medium.
      Patch requirement: See the description. You can also consider some of the nr good to start issues. Or, you can start writing some APIs for the selected project proposal. Also, if you have some previous MRs to ns-3 or the nr module, you can contact us to check whether it is enough for the patch requirement.
      
      

      ~~~~~~~~~~
      
      Upgrade the AQM Evaluation Suite for ns-3
      Mentors: Mohit P. Tahiliani
      AQM (Active Queue Management) evaluation suite for ns-3 helps to quickly study the performance of AQM algorithms based on the guidelines mentioned in RFC 7928. This suite automates simulation setup, topology creation, traffic generation, program execution, results collection and their graphical representation using ns-3 based on the scenarios mentioned in RFC 7928. It was designed and developed in 2017 and actively maintained till 2019. In the past few years, the traffic control model in ns-3 has grown significantly in terms of supporting state-of-the-art packet scheduling and AQM algorithms, and the ns-3 build system has changed from waf to cmake. This project has four main goals: (1) upgrade the AQM Evaluation Suite according to the latest ns-3-dev, (2) enable support for latest packet scheduling, AQM algorithms and ECN functionality (3) update the examples in AQM Evaluation Suite to better suit the needs of researchers working in this area, and (4) make AQM Evaluation Suite available on the ns-3 app store.
      Required Experience: Familiarity with AQM and C++ programming.
      Bonus Experience: Familiarity with traffic control model in ns-3.
      Interests: Packet Scheduling algorithms, AQM algorithms and ECN.
      Difficulty: Medium.
      Recommended Reading:
      AQM Evaluation Suite [Paper] [Implementation]
      RFC 7928
      Traffic Control Model in ns-3
      Patch requirement: Create a pull request to handle the case when an incorrect Scenario name or number is passed via command line.
      
      small size : 90 hours
      ~~~~~~~~~~
      Implementation of Alternative Backoff with ECN (ABE)
      Mentors: Mohit P. Tahiliani
      Alternative Backoff with ECN (ABE) is a newly proposed feature to enhance the performance of TCP when ECN is deployed. The main idea of ABE is to make the TCP sender respond differently to an ECN signal than it does for a packet loss. This project intends to implement, test and document this feature in ns-3. Additonally, an example program must be developed to demonstrate the usage of ABE in ns-3.
      Required Experience: Familiarity with ECN and C++ programming.
      Bonus Experience: Familiarity with traffic control model in ns-3.
      Interests: Packet Scheduling algorithms, AQM algorithms and ECN.
      Difficulty: Medium.
      Recommended Reading:
      Alternative Backoff with ECN [RFC 8511] [Paper]
      ECN support in ns-3
      Traffic Control Model in ns-3

      ~~~~~~~~~~



      Medium sized projects (175 hours)
      ICMP socket and generate/handle ICMP messages (host/net unreachable)
      Mentors: Tommaso Pecorella, Manoj K. Rana.
      The current IP stack in ns-3 does not provide an ICMP socket, and in order to send or receive ICMP packets (either IPV4 or IPv6) it is necessary to use a "RAW" socket. This approach works, but has a severe limitation: it does not work if the packet has been fragmented. Moreover, using a RAW socket is far more complex than a normal socket, as the receiver application must filter the incoming packets according to specific rules.
      The goal of the idea is to create, test, and document an ICMP socket that works both for IPv4 and IPv6, mimicking the Linux sockets socket(AF_INET, SOCK_DGRAM, IPPROTO_ICMP) and socket(AF_INET6, SOCK_DGRAM, IPPROTO_ICMPV6). Note that the choice of SOCK_DGRAM or SOCK_RAW (i.e., with or without the IP header) is totally left to the proposal.
      The most important point of the implementation should be code duplicate minimization, in order to have the minimize maintenance efforts.
      Once the sockets are in place, beside the "normal" tests, it will be necessary to modify the code that is actually made obsolete by the new sockets, e.g.:
      IPv6 ICMP messages (RA, RS, NA, NS, etc.),
      IPv4 ICMP messages,
      ICMP Echo and ICMPv6 Echo messages.
      and to handle properly ICMP error messages like Destination Unreachable in the Ping application.
      Required Experience: Fundamentals of IPv4 and IPv6 sockets, C++ programming.
      Interests: Sockets and API interface implementation.
      Difficulty: Medium.
      Recommended reading:
      Linux socket
      Raw Sockets and ICMP, Srinidhi Varadarajan
      Issue #810
      Possible tasks to fulfill the patch requirement:
      Submit a patch to fix Issue #809

      ~~~~~~~~~~
      6LoWPAN mesh-under routing enhancements
      Mentors: Tommaso Pecorella, [TBD].
      The 6LoWPAN module offers a simple option to implement a multi-hop topology by using a contolled flooding. However, the implemented controlled flooding is very simple, and is not efficient in complex networks. This is mainly due to the lack of congestion control, or rather its naive implementation. A better approach would be to borrow some concepts and ideas from RFC 7731 Multicast Protocol for Low-Power and Lossy Networks (MPL), so that messages do not generate network congestions when the network is large.
      The candidate should outline what parts of code are going to be affected, and how they can be enhanced thanks to RFC 7731.
      Required Experience: Fundamentals of IPv6 addressing, C++ programming.
      Bonus Experience: Familiarity with mesh routing and 6LoWPAN ns-3
      Interests: IPv6 mesh routing
      Difficulty: Easy.
      Recommended reading:
      Mesh-under in ns-3 6LoWPAN
      RFC 7731
      Possible tasks to fulfill the patch requirement:
      TBD

      medium size : 175 hours

      ~~~~~~~~~~
      6LoWPAN neighbor discovery protocol
      Mentors: Tommaso Pecorella, [TBD].
      The 6LoWPAN-ND (RFCs 4944, 6775, and 8505) is a replacement for IPv6 DAD and NDP for 6LoWPAN networks, and it is important to ensure address uniquness across a network that can potentially use different MAC/PHY layers.
      There is a model for 6LoWPAN-ND, but it still not merged in the main ns-3 branch. The goal is to cleanup the implementation, remove an actual limitation due to a questionble assumption, and to add the support for multi-hop operations (EDAR and EDAC messages).
      The candidate should outline in the proposal the parts of the code should be modified, and how. The repository for 6LoWPAN-ND is necessary, and the link will be shared upon request.
      Required Experience: Fundamentals of IPv6 addressing, C++ programming.
      Bonus Experience: Familiarity with 6LoWPAN and 6LoWPAN-ND
      Interests: IPv6 and IoT networks
      Difficulty: Easy.
      Recommended reading:
      RFC 8505
      RFC 6775
      RFC 4944
      Possible tasks to fulfil the patch requirement:
      Patch the actual 6LoWPAN-ND to remove the limitation about concurrent address registrations.
      
      medium size : 175 hours

      ~~~~~~~~~~
      
      Improving 5G NR module usability through helpers
      Mentors: Biljana Bojovic,Gabriel Ferreira, Katerina Koutlia and Amir Ashtari Gargari
      This project would be focused on improving the usability of the 5G nr module by enabling new helper support. The new helpers should allow for simplifying the setup of NR applications, XR applications, scenarios, the management of the configuration of many parameters of the scenario, etc. All the NR examples should be updated to make use of these new helpers. The use of such helpers would help reduce significantly the code duplication in 5G NR examples.
      For starters, we would suggest adding the CTTC 5G-LENA (nr module) to ns-3, in the typical way (as a module in the contrib/ directory), and building and running the examples. Documentation is available from here: https://5g-lena.cttc.es/. There is an overview tutorial video available here: https://acmse.net/2021/tutorials-offered/#tut-work03. That is the background information.
      Required Experience: C++ programming, understanding of 5G NR, LTE, and wireless networks
      Interests: 5G NR simulations
      Difficulty: Medium.
      Patch requirement: See the description. You can also consider some of the nr good to start issues. Or, you can start writing some APIs for the selected project proposal. Also, if you have some previous MRs to ns-3 or the nr module, you can contact us to check whether it is enough for the patch requirement.
      medium size : 175 hours

      ~~~~~~~~~~
      
      Enabling 5G NR examples visualization
      Mentors: Amir Ashtari Gargari, Gabriel Ferreira, Biljana Bojovic and Katerina Koutlia
      The main idea of this project is to allow easier visualization of 5G NR examples by integrating the NR module with some ns-3 visualization tools like NetAnim, or by implementing a kind of web-based visualization, e.g., through Jupyter notebook. The new feature should allow the visualization of already existing traces, visualization of topology, or even some new relevant simulation aspects could be considered. The idea is that users better understand how the metrics collection works, and how changing parameters can affect simulation results. In this project, we are open to other ideas on how to implement visualizations.
      For starters, we would suggest adding the CTTC 5G-LENA (nr module) to ns-3, in the typical way (as a module in the contrib/ directory), then building and running the examples. After getting used to C++, then proceed to use the Python bindings, as described by the documentation: https://www.nsnam.org/docs/manual/html/python.html#using-the-bindings-from-the-ns-3-source. Documentation is available here: https://5g-lena.cttc.es/. There is an overview tutorial video available here: https://acmse.net/2021/tutorials-offered/#tut-work03. That is the background information. For more specific guidelines, please view this Google document.
      Required Experience: C++ and Python programming, understanding of 5G NR, LTE, and wireless networks
      Interests: 5G NR simulations
      Difficulty: Medium.
      Patch requirement: See the description. You can also consider some of the nr good to start issues. Or, you can start writing some APIs for the selected project proposal. Also, if you have some previous MRs to ns-3 or the nr module, you can contact us to check whether it is enough for the patch requirement.
      
      medium size : 175 hours

      ~~~~~~~~~~
      Linux-like Loss Detection Techniques for ns-3 TCP
      Mentors: Mohit P. Tahiliani
      Forward Acknowledgement (FACK), Duplicate Selective Acknowledgement (DSACK), and Recent Acknowledgement (RACK) Tail Loss Probe (TLP) are the loss detection techniques implemented in the Linux kernel. These techniques have been already implemented for ns-3 TCP but their code is not yet merged into the mainline. This project has four main goals: (1) update the implementation of these techniques according to the latest ns-3-dev, (2) develop a framework to test the functionality of these techniques, (3) develop example program(s) to demonstrate the usage of these techniques in ns-3 and (4) merge these techniques in the mainline of ns-3.
      Required Experience: Familiarity with TCP and C++ programming.
      Bonus Experience: Familiarity with TCP implementation in Linux kernel.
      Interests: TCP packet loss detection techniques.
      Difficulty: Medium to Hard.
      Recommended Reading:
      Forward Acknowledgement (FACK) [Paper] [Implementation]
      Duplicate Selective Acknowledgment (DSACK) [RFC 2883] [Implementation]
      RACK-TLP [RFC 8985] [Implementation]

      medium size : 175 hours

      ~~~~~~~~~~
      AODVv2 Protocol enhancements
      Mentors: Tommaso Pecorella, [TBD].
      ns-3 contains models for proactive (DSDV and OLSR) and reactive (AODV and DSR) ad hoc routing protocols. AODVv2 is currently an IETF draft, and its implementation in ns-3 is ongoing. This project aims at enhancing the AODVv2 model for ns-3.
      In particular the project should address the following points: 1) AODVv2 performances, 2) AODV address compression, 3) "external" network routing support, 4) general model validation against the latest draft. Collaboration with the draft authors is also highly suggested.
      Required Experience: Fundamentals of IPv6 addressing, C++ programming.
      Bonus Experience: Familiarity with AODV implementations in ns-3 and AODVv2
      Interests: Ad hoc routing
      Difficulty: Medium.
      Recommended reading:
      IPv6 model in ns-3
      AODV model in ns-3
      Ad Hoc On-demand Distance Vector Version 2 (AODVv2) Routing
      Possible tasks to fulfill the patch requirement:
      Issue #368 - aodv: aodv parameters can be set to "impossible" values
      
      
      ~~~~~~~~~~
      Large projects (350 hours)
      IPv6 global routing
      Mentors: Tommaso Pecorella, [TBD].
      Creating a complex topology can be a problem, and sometimes the user do not want to be (also) concerned about setting up dynamic routing protocols (e.g., RIP, RIPng). For IPv4, ns-3 provides two alternatives: GlobalRouting, and NixRouting, which just "do the trick" - they simply fill the routing tables in intermediate nodes, GlobalRouting using an approach similar to OSPF, NixRouting by leveraging the "abstract" knowledge of the network. Neither actually use any message between the nodes, so they also reduce the network overhead - something that is useful in many cases.
      The problem is that GlobalRouting don't work for IPv6 (NixRouting was migrated to IPv6 recently), and that's a huge limitation. The goal of the project is to fix that limitation. Note that the project must cope with different IPv6 address kinds (link-local, global, scoped multicast, etc.).
      The most important point of the implementation should be code duplicate minimization, in order to have the minimize maintenance efforts. The proposer is advised to check the approach used for NixRouting, as it might be a starting point.
      Required Experience: Fundamentals of IPv6 addressing, C++ programming.
      Bonus Experience: Familiarity with GlobalRouting implementations in ns-3
      Interests: IPv6 routing
      Difficulty: Medium.
      Recommended reading:
      IPv6 model in ns-3
      GlobalRouting model in ns-3
      Possible tasks to fulfill the patch requirement:
      Add a function to print the path that a packet will use (according to Ipv4GlobalRouting), i.e., given source and destination IP print the IP addresses of the nodes that Ipv4GlobalRouting will use.
      
      ~~~~~~~~~~
      Mesh Link Establishment (MLE) protocol
      Mentors: Tommaso Pecorella, TBD.
      The Mesh Link Establishment (MLE) is a proposed IETF protocol for establishing and configuring secure radio links in IoT networks. It was originally proposed for IEEE 802.15.4, and the IETF draft seems to be not progressing. However, MLE is being used in Thread, and it can be useful to implement it.
      The goal of the project is to study the differences between the IETF version of MLE and the one being used in Thread, and propose an implementation that complies with either, or both.
      Required Experience: Fundamentals of IPv4 and IPv6 sockets, C++ programming.
      Interests: Sockets and API interface implementation.
      Difficulty: Hard.
      Recommended reading:
      MLE draft
      Thread primer
      Thread specifications
      Possible tasks to fulfill the patch requirement:
      TBD, contact the mentors if interested.

      large size : 350 hours


      ~~~~~~~~~~
      Lr-WPAN (IEEE 802.15.4) preamble detection support
      Mentors: Tommaso Pecorella, Alberto Gallegos Ramonet.
      A preamble is a series of defined bits that signal the data transmission between two or more devices. The current Lr-WPAN module takes into consideration the preamble transmission time but it does not support preamble detection (hence there is no chance of detection failure). Implementing preamble detection would have the added benefit of adding RSSI support to the Lr-WPAN module which itself has many added benefits.
      This project touches on some core PHY functions of the Lr-WPAN module (the detection of packets). Unlike similar ns-3 modules, Lr-WPAN is relatively simple, therefore, it is a good opportunity to learn about Lr-WPAN and how PHYs are handled in ns-3.
      As usual, reduction of code duplicity and a flexible scalable design is desired (e.g. Allow the inclusion of different preambles in the future).
      Required Experience: Basic understanding of IEEE 802.15.4, C++ programming.
      Bonus Experience: PHY process familiarity, Familiarity with ns-3's Lr-WPAN
      Interests: Lr-WPAN, MAC and PHY designs
      Difficulty: Medium.
      Recommended reading:
      IEEE 802.15.4-2006
      IEEE 802.15.4-2015
      ns-3 lr-wpan module
      Possible tasks to fulfill the patch requirement:
      TBD, contact the mentors if interested.


      large size : 350 hours


      ~~~~~~~~~~
      5G NR module integration with ns-3-ai
      Mentors: Katerina Koutlia, Gabriel Ferreira, Amir Ashtari Gargari and Biljana Bojovic
      The objective of this project is to integrate the ns-3 5G NR module with ns-3-ai. In GSoC 2024 we had a project in which 5G NR was integrated with ns-3 gym. While ns-3 gym is a popular ns-3 module for AI, it is limited to the application of reinforcement learning techniques in networking research. On the other hand, ns-3-ai module provides a more general solution that enables the data interaction between ns-3 and other Python-based AI frameworks, like Tensorflow C++ APIs and PyTorch C++ APIs, which opens the door to use different machine learning-based techniques in 5G NR models. The correct functioning of the integration should be tested, and documented, and a fully working example using ns-3-ai should be provided. The contributor can propose a use-case scenario for matching learning. One option is to use it for MAC scheduling, but it could be used for other 5G related research problems, and the contributor is encouraged to propose the use case of his/her interest.
      For starters, we would suggest adding the CTTC 5G-LENA (nr module) to ns-3, in the typical way (as a module in the contrib/ directory), and building and running the examples. Documentation is available from here: https://5g-lena.cttc.es/. There is an overview tutorial video available here: https://acmse.net/2021/tutorials-offered/#tut-work03. That is the background information. For more specific guidelines, please view this Google document.
      Required Experience: C++ programming, understanding of 5G NR, LTE, and wireless networks
      Interests: 5G NR simulations
      Difficulty: Medium.
      Patch requirement: See the description. You can also consider some of the nr good to start issues. Or, you can start writing some APIs for the selected project proposal. Also, if you have some previous MRs to ns-3 or the nr module, you can contact us to check whether it is enough for the patch requirement.
      
      
      large size : 350 hours


      ~~~~~~~~~~
      Linux-like CAKE queue discipline for ns-3
      Mentors: Mohit P. Tahiliani
      Common Applications Kept Enhanced (CAKE) is the most recent queue discipline added in Linux 4.19. It is a comprehensive queue management framework targeted for home Internet gateways, and integrates the following four components: bandwidth shaping, a new Active Queue Management (AQM) algorithm called COBALT (CoDel BLUE Alternate), handling Differentiated Services (DiffServ) and TCP ACK filtering. The main tasks in this project include: implementation, testing and documentation of individual components of CAKE in ns-3, followed by the integration of these components to form CAKE queue discipline in ns-3.
      Required Experience: Familiarity with queue disciplines, TCP and C++ programming.
      Bonus Experience: Familiarity with CAKE framework in Linux 4.19
      Interests: Active Queue Management, Packet scheduling and TCP.
      Difficulty: Medium to Hard
      Recommended reading:
      Piece of CAKE: A Comprehensive Queue Management Solution for Home Gateways
      Let them run CAKE
      Queue disciplines in ns-3
      
      
      large size : 350 hours


      ~~~~~~~~~~
      Switched Ethernet
      Mentors: Tommaso Pecorella, TBD.
      The current ns-3 models for wired connections are fine for simple networks, but the lack of a switched Ethernet model is a limitation in some cases.
      The goal of the idea is to create, test, and document a Switched Ethernet model, able to simulate (at least) 1, 10, and 40 GbE links and model for a switch.
      The model of the NetDevice and Channel shall take into account the link delays and errors, similarly to what is done by the point-to-point model. Futhermore, it should be able to set the link speed and if it is full-duplex or half-duplex. Additional support for flow control is a bonus, but not strictly required. Link speed auto-negotiation is not considered to be interesting.
      The model for the switch should be modular (i.e., allowing the development of different switch types), and include auto-learning of I/O ports based on the MAC address, i.e., have a MAC/port table, and a basic store-and-forward operation. Features like advanced I/O buffer handling and ARP/NDP spoofing detection are not a priority and shall be left for future implementations.
      The model should consider the future implementaion of algorithms like VLANs (IEEE 802.1Q, 802.1ad), and the Spanning Tree Protocol (IEEE 802.1D, 802.1w, and 802.1s). Their implementaion is not required, but the model design should allow their development.
      Required Experience: Fundamentals of Ethernet sitched networking, C++ programming.
      Interests: Ethernet networks and switched data networks.
      Difficulty: Medium.
      Recommended reading:
      Basic implementation (very old)
      Full-duplex CSMA, somehow related
      Paper on gigabit Ethernet switch models for simulation
      Possible tasks to fulfill the patch requirement:
      TBD, contact the mentors if interested.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-ns-3-network-simulator-project/
    idea_list_url: https://www.nsnam.org/wiki/GSOC2025Projects

  - organization_id: 163
    organization_name: Typelevel
    no_of_ideas: 12
    ideas_content: |
 
      MACHINE LEARNING INFERENCE IN CATS EFFECT
      We want to make it possible to deploy machine learning inference as part of a larger web service without compromising the latency of other on-going requests. The goal of this project is to create a compiler to transform a pre-trained ML model into a sequence of Cats Effect IO steps that perform inference on some input.
      PREREQUISITES
      Scala, ideally some experience with ML
      EXPECTED DIFFICULTY
      Hard but doable. Will draw on knowledge of ML and compilers.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @armanbilge @djspiewak @ekrich @valencik
      RELATED REPOS
      cats-effect
      AI WEB PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      SERVERLESS INTEGRATIONS FOR FERAL
      Feral is a Typelevel library for building serverless functions that currently supports AWS Lambda and Google Cloud Run Functions. We want to add support for more types of serverless events and more cloud providers.
      PREREQUISITES
      Scala, ideally experience with serverless
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Medium (~ 175 hours)
      MENTORS
      @armanbilge @bpholt @Chingles2404
      RELATED REPOS
      feral
      CLOUD PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      NATIVE I/O BACKEND FOR FS2 JVM
      FS2 on the JVM currently implements its networking API using JDK NIO. Unfortunately this indirection incurs a non-trivial performance penalty. We want to replace the use of JDK NIO with direct calls to system I/O APIs such as epoll and kqueue.
      PREREQUISITES
      Scala, ability to read C
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @antoniojimeneznieto @djspiewak @mpilquist @armanbilge
      RELATED REPOS
      fs2
      OPERATING SYSTEMS PROGRAMMING LANGUAGES


      ~~~~~~~~~~
      POLLING-BASED I/O IN FS2
      Cats Effect v3.6.0 introduced the ability to poll for I/O readiness. We want to use polling to reimplement several I/O APIs in FS2, including datagrams, unix sockets, and processes, on the JVM and Native platforms.
      PREREQUISITES
      Scala, ability to read C
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @armanbilge @mpilquist @antoniojimeneznieto
      RELATED REPOS
      fs2
      OPERATING SYSTEMS PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      FS2 CONNECTION API
      TCP-based protocols are common (e.g. HTTP, Postgres, Redis) and are implemented by clients to interface with these services (e.g. Ember, Skunk, Rediculous). The goal of this project is to create a “connection” API that supports pooling, error conditions, and metrics and can be shared by all of our client libraries.
      PREREQUISITES
      Scala, ideally some knowledge of networking
      EXPECTED DIFFICULTY
      Hard.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @mpilquist @armanbilge
      RELATED REPOS
      fs2
      OPERATING SYSTEMS PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      WEB COMPONENTS FOR CALICO
      Calico is a reactive UI library built with Cats Effect and FS2. Web Components are a standard for creating framework-agnostic, reusable UI elements. The goal of this project is to enable Calico users to access the vast array of web components available by improving its DSL and code-generation.
      PREREQUISITES
      Scala, ideally experience with Web APIs
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @armanbilge
      RELATED REPOS
      calico
      WEB PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      UPGRADE SBT-TYPELEVEL TO SBT 2
      sbt-typelevel is a plugin for sbt, the Scala build tool, used by hundreds of open source and enterprise projects. sbt 2 is in the final stages of development. We want to upgrade sbt-typelevel to sbt 2 and adopt its new features, such as “project matrix” for cross-building.
      PREREQUISITES
      Scala
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @mzuehlke @armanbilge
      RELATED REPOS
      sbt-typelevel
      DEVELOPMENT TOOLS

      ~~~~~~~~~~
      REFRESH DAVENVERSE PROJECTS
      The Davenverse is a collection of several popular Typelevel libraries, including Mules and cats-scalacheck. Unfortunately, we have fallen behind on their maintenance. We want to move these libraries under the Typelevel org, refresh their build tooling, and bring them up-to-date to ensure their longevity.
      PREREQUISITES
      Scala
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Medium (~ 175 hours)
      MENTORS
      @samspills @valencik
      RELATED REPOS
      davenverse
      DEVELOPMENT TOOLS PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      CATS EFFECT & FS2 ON WASM/WASI
      Web Assembly and its System Interface are emerging technologies for deploying secure, modular applications. The goal of this project is to prototype porting the Cats Effect runtime and FS2 streaming I/O to the Wasm/WASI platform, also possibly generating feedback for the Scala WASM and WASI teams.
      PREREQUISITES
      Scala, ideally some experience with Wasm/WASI
      EXPECTED DIFFICULTY
      Hard. Wasm/WASI support in Scala is experimental.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @armanbilge @tanishiking @valencik
      RELATED REPOS
      cats-effect fs2
      WEB CLOUD OPERATING SYSTEMS PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      EXTENSIBLE LOG4CATS INTERFACE
      log4cats is the de facto logging library for the Typelevel stack. Recently, a new API was proposed that overcomes current limitations of log4cats. The goal of this project is to adopt the new API in log4cats, migrate existing integrations to the new API, and create a compatibility layer with the old API.
      PREREQUISITES
      Scala
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @morgen-peschke @kubukoz @irevive
      RELATED REPOS
      log4cats
      CLOUD PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      HTTP4S-FS2-DATA
      fs2-data is a streaming data library that supports a plethora of formats. http4s is a library for creating and consuming web services. http4s-fs2-data is a project to integrate the two libraries. We want to integrate more fs2-data modules as well as enhance the existing integrations.
      PREREQUISITES
      Scala
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Short (~ 90 hours)
      MENTORS
      @satabin @ybasket
      RELATED REPOS
      http4s-fs2-data fs2-data http4s
      CLOUD WEB PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      CONVERT DOOBIE TEST SUITE TO USE MUNIT-CATS-EFFECT
      Doobie is a purely functional library for database access. Our test suites are written before there is good integration between MUnit (the test framework) and Cats-Effect (the effect system we depend on). We want to convert to use munit-cats-effect to make them less verbose and error prone.
      PREREQUISITES
      Scala
      EXPECTED DIFFICULTY
      Easy.
      EXPECTED LENGTH
      Medium (~ 175 hours)
      MENTORS
      @jatcwang
      RELATED REPOS
      doobie munit-cats-effect
      CLOUD PROGRAMMING LANGUAGES
     
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/typelevel/
    idea_list_url: https://typelevel.org/gsoc/ideas

  - organization_id: 164
    organization_name: UC OSPO
    no_of_ideas: 55
    ideas_content: |
      
      

      
      AI Data Readiness Inspector (AIDRIN)
      Jean Luca Bez, Suren Byna
      Feb 11, 2025

      Garbage In Garbage Out (GIGO) is a universally agreed quote by computer scientists from various domains, including Artificial Intelligence (AI). As data is the fuel for AI, models trained on low-quality, biased data are often ineffective. Computer scientists who use AI invest considerable time and effort in preparing the data for AI.

      AIDRIN (AI Data Readiness INspector) is a framework that provides a quantifiable assessment of the readiness of data for AI processes, covering a broad range of readiness dimensions available in the literature. AIDRIN uses metrics in traditional data quality assessment, such as completeness, outliers, and duplicates, for data evaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI, such as feature importance, feature correlations, class imbalance, fairness, privacy, and FAIR (Findability, Accessibility, Interoperability, and Reusability) principle compliance. AIDRIN provides visualizations and reports to assist data scientists in further investigating the readiness of data.

      AIDRIN Visualizations and Science Gateway
      The proposed work will include improvements in the AIDRIN framework to (1) enhance, extend, and optimize the visualizations of metrics related to all six pillars of AI data readiness and (2) set up a science gateway on NERSC or AWS cloud service.

      Topics: data readiness AI
      Skills: Python, C/C++, good communicator
      Difficulty: Moderate
      Size: Large (350 hours)
      Mentors: Jean Luca Bez and Suren Byna

      ~~~~~~~~~~

      AI for Science: Automating Domain Specific Tasks with Large Language Models
      Daniel Wong, Luanzheng "Lenny" Guo
      Feb 23, 2025

      Recent advancements in Large Language Models (LLMs) have transformed various fields by demonstrating remarkable capabilities in processing and generating human-like text. This project aims to explore the development of an open-source framework that leverages LLMs to enhance discovery across specialized domains.

      The proposed framework will enable LLMs to analyze and interpret complex datasets, automate routine tasks, and uncover novel insights. A key focus will be on equipping LLMs with domain-specific expertise, particularly in areas where specialized tools – such as ANDES – are not widely integrated with LLM-based solutions. By bridging this gap, the framework will empower researchers and professionals to harness LLMs as intelligent assistants capable of navigating and utilizing niche computational tools effectively.

      AI for Science: Automating Domain Specific Tasks with Large Language Models
      Topics: Large Language Models AI for Science
      Skills: Python, Experience with LLMs, Prompt Engineering, Fine-Tuning, LLM Frameworks
      Difficulty: Medium-Difficult
      Size: Large (350 hours)
      Mentor: [Daniel Wong]Daniel Wong, [Luanzheng “Lenny” Guo]Luanzheng "Lenny" Guo
      Project Tasks and Milestones
      Designing an extensible framework that facilitates the integration of LLMs with specialized software and datasets.
      Developing methodologies for fine-tuning LLMs to act as domain experts.
      Implementing strategies for improving tool interoperability, allowing LLMs to interact seamlessly with less commonly used but critical analytical platforms.


      ~~~~~~~~~~

      AR4VIP
      alex pang
      Feb 18, 2025
      We are interested in developing navigation aids for visually impaired people (VIP) using AR/VR technologies. Our intended use is primarily indoors or outdoors but within private confines e.g. person’s backyard. Using AR/VR headsets or smart glasses allows navigation without using a cane and frees the users’ hands for other tasks.

      Continue Development on Meta Quest 3 Headset
      Topics: Dynamic scenes Spatial audio Proximity detection
      Skills: AR/VR familiarity, WebXR, Unity, SLAM, good communicator, good documentation skills
      Difficulty: Moderate
      Size: Medium or large (175 or 350 hours)
      Mentors: Alex Pang, James Davis
      Continue development and field testing with the Meta Quest 3 headset. See this repository page for current status.

      Specific tasks:

      Improve spatial audio mapping
      Improve obstacle detection, at different heights, with pre-scanned geometry as well as dynamic objects e.g. other people, pets, doors
      Special handling of hazards e.g. stairs, uneven floors, etc.
      Explore/incorporate AI to help identify objects in the scene when requested by user
      New Development on Smart Glasses
      Topics: Dynamic scenes Spatial audio Proximity detection
      Skills: AR/VR familiarity, WebXR, Unity, SLAM, good communicator, good documentation skills
      Difficulty: Moderate
      Size: Large (350 hours)
      Mentors: Alex Pang, James Davis
      VR headsets are bulky and awkward, but currently is more advanced than AR glasses in terms of programmability. Ultimately, the form factor of smart glasses is more practical for extended use by our target users. There are many vendors working on pushing out their version of smart glasses targetting various applications e.g. alternative for watching TV, etc. We are interested in those that provide capabilities to support spatial computing. Most of these will likely have their own brand specific APIs. This project has 2 goals: (a) develop generic brand-independent API, perhaps extensions to WebXR, to support overarching goal of navigation aid for VIP, and (b) port functionality of VR version to smart glasses while taking advantage of smart glass functionalities and sensors.

      Specific tasks:

      Explore current and soon-to-be-available smart glass options e.g. Snap Spectacles, Xreal Air 2 ultra, etc. and select a platform to work on (subject to cost and availability of SDK). At a minimum, glass should be microphones and speakers, and cameras. Infrared cameras or other low light capability is a plus. Sufficient battery life or option for quick exchange.
      Identify support provided by SDK e.g. does it do realtime scene reconstruction? does it support spatial audio? etc. If it supports features outside of WebXR, provide generic hooks to improve portability of code to other smart glasses.
      Port and extend functionalities from the Meta Quest 3 VR headsets to smart glass platform.
      Add AI support if glasses support them.
      Provide documentation of work.

      ~~~~~~~~~~

      Autograder
      Eriq Augustine
      Feb 6, 2025

      The EduLinq Autograder is an open source tool used by several courses at UCSC to safely and quickly grade programming assignments. Grading student code is something that may seem simple at first (you just need to run their code!), but quickly becomes exceeding complex as you get more into the details. Specifically, grading a student’s code securely while providing the “last mile” service of getting code from students and sending results to instructors/TAs and the course’s LMS (e.g., Canvas) can be very difficult. The Autograder provides all of this in a free and open source project. The LINQS Lab has made many contributions to the maintain and improve the Autograder.

      As an open source project, there are endless opportunities for development, improvements, and collaboration. Here, we highlight some specific projects that will work well in the summer mentorship setting.

      All students interested in LINQS projects for OSRE/GSoC 2025 should fill out this form. Towards the end of the application window, we will contact those who we believe to be a good fit for a LINQS project. The form will stop accepting responses once the application window closes. Do not post on any of the project repositories about OSRE/GSoC (e.g., comment on an issue that you want to tackle it as a part of OSRE/GSoC 2025). Remember, these are active repositories that were not created for OSRE/GSoC.

      LLM Detection
      Topics: AI/ML LLM Research Backend
      Skills: software development, backend, systems, data munging, go, docker
      Difficulty: Challenging
      Size: Large (350 hours)
      Mentors: Eriq Augustine, Fabrice Kurmann, Lise Getoor
      As Large Language Model (LLM) tools like ChatGPT become more common and powerful, instructors need tools to help determine if students are the actual authors of the code they submit. More classical instances of plagiarism are often discovered by code similarity tools like MOSS. However these tools are not sufficient for detecting code written not by a student, but by an AI model like ChatGPT or GitHub Copilot.

      The task for this project is to create a system that provides a score indicating the system’s confidence that a given piece of code was written by an AI tool and not a student. This will supplement the existing code analysis tools in the Autograder. There are many approaches to completing this task that will be considered. A more software development approach can consist of levering exiting systems to create a production-ready system, whereas a more research approach can consist of creating a novel approach complete with a paper and experiments.

      See Also:

      Repository for Autograder Server
      GitHub Issue
      
      ~~~~~~~~~~
      
      Code Analysis GUI
      Topics: Frontend
      Skills: software development, frontend, data munging, js, css, go
      Difficulty: Easy
      Size: Medium or Large (175 or 350 hours)
      Mentors: Eriq Augustine, Fabrice Kurmann, Lise Getoor
      The Autograder has existing functionality to analyze the code in a student’s submission for malicious content. Relevant to this project is that the Autograder can run a pairwise similarity analysis against all submitted code. This is how most existing software plagiarism systems detect offending code. The existing infrastructure provides detailed statistics on code similarity, but does not currently have a visual way to display this data.

      The task for this project is to create a web GUI using the Autograder REST API to display the results of a code analysis. The size of this project depends on how many of the existing features are going to be supported by the web GUI.

      See Also:

      Repository for Autograder Web GUI
      GitHub Issue
      Pairwise Code Analysis Type
      Sample API Data

      ~~~~~~~~~~
      Web GUI
      Topics: Frontend
      Skills: software development, frontend, js, css
      Difficulty: Easy
      Size: Medium or Large (175 or 350 hours)
      Mentors: Eriq Augustine, Fabrice Kurmann, Lise Getoor
      The Autograder contains dozens of API endpoints, most directly representing a piece of functionality exposed to the user. All of these features are exposed in the Autograder’s Python Interface. However, the Python interface is a purely command-line interface. And although command-line interface are objectively (read: subjectively) the best, a web GUI would be more accessible to a wider audience. The autograder already has a web GUI, but it does not cover all the features available in the Autograder.

      The task for this project is to augment the Autograder’s web GUI with more features. Specifically, add support for more tools used to create and administer courses.

      See Also:

      Repository for Autograder Web GUI
      GitHub Issue
      Autograder API Endpoints
      Autograder’s Python Interface

      ~~~~~~~~~~

      Brahma / Protoocol Release and Validation
      Topics: Web Development Software Architecture VR Development Computer Graphics Cloud Platforms
      Skills: Node.js, Three.js
      Difficulty: Moderate-Challenging
      Size: Large (350 hours)
      Mentors: Samir Ghosh
      The proposed work includes three phases, primarily working on backend code, and API design. In the first phase, to gain familiarity, the mentee will be running and testing the Brahma backend on a variety of cloud platforms such as AWS, Google Cloud, and Azure– and learning best methods for documentation in the process. Then, in the second phase, the mentee will work on formalizing the protocol for avatar embodiment and other multi-user interfaces, testing the application with a simple pong game. In the third phase, the mentee will address telemetry, logging, and analysis considerations.

      This project is well suited for someone who has interest in virtual reality, especially social VR, multi-user, or collaborative applications

      ~~~~~~~~~~
      
      Brahma / Allocentric WebXR Interfaces
      Topics: Web Development VR Development Computer Graphics UX/UI
      Skills: Three.js, GLSL, WebSocket
      Difficulty: Moderate-Challenging
      Size: Medium or large (175 or 350 hours)
      Mentors: Samir Ghosh
      The proposed work primarily involves front-end code and VR interface design. In the first phase, the mentee will gain familiarity with best practices for WebXR development through the implementation and documentation of simple interaction patterns. Then, the mentee will implement a simple multi-user pong game to learn about allocentric interfaces. In the final phase of the project, the mentee will design and implement one or more allocentric interface of their choosing.

      This project is well suited for someone who has interest in virtual reality, especially aspects of graphics and interaction design.



      ~~~~~~~~~~

      CarbonCast: Building an end-to-end consumption-based Carbon Intensity Forecasting service
      Abel Souza
      Feb 18, 2025

      CarbonCast is a machine-learning-based approach to provide multi-day forecasts of the electrical grid’s carbon intensity. Developed in Python, the current version of CarbonCast delivers accurate forecasts in numerous regions by using historical source production data of a particular geographical region, time of day/year, and weather forecasts as features. However, there is no easy way to access and visualize the data through a standard interface. In addition, much important information is left out and is not available to users. For instance, electricity grids often import electricity from neighboring regions and so electricity consumption depends on both electricity generation and imports. Moreover, it is imperative for each energy source to utilize a tailored predictive mechanism. Consequently, any carbon optimization solution trying to reduce carbon emissions due to its electricity consumption will benefit more from following a consumption-based CI signal.

      The plan for this project is to develop both the frontend and the backend API services for CarbonCast. We also intend to enhance CarbonCast by implementing an architecture wherein each region can employ a distinct interface for their predictive modeling. In scenarios where these new models do not yield superior outcomes within a region, the current architecture will serve as a fallback solution.

      Building an end-to-end consumption-based Carbon Intensity Forecasting service
      Topics: Databases Machine Learning
      Skills: Python, command line (bash), MySQL, Django, machine learning, cronjob
      Difficulty: Moderate
      Size: Medium (175 hours)
      Mentors: Abel Souza
      Develop a containerized end-to-end backend, API, and frontend for collecting, estimating, and visualizing real-time and forecast electrical grid’s carbon intensity data in a scalable manner.

      Tasks:

      Research web technologies and frameworks relevant to CarbonCast development.
      Run and collect CarbonCast’s data (CSV)
      Ingest CSV into a MySQL or SQLite database
      Develop an Application Programming Interface (API) and a Web User Interface (UI) to provide real-time data access and visualization.
      Deploy the CarbonCast API as a service and dockerize it so that other users and applications can locally deploy and use it easily.
      Implement a choropleth web map to visualize the carbon intensity data across the different geographical regions supported by CarbonCast.
      Enhance CarbonCast by implementing an extensible architecture wherein every region can employ distinct models for their predictive modeling.



      ~~~~~~~~~~

      
      Causeway / Improving the Core Infrastructure
      The proposed work includes adding logging, analytics, and a production-level CI/CD pipeline, adding a robust testing framework, and refactoring some of our code into seperate modules. Both roles will also contribute to running usability studies and documenting the platform.

      Topics: Web Development, Educational Technologies, Angular
      Skills: Web development experience, HTML, CSS, Javascript, Angular, RxJS, NgRx, Firebase
      Difficulty: Medium to Hard
      Size: Large (350 hours)
      Mentors: David Lee
      
      ~~~~~~~~~~
      
      Causeway / Quizzes and Generative AI
      The proposed work includes extending the application to support quizzes, adding quizzes for the existing tasks, and exploring the use of generative AI to support the quizzes feature. Both roles will also contribute to running usability studies and documenting the platform.

      Topics: Web Development, Educational Technologies, Angular
      Skills: Web development experience, HTML, CSS, Javascript, Angular, RxJS, NgRx, Firebase, Generative AI
      Difficulty: Medium to Hard
      Size: Large (350 hours)
      Mentors: David Lee

      ~~~~~~~~~~

      Disentangled Generation and Editing of Pathology Images
      Xi Li
      Feb 7, 2025

      Topics: computational pathology, image generation, disentangled representations, latent space manipulation, deep learning
      Skills:
      Programming Languages:
      Proficient in Python, with experience in machine learning libraries such as PyTorch or TensorFlow.
      Generative Models:
      Familiarity with Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and contrastive learning methods.
      Data Analysis:
      Image processing techniques, statistical analysis, and working with histopathology datasets.
      Biomedical Knowledge (preferred):
      Basic understanding of histology, cancer pathology, and biological image annotation.
      Difficulty: Advanced
      Size: Large (350 hours). The project involves substantial computational work, model development, and evaluation of generated pathology images.
      Mentors: Xi Li (contact person), Mentor Name
      Project Idea Description
      The project aims to advance the generation and disentanglement of pathology images, focusing on precise control over key histological features. By leveraging generative models, we seek to create synthetic histological images where specific pathological characteristics can be independently controlled.

      Challenges in Current Approaches
      Current methods in histopathology image generation often struggle with:

      Feature Entanglement: Difficulty in isolating individual factors such as cancer presence, severity, or staining variations.
      Lack of Control: Limited capability to manipulate specific pathological attributes without affecting unrelated features.
      Consistency Issues: Generated images often fail to maintain realistic cellular distributions, affecting biological validity.
      Project Motivation
      This project proposes a disentangled representation framework to address these limitations. By separating key features within the latent space, we aim to:

      Control Histological Features: Adjust factors such as cancer presence, tumor grade, number of malignant cells, and staining methods.
      Ensure Spatial Consistency: Maintain the natural distribution of cells during image reconstruction and editing.
      Enable Latent Space Manipulation: Provide interpretable controls for editing and generating realistic histopathology images.
      Project Objectives
      Disentangled Representation Learning:
      Develop generative models (e.g., VAEs, GANs) to separate and control histological features.
      Latent Space Manipulation:
      Design mechanisms for intuitive editing of pathology images through latent space adjustments.
      Spatial Consistency Validation:
      Implement evaluation metrics to ensure that cell distribution remains biologically consistent during image generation.
      Project Deliverables
      Generative Model Framework:
      An open-source Python implementation for pathology image generation and editing.
      Disentangled Latent Space Tools:
      Tools for visualizing and manipulating latent spaces to control specific pathological features.
      Evaluation Metrics:
      Comprehensive benchmarks assessing image quality, feature disentanglement, and biological realism.
      Documentation and Tutorials:
      Clear guidelines and code examples for the research community to adopt and build upon this work.
      Impact
      By enabling precise control over generated histology images, this project will contribute to data augmentation, model interpretability, and biological insight in computational pathology. The disentangled approach offers new opportunities for researchers to explore disease mechanisms, develop robust diagnostic models, and improve our understanding of cancer progression and tissue morphology.


      ~~~~~~~~~~

      Environmental NeTworked Sensor (ENTS)
      Colleen Josephson
      Last updated on Feb 10, 2025

      ENTS I: Web portal for large-scale sensor networks
      Data Visualization Dashboard
      Topics: Data Visualization, Backend, Frontend, UI/UX, Analytics
      Skills:
      Required: React, Javascript, Python, SQL, Git
      Nice to have: Flask, Docker, CI/CD, AWS, Authentication
      Difficulty: Medium
      Size: Large (350 hours)
      Mentors: Colleen Josephson, John Madden, Alec Levy
      The Environmental NeTworked Sensor (ENTS) platform, formally Open Sensing Platform (OSP), implements data visualization website for monitoring microbial fuel cell sensors (see GitHub). The mission is to scale up the current platform to support other researchers or citizen scientists in integrating their novel sensing hardware or microbial fuel cell sensors for monitoring and data analysis. Examples of the types of sensors currently deployed are sensors measuring soil moisture, temperature, current, and voltage in outdoor settings. The focus of the software half of the project involves building upon our existing visualization web platform, and adding additional features to support the mission. A live version of the website is available here.

      Below is a list of project ideas that would be beneficial to the ENTS project. You are not limited to the following projects, and encourage new ideas that enhance the platform:

      Improve streaming functionality
      Generic interface for sensor measurements
      Logger registration
      Over the air (OTA) configuration updates
      Implement unit tests and API documentation

      ~~~~~~~~~~

      ENTS II: Hardware to for large-scale field sensor networks
      Hardware
      Topics: Embedded system, wireless communication, low-power remote sensing
      Skills:
      Required: C/C++, Git, Github, PlatformIO
      Nice to have: STM32 HAL, ESP32 Arduino, protobuf, python, knowledge of standard communication protocols (I2C, SPI, and UART)
      Difficulty: Hard
      Size: Large (350 hours)
      Mentors: Colleen Josephson, John Madden, Jack Lin
      The Environmental NeTworked Sensor (ENTS) node aims to be a general purpose hardware platform for outdoor sensing (e.g. agriculture, ecological monitoring, etc.). The typical use case involves a sensor deployment in an agricultural field, remotely uploading measurements without interfering with farming operations. The current hardware revision (Soil Power Sensor was originally designed for monitoring power output of microbial fuel cells using high fidelity voltage and current measurement channels, as well as auxiliary sensors such as the SDI-12 TEROS-21 soil moisture sensor. The primary activities of this project will involve low-level firmware design and implementation, but may also incorporate hardware design revisions if necessary. We are looking to expand functionality to other external sensors, as well as optimize for power consumption, via significant firmware design activities.

      Long-range, low-power wireless communication is achieved through a LoRa capable STM32 microcontroller with in-lab experiments using an ESP32 microcontroller to enable the simpler WiFi interface. Both wireless interfaces communicate upload measurements to our data visualization dashboard, ENTS I. The combined goal across both of these projects is to create a system that enables researchers to test and evaluate novel sensing solutions. We are looking to make the device usable to a wide range of researchers which may not have a background in electronics, so are interested in design activities that enhance user friendliness.

      In total there will be 2-4 people working on the hardware with progress being tracked on GitHub. Broader project planning is tracked through a Jira board. We intend to have weekly meetings to provide updates on current issue progress along with assigning tasks. Please reach out to John Madden if there are any questions or specific ideas for the project.

      Below is a list of project ideas that would be beneficial to the ENTS project. You are not limited to the following projects, and encourage new ideas that enhance the platform:

      Backup logging via SD card
      I2C multiplexing for multiple of the same sensors
      Batch sensor measurement uploading


      ~~~~~~~~~~

      Exploration of I/O Reproducibility with HDF5
      Luanzheng "Lenny" Guo, Wei Zhang
      Last updated on Feb 20, 2025

      Parallel I/O is a critical component in high-performance computing (HPC), allowing multiple processes to read and write data concurrently from a shared storage system. HDF5—a widely adopted data model and library for managing complex scientific data—supports parallel I/O but introduces challenges in I/O reproducibility, where repeated executions do not always produce identical results. This lack of reproducibility can stem from non-deterministic execution orders, variations in collective buffering strategies, and race conditions in metadata and dataset chunking operations within HDF5’s parallel I/O hierarchy. Moreover, many HDF5 operations that leverage MPI I/O require collective communication; that is, all processes within a communicator must participate in operations such as metadata creation, chunk allocation, and data aggregation. These collective calls ensure that the file structure and data layout remain consistent across processes, but they also introduce additional synchronization complexity that can impact reproducibility if not properly managed. In HPC scientific workflows, consistent I/O reproducibility is essential for accurate debugging, validation, and benchmarking, ensuring that scientific results are both verifiable and trustworthy. Tools such as h5bench—a suite of I/O kernels designed to exercise HDF5 I/O on parallel file systems—play an important role in identifying these reproducibility challenges, tuning performance, and ultimately supporting the overall robustness of large-scale scientific applications.

      Workplan
      The proposed work will include (1) analyzing and characterizing parallel I/O operations in HDF5 with h5bench miniapps, (2) exploring and validating potential reproducibility challenges within the parallel I/O hierarchy (e.g., MPI I/O), and (3) implementing solutions to address parallel I/O reproducibility.

      Topics: Parallel I/O MPI-I/O Reproducibility HPC HDF5
      Skills: C/C++, Python
      Difficulty: Medium
      Size: Large (350 hours)
      Mentors: Luanzheng "Lenny" Guo and [Wei Zhang]Wei Zhang

      ~~~~~~~~~~

      FairFace: Reproducible Bias Evaluation in Facial AI Models via Controlled Skin Tone Manipulation
      Bias in facial AI models remains a persistent issue, particularly concerning skin tone disparities. Many studies report that AI models perform differently on lighter vs. darker skin tones, but these findings are often difficult to reproduce due to variations in datasets, model architectures, and evaluation settings. The goal of this project is to investigate bias in facial AI models by manipulating skin tone and related properties in a controlled, reproducible manner. By leveraging BioSkin, we will adjust melanin levels and other skin properties on existing human datasets to assess whether face-based AI models (e.g., classification and vision-language models) exhibit biased behavior toward specific skin tones.

      Topics: Fairness & Bias in AI, Face Recognition & Vision-Language Models, Dataset Augmentation for Reproducibility
      Skills: Machine Learning & Computer Vision, Deep Learning (PyTorch/TensorFlow), Data Augmentation & Image Processing, Reproducibility & Documentation (GitHub, Jupyter Notebooks).
      Difficulty: Moderate
      Size: Medium or Large ( Can be completed in either 175 or 350 hours, depending on the depth of analysis and number of models tested.)
      Mentors: James Davis, Alex Pang
      Key Research Questions
      Do AI models perform differently based on skin tone?
      How do classification accuracy, confidence scores, and error rates change when skin tone is altered systematically?
      What are the underlying causes of bias?
      Is bias solely dependent on skin tone, or do other skin-related properties (e.g., texture, reflectance) contribute to model predictions?
      Is bias driven by dataset imbalances (e.g., underrepresentation of certain skin tones)?
      Do facial features beyond skin tone (e.g., structure, expression, pose) contribute to biased predictions?
      Are bias trends reproducible?
      Can we replicate bias patterns across different datasets, model architectures, and experimental setups?
      How consistent are the findings when varying image sources and preprocessing methods?
      Specific Tasks:
      Dataset Selection & Preprocessing
      Choose appropriate face/human datasets (e.g., FairFace, CelebA, COCO-Human).
      Preprocess images to ensure consistent lighting, pose, and resolution before applying transformations.
      Skin Tone Manipulation with BioSkin
      Systematically modify melanin levels while keeping facial features unchanged.
      Generate multiple variations per image (lighter to darker skin tones).
      Model Evaluation & Bias Analysis
      Test face classification models (e.g., ResNet, FaceNet) and vision-language models (e.g., BLIP, LLaVA) on the modified images.
      Compute fairness metrics (e.g., demographic parity, equalized odds).
      Investigate Underlying Causes of Bias
      Compare model behavior across different feature sets.
      Test whether bias persists across multiple datasets and model architectures.
      Ensure Reproducibility
      Develop an open-source pipeline for others to replicate bias evaluations.
      Provide codebase and detailed documentation for reproducibility.


      ~~~~~~~~~~

      h5bench with AI workloads
      Jean Luca Bez, Suren Byna
      Feb 11, 2025

      h5bench is a suite of parallel I/O benchmarks or kernels representing I/O patterns that are commonly used in HDF5 applications on high performance computing systems. h5bench measures I/O performance from various aspects, including the I/O overhead, and observed I/O rate.

      Parallel I/O is a critical technique for moving data between compute and storage subsystems of supercomputers. With massive amounts of data produced or consumed by compute nodes, high-performant parallel I/O is essential. I/O benchmarks play an important role in this process; however, there is a scarcity of I/O benchmarks representative of current workloads on HPC systems. Toward creating representative I/O kernels from real-world applications, we have created h5bench, a set of I/O kernels that exercise HDF5 I/O on parallel file systems in numerous dimensions. Our focus on HDF5 is due to the parallel I/O library’s heavy usage in various scientific applications running on supercomputing systems. The various tests benchmarked in the h5bench suite include I/O operations (read and write), data locality (arrays of basic data types and arrays of structures), array dimensionality (1D arrays, 2D meshes, 3D cubes), I/O modes (synchronous and asynchronous). h5bench measurements can be used to identify performance bottlenecks and their root causes and evaluate I/O optimizations. As the I/O patterns of h5bench are diverse and capture the I/O behaviors of various HPC applications, this study will be helpful to the broader supercomputing and I/O community.

      h5bench with AI workloads
      The proposed work will include (1) analyzing and characterizing AI workloads that rely on HDF5 datasets, (2) extracting a kernel of their I/O operations, and (3) implementing and validating the kernel in h5bench.

      Topics: I/O HPC benchmarking
      Skills: Python, C/C++, good communicator
      Difficulty: Moderate
      Size: Large (350 hours)
      Mentors: Jean Luca Bez and Suren Byna


      ~~~~~~~~~~

      HAgent is a platform to build AI hardware agent engine to support multiple components in chip design, such as code generation, verification, debugging, and tapeout.

      HAgent is build as a compiler for for Hardware Agents, it interfaces with typical EDA tools like compilers, synthesis, and verification. There are several projects around enhancing HAgent.

      BugFarm hagent step
      Objective: Develop a HAgent step (pass) to create bugs in a given design.

      Description: Using LLMs (Hagent APIs), the goal is to add “bugs” to input Verilog design. The goal is for other tools passes that need to fix bugs, to use this infrastructure as a bug generator. There is a MCY (https://github.com/YosysHQ/mcy) that does something similar but it does not use verilog and create a very different Verilog output. The BugFarm is supposed to have somewhat similar functionality but edit the Verilog directly which results in a code with just a few edits. Like MCY, there has to be a step to confirm that the change affects results. The project should benchmarks and compare with MCY.

      Skills Needed: Python, Verilog, and understand agents
      Difficulty: Medium
      Size: Medium
      Mentors: Jose Renau, Farzaneh Rabiei Kashanaki


      ~~~~~~~~~~
      HDEval Competition Repository
      Objective: Create a platform for HDL programming challenges and community engagement.

      Description: Develop a repository where users can solve HDL problems in Verilog, Chisel, PyRTL, etc. Implement a points system for successful solutions. Allow users to submit new problems (code, specifications, verification, and tests) that are not easily solvable by LLMs. Automate solution testing and provide feedback on submissions.

      The submissions consist of 4 components: code, specification, verification, and tests. It should be possible to submit also examples of bugs in code/specification/verification/tests during the design.

      If the code is different from Verilog, it should include the HDL (chisel, PyRTL,…) and also the Verilog.

      The specification is free form. For any given specification, an expert on the area should be able to generate code, verification, and tests. Similarly, from any pair. Any expert should be able to generate the rest. For example, from verification and tests, it should be able to generate the code and specification.

      Typical specifications consist of a plan, API, and a sample usage.

      Skills Needed: Web design, some hardware understanding
      Difficulty: Medium
      Size: Medium
      Mentors: Jose Renau, Farzaneh Rabiei Kashanaki

      ~~~~~~~~~~
      Integrate Silicon Compiler
      Objective: Silicon Compiler is an open-source Python library that allows to interface with many EDA tools. The idea is to integrate it with HAgent to allow prompts/queries to interface with it.

      Description: The agentic component requires to check with silicon compiler that the generated Python compiles but also that has reasonable parameters. This will require a react loop for compiler errors, and likely a judge loop for testing for reasonable options/flow with feedback from execution. Since there is not much training examples, it will require a few shot with a database to populate context accordingly.

      The end result should allow to select different tools and options trhough silicon compiler.

      Skills Needed: Backend chip design
      Difficulty: High
      Size: Medium
      Mentors: Jose Renau

      ~~~~~~~~~~
      Comodore 64 or MSX or Gameboy
      Objective: Create a prompt-only specification to build a hardware accelerated for the target platform (Comodore 64, MSX or Gameboy). The generated code should focus on Verilog, but it is fine to also target some other HDL. In all the cases, the project should include a generated Verilog integrated with some emulator for verification.

      Description: Using Hagent, create an HDLEval benchmark (set of prompts) that provide the necessary information to create the Verilog implementation. HDLEval prompts usually consists of a high-level PLAN or specification, an API to implement, and a few examples of usage for the given API.

      The result of running the bencharmk, a generated Verilog runs program in the emulator and the Verilog to compare correctness. The platform should have an already existing emulator vice-emu or mGBA to perform cosimulation against the generated specification.

      Skills Needed: Verilog for front-end design
      Difficulty: High
      Size: Large (175 or 350 hours)
      Mentors: Jose Renau

      ~~~~~~~~~~
      LLMSeqRec: LLM Enhanced Contextual Sequential Recommender
      Linsey Pang, Bin Dong
      Feb 6, 2025

      Project Description
      Sequential Recommender Systems are widely used in scientific and business applications to analyze and predict patterns over time. In biology and ecology, they help track species behavior by suggesting related research on migration patterns and environmental changes. Medical applications include personalized treatment recommendations based on patient history and predicting disease progression. In physics and engineering, these systems optimize experimental setups by suggesting relevant past experiments or simulations. Environmental and climate science applications include forecasting climate trends and recommending datasets for monitoring deforestation or pollution. In business and e-commerce, sequential recommenders enhance user experiences by predicting consumer behavior, suggesting personalized products, and optimizing marketing strategies based on browsing and purchase history. By leveraging sequential dependencies, these recommender systems enhance research efficiency, knowledge discovery, and business decision-making across various domains. Traditional sequential recommendation systems rely on historical user interactions to predict future preferences, but they often struggle with capturing complex contextual dependencies and adapting to dynamic user behaviors. Existing models primarily use predefined embeddings and handcrafted features, limiting their ability to generalize across diverse recommendation scenarios. To address these challenges, we propose LLM Enhanced Contextual Sequential Recommender (LLMSeqRec), which leverages Large Language Models (LLMs) to enrich sequential recommendations with deep contextual understanding and adaptive reasoning. By integrating LLM-generated embeddings and contextual representations, LLMSeqRec enhances user intent modeling, cold-start recommendations, and long-range dependencies in sequential data. Unlike traditional models that rely solely on structured interaction logs, LLMSeqRec dynamically interprets and augments sequences with semantic context, leading to more accurate and personalized recommendations. This fusion of LLM intelligence with sequential modeling enables a more scalable, adaptable, and explainable recommender system, bridging the gap between traditional sequence-based approaches and advanced AI-driven recommendations.

      Project Objectives
      Aligned with the vision of the 2025 Open Source Research Experience (OSRE), this project aims to develop an LLM-Enhanced Contextual Sequential Recommender (LLMSeqRec) to improve sequential recommendation accuracy across various scientific and business applications. Sequential recommender systems are widely used to analyze and predict patterns over time, assisting in fields such as biology, ecology, medicine, physics, engineering, environmental science, and e-commerce. However, traditional models often struggle with capturing complex contextual dependencies and adapting to dynamic user behaviors, as they primarily rely on vanilla sequential Id orders. To address these limitations, this project will leverage Large Language Models (LLMs) to enhance context-aware sequential recommendations by dynamically integrating LLM-generated embeddings and contextual representations. The core challenge lies in designing LLMSeqRec, a unified and scalable model capable of enriching user intent modeling, mitigating cold-start issues, and capturing long-range dependencies within sequential data. Unlike conventional systems that rely solely on structured interaction logs, LLMSeqRec will interpret and augment sequences with semantic context, resulting in more accurate, adaptable, and explainable recommendations. Below is an outline of the methodologies and models that will be developed in this project:

      Step 1: Data Preprocessing & Feature Creation: Develop a data processing pipeline to parse user’s sequential interaction behaviors into sequential data points for LLM-based embeddings and contextual sequential transformer modeling; Extract user behavior sequences, items’ metadata, and temporal patterns to create context-aware sequential representations for training, validation and testing; The data source can be from Amazon open public data or Movie Lense data set. The data points creation can follow SASRec (in the reference 1).

      Step 2: Model Development: Design and implement LLM-enhanced sequential recommendation models, integrating pretrained language models to augment user-item interactions with semantic context; Develop an adaptive mechanism to incorporate external contextual signals, such as product descriptions, reviews into the sequential recommendation process; The baseline model can be SASRec pytorch implementation.

      Step 3: Evaluation: : Benchmark LLMSeqRec against state-of-the-art sequential recommenders, evaluating on accuracy, NDCG and cold-start performance; Conduct ablation studies to analyze the impact of LLM-generated embeddings on recommendation quality; Optimize model inference speed and efficiency for real-time recommendation scenarios.

      Project Deliverables
      This project will deliver three components, software, model training, validation and performance evaluation and demo. The software which implements the above LLMSeqRec model will be hosted on the github repo as open-access repositories. The evaluation results and demo will be published along the github repo .

      LLMSeqRec
      Topics: LLM Enhanced Contextual Sequential Recommender
      Skills: Proficiency in Python, Pytorch, Github, Self-attention, Transformer
      Difficulty: Difficult
      Size: Large (350 hours)
      Mentor: Linsey Pang, Bin Dong
      References:
      Self-Attentive Sequential Recommendation (SASRec)
      BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer
      VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks
      Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
      Amazon Dataset: https://cseweb.ucsd.edu/~jmcauley/datasets.html#amazon_reviews
      Movie Lense Data: https://grouplens.org/datasets/movielens/


      ~~~~~~~~~~

      Advanced Canvas Support
      Topics: Backend Teaching Tools API
      Skills: software development, backend, rest api, data munging, http request inspection, python
      Difficulty: Moderate
      Size: Medium or Large (175 or 350 hours)
      Mentors: Eriq Augustine, Batuhan Salih, Lise Getoor
      The LMS Toolkit already has basic read-write support for core Canvas functionality (working with grades and assignments). However, there are still many more features that can be supported such as group management, quiz management, quiz statistics, and assignment statuses.

      The task for this project is to implement chose of set of advanced Canvas features to support (not limited to those features mentioned above), design an LMS-agnostic way to support those features, and implement those features. The flexibility in the features chosen to implement account for the variable size of this project.

      See Also:

      Repository for LMS Toolkit
      GitHub Issues
      Group Management,
      Quiz Management,
      Quiz Statistics,
      Assignment Statuses.

      ~~~~~~~~~~
      New LMS Support: Moodle
      Topics: Backend Teaching Tools API
      Skills: software development, backend, rest api, data munging, http request inspection, python
      Difficulty: Moderate
      Size: Large (350 hours)
      Mentors: Eriq Augustine, Batuhan Salih, Lise Getoor
      The goal of the LMS toolkit is to provide a single interface for all LMSs. It is a lofty goal, however there is currently only support for Canvas. Moodle is one of the more popular LMSs. Naturally, the LMS Toolkit wants to support Moodle as well. Moodle is open source, so adding support in the LMS Toolkit should not be too challenging.

      The task for this project is to add basic support for the Moodle LMS. It is not necessary to support all the same features that are supported for Canvas, but at least the core features of score and assignment management should be implemented.

      See Also:

      Repository for LMS Toolkit
      Moodle Wiki Page
      GitHub Issue

      ~~~~~~~~~~
      New LMS Support: Blackboard
      Topics: Backend Teaching Tools API
      Skills: software development, backend, rest api, data munging, http request inspection, python
      Difficulty: Challenging
      Size: Large (350 hours)
      Mentors: Eriq Augustine, Batuhan Salih, Lise Getoor
      The goal of the LMS toolkit is to provide a single interface for all LMSs. It is a lofty goal, however there is currently only support for Canvas. Blackboard (also called “Blackboard Learn”) is one of the more popular LMSs. Naturally, the LMS Toolkit wants to support Blackboard as well. However, a challenge in supporting Blackboard is that it is not open source (unlike Canvas). Therefore, support and testing on Blackboard may be very challenging.

      The task for this project is to add basic support for the Blackboard LMS. It is not necessary to support all the same features that are supported for Canvas, but at least the core features of score and assignment management should be implemented. The closed nature of Blackboard makes this a challenging and uncertain project.

      See Also:

      Repository for LMS Toolkit
      Blackboard Wiki Page
      GitHub Issue

      ~~~~~~~~~~
      New LMS Support: Brightspace
      Topics: Backend Teaching Tools API
      Skills: software development, backend, rest api, data munging, http request inspection, python
      Difficulty: Challenging
      Size: Large (350 hours)
      Mentors: Eriq Augustine, Batuhan Salih, Lise Getoor
      The goal of the LMS toolkit is to provide a single interface for all LMSs. It is a lofty goal, however there is currently only support for Canvas. D2L Brightspace is one of the more popular LMSs. Naturally, the LMS Toolkit wants to support Brightspace as well. However, a challenge in supporting Brightspace is that it is not open source (unlike Canvas). Therefore, support and testing on Brightspace may be very challenging.

      The task for this project is to add basic support for the Brightspace LMS. It is not necessary to support all the same features that are supported for Canvas, but at least the core features of score and assignment management should be implemented. The closed nature of Brightspace makes this a challenging and uncertain project.

      See Also:

      Repository for LMS Toolkit
      Brightspace Wiki Page
      GitHub Issue

      ~~~~~~~~~~
      Testing / CI Infrastructure
      Topics: Backend Teaching Tools Testing CI
      Skills: software development, backend, testing, ci, docker
      Difficulty: Challenging
      Size: Large (350 hours)
      Mentors: Eriq Augustine, Batuhan Salih, Lise Getoor
      The goal of the LMS toolkit is to provide a single interface for all LMSs. This means that our system must communicate with several different (the LMSs), each with their own systems, data patterns, versions, and quirks. Testing will be essential to ensure that our tools keep working as the different LMSs evolve and update. The LMS Toolkit currently tests with Canvas by mocking API responses. However, this tactic does not scale well with multiple LMSs (and multiple versions of each system). A more scalable approach would be to have test instances of the different LMSs that our testing infrastructure can interact with both interactively and in continuous integration (CI).

      The task for this project is to create testing infrastructure that connects to test instances of different LMS systems (e.g., Canvas). This task does not require that all the LMSs in this document are used, but the testing infrastructure should be robust enough to support them all. The open source LMSs (Canvas and Moodle) will likely be much easier to setup than the others, and should be targeted first. We should be able to run tests locally as well as in CI, and will likely heavily use Docker containers.

      See Also:

      Repository for LMS Toolkit
      GitHub Issue
      Mocked API Responses.

      ~~~~~~~~~~

      Medicinal Language Embeddings
      Topics: Large Language Models NLP Embeddings Medicine
      Skills: Python, JavaScript, Data Science, Technical Communication
      Difficulty: Challenging
      Size: Large (350 hours)
      Mentors: Oskar Elek, Kiran Deol
      This project aims to refine and enhance Mediglot, a web application for visualizing 3D medicinal embeddings, which extends the Polyglot app and leverages the PolyPhy toolkit for network-inspired data science. Mediglot currently enables users to explore high-dimensional vector representations of medicines (derived from their salt compositions) in a 3D space using UMAP, as well as analyze similarity through the innovative Monte-Carlo Physarum Machine (MCPM) metric. Unlike traditional language data, medicinal embeddings do not have an inherent sequential structure. Instead, we must work with the salt compositions of each medicine to create embeddings that are faithful to the intended purpose of each medicine.

      This year, we would like to focus on exploring and integrating state-of-the-art AI techniques and algorithms to improve Mediglot’s clustering capabilities and its representation of medicinal data in 3D. The contributor will experiment with advanced large language models (LLMs) and cutting-edge AI methods to develop innovative approaches for refining clustering and extracting deeper insights from medicinal embeddings. Beyond LLMs, we would like to experiment with more traditional language processing methods to design novel embedding procedures. Additionally, we would like to experiment with other similarity metrics. While the similarity of two medicines depends on the initial embedding, we would like to examine the effects of different metrics on the kinds of insights a user can extract. Finally, the contributor is expected to evaluate and compare different algorithms for dimensionality reduction to enhance the faithfulness of the visualization and its interpretability.

      The ideal contributor for this project has experience with Python (and common scientific toolkits such as NumPy, Pandas, SciPy). They will also need some experience with JavaScript and web development (MediGlot is distributed as a vanilla JS web app). Knowledge of embedding techniques for language processing is highly recommended.

      Specific tasks:

      Closely work with the mentors to understand the context of the project and its detailed requirements in preparation for the proposal.
      Become acquainted with the tooling (PolyPhy, PolyGlot, Mediglot) prior to the start of the project period.
      Explore different embedding techniques for medicinal data (including implementing novel embedding procedures).
      Explore different dimensionality reduction techniques, with a focus on faithful visualizations.
      Document the process and resulting findings in a publicly available report.
      
      ~~~~~~~~~~
      
      Enhancing PolyPhy Web Application
      Topics: Web Development UI/UX Design Full Stack Development JavaScript Next.js Node.js
      Skills: Full Stack Web Development, UI/UX Design, JavaScript, Next.js, Node.js, Technical Communication
      Difficulty: Challenging
      Size: Medium (175 hours)
      Mentors: Oskar Elek, Kiran Deol
      This project aims to revamp and enhance the PolyPhy web platform to better support contributors, users, and researchers. The goal is to optimize the website’s UI/UX, improve its performance, and integrate Mediglot to provide users with a seamless experience in visualizing both general network structures and 3D medicinal embeddings.

      The contributor will be responsible for improving the website’s overall look, feel, and functionality, ensuring a smooth and engaging experience for both contributors and end-users. This includes addressing front-end and back-end challenges, optimizing the platform for better accessibility, and ensuring seamless integration with Mediglot.

      The ideal candidate should have experience in full-stack web development, particularly with Next.js, JavaScript, and Node.js, and should be familiar with UI/UX design principles. A strong ability to communicate effectively, both in writing and through code, is essential for this role.

      Specific tasks:

      Collaborate with mentors to understand the project’s goals and the specific requirements for the website improvements.
      UI/UX Redesign:
      Redesign and enhance the website’s navigation, layout, and visual elements to create an intuitive and visually engaging experience.
      Improve mobile responsiveness for broader accessibility across devices.
      Website Performance & Stability:
      Identify and resolve performance bottlenecks, bugs, or issues affecting speed, stability, and usability.
      Mediglot Integration:
      Integrate the Mediglot web application with PolyPhy, ensuring seamless functionality and a unified user experience for visualizing medicinal data alongside general network reconstructions.
      Documentation:
      Document the development process, challenges, and solutions in a clear and organized manner, ensuring transparent collaboration with mentors and the community.


      ~~~~~~~~~~

      Improving Code Quality in OpenROAD
      Topics: Coding Best Practices in C++, Code Quality Tooling, Continuous Integration
      Skills: C++
      Difficulty: Medium
      Size: Medium (175 hours)
      Mentors: Matt Liberty & Arthur Koucher
      OpenROAD is a large and complex program. This project is to improve the code quality through resolving issues flagged by tools like Coverity and clang-tidy. New tools like the clang sanitizers ASAN/TSAN/UBSAN should also be set up and integrated with the Jenkins CI.

      ~~~~~~~~~~
      
      GUI Testing in OpenROAD
      Topics: Testing, Continuous Integration
      Skills: C++, Qt
      Difficulty: Medium
      Size: Large (350 hours)
      Mentors: Matt Liberty & Peter Gadfort
      The OpenROAD GUI is a crucial set of functionality for users to see and investigate their design. GUI testing is specialized and rather different from standard unit testing. The GUI therefore needs improvements to its testing to cover both interaction and rendering. The GUI uses the Qt framework. An open-source testing tool like https://github.com/faaxm/spix will be set up and key tests developed. This will provide the framework for all future testing.

      ~~~~~~~~~~
      
      Rectilinear Floorplans in OpenROAD
      Topics: Electronic Design Automation, Algorithms
      Skills: C++, data structures and algorithms
      Difficulty: Medium
      Size: Large (350 hours)
      Mentors: Eder Monteiro & Augusto Berndt
      OpenROAD supports block floorplans that are rectangular in shape. Some designs may require more complex shapes to fit. This project extends the tool to support rectilinear polygon shapes as floorplans. This will require upgrading data structures and algorithms in various parts of OpenROAD including floor plan generation, pin placement, and global placement.

      ~~~~~~~~~~
      
      LEF Reader and Database Enhancements in OpenROAD
      Topics: Electronic Design Automation, Database, Parsing
      Skills: Boost Spirit parsers, Database, C++
      Difficulty: Medium
      Size: Medium (175 hours)
      Mentors: Osama Hammad & Ethan Mahintorabi
      LEF (Library Exchange Format) is a standard format for describing physical design rules for integrated circuits. OpenROAD has support for many constructs but some newer ones for advanced process nodes are not supported. This project is to support parsing such information and storing in the OpenDB for use by the rest of the tool.

      ~~~~~~~~~~
      
      ORAssistant - LLM Data Engineering and Testing
      Topics: Large Language Model, Machine Learning, Data Engineering, Model Deployment, Testing, Full-Stack Development
      Skills: large language model engineering, database, evaluation, CI/CD, open-source or related software development, full-stack
      Difficulty: Medium
      Size: Medium (175 hours)
      Mentor: Jack Luar & Palaniappan R
      This project is aimed at enhancing robustness and accuracy for OR Assistant, the conversational assistant for OpenROAD through comprehensive testing and evaluation. You will work with members of the OpenROAD team and other researchers to enhance the existing dataset to cover a wide range of use cases to deliver accurate responses more efficiently. This project will focus on data engineering and benchmarking and you will collaborate on a project on the LLM model engineering. Tasks include: creating evaluation pipelines, building databases to gather feedback, improving CI/CD, writing documentation, and improving the backend and frontend services as needed (non-exhaustive). You will gain valuable experience and skills in understanding chip design flows and applications. Open to proposals from all levels of ML practitioners.

      ~~~~~~~~~~
      
      ORAssistant - LLM Model Engineering
      Topics: Large Language Model, Machine Learning, Model Architecture, Model Deployment
      Skills: large language model engineering, prompt engineering, fine-tuning
      Difficulty: Medium
      Size: Medium (175 hours)
      Mentor: Jack Luar & Palaniappan R
      This project is aimed at enhancing robustness and accuracy for OR Assistant, the conversational assistant for OpenROAD through enhanced model architectures. You will work with members of the OpenROAD team and other researchers to explore alternate architectures beyond the existing RAG-based implementation. This project will focus on improving reliability and accuracy of the existing model architecture. You will collaborate on a tandem project on data engineering for OR assistant. Tasks include: reviewing and understanding the state-of-the-art in retrieval augmented generation, implementing best practices, caching prompts, improving relevance and accuracy metrics, writing documentation and improving the backend and frontend services as needed (non-exhaustive). You will gain valuable experience and skills in understanding chip design flows and applications. Open to proposals from all levels of ML practitioners.

      ~~~~~~~~~~

      Canvas Import
      Topics: Backend Teaching Tools API
      Skills: software development, backend, rest api, data munging, http request inspection, python
      Difficulty: Moderate
      Size: Medium (175 hours)
      Mentors: Eriq Augustine, Lucas Ellenberger, Lise Getoor
      The Quiz Composer houses quizzes and quiz questions in a simple and unambiguous format based on JSON and Markdown (specifically, the CommonMark specification). This allows the Quiz Composer to unambiguously create versions of the same quiz in many different formats. However, creating a quiz in the Quiz Composer format can be a daunting task for those not familiar with JSON or Markdown. Instead, it would be easier for people to import quizzes from another format into the Quiz Composer format, and then edit it as they see fit. Unfortunately not all other quiz formats, namely Canvas in this case, are unambiguous.

      The task for this project is to implement the functionality of importing quizzes from Canvas to the standard Quiz Composer format. The unambiguous nature of Canvas quizzes makes this task non-trivial, and adds an additional element of design decisions to this task. It will be impossible to import quizzes 100% correctly, but we want to be able to get close enough that most people can import their quizzes without issue.

      See Also:

      Repository for Quiz Composer
      GitHub Issue

      ~~~~~~~~~~
      Google Forms Export
      Topics: Backend Teaching Tools API
      Skills: software development, backend, rest api, data munging, python
      Difficulty: Moderate
      Size: Medium (175 hours)
      Mentors: Eriq Augustine, Lucas Ellenberger, Lise Getoor
      The Quiz Composer can export quizzes to many different formats, each with a varying level of interactivity and feature support. For example, quizzes can be exported to PDFs which will be printed and the students will just write down their answers to be checked in the future. Quizzes can also be exported to interactive platforms like Canvas where students can enter answers that may be automatically checked with feedback immediately provided to the student. On potential platform with functionality somewhere between the above two examples is Google Forms. “Forms” (an entity on Google Forms) can be something like a survey or (as of more recently) a quiz.

      The task for this project is to add support for exporting quizzes from the Quiz Composer to Google Forms. There is a large overlap in the quiz features supported in Canvas (which the Quiz Composer already supports) and Google Forms, so most settings should be fairly straightforward. There may be some design work around deciding what features are specific to one quiz platform and what features can be abstracted to work across several platforms.

      See Also:

      Repository for Quiz Composer
      GitHub Issue

      ~~~~~~~~~~
      Template Questions
      Topics: Backend Teaching Tools API
      Skills: software development, backend, data munging, python
      Difficulty: Moderate-Challenging
      Size: Large (350 hours)
      Mentors: Eriq Augustine, Lucas Ellenberger, Lise Getoor
      Questions in the Quiz Composer are described using JSON and Markdown files which contain the question prompt, possible answers, and the correct answer. (Of course there are many differ question types, each with different semantics and requirements.) However, a limitation of this is that each question is always the same. You can have multiple copies of a question with slightly different prompts, numbers, and answers; but you are still limited to each question being static and unchanging. It would be useful to have “template questions” that can dynamically create static questions from a template and collection of replacement data.

      The task for this project is to add support for the “template questions” discussed above. Much of the high-level design work for this issue has already been completed. But there is still the implementation and low-level design decision left to do.

      See Also:

      Repository for Quiz Composer
      GitHub Issue


      ~~~~~~~~~~


      RAG-ST: Retrieval-Augmented Generation for Spatial Transcriptomics
      Ziheng Duan
      Jan 15, 2025

      Topics: bioinformatics, spatial transcriptomics, gene expression generation, retrieval-augmented generation, large models
      Skills:
      Programming Languages:
      Proficient in Python, and familiarity with machine learning libraries such as PyTorch.
      Data Analysis:
      Experience with spatial transcriptomics datasets and statistical modeling.
      Machine Learning:
      Understanding of vision models, retrieval-based systems, and MLP architectures.
      Bioinformatics Knowledge (preferred):
      Familiarity with scRNA-seq data integration and computational biology tools.
      Difficulty: Advanced
      Size: Large (350 hours). Given the scope of integrating RAG models, building a robust database, and ensuring interpretable predictions, this project involves substantial computational and data preparation work.
      Mentors: Ziheng Duan (contact person)
      Project Idea Description
      Spatial transcriptomics (ST) is a revolutionary technology that provides spatially resolved gene expression measurements, enabling researchers to study cellular behaviour within tissues with unprecedented detail. This technology has transformed our understanding of complex biological systems, such as disease progression, tissue development, and cellular heterogeneity. However, the widespread adoption of ST is limited by its high cost and technical requirements.

      Histology imaging, on the other hand, is far more accessible and cost-effective. If gene expression could be accurately predicted from histology images, it would enable researchers to leverage these abundant images for high-resolution biological insights without the need for expensive spatial transcriptomics experiments. This task has immense potential to democratize spatial transcriptomics research and significantly reduce costs.

      Challenges in Current Approaches
      Current methods for predicting gene expression from histology images typically involve:

      Using large vision models to encode histology image patches into embeddings.
      Employing Multi-Layer Perceptrons (MLPs) to map these embeddings to gene expression profiles.
      While these approaches have shown promise, they suffer from two critical limitations:

      Accuracy: The MLP-based mappings often fail to fully capture the biological complexity encoded in the histology images, leading to suboptimal predictions.
      Interpretability: These models act as black boxes, providing no insight into the underlying biological rationale for the predictions. Researchers cannot determine why a specific gene expression profile was generated, limiting trust and utility in biological contexts.
      Project Motivation
      To overcome these limitations, this project proposes a novel Retrieval-Augmented Generation (RAG) framework for spatial transcriptomics. Instead of relying solely on black-box MLPs, RAG-ST will:

      Retrieve relevant examples from a curated database of paired histology images, scRNA-seq data, and gene expression profiles.
      Use these retrieved examples to inform and enhance the generation process, resulting in predictions that are both more accurate and biologically interpretable.
      This approach not only grounds predictions in biologically meaningful data but also provides transparency by revealing which database entries influenced the results.

      Project Objectives
      Database Construction:
      Curate a large and diverse database of histology images paired with scRNA-seq and gene expression data.
      Model Development:
      Develop a RAG framework combining vision-based encoders and retrieval-enhanced generation techniques.
      Incorporate interpretability mechanisms to link predicted gene expressions to retrieved examples.
      Evaluation and Benchmarking:
      Assess RAG-ST against state-of-the-art methods, focusing on accuracy, interpretability, and biological validity.
      Project Deliverables
      Curated Database:
      A publicly available, well-documented database of histology images and gene expression profiles.
      RAG-ST Framework:
      An open-source Python implementation of the RAG-ST model, with retrieval, generation, and visualization tools.
      Benchmark Results:
      Comprehensive evaluations demonstrating the benefits of RAG-ST over conventional pipelines.
      Documentation and Tutorials:
      User-friendly guides to facilitate adoption by the spatial transcriptomics research community.
      Impact
      By integrating retrieval-augmented generation with large models, RAG-ST represents a paradigm shift in spatial transcriptomics. It offers a cost-effective, accurate, and interpretable solution for gene expression prediction, democratizing access to high-quality spatial transcriptomic insights and fostering advancements in biological research.



      
      ~~~~~~~~~~
      ReasonWorld: Real-World Reasoning with a Long-Term World Model
      A world model is essentially an internal representation of an environment that an AI system would construct based on external information to plan, reason, and interpret its surroundings. It stores the system’s understanding of relevant objects, spatial relationships, and/or states in the environment. Recent augmented reality (AR) and wearable technologies like Meta Aria glasses provide an opportunity to gather rich information from the real world in the form of vision, audio, and spatial data. Along with this, large language (LLM), vision language models (VLMs), and general machine learning algorithms have enabled nuanced understanding and processing of multimodal inputs that can label, summarize, and analyze experiences.

      With ReasonWorld, we aim to utilize these technologies to enable advanced reasoning about important objects/events/spaces in real-world environments in a structured manner. With the help of wearable AR technology, the system would be able to capture real-world multimodal data. We aim to utilize this information to create a long-memory modeling toolkit that would support features like:

      Longitudinal and structured data logging: Capture and storing of multimodal data (image, video, audio, location coordinates etc.)
      Semantic summarization: Automatic scene labeling via LLMs/VLMs to identify key elements in the surroundings
      Efficient retrieval: For querying and revisiting past experiences and answering questions like “Where have I seen this painting before?”
      Adaptability: Continuously refining and understanding the environment and/or relationships between objects/locations.
      Adaptive memory prioritization: Where the pipeline can assess the contextual significance of the captured data and retrieve those that are the most significant. The model retains meaningful, structured representations rather than raw, unfiltered data.
      This real-world reasoning framework with a long-term world model can function as a structured search engine for important objects and spaces, enabling:

      Recognizing and tracking significant objects, locations, and events
      Supporting spatial understanding and contextual analysis
      Facilitating structured documentation of environments and changes over time
      Alignment with Summer of Reproducibility:
      Core pipeline for AR data ingestion, event segmentation, summarization, and indexing (knowledge graph or vector database) would be made open-source.
      Clear documentation of each module and how they collaborate with one another
      The project could be tested with standardized datasets, simulated environments as well as controlled real-world scenarios, promoting reproducibility
      Opportunities for Innovation - A transparent, modular approach invites a broad community to propose novel expansions
      Specific Tasks:
      A pipeline for real-time/batch ingestion of data with the wearable AR device and cleaning
      Have an event segmentation module to classify whether the current object/event is contextually significant, filtering out the less relevant observations.
      Have VLMs/LLMs summarize the events with the vision/audio/location data to be stored and retrieved later by structured data structures like knowledge graph, vector databases etc.
      Storage optimization with prioritizing important objects and spaces, optimizing storage based on contextual significance and frequency of access.
      Implement key information retrieval mechanisms
      Ensure reproducibility by providing datasets and scripts
      ReasonWorld
      Topics: Augmented reality Multimodal learning Computer vision for AR LLM/VLM Efficient data indexing
      Skills: Machine Learning and AI, Augmented Reality and Hardware integration, Data Engineering & Storage Optimization
      Difficulty: Hard
      Size: Large (350 hours)
      Mentors: James Davis, Alex Pang


      ~~~~~~~~~~



      ReIDMM: Re-identifying Multiple Objects across Multiple Streams
      Bin Dong, Linsey Pang
      Feb 6, 2025

      Project Description
      Re-identifying multiple objects across multiple streams (ReIDMM) is essential in scientific research and various industries. It involves tracking and analyzing entities across different viewpoints or time frames. In astronomy, ReIDMM helps track celestial objects like asteroids and space debris using multiple observatories. In biology and ecology, it enables the identification of animals across different camera traps and aids in tracking microscopic organisms in laboratory studies. In physics and engineering, it is used for tracking particles in high-energy physics experiments, monitoring structural changes in materials, and identifying robots or drones in lab automation. Beyond scientific applications, ReIDMM plays a critical role in industries such as retail, where it tracks customer behavior across multiple stores and improves sales and prevents theft. In smart cities, it supports traffic monitoring by identifying vehicles across intersections for improved traffic flow management. In manufacturing, it enables supply chain tracking by locating packages across conveyor belts and warehouse cameras. In autonomous systems, ReIDMM enhances multi-camera sensor fusion and warehouse robotics by identifying pedestrians, obstacles, and objects across different camera views.

      Project Objectives
      Aligned with the vision of the 2025 Open Source Research Experience (OSRE), this project aims to develop an open-source algorithm for multiple-object re-identification across diverse open-source data streams. As highlighted earlier, this method is expected to have wide-ranging applications in both scientific research and industry. Utilizing an open-source dataset, our focus will be on re-identifying common objects such as vehicles and pedestrians. The primary challenge lies in designing a unified algorithm, ReIDMM, capable of performing robust multi-object re-identification across multiple streams. Users will be able to tag any object as a target in a video or image for tracking across streams. Below is an outline of the algorithms to be developed in this project:

      Step 1: Target Object Identification: Randomly select a target object from an image or video using object detection models such as YOLOv7. These models detect objects by generating bounding boxes around them. Target objects could include vehicles, pedestrians, animals, or other recognizable entities. This step ensures an initial object of interest is chosen for re-identification.

      Step 2: Feature Extraction and Embedding: Once the target object is identified, extract relevant features such as bounding box coordinates, timestamp, location metadata (if available), and visual characteristics. A multimodal embedding approach is used, where these features are transformed into a numerical representation (embedding vector) that captures the object’s unique identity. This allows for efficient comparison across different images or videos.

      Step 3: Searching and Matching: To find the target object in other images or videos: (1) Extract embeddings of all objects detected in the other images/videos; (2) Compute similarity between the target object’s embedding and those of all detected objects using metrics like cosine similarity or Euclidean distance. (3) Rank objects by similarity, returning the most probable matches. The highest-ranked results are likely to be the same object observed from different angles, lighting conditions, or time frames.

      Project Deliverables
      This project will deliver three things, software, evaluation results and demo. The software which implements the above ReIDMM algorithm will be hosted on the github repo as open-access repositories. The evaluation results and demo will be published along the github repo.

      ReIDMM
      Topics: ReIDMM: Re-identifying Multiple Objects across Multiple Streams`
      Skills: Proficient in Python, Experience with images processing, machine learning
      Difficulty: Difficult
      Size: Large (350 hours)
      Mentor: Bin Dong, Linsey Pang
      Reference:
      multiple-object-tracking-using-person
      Dataset: Vehicle re-identification dataset and paper and Person re-identification data and paper


      ~~~~~~~~~~



      3D Driving Scenarios
      Topics: Autonomous Driving 3D modeling
      Skills: Python; basic vector geometry
      Difficulty: Moderate
      Size: Medium or Large (175 or 350 hours)
      Mentors: Daniel Fremont, Eric Vin
      Scenic scenarios written to test autonomous vehicles use the driving domain, a Scenic library defining driving-specific concepts including cars, pedestrians, roads, lanes, and intersections. The library extracts information about road networks, such as the shapes of lanes, from files in the standard OpenDRIVE format. Currently, we only generate 2D polygons for lanes, throwing away 3D information. While this suffices for many driving scenarios, it means we cannot properly model overpasses (the roads appear to overlap) or test driving scenarios where 3D geometry is important, such as hilly terrain.

      The goals of this project are to extend our road network library to generate 3D meshes (instead of 2D polygons) for roads, write new Scenic scenarios which use this new capability, and (if time allows) test autonomous driving software using them.

      ~~~~~~~~~~
      
      A Library for Aviation Scenarios
      Topics: Autonomous Aircraft
      Skills: Python; ideally some aviation experience
      Difficulty: Moderate
      Size: Medium or Large (175 or 350 hours)
      Mentors: Daniel Fremont, Eric Vin
      We have used Scenic to find, diagnose, and fix bugs in software for autonomous aircraft: in particular, this paper studied a neural network-based automated taxiing system using the X-Plane flight simulator. We also have prototype interfaces to AirSim and Microsoft Flight Simulator. However, our experiments so far have mainly focused on simple scenarios involving a single aircraft.

      The goal of this project is to develop an aviation library for Scenic (like the driving domain mentioned in the previous project) which will allow users to create complex aviation scenarios in a simulator-agnostic way. The library would define concepts for aircraft, flight paths, weather, etc. and allow importing real-world data about these. The student would demonstrate the library’s functionality by writing some example scenarios and testing either simple aircraft controllers or (if time allows) ML-based flight software.

      ~~~~~~~~~~
      
      Interfacing Scenic to New Simulators
      Topics: Simulation Autonomous Driving Robotics LLMs
      Skills: Python
      Difficulty: Moderate
      Size: Medium or Large (175 or 350 hours)
      Mentors: Daniel Fremont, Eric Vin
      Scenic is designed to be easily-interfaced to new simulators. Depending on student interest, we could pick a simulator which would open up new kinds of applications for Scenic and write an interface for it. Some possibilities include:

      The AWSIM driving simulator (to allow testing the Autoware open-source autonomous driving software stack)
      The CoppeliaSim robotics simulator
      NVIDIA’s Cosmos, an LLM which generates videos from text prompts
      NVIDIA’s Omniverse (various applications, e.g. simulating virtual factories)
      Various simulators for which we have prototype interfaces that could be generalized and made more usable, including MuJoCo and Isaac Sim
      The goal of the project would be to create an interface between Scenic and the new simulator and write scenarios demonstrating it. If time allows, we could do a case study on a realistic system for publication at an academic conference.

      ~~~~~~~~~~
      
      Optimizing and Parallelizing Scenic
      Topics: Optimization Parallelization
      Skills: Python
      Difficulty: Moderate
      Size: Medium or Large (175 or 350 hours)
      Mentors: Daniel Fremont, Eric Vin
      Large-scale testing with Scenic, when one wants to generate thousands of simulations, can be very computationally-expensive. In some cases, the bottleneck is the simulator, and being able to easily run multiple simulations in parallel would greatly increase scalability. In others, Scenic itself spends substantial time trying to sample scenarios satisfying all the given constraints.

      This project would explore a variety of approaches to speeding up scene and simulation generation in Scenic. Some possibilities include:

      Parallelizing scene generation and simulation (e.g. using Ray)
      Systematically profiling real-world Scenic programs to characterize the main bottlenecks and propose optimizations
      JIT compiling Scenic’s internal sampling code (e.g. using Numba)
      
      ~~~~~~~~~~
      Improvements and Infrastructure for the VerifAI Toolkit
      Topics: DevOps Documentation APIs
      Skills: Python
      Difficulty: Easy
      Size: Medium or Large (175 or 350 hours)
      Mentors: Daniel Fremont, Eric Vin
      VerifAI is a toolkit for design and analysis of AI-based systems that builds on top of Scenic. It adds among other features the ability to perform falsification, intelligently searching for scenarios that will cause a system to behave in an undesirable way.

      The goal of this project is to improve VerifAI’s development infrastructure, documentation, and ease of use, which are currently relatively poor compared to Scenic. Specific tasks could include:

      Setting up continuous integration (CI) on GitHub
      Creating processes to help users/developers submit issues and PRs and deal with them in a timely manner
      Writing more documentation, including tutorials and examples (not only for end users of VerifAI but those wanting to develop custom falsification components, for example)
      Refactoring VerifAI’s API to make it easier to use and extend


      ~~~~~~~~~~

      Seam / Kubernetes Resource Provisioning and Management
      The proposed work includes expanding the Python library to support comprehensive Kubernetes resource provisioning, network management, and virtual machine provisioning using KubeVirt. Students will enhance the current implementation to allow users to define resource limits, CPU/GPU quotas, and network policies. They will also integrate with ESnet SENSE to facilitate L2 networking, and explore the use of Prometheus and Grafana for real-time performance monitoring and metrics collection.

      Topics: Kubernetes, Python, Cloud Computing, Networking, Programmable Networking, Monitoring, CI/CD
      Skills: Python, Kubernetes, P4 programming, KubeVirt, ESnet SENSE, Docker, GitLab CI/CD, Prometheus, Grafana, PostgreSQL, Flask
      Difficulty: Hard
      Size: Large (350 hours)
      Mentors: Mohammad Firas Sada

      ~~~~~~~~~~
      Seam / Full-Stack Web Development and Dashboard
      The proposed work includes building a Flask-based web dashboard using Bootstrap for UI, integrating it with the Python library to enable users to easily provision resources, monitor network performance, and track resource usage in real-time. The dashboard will support role-based access control (RBAC), allowing for secure multi-user management. Students will also integrate PostgreSQL for managing and storing configurations, logs, and performance metrics.

      Topics: Full-Stack Web Development, Flask, Bootstrap, PostgreSQL, Kubernetes, Monitoring, DevOps
      Skills: Web Development, Flask, Bootstrap, PostgreSQL, API Development, Kubernetes
      Difficulty: Medium to Hard
      Size: Large (350 hours)
      Mentors: Mohammad Firas Sada

      ~~~~~~~~~~
      Seam / CI/CD and GitLab Integration
      The proposed work includes setting up GitLab CI/CD pipelines for automated testing, deployment, and maintenance of the Python library, Kubernetes resources, and web dashboard. Students will automate the deployment of P4 programs, Kubernetes deployments, and networking configurations. They will also focus on unit testing, integration testing, and the automation of benchmarking experiments to ensure reproducibility of results.

      Topics: CI/CD, GitLab, Python, Kubernetes, DevOps, Testing, Automation
      Skills: GitLab CI/CD, Python, Kubernetes, Docker, Automation, Testing, Benchmarking
      Difficulty: Medium to Hard
      Size: Large (350 hours)
      Mentors: Mohammad Firas Sada

      ~~~~~~~~~~
      Seam / Networking & SmartNIC Programming
      The proposed work includes writing P4 programs to control network traffic flow, enforce network security policies, and optimize data transfer across the Kubernetes cluster. Students will gain experience with SmartNICs (Xilinx Alveo U55C, SN1000, NVIDIA Bluefield 2) and Tofino switches, using P4 to write network policies and integrate with the Kubernetes network layer (Multus, Calico). Students will also explore gRPC APIs for dynamically adjusting network policies and provisioning virtual network interfaces in real time.

      Topics: Networking, P4 Programming, SmartNICs, Kubernetes Networking, Cloud Computing
      Skills: P4, Networking, SmartNICs, Kubernetes Networking, Multus, Calico, gRPC
      Difficulty: Hard
      Size: Large (350 hours)
      Mentors: Mohammad Firas Sada

      ~~~~~~~~~~

      Smart Batching for Large Language Models
      Daniel Wong, Luanzheng "Lenny" Guo
      Feb 9, 2025

      Sequence tokenization is a crucial step during Large Language Model training, fine-tuning, and inference. User prompts and training data are tokenized and zero-padded before being fed to the model in batches. This process allows models to interpret human language by breaking down complex sentences into simple token units that are numerically represented in a token set. However, the process of sequence padding for maintaining batch dimensions can introduce unnecessary overhead if batching is not properly done.

      In this project, we introduce Smart Batching, where we dynamically batch sequences in a fine-tuning dataset by their respective lengths. With this method, we aim to minimize the amount of zero padding required during sequence batching, which can result in improved and efficient fine-tuning and inference speeds. We also analyze this method with other commonly used batching practices (Longest Sequence, Random Shuffling) on valuable metrics such as runtime and model accuracy.

      Project Title
      Topics: Large Language Models Fine-Tuning AI Transformers
      Skills: Python, Pytorch, Large Language Models
      Difficulty: Moderate
      Size: Large (350 hours)
      Mentor: [Daniel Wong]Daniel Wong, [Luanzheng “Lenny” Guo]Luanzheng "Lenny" Guo
      Project Tasks and Milestones
      Implement an open source smart batching framework based on HuggingFace to allow for dynamically grouping sequences of similar token lengths into batches
      Analyze runtime, padding, and model accuracy with smart batching and other commonly used batching practices
      Apply smart batching with distributed fine-tuning and observe large language model outputs


      ~~~~~~~~~~

      UC Open Source Repository Browser
      Juanita Gomez
      Mar 3, 2025

      The University of California Open Source Repository Browser (UC ORB) is a discovery tool designed to map and classify open source projects across the UC system. This project is a collaboration with the UC Network of Open Source Program Offices (OSPOs), which brings together six UC campuses (Santa Cruz, Berkeley, Davis, Los Angeles, Santa Barbara, and San Diego) to support open source research, promote sustainability, and establish best practices within academic environments.

      By providing a centralized platform, UC ORB enhances the visibility of UC’s open source contributions, fosters collaboration among researchers and developers, and serves as a model for other institutions aiming to improve open source discovery and sustainability.

      This project focuses on building the web application for UC ORB, which will serve as the primary interface for users to explore and interact with UC’s open source projects. The student will work on developing a clean, user-friendly, and scalable web application.

      Develop the UC ORB Application
      Topics: Web development
      Skills: Experience in Python and at least one Python-based web framework (e.g., Flask, Django, FastAPI), experience with front-end technologies (React, HTML, CSS, JavaScript), familiarity with Git and collaborative development workflows, familiarity with database interaction (SQL).
      Difficulty: Moderate
      Size: Large (350 hours)
      Mentors: Juanita Gomez
      Develop a web application that serves as the front-end interface for the UC ORB. The application will allow users to browse, search, and explore open source projects across the UC system. The project will involve integrating with the repository database to fetch and display repository data, designing an intuitive user interface, and ensuring the application is scalable and maintainable.

      Specific Tasks:

      Choose an appropriate Python-based web framework (e.g., Flask, Django, or FastAPI) for the backend and set up the basic structure of the application.
      Develop a responsive and user-friendly front-end interface ensuring that it is accessible and works well on both desktop and mobile devices.
      Add search functionality to allow users to find projects by keywords, tags, or other metadata.
      Implement filtering options to narrow down search results (e.g., by campus, topic, or programming language).
      Deploy the application to a cloud platform (e.g., AWS, or Google Cloud) or GitHub Pages (GitHub.io) for public access.
      Create developer documentation that explains the application’s architecture, setup instructions, and contribution guidelines.
      Write a short user manual to help end-users browse and use the web application effectively.


      ~~~~~~~~~~


      Vector Embeddings Dataset
      jayjeetc
      Feb 11, 2025
      Vector Embeddings Dataset
      Topics: Vector Embeddings LLMs Transformers
      Skills: software development, apis, scripting, python
      Difficulty: Moderate
      Size: Medium or Large (175 or 350 hours)
      Mentors: Jayjeet Chakraborty
      To benchmark vector search algorithms (aka ANN algorithms), there are several datasets available but none of them represent actual real world workloads. This is because they usually have small vectors of only a few hundred dimensions. For vector search experiments to represent real world workloads, we want to have datasets with several thousand dimensions like what is generated by OpenAIs text-embedding models. This project aims to create a dataset with 1B embeddings from a wikipedia dataset using open source models. Ideally, we will have 3 versions of this dataset, with 1024, 4096, and 8192 sized embeddings to start with.


      ~~~~~~~~~~

      Improving and Optimizing Data Processing Pipeline for More Accurate Soil Moisture Measurements
      Topics: Digital Signal Processing Machine Learning
      Skills: C/embedded, signal processing, machine learning, MATLAB (optional)
      Difficulty: Moderate
      Size: Medium (175 hours)
      Mentors: Colleen Josephson, Eric Vetha
      Enhance the accuracy of soil moisture measurements by refining the data processing pipeline.

      Tasks:

      Develop and test algorithms for noise reduction and signal improvement.
      Implement advanced filtering and statistical techniques to improve measurement precision.
      Validate improvements using real-world field data.
      Translate algorithms into embedded to be implemented in real-time embedded hardware.
      
      ~~~~~~~~~~
      
      Improving Backscatter Tag PCB
      Topics: Hardware Design Signal Processing
      Skills: PCB design, RF knowledge
      Difficulty: Moderate
      Size: Medium (175 hours)
      Mentors: Colleen Josephson, Eric Vetha
      Enhance the performance of WaDAR’s backscatter tags by optimizing PCB design for improved signal-to-noise ratio (SNR) and implementing a communication protocol for tag identification.

      Tasks:

      Redesign PCB for improved readings.
      Implement and test a communication protocol to distinguish between multiple tags.
      Evaluate hardware changes in real-world field conditions.
      Optimize power consumption and scalability for practical deployment.


      ~~~~~~~~~~

      WildBerryEye
      Carlos Isaac Espinosa Ramirez
      Last updated on Feb 12, 2025

      WildBerryEye leverages Raspberry Pi and YOLO object detection models to monitor pollinizers like bees and hummingbirds visiting flowers. This initiative aims to enhance environmental research by automating data collection and analysis of pollinator activities, which are crucial for ecological assessments and conservation efforts. The project utilizes video data provided by Dr. Rossana Maguiña, processed through advanced machine learning techniques to accurately identify and track pollinator interactions in natural habitats.

      Develop web-based user interface
      Topics: Full Stack Development React Flask
      Skills: Experience with full stack development and real time processing
      Difficulty: Moderate to Challenging
      Size: Medium or large (175 or 350 hrs)
      Mentors: Carlos Isaac Espinosa Ramirez
      Develop a clean and intuitive web-based interface for WildBerryEye, ensuring ease of use for researchers and contributors. The platform should present real-time pollinator detection results, facilitate data visualization, and allow users to interact with system settings efficiently. The website must be accessible, visually appealing, and optimized for both desktop and mobile users, avoiding unnecessary complexity or intrusive elements.

      Specific tasks:

      Frontend Development: Continue development to enhance the user interface using React and CSS, ensuring a responsive and user-friendly design.
      Backend Development: Expand functionality using Flask, focusing on efficient API endpoints and seamless interaction with the frontend (excluding database implementation).
      Real-Time Communication: Implement and refine real-time updates between the frontend and backend to enhance system responsiveness.
      Usability & Design Optimization: Research and propose improvements to the system’s usability, design, and overall user experience.















       

























      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/unicode-inc./
    idea_list_url: https://docs.google.com/document/u/2/d/e/2PACX-1vQbj0-VFkRjYdnivuPPXuHM3IW4LuHxK6E0LVO3O8ZU_-k8CYH_eFMZ_IwFg_r-oBw3FCEOmHCb5jrn/pub


  - organization_id: 166
    organization_name: Unikraft
    no_of_ideas: 10
    ideas_content: |
      Expanding the Unikraft Software Support Ecosystem
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 2
      Constraints/requirements Basic OS concepts, familiarity with POSIX and system calls, build systems and tool stacks.
      Description
      One of the weak points of most unikernel projects has always been application support, often requiring that applications be ported to the target unikernel OS. With Unikraft we have been making a strong push towards POSIX compatibility so that applications can run unmodified on Unikraft. We have been doing this in two different ways:
      by adding support for the Musl libc library such that applications can be compiled against it, using their native build systems, and then linked into Unikraft
      through binary-compatibility mode, where unmodified ELFs are directly executed in Unikraft and the resulting syscalls trapped and redirected to the Unikraft core, via the app-elfloader.
      This has lead to the creation of the application catalog repository where running applications and examples are brought together.
      This project focuses on expanding Unikraft's software support ecosystem by adding new applications to the application catalog repository, primarily in binary-compatibility mode. While doing this, you will also:
      implement and extend system calls
      add extensive testing for the application or framework that is to be included in the catalog
      add benchmarking scripts to measure the performance and resource consumption of the application running with Unikraft
      conduct synthetic tests using tools such as the Linux Test Project
      The success of this project will directly impact Unikraft adoption. The project length can be varied depending on which of these items are covered by the project.
      Reading & Related Material
      https://www.musl-libc.org/
      https://unikraft.org/guides/using-the-app-catalog
      https://github.com/unikraft/catalog
      https://unikraft.org/docs/contributing/adding-to-the-app-catalog

      ~~~~~~~~~~
      Software Quality Assurance of Unikraft Codebase
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 2
      Constraints/requirements C programming skills, Linux command-line experience, build tools
      Description
      During its 6 years of existence, Unikraft, now at version 0.16.1, has grown in features, application support and codebase. As it matures, a high quality of the code and robust behavior are a must to provide a stable solution for its user base.
      The aim of this project is to assist in the software quality assurance of the Unikraft codebase, by tackling one of the following ideas:
      The use of the uktest framework to create unit tests for internal libraries and external libraries. Not many libraries have unit tests, those that do are mostly exceptions. This will directly impact the stability of the code base and allow quick validation of new features that may break existing functionality.
      Inclusion of static and dynamic analysis tools that highlight potential spots of faulty or undefined behavior.
      The use of compiler builtins and compiler flags providing constraints on the code to increase its resilience to faulty behavior.
      Augmenting the CI/CD system used by Unikraft (based on GitHub Actions) to feature automatic testing, validation and vetting of contributions to Unikraft repositories: core, libraries, applications. Potential items are:
      handling running of unikernels instead of simple builds
      static analysis of images to be delivered as reports to GitHub pull requests
      regression checks on performance (delivered as % change from the current upstream version)
      Any other project that is targeted towards increasing the robustness of Unikraft source code is welcome. These will both increase the viability of Unikraft as a stable solution and increase the quality of future contributions, by enforcing good practices on submitted code.
      Reading & Related Material
      Writing Tests in Unikraft
      https://www.guru99.com/unit-testing-guide.html
      https://docs.kernel.org/dev-tools/kunit/index.html
      https://github.com/features/actions
      https://unikraft.org/docs/contributing/review-process/

      ~~~~~~~~~~
      Supporting macOS networking (medium-large, 175-350hrs)
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 1
      Constraints/requirements Good Go skills, familiarity with virtualization, macOS and networking, good OS knowledge
      Description
      KraftKit, the supporting codebase for the modular library operating system Unikraft designed for cloud native applications, provides users with the ability to build, package and run unikernels. As a Swiss-army-knife of unikernel development, it eases both the construction and deployment of unikernels. To this end, supporting diverse user environments and their ability to run unikernels locally supports the ultimate goal of the project. One such environment which requires more attention is macOS.
      Towards better facilitating the execution of unikernel virtual machine images on macOS, this project aims to introduce new packages which interface directly with macOS environments by interfacing natively with the local networking environment such that the execution of unikernels is accessible through a more direct communication mechanisms of the host. Until now, the project only supports Linux bridge networking with accommodation (albeit "stubs") in the codebase for Darwin.
      Reading & Related Material
      unikraft/kraftkit#841

      ~~~~~~~~~~
      Converting the eroFS library to Golang and testing it
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 1
      Constraints/requirements Good Go skills, decent C skills, familiarity with file systems, basic testing knowledge
      Description
      EROFS (Enhanced Read-Only File System) is a lightweight, high-performance read-only filesystem tailored for Linux environments. It is designed to provide fast and efficient access to data while supporting built-in transparent compression, which helps reduce storage overhead. Currently, Golang has support through libraries only for reading EROFS files and no support for creating them.
      Towards better support in KraftKit, this project aims to introduce a new library that reimplements the mkfs.erofs command with all its functionality. This is currently implemented in C which can only be imported into Golang with C to Go bindings. Some attempts have been made to implement this, but are incomplete and do not offer all arguments, of which some we need. Finally, at all steps tests should be implemented that compare original functionality to the ported library functionality.
      Reading & Related Material
      https://docs.kernel.org/filesystems/erofs.html
      https://github.com/erofs/erofs-utils/blob/dev/mkfs/main.c
      unikraft/kraftkit#2007
      https://pkg.go.dev/gvisor.dev/gvisor/pkg/erofs
      https://github.com/dpeckett/archivefs/tree/main/erofs

      ~~~~~~~~~~
      Fine-Tuning Unikraft's Performance
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 1
      Constraints/requirements Good C skills, familiarity with general operating system concepts, good testing knowledge
      Description
      Over the past releases the development focus of Unikraft has been set on improving its compatibility with existing code bases and adding missing operating system features. This means that less efforts were dedicated to performance-testing Unikraft, resulting in a potential loss of performance in recent releases. Now that Unikraft is reaching the desired level of maturity and compatibility, it is time to go back to evaluating and fine-tuning its performance.
      The aim of this project is to 1) evaluate the current performance of Unikraft, 2) identify potential performance bottlenecks, and 3) address these bottlenecks through targeted patches.
      To evaluate the performance of Unikraft, this project will base on the evaluation of the Unikraft EuroSys paper, re-running experiments with the latest release of Unikraft. The first phase of the project will be to create a new repository with updated experiments that can easily be run in a push-button manner (deliverable 1).
      Following this, bottlenecks will be identified. Performance bottlenecks may lie in any Unikraft component: this will be a unique opportunity to touch on many operating system concepts. Performance bottlenecks will be reported in the form of GitHub issues (deliverable 2).
      Finally, the project will aim to provide self-contained, targeted fixes for these bottlenecks in the form of GitHub Pull-Requests (deliverable 3).
      This project is a unique opportunity to learn about performance evaluation and optimization in a production-grade operating system. It is also an opportunity to participate in a potential academic journal submission of Unikraft by refreshing its evaluation.
      Reading & Related Material
      The Unikraft EuroSys 2021 paper (see the Evaluation, Section 5): https://dl.acm.org/doi/10.1145/3447786.3456248
      The EuroSys 2021 evaluation repository: https://github.com/unikraft/eurosys21-artifacts
      
      ~~~~~~~~~~
      
      Testing Framework for Unikraft Builds
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 1
      Constraints/requirements Python knowledge, Linux CLI
      Description
      We are currently developing a testing framework that is able to multiplex the variety of configuration options, VMMs, hypervisors, architectures, boot protocols, to validate the successful building and running of unikernel images. This framework is able to configure, build, run and test the variety of Unikraft builds. It is written in Python and is subject to improvements and refactoring.
      We are looking to augment the testing infrastructure to make it seamless to be used by Unikraft developers and users. To this end we aim to:
      Consolidate the testing framework as a separate project inside its own repository.
      Have the testing framework work out-of-the-box with the catalog and catalog-core repositories.
      Integrate the testing framework with the CI/CD system used in the Unikraft organization repositories to automatically validate builds for contributions. Tests are to be triggered each time a pull request is open in the unikraft and in core library repositories.
      Reading & Related Material
      https://github.com/unikraft/catalog
      https://github.com/unikraft/catalog-core
      https://github.com/unikraft-upb/catalog/tree/razvand/generator/new-design/utils/new-design


      ~~~~~~~~~~
      Update Newlib and Pthread-embedded Libraries
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 1
      Constraints/requirements C, assembly, Linux CLI, GNU build tools
      Description
      The default Unikraft standard C library (libc) is Musl, a lightweight libc providing a POSIX interface. Up until 2022, the default libc was Newlib. Starting with release 0.11.0 the default libc switched to Musl.
      Ever since that point, Newlib supported hasn't been updated to keep up with the recent version of Unikraft.
      The goal of this project is to update Newlib and pthread-embedded support to the recent Unikraft versions. Such as current builds would work out-of-the-box with Newlib and pthread-embedded as well as Musl.
      The steps to be done are:
      Update Newlib and pthread-embedded to build with the most recent Unikraft version.
      Update Newlib version to the most recent upstream version.
      Build and run applications on the catalog-core and catalog repositories.
      (Optionally) Add CI pipelines to work with Newlib and pthread-embedded.
      Reading & Related Material
      https://github.com/unikraft/lib-newlib
      https://github.com/unikraft/lib-pthread-embedded
      https://github.com/RWTH-OS/pthread-embedded
      https://sourceware.org/newlib/


      ~~~~~~~~~~
      Update Unikraft Core External Libraries
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 2
      Constraints/requirements C, assembly, Linux CLI, GNU build tools
      Description
      The Unikraft core external libraries haven't been updated in the past 2 years. We aim to update them to their latest version. That means:
      Update lib-musl from 1.2.3 to 1.2.5 (the most recent upstream Musl version).
      Update lib-lwip from 2.1.2 to 2.2.1 (the most recent upstream LWIP version).
      Update lib-gcc from 7.3.0 to 14.2.0 (the most recent upstream GCC version).
      Update lib-libcxx from 14.0.6 to 19.1.7 (the most recent upstream LLVM version).
      Update lib-libcxxabi from 14.0.6 to 19.1.7 (the most recent upstream LLVM version).
      Update lib-compiler-rt from 14.0.6 to 19.1.7 (the most recent upstream LLVM version).
      Update lib-libunwind from 14.0.6 to 19.1.7 (the most recent upstream LLVM version).
      The update is aimed to use the workflow for Unikraft microlibrary version. As part of the update effort, we aim to also test and validate builds for the catalog-core and catalog repositories.
      Reading & Related Material
      RFC: Unikraft Microlibrary Versioning

      ~~~~~~~~~~
      Update Unikraft Application Libraries
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 2
      Constraints/requirements C, assembly, Linux CLI, GNU build tools
      Description
      The Unikraft application libraries haven't been updated in the past 2 years. We aim to update them to their latest upstream version. Target libraries / applications are:
      lib-nginx
      lib-redis
      lib-sqlite
      lib-python3
      lib-libgo
      lib-lua
      The update is aimed to use the workflow for Unikraft microlibrary version. As part of the update effort, we aim to also test and validate builds for the catalog-core and catalog repositories.
      Reading & Related Material
      RFC: Unikraft Microlibrary Versioning


      ~~~~~~~~~~
      Add FreeBSD Libc as Unikraft External Library
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 1
      Constraints/requirements C, assembly, Linux CLI, GNU build tools
      Description
      The default Unikraft standard C library (libc) is Musl, a lightweight libc providing a POSIX interface. FreeBSD Libc is the default libc used by default by FreeBSD, with a compatible license with Unikraft.
      The goal of this project is have a FreeBSD libc build repository for Unikraft and build existing applications against it. In the end, you would be able to build and run applications on the catalog-core and catalog repositories using the FreeBSD libc variant.
      Reading & Related Material
      https://github.com/freebsd/freebsd-src/tree/main/lib/libc
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/unikraft/
    idea_list_url: https://github.com/unikraft/gsoc/blob/staging/gsoc-2025/ideas.md


  - organization_id: 167
    organization_name: Uramaki LAB
    no_of_ideas:
    ideas_content: |
      GSoC 2025 Ideas for RUXAILAB
      All the current ideas for GSoC2025 are listed bellow:
      Big size projects (~350h)
      AI-Powered Accessibility Evaluation in RUXAILAB (350h)
      This project aims to develop a comprehensive AI-powered accessibility evaluation system within RUXAILAB, focusing on automating and enhancing WCAG compliance testing. By integrating artificial intelligence with semi-automated evaluation techniques, this system will assist developers and usability experts in identifying and addressing accessibility barriers in digital content, including websites, documents, and mobile applications. The system will provide detailed, multi-dimensional reports, offering both quantitative compliance scores and qualitative insights in plain language.
      Key Features:
      Automated WCAG Compliance Testing: Utilize AI-enhanced evaluation tools and integrate existing APIs (e.g., WAVE API) to generate automated accessibility assessments.
      AI-Powered Accessibility Insights: Implement machine learning models to detect complex accessibility issues that may not be captured by traditional automated tools, such as color contrast issues, ARIA misconfigurations, and screen reader compatibility problems.
      Data Integration and Analysis: Merge results from automated tools and AI-generated insights, creating a comprehensive accessibility evaluation framework.
      Semi-Automated Expert Evaluation: Enable expert evaluators to refine AI-generated reports, ensuring higher evaluation accuracy and adaptability.
      Quantitative Compliance Scoring: Establish a numerical accessibility index based on WCAG success criteria, enabling users to track and compare improvements over time.
      Natural Language Summaries: Use AI-driven text generation to translate technical accessibility reports into readable, actionable insights for designers, developers, and content creators.
      Continuous Learning Mechanism: Implement an AI model that improves over time by learning from expert evaluations and new accessibility guidelines.
      Keywords: Artificial Intelligence (AI), Accessibility Testing, WCAG Compliance, Data Analysis, Machine Learning, Usability Evaluation
      Expected Outcome: A fully integrated AI-driven accessibility evaluation system that enhances and automates WCAG compliance testing, making accessibility validation more efficient and insightful within RUXAILAB.
      Skills Required: Python, JavaScript, AI for Data Analysis, Machine Learning, Accessibility Standards (WCAG), NLP for Report Generation
      Mentor: Marc
      Difficulty: Hard
      AI Tool for Heuristic Evaluation (350h)
      This project aims to develop an AI-based heuristic evaluation tool capable of automatically assessing usability issues in digital interfaces, mimicking the analysis of an expert usability evaluator. The system will apply well-established usability heuristics, such as Nielsen’s Heuristics, to evaluate web pages and identify usability problems based on structured guidelines. The tool will generate detailed reports with quantitative scores and qualitative insights, helping designers and developers improve their interfaces.
      Key Features:
      Automated Heuristic Evaluation: Utilize AI to systematically analyze web pages based on usability heuristics.
      Expert-Level Analysis: Develop machine learning models trained on usability best practices to identify common usability problems such as poor feedback, inconsistent navigation, and inefficient workflows.
      Multi-Dimensional Reporting: Generate both quantitative usability scores and qualitative insights that explain detected usability issues similarly as RUXAILAB is doing right now.
      Continuous Learning Mechanism: Enhance evaluation accuracy by refining AI models based on expert reviews and user feedback.
      Integration with RUXAILAB: Seamlessly integrate with the existing usability evaluation tools within RUXAILAB.
      Keywords: Artificial Intelligence (AI), Usability Testing, Heuristic Evaluation, Data Analysis, Machine Learning, UI/UX Optimization
      Expected Outcome: A fully automated heuristic evaluation tool that functions as an AI-based usability expert, identifying and reporting usability issues based on standard heuristic guidelines.
      Skills Required: Python, JavaScript, NLP for Report Generation
      Mentor: Marc González
      Difficulty: Hard
      Integration of Heat Maps into Remote Usability LAB (350h)
      Heat maps encompass a variety of tracking tools, including scroll maps, click maps, and move maps, each providing distinct insights into user behavior. This project aims to develop and integrate a comprehensive heatmap recording tool for usability testing inside the RUXAILAB framework. The system will optimize mouse tracking and generate detailed reports on user interactions.
      Key Features:
      Comprehensive Heatmap Tracking: Implementation of scroll maps, click maps, and move maps for a thorough performance analysis
      Real-Time Data Collection: AI-powered tracking to capture and visualize user interaction patterns
      Optimized Mouse Tracking System: Enhancing usability testing with advanced cursor movement analytics
      Automated Report Generation: AI-driven insights into user behavior for usability evaluation
      Seamless RUXAILAB Integration: Full compatibility with existing usability testing tools
      Keywords: Artificial Intelligence (AI), Algorithm Optimization, JavaScript, Usability Testing, Front-end Development
      Expected Outcome: A fully integrated heatmap tracking system that enhances usability testing in RUXAILAB by analyzing user behavior and generating reports
      Skills Required: Python, JavaScript, AI for Data Analysis
      Mentor: Murilo
      Difficulty: Hard
      Integration of User Testing into RUXAILAB with Eye Tracking, Sentiment Analysis and Pre-Post Form Tasks (350h)
      This project aims to integrate advanced user testing capabilities into RUXAILAB, incorporating eye tracking, sentiment analysis, and structured pre/post-test forms. By combining these elements, the system will provide a comprehensive framework for usability testing, offering insights into user behavior, emotional response, and engagement levels.
      Key Features:
      Eye Tracking Integration: Analyze user gaze patterns to identify usability issues and areas of focus
      Sentiment Analysis: Utilize AI-driven sentiment detection to assess user emotions during interactions
      Pre and Post-Test Forms: Structured questionnaires to collect user expectations and post-experience feedback
      Automated Data Analysis: Generate real-time reports with actionable insights for improving usability
      Seamless RUXAILAB Integration: Ensure compatibility with existing usability testing workflows
      Keywords: User Testing, Eye Tracking, Sentiment Analysis, AI, Usability Testing
      Expected Outcome: A fully integrated user testing framework that enhances RUXAILAB by capturing and analyzing user behavior, emotional responses, and structured feedback
      Skills Required: Python, JavaScript, AI/ML for Sentiment Analysis, Eye Tracking APIs
      Mentor: Marc and Karine Difficulty: Hard
      Medium size projects (~175h)
      UI Layout Optimization for RUXAILAB (175h)
      This project aims to redesign the RUXAILAB user interface (UI) to improve usability, accessibility, and responsiveness.
      Key Improvements:
      Simplified Navigation: Improved menu structure for seamless interaction
      Responsive Design: Optimized for mobile, tablet, and desktop
      Accessibility Features: WCAG-compliant color contrast, keyboard navigation, screen reader support
      Dark Mode & Custom Themes: Enhancing user comfort for different environments
      Keywords: UI/UX Design, Accessibility, Front-end Development, , Usability Testing
      Expected Outcome: A fully redesigned and accessible RUXAILAB interface Skills Required: JavaScript, Vue.js, CSS, Figma, AI for UI Optimization
      Mentor: Leticia
      Difficulty: Medium
      Comparative Analysis and Fine-Tuning of Sentiment Models for Improved System Integration (175h)
      This project focuses on comparing and fine-tuning sentiment analysis models to enhance integration efficiency and scalability within RUXAILAB. The goal is to analyze both traditional performance metrics and operational scalability factors to determine the most efficient sentiment models for real-time and batch processing scenarios.
      Key Features:
      Resource Efficiency Analysis: Evaluate computation time, response latency, and initialization speed
      Performance Comparison: Assess accuracy, F1-score, and contextual processing capabilities
      Scalability and Memory Management: Optimize model performance under varying data loads
      Batch vs. Real-Time Processing: Analyze trade-offs between batch processing and real-time sentiment detection
      Storage and Memory Optimization: Identify strategies to minimize memory footprint while maintaining performance
      Monitoring and Observability: Implement tracking mechanisms for efficient model oversight
      Keywords: Sentiment Analysis, Machine Learning, AI Optimization, Scalability, Performance Metrics
      Expected Outcome: A comparative study and fine-tuned sentiment models optimized for scalability, resource efficiency, and real-time usability in RUXAILAB
      Skills Required: Python, NLP, AI/ML, Model Optimization
      Mentor: Karine
      Difficulty: Medium
      Transcription Tool for Usability Testing (175h)
      This project aims to create a transcription service designed to streamline usability testing processes within RUXAILAB. The service will allow testers to activate transcription during specific tasks of a test and provide an interface to review and analyze transcriptions afterward. By integrating real-time speech-to-text capabilities, usability researchers can better capture verbal feedback from users.
      Key Features:
      Task-Specific Transcription: Testers can activate transcription for specific tasks during usability tests
      Post-Test Review and Editing: An interface for reviewing, organizing, and editing transcriptions task by task
      Automated Report Generation: Generate comprehensive task-specific transcription reports exportable in multiple formats (e.g., PDF, CSV)
      Seamless RUXAILAB Integration: Ensuring compatibility with existing usability testing workflows
      Real-Time Speech-to-Text Processing: Enable accurate transcription of verbal feedback during user testing
      Keywords: Speech-to-Text, Transcription, Usability Testing, AI, Automation
      Expected Outcome: A task-based transcription system integrated into RUXAILAB, allowing testers to capture, analyze, and report usability test transcriptions efficiently
      Skills Required: Python, NLP, Speech-to-Text APIs, Front-End Development
      Mentor: Anna
      Difficulty: Medium
      Implementation of A/B Testing Capability in RUXAILAB (175h)
      This project focuses on implementing A/B testing functionality within RUXAILAB to enhance usability evaluation and data-driven decision-making. The goal is to provide an integrated system for running controlled experiments, comparing different UI designs, and gathering insights on user preferences.
      Key Features:
      Automated A/B Test Setup: Allow testers to configure and manage A/B tests within RUXAILAB
      Real-Time Performance Tracking: Collect user interaction data for different variations
      Statistical Analysis Module: Provide insights on test results using key performance indicators
      User Segmentation: Enable tests based on demographic, behavior, or experience level
      Seamless UI Integration: Ensure compatibility with existing usability testing workflows
      Keywords: A/B Testing, User Experience, Usability Testing, Data Analysis, Front-End Development
      Expected Outcome: A fully integrated A/B testing module that allows usability researchers to conduct controlled experiments and make data-driven design decisions in RUXAILAB
      Skills Required: JavaScript, Python, Data Analysis, UI/UX Testing
      Mentor: Igor
      Difficulty: Medium
      Small size projects (~90h)
      Integration of GitHub Actions with Discord Role Management (90h)
      This project aims to integrate GitHub Actions with Discord to automate role creation, pull request (PR) management, and collaboration analytics. The system will enable seamless automation between GitHub repositories and Discord servers, ensuring that users receive appropriate roles based on their contributions and project interactions.
      Key Features:
      Automated Role Assignment: Assign Discord roles based on GitHub contributions, such as merged PRs, issues opened, and commits
      Pull Request Management: Automate PR reviews, label assignments, and notifications to Discord channels
      Collaborator Analytics: Generate visual charts of contributors' activities and display them in Discord
      Customizable GitHub Actions: Enable project maintainers to define rules for PR handling, auto-merging, and CI/CD notifications
      Seamless RUXAILAB Integration: Extend usability for research and open-source projects
      Keywords: GitHub Actions, Discord API, Automation, Open Source Collaboration, Workflow Management
      Expected Outcome: A GitHub Actions-powered integration that automates role management, PR handling, and contributor analytics for Discord communities
      Skills Required: JavaScript, Python, GitHub Actions, Discord API
      Mentor: Leticia
      Difficulty: Easy
      Automating Issue Creation from SonarQube in CI/CD Pipelines (90h)
      This project focuses on automating the creation of GitHub issues based on SonarQube analysis in a CI/CD pipeline. By integrating SonarQube results into the development workflow, the system will automatically detect code quality issues, create GitHub issues, and notify maintainers for quick action.
      Key Features:
      Automated Issue Creation: Detect new issues from SonarQube scans and create corresponding GitHub issues
      Severity-Based Issue Prioritization: Categorize issues based on severity (Critical, Major, Minor)
      Pipeline Integration: Ensure smooth integration with CI/CD workflows for real-time analysis
      Developer Notifications: Automatically notify responsible developers about newly created issues
      Customizable Rules: Allow maintainers to define which issues should trigger automatic creation
      Keywords: SonarQube, Software Quality, CI/CD, GitHub Actions, Automation
      Expected Outcome: A fully automated issue tracking system that integrates SonarQube with GitHub for better software quality management
      Skills Required: Python, JavaScript, GitHub Actions, SonarQube API
      Mentor: Leticia
      Difficulty: Easy
      Enhancing Playwright Testing in RUXAILAB (90h)
      This project aims to refine and optimize Playwright-based automated testing in RUXAILAB, improving test efficiency and documentation to enhance maintainability and ease of use. The focus will be on ensuring robust test coverage, optimizing test workflows, and developing comprehensive documentation to support contributors.
      Key Features:
      Improving Test Maintainability: Refactor test scripts for better reusability and efficiency
      Cross-Browser and Device Compatibility: Ensure consistent behavior across different browsers and devices
      Accessibility Testing Enhancements: Strengthen WCAG compliance validation for UI components
      Comprehensive Documentation: Develop detailed guides on test creation, execution, and maintenance
      Integration with CI/CD Pipelines: Enhance GitHub Actions workflows for streamlined automated testing
      Keywords: Playwright, Automated Testing, UI Testing, Accessibility, Documentation
      Expected Outcome: A more maintainable and well-documented Playwright testing framework, ensuring long-term usability and ease of contribution in RUXAILAB
      Skills Required: JavaScript, Playwright, Automated Testing, CI/CD, GitHub Actions, Technical Writing
      Mentor: Eric
      Difficulty: Easy
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/uramaki-lab/
    idea_list_url: https://github.com/ruxailab/gsoc/blob/main/ideas2025.md

  - organization_id: 168
    organization_name: VideoLAN
    no_of_ideas: 28
    ideas_content: |
      
      
      Advanced Audio Filters
      Project Description: We are looking for a skilled audiophile that knows a lot about audio theory and practice to work on new audio filters for VLC.
      Duration: 350h
      Tasks to do:
      SRS WoW like or other 3D effects;
      channels mixing, notably upmixing, like Prologic-II;
      tracks mixing, and transitions;
      scriptable new audio filters in lua and enable users to create whatever audio filtering function they want in a Lua script;
      LADSPA or other libraries integration.
      Requirements: This project needs some good audio knowledge and good C experience.
      Qualification task: Port any audio filter from MPlayer
      Proposed mentor: unidan

      ~~~~~~~~~~
      VLC Qt interface redesign
      Project Description: The VLC interface is quite outdated on Linux and Windows. It has a lot of features, but some are not properly exposed.
      We are currently reworking the interface, but we need help.
      Duration: 350h
      Scope of the tasks to do:
      Use the new designs shared on the mailing list, and help developping part of those, using Qml.
      This new interface is simpler, more user friendly, and has a better "media center" feel into it.
      It requires integration with the media library and with the current interface.
      Qml is the technology needed to improve the current UI.
      Requirements: This project requires Qt/C++ knowledge, and qml would be a nice plus.
      Proposed mentor: Pierre

      ~~~~~~~~~~
      VLC Skins2 interface update
      Project Description: The VLC Skins2 interface was not updated for the latest interface and core changes for the media player and playlist engine yet.
      We are currently reworking the interface, but we need help.
      Duration: 350h
      Scope of the tasks to do:
      wayland integration
      video integration rework (like Qt interface)
      medialibrary integration
      Requirements: This project requires Qt/C++ knowledge, and qml would be a nice plus.
      Proposed mentor: Pierre

      ~~~~~~~~~~
      VLC macOS interface redesign
      Project Description: The VLC interface is quite outdated on macOS and we are currently in the process of re-writing it to give it a modern feel, but also to integrate recent additions to libvlc regarding playback control and library management.
      This project for the summer is to rework heavily this interface to make it beautiful and useful again.
      Duration: 350h or 175h
      Scope of the tasks to do:
      There is a full design already done and tested. The major hurdle is to actually implement it the way we want it to be. The iOS/tvOS interface is simpler, more user friendly, and has a better "media center" feel into it, which influenced what we want to achieve on the Mac. Note that the objective is to use AppKit. UIKit will not be part of this project.
      Iterating from the current UI and closely collaborating with the team currently working on it is a requirement.
      Requirements: This project requires Obj-C knowledge, a thorough understanding of OOP and proven previous Mac development experience. You cannot use swift for this project.
      Proposed mentor: David Fuhrmann, Felix Paul Kühne

      ~~~~~~~~~~
      VLC watchOS port
      Project Description: VLCKit recently added support for playback of audio files on watchOS with support for http streams coming in a future update. The idea is to create a new, standalone app for watchOS that can play local files on device with a good way to synchronize those either from a computer or the app on the companion iPhone. The UI development needs to be done in SwiftUI following the restrictions of the platform.
      Duration: 350h
      Proposed mentor: Diogo Simao Marques, Felix Paul Kühne

      ~~~~~~~~~~
      iced ui for VLC
      iced is a cross-platform UI library for Rust. The project aims to provide a VLC iced Widget as first step and then a full UI as complete as possible within the time available.
      Tasks
      Revamp and publish the VLC-rs bindings
      Create an iced Widget similar to what exists already forGStreamer
      Increase the richness of the UI gradually
      First normal direct playback (play pause seek)
      Add volume controls
      Add support to manage subtitles
      Expose the VLC configuration knobs (one subset at time)
      Duration: 175h
      Proposed mentor: Luca Barbato

      ~~~~~~~~~~
      Improve Android MediaCodec support
      Project Description: The goal is to fix few bugs (black screen with some device/video, HDR issues), and to improve the download of MediaCodec surfaces to the CPU
      Duration: 175h
      Scope of the tasks to do:
      Fix MediaCodec bugs https://code.videolan.org/videolan/vlc/-/issues/?sort=updated_desc&state=opened&label_name%5B%5D=Component%3A%3AVideo%3A%20Android&first_page_size=20
      Fix download for all kind of chromas/size/offset/crop (Decoding Acceleration in the vlc-android app)Duration: 350hRequirements: Those will be done in C, and it requires familiarity with the android dev environment and hardware decoders.
      Proposed mentor: Thomas Guillem

      ~~~~~~~~~~
      Add back netsync module
      Project Description: Use the new vlc clock to add back the netsync module
      Duration: 350h
      Scope of the tasks to do:
      Use a new network protocol: RTP Midi
      Expose some vlc_clock APIs to be used by "control" module
      Plug the vlc_clock API inside the new module
      Requirements: Very good C knowledge
      Proposed mentor: Thomas Guillem

      ~~~~~~~~~~
      VLC iOS UI update
      Project Description: We're currently in the process of rewriting and updating the entire UI for VLC iOS
      There is a lot of components that need refactoring and need to get an updated UI.
      The Android port of VLC has done most of that and was successful. We need the same level of features.
      Duration: 350h or 175h
      Tasks to do:
      Get an overview of the current App and components that need an update
      Refactor and give the appropriate components a new look
      See what is missing compared to the Android version
      Code it :
      Requirements: This project requires Obj-C and Swift knowledge and ideally knowledge of writing tests for iOS but this can be learned.
      Proposed mentor: Felix Paul Kühne, Diogo Simao Marques

      ~~~~~~~~~~
      Qt integration tests
      Project Description: In order to improve the robustness of our application, we would like to develop integration tests for the Qt interfac.e The goal being to ensure that new features and refactors won't break other parts of the UI.
      Duration: 350h or 175h
      Scope of the Tasks to do:
      study existing solutions used in other open-source projects (https://invent.kde.org/sdk/selenium-webdriver-at-spi)
      adapt test framework to our environment
      write sample test cases
      study CI integration feasibility (Linux and/or Windows tests)
      Requirements: This project requires Qt/C++ and some scripting language (pyhton?) knowledge, Qml would be a nice plus.
      Proposed mentor: Pierre

      ~~~~~~~~~~
      
      Cloud integration for desktop
      Project Description: We want to be able to access Cloud Storage services (Dropbox, Google Drive and so on) in the VLC application.
      Duration: 350h or 175h
      Scope of the Tasks to do:
      revive libcloudstorage
      integrate libcloudstorage inside VLC
      write sample test cases
      Requirements: This project requires C++ knowledge.
      Proposed mentor: Pierre

      ~~~~~~~~~~
      
      Improve libNDI and integrate in VLC
      Project description: Improve the libNDI project supporting the NDI protocol to support more formats.
      Duration: 350h
      Tasks to do:
      Study the NDI protocol, implement and test and integrate inside VLC.
      Requirements:
      NDI understanding
      C knowledge.
      Proposed mentor: j-b

      ~~~~~~~~~~
      Update the Lua integration
      Project description: The current extension implementation in Lua needs more love to make them first class citizen (they are currently loaded by GUI instead of the core).
      Duration: 350h
      Tasks to do:
      update libvlccore to load Lua extensions instead of the GUI
      work on a better descriptive abstraction for lua stream parsers extensions which needs to extract data from the webpage. (currently done by manual read())
      more testing infrastructure for the scripts
      Requirements:
      Lua and C knowledge, c++ is a plus
      Proposed mentor: Alexandre Janniaux

      ~~~~~~~~~~
      Implement DVD-Audio deciphering
      Project description: Support DVD-Audio deciphering using dvdcpxm
      https://offog.org/git/dvdaexplorer/
      http://www.thescrapyard.org/software/libdvdcpxm.html
      http://forum.doom9.org/showthread.php?t=167537
      https://sourceforge.net/projects/dvdadecoder/
      Duration: 350h
      Tasks to do:
      Understand DVD-Audio
      Implement VLC module based on those modules
      Requirements:
      Audio likeness
      C knowledge.
      Proposed mentor: j-b

      ~~~~~~~~~~
      Radio-Browser integation
      Project Description: Integrate the Radio-Browser.info API in a service discovery module so it is available on all of VLC's platforms.
      Duration: 175h
      Tasks to do:
      Study and understand the REST API
      Implement a VLC module based on the API
      Add a way to favorite channels
      Requirements:
      previous experience with REST APIs
      C knowledge
      Proposed mentor: Felix

      ~~~~~~~~~~
      Port the remote access webserver to VLC Desktop
      Description: To remotely access and control a VLC instance, a webserver has been developped for VLC Android. The goal is to port it to VLC desktop.
      Duration: 350h
      Tasks to do:
      Extract the web client code from the VLC for Android reprository to a dedicated one
      Write the server part in VLC desktop using lua scripts
      Adapt the client to be compatible with the new VLC desktop web server
      Requirements:
      js, Vue, lua, websockets
      Proposed mentor Nicolas

      ~~~~~~~~~~
      demux Rust bindings and AVI module for VLC
      VLC has already its first Rust (logger) module: https://code.videolan.org/videolan/vlc/-/commit/e8e46b0d915d153a58d002c9d6f19a7dbdfeeca9 There was a proposal to add several Rust bindings and example: https://code.videolan.org/videolan/vlc/-/merge_requests/2738
      Tasks
      Adapt demux API Rust bindings to upstream VLC
      Add a new AVI demux module to test the new bindings (Using the nom crate: https://crates.io/crates/nom/)
      Duration: 350h
      Requirements: Good C knowledge and very good Rust knowledge
      Proposed mentors: Thomas Guillem and Alexandre Janniaux

      ~~~~~~~~~~
      integrate checkasm tooling and improve existing asm coverage
      VLC has some amount of existing assembly (yadif, video chroma) but we lack test coverage for it and also could use more for newer architectures
      Tasks
      Integrate checkasm for validation (against a C baseline) and benchmarking (similarly to what's done in dav1d)
      Convert the existing assembly to use it
      Add new optimizations for things like audio/video format conversions, filters and also for newer arch's (riscv etc.)
      Duration: 175h or 350h
      Proposed mentors: Marvin Scholz, Nathan Egge, Tristan Matthews
      
      ~~~~~~~~~~
      libvlc Wayland API
      In order to allow easy integration of VLC video rendering into application that uses Wayland, similarly to what we provide for X11 or HWND.
      Duration: 175h
      Scope of the Tasks to do:
      Provide a method to expose external Wayland surface and additional mechanisms to libvlc.
      Write a sample application to illustrate how to use the API
      Requirements: This project requires some good C experience
      Proposed mentor: Pierre Lamot

      ~~~~~~~~~~
      Other short ideas for VLC & libVLC
      Those ideas are not detailed, but they are ideas that we could help to spring new ideas. We can help work with you to make those more detailed.
      Those ideas should be 175h long
      Improve Vulkan output for VLC, including HDR support
      Improve id3 tag and metadata handling in VLC
      Bridge module for GMI'C or other video filters
      Automated Testing Environment like ffmpeg Fate (port ?) for demuxing, non-hw decoding
      Integrate libavfilter in VLC
      Improve the libVLCSharp bindings for VLC in C#
      Provide setups for popular streaming services / sout templates (ui ?)
      Improve cue support in VLC

      ~~~~~~~~~~
      Ideas for VideoLAN infrastructure
      Improve the VideoLAN crash reporter in Go and Vue.js
      The idea is to improve the current crash reporter of VLC, called CrashDragon.
      The tasks are the following:
      Review the current code
      Improve the API in Go
      Write a new Vue.js frontend
      Those will be done in Go and JS
      Duration: 350h
      Proposed mentor: David and j-b

      ~~~~~~~~~~
      Ideas for dav1d
      dav1d RISC-V optimizations
      Improving the performance of the AV1 decoder is very important for VLC and the whole ecosystem.
      It requires to:
      Understand of RISC-V assembly
      Understand a bit what a video decoder is
      Write RISC-V functions
      Requirements: This project requires C and ASM knowledge, as well as system programming skills
      Duration: 175h
      Contact 'j-b'

      ~~~~~~~~~~
      dav1d GPU Compute Shaders
      Improving the performance of the AV1 decoder is very important for VLC and the whole ecosystem.
      This project requires to port one of the filter, like SGR or Wiener to one of the Shader languages. iPhones or Xbox One would be a good target.
      This is a tricky project, but is doable during the summer
      Duration: 350h
      Requirements: This project requires C and GPU Shaders knowledge, as well as system programming skills
      Contact 'j-b'

      ~~~~~~~~~~
      dav1d statistics extractions
      The dav1d AV1 decoder is a new high performance AV1 decoder by VideoLAN.
      Current open source tools for AV1 analysis use instrumentation in the reference decoder libaom to extract decode-time metadata for display and reporting, but support for sophisticated analysis is lacking.
      To speed development of AV1 tools like the rav1e, it would be helpful to add similar decoder metadata extraction APIs to the dav1d decoder so that rapid testing of encoder algorithms is easier. This includes the ability to quickly produce statistics, visualizations and other reporting that can be used for tuning encoder parameters or guiding development. Advanced ideas include adding similar encoder metadata API to rav1e that add encode-time visualizations.
      Requirements: This project requires C knowledge.
      Duration: 175h
      Contact 'unlord'

      ~~~~~~~~~~
      Ideas for libplacebo
      Direct3D 11 backend
      Project Description:
      libplacebo uses a GPU abstraction with a number of backends. The goal would be to add a new backend based on Direct3D 11, since Vulkan and OpenGL support on Windows are often of limited quality, especially for older hardware.
      Lots of example code for how this implementation would look can be found as part of the mpv project .
      Large parts can be copy/pasted and adapted to the libplacebo API.
      Tasks to do:
      Add a new `pl_gpu` backend based on Direct3D 11
      Integration into the build system, test framework and CI infrastructure
      Requirements:
      Knowledge of C as well as, ideally, graphics API fundamentals. (But the latter can be learned as part of the project)
      Ability to develop and test on Windows
      Duration: 175h
      Contact 'haasn'

      ~~~~~~~~~~
      Dolby Vision Profile 5 (IPT-PQ)
      Project Description:
      Dolby IPT-PQ is a HDR color space similar to ITU-R ICtCp, but with proprietary Dolby modifications (reshaping algorithm). Your goal is to implement this reshaper in the form of a GLSL shader, using knowledge from known Dolby patents and dumped headers.
      Tasks to do:
      Figure out, and (if necessary) reverse engineer the stream format for the Dolby reshaping algorithm described in several of their patents.
      Implement this algorithm in GLSL
      Integration into libplacebo (optional)
      Test against reference implementations of Dolby Vision profile 5
      Requirements:
      Knowledge of GLSL and C. Knowledge of colorspaces in general is an obvious plus, but the theory here is not important - only the implementation.
      (Possibly) Ability to reverse engineer any still-unknown or differing-from-patents parts of the stream headers.
      Knowledge of libplacebo internals is not required, since the skeleton code for this already exists - what's missing is the reshaping algorithm.
      Duration: 350h
      Contact 'haasn'

      ~~~~~~~~~~
      GPU motion interpolation (mvtools)
      Project Description
      Your goal is to develop GPU shaders for motion-adaptive frame interpolation in the style of [mvtools](https://github.com/dubhater/vapoursynth-mvtools).
      This is an open-ended project. If not completed, any progress towards this goal is good enough.
      Sub-goals:
      Recreate the motion vector search algorithms from MAnalyze
      Implement the pixel masking and pixel flow algorithms from MFlowFps
      These can be tackled and complete out-of-order.
      Requirements:
      Good knowledge of both C and GLSL, especially compute shaders and other GPGPU techniques. (CUDA or OpenCL skills also transfer, though the shader will have to be GLSL)
      Ideally, general knowledge of video processing techniques (e.g. motion vector search) - at least enough to be able to understand what mvtools code is doing.
      Duration: 350h
      Contact 'haasn'

      ~~~~~~~~~~
      Ideas for VLC dependencies
      libmicrodns refactoring
      Our current mDNS discoverer is working, but is not so respectful of the RFC. Possible improvements include:
      Device TTL support
      Device removal detection
      Better request pacing
      Delegate socket interactions to the caller
      Unit testing
      Fuzzing
      Requirements: This project require C knowledge, as well as system programming skills
      Duration: 175h
      Proposed mentor: tguillem

    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/videolan/
    idea_list_url: https://wiki.videolan.org/SoC_2025/


  - organization_id: 169
    organization_name: Wagtail
    no_of_ideas: 2
    ideas_content: |
  
      Content Security Policy compatibility
      Summary
      Wagtail is close to being compatible with strict Content Security Policies (CSP). With one final push, we can get fundamental features all compatible with CSPs, document support, and treat any gaps as bugs.
      For more information, see:
      CSP compatibility issues #1288
      A list of widgets breaking strict Content-Security-Policy (CSP) directives #7053
      Wagtail Stimulus Adoption Schedule (2022-25) 🎛️.
      Expected outcomes
      Addressing any remaining CSP issues in Wagtail.
      Providing official recommendations for compatible CSP settings.
      Ensuring essential functionality works with a strict CSP.
      Documenting or backlogging all CSP-related issues.
      Adding a strict CSP to wagtail.org.
      Implementation
      This will require reviewing existing issues and technical discovery work to device a plan for addressing them. Understanding options in django-csp, and possibly trialing any changes with core Django CSP support.
      The changes required will be a mix of front-end and backend work, and require expertise with security fundamentals to understand what is needed.
      Skills
      Django
      JavaScript
      Security headers
      CSP
      Cross-site scripting
      Technical writing
      Mentors
      Lead: TBC - Sage Abdullah
      Support: TBC
      Support: TBC
      Size
      Expected size of project approximately 350 hours.
      Difficulty rating
      High

      ~~~~~~~~~~
      Grid-aware websites
      Summary
      We want to trial the grid-aware websites concept on a real Wagtail project: the wagtail.org website. This will involve understanding what grid awareness means for websites, how to implement it with Wagtail, and how to measure the website’s energy use depending on different adaptations.
      Expected outcomes
      A grid-aware version of the wagtail.org website.
      A blog post explaining the process and outcomes.
      A report on energy use of different website front-end and back-end components.
      A set of recommendations for other Wagtail websites to become grid-aware.
      Implementation
      This is highly dependent on the outcome of the ongoing grid-aware websites project, which is currently under way. More information will be available in March 2025.
      Skills
      JavaScript
      Django
      Cloudflare workers
      Digital sustainability
      Performance auditing
      Mentors
      Lead: Thibaud Colas
      Support: TBC
      Support: TBC
      Size
      Expected size of project approximately 350 hours.
      Difficulty rating
      High

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/wagtail/
    idea_list_url: https://github.com/wagtail/gsoc/blob/main/project-ideas.md


  - organization_id: 170
    organization_name: Waycrate
    no_of_ideas: 3
    ideas_content: |
 
      Idea 1: Introduce ext_image_capture_source_v1 protocol support in Wayshot and improve security features
      Possible Mentors:
      Rachancheet Singh Kohli (rachancheet37 [at] gmail.com)
      Aakash Sen Sharma (aakashsensharma [at] gmail.com)
      Ishan Joshi (joshiishan246890 [at] gmail.com)
      Difficulty: Hard
      Project Size: Large (350 Hours)
      Pre-requisite Skills: Rust, Wayland Protocols ( Optional )
      Description:
      The ext_image_capture_source_v1 protocol has recently been introduced to Wayland, providing a standardized method for display and top-level window capture. Wayshot currently supports CPU-based and GPU-based capture over wlr-screencopy protocol which is non-standard. Adopting the official protocol offers toplevel capture capabilities natively and improves the user experience.
      This idea aims to introduce a new backend and turn the wlr backend into a legacy codebase for backwards compatibility. Due to the existence of this standardized protocol, we can now also provide extra security to users and denote over dbus notifications when a particular app-id is being recorded by wayshot clients.
      Expected Outcomes:
      Introduction of new standardized protocol and security features to denote when toplevels are recorded by clients.
      Integration of the same protocol to xdg-desktop-portal-luminous to enable standardized WebRTC streaming.
      ~~~~~~~~~~
      
      Idea 2: Introduce libinput backend to SWHKD to improve keyboard detection and security heuristics
      Possible Mentors:
      Ishan Joshi (joshiishan246890 [at] gmail.com)
      Aakash Sen Sharma (aakashsensharma [at] gmail.com)
      Difficulty: Medium
      Project Size: Medium (175 Hours)
      Skills: Rust
      Description:
      Currently SWHKD uses the linux kernel evdev module to read keyboards and has very simplistic heuristics for device detection that is not ideal and prone to errors. Due to these heuristics SWHKD in some scenarios may capture kernel events from devices that are NOT meant to be grabbed.
      Evdev also requires a very complex security model to work with to ensure proper execution and we hope libinput helps us resolve some of that.
      This can be avoided by a more restricted libinput API and can significantly reduce code complexity. This would also vastly enhance the UX of the project at the cost of reduced capabilities but that can be avoided by a feature flag during build time.
      PS: Due to space constraints we are unable to list out all the advantages & disadvantages of evdev. If you’d be interested in those details, feel free to contact the listed possible mentors.
      Expected Outcomes:
      Introduction of new libinput API for improved UX
      
      ~~~~~~~~~~
      Idea 3: Introduce RDP support into xdg-desktop-portal-luminous
      Possible Mentors:
      Decodetalkers (chenhongtao12345678 [at] gmail.com)
      Aakash Sen Sharma (aakashsensharma [at] gmail.com)
      Difficulty: Medium-ish (leaning towards hard)
      Project Size: Medium (175 Hours)
      Skills: Rust
      Description:
      Xdg-desktop-portal-luminous is a high performance capture portal for wayland compositors that supports frame capture and gpu-copy based frame streaming. The goal of this idea is to introduce support for remote-desktop protocol to enable applications like teamviewer and anydesk to work seamlessly on wayland compositors using our custom portal backends.
      This will improve adoption and UX, users will no longer need to depend on other portals for this particular usecase and all usecases can be consolidated into 1 portal.
      Expected Outcomes:
      Introduction of RDP support to luminous portal.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/waycrate/
    idea_list_url: https://waycrate.github.io/outreach/gsoc/2025/idea-list/
  

  - organization_id: 171
    organization_name: Wellcome Sanger Tree of Life
    no_of_ideas: 5
    ideas_content: |

        Finding the impact of biodiversity genomics datasets in scientific publications

        Mentors

        TBC (Sanger Tree of Life and Europe PMC at EMBL-EBI)

        Size

        LARGE (350 hours)

        Difficulty

        HARD

        Technologies

        Python, Machine-learning, Text processing

        THIS project aims to develop an advanced literature retrieval method tailored for research within biodiversity projects such as the Darwin Tree of Life (DToL) initiative. By integrating the Europe PubMed Central (Europe PMC) literature search functionality, the tool will provide researchers with a powerful platform to efficiently identify, access, and analyse cutting-edge scientific information. Beyond enhancing literature accessibility, this project will offer valuable insights into the outcomes of Tree of Life research, deepening our understanding of the impact of biodiversity genomics and its applications. It will also inform future resource management strategies by identifying key trends, gaps, and opportunities in the field. Ultimately, this initiative aims to equip researchers with the tools and knowledge needed to drive advancements in biodiversity genomics while supporting sustainable and informed decision-making for the management of biological resources.

        MORE technically, the project focuses on co-developing an NLP-based tool that can find relevant biodiversity genomics articles in Europe PMC. Key steps in the project may include:

        Building a specialized dictionary of biodiversity genomics-related keywords, phrases, and domain-specific terms from relevant documents, publications, and biological terminology databases.
        Data collection from the Europe PMC database and preprocessing.
        Annotation using the dictionary and filtering.
        Language pattern recognition.
        Machine learning based classification method development.
        It is an extremely challenging project. We will be working with the Europe PMC team at EMBL-EBI to develop this methodology and may have to align with some of their existing text mining initiatives and frameworks already used in production. Flexibility will be key to design and implement this right.

        Further reading:

        Darwin Tree of Life website and example scientific output
        Europe PMC web portal, Annotation service / API, and download page.

        ~~~~~~~~~~

        Building a machine-learning taxon classifier to inform genomic classification in malaria mosquitoes

        Mentors

        Chris Clarkson, Anastasia Hernandez-Koutoucheva, Alistair Miles

        Size

        Medium (175 hours)

        Difficulty

        Medium

        Technologies

        Python, Machine-learning, Google Cloud Storage

        Identifying Anopheles mosquitoes species with precision is critical for malaria control. The Anopheles gambiae sensu lato (An. gambiae s.l.) complex, the primary malaria vector in sub-Saharan Africa, consists of multiple species, including An. arabiensis, An. coluzzii, and An. gambiae s.s. Each of these species has unique ecological roles and varying susceptibility to vector control strategies, leading to heterogeneity in their contribution to malaria transmission.

        Taxonomic identification of Anopheles mosquitoes is challenging as they are morphologically identical, and genomic data is key to correctly classify individuals. Misclassification can lead to suboptimal interventions and flawed epidemiological insights, underscoring the need for robust, scalable and accessible classification frameworks.

        This project aims to optimise, enhance, and package a cloud-native genomic taxon classifier for Anopheles mosquitoes. The starting point will be to optimise an existing random-forest classifier to improve accuracy and computational efficiency while validating the predictions against expertly curated taxonomic datasets.

        As the current implementation is trained on high-resolution genomic data from the Vector Observatory, which integrates whole-genome sequence data for over 25,000 mosquitoes, a key aspect of the project will be to package the classifier in an accessible manner, ensuring any research group can use this tool.

        Further reading:

        Malaria Genome Vector Observatory: https://www.malariagen.net/vobs
        Article on the distribution of African mosquitoes belonging to the Anopheles gambiae complex: https://www.cell.com/partod/fulltext/S0169-4758(09)01563-X

        ~~~~~~~~~~

        Building cloud-native analytical tools to detect and track outbreaks of insecticide resistance in African malaria mosquitoes

        Mentors

        Alistair Miles, Anastasia Hernandez-Koutoucheva, Chris Clarkson

        Size

        Large (350 hours)

        Difficulty

        Medium

        Technologies

        Python, Statistical Analysis, Google Cloud Storage

        Description

        The Malaria Vector Genome Observatory is an open and collaborative ecosystem that supports researchers and public health authorities to access, analyse and visualise data from Anopheles mosquitoes collected from affected countries. Integrating high-quality whole-genome sequence data from over 25,000 mosquitoes contributed by partners across 30 countries, this resource represents the largest natural genetic variation dataset for any multicellular organism, second only to humans.

        At the core of this resource, is the malariagen_data API - a cloud-native, open-source Python software package that enables scalable population genomics and genomic surveillance by providing robust statistical and visualisation tools designed for rapid and reproducible analysis.

        For this project, we are looking for contributors who have an interest in expanding and enhancing this ecosystem to identify and track new insecticide resistance outbreaks in response to new vector control interventions. A suggested starting point will be to look into methods to improve the detection of genes and variants under recent positive selection, to identify variants associated with insecticide resistance, and to track the spread of resistance variants over space and time. We would also encourage contributors to develop their own ideas for potential improvements and new features, after building an understanding of the capabilities that would have the most impact for researchers working on malaria vector surveillance and control in Africa.

        Further reading:

        Source code: https://github.com/malariagen/malariagen-data-python
        Malaria Vector Genome Observatory: https://www.malariagen.net/vobs
        Training course showcasing data analysis with the malariagen_data API: https://anopheles-genomic-surveillance.github.io/home.html

        ~~~~~~~~~~

        Implementing a user interface to KinFin for interactive exploration of protein clustering data

        Mentors

        Rich Challis & Cibele Sotero-Caio

        Size

        Large (350 hours)

        Difficulty

        Medium

        Technologies

        Javascript (React) & Python

        Analysing how gene families evolve is key to many large scale projects in phylogenetics and genomics. Most eukaryotic species have between 15,000 and 25,000 protein coding genes and toolkits exist to cluster these into protein families based on sequence similarity. KinFin is a command line tool that takes protein clustering derived from variants of the MCL algorithm and facilitates intensive interrogation of protein families across hundreds of species (and many million proteins) for patterns that reveal biological processes. A GSoC 2024 project updated the codebase and built an API layer to deliver an analysis interface to web-available genome browsing or analysis systems such as Ensembl and GenomeHubs. This project will build the functionality to extend the API and add interactive UI components to provide a standalone UI and allow integration into GenomeHubs sites such as MolluscDB. Much of the power of KinFin lies in its innovative visualisation approaches, and development of additional visualisations and analytic outputs will be part of the project.

        KinFin plot of frequencies of protein clusters from 19 species. The peak at a cluster size of ~19 identifies the likely set of one-to-one orthologues in the analysed data.


        Further reading:

        KinFin publication: OrthoFinder publication
        Modified KinFin code at GitHub
        GenomeHubs
        MolluscDB

        ~~~~~~~~~~

        Genome After-Party: a global database of ready-made genome analyses

        Mentors

        Matthieu Muffato and another bioinformatician (TBC)

        Size

        Large (350 hours)

        Difficulty

        Medium

        Technologies

        Nextflow (nf-core), Python/Shell for glue/wrapper scripts. Bioinformatics tools

        The Tree of Life department of the Wellcome Sanger Institute is largely devoted to generating and analysing high-quality reference genomes from biodiversity projects. Our flagship project is Darwin Tree of Life (DToL), for which we have generated more than 1,500 reference genome assemblies. All those assemblies are then released to INSDC without embargo and a short paper, called a Genome Note, is published at Wellcome Open Research. Genome Notes require certain genome analyses, such as quality scores (QV, BUSCO) or plots (Hi-C contact maps, BlobTools). These represent the core of the Genome After-Party, a new public data repository (https://gap.cog.sanger.ac.uk/) for common genome analyses. that we are now expanding with sequence-composition tracks, variant-calls, variant analysis, etc.

        All Genome After-Party data come from a suite of production-grade pipelines written in Nextflow using the nf-core standards, and made public on GitHub https://github.com/sanger-tol. Complete documentation and examples of the pipelines are on the website https://pipelines.tol.sanger.ac.uk/.

        Several pipelines are used in production to generate analysis data for many genomes and we're now looking to expand the range of analyses being performed, with guidance from the researcher community. In this project, we are looking for people interested in contributing to our vision and implementing new analyses in Nextflow. We already have a list of analyses and tools in mind, requested or advised by Faculty partners, on our Project board on GitHub. We're particularly interested in expanding the sequence composition pipeline (e.g. to annotate all sorts of repeat elements) and the variant calling & analysis pipelines.

        Further reading:

        Overview of pipelines: https://pipelines.tol.sanger.ac.uk/genome_after_party
        Project board: https://github.com/orgs/sanger-tol/projects/3
        Nf-core documentation: https://nf-co.re/docs/









       
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/wellcome-sanger-tree-of-life/
    idea_list_url: https://docs.google.com/document/d/1dRHwnHAXlwQbRDstnd0OZTDJYA9cTsl1jG_hOempqII/edit?usp=sharing

  - organization_id: 172
    organization_name: Zendalona
    no_of_ideas: 10
    ideas_content: |
      Project Title: Accessible-Bluff Bot - Enhancing AI Opponents for Inclusive Card Gaming


      What is Accessible-Bluff


      Accessible-Bluff is a web-based card game designed with accessibility in mind, ensuring that all actions and information are conveyed audibly using a screen reader. It mimics a physical card game with real-life experiences by enabling teams to establish private rooms for remote collaboration and gaming.


      How to play the Bluff game?
      Like a regular card game, a group of players join a virtual room and shuffle the cards. The game begins with the first player placing one or more cards by either telling the truth or lying. For instance, if the player places “the king”, he/she can claim it as “a queen”, “a jack”, or “any other card”, or truthfully state it as “a king” itself. Other players can challenge if they suspect deception/cheat. If a player falsely claims “a queen” as “a king” and is challenged, the player receives a penalty, while the challenger earns an extra chance. However, if the challenger is wrong, he/she receives the penalty. Players can choose to “Pass” if they don’t want to participate in the round, but they can still “Raise” a challenge. A round concludes only when all players “Pass”, or someone “Raise” the challenge.  The winner is the player who clears his/her cards first. 


      Project Details
      Project page: https://zendalona.com/accessible-bluff/
      Game URL (Project): bluff.zendalona.com
      Bluff GitHub repository: https://github.com/zendalona/accessible-bluff
      This project is to develop an AI bot for the Accessible-Bluff card game, ensuring it is fully accessible to visually impaired players. The bot should be one of the players. The bot should support multiple difficulty levels, allowing players of different skill levels to enjoy the game. The design should be modular, enabling future improvements and enhancements. The bot should be seamlessly integrated with the existing Accessible-Bluff game environment and its actions must be fully conveyed via screen readers.
      Expected Output
      AI Bot for Accessible-Bluff  
      On the homepage, players can select the number of bots and their difficulty level while creating a game room. Once the game starts, bots will be displayed with names like Bot1, Bot2, etc., alongside human players, according to the user's selection on the game page. 


      A fully functional AI bot capable of playing the Accessible-Bluff card game, mimicking a real human player throughout the game.  
      
      Multiple difficulty levels cater to different player skill levels, including the following. 


      Beginner (Easy Mode) – The AI plays with basic strategies, making   predictable moves and occasionally bluffing. This level helps new players understand   the game mechanics.  
         
      Intermediate (Normal Mode) – The AI uses a mix of strategy and deception, analyzing previous moves to make more competitive decisions. It bluffs more effectively and detects bluffs with moderate accuracy.  


      Advanced (Hard Mode) – The AI employs complex strategies, adaptive learning, and advanced bluff detection. It bluffs unpredictably and adjusts its playstyle based on opponents' behaviour, making it challenging for experienced players.  
            
      2. Accessibility Features
      Seamless integration with screen readers, ensuring all bot actions (bluffing with selected cards and bluff text, challenging opponents' actions) are audibly conveyed.  
      3. Modular Design & Integration
      A flexible and expandable bot architecture for future improvements.  
      Seamless integration with the Accessible-Bluff game environment, preserving existing accessibility and gaming logic.   
      4. Comprehensive Documentation  
      Detailed documentation covering the bot's architecture, algorithms, and usage.


      Skills required/preferred Bot, NodeJs, Javascript,  
      Expected size of the project: 175 hours
      Difficulty: High
      Possible mentors: Nalin Sathyan

      ~~~~~~~~~~





      Project Title: AI-Powered Agent to provide support for Zendalona products
      Project Description:
      Develop an AI-powered Agent that provides information and support related to Zendalona products and assistive technologies for visually impaired individuals. This project aims to enhance the agent’s capabilities by integrating advanced Natural Language Processing (NLP) techniques, improving accessibility features, and expanding its knowledge base to better serve users with visual impairments.
      Project Goals:
      Advanced NLP Integration:
      Implement state-of-the-art NLP models (e.g., BERT, GPT) to improve the AI Agents understanding of user queries.
      Enhance the Agents ability to handle complex, multi-turn conversations and provide contextually relevant responses.
      Accessibility Enhancements:
      Ensure the Agent is compatible with screen readers and other assistive technologies commonly used by visually impaired individuals.
      Implement text-to-speech (TTS) and speech-to-text (STT) functionalities to facilitate seamless communication.
      Knowledge Base Expansion:
      Curate and integrate a comprehensive database of Zendalona, including detailed descriptions, usage instructions, and user reviews.
      Enable the chatbot to provide personalized recommendations based on user preferences and needs.
      User Experience Improvements:
      Conduct user testing with visually impaired individuals to gather feedback and identify areas for improvement.
      An intuitive and user-friendly user experience for all types of queries.
      Expected Outcomes:
      An intelligent and responsive AI Agent capable of understanding and addressing a wider range of user queries.
      Enhanced accessibility features that make the Agent accessible for visually impaired individuals.
      A richer knowledge base that provides users with detailed and accurate information about assistive technologies.
      A user-friendly interface that improves overall satisfaction and engagement.


      Skills required/preferred : AI, NLP, Python
      Expected size of project: 175 hours
      Difficulty: High
      Possible mentors: Sivasailam vellaisamy, Mukundhan

      ~~~~~~~~~~


      





      Project Title: Accessible World-Map-Explorer V2
      Description: World-Map-Explorer is an inclusive and educational mapping tool designed for both visually impaired and sighted users. Powered by OpenStreetMap, it provides a seamless way to explore the world using keyboard navigation, audio feedback, and interactive features. Users can search for places, move through locations using arrow keys, get real-time border alerts, measure distances, and access detailed geographic information. Additional features include an adjustable pointer for exploring surroundings, inbound navigation to limit movement within a selected region, and a road distance calculator. 
      The Application is live at map.zendalona.com 
      User guide - https://map.zendalona.com/src/pages/user-guide/index.html 
      GitHub repository: https://github.com/zendalona/world-map-explorer-v2
      
      Outcome: Migrate the project to Next.js for better performance, implement server-side functionalities, and add the following features. 
      User Login – Log in to save your preferences and create a personalized experience. 
      Search History and Undo/Redo – Access a history of your previous actions to revisit locations easily. 
      Dynamic Routing – Navigate to places directly using external URLs when applicable 
      Bookmarks – Add and manage bookmarks, saving them in the database for future reference. 
      Settings Management – Save and manage your preferences for a customized experience: 
      Profile – Edit your email and personal data.  
      Key binding – Customize keyboard shortcuts for efficient navigation.  
      Bookmark Management – Edit and organize your bookmarks.  
      Other Settings – Adjust cursor pointer size, angle, and related features. 
      Path Navigation – Navigate through roads, railways, rivers, and other paths using the cursor to inform the user about the places passing through. 
      Water Sound Alerts – Receive auditory cues when cursor enters water bodies for enhanced interaction. 
      


      Skills required/preferred : JavaScript, TypeScript, Next.js, Leaflet.js, and PostgreSQL.
      Expected size of project: 175 hours
      Difficulty: High
      Possible mentors: K Sathyaseelan, Nalin Sathyan

















      ~~~~~~~~~~

      Project Title: Accessible TuxType and TuxMath Enhancement
      Description
      During Google Summer of Code (GSoC) 2013, we made TuxType and TuxMath accessible for visually impaired users. However, the current official versions lack these accessibility features. It's crucial to release a new official version of TuxType and TuxMath on all platforms.


      TuxType


      The keyboard is the primary input device for visually impaired users, making keyboard practice essential for effective computer use.


      TuxType is an educational typing game designed to improve users' typing skills in an engaging way. It consists of multiple game modes: 


      Fish Cascade: Tux must eat fish while avoiding those with letters by typing them to make them disappear. 


      Comet Zap: Tux defends cities from falling comets by typing the letters on them, inspired by the classic math game "Tux, of Math Command." 


      Lessons and Phrase Typing: Players practice typing through structured lessons and phrases, tracking accuracy and speed. Future improvements aim to make it easier for educators to customize content. 


      GitHub Repository:  https://github.com/tux4kids/tuxtype


      TuxMath 
      TuxMath transforms math practice into an exciting game where players help Tux defend planets from asteroids by solving arithmetic problems. It fosters quick thinking, hand-eye coordination, and strategic planning while reinforcing mathematical skills. 


      GitHub Repository: https://github.com/tux4kids/tuxmath/


      t4common library
      Tuxmath and Tuxtype are coded in C and utilize the SDL library for graphics. They share the t4common library. Accessibility features can be activated via a new menu or keyboard shortcuts.


      GitHub Repository: https://github.com/tux4kids/t4kcommon




      Expected Output: 
      Improve documentation around the build
      Fix Mac build for m-X chips
      Check and update dependencies, this will include updating the SDL library to version 2
      Expose accessibility features in Tuxmath and Tuxtype
      Fix existing bugs that include supporting it over other Linux distros like Fedora, Arch Linux
      Make an official release for GNU/Linux
      Make an official release for Microsoft Windows
      Make an official release for MacOS
      Prepare and release official packages or installers for all platforms.
      Releasing snap packages for the Ubuntu store
      Add Ukrainian translation
      Add fractions question support: There is an issue around it: https://github.com/tux4kids/tuxmath/issues/38


      Release TuxType and TuxMath with accessibility features for visually impaired users on all platforms without compromising the comfort of regular users.


      Skills preferred: C, SDL
      Expected time of project: 175 hours 
      Difficulty: Intermediate 
      Possible mentors: Deepak Agarwal, Mukundhan Annamalai














      ~~~~~~~~~~

      Project Title: Liblouis table editor - Enhancement
      
      Description: “The Liblouis software suite provides an open-source braille translator, back-translator, and formatter for many languages and braille codes. It is a set of libraries designed for use in several applications, both free and commercial.”   - https://liblouis.io/ 
      
      Numerous software applications like NVDA, JAWS, BrlTTY, TalkBack, make use of liblouis. 
      The total global user count is in millions. Many projects developed in Zendalona utilize liblouis, including IBus-Braille, Sharada-Braille-Writer, Braille-Translator-GUI, and the Braille-Translator Web version.  


      Outcome: Creating Liblouis translation tables is a laborious and time-consuming task. Both software developers and end users at the Braille printing press require a more convenient method for editing the liblouis table. Furthermore, in numerous languages, the editing process involves inputting Unicode code points instead of directly writing the letters, adding an extra layer of complexity to the table editing process. 
      
      Liblouis manual: https://liblouis.io/documentation/liblouis.html#How-to-Write-Translation-Tables 
      
      As part GSoC 2024, We have created a free and open-source Liblouis table editor compatible with GNU/Linux, Microsoft Windows, and macOS, fulfilling the following criteria: 
      Display characters as they are alongside their Unicode code points. 
      Provide a drop-down list for selecting opcodes. 
      Enable the insertion of operands through entries with validity checks. 
      Include an option to test forward and back-translation on the fly. 
      Allow users to view and modify the Unicode character equivalent corresponding to the written Unicode code point. 
      Indicators to ensure the user is aware of duplicate entries. 
      Should be accessible to visually challenged people 

      GitHub repository: https://github.com/zendalona/liblouis-table-editor



      Here is the list of tasks we need to complete to release the project

      Implement the Forward/Backward table testing feature 
      Fix bugs related to the toolbar
      Fix bugs
      Showcase the project internally within the organization
      Do internal testing and fix bugs
      Create a package for GNU/Linux
      Develop an installer for Windows
      Present the project to potential users
      Facilitate testing with end users
      Perform accessibility testing with blind users
      Fix bugs and release the final version




      Skills required/preferred Python, Qt, Liblouis.
      Expected size of project: 175 hours
      Difficulty: Intermediate
      Possible mentors: Samuel Thibault, Nalin Sathyan








      ~~~~~~~~~~


      Project Title: Enhancing Accessibility in the Ubuntu Installer for Visually Impaired Users to Support Accessible-Coconut 24.04
      Description:
      The Ubuntu installer is a critical tool for users to set up their systems, but it currently lacks sufficient accessibility features for visually impaired users. This issue directly impacts projects like Accessible-Coconut, a specialized Linux distribution developed by Zendalona over the past decade. Zendalona has been releasing Accessible-Coconut every two years, with the upcoming Accessible-Coconut 24.04 planned to be based on Ubuntu MATE 24.04. Improving the accessibility of the Ubuntu installer is essential to ensure a smooth and inclusive experience for users of Accessible-Coconut.
      This project aims to address the accessibility shortcomings of the Ubuntu installer(Ubuntu Desktop Provision) by improving compatibility with screen readers like Orca, enhancing keyboard navigation, and providing clear audio feedback. These improvements will not only benefit Ubuntu users but also directly support the efforts of Zendalona, the developer behind Accessible-Coconut, in releasing a fully accessible 24.04 version.
      Ubuntu-Desktop-Provision GitHub repository: https://github.com/canonical/ubuntu-desktop-provision
      Objectives:
      Improve Orca Screen Reader Integration:
      Investigate and fix issues with Orca compatibility in the Ubuntu installer, ensuring that all installer components are properly labelled and navigable using the screen reader.
      Collaborate with the Orca development team to address any upstream issues affecting the installer.
      Enhance Keyboard Navigation:
      Ensure that all installer elements can be accessed and interacted with using only the keyboard, as many visually impaired users rely on keyboard navigation instead of a mouse.
      Provide Clear Audio Feedback:
      Implement audio cues and feedback for critical actions (e.g., selecting a disk, confirming installation) to guide visually impaired users through the installation process.
      Simplify and Streamline the User Interface:
      Work with the Ubuntu design team to simplify the installer interface, making it easier for screen readers to interpret and for users to understand.
      Support Accessible-Coconut 24.04:
      Collaborate with Zendalona, who has been releasing Accessible-Coconut every two years for the past decade, to ensure that the improvements align with the needs of Accessible-Coconut users.
      Test the installer changes in the context of Ubuntu MATE 24.04, which is the base for Accessible-Coconut 24.04.
      Documentation and Testing:
      Create detailed documentation for visually impaired users on how to use the improved installer.
      Conduct usability testing with visually impaired users, including those from the Accessible-Coconut community, to gather feedback and ensure the changes meet their needs.
      Expected Outcomes:
      A more accessible Ubuntu installer that provides a seamless experience for visually impaired users, including those using Accessible-Coconut.
      Improved compatibility with Orca and other screen readers.
      Clearer navigation and feedback mechanisms for users relying on assistive technologies.
      Comprehensive documentation and testing reports to guide future accessibility improvements.
      Direct support for Zendalona's efforts to release Accessible-Coconut 24.04 based on Ubuntu MATE 24.04, continuing a decade-long tradition of providing accessible Linux solutions.
      Skills Required:
      Familiarity with Linux systems and Ubuntu.
      Experience with accessibility tools like Orca and knowledge of accessibility standards (e.g., WCAG).
      Proficiency in Python (used in the Ubuntu desktop provisioner) and GTK (for UI improvements).
      Strong communication skills to collaborate with the Ubuntu community, Zendalona, and visually impaired users.
      Related Links:
      Ubuntu Discourse Thread on Installer Accessibility
      Launchpad Bug Report on Accessibility Issues
      GitHub Issue on Installer Accessibility
      Ubuntu MATE Community Discussion on Orca Improvements
      Impact:
      This project will significantly improve the inclusivity of the Ubuntu installer, making it easier for visually impaired users to install and use Ubuntu. It will also directly support Zendalona's efforts to release Accessible-Coconut 24.04, ensuring that the distribution remains a leading choice for visually impaired users. Additionally, the improvements will set a precedent for future accessibility enhancements across Ubuntu and other Linux distributions. By supporting Zendalona's decade-long commitment to accessibility, this project will contribute to a more inclusive open-source ecosystem.
      Skills preferred: Flutter, Dart, Python
      Expected time of project: 175 hours 
      Difficulty: High 
      Possible mentors: K Sathyaseelan, Akshay S Dinesh


      ~~~~~~~~~~




      Project Title: Linux-Intelligence-OCR-Solution(LIOS) - Enhancement 
      
      Description: LIOS is a free and open-source software designed for converting printed text into digital format using scanners or cameras. It is also capable of generating text from scanned images sourced from various formats, including PDFs, images, image folders, or screenshots. The program ensures complete accessibility for visually impaired users through a graphical user interface (GUI). Leveraging OCR engines like Tesseract and Cuneiform, LIOS facilitates the conversion of images to text. 
      
      Significantly, LIOS is included in the Debian repository and distinguishes itself as the exclusively accessible OCR user interface within the GNU/Linux environment. Furthermore, it has been developed inclusively, allowing many sighted individuals to also benefit from its features. 
      
      Github page: https://github.com/zendalona/lios 
      Debian repository: https://packages.debian.org/bookworm/lios


      Outcome:  We need the following  
      Make the UI simpler more easier by moving/removing many UI components  
      Make the UI more readable for Low vision by providing easy switchable themes 
      Make items in preferences more reasonably categorized 
      Fix scanner driver issues  
      Refine the code  
      Fix all reported bugs 
      Enhance detection of Tesseract data paths
      Make dialog boxes foolproof
      Release the new version as RPM package  
      
      
      Skills required/preferred Python, Gtk, Cairo 
      Expected size of project: 175 hours
      Difficulty: Intermediate
      Possible mentors: Samuel Thibault, Nalin Sathyan

      ~~~~~~~~~~


      Project Title: Accessible World-Map-Explorer Android version - zMap
      Description: Discover the world with world map explorer, a web app made with inclusivity in mind. Navigate through keyboard or via search and explore the world with real time voice over. Search for countries, states, places, rivers or even historic monuments. Control the exploration area to stay within a region or make sure you don’t get lost in the map with real time border crossing alert. Explore the surroundings with the adjustable pointer by changing its distance and angle. Start your adventure with World Map Explorer today and navigate the world with ease and confidence!  
      The web version is currently availablemap.zendalona.com	


      The Application is live at map.zendalona.com 
      User guide - https://map.zendalona.com/src/pages/user-guide/index.html 
      GitHub repository (Web version): https://github.com/zendalona/world-map-explorer-v2
      
      Expected Outcome:
      The android version can be a webview which should achieve the same experience as the web version by using gestures instead of keys of the keyboard. The features of the app are: 
      Gesture-Assisted navigation: The user should be able to use the app by using the gestures and no gesture should overlap with other gestures. 
      Capturing User Location: User should be able to start navigation from a place near user’s actual location. 
      Navigation Using Search: User should be able to	
      discover and navigate to any places, rivers and historic monuments by using the search feature. 
      Boundary setting for search and navigation: The user should be able to select to select a place to learn more about it and restrict the navigation within it’s boundaries. 
      Adjustable pointer: The user should be able to customize the distance and angle of a pointer to explore nearby locations with precision. 
      Distance to Borders: The user should instantly know the distance to the borders in the north, south, east and west direction. 
      Zoom in: The user should be able to zoom in zoom out. 
      Distance Finder: The user should be able to find the distance between any two places with ease. 
      Map layout options: The user should be able to switch between political and geographical views. 
      Altitude awareness: The user should instantly know the altitude of the current place. 
      Managing notifications and calls: Managing many activities that can occur while using the apps such as notifications, calls etc. 


      Skills preferred: Android, Java 
      Expected time of project: 350 hours 
      Difficulty: Intermediate 
      Possible mentors: Nalin Sathyan, Mukundhan Annamalai  


      ~~~~~~~~~~
      

















      Project Title: Maths-Tutor QT Version and Enhancement 
      
      Description: Accessible Maths-Tutor is a software tool that combines the enjoyment of gaming with the essential skill of mathematics. Imagine having a friendly mentor right on your computer screen, guiding you through math problems in a fun and interactive way. This is precisely what Maths Tutor offers a unique and engaging learning experience. 
      
      Information about the previous version(1): https://zendalona.com/accessible-maths-tutor/ 


      In the previous year's GSoC, we migrated the project from GTK to Qt to address accessibility issues on Windows and macOS. 


      Repository link: https://github.com/zendalona/maths-tutor-v2/tree/development 


      Here is the list of tasks to be completed:


      Bugs in Maths-Tutor V2: 
      Upload option not implemented in Home 
      Settings Option not implemented 
      Even though we answered correctly, the animation for the wrong answer appears and announces the wrong answer and moves to the next question. 
      In Subject Time the Questions are not fully visible 
      Only for the first right answer the clap audio is heard but for the second right answer  
      Note overrides over the subject menu 
      The Bell Ringing option was not implemented 
      The difficulty level not working as intended same questions are repeated in every level 
      
      
      Things Remaining to be implemented: 
      Provide Speech Sound using Human Voice instead of Text-To-Speech Engine  
      Intermediate score announcement for Appreciation 
      Provide Answer clues in situations like the User taking too much time  
      User Interface for creating Question File  
      Clock Tick Sound for indicating Time consumption  
      Introduce the "Assessment Mode" Checkbox to Enable/Disable exposing Score, Clock, etc.  
      User Guide  
      Themes for Low Vision - High Contrast, Low Contrast  
      Lessen the Lock to make the User finish for the Next Lesson  
      Increase sound playing Speed to Speech Rate  
      Profile Preferences for Each Kid and Use their Name While Appreciating  
      Pair Question in Percentage  
      Dataset - Add number typing of Lakhs / Millions  
      Dataset for teaching multiple ways to make the same Digit  
      Fix announcement of Lakhs / Millions  




      


      
      Skills required/preferred: Python, QT
      Expected size of project: 175 hours
      Difficulty: Intermediate
      Possible mentors: Sai Saravan, K Sathyaseelan
      
      












      ~~~~~~~~~~
      Project Title: Maths-Mantra Enhancement
      
      Description: In GSoC 2024, we developed a comprehensive smartphone application incorporating all the features of the Math-Tutor computer version. Additionally, we integrated the functionalities outlined in the 'What We Need' section. The app utilizes various input methods, including touch screen, accelerometer, microphone, GPS, clock, and magnetometer, to create an immersive and interactive learning experience. To enhance user engagement and effectiveness, we implemented feedback mechanisms such as stereo sound, vibrations, and other sensory cues.


      This year, we need to fix existing bugs and add the remaining features to complete the project.


      GithHub repository: https://github.com/zendalona/Math-Mantra 


      Outcome: Include the following concepts in the application: 
      
      1. Utilize phone sensors and stereo sound to teach cardinal directions (North, East, West, South) through interactive methods. 
      2. Integrate lessons on Angle X, Y, Z, and incorporate simple distance/height calculations using trigonometric functions. 
      3. Enable user engagement by allowing kids to input answers through sound or clapping using the device's microphone. 
      4. Leverage GPS functionality to teach distance-related concepts, providing a real-world context for understanding spatial relationships. 
      5. Implement multi-touch functionality on the screen to teach number concepts and facilitate the drawing of various shapes such as triangles, rectangles, rounds, ovals, etc. 




      Skills required/preferred: Android, Java, UI development
      Expected size of project: 350 hours
      Difficulty: Intermediate
      Possible mentors: Nalin Sathyan, Mukundhan
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/zendalona/
    idea_list_url: https://docs.google.com/document/d/1HshVGE-oQq_xx09zG2LfqfVYWRhyrASteXzabCV9eIQ/edit?usp=sharing

  - organization_id: 173
    organization_name: Zulip
    no_of_ideas: 17
    ideas_content: |
      Full stack and web frontend focused projects
      Code: github.com/zulip/zulip – Python, Django, TypeScript/JavaScript, and CSS.
      Cluster of priority features. Implement a cluster of new full stack features for Zulip. The high priority label documents hundreds of issues that we’ve identified as important to the project. A great project can be 3-5 significant features around a theme (often, but not necessarily, an area label); the goal will be to implement and get fully merged a cluster of features with a meaningful impact on the project. Zulip has a lot of half-finished PRs, so some features might be completed by reading, understanding, rebasing, and reviving an existing pull request. 175 or 350 hours; difficulty will vary. Skills required: Depends on the features; Tim Abbott will help you select an appropriate cluster once we’ve gotten to know you and your strengths through your getting involved in the project.
      Experts: Tim Abbott and various others depending on project area

      ~~~~~~~~~~
      Complete some unfinished projects. This is a variant of the previous project idea category, but focused on projects with significant existing work to start from and polish, rather than projects that have not been seriously attempted previously.
      We maintain a completion candidate label for pull requests where a previous contributor (sometimes via GSoC!) did significant work towards something valuable, and there’s significant feedback from maintainers, but the project was never finished, and requires significant further effort from a new contributor in order to progress. One of our goals for this summer’s GSoC is to complete many of these issues. Start by picking something that’s interesting to you, and you feel you have the skills required to complete. Read the code and the feedback, and then create your own PR for the issue. See the guide on continuing unfinished work for details. 175 or 350 hours; difficulty will vary. Skills required: Varies with project; a common skill will be good reading comprehension and organization/communication skills, to walk maintainers through how you resolved problems, addressed any pending feedback on the previous PR, and your understanding of the outstanding questions for a given project. Taking the time to get really good at resolving merge conflicts is likely to be valuable here as well.

      Experts: Tim Abbott and various others depending on project area

      ~~~~~~~~~~
      Migrate Zulip’s direct message recipient data structures to a new model that enables personal settings associated with a direct message conversation, and add several settings (see the linked issues) enabled by that infrastructure work. 175 or 350 hours; fairly difficult. Skills required: This project will be deep Python 3/PostgreSQL work. Concretely, challenging parts of this project include thinking about races and database transactions, writing database migrations intended to be run live at scale, complex internal refactors, and carefully verifying the indexes used by migrated database queries.
      Experts: Tim Abbott, Mateusz Mandera, Prakhar Pratyush

      ~~~~~~~~~~
      Implement channel groups that simplify administration of collections of related channels in Zulip. Contributors interested in working on this should start with studying Zulip’s existing channel and group-based permissions system, both UX and implementation, and doing some starter issues in the settings area. 175 or 350 hours; medium difficulty. Skills required: Ability to read and understand a lot of code, as well web frontend work in TypeScript/HTML/CSS, with a bit of Python server programming. We’ll be particularly interested in the ability to explain and reason about complex logic and follow the existing UI patterns for group settings and channel settings.
      Experts: Sahil Batra, Shubham Padia
      ~~~~~~~~~~
      Add the core infrastructure for topic-based permissions and settings like pinned topics and read-only topics, and then build some of those settings. This project will be a mixture of Python 3/PostgreSQL work, including thinking about database transactions and races, writing database migrations intended to be run live at scale, and complex logic to handle moving messages correctly in the context of these settings, including significant changes to the Zulip API and API documentation. 175 or 350 hours; fairly difficult. Skills required: A high level of fluency with writing readable Python 3 and thinking about corner cases.
      Experts: Tim Abbott, Prakhar Pratyush

      ~~~~~~~~~~
      Zulip’s REST API documentation, which is an important resource for any organization integrating with Zulip, as well as the developers of our API clients. Zulip has a nice framework for writing API documentation built by past GSoC students based on the OpenAPI standard with built-in automated tests of the data both the Python and curl examples. However, the documentation isn’t yet what we’re hoping for: there are a few dozen endpoints that are missing, several of which are quite important, the visual design isn’t perfect (especially for, e.g., GET /events), many templates could be deleted with a bit of framework effort, etc. See the API docs area label for some specific projects in the area; and git grep pending_endpoints to find the list of endpoints that need documentation and their priorities. Our goal for the summer is for 1-2 students to resolve all open issues related to the REST API documentation. 175 or 350 hours; difficulty easy or medium. Skills required: Python programming. Expertise with reading documentation and English writing are valuable, and product thinking about the experience of using third-party APIs is very helpful.
      Expert: Lauryn Menard

      ~~~~~~~~~~
      Improve the UI and visual design of the Zulip web app. We are working on a major redesign for the core surfaces of the Zulip web app – see the redesign label for specced out work, with more to come. We’re particularly excited about students who are interested in making our CSS clean and readable as part of working on the UI. 175 or 350 hours; medium to difficult. Skills required: Design, HTML and CSS skills; most important is the ability to carefully verify that one’s changes are correct and will not break other parts of the app; design changes are very rewarding since they are highly user-facing, but that also means there is a higher bar for correctness and reviewability for one’s work. A great application would include PRs making small, clean improvements to the Zulip UI (whether logged-in or logged-out pages).
      Experts: Aman Agrawal, Karl Stolley, Alya Abbott

      ~~~~~~~~~~
      Improve type safety of node tests. Rework Zulip’s automated node tests to use objects that consistently have the correct type. Currently, many tests use fake message, user, or channel objects with only a handful of fields relevant to the test. We’ve been working towards web/tests/lib/example_*. A good starter project would be to try to convert a small test module that currently does not use the make_user type functions to do so. The main TypeScript migration thread is useful background reading, and #frontend channel is a good place to start new topics while working on this project. 175 or 350 hours; medium difficulty. Skills required: TypeScript fluency, and the discipline to write easily reviewed pull requests that often will include a series of changes to clean up an individual test while you’re working on it.
      Experts: Afeefuddin, Lalit

      ~~~~~~~~~~
      Replace hundreds of dict[str, Any] types with modern dataclasses. While functionally efficient, dataclasses are more readable, safe against typos, and have nice support for optimizing them further using __slots__. A lot of Zulip server code was written before dataclasses existed, and while a lot has been converted naturally as part of other projects, we’d like to make a focused push to replace the remaining ones. This project will involve making dozens of small commits and PRs, each a clean refactor converting a single type. Use this conversation for discussion and coordination. Skills required. Solid understanding of statically typed Python, and the discipline to learn to write refactoring commits that are easy to integrate, following our standard guidelines, because they convincingly don’t change any product behavior while improving type-safety.
      Experts: Tim Abbott, Anders Kaseorg

      ~~~~~~~~~~
      Optimize performance and scalability, either for the web frontend or the server. Zulip is already one of the faster web apps out there, but we have a number of ideas for how to make it substantially faster yet. This is likely a particularly challenging project to do well, since there are a lot of subtle interactions to understand. 175 or 350 hours; difficult. Skill recommended: Strong debugging, communication, and code reading skills are most important here. JavaScript experience; some Python/Django experience, some skill with CSS, ideally experience using the Chrome Performance profiling tools (but you can pick this up as you go) can be useful depending on what profiling shows. Our backend scalability design doc and the performance label may be helpful reading for the backend part of this.
      Experts: Tim Abbott
      ~~~~~~~~~~
      Fill in gaps, fix bugs, and improve the framework for Zulip’s library of native integrations. We have about 120 native integrations, but there are a number of others we would like to add. Also, several extensions to the framework that would dramatically improve the user experience of using integrations, e.g., being able to do callbacks to third-party services like Stripe to display more user-friendly notifications. The the integrations label on GitHub lists some of the priorities here (many of which are great preparatory projects). 175 or 350 hours; medium difficulty with various possible difficult extensions. Skills required: Strong Python experience, will to install and do careful manual testing of third-party products. Fluent English, usability sense and/or technical writing skills are all pluses.
      Experts: Niloth, Lauryn Menard
      ~~~~~~~~~~
      Make Zulip integrations easier for nontechnical users to set up. This includes adding a backend permissions system for managing bot permissions (and implementing the enforcement logic), adding an OAuth system for presenting those controls to users, as well as making the /integrations page UI have buttons to create a bot, rather than sending users to the administration page. 175 or 350 hours; easy to difficult depending on scope. Skills recommended: Strong Python/Django; JavaScript, CSS, and design sense helpful. Understanding of implementing OAuth providers, e.g., having built a prototype with the Django OAuth toolkit would be great to demonstrate as part of an application. The Zulip integration writing guide and integration documentation are useful materials for learning about how things currently work, and the integrations label on GitHub has a bunch of good starter issues to demonstrate your skills if you’re interested in this area.
      Experts: Niloth, Lauryn Menard

      ~~~~~~~~~~
      Work on Zulip’s development and testing infrastructure. Zulip is a project that takes great pride in building great tools for development, but there’s always more to do to make the experience delightful. Significantly, about 10% of Zulip’s open issues are ideas for how to improve the project’s contributor experience, and are in these four labels for tooling improvements.
      This is a somewhat unusual project, in that it would likely consist of dozens of small improvements to the overall codebase, but this sort of work has a huge impact on the experience of other Zulip developers and thus the community as a whole (project leader Tim Abbott spends more time on the development experience than any other single area). 175 or 350 hours; difficult. Skills required: Python, some DevOps, and a passion for checking your work carefully. A strong applicant for this will have completed several projects in these areas.
      Expert: Tim Abbott

      ~~~~~~~~~~
      Terminal app
      Code: Zulip Terminal
      Experts: Neil Pilgrim, Aman Agrawal
      
      Work on Zulip Terminal, the official terminal client for Zulip. zulip-terminal is out in beta, but there’s still a lot to do for it to approach parity with the web app. We would be happy to accept multiple strong students to work on this project. 175 or 350 hours; medium difficulty. Skills required: Python 3 development skills, good communication and project management skills, good at reading code and testing.
      
      ~~~~~~~~~~
      Desktop app
      Code: Our cross-platform desktop app written in JavaScript on Electron.
      Expert: Anders Kaseorg
      Contribute to our Electron-based desktop client application. There’s plenty of feature/UI work to do, but focus areas for us include things to (1) improve the release process for the app, using automated testing, TypeScript, etc., and (2) polishing the UI. Browse the open issues and get involved! 175 or 350 hours. This is a difficult project because it is important user-facing code without good automated testing, so the bar for writing high quality, reviewable PRs that convince others your work is correct is high. Skills required: JavaScript, Electron; you can learn Electron as part of your application.
      
      ~~~~~~~~~~
      Prototype a next generation Zulip desktop app implemented using the Tauri Rust-based framework. Tauri is a promising new project that we believe is likely a better technical direction for client applications than Electron for desktop apps, for security and resource consumption reasons. The goal of this project would be to build a working prototype to evaluate to what extent Tauri is a viable platform for us to migrate the Zulip desktop app to. 350 hours only; difficult. Skills required: Ability to learn quickly. Experience with Rust and secure software design may be helpful.
      Expert: Anders Kaseorg

      ~~~~~~~~~~
      Mobile app
      Code: The next-generation Zulip mobile app, written with Flutter (now in beta)
      Experts: Greg Price, Chris Bobbe, Zixuan James Li
      Work on the upcoming Flutter-based Zulip client. Zulip has a freshly-written new mobile app built on Flutter, which we’re nearing the point of rolling out to replace the legacy React Native-based app. We’ll be using this foundation to build much-anticipated features that the Zulip mobile apps have never had before, as well as some that the legacy app had but were skipped for the initial rollout.
      This project will involve building features for the Flutter app, including code for UI, data structures, and interacting with the Zulip server and the Android and/or iOS platforms. For a sense of the features we’re working on, see our project board for the new app; the tasks we’ll be working on during GSoC will come mostly from the [“M6: Post-launch” milestone][flutter-milestone-post-launch]. For some features, we may find ourselves contributing changes upstream to the Flutter project itself. 175 or 350 hours; difficult.
      Skills required: Ability to learn quickly, check your work carefully, and communicate clearly and accurately. The code for this project will be written primarily in Dart atop Flutter; previous experience may be helpful, but you can learn both during the contributions leading up to your application. Previous experience with Android or iOS may also be helpful but is not necessary.
      Previous
      Next
      © Copyright 2012–2015 Dropbox, Inc., 2015–2021 Kandra Labs, Inc., and contributors.
      Built with Sphinx using a theme provided by Read the Docs.
      latest
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/zulip/
    idea_list_url: https://zulip.readthedocs.io/en/latest/outreach/gsoc.html

  - organization_id: 174
    organization_name: cBioPortal for Cancer Genomics
    no_of_ideas: 10
    ideas_content: |
      
      Add in Chromoscope component for Strctural Variants visualization
      cBioPortal
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Java
      Javascript
      Size: Large (350h)
      Size: Medium (175h)


      Background
      cBioPortal:
      The cBioPortal for Cancer Genomics is an open-access, open-source resource for interactive exploration of multidimensional cancer genomics data sets. The goal of cBioPortal is to significantly lower the barriers between complex genomic data and cancer researchers by providing rapid, intuitive, and high-quality access to molecular profiles and clinical attributes from large-scale cancer genomics projects, and therefore to empower researchers to translate these rich data sets into biologic insights and clinical applications.
      cBioPortal's Strctural Variants tab:
      In the cBioPortal results view page, we have a Structural Variants tab displaying all strcutural variants regarding queried genes in selected study (see example here). This helps cancer researchers dive deep into detailed strctural variants information on every sample in this study cohort.
      Image
      Chromoscope
      The Chromoscope is an interactive multiscale visualization for structural variation in human genomes. It enables a user to analyze structural variants at multiple scales, using four main views. Each view uses different visual representations that can facilitate the interpretation for a given level of scale. All views in Chromoscope are interactive, allowing a user to explore data effectively.
      Image

      Goal
      Implement backend logic to transform cBioPortal's structural variants data into Chromoscope's data format
      Integrate Chromoscope as a React component into the Structural Variants tab
      To have a sense of what it looks like, we have a patient view page hosting Chromoscope on external server here.

      Approach
      For data format transformation:

      Get familiar with cBioPortal backend codebase
      Compare cBioPortal data format with Chromoscope's, find the mapping relationships between them
      Implement backend transformation solutions and verify the format is correct
      Up to this point can be taken as a medium project.

      For Chromoscope component integration:

      Get familiar with cBioPortal frontend codebase
      Sketch out a frontend design balancing functionality and visual appearace
      Integreat React version of Chromoscope into our Structural Variants tab
      Everything above as a whole can be taken as a large project.

      Needed skills
      Backend: Java, Spring Boot, SQL. Frontend: Typescript, React
      Willingness and ability to gather relavant information (search, docs, etc) and attention to details.
      Maybe some starting point
      Help on some of our backend and frontend issues to demonstrate (show off :0) your understanding of our codebase and your programming skills
      Some hints to think of and can be included in your proposal, among other things:
      Where to find data format specifications?
      How to return transformed results (and communicate to the frontend)?
      The table is displaying multiple samples but can Chromoscope summarize them? Any examples?
      Possible mentors
      Ryan (@fuzhaoyuan)
      
      ~~~~~~~~~~
      Create an automated metadata harmonization/curation tool
      cBioPortal
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Python
      Size: Large (350h)

      Background:
      Though many omics data repositories host large volumes of datasets from diverse studies, cross-study analysis within these repositories is still somewhat limited due to the heterogeneity in their metadata structures. This lack of metadata harmonization especially impedes the application and development of machine learning tools around high-throughput biological data, which is in high demand due to the complexity and high dimensionality of multi-omics datasets. To facilitate comparable analysis across data sources through machine learning, we initiated OmicsMLRepo projects harmonizing metadata from diverse omics data repositories. Under this project, we manually reviewed metadata schema, consolidated similar or identical information spread across schema, and incorporated ontologies where possible. One of our target data repositories is cBioPortal and we have harmonized cBioPortal’s key clinical metadata across the whole data repository, not just at the study level, and incorporated ontology terms to improve the AI/ML-readiness of the cBioPortal data.

      We performed a manual inspection of clinical metadata from 375 studies in cBioPortal (available on 5/13/2023) and harmonized major attributes, such as treatment, demographic information (e.g., age, sex, etc.), and disease. For example, 24 different values (e.g., RADIO_THERAPY, Rad, XRT, etc.) categorized as ‘treatment_type’ were harmonized into a single ontology term, “Radiation Therapy” (NCIT:C15313). While the comparability of the 375 datasets has been improved a lot, cBioPortal is continuously growing and we want to harmonize/digest new data to follow the data dictionary established under the OmicsMLRepo project. To reduce this maintenance effort, we would like to create an automated data harmonization tool.

      The main approach we are currently considering is using semantic similarity. Understanding the meaning of a set of terms is often not straightforward because words might be different but meanings might be the same (e.g., leukemia and blood cancer). “Semantic similarity search” is searching by meaning rather than by word through “encoding”. Encoding is a way of transforming words or sentences into vectors of numbers, such that the points in N-dimensional space (usually 700~2,000), where points near each other have similar meanings. We want to encode both curated terms (from our data dictionary) and uncurated terms (from new incoming data), compare them, and map uncurated terms into curated terms.

      Goal:

      Create an automated data harmonization/digestion tool based on semantic similarity search.
      Create an interactive dashboard showing (and potentially allowing edits on) the automated harmonization results.
      Approach:

      We will use sentence transformers, a type of natural language processing (NLP) model designed specifically for transforming sentences or text snippets into fixed-dimensional vectors to capture the semantic similarity (e.g., txt2onto).
      Commonly used architectures for sentence transformers include BERT (Bidirectional Encoder Representations from Transformers), RoBERTa (Robustly optimized BERT approach), and DistilBERT, among others. Pre-trained transformer models can be fine-tuned on specific tasks or datasets to create sentence embeddings tailored to a particular application.
      Semantic similarity search can be done at two stages - column/attribute names and actual values for a given column/attribute.
      Need skills:
      Python
      R

      Possible mentors:
      Sehyun Oh (@shbrief), Sean Davis (@seandavi)

      If you are interested:
      Anyone interested in this project, please try the EDA below and email your EDA work to Sehyun.Oh@sph.cuny.edu. Looking forward to hearing your idea. Thanks!

      [Required] How can you harmonize new_meta to follow the curated_meta schema with minimum manual curation? You can sketch the overall process or select a specific attribute to demonstrate your idea. (metadata_samples.zip)
      [Optional] Design the curator supporting tool that shows which attribute a new value belongs to.
      [Optional] automated_metadata_curation.ipynb (curated_bodysite.csv)
            

      ~~~~~~~~~~
      Streamline cBioPortal Docker Compose Initialization Setup
      cBioPortal
      devops
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Size: Medium (175h)

      Background:

      cBioPortal: cBioPortal is an open-source platform for cancer genomics data analysis and visualization. It provides a centralized resource for exploring and analyzing large-scale cancer genomic data sets, including genomic alterations, gene expression, and clinical information. The platform integrates data from multiple sources, including The Cancer Genome Atlas (TCGA) and the International Cancer Genome Consortium (ICGC), and makes it available through a web interface for researchers, clinicians, and the general public. Please refer to the cBioPortal home page for an overview.
      Docker Compose: We also provide a Docker Compose Setup to allow users to spin up their own local instances of cBioPortal. This approach involves a lot of bash scripts that need to be run as part of the initialization setup, leading to incompatibility issues and silent errors when these scripts are run on varying operating systems.
      Goal:

      Streamline the cBioPortal docker compose initialization setup by ensuring consistency across operating systems and eliminating silent errors.
      Approach:

      Detect points of failure in the init scripts and eliminate them. Dockerize the init scripts to eliminate dependency on the operating system.
      Ensure the changes are backwards compatible.
      Test changes with other scripts in cbioportal-test repo and localdb tests
      Need skills:
      Familiarity with the command line, bash, docker/docker compose.

      Possible mentors:
      @zainasir


      ~~~~~~~~~~
    
      Show Variant Allele Frequency on the Plots Tab and OncoPrint
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Javascript
      Size: Large (350h)
      Size: Medium (175h)

      Background:

      The cBioPortal is an open-access, open-source resource for interactive exploration of multidimensional cancer genomics data sets, which are collected from a multitude of sources such as published research papers, publicly available data repositories, and private data sets. Please refer to the cBioPortal home page for an overview.

      The cBioPortal can show mutations in a cohort of patients on various pages, but in most places it only shows the mutation type (missense, truncating, etc). Another attribute of a mutation is the "variant allele frequency (VAF)", in how many reads of sequenced DNA a mutation occurs in all of the sequenced DNA at that position in the genome.

      Plots Tab
      One can currently plot e.g. the cancer type vs the number of mutations in a sample (see here):

      Image

      It is, however, not possible to plot e.g. the VAF of a particular gene across the different cancer types (or stages of the tumor), one can only choose categorical values:

      Image

      OncoPrint
      The OncoPrint currently only shows the type of mutations on the Results View. See e.g. here:

      Image

      We can add a new feature to allow users to plot the VAF of each individual mutation in a separate track. Similar to what's possible on the patient view:

      Image

      Goal:

      Add Variant Allele Frequency in the Plots Tab

      Add Variant Allele Frequency in the OncoPrint on the Restuls View

      Approach:

      Add VAF to the Plots Tab:

      Get familiar with the plots tab codebase
      Update the axis selection interface to allow a user to select the VAF of a specific Gene
      Implement and collaborate with other devs
      For OncoPrint:

      Get familiar with the oncoprint codebase
      Update the toolbox interface to allow a user to select the VAF
      Implement and collaborate with other devs
      For a medium project (175h), one could do only the Plots Tab. For a large project (350h), one could implement both. An additional way to expand scope would be to add the cancer cell fraction of a mutation, which is available for a subset of studies.

      Needed skills:

      Javascript, TypeScript, React
      General good programming skills and willingness to learn.
      Possible mentors:

      @onursumer
      @mlizchap
      @gblaih
      @fuzhaoyuan
      
      ~~~~~~~~~~
      LLM Copilot for cBioPortal
      cBioPortal
      Difficulty: Hard
      GSoC-2025
      GSoC 2025 Candidate Projects
      Java
      LLM
      Size: Large (350h)


      Background
      cBioPortal is a powerful platform for exploring cancer genomics data, but its rich interface can be challenging for new users to navigate and interpret. An integrated Copilot (AI assistant powered by LLMs) could guide users through key pages of cBioPortal, answering questions and providing contextual help in real-time. This Copilot concept can be applied to multiple parts of the portal, including:

      Query Page: Assists users in selecting relevant studies and genomic profiles for their analysis through natural language suggestions or explanations of available options.
      Study View Page: Helps users navigate study-level data (genomic alterations, clinical summaries, etc.), highlighting important findings and answering questions about the cohort’s genomic and clinical landscape.
      Results Page: Guides users through complex visualizations (Oncoprint, Plots, Mutations, Mutual Exclusivity, etc.), explaining charts and results, and helping interpret findings (e.g. what a mutual exclusivity plot means or how to download data).
      Comparison Page: Assists in comparing patient groups (e.g. mutated vs. wild-type cases) by explaining differences in genomic or clinical characteristics and helping users set up or interpret group comparisons.
      Patient View Page: Helps users understand a single patient’s data by summarizing the patient’s “journey” (diagnosis, treatments, outcomes) and explaining specific mutations or treatment history in context.
      While the Copilot could eventually span all five pages above, the primary goal for GSoC 2025 is to achieve deep integration on at least one page rather than superficial support across all pages. We would recommend that the proposed project focus on one page. By narrowing the scope to one page, we aim to deliver a fully functional and insightful assistant experience that can later be extended to other parts of cBioPortal. The goal is to fully understand the technical feasibility and showcases the Copilot’s capabilities.

      Benefits to the Community
      Improved User Experience: This project will make cBioPortal more intuitive and user-friendly, especially for novices. An AI Copilot can lower the learning curve by providing on-demand explanations and guidance, allowing researchers and clinicians to focus on insights rather than figuring out the tool.
      Innovation in Bioinformatics Tools: Implementing an LLM-driven assistant in cBioPortal will be a novel proof-of-concept for how AI can enhance bioinformatics software. It could inspire similar features in other scientific platforms and spark further development of intelligent user assistance in open-source tools.
      Efficiency in Data Analysis: Researchers and clinicians will be able to navigate large genomic datasets more efficiently with the Copilot’s help. For example, instead of manually searching documentation, a user could ask the Copilot questions like “How many patients have this alteration?” or “What does this clinical term mean?” and get quick answers. This accelerates data interpretation and could lead to faster hypotheses generation or insights.
      Community and Educational Value: A well-documented Copilot feature can also serve as an educational resource. New contributors can learn from the implementation about integrating AI into web applications. Users of cBioPortal will indirectly learn more about genomics as the Copilot explains concepts to them. Plus, the feature shows the community that cBioPortal is staying at the forefront by adopting modern AI assistance capabilities.
      Overall, the Copilot integration aims to enhance cBioPortal’s functionality and accessibility, ensuring that the research community can leverage the portal’s full potential with greater ease and understanding. The project’s outcome will not only benefit current users but also lay the groundwork for future expansions of AI-driven assistance across the platform.

      Approach
      We will develop an interactive Copilot panel or chatbot UI within the chosen cBioPortal page. The Copilot will leverage a Large Language Model (LLM) to understand user questions or actions and provide helpful, context-specific responses. Key steps include:

      Backend Integration (Java): Extend cBioPortal’s Java backend if necessary to gather the relevant context from the portal (such as current study details, selected patient data, or query parameters) and make it available to the Copilot. This may involve utilizing data fetched by the current page, creating new API endpoints or services to retrieve metadata (e.g. study descriptions, gene annotations, patient clinical data) on the fly.
      API Development: Ensure that all information the Copilot needs (e.g. definitions of genomic terms, interpretation of plots, data summaries) is either already fetched by the page, or can be retrieved through cBioPortal’s APIs. We might enhance existing APIs or add new ones to provide richer context. This will enable the LLM to ground its answers in real cBioPortal data.
      LLM Integration: Use an LLM to power the Copilot’s natural language understanding and generation. The Copilot will be prompted with the context from the current page and the user’s query. We will likely use a hosted LLM service or an open-source model, depending on what’s feasible within the project (ensuring compliance with any data privacy or hosting constraints).
      Prompt Engineering: Craft effective prompts and conversation flows so that the LLM provides accurate and relevant assistance. This involves instructing the LLM on cBioPortal-specific roles (e.g. “You are an expert assistant for a cancer genomics portal…”) and feeding it context like “the user is looking at Oncoprint for Study X” or “the user selected patient Y with these mutations”. Iterative refinement of prompts will be done to handle different user questions (from basic “what is shown in this plot?” to complex “how do I find patients with KRAS mutations and treated with sotorasib?”) and to ensure the responses are correct, concise, and helpful.
      UI/UX Integration: Design a user-friendly interface element on the page (such as a chat window or help sidebar) where users can interact with the Copilot. The UI will display the Copilot’s guidance and allow the user to ask follow-up questions. It should feel like a seamless part of cBioPortal, with context-aware behavior (for example, suggesting what to do next or providing explanations without the user always needing to ask).
      Throughout development, we will test the Copilot’s responses for accuracy and helpfulness. We will also document how the context is gathered and used, to make it easier to expand the Copilot to the other pages in the future. If time permits after achieving a solid integration on the primary page, we can create a minimal prototype on one of the other pages to demonstrate scalability.

      Technologies
      Java: Used for back-end development in cBioPortal. We will use Java to integrate the Copilot with server-side logic, ensuring the LLM has access to necessary data through cBioPortal’s backend.
      REST APIs: Developing and extending APIs will be crucial for retrieving page-specific metadata and context. This project will likely involve creating new API calls or augmenting existing ones.
      LLM (Large Language Model): The core of the Copilot’s intelligence. We will utilize an LLM (such as GPT-based models or similar) to interpret user queries and generate helpful responses. The model could be accessed via an API (e.g. OpenAI, Anthropic, or a local model) depending on feasibility and permissions.
      Prompt Engineering: Techniques for constructing effective prompts and handling the conversation with the LLM. This includes providing context, controlling the tone and detail of responses, and guiding the model to stay on topic (for instance, focusing on genomic data interpretation rather than general knowledge).
      Expected Outcome
      By the end of the project we expect to deliver:

      Copilot on One Key Page: A fully functional, context-aware Copilot integrated into one of the major cBioPortal pages (as identified in the scope). Users should be able to interact with it to get assistance specific to that page (e.g. asking “What does this chart mean?” on the Results page and receiving a useful explanation).
      Enhanced Metadata Access: Any necessary enhancements to cBioPortal’s data retrieval (such as new API endpoints or backend methods) to support the Copilot’s functionality will be implemented. This ensures the Copilot has the data it needs.
      Documentation and Guides: Clear documentation of the Copilot’s implementation and usage. This will include how to configure or extend it to other pages, instructions for developers to maintain or improve it, and maybe a short user guide section on how to use the Copilot feature.
      Proof-of-Concept for Expansion: Although we focus on one page, the project will serve as a template for future Copilot integrations in cBioPortal. The outcome will include insights or even a demo on how the Copilot could be rolled out to the other pages (for instance, noting what additional data would be needed for those pages), providing a foundation for continued development after GSoC.
      Difficulty
      Difficulty Level: Advanced – This project is challenging because it involves cutting-edge integration of AI (LLMs) with a complex bioinformatics platform. The student will need to be comfortable working across the full stack (front-end UI, back-end Java, and external AI services) and handling the uncertainties of LLM interactions. Experience with both software engineering and some understanding of the biological context will be helpful to navigate this project’s complexity.

      Skills Required
      LLM Integration: Experience or willingness to learn how to integrate large language model APIs or libraries. This includes handling API calls, parsing model responses, and possibly fine-tuning prompts or using libraries for better context management.
      Prompt Engineering: Skill in crafting and refining prompts to get useful outputs from the LLM. The student should be prepared to experiment with prompt phrasing and conversation structure to improve the Copilot’s accuracy and usefulness.
      Java Development: Strong skills in Java for modifying cBioPortal’s backend, adding new endpoints, and ensuring the application remains robust and efficient with the new features.
      API Design & Development: Ability to design clear and efficient APIs. The student should be able to extend cBioPortal’s REST API or backend services to provide the data the Copilot needs.
      Web Integration (Frontend): Familiarity with web development (JavaScript/React) to embed the Copilot interface seamlessly into the cBioPortal UI. While the project description emphasizes backend and LLM, some frontend work will be needed for the user interface.
      Bioinformatics Domain Knowledge (Preferred): While not strictly required, familiarity with cancer genomics concepts and portals like cBioPortal will be very beneficial. Understanding terms like “oncoprint”, “mutation frequency”, or clinical data will help in guiding the LLM and interpreting what users might ask.
      Potential Mentors
      @pieterlukasse, @forus, @jjgao, Michele Water, Mitchell Parker

      ~~~~~~~~~~
     
      Re-implement Study View's data binning algorithm using SQL (instead of Java)
      cBioPortal
      Difficulty: Medium
      enhancement
      GSoC-2025
      GSoC 2025 Candidate Projects
      Java
      Size: Medium (175h)
      SQL


      Background:
      cBioPortal is an open-source platform designed to provide a web interface for exploring, visualizing, and analyzing cancer genomics data, and has grown to be widely used by researchers and clinicians worldwide. The current interface provides comprehensive tools for individual patient data exploration, including mutations, copy number variations, and clinical information as well as cohort exploration, analytics, and cohort comparisons.

      The endpoints which drive the histogram charts on the cBioPortal Study View calculate data bins and return them to the frontend for display. To do this, they must fetch the underlying data from the database and run it through custom binning logic written in Java. This is not performant for large data sets. The binning should be done in the database query so that we don't have to return voluminous data and keep it in web server memory. Clickhouse, the new database we are adopting, provides functions to do this.

      Image

      Goal:
      Optimize the cBioPortal Study View data binning algorithm by replacing the existing logic written in Java and re-implementing it so that the heavy lifting is performed by the database instead.

      Approach:
      We believe this is possible using the RoundDown function of Clickhouse (our new OLAP database).

      This project requires:

      Understanding the specific requirements of binning in the cBioPortal (e.g. custom bin definitions)
      Meeting these requirements using RoundDown.
      If 2 proves unfeasible, we may resort to Clickhouse's User Defined Functions.
      Getting started:
      The code which we want to replace can be examined here

      Image

      One case see that the current implementation requires that we load the clinical data into server memory for the purpose of running our custom binning logic in Java. We want to see if we can achieve the binning logic in SQL.

      Possible mentors:
      @alisman
      ~~~~~~~~~~
      Similar Patient Discovery
      cBioPortal
      Difficulty: Hard
      GSoC-2025
      GSoC 2025 Candidate Projects
      Pipeline
      Python
      Size: Large (350h)

      Background:
      The cBioPortal for Cancer Genomics is an open-source platform designed to provide a web interface for exploring, visualizing, and analyzing cancer genomics data, and has grown to be widely used by researchers and clinicians worldwide. The current interface provides comprehensive tools for individual patient data exploration, including mutations, copy number variations, and clinical information as well as cohort exploration, analytics, and cohort comparisons.

      A user can find similar patients by using the interface to look for patients that e.g. are of the same cancer type, have similar mutations, or received the same treatment. There are currently however no similar patients proposed automatically; finding similar ones requires many manual steps. Here, we propose to develop a new web service that would recommend similar patients a user could explore given a patient's molecular and clinical profile. In oncology, where genetic mutations and biomarkers play critical roles in determining the most effective treatments, the ability to easily find and compare similar patient cases is invaluable. Moreover, a patient similarity function within cBioPortal would empower users to leverage the vast amounts of data available in the portal more effectively. By integrating sophisticated similarity search capabilities, users could identify cohorts of patients based on specific criteria, compare their genomic landscapes, and analyze their treatment outcomes.

      image
      Goal:
      Develop a REST API that provides patient similarity information given a patient's molecular and clinical profile. For the similarity scoring we will use an existing algorithm

      Approach:
      We will develop a backend web service for an existing Python-based algorithm that generates a model for identifying similar patients. This web service will provide a RESTful API to allow for communication of the cBioPortal frontend with the patient similarity model. These endpoints will be designed to handle real-time data exchanges, leveraging JSON for its versatility and efficiency in data transmission.

      To manage data updates to the patient similarity model whenever new cBioPortal data is added to the system we propose to leverage event-driven triggers. When new data enters the system, we rerun the pipeline to regenerate the model and redeploy the backend web service Whenever a user visits the frontend page it will be using this new backend web service. This ensures that the frontend displays the most current data, enhancing the user experience in exploring patient similarities. Additionally, to maintain system efficiency and prevent overload, it's crucial to optimize the data payload and update frequency based on user interaction and system capabilities

      Need skills:
      Understanding of RESTful APIs, Familiarity with Python

      Possible mentors:
      @Thahmina
      

      ~~~~~~~~~~
      AI/LLM Generated gene alteration and expression based subtyping for each tumor type
      cBioPortal
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Prompt Engineering
      Python
      Size: Large (350h)
      Size: Medium (175h)

      Background:

      Cancer Classification: Cancer manifests in various forms across different tissues and organs of the body. The classification of cancer plays a pivotal role in understanding its behavior, prognosis, and treatment strategies. Over the years, advancements in medical research and technology have led to a deeper understanding of the molecular and cellular mechanisms underlying cancer development, thereby refining the classification systems used by oncologists and researchers. At its core, cancer classification categorizes malignancies based on a multitude of factors, including their tissue of origin, histological characteristics, genetic alterations, and clinical behavior.
      OncoTree: OncoTree is a dynamic and flexible community-driven cancer classification platform encompassing rare and common cancers that provides clinically relevant and appropriately granular cancer classification for clinical decision support systems and oncology research.
      cBioPortal: cBioPortal is an open-source platform for cancer genomics data analysis and visualization. It provides a centralized resource for exploring and analyzing large-scale cancer genomic data sets, including genomic alterations, gene expression, and clinical information. The platform integrates data from multiple sources, including The Cancer Genome Atlas (TCGA) and the International Cancer Genome Consortium (ICGC), and makes it available through a web interface for researchers, clinicians, and the general public. All samples in cBioPortal are assigned a particular cancer type based on OncoTree
      The Challenge: in cBioPortal there are many pages where it would be useful to list a set of default genes when we know what cancer type the user is looking at. E.g. imagine exploring a breast cancer dataset, it probably makes sense to look at BRCA1, BRCA2 and EGFR alterations. Similarly, for Glioblastoma you'll want to look at IDH1 and IDH2. We can use an LLM (or another method) to generate these recommended genes for each OncoTree code by e.g. constructing a prompt like "Which genes are relevant for subtype x"
      Goal:

      Generate a list of recommended default genes for each OncoTree code that are often used for molecular classification of that subtype
      Approach:

      Try different prompts on any LLM of choice and script a way to do this semi-automatically
      Some example prompts:
      Which genes and pathways are relevant for classifying Breast Cancer? Could you give your answer in a JSON structure like:
      {
          "Breast Cancer": {
              "Mutation-Based": ["Gene1", "Gene2", "Gene3"],
              "Expression-Based": ["GeneX","GeneY","GeneZ"]
              "Pathways": ["PathwayA","PathwayB"]
      }
      The LLM of choice can be vanilla ChatGPT, Gemini, something you train yourself, etc
      Start with just the main OncoTree Types, e.g. "Breast Cancer", "Lung Cancer", etc
      Explore ways to validate the proposed genes. One way would be to leverage the cBioPortal API to see if samples with this OncoTree code have any alterations in those genes
      For the 350h project we can try to do the same for the more detailed subtypes like e.g. 'Breast Lobular Carcinoma In Situ'.
      Need skills:
      Prompt Engineering, Python or similar scripting language

      Possible mentors:
      @inodb

      

      

      ~~~~~~~~~~
      Clinical Timeline Standalone Package and Documentation
      cBioPortal
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Size: Large (350h)
      Size: Medium (175h)

      Background:

      cBioPortal uses the React JS framework to aid in the reusability of components. Some cBioPortal components (i.e., clinical timeline) have been built with the goal of reusability, but require additional work and documentation for the wider community to reuse. The clinical timeline component aids research in understanding how the disease of a patient changes over time for specific samples taken from the patient along with information about their treatment.

      Example: https://www.cbioportal.org/patient?sampleId=gbm_columbia_2019_13&studyId=gbm_columbia_2019
      Screenshot 2024-01-12 at 12 13 16 PM

      Goal:

      The goal is to harden (ensure standalone use and document) the clinical timeline component. Documentation and standalone example for a previous version of the component: https://github.com/cBioPortal/clinical-timeline (the repository is for an old prototype; this is the minimum level of documentation expected as outcome from this project).

      For the larger project (350h) a secondary goal is to generate a wrapper for the standalone component for reuse within the R Shiny web framework (https://cran.r-project.org/web/packages/reactR/vignettes/intro_htmlwidgets.html).

      Approach:
      The clinical-timeline is already a package in the cBioPortal frontend monorepo. We will begin by adding a README file to the existing NPM package that explains how to embed this package into a new create-react-app project. Iteratively we'll add more documentation so it starts looking more similar to the old clinical timeline package README in terms of completeness.

      Need skills:

      Typescript, Javascript

      Code/Repositories:

      https://github.com/cBioPortal/cbioportal-frontend/tree/master/packages/cbioportal-clinical-timeline
      https://github.com/cBioPortal/cbioportal-frontend/blob/master/src/pages/patientView/timeline/timeline_helpers.tsx
      https://www.npmjs.com/package/cbioportal-clinical-timeline
      Possible mentors:

      Augustin Luna
      Ino de Bruijn
    
      ~~~~~~~~~~
      Create Chat Bot Interface Trained On Documentation Site
      cBioPortal
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Size: Large (350h)
      Size: Medium (175h)

      Background:

      cBioPortal: cBioPortal is an open-source platform for cancer genomics data analysis and visualization. It provides a centralized resource for exploring and analyzing large-scale cancer genomic data sets, including genomic alterations, gene expression, and clinical information. The platform integrates data from multiple sources, including The Cancer Genome Atlas (TCGA) and the International Cancer Genome Consortium (ICGC), and makes it available through a web interface for researchers, clinicians, and the general public. Please refer to the cBioPortal home page for an overview.
      cBioPortal has lots of documentation available (https://docs.cbioportal.org/) on how (1) to install and configure cBioPortal locally, (2) use cBioPortal as a user, (3) programmatically use the API. Searching through the documentation is not always straightforward and we often get questions on the user group (https://groups.google.com/g/cbioportal) where we mainly point to a link in the docs. A chat interface might be a good solution for giving users quicker feedback on what they are searching for
      The cBioPortal documentation site uses ReType and all the markdown files are located here: https://github.com/cBioPortal/cbioportal/tree/master/docs
      Goal:

      Build a chat bot interface for cBioPortal's Documentation
      Approach:

      Evaluate existing services in this space, e.g. Custom GPT, PickAxe, Gitbook AI), or others. Contrast these against training a local LLM in terms of development time and cost
      Train one or more models on our documentation site
      Evaluate the models. Implement a suite of tests that can check output or provide a document for manual evaluation
      Integrate chat interface into the documentation site, which should allows users to interact with it (350h project). Note that we have ~3K users / day, so please keep cost into consideration for the deployment setup
      Need skills:
      Familiarity with the command line and the use of APIs

      Possible mentors:
      @zainasir
      @inodb
      @walleXD


      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/cbioportal-for-cancer-genomics/
    idea_list_url: https://github.com/cBioPortal/gsoc/issues?q=is%3Aissue%20state%3Aopen%20label%3AGSoC-2025

  - organization_id: 175
    organization_name: checkstyle
    no_of_ideas: 17
    ideas_content: |
      AI-Powered XPath Generator for Checkstyle Suppressions
      Improve Modules used in Google Style
      Auto-fix Module
      Markdown Javadoc Support
      Improve Performance of Html-formatted Javadoc parser and create new Markdown Javadocs parser
      Optimization of distance between methods in single Java class
      Reconcile formatters of Eclipse , NetBeans and IntelijIdea IDEs by Checkstyle config
      Coverage of Documentation Comments Style Guide and performance improvement
      Open JDK Code convention coverage
      Spellcheck of Identifiers by English dictionary
      Patch Suppression improvement
      Extend Checker Framework Integration
      New ANTLR Grammar for Javadoc Comments
      Upgrade dependencies to use latest version of libraries and use their features
      Enhance Mutation Testing Coverage
      Eliminate Maven Plugin Usage
      Automated Website Generation
      Project Name: AI-Powered XPath Generator for Checkstyle Suppressions
      Skills required:
      Java (advanced)
      Knowledge of XPath
      Experience with machine learning frameworks
      Basic understanding of Abstract Syntax Trees (AST)
      Familiarity with Docker
      Project goal: Develop a local LLM-based solution that generates optimal XPath queries to suppress specific Checkstyle violations based on user prompts, violation details, and code context.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Ruslan Diachenko, Roman Ivanov, Andrei Paikin, Timur Tibeyev
      Description: Creating XPath expressions to suppress Checkstyle violations is a complex task requiring deep understanding of both XPath syntax and AST structure. This leads to either overly broad suppressions hiding important issues or overly specific rules needing frequent updates. This project aims to create an AI-powered system to convert Checkstyle violations and user instructions into precise XPath expressions for violation suppression. The core focus is on developing a containerized LLM-based solution that can understand both the violation context and user intent to generate accurate XPath queries.
      A preliminary proof of concept (PoC) demonstrates the basic feasibility of using LLMs for XPath generation. While this PoC serves as an experimental starting point, the GSoC project will require a complete redesign and implementation to create a production-ready solution.
      Deliverables:
      Containerized LLM-based solution for XPath generation
      Command-line interface for basic interaction
      Basic documentation for setup and usage
      Fix for all issues with "xpath" label in the Checkstyle repository
      QnA: https://discord.com/channels/845645228467159061/1338507765207007242 (invite)

      ~~~~~~~~~~
      Project Name: Upgrade dependencies to use latest version of libraries and use their features
      Skills required: Java, Groovy, BASH, continuous integration, basic understanding of testing principles
      Project goal: upgrade our jdk to 17 and 21, bump all other dependencies
      Project size: medium (175 hours)
      Complexity Rating: intermediate
      Mentors: Roman Ivanov,
      Description:
      we use jdk11, whole world already use jdk21 , we need to bump minimal jdk usage to jdk17 and than to jdk21. Bump version of apache doxia, and other dependencies.
      Deliverables:
      bump jdk dependency
      bump for doxia dependencies
      bump for intelij idea inspection
      check if we can use BOMs for dependency management
      activate Checks UnusedLambdaParameterShouldBeUnnamed, UnusedCatchParameterShouldBeUnnamed, SealedShouldHavePermitsList, WhenShouldBeUsed, MissingNullCaseInSwitch
      use maven wrapper
      migrate our code base to new nio jdk api - https://github.com/checkstyle/checkstyle/issues/16155
      
      
      
      create module-info.java, see initial activity https://github.com/checkstyle/checkstyle/pull/14139
      QnA: https://discord.com/channels/845645228467159061/1338509064669495377 (invite)

      ~~~~~~~~~~
      Project Name: Markdown Javadoc Support
      Skills required: Java, basic understanding of testing principles, basic understanding of static analysis
      Project type: new feature implementation.
      Project goal: Integrate support for Markdown Javadoc comments in Checkstyle.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Nick Mancuso
      Description:
      With the introduction of JEP 467, Java supports Markdown-style documentation comments. This feature modernise Java's documentation capabilities but is not currently supported in Checkstyle. The current Javadoc parsing in Checkstyle is tightly coupled to the traditional /** ... */ syntax and HTML-based formatting, presenting challenges in extending support for Markdown's structure. This project aims to enhance Checkstyle by introducing new grammar and update exisiting checks to support Markdown Javadoc comments.
      Deliverables
      New implementation of grammar for Markdown Javadoc Comments
      New tokens to identify and validate elements specific to Markdown Javadoc syntax.
      New Checkstyle Checks for new format of javadoc, ideas on what should be validated should be taken from existing Checks.
      Creation of new checks (if necessary): Create new checks to enforce Markdown-specific best practices.
      


      QnA: https://discord.com/channels/845645228467159061/1338509670255562772 (invite)

      ~~~~~~~~~~
      Project Name: Improve Performance of Html-formatted Javadoc parser and create new Markdown Javadocs parser
      Skills required: strong Java, deep understanding of testing principles, understanding of how language grammar works
      Project type: improvement and new feature implementation.
      Project goal: improve Performance of Html formatted Javadoc Check and parsing support of Markdown Javadocs.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov
      Description:
      Performance improvement of existing javadoc parser are expected, see details at https://github.com/checkstyle/checkstyle/issues/11193 .
      With the introduction of JEP 467, Java supports Markdown-style documentation comments. This feature modernise Java's documentation capabilities but is not currently supported in Checkstyle. This project aims to enhance Checkstyle by introducing new grammar, implementation of few basic validations just as prove of concept and example of new parser posibilities.
      Deliverables
      Improved implementation of html based javadoc Checks, possible breaking changes is fine.
      Update for all AST based existing Checks to use new html based parser (we can update some Checks only if there will be time constraints).
      New implementation of grammar for Markdown Javadoc Comments
      New tokens to identify and validate elements specific to Markdown Javadoc syntax.
      Few Checkstyle Checks for new format of javadoc, ideas on what should be validated should be taken from existing Checks.
      New documentation html page to explain how to write Check for markdown javadoc validation.
      
      QnA: https://discord.com/channels/845645228467159061/1338849908211580969 (invite)

      ~~~~~~~~~~
      Project Name: Improve Modules used in Google Style
      Skills required: Java, basic understanding of testing principles, basic understanding of static analysis
      Project goal: improve quality of google style guide implementation
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Mauryan Kansara, Daniel Mühlbachler,
      Description:
      During GSoC'24, we successfully updated our implementation of google style guide to the latest version ( 03 Feb 20222 ). google_checks.xml is the configuration file where our google java style guide is implemented. Though we have covered almost all rules of the google style guide, users have reported bunch of issues pointing out flaws in our implementation, these issues are labeled as google style issues, we need to solve them. On top of this, we have few rules which we are not able to completely follow/implement, they are marked with "Blue Tick" in our coverage page, we need to find a way to reduce such blue ticks rules and improve our coverage.
      Deliverables:
      Resolve all issues labeled as google style
      Reduce "Blue Tick" rules by analyzing the rule and our coverage for that rule and provide solutions for them.
      Investigate the issues related to Modules/Checks in issue tracker of Checkstyle repository which are used in google_checks.xml, if the Module/Check configuration found in the issue is same as present in google_checks.xml then that issue is qualified for the project, it should be reported to us and marked by google style label.
      We already have started process of triaging issues which affects user experience, they're listed at: https://github.com/orgs/checkstyle/projects/10, this work should be continued and finished.
      
      QnA: https://discord.com/channels/845645228467159061/1338510140277522442 (invite)

      ~~~~~~~~~~
      Project Name: Auto-fix Module
      Skills required: intermediate Java
      Project type: new feature implementation.
      Project goal: implement new module, test it on real projects
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Baratali Izmailov
      Description: Checkstyle is known as tool that raises numerous minor issues. There are so many of these and they are so minor that it is hard to find time and engineer to fix them. Most of the issues are so easy to fix but navigation to certain part of the code and making the fix takes time. Engineers could spend this time doing something more valuable. Implementation of an auto-fix functionality could significantly simplify introduction of checkstyle to project as it will do most tedious work automatically.
      The major part of checkstyle violations are specifically targeting the formatting of the code. It is often that IDE formatting settings are not in sync with the checkstyle configuration. The IDE can fix the code itself as part of it’s auto-formatting. The same should be done by Checkstyle. Each Check that is targeting the formatting part of the code should have “Fix” functionality built-in. This functionality will convert the code with the violation to compliant code without any user interaction. Such functionality is in huge demand by users.
      In scope of this project, it is required to review all existing functionality of auto-fix of code in plugins and tools to learn challenges they have and see the whole list of requirements to resolve such a task. Make implementation of auto-fix for formatting Checks as part of a special Module that takes all reported violations and fix them that will support auto-fix. If the resulting functionality proves to be easy to maintain, and might be reused by checkstyle plugins, then propose API changes can be brought to the core library and allow any plugins to reuse it.
      More details at https://github.com/checkstyle/checkstyle/issues/7427
      Links to similar tools: https://docs.openrewrite.org/tutorials/automatically-fix-checkstyle-violations, https://github.com/solven-eu/cleanthat
      Ai autofix for checkstyle: https://link.springer.com/article/10.1007/s10664-021-10107-0
      Auto fix in Eclipse https://github.com/checkstyle/eclipse-cs/pull/566/files#diff-13e277cb135ea2a474dad0b4ac46b5cb020f9c03a2eb6676b15de010f8aec369R549
      OpenRewrite project - example of enabling at eclipse-cs https://github.com/checkstyle/eclipse-cs/pull/805
      Deliverables:
      selection of existing library that will do code modification or making our own implementation
      defining api for triggering code changes
      selection of Checks that can produce violations that are auto fixable
      implementation of auto fix for selected Checks
      find a model to avoid conflicts of auto fixes
      QnA: https://discord.com/channels/845645228467159061/1214569225247793282 (invite)

      ~~~~~~~~~~
      Project Name: Optimization of distance between methods in single Java class
      Skills required: basic Java , good analytical abilities, good background in mathematics.
      Project type: new feature implementation.
      Project goal: to make quality practices automated and publicly available.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Baratali Izmailov, Ruslan Diachenko
      Description:
      This task is ambitious attempt to improve code read-ability by minimizing user jump/scrolls in source file to look at details of method implementation when user looks at method first usage.
      It is required to analyse a lot of code and find a model to minimize distance between methods first usage and method declaration in the same file and respect users preferences to keep grouped overloaded and overridden methods together. Some other preferences may appear during investigation of open-source projects.
      First step is already done by our team, we created a web service that already calculate distances between methods and make DSM matrix to ease analysis - methods-distance. We already practice it in our project.
      As a second step it is required to use a matrix of distances between methods and optimize it by some empiric algorithm to allow user define expected model of class by arguments. This will allow to use this algorithm as a Check to enforce code structure automatically during build time.
      Prove of necessity: we have a number of PRs where contributors put new methods at any possible place in a class but better place is close to first usage. Example #1, Example #2, Example #3, ....
      Deliverables:
      new Checkstyle's Check with optimization algorithm to share the algorithm with whole java community.
      analytical report that proves reason why default values for Check parameters are selected
      article with all details of analysis and algorithm details;
      QnA: https://discord.com/channels/845645228467159061/1214569693336182864 (invite)

      ~~~~~~~~~~
      Project Name: Reconcile formatters of Eclipse , NetBeans and IntelliJ IDEA IDEs by Checkstyle config.
      Skills required: basic Java.
      Project type: new feature implementation, analysis of existing IDE features.
      Project goal: to make well-known quality practices publicly available.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Andrei Paikin, Mauryan Kansara
      Description:
      Usage of different IDEs in the same team is already a serious problem, as different IDEs format code base on their own rules and configurations. Unwanted formatting changes happen to code which complicate code-review process. Problem become more acute when project use static analysis tool like Checkstyle that has a wide range of code formatting Checks.
      It is required to make it possible to use the same Checkstyle config to work in IDEs without conflicts with IDEs internal formatters. This will help team members be independent on IDE choice but at the same time keep the same format and code style throughout the team.
      Main focus of this project is the analysis of formatting abilities of IDEs (indentation, imports order, declaration order, separator/operator wrap, .....) . Update existing Checkstyle Rules to be able to work in the similar and non-conflicting way.
      Deliverables:
      create configuration for IDEs for Checkstyle project to let Checkstyle team use it and auto-format code to conform with checkstyle_check.xml file that is used by Continuous Integration.
      create Checkstyle config that follows default Eclipse formatting + inspection rules
      create Checkstyle config that follows default IntelliJ IDEA formatting + inspection rules
      create Checkstyle config that follows default NetBeans formatting + inspection rules
      Deep refactoring of Indentation Check to fix its numerous problems.
      Prove of necessity: mail-list post #1, mail-list post #2, mail-list post #3 , discussion #1
      QnA: https://discord.com/channels/845645228467159061/1214571037451100180 (invite)

      ~~~~~~~~~~
      Project Name: Open JDK Code convention coverage
      Skills required: basic Java.
      Project type: new feature implementation.
      Project goal: to make well-known quality practices publicly available.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Baratali Izmailov, Daniel Mühlbachler, Mauryan Kansara
      Description:
      OpenJdk Code Convention was one of the first guidelines on how to write Java code. OpenJdk Code Convention is marked as outdated (because of date of last update made in it) but best practices described there do not have an expiration date. New OpenJDK Java Style Guidelines is close to the final version and most likely will be successor of OpenJdk Code Convention. But there is a number of projects in Apache that still follow OpenJdk rules, so both configurations are in need by community.
      OpenJdk Code Convention is already partly covered by Checkstyle, known as Sun Code Convention. A lot of validation Rules were added and changed in Checkstyle from the time when Sun's configuration was created (2004 year).
      During the project it is required to review both documents in detail and prove publicly that Checkstyle covers all guideline rules. Missed functionality needs to be created, blocking bugs need to be fixed. Page OpenJdk Java Style Checkstyle Coverage needs to be updated. New page "New OpenJDK's Java Style Checkstyle Coverage" need to be created. Both pages need to be formatted in the same way as it is done for Google's Java Style Checkstyle Coverage.
      Prove of necessity: javadoc issues on github; results of open survey; request from users for Openjdk coverage support.
      Deliverables:
      embedded config file with all modules that are required for coverage
      html page that explains how each paragraph in style guide is covered by Checkstyle
      
      QnA: https://discord.com/channels/845645228467159061/1214571550783840307 (invite)

      ~~~~~~~~~~
      Project Name: Coverage of Documentation Comments Style Guide and performance improvement
      Skills required: basic Java.
      Project type: new feature implementation.
      Project goal: to make well-known quality practices publicly available.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Baratali Izmailov, Mauryan Kansara
      Description:
      Project will mainly be focusing on automation of Documentation Comments (javadoc) guidelines by Checkstyle Checks. Reliable comments parsing was a major improvement in Checkstyle during GSoC 2014, archived results need to be reused to reliably implement automation of Javadoc best practices.
      Separate configuration file with newly created Checks need to be created. Best practices in documentation make sense not for all projects. Javadoc validation matters only for library projects that need to expose online documentation in web publicly.
      Performance improvement of existing javadoc parser are expected, see details at https://github.com/checkstyle/checkstyle/issues/11193 .
      Deliverables: The result of this project will be a configuration file with the maximum possible coverage of Comment style guide. Report should look like Google's Java Style Checkstyle Coverage. Performance improvements of javadoc parsing. If there will be time left we can focus on coverage of guidelines from https://blog.joda.org/2012/11/javadoc-coding-standards.html
      Prove of necessity: javadoc issues on github.
      QnA: https://discord.com/channels/845645228467159061/1214571282776064130 (invite)

      ~~~~~~~~~~
      Project Name: Spellcheck of Identifiers by English dictionary
      Skills required: intermediate Java.
      Project type: new feature implementation.
      Project goal: implement spell checking for java code for all identifiers .
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Andrei Paikin
      Description:
      The correct spelling of words in code is very important, since a typo in the name of method that is part of API could result in serious problem. Mistakes in names also make reading of code frustrating and misleading, especially when a typo in one letter makes developer to read javadoc or even implementation of the method. Two most popular IDEs (Eclipse and IntelliJ IDEA) already have spell-check ability. It will be beneficial for Checkstyle to have the same functionality that could be used in any Continuous Integration system by Command Line Interface or as part of build tool (maven, ant, gradle, ....) with wide range of options to customize to users needs. Features of existing spell-checkers need to be analyzed -
      IntelliJ IDEA Spellchecking , Eclipse Spelling. There are numbers of open-source projects that do spell-check. It is ok to reuse them if license is compatible. Examples: https://code.google.com/archive/p/bspell/ , http://www.softcorporation.com/products/spellcheck/, ... https://github.com/giraciopide/shellcheck-maven-plugin, https://github.com/codespell-project/codespell
      Deliverables:
      regular Checkstyle module that does validation
      such module should be applied to all sources of our Code
      disablement of shell based implemnetation of spellcheck in our project for java sources.
      documentation on how to use module
      QnA: https://discord.com/channels/845645228467159061/1214572273038786631 (invite)

      ~~~~~~~~~~
      Project Name: Automated Website Generation
      Skills required: Java, basic understanding of testing principles, technical writing, continuous integration
      Project goal: organize documentation and automate its maintenance
      Project size: large (350 hours)
      Complexity Rating: intermediate
      Mentors: Roman Ivanov, Daniel Mühlbachler,Mauryan Kansara
      Description:
      This project is designed to tackle the persistent challenge of maintaining accurate and current documentation in our dynamic development environment. Acknowledging the limitations of manual documentation processes, this initiative introduces automation to streamline content creation, with a focus on ensuring consistent formats and robust verification checks. The project's goal is to provide users with reliable, standardized, and regularly updated information while equipping contributors with templates and automated tools to simplify the incorporation of details for new modules. By elevating documentation practices, this project aligns with industry best practices, fostering clarity for both users and contributors within the Checkstyle project.
      Deliverables:
      migration to latest maven site plugin and doxia library.
      Reusage of xdoc templates model that we already have.
      Introduction of description macros that would take content from javadoc of module
      Resolution of edge cases in documentation generation
      Extend and make consistent all check usage examples
      Reduce/eliminate manual documentation updates for examples
      Introduce checks to ensure that all configuration options are covered in examples
      Moving website generation logic to separate project to avoid extra classes and dependencies in checkstyle jar artifact.
      HTML Enhancements for our website to ease navigation and user experience by search toolbar
      QnA: https://discord.com/channels/845645228467159061/1214574452021530686 (invite)

      ~~~~~~~~~~

    
      Project Name: Enhance Mutation Testing Coverage
      Project goal: reduce technical debt and improve code quality
      Skills required: Java, basic understanding of testing principles
      Project size: large (350 hours)
      Complexity Rating: intermediate
      Mentors: Roman Ivanov, Daniel Mühlbachler, Mauryan Kansara
      Description:
      Checkstyle has recently enriched its mutation testing suite with a set of new mutators powered by pitest, a state-of-the-art mutation testing system renowned for providing gold standard test coverage in Java and the JVM. This project focuses on a meticulous review of suppressions employed within Checkstyle to manage pitest violations, aiming to identify opportunities for new tests or adjustments to existing ones that can effectively resolve these suppressions. The objective is to ensure the continued functional soundness of the code, potentially involving a deep dive into module logic to facilitate test identification and contribute to the resolution of suppression-related issues.
      Deliverables:
      Review of existing suppressions of pitest survivals
      New tests or improvements to existing tests
      Resolution of 100% of existing suppressions
      usage of new mutators https://docs.arcmutate.com/docs/extended-operators.html
      Documentation, including examples
      QnA: https://discord.com/channels/845645228467159061/1214573720056762468 (invite)


      ~~~~~~~~~~
      Project Name: Eliminate Maven Plugin Usage
      Skills required: Java, Groovy, Maven
      Project goal: remove all usages of maven-checkstyle-plugin in our tools
      Project size: medium (175 hours)
      Complexity Rating: intermediate
      Mentors: Roman Ivanov, Daniel Mühlbachler,
      Description:
      Checkstyle serves as a widely used library across various tools, with a notable dependency on the maven-checkstyle-plugin for continuous integration and regression testing. However, this reliance on an external tool has restricted our ability to introduce breaking changes to the Checkstyle project, given the potential disruptions it causes in testing. Consequently, we've had to implement workarounds to maintain the connection and dependence on the maven-checkstyle-plugin. To foster autonomy and minimize dependencies, Checkstyle is undertaking efforts to break away from this plugin and shift towards relying solely on tools under our maintenance. The list of connected issues below outlines specific areas that require modification to facilitate this transition.
      Deliverables:
      Remove all usages of maven-checkstyle-plugin in our tools
      Update documentation to reflect changes
      Update build, CI, and regression testing to use internal tools exclusively
      Connected Issues:
      Launch/Diff Groovy should remove use of maven-checkstyle-plugin
      Convert sevntu-checkstyle-check to ant run
      Convert regressions that use maven-checkstyle-plugin to CLI based
      Example of Plugin Issue: Upgrade XML logger to XML 1.1
      QnA: https://discord.com/channels/845645228467159061/1214574180591214592 (invite)

      ~~~~~~~~~~
      Project Name: Patch Suppression improvement
      Skills required: basic Java
      Project type: extension of existing feature implementation.
      Project goal: implement new strategies for existing filter/suppression module or improve existing
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Ruslan Diachenko
      Description: Introducing Checkstyle to a project can be a challenging and NOT an easy job, especially when a project has massive amount of code, very active in development, and there are no resources to start a new process of code cleanup. It may require an extensive effort, especially when there is legacy code from previous contributors that becomes a monotonous job, that everyone tries to avoid. It is easy to say how code should look like, but may be hard to actually enforce rules in existing codebase.
      For example Guava is not following google style, and it is easy to say how code should look like but hard to assign somebody to fix ALL problems from previous contributors. It is very boring activity that all will try to avoid. Good practice from openjdk actually discourage code changes without good reason.
      Better approach is to let existing code be as is and validate only new code. Checkstyle already has a wide array of filter functionality that could suppress certain violations if user classify a violation as “won’t fix”. Just getting started with setting up the initial suppressions still requires a huge effort to review all the violations, or organize a team on special cleanup process.
      This project was originally done at GSOC 2020, but during usage of this project we found problems that checkstyle violations are still going beyond changed code that creates avalanche of change so it complicate usage of it in real project.
      We need to invest focus on parsing of patch files to get more precise location of changes and be able skip violation if fix for it goes outside of changed lines. For example: user changing line wrapping of long signature of method and we should not demand decreasing of amount of parameters or fixing names, as this will trigger changes in other part of code.
      As proof of success for this project, it is required to get some open source project onboard to use checkstyle and this new feature. It would be good to try collaborate one more time with Guava project or we can ask our friends in Eclipse-CS or Spring or Hbase project.
      Deliverables:
      new Filter in Chekstyle that is applied to our code base.
      documentation on how to use new filter.
      apply filer to eclpse-cs project to work on each update (address feedback from usage).
      QnA: https://discord.com/channels/845645228467159061/1214572538043043890 (invite)

      ~~~~~~~~~~
      Project Name: Extend Checker Framework Integration
      Skills required: Java, basic understanding of testing principles, basic understanding of Java type system
      Project goal: Further usage of Checker Framework and increase internal knowledge base
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov
      Description:
      The goal of this project is to advance the integration of the Checker Framework into our existing codebase, enhancing code quality, correctness, and maintainability. In addition to refining the setup already present in our build, the project will focus on incorporating the Checker Framework's type system into key components of our code and creating comprehensive documentation and best practices to guide developers in utilizing the framework effectively.
      Deliverables:
      Integrate Checker type system with codebase
      Refine existing build
      Develop internal documentation about our usage of Checker
      Provides examples, guidelines and best practices for developers to follow
      QnA: https://discord.com/channels/845645228467159061/1214572824736571472 (invite)

      ~~~~~~~~~~
      Project Name: New ANTLR Grammar for Javadoc Comments
      Skills Required: Java, understanding of testing principles, static analysis, and language grammar.
      Project Type: New feature implementation.
      Project Goal: Develop a new ANTLR-based parser for Javadoc comments to improve performance and maintainability.
      Project Size: Large (350 hours)
      Complexity Rating: Hard
      Mentors: Roman Ivanov, Nick Mancuso
      Description:
      The need for a new parser has been discussed multiple times due to growing issues with the old implementation(e.g., Performance Issue 1, Performance Issue 2). This project introduces a new ANTLR-based grammar for parsing Javadoc comments in Checkstyle. The existing Javadoc parser becomes inefficient and hard to maintain. making Javadoc validation a bottleneck. By replacing it, we aim to improve performance, accuracy, and maintainability while ensuring compatibility with existing Javadoc checks. The existing AST-based Javadoc checks will be incrementally migrated to the new parser, ensuring a seamless transition. Additionally, the old parser will be deprecated, allowing Checkstyle in the future to fully rely on the new parser for better maintainability.
      Speeding up Javadoc parsing will enable users to run Checkstyle more frequently without performance concerns, making Javadoc checks easier to integrate into code reviews and build cycles. Currently, enabling any Javadoc check significantly increases validation time, making it frustrating to use. The new parser aims to resolve this issue.
      Deliverables:
      A maintainable and effiecent ANTLR grammar for Javadoc comments.
      Update for all AST-based existing Checks to use the new parser (we can update some Checks only if there will be time constraints), possible breaking changes is fine.
      Update for all non-AST checks to use the new paresr (we can update some Checks only if there will be time constraints).
      Deprecation Plan: Transition strategy for phasing out the old parser.
      New documentation to help the community understand new parser and contribute to the migration process.
      QnA: https://discord.com/channels/845645228467159061/1338849908211580969 (invite)
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/checkstyle/
    idea_list_url: https://github.com/checkstyle/checkstyle/wiki/Checkstyle-GSoC-2025-Project-Ideas


  - organization_id: 176
    organization_name: dora-rs
    no_of_ideas: 4
    ideas_content: |
      
     
      Project #1: Robot Data Collection improvement.
      Description The robot data collection is expensive and hard to manage. The primary objective of this project is to create an end to end tutorials with affordable robot kit, specifically designed around the Dora platform, and utilize it to establish a comprehensive robot dataset collection system. This system is designed to facilitate the collection of data, which can be used for various applications such as robotics research, algorithm development, and model training.
      Expected Outcomes
      Designing and 3D printing the robot components. The robot will be constructed using 3D - printed components made from low - cost materials. This approach not only reduces the overall cost of the robot but also allows for easy customization and modification. The use of 3D printing enables the creation of complex geometries tailored to the specific requirements of the data collection tasks. This can be done with help from other open source projects such as Koch robot arms.
      Creating the Mojoco robot model. A Mojoco robot model will be created based on the robot arm. Mojoco is a high - performance physics simulation engine that provides accurate and efficient simulations. By creating a Mojoco model of the robot, we can collect data from the simulated model. This simulated data can serve as a baseline or supplement to the data collected from the real robot, and can also be used for preliminary testing and algorithm development in a controlled virtual environment.
      Implementing data collection nodes in Dora. The system will be programmed to collect a variety of data from the real robot, including the robot's joint angles, rotational speeds, and pose information. The data format can follow the ARIO unified data format or the LeRobot Dataset format.
      Create tutorials and documentation that will help the community replicate the data collection system.
      dataset collected will be shared within the open source community.
      Resources.
      https://imaei.github.io/project_pages/ario/
      Skills required/preferred. Python, CAD, DORA
      Difficulty rating. medium
      Expected size: 350h
      Mentors: bding@dora-rs.org, huangyu@dora-rs.org

      ~~~~~~~~~~
      Project #2: Improve Dora-Lerobot Demo Tutorial
      Description In robotics education, a gap often exists between theoretical knowledge and practical application. Dora-Lerobot bridges this gap by integrating hands-on learning with AI-powered, pre-trained models. Its primary goal is to lower the barrier to entry in robotics, enabling everyone to master end-to-end control.
      Recently, support for the SO-ARM100, a low-cost robotic arm, was added to Dora through its driver. However, there is currently no end-to-end tutorial available for using this arm. Tutorials and documentation are critical for making the project more accessible to new users.
      The goal of this project is to improve the Python-based tutorial for using the SO-ARM100 robotic arm with Dora-LeRobot, enabling users to easily get started and contribute to the ecosystem.
      Expected Outcomes
      Fix issues and add missing code so that Dora-LeRobot can be run with SO-ARM100 successfully.
      Writing detailed setup and usage tutorials.
      Implementing code for calibration, control, training, and inference.
      Creating video tutorials and improve based on community feedbacks.
      Creating test plan for user testing to ensure the tutorial is easy to follow.
      Resources.
      https://github.com/dora-rs/dora-lerobot/tree/main
      https://github.com/huggingface/lerobot
      Skills required/preferred. Python, Rust, DORA
      Difficulty rating. medium
      Expected size: 350h
      Mentors: shavtao@gmail.com, bding@dora-rs.org

      ~~~~~~~~~~
      Project #3: Enhancing Debugging with Rerun
      Description Currently, debugging Dora nodes has several limitations. There's limited real - time visibility as debug messages are only accessible from log files, forcing developers to halt the robot application, access and analyze logs, which is time - consuming and lacks real - time insights. There's also a lack of integrated visualization, making it hard to correlate debug messages with sensor data processing like LiDAR or camera feeds, and thus difficult to determine if issues in object detection are due to sensor data or the algorithm. Additionally, the absence of a unified real - time debugging solution leads to a fragmented debugging experience, with developers relying on multiple tools and techniques, making it more challenging to identify and fix issues efficiently.
      Expected Outcomes
      Improving the dora-rerun node to collect real-time debug messages. Improve dora-rerun node to allow rerun viewer to collect each node real time debug message with python or rust.
      Displaying sensor data processing examples. Create sensor data processing(e.g., LiDAR, camera feeds) python or Rust example code and documentation to show how to use debug messages.
      Visualizing robot trajectories and arm poses. Rerun will be used to visualize robot trajectories, arm poses, or other relevant data in the same rerun window and how to setup with detailed tutorials.
      Creating detailed tutorials. Create detailed tutorials on how to set up Rerun for debugging Dora nodes. This makes it easier for developers, especially those new to Rerun or Dora, to start using this debugging tool effectively.
      Resources.
      https://github.com/dora-rs/dora/tree/main/node-hub/dora-rerun
      Skills required/preferred. Rust, DORA
      Difficulty rating. medium
      Expected size: 175h
      Mentors: shavtao@gmail.com, bding@dora-rs.org

      ~~~~~~~~~~
      Project #4: Support additional hardware
      Description Dora currently lacks a library for many widely used robots such as UR5, Franka, .... This project aims to extend Dora’s capabilities by adding support for Universal Robots’ UR5 collaborative robots and more. The primary focus is to develop better hardware integration within the Dora framework. By doing so, it will empower developers to more effectively integrate and utilize Dora in combination with their existing assets, opening up new possibilities for seamless robotics development and enhanced productivity.
      Example Expected Outcomes
      Developing the Rust library for UR5 control. A well-documented, efficient, and effective Rust library that interfaces with UR5 cobots through Dora.
      Integrating with URSim. The project will include an implementation that demonstrates control of the UR5 robot model and its gripper within the URSim virtual machine environment.
      Porting the test_move example to Rust. A Rust version of the test_move example (originally in Python) will be developed, providing a concrete demonstration of how to use the library with Dora.
      Creating comprehensive documentation and tutorials. Comprehensive documentation and usage tutorials that guide developers on UR5 support within their robotics projects using Dora.
      Resources.
      (https://github.com/UniversalRobots/Universal_Robots_ROS_Driver/blob/master/ur_robot_driver/scripts/test_move)
      https://github.com/dora-rs/libfranka-rs. for reference on interfacing with robotics hardware using Rust
      Skills required/preferred. Rust,C++, Python, DORA
      Difficulty rating. hard
      Expected size: 350h
      Mentors: bding@dora-rs.org, shavtao@gmail.com
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/dora-rs/
    idea_list_url: https://github.com/dora-rs/dora/wiki/GSoC_2025


  - organization_id: 177
    organization_name: freifunk
    no_of_ideas: 17
    ideas_content: |
      
      
      Live Protocol Overhead Dissector/Statistics for Gluon
      Generate live protocol overhead visualizations of batman-adv packet subtypes and layer 2 multicast traffic in Gluon.
      Linus Lüssing
      medium 175 hours
      GSoC 2025

      The overall goal is to gather a better insight into the overhead details of a Gluon / batman-adv based mesh network. To be able to evaluate past protocol changes and to spot areas for future improvements regarding protocol overhead. A live view should also help to monitor and alert on unexpectedly high protocol overhead in a real world setup.

      A package/daemon on a Gluon mesh node needs to collect statistics on the protocol’s “background noise” on both the upper interfaces as well as the underlying mesh interfaces and shall do so with a configurable list of packet types based on the pcap-filter syntax. And must provide this to a server. This has already (mostly) been implemented via:

      gluon-statistics-mcast package:
      https://github.com/freifunk-gluon/gluon/pull/2367
      bpfcountd:
      https://github.com/lemoer/bpfcountd/
      this is used by gluon-statistics-mcast for getting the
      this uses libpcap + a (not yet upstream) batman-adv dissector patch
      The first and next steps would be to rebase, update with the needed changes to be able to be merged upstream and test it:

      libpcap: “Add support for B.A.T.M.A.N. Advanced #980”: https://github.com/the-tcpdump-group/libpcap/pull/980
      add the new batman-adv multicast packet type to this PR
      add support to dissect within TVLV enabled batman-adv packet types (needs BPF code which reads the TVLV length field and adjusts the inner header offsets with it)
      (try to) persuade libpcap to merge it (they haven’t merged it in three years yet, with no additional feedback on why not)
      submit the updated version to OpenWrt: https://github.com/openwrt/openwrt/blob/main/package/libs/libpcap/patches/300-Add-support-for-B.A.T.M.A.N.-Advanced.patch
      Gluon: “gluon-statistics-mcast: adding initial package #2367”: https://github.com/freifunk-gluon/gluon/pull/2367
      update it with the changes requested in the ticket, get it merged upstream in Gluon
      add dissectors for the new batman-adv multicast packet type
      replace gluon-neighbor-info and respondd usage in general with providing the (compressed) statistics data directly via HTTP (while keeping the previous JSON format?); only set some flag (and/or URL? http path?) in respondd “nodeinfo” (or “statistics”?) provider so that a respondd querier would be informed about where/what extra data to get and to make this PR obsolete: https://github.com/freifunk-gluon/packages/pull/256
      Then deploy and run this on either a WiFi router with enough RAM + CPU power, capable of Gluon, or an x86 VM.

      Then either add to requestd or implement something new (usable on Debian?) for the gathering side:

      from responses to general respondd queries, determine which nodes have the gluon-statistics-mcast package installed
      query this JSON formatted data via HTTP from the nodes determined in step 1); do this a lot less frequently than the general respondd queries (e.g. only every 30min?)
      parse and push this data into an InfluxDB (or Prometheus?)
      Create live graphs in Grafana from InfluxDB data (or Prometheus?)
      You can get access to a Requestd/InfluxDB/Grafana server at Freifunk Lübeck for real world statistics measurements in a network with a recent Gluon / batman-adv version.

      (Optional) Bonus Milestones:

      Likey all very much out of scope - but if you’d be interested about anything of this in particular, we could talk about it :-).

      reduce bpfcountd overhead through eBPF? Ideally this would be a feature in libpcap, to be able to count packets through eBPF in kernelspace, without needing to copy them to userspace, while staying easy to customize & use through libpcap’s pcap-filter syntax; another option would be to replace libpcap usage in bpfcountd with one’s own, new eBPF counting library which still uses/reimplements the libpcap pcap-filter syntax parsing (difficulty: hard?)
      add dissectors for OLSRv2 (+ Babel?) and compare protocol overhead between these with batman-adv (though currently no Gluon Babel setup active, size/status of Gluon with OLSRv2 at FunkFeuer Graz unknown/WIP?
      measure various batman-adv tweaks:
      measure ARP overhead reduction with pending batman-adv DAT DHT/Cache split and increased DAT DHT timeout? also needs rebase) https://patchwork.open-mesh.org/project/b.a.t.m.a.n./cover/20190407112320.32021-1-linus.luessing@c0d3.blue/
      measure multicast overhead with batctl multicast_forceflood 1 (disables batman-adv multicast packet type and unicasted multicast packets)
      might be useful to have a package that allows configuring these on all nodes, without requiring full SSH access on all these nodes, e.g. something like the gluon-authorized-keys package but with a lot less privileges (implement a site.conf list option in gluon-authorized-keys which contains allowed files to execute, which would disallow ash usage over SSH?)
      Milestones
      GSOC COMMUNITY BONDING
      Conceptual work should be finished.
      The contributor have a repository, know how to work with the community.
      The applicant should know the community.
      GSOC MIDTERM
      Everything listed here has to be reviewed and merged by midterm.
      No exceptions to that. Changing the goals is possible together with mentors.
      Yes, that includes tests and documentation.
      GSOC FINAL
      Everything has to be reviewed and merged.
      Including tests and docs, again.
      
      
      
      
      
      
      ~~~~~~~~~~
      Adding Wi-Fi Support to QEMU Simulations in LibreMesh
      Adding the wireless interfaces to the LibreMesh virtualized environemnt in QEMU is expected to greatly improve its continuous testing.
      Javier Jorge
      medium 350 hours
      GSoC 2025GSoC
      Synopsis
      LibreMesh relies on continuous testing to ensure its robustness across various network conditions and hardware setups. Currently, testing new firmware images lacks a standardized method to include Wi-Fi simulations within a virtualized environment. This project aims to add Wi-Fi support to existing QEMU simulations for LibreMesh, allowing near-realistic network testing using virtual Wi-Fi interfaces. By leveraging the mac80211_hwsim module and integrating existing OpenWrt-friendly virtual Wi-Fi tools, we can enhance testing automation and reproducibility.

      Benefits to the Community
      Improved Testing Framework: This project will enable LibreMesh developers to run “almost real” tests in a virtualized environment, improving debugging and validation before deploying changes to physical hardware.
      Enhanced Automation: By integrating virtual Wi-Fi support into QEMU, developers can automate complex test scenarios without requiring physical routers.
      A set of scripted tests that can be run on real hardware: Currently, real tests on physical hardware are performed manually at each release. With this new set of test scripts for QEMU and Wi-Fi, many tests will be automated and easily adapted to real hardware.
      Collaboration with OpenWrt: Given that OpenWrt is also working on virtual Wi-Fi support, this project can align efforts with the broader open-source networking community, benefiting multiple projects.
      Lower Barrier to Entry: New contributors will find it easier to test their changes without needing specialized hardware.
      Deliverables
      Initial Research & Setup

      Review existing tools (mac80211_hwsim, vwifi, OpenWrt test frameworks).
      Set up a basic QEMU-based LibreMesh test environment.
      Virtual Wi-Fi Interface Integration

      Configure and validate mac80211_hwsim in a QEMU LibreMesh instance.
      Enable multiple virtual Wi-Fi interfaces to simulate different network conditions.
      Script Development for Network Testing

      Develop and document a set of scripts using rpcd interfaces for network diagnostics.
      Implement automated tests using the virtualized Wi-Fi environment.
      Integration with Existing LibreMesh Testing Framework (Weeks 7-8)

      Ensure the developed solution integrates seamlessly with the current LibreMesh testing setup.
      Validate compatibility with different network topologies.
      Documentation and Final Testing (Weeks 9-10)

      Create detailed documentation for developers on setting up and using the virtual Wi-Fi testing environment.
      Final debugging and submission of the project for review.
      blog posts to spread the news.
      Related Work
      mac80211_hwsim: A kernel module that emulates multiple Wi-Fi radios, widely used for testing wireless protocols.
      VWIFI (Raizo62/vwifi): A project focused on virtual Wi-Fi interfaces, particularly OpenWrt-friendly solutions.
      Estimated Timeline & Milestones
      Week	Task	Deliverable
      May 5 - May 29	Intro to QEMU, research and setup QEMU-based LibreMesh instance	First post in Freifunk’s blog, Suggestions to improve libremesh documentation
      May 29- Jun 23	Configure mac80211_hwsim and enable virtual Wi-Fi	QEMU instance with functional Wi-Fi simulation
      Jun 23- July 14	Develop network testing scripts	Scripts for automated testing using rpcd
      July 14 MID TERM EVALUATION	 	 
      July 14 - Aug 11	Integrate with LibreMesh testing framework	Testing capabilities report, expanded current RPC tests to run against QEMU
      Aug 11 - Aug 25	Final documentation and debugging	Documentation in LibreMesh repo and blog posts in Freifunk’s blog
      September 1 FINAL EVALUATION	 	 
      This project will provide LibreMesh with a powerful new tool for virtualized testing, improving both development efficiency and deployment reliability.

      The communication with mentors and LibreMesh community is absolutely necessary for the success of the project. For this, the applicant will be required to write 3 blog posts, one at the beginning, one in the middle, and one at the end of the project, on Freifunk’s blog. Also, the applicant is expected to join the LibreMesh mailing list and chat channel, announce there the advancements and seek for feedback. Weekly meetings will be held with the mentor to ensure the success of the project.
      
      
      
      
      
      ~~~~~~~~~~
      Quantum Safe VPN Mesh
      Secure a WireGuard mesh network against quantum computers
      Paul Spooren
      high 350 hours
      GSoC 2025

      Quantum computers pose a threat to existing cryptographic algorithms, including those used in VPNs. This project aims to develop a quantum-safe VPN mesh network using WireGuard on OpenWrt. The core component, unetdunetd, is an OpenWrt daemon that creates mesh networks using WireGuard. However, WireGuard itself is not quantum-safe. To address this, the project will extend unetd to support injecting pre-shared keys generated or exchanged through quantum-safe methods. Additionally, unetd will be enhanced to incorporate peer properties that influence routing decisions, ensuring policies enforce routing over specially strengthened links.

      Tests will be performed in the german Q-net-Q research network, which is part of an european initiative to develop a quantum-safe communicationn. The project will be guided by the mentors and parts of the Q-net-Q team.

      Quantum Safe means in this case that pre-shared keys are available at both ends of the VPN tunnel, allowing an additional layer of security by symetrically encrypting the data. To generate these keys either Quantum Key Distribution (QKD) and/or Post-quantum Cryptography (PQC) is used. The detailed generation of these keys is out of the scope for this project and will be guided through the mentors, no prior knowledge is required.

      Milestones
      GSOC COMMUNITY BONDING
      Setup development environment of multiple OpenWrt instances.
      Deploy unetd on OpenWrt instances and document the process.
      Run Rosenpassrosenpass container on OpenWrt instances and document the process.
      unetd codebase understood sufficiently to extended injection of pre-shared key feature.
      GSOC MIDTERM
      Reproducible Rosenpass on OpenWrt setup documented and tested
      unetd extended to allow injection of pre-shared keys.
      Design of unetd peer properties, to influence routing decisions.
      GSOC FINAL
      Working unetd with pre-shared key injection feature.
      Working unetd with peer properties influencing routing decisions.
      Documentation of the project and how to use it.
      Presentation of the project including a demo to the OpenWrt community and Q-net-Q members.
      
      
      
      
      
      
      ~~~~~~~~~~
      Change SSID when servers are not accessible
      In larger installations there will be many routers at different parts of a building on different channels, and one these may not be able to reach to the project's servers, and consequently also not issue IP numbers. Users changing their location may interpret this as an instability of the Freifunk and not attempt to fix what may be a loose cable on their side. The routers should change their SSID to an indication that it needs help.
      Steffen Möller
      easy 175 hours
      GSoC 2024

      In larger installations there will be many routers at different parts of a building on different channels, and one these may not be able to reach to the project’s servers, and consequently also not issue IP numbers. Users changing their location may interpret this as an instability of the Freifunk and not attempt to fix what may be a loose cable on their side. The routers should change their SSID to an indication that it needs help, so local organisers can find the issue earlier and error reports improve. The meshing between routers should not be affected.

      This project idea is not new, above shows a respective suggestion from the community. But yet no solution has been integrated with the regular Freifunk images. The solution from 2016 may stimulate a better implementation.

      Milestones
      GSOC COMMUNITY BONDING
      Conceptual work should be finished.
      The contributor have a repository, know how to work with the community.
      The applicant should know the community.
      GSOC MIDTERM
      Everything listed here has to be reviewed and merged by midterm.
      No exceptions to that. Changing the goals is possible together with mentors.
      Yes, that includes tests and documentation.
      GSOC FINAL
      Everything has to be reviewed and merged.
      Including tests and docs, again.
      
      
      
      
      
      
      ~~~~~~~~~~
      OpenWrt integration with bird2 (UCI and LuCI) for BGP and Babel protocols
      Develop BIRD2 integration for OpenWrt, including support for Babel and BGP
      IlarioBruno
      high 350 hours
      GSoC 2025GSoC

      Abstract
      The project’s proposal consists on developing OpenWrt’s integration with bird2 to support the BGP and Babel routing protocols via UCI and LuCI in a way that is useful for community networks. The project aims to build upon previous work on bird1, which reached end of life in 2023, aiming to modernize and maintain interoperability for community networks. The plan outlines phased milestones to implement, test, and document bird2’s integration, ensuring robust support for both routing protocols while preparing for future transitions, including bird3.

      Context
      Years ago, Eloi Carbó successfully participated in the 2014 edition of Google Summer of Code to improve integration of Bird with OpenWrt. The code was retired on 2023 because bird1 reached end of life in 31 Dec 2023, see commit fa136b7.

      Bird version 2 comes also with Babel mesh routing protocol support. The Babel Routing Protocol (RFC6126) is a loop-avoiding distance-vector routing protocol that is robust and efficient both in ordinary wired networks and in wireless mesh networks.

      The overall idea of this project is to:

      Upgrade from bird1 to bird2
      Do some maintenance on existing code
      Include Babel as a protocol and make it interact with BGP both via UCI and LUCI
      Why is relevant to maintain and upgrade OpenWrt Bird bindings?
      Bird is relevant software, it is used in production for BGP in large scale deployments (see evidence1 and evidence2 via bird-users mailinglist).

      It is also appreciated by community networks. For example, the following internship report, used the bird1-openwrt package to enable community networks interoperability through BGP. In fact, in guifi.net we have some nodes that use the bird1-openwrt package to make interoperability between the backbone network in BGP and the mesh BMX6 networks. In fact, in the following table, we show some relevant networks that work with BMX6 but are reachable from guifi.net through BGP’s Bird:

      nodes	zone
      23	Sant Andreu
      41	Sants
      12	Raval
      14	Vallcarca
      : Number of mesh nodes in Barcelona per sub-zone as of 2025-02-01

      Why is relevant to add Babel?
      There are about a hundred nodes (see previous table and related links) running BMX6 in guifi.net, but BMX6 software is unmaintained (last code commit d8869ec is from 2018). In fact, it was removed from openwrt routing repository in 2023 (see #963); that’s why community networks are deciding migrations to BMX7 or Babel. BMX7 was unmaintained for long time, but looks like it came back in 2024. We believe Babel provides a distance-vector easy to use alternative to BMX6 and BMX7. It has two maintained implementations: (1) lightweight and experimental Babeld; and (2) heavier but production-ready Babel inside the Bird software.

      Relevant deployments of Babel
      Babeld is what communities choose in general when they go for the Babel protocol, but comes with some problems: (1) the CLI is very limited, (2) it is not easy to debug on it and (3) it has no WebGUI at all (this is just a LuCI status page that at least is not working in OpenWrt 23.05.5 release). Babeld is used as a default configuration for LibreRouter, and it is used in at least a relevant deployment in Quintana Libre of around 60 nodes.

      Bird2 OpenWrt package (without UCI and LuCI) is being used in a small community network of 9 nodes with good results.

      About the upcoming bird3
      On December 2024, a new bird3 package appeared in openwrt-routing repository.

      Working on bird2 OpenWrt integration is still relevant for the upcoming bird3, in the official announcement they said:

      There are some minor breaking changes in config and CLI, most notably unified route attribute names to the filter variant. We are expecting to add a compatibility mode for the CLI. Anyway, it should be possible to reuse most of the configs and CLI scriptings from BIRD 2.

      It’s also good to stay on bird2, specially, if we want to be able to run it on legacy and very old devices that are in the network:

      The memory consumption has gone up significantly. We are still working on reducing the memory footprint and the next versions should be better in that.

      Resources
      Bird2 babel docs
      Bird2 bgp docs
      OpenWrt package bird1 OpenWrt, project’s extra documentation
      User guide on babeld
      OpenWrt package babeld
      OpenWrt package of luci app for babeld
      Babel IETF standard
      [BSc] Interoperability between classic infrastructure and Libre-Mesh networks in Guifi.net. Gioacchino Mazzurco, 2015, Università di Pisa
      [MSc] LEDE Firmware optimization for wired deployments using BGP and BMX6 for routing by enhancing and extending Bird Daemon’s configuration and UI integration. Eloi Caso, 2017, Universitat Oberta de Catalunya
      GSoC 2025 plan
      Milestones
      Here are the milestones to track the project completion.

      During GSOC Community Bonding

      Blog post announcing GSOC starts
      Blog post that summarizes end of GSOC Community Bonding Phase
      During GSOC MidTerm

      Bird2 BGP is configurable through UCI
      Bird2 BGP is configurable through LUCI
      Blog post that summarizes end of GSOC MidTerm
      During GSOC Final

      Bird2 Babel is configurable through UCI
      Bird2 Babel is configurable through LUCI
      Bird2 BGP and babel working at the same time in the same device
      Blog post that summarizes end of GSOC Final
      GSOC Community Bonding
      Tasks for phase 1 (May 4 - 28), introducing the gsoc contributor to the project.

      Get familiar on OpenWrt version 23.05.x and its BuildRoot
      Get familiar on how LuCI works
      Get familiar on how ubus works
      Get familiar on how Babel routing protocol works
      Get familiar on how BGP routing protocol works
      Learn to develop a basic openwrt-routing package
      Get familiar with existing codebase of bird1-openwrt in Lua and shell
      Get familiar with test frameworks that could fit well with OpenWrt environment
      Document the entire process at least with a blog post
      GSOC MidTerm
      Tasks for phase 2 (May 29 - July 10), work mainly on BGP but start approaching Babel.

      Integrate and use end to end tests for frontend and backend in the project, to improve code quality and ensure no functionality is lost (specially on the unstable code or most complex UX journeys)
      Set up a small testbed for experimenting the routing protocols
      Adapt configuration syntax changes from BGP from bird1 to bgp bird2
      Upgrade bird1-openwrt code to reach a bird2
      Do code maintenance tasks, minor bugfixes and improvements
      First development iteration on UCI and LuCI bird2 Babel development
      Document the entire process at least with a blog post
      GSOC Final
      Tasks for phase 3 (July 14 - August 21), work mainly on babel and finish project.

      Last development iteration on UCI and LuCI bird2 babel development
      Improve bird2 BGP and Babel integration, ensure it will work for bird3
      Refactor code if needed, so it is easier to maintain
      Document the entire process at least with a blog post
      
      
      
      
      
      
      ~~~~~~~~~~
      Simplify LibreMesh and get it closer to OpenWrt
      Replace some tools developed or just used in LibreMesh with the OpenWrt's counterpart, for stability and quality. Also, develop a light version of LibreMesh more suited for smaller communities.
      Javier Jorge
      medium 350 hours
      GSoCGSoC 2025

      Project objectives
      LibreMesh is composed by a set of modules which configure OpenWrt.

      Over the past few years, OpenWrt has improved massively, and some of the features developed within the LibreMesh modules have been created inside OpenWrt as well. So, the first goal of this project is to migrate from LibreMesh’s own solutions to the OpenWrt’s ones, in order to merge the efforts of the two communities. In some cases, it could be needed to add features to the OpenWrt softwares, and the feasibility of this will be evaluated on a per-case basis.

      Also, the development of LibreMesh’s modules is going on since more than 10 years with a joint effort from several network communities worldwide. Complexity built up and it is time to review it, for checking which code lines can now be spared. So, the second goal of this project is to simplify LibreMesh modules.

      The communication with mentors and LibreMesh community is absolutely necessary for the success of the project. For this, the applicant will be required to write 3 blog posts, one at the beginning, one in the middle, and one at the end of the project, on Freifunk’s blog. Also, the applicant is expected to join the LibreMesh mailing list and chat channel, announce there the advancements and seek for feedback.

      Identified actions
      Some tasks have already been identified, and should be analyzed in the project. More tasks could be identified during the process.

      Tasks for getting closer to OpenWrt (first goal)
      Replace deferrable-reboot with watchcat. Within the José de la Quintana network community, several tools have been developed over the years. Between them, deferrable-reboot is a tool decreasing the need of maintenance of the network, simply rebooting the devices when they lose internet connectivity. This simple solution clearly will not fix real fundamental network issues, but will help in decreasing the annoyance caused by undetected and not-yet-fixed stability issues. Inside OpenWrt, a similar tool named watchcat has been created, and could be used for replacing deferrable-reboot.

      Replacing dnsmasq with odhcpcd. LibreMesh is using dnsmasq (also) as a DHCP server, while OpenWrt is using odhcpcd by default. The migration towards odhcpcd involves checking whether odhcpcd has all the required features, understanding how to use them, and adapting LibreMesh to using them. A reference ticket with already some information can be seen here:

      “Replace dnsmasq by odhcpd”
      Tasks for simplifying LibreMesh (second goal)
      Removing VLAN from Babel interfaces. LibreMesh creates one VLAN interface on top of each physical interface specifically for Babel routing protocol. This is not needed, decreases the maximum transmission unit (MTU) and increases the complexity of LibreMesh. There are two relevant tickets with some information on this:

      “Lets remove unneded vlans from protocol interfaces”
      “Babeld without VLAN does not run on LAN ethernet ports”
      “Support Babeld without VLAN on ethernet interfaces inside br-lan”
      Creating a layer2-only version of LibreMesh. LibreMesh has been designed for scalability. For this, it includes a layer 2 routing protocol -Batman-adv- for managing local networks, together with a layer 3 routing protocol -Babel- for connecting local networks with each other. With this two-layers approach, enormous networks can be created, at the cost of high complexity. But in most cases, communities are smaller than a hundred nodes, and having a complex structure increase the access barrier for community members to debug issues in their network and develop new features. So, a layer2-only version of LibreMesh could be developed. A ticket with some relevant info can be found here:

      “LibreMesh releases: only layer2+3 or both layer2+3 and layer2?”
      Milestones
      May 8 - June 1 Community Bonding Period
      The applicant is expected to:

      buy or gather somehow at least 3 LibreMesh-compatible routers and install a pre-compiled LibreMesh firmware image on them. At least one router model should have a switch that is DSA-supported within OpenWrt. At least one router should not be supported yet by DSA in OpenWrt.
      deploy LibreMesh in a virtual environment.
      compile a LibreMesh firmware image using the BuildRoot method.
      June 2 - July 14 First work period
      Analyze the already identified actions and select the ones that seems feasible and easiest to implement.
      Start implementing them while testing the results on a real testing network composed by at least 3 routers.
      July 14 MID TERM EVALUATION
      July 14 - September 1 Second work period
      Identify new actions that help with simplifying LibreMesh or to get it closer to OpenWrt. Write them down as issues on the lime-packages repository.
      Complete the implementation of the selected actions and test various network configuration to make sure that the solution is solid.
      Propose the changes as one or more pull requests on the lime-packages repository.
      September 1 FINAL EVALUATION
            
      
      
      
      
      
      ~~~~~~~~~~
      Renovate freifunk ICS Collector
      Update to latest libraries and versions, fix timezone issues
      andibraeu
      medium 90 hours
      GSoCGSoC 2025

      Back in 2015 during GSoC we developed this ICS Collector to merge multiple calendars from freifunk communities. The software is quite stable, but needs some updates and renovation, as calendars evolved, too.

      The software should be adopted to latest versions of php and libraries used.

      We also need to find a way to fix timezone issues we run into, when we want to use the merged calendar result. The API should be kept stable.

      Milestones
      Preparation/Bonding
      checkout the repository and try to understand how it works
      find possible library and dependency updates
      identify potential refactorings
      look for updated or new ical libraries
      Coding period
      update or replace libraries
      refactor code and add more tests
      add timezone to single events, if the source contains a timezone


      
      
      
      
      
      
      ~~~~~~~~~~
      Static Social Media Archive Explorer
      Develop a (static) website to display and search an archive of social media posts (e.g. tweets) gathered using Cyd, leveraging both HTML archives and a SQLite3 database.
      andibraeu
      medium 90 hours
      GSoCGSoC 2025

      Idea
      The project aims to create a static website that serves as an archive explorer for our social media posts, which were collected using Cyd. The archive exists in two formats: HTML files and a SQLite3 database. The resulting site should allow users to browse and search through historical posts in a clear, user-friendly interface.

      A key component of the project is to develop an easy-to-use extractor tool. This tool will:

      Process the existing HTML and SQLite3 data,
      Normalize and export it into a common format (e.g., JSON),
      Allow the results to be easily reproduced,
      Enable others to use the tool to set up their own static websites for similar archives.
      Since no new posts will be added, the focus is on efficient data extraction, processing, and client-side search capabilities.

      Milestones
      Milestone 1: Data Extraction and Processing Tool
      Analyze the archive formats (HTML and SQLite3).
      Develop an easy-to-use extraction tool that converts the data into a common format (e.g., JSON), ensuring that the process is reproducible.
      Document the tool and provide clear instructions so that others can use it for their own social media archives.
      Validate data consistency and completeness.
      Milestone 2: Static Website Setup
      Choose and set up a static site generator.
      Create basic templates for listing posts and individual post pages.
      Integrate the processed data into the static site build.
      Milestone 3: Client-side Search Integration
      Implement search functionality using a JavaScript library.
      Pre-index the data during the build process.
      Ensure the search interface is intuitive and responsive.
      Milestone 4: Testing, Optimization, and Deployment
      Conduct testing to ensure data integrity, search accuracy, and overall usability.
      Optimize the site for performance and accessibility.
      Prepare documentation and deploy the static site.
      Extra: Theming Support (Optional)
      If time permits, implement theming support to allow customization of the site’s appearance.
      Ensure that themes can be easily switched or customized via configuration files.
      
      
      
      
      
    
      ~~~~~~~~~~
      VocToWeb: Install and apply customizations
      Develop components to apply customizations to the default VocToWeb
      andibraeuchristian-draeger
      medium 175 hours
      GSoCGSoC 2025

      Voctoweb is the software behind media.ccc.de and used for distributing video recordings of a lot of events. We forked their repo to set up our own video portal, media.freifunk.net. As there was only one user of this software for years, content pages and templates are mixed with the business logic.

      Goal of this project should be: We’re able to set up a new instance of voctoweb and add our own contents, designs, templates and other customizations. When the projects is finished we have a document on how to get your own, independent and customized instance.

      It may be hard to split the original project in a first step. But if we find a way to make it easy for others to customize the installation, that doesn’t matter.

      Milestones
      Preparation/Bonding
      Install your own instance of voctoweb and try to understand how it works
      identify the components to be used for customizations
      Coding period
      merge upstream changes
      identify the general and the customizable parts
      find ways to apply the customizable parts to a default installation
      update media.freifunk.net, maybe use docker based components
      improve documentation on installing voctoweb
      add documentation on how to apply and develop customizable parts
      
      
      
      
      
      
      ~~~~~~~~~~
      Deep Q Network-based Rate Adaptation for IEEE 802.11ac Networks
      Implementation and performance evaluation of reinforcement learning algorithm based on the Deep Q Network approach for MCS rate adaptation in real WiFi networks
      thuehnSankalp Prakash Pawar
      tough 350 hours
      GSoCGSoC 2025

      The goal of MAC-layer Wi-Fi rate adaptation (RA) is to dynamically select modulation and coding scheme (MCS) rate parameters for the transmission of frames to optimize throughput given a varying channel. Conventional Wi-Fi RA algorithms rely on heuristics from older IEEE 802.11 amendments, which can struggle in denser, more complex networks. As Wi-Fi environments become more crowded, machine learning techniques, especially reinforcement learning (RL), are gaining attention for their potential to improve rate selection [3].

      RL addresses the exploration-exploitation tradeoff by continuously exploring actions and exploiting the best-performing ones. This dynamic approach can adapt to real-time network conditions, optimizing throughput, and improving overall performance. Unlike traditional heuristics, RL can evolve, offering a more flexible and robust solution for modern Wi-Fi networks. However, even with the promising potential of applying RL-based approaches for WiFi RA, there are limited investigations that offer an in-depth performance evaluation for real IEEE 802.11 networks using commercial off-the-shelf (COTS) hardware.

      The objective of this project is to investigate the use of Deep Q Networks (DQN) for Wi-Fi RA. In [2], R. Queirós et al. demonstrated the effectiveness of a DQN-based RA algorithm in an IEEE 802.11n network through simulation. Building on this work, this project aims to extend the algorithm for the IEEE 802.11ac standard, which involves a relatively larger action space. The implemented algorithm will be evaluated using an experimental toolchain based on the Open-source Resource Control API (ORCA) [1] which enables user space implementation of novel WiFi RA algorithms and their comparison. ORCA is a kernel-user space API for the Linux-based OpenWrt OS. Performance evaluation will include comparing the DQN-based RA algorithm and variants of Minstrel-HT based on metrics such as throughput.

      Milestones
      GSOC COMMUNITY BONDING
      Primer on existing Wi-Fi RA algorithms and their limitations (especially in dense environments).
      Gained hands-on experience using ORCA to learn about its control and monitoring capabilities for user space research on WiFi resource control for OpenWrt-based WiFi nodes.
      Overview report on reinforcement learning-based rate adaptation techniques, focusing on Deep Q Networks (DQN).
      GSOC MIDTERM
      Implemented the core DQN-based RA algorithm for the action space (MCS rates), state space (RSSI), and reward (expected throughput) using TensorFlow or an appropriate RL library.
      Tested the initial algorithm using a testbed involving an RF-isolated single-link Access Point (AP) and Station (STA) setup.
      Defined possibilities to tune hyperparameters (learning rate, discount factor, etc.) for stability and performance.
      Designed experiment plan with details on traffic flows and channel scenarios.
      GSOC FINAL
      Completed deploying a desk setup consisting of a single-link with AP and STA using IEEE 802.11ac Conducted measurements using the DQN-based RA algorithm and state-of-the-art Minstrel-HT based on the experiment plan.
      Performed statistical analysis of measurement data and visualization using libraries such as matplotlib.
      Improved the DQN-based RA algorithm based on analysis results.
      Presented a demo to highlight the potential performance improvements using the DQN-based RA algorithm.
      Published comprehensive source code and project documentation.
      Resources
      [1] Open-source Resource Control API for real IEEE 802.11 Networks
      [2] Wi-Fi Rate Adaptation using a Simple Deep Reinforcement Learning Approach
      [3] SmartLA: Reinforcement Learning-based Link Adaptation for High Throughput Wireless Access Networks
      
      
      
      
      
      ~~~~~~~~~~
      
      Freifunk Fiber Backbone over 100G
      Running Freifunk Fiber Backbone Links via Mellanox 100G Switches on OpenWrt
      schuzathuehn
      midrange 350 hours
      GSoCGSoC2024

      Current Freifunk Community networks across Europe are expanding their wireless P2P backbone infrastructure to wired fibre links, hence capacities beyond 10GBit/s are achievable. Today’s switching hardware can be categorised into three design approaches: - Switch Abstraction Interface (SAI) [1] which is leveraged by SONiC (NOS) [2] - OF-CONFIG [3] which enables to configure the forwarding plane of Broadcom-based switches - Switchdev (Linux kernel API [4]), which could be leveraged by the Distributed Switch Architecture (DSA) [5]

      Moreover, other approaches exist to expose the packet handling/forwarding into the user space

      DPDK/VPP interface that would require a significant re-implementation of the Freifunk network stack and features such as olsrd/batman/babel routing daemons. The flexible switchdev Linux kernel API builds upon standard Linux tools such as IP etc. this enables Freifunk communities to code as well as add features running atop a classical Linux-based system also on devices beyond 10 Gbps interfaces. Since NVIDIA Mellanox Spectrum II switches implement the Linux kernel switchdev API, they seem to be a reasonable choice to achieve this goal.
      Accordingly, the goal of this project is to port Freifunk/OpenWrt [6] OS to the Mellanox Spectrum II-based switch[7] hardware - in such a way, that the ONIE [8] bootloader triggers an OpenWrt boot, daemons such as olsrd/batman/babel routing daemons can run as usual, and (Q)SFP-based ports are deployable on fiber links.

      Resources
      [1] https://github.com/opencomputeproject/SAI
      [2] https://sonic-net.github.io/SONiC/
      [3] https://github.com/openvswitch/of-config
      [4] https://www.kernel.org/doc/html/latest/networking/switchdev.html
      [5] https://www.kernel.org/doc/Documentation/networking/dsa/dsa.txt
      [6] https://openwrt.org/
      [7] https://github.com/Mellanox/mlxsw/wiki
      [8] https://opencomputeproject.github.io/onie/
      Milestones
      DTS Integration for at least Mellanox Spectrum II-based switches in OpenWrt
      add new OpenWrt “Mellanox” target with ONIE bootloader support
      SFP+ p2p 100G link setup test on desk
      PREPARATION/BONDING
      Understanding of the OpenWrt build environment
      Understanding of the different Switching-based Architectures such as switchdev, SAI, OF-CONFIG
      Understanding of ONIE and Linux OS bring-up process
      Coding Period
      Porting Mellanox Switch with Sectrum II chipset to OpenWrt
      Add dedicated Mellanox target to the Freifunk/OpenWrt device set
      Evaluation 100G SFP+ fiber ports
      
      
      
      
      
      ~~~~~~~~~~
      
      OpenWrt Google Coral board support
      Integration of Google Coral board in Openwrt
      schuza
      tough 350 hours
      GSoCGSoC 2025

      The Coral Board integrates a Google Coral Edge Tensor Processing Unit (TPU) as Mini PCIe Accelerator [1], M.2 Accelerator A+E key or via USB. The TPU can be leveraged to run TensorFlow Light models on embedded systems. The goal is to integrate the board and environment into the OpenWrt build environment [2].

      Moreover, within the GSoC project, the task is to come up with a simple example [3] to demonstrate the capabilities of the Coral board. Thus, the goal is to develop and evaluate some use cases such as device fingerprinting etc.

      Accordingly, the participant will first integrate the board into the OpenWrt environment, design and describe possible use cases, and realize a use case that shows the benefits of the TPU.

      Resources
      [1] https://coral.ai/products/pcie-accelerator
      [2] https://openwrt.org/
      [3] https://trac.gateworks.com/wiki/TPU
      [4] https://coral.ai/docs/edgetpu/models-intro
      Milestones
      Integration plan for the Coral board in the OpenWrt build environment
      Integration of the tools and drivers into OpenWrt
      Description of different use cases that leverage the capabilities of the Google Coral Edge Tensor Processing Unit (TPU)
      Implementation of a dedicated use case that demonstrates the benefits of the TPU
      PREPARATION/BONDING
      Understanding of the OpenWrt build environment
      Understanding of convolutional neural networks (CNN) and frameworks
      Coding Period
      Integration of the Coral board support into OpenWrt
      Implementation of a use case
      Evaluation of the use case
      Demonstration of the benefits
            
      
      
      
      
      ~~~~~~~~~~
      
      Data-Driven Analysis of Rate Adaptation Using Machine Learning on Traces from a Real IEEE 802.11 Mesh Deployment
      thuehnprashiddhath
      high 350 hours
      GSoC 2025


      Rate Adaptation (RA) plays an important role in deciding the performance of a WiFi link. As WiFi operates within the limited and unlicensed ISM band, it is highly prone to interference. Newer standards of IEEE 802.11 offer faster Modulation and Coding Scheme (MCS) rates, higher bandwidth and more spatial stream, increasing the number of possible transmission configurations. However, efficiently navigating this growing search space for optimal rate selection remains a challenge. To address this challenge, we leverage data-driven machine learning techniques, such as LSTMs, to navigate the search space efficiently. Analyzing RA traces from a real rural ISP network could help us learn which data rates perform well and which do not across diverse environments. The access points run OpenWrt OS, based on Linux, with the ORCA API for monitoring frame transmissions and control of RA parameters. The details of the API and the trace format has been provided under Resources for Proposal.

      This project is positioned as a research initiative, exploring the following key questions:

      Can RA traces be effectively analyzed as time-series data?
      Are data rates inherently correlated, or are they primarily influenced by environmental factors?
      How effectively can historical RA data (RSSI and TX status) be leveraged in an LSTM model for optimal data rate prediction?
      The optimisation challenge in RA is framed as selecting the optimal data rate from a set of available options, where the best choice can be highly dynamic and fluctuate every 20-50ms. This rapid variability is influenced by factors such as channel conditions, interference, and device mobility, making real-time prediction crucial for maintaining optimal performance. We have real ISP traces from the Linux mac80211 subsystem of mesh access points, providing insights into the performance of data rates across different environments. The key challenge lies in accurately modelling with the limited information exposed to us, capturing the diversity of the channel environment for precise data rate predictions.

      Resources for Proposal
      IEEE 802.11 Rate Adaptation
      ORCA API Paper
      Inferring ORCA Trace Lines
      ORCA Trace Snippet
      Milestones
      GSOC COMMUNITY BONDING
      Knowledge on the basics of IEEE 802.11 Rate Adaptation.
      Familiarity with the ORCA API traces.
      Defined structured plan for data analysis and ML model development including data selection and preprocessing.
      GSOC MIDTERM
      Analysed (temporal) data rates correlation.
      Identified and engineered features to effectively characterise the wireless channel.
      Implemented a functional LSTM-RA model with preliminary trace evaluation.
      GSOC FINAL
      Evaluated LSTM on traces from selected productive Freifunk Mesh and Access deployments.
      Documented source code and project for future reference.
      Optional
      Implementation of LSTM RA for real WiFi access points using RateMan and ORCA.
      
      
      
      
      
      ~~~~~~~~~~
      
      uMesh: New mac80211 architecture for faster WiFi mesh networks
      Implement an alternative wifi mesh network mac80211 mode based on AP WDS<->WDS as successor of IEEE 802.11s
      thuehn
      tough 350 hours
      GSoCGSoC2024


      Our Freifunk community is a foundation of people building networks in a decentralized, hands-on DIY way - distributed, self-made and community managed. The network technology and components span from WiFi mesh routers over P2P 60GHz to fiber optical links.

      The objectives of the uMesh proposal are to plan, build and run fast and robust wireless mesh networks as FOSS based decentralized network infrastructure on current IEEE 802.11ax and upcoming IEEE802.11be chips.

      This goal is achieved through the strategic deployment of a highly dense arrangement of WiFi nodes, each possessing the capability to establish visual connectivity with neighboring nodes. The emphasis is placed on maximizing network interconnectivity, thereby enhancing redundancy and resilience within the system.

      To attain the desired level of interconnectivity, conventional AP (Access Point) station mode proves inadequate due to its inherent limitation in constructing solely star-shaped topologies. This limitation arises from the singular central instance, the AP, rendering the entire network susceptible to failure upon its malfunction. Additionally, under the AP station mode, stations lack the capacity to engage in data exchange amongst themselves. The introduction of the ad-hoc mode in WiFi was conceived as a solution, enabling decentralized and egalitarian data exchange among all stations. However, the universal support for ad-hoc mode was impeded by inconsistent and unreliable implementation across various drivers. Seeking a comprehensive remedy, the 802.11s mode was conceived, purporting to establish a mesh network capable of overcoming the drawbacks associated with traditional station and AP links. Nevertheless, the efficacy of IEEE 802.11s mode has been hindered by a lack of consistent support within Linux kernel wifi device drivers. Notably, disparities in performance between ad-hoc mesh links and conventional station-to-AP links have been observed, with the situation exacerbated by emerging chipsets designed to accommodate ever-increasing data rates, such as IEEE 802.11ax. The exigencies of these advanced data rates necessitate specialized offloading techniques, often not implemented and hence supported in the implementations of IEEE 802.11s, resulting in its neglect or outright abandonment in certain instances or low performance figures in data throughout.

      The LibresMesh community introduced the concept of utilizing Mesh while retaining AP WDS links. As the name implies, this approach ostensibly involves the criticized star-shaped topology where a failure could potentially cripple the network. The distinction lies in the modification of the WiFi stack, wherein all WiFi nodes operate in AP mode. Instead of functioning as APs, they emit beacon frames, which are received by all other nodes. Upon detecting identical SSIDs, the APs establish WDS-Station links with each other, facilitating subsequent communication.

      This configuration can be analogized to each node having an AP interface and connecting, as a Station, to the respective APs of others using the same radio, akin to proprietary products. The key distinction lies in the automated functionality of this process.

      Through this technique, we amalgamate the benefits of the resilient 802.11s mesh while concurrently leveraging the significantly better-maintained AP mode drivers embedded within the WiFi chip. This approach alleviates concerns regarding the potential absence or infrequent implementation of the 802.11s mode in future chips.

      Based on an initial proof-of-conecpt implementation of an AP-WDS-WDS mesh within the uMesh proposal we plan to implement, validate and evaluate the uMesh approach in different productive Freifunk WiFi Mesh networks using IEEE 802.11ax chips and OpenWrt Linux WiFi Routers. Our plan is to elevate the current implementation to a level where the rate negotiation functions properly, and the timeouts of the WiFi link distances operate correctly. Subsequently, we will conduct a performance analysis between the 802.11s and the new WDS-AP-AP mode across various WiFi generations, ranging from older 802.11n to newer standards such as 802.11ax.

      Milestones
      Connecting with the community. This includes joining all relevant channels and in touch with the mentors.
      Work on a hostapd patchset to enable IEEE 802.11n/ac/ax uMesh capabilities.
      Validate and evaluate the throughput performance of IEEE 802.11ac and IEEE 802.11ax uMesh WiFi links.
      Test and ensure the usability of the integration of common Freifunk mesh routing protocols (such as Babel, OLSR, BMW, or Batman) on uMesh interfaces for the purpose.
      Evaluate and publish a community white paper outlining the migration plan from the existing Freifunk Mesh utilizing IEEE 802.11s to the implementation of uMesh.
      Explore options for implementing encryption in this scenario.
      Identify limitations. How many WiFi routers can be connected to each other? Are there any other potential issues?
      GSOC 2024 COMMUNITY BONDING
      The conceptual work is aimed at generating a cohesive proposal for community review. Applicants are expected to participate in all project communication channels and attend periodic online meetings with the community. Additionally, an initial blog post will be authored, inviting proposals for alternative solutions to address identified challenges.

      GSOC 2024 MIDTERM
      In this milestone, the focus is on the aforementioned coding milestones. This involves delving into the hostapd, creating a corresponding patch set for WDS-AP-AP communication, resolving issues, establishing a testbed, identifying limitations. At the end, a blog post will then be published.

      GSOC 2024 FINAL
      Every aspect needs to undergo review and be merged. Comprehensive documentation should be made accessible. Lastly, a conclusive blog post will be authored.
      
      
      
      
      
      
      ~~~~~~~~~~
      WiFi device clustering and fingerprinting
      Realization of an approach to perform WiFi device clustering and fingerprinting
      schuza
      tough 350 hours
      GSoCGSoC2024

      The goal is to create an environment that allows to collect rate control and client capabilities to optimize transmission rate control for client devices. To this end, the project will leverage an interface provided by the supraconex [1] project to collect transmission rate statistics from OpenWrt-based [2] devices. Moreover, the system should also allow to leverage fingerprinting mechanisms based on the client capabilities such as WiFi taxonomy [3].

      Within the project, both approaches are combined to perform a client-based clustering of WiFi devices to create an understanding whether used rates etc. might correlate between different classes of devices. This should allow to further optimize transmission rate algorithms in the presence of handovers etc. Accordingly, a measurement environment needs to be proposed that allows to anonymously collect statistics from different home networks.

      Resources
      [1] https://supraconex.de/
      [2] https://openwrt.org/
      [3] https://github.com/NetworkDeviceTaxonomy/wifi_taxonomy
      Milestones
      Planing of the integration of different mechanisms into the OpenWrt build environment
      Integration of the tools and drivers into OpenWrt
      Design and description of a measurement environment
      Implementation of the measurement environment and necessary tools
      Evaluation of the collected statistics
      PREPARATION/BONDING
      Understanding of the OpenWrt build environment
      Understanding of statistics
      Understanding of WiFi such as transmission rate control and capabilities
      Coding Period
      Implementation of different tools
      Integration of the tools and APIs into OpenWrt
      Realization of the measurement environment
      Collection of privacy-preserving statistics
      Evaluation of the use case
      
      
      
      
      
      
      ~~~~~~~~~~
      qaul RPC user authentication layer
      libqaul <-> GUI protobuf RPC authentication
      MathJud
      medium 350 hours
      GSoCGSoC 2025

      User Authentication Layer
      The GUI communicates via protobuf RPC messaging with libqaul. At the moment there is only one user per node. libqaul is capable of having multi users per node. The GUI <-> libqaul RPC communication shall be organized in sessions. Each session shall be authenticated and encrypted.

      The user authentication layer shall have the following qualities:

      Secure authentication mechanism
      optional user password.
      The system should be zero-config for the user. A password and/or a session key (which can be cached) can be used.
      The system shall support multiple sessions per user & multiple users per node.
      Each session shall be transport encrypted via the Noise protocol.
      This work is also the foundation of a possible web interface in qaul, in which users interact with a node via a web GUI.

      Milestones
      During application period: Create a concept for your project. Discuss your concept with a mentor.
      Define the authentication system
      Define the encryption system
      Define the Protobuf communication structure
      Implement the Sessions.
      Implement the sessions into the CLI application.
      Implement the Authentication system.
      Encrypt the sessions
      Resources
      qaul Protobuf RPC
      About qaul
      qaul is an Internet independent wireless mesh communication app. To communicate P2P directly from device to device and mesh all interconnected devices together. qaul.net interconnects Android, iOS, Linux, MacOS & Windows devices via LAN, Bluetooth and Internet overlay connections.

      qaul is written in rust, uses rust-libp2p internally and has a cross platform flutter GUI.

      https://qaul.net

      Applying for this Project
      Please get in contact with the Mentor @MathJud (via Email or qaul matrix chat #qaul.net:c-base.org) to discuss and prepare your application and project.
      
      
      
      
      ~~~~~~~~~~
      
      
      A modular Wizard for OpenWrt
      Write a wizard to easen the initial configuration of OpenWrt based devices
      akira25Noki
      medium 175 hours
      GSoCGSoC2024

      OpenWrt is a distribution for embedded devices such as WiFi router and similar devices.

      While it gained very much popularity in the rather experienced Tech-Community, its further expansion is damped by the fact, that the further configuration of an OpenWrt-System needs knowledge of Wireless Routers.

      Therefor, commercial OpenWrt-based devices mostly come with a custom UI, which incorporates a setup wizard for initially setting up the device, like it is known from many other firmwares already.

      The objective of the project is, to develop such a wizard, which will ease the initial configuration of a device.

      That wizard will be implemented by using LuCI, which is a framework to build a web interface for configuration and monitoring.

      The to-be-developed wizard should be modular and adoptable to different scenarios by scripting. Thus it can be adjusted to the needs of OpenWrt-based communities, like Freifunk and others.

      Data will be provided by the user through the UI, the configuration of the actual router will be done by shell scripts in the backend.

      Milestones
      Learn how the LuCI client side API works
      Learn how to write rpcd services
      Learn how to set permissions and menu entries
      Discuss an easy and reliable approach to run the wizard on initial startup.
      Make a HowTo for others to help them adjusting the wizard for their needs.
      Preparation/Bonding
      Study the example app to see how it generally works.
      See other apps like luci-mod-freifunk that are more sophisticated to learn more details.
      Get familiar with rpcd and ubus.
      Have a look on the Mock-UI to get an idea of how the Freifunk specific implementation should look like
      Coding period
      Start creating an minimalist UI example and the related backend module
      Verify that example to be functional by testing it on an OpenWrt system
      Create documentation for implementing a specific wizard with code examples
      Once the example UI and its backend script work, start implementing the Freifunk Berlin wizard as specified by the mockups in the Freifunk Berlin Repo
      
      
      IN REVIEW
      This idea is currently in review. Please visit this idea later, too, as there may be some changes.
      
      
      
      
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/freifunk/
    idea_list_url: https://projects.freifunk.net/

  - organization_id: 178
    organization_name: gprMax
    no_of_ideas: 4
    ideas_content: |
      
      1. AI Chatbot for support
      This project will build upon the work done in the previous GSoC where an AI chatbot was developed capable of answering questions and assisting on building models with gprMax. For more information you can check the following link.
      The developed chatbot is based on ChatGPT from OpenAI, therefore it is not free. The current project will aim at building light chatbots using open-source LLMs such as Lama and Deepsheek, in order to provide a free and computationally cheap chatbot for gprMax.
      Moreover, the next generation of gprMax AI chatbots will be capable of building models automatically based on some given instructions. We currently have a set of gprMax commands that we can use to fine-tune open-source LLMs.
      To summarise, this project will aim at building AI chatbots based on open-source LLMs, and fine-tune them not only to answer questions related to gprMax, but also to automatically build full gprMax models based on simple and intuitive instrustions by the user.
      Expected outcomes: A functional AI chatbot based on open-source LLMs capable of automatically developing gprMax models using simple written commands.
      Skills required: Python, machine learning
      Difficulty: Medium
      Length: 350hrs

      ~~~~~~~~~~
      2. Apple Metal port
      The aim of the project is to develop an Apple Metal port. The performance (speed) of the solver is a critical feature as simulations become ever larger and more complex.
      The solver is based on the Finite-Difference Time-Domain (FDTD) method, which has shown significant performance benefits when parallelised – particularly on GPU. The project will require building on the already existing initial Apple Metal port and developing and testing it to ensure all main features in gprMax execute correctly and efficiently.
      Expected outcomes: A working port of the FDTD solver engine for gprMax using Apple Metal.
      Skills required: Python, C
      Hardware required: You must have your own access to Apple hardware.
      Difficulty: Medium
      Length: 350hrs

      ~~~~~~~~~~
      3. AMD ROCm HIP port
      The aim of the project is to develop an HIP port. The performance (speed) of the solver is a critical feature as simulations become ever larger and more complex.
      The solver is based on the Finite-Difference Time-Domain (FDTD) method, which has shown significant performance benefits when parallelised – particularly on GPU. The project will require porting existing code from the PyCUDA-based solver we already have, to the HIP API. There are automated translation tools, such as HIPIFY that can be used to support the process.
      Expected outcomes: An initial working port of the FDTD solver engine for gprMax using HIP.
      Skills required: Python, C
      Hardware required: You must have your own access to an AMD GPU.
      Difficulty: Medium
      Length: 350hrs

      ~~~~~~~~~~
      4. Implementation of a Near to Far Field Transformation (NFFT) calculation and output of relevant information
      The aim of this project is to implement a Near-to-far-field Transformation output process in gprMax based in well known theory and an existing algorithm.
      NFFT outputs are needed when information of the electromagnetic field response is needed far away from the object of interest modelled in detail by gprMax using the FDTD numerical mehtod.Initially we need to implement such a process, which is well documented in the literature and algorithmically available, for objects located in a simple homogenous background. This feature will allow us to easily perform an number of additional modelling tasks like radar cross section (RCS) calcualtions and complicated antenna patterns that are not possible at the moment.
      Skills required: Python
      Difficulty: Medium
      Length: 350hrs
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gprmax/
    idea_list_url: https://github.com/gprMax/GSoC/blob/main/project-ideas-2025.md


  - organization_id: 179
    organization_name: kro | Kube Resource Orchestrator
    no_of_ideas: 4
    ideas_content: |
  
      1. Metrics and Observability for kro
      Difficulty: Medium
      Issues: #195, #190
      Skills needed: Go, Prometheus, Grafana
      Project goals:
      Implement CEL expression execution metrics with Prometheus integration
      Add performance metrics for resource creation/deletion cycles
      Add Grafana dashboard to visualize kro metrics

      ~~~~~~~~~~
      2. Enhanced Developer Tools and IDE Integration
      Difficulty: Medium
      Issues: #141
      Skills needed: Go, VSCode extension API
      Project goals:
      Create VSCode extension for kro ResourceGraphDefinitions
      Implement syntax highlighting for schema definitions
      Add auto-completion for CEL expressions
      Provide inline validation for resource templates
      Create real-time schema validation

      ~~~~~~~~~~
      3. Examples Validation and Generation in kro.run
      Difficulty: Easy/Medium
      Issues:: TBD
      Skills needed: Go, Web development
      Project goals:
      Build pipelines to expose ./examples content in the kro.run website
      Create example validation framework
      Implement automated testing for documentation examples
      Create categorized example library

      ~~~~~~~~~~
      4. Performance and Scale Study
      Difficulty: Hard
      Skills needed: Go, Kubernetes, Profiling, Performance testing
      Project goals:
      Design and implement performance benchmarks
      Study resource usage patterns under load
      Analyze CEL expression evaluation performance
      Create scale testing framework
      Document performance recommendations
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kro-or-kube-resource-orchestrator/
    idea_list_url: https://github.com/kro-run/kro/issues/288


  - organization_id: 180
    organization_name: libssh
    no_of_ideas: 3
    ideas_content: |
      
      
      Support for FIDO/U2F keys on the client side
      The server side support (signature verification) and key type definitions are in place so authenticating using these keys from openssh client to libssh server should already work. But the libssh clients can not use the U2F based keys as well as it can not be used to enroll the hardware for authentication with ssh.
      The project should involve adding code paths to create U2F signatures, as well as possibility to test them without the actual hardware in the CI. Here we can get inspiration from OpenSSH, as they provide sk-dummy.so, which can simulate fido/u2f devices. This is packaged in Fedora.
      Difficulty: Medium
      Project length: 350 hours
      Language(s): Good knowledge of C, knowledge about elliptic curves cryptography or u2f is a plus 😉
      Possible Mentors: Jakub Jelen
      References:
      https://github.com/openssh/openssh-portable/blob/master/PROTOCOL.u2f

      ~~~~~~~~~~


      OpenSSH-compatible CLI
      The libssh is provided as a library and only provided binaries are examples implementing either specific client or server examples without an attempt to implement a CLI that can support most of the OpenSSH’s CLI use cases and could be used as a drop-in replacement. The libssh should already support most of the use cases (and if not, new issues should be opened and implemented). Similar exercise can be done for server, but there will many more gaps.
      Difficulty: Medium
      Project length: 350 hours
      Language(s): Good knowledge of C
      Possible Mentors: Jakub Jelen
      References:
      Manual page for ssh: https://linux.die.net/man/1/ssh

      ~~~~~~~~~~


      Improve configuration compatibility with OpenSSH
      The libssh is trying to be compatible with the OpenSSH configuration files to make the experience for our users as smooth as possible to be able to use only one configuration file for both. But OpenSSH configuration file options grow in complexity and we are not catching up with all the corner cases, which sometimes got reported to us. This project is about understanding the SSH configuration, how it is handled by OpenSSH and adjusting the libssh configuration parser to match as closely as possible, including adding a automated test coverage that can compare results with the OpenSSH parser.
      It might be possible to create a fuzzer for the configuration file, that would feed the inputs into both openssh and libssh to verify they result in the same effective configuration.
      Difficulty: Medium
      Project length: 350 hours
      Language(s): Good knowledge of C, understanding of fuzzing testing is a plus
      Possible Mentors: Jakub Jelen
      References:
      Manual page for ssh_config: https://linux.die.net/man/5/ssh_config

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/libssh/
    idea_list_url: https://www.libssh.org/development/google-summer-of-code/
  

  - organization_id: 181
    organization_name: omegaUp
    no_of_ideas: 6
    ideas_content: |
     
      AI Teaching Assistant
      Brief Description:
      We recently added the role of (human) Teaching Assistant, which has the capability of providing code-reviews to students and answering clarification questions asked by students about assignments. In this project we want to create a bot that can answer clarifications and perform code reviews both proactively and upon request. This will help tighten the feedback loop for students so they can grow more rapidly.
      Expected results:
      omegaUp has an AI Teaching Assistant bot that can answer clarification questions and perform code reviews, proactively and upon request.
      Preferred skills:
      Python
      PHP
      MySQL
      LLM Prompt Engineering
      REST APIs
      Possible mentor:
      Aritra8438, heduenas
      Estimated size of project:
      350 hours
      Skill level:
      Advanced

      ~~~~~~~~~~
      Generate Problem Editorials Using AI
      Brief Description:
      omegaUp has a problem base with thousands of public problems, the big majority of them do not have an official solution for students to read and learn when they can't solve the problem on their own. This project consists of using generative AI and validate official solutions to the thousands of public problems. Generative AI should also be used to validate the editorial by asking it to generate code based on the editorial.
      Expected results:
      A high percentage (> 70%) of existing and new problems should have an official editorial that has been generated and validated using AI.
      Preferred skills:
      Python
      LLM Prompt Engineering
      PHP
      Vue.js
      Possible mentor:
      heduenas, pabo99
      Estimated size of project:
      350 hours
      Skill level:
      Advanced

      ~~~~~~~~~~
      Public Courses on github
      Brief Description:
      omegaUp offers many public courses in Spanish open to everyone. They have been solely managed by omegaUp staff but we want to be able to manage them through github so anyone can suggest improvements to the content (through pull requests). The Mexican Olympiad in Informatics already does this on a public course that they offer through omegaUp. We need to replicate what they have on our courses.
      Expected results:
      The content of public courses offered by omegaUp is managed through github and anybody is able to propose improvements through pull requests.
      Preferred skills:
      git/github
      Python
      Continuos Integration
      REST APIs
      Possible mentor:
      heduenas, tvanessa
      Estimated size of project:
      175 hours
      Skill level:
      Medium to Advanced

      ~~~~~~~~~~
      Cronjob Optimization
      Brief Description:
      We have a number of cronjobs responsible for things such as updating student/school rankings, awarding badges to students, etc. Over the time they have become inefficient, error prone and hard to debug. We want to make them more efficient, increase their test coverage and improve their debug-ability.
      Expected results:
      Cronjobs become much leaner, faster and easier to maintain.
      Preferred skills:
      Python
      MySQL
      PHP
      Unit and Integration Testing
      Possible mentor:
      carlosabcs, tvanessa
      Estimated size of project:
      350 hours
      Skill level:
      High

      ~~~~~~~~~~
      Integrate Problem Creator with Create/Edit Problem Workflows
      Brief Description:
      A project from last year's GSoC introduced the Problem Creator, a visual editor that helps problem authors create and edit problems more easily. However, the Problem Creator isn't yet fully integrated with omegaUp. Currently, authors must:
      Write their problem using the Problem Creator
      Download it as a .zip file
      Upload it through a separate UI to add it to the platform
      The editing process is similarly cumbersome, requiring authors to download a .zip, upload it to Problem Creator, make changes, download again, and upload again to update. This year, we aim to streamline these workflows by fully integrating the Problem Creator with omegaUp's create and edit problem features.
      Expected Results:
      Authors will have access to a simple, straightforward workflow to create and edit problems without needing to handle .zip files.
      Preferred skills:
      Vue.js
      Typescript
      PHP
      Estimated size of project: 350 hours
      Skill level:
      Medium
      Possible mentor:
      Aritra8438, carlosabcs

      ~~~~~~~~~~
      Code Coverage Measurement for End-to-end Tests
      Brief Description:
      We recently migrated our integration tests written in Cypress. We use codecov to measure and enforce test coverage, however our codecov setup right now only takes into account unit tests and not end-to-end tests. In this project we want codecov to also measure cypress test coverage so we can enforce minimum levels of coverage.
      Expected results:
      Codecov reports cypress test coverage enabling coverage levels to be monitored and minimum levels of coverage to be enforced.
      Preferred skills:
      Integration testing
      Typescript
      PHP
      Possible mentor:
      pabo99, heduenas
      Estimated size of project:
      90 hours
      Skill level:
      Medium
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/omegaup/
    idea_list_url: https://github.com/omegaup/omegaup/wiki/Google-Summer-of-Code-2025

  - organization_id: 182
    organization_name: openSUSE Project
    no_of_ideas: 17
    ideas_content: |
      
      New workflow for building and publishing openSUSE Leap Release Notes

      Project Title:
      New workflow for building and publishing openSUSE Leap Release Notes

      The deployment of openSUSE Leap release notes is currently a manual process.
      We can do much better!

      Goals:

      In ideal world Leap release notes include also content from SLES release-notes (as Leap is essentially SLES + community packages. And we use something like simple github CI to publish it.

      Avoid building packages in OBS. RN rpms were required by our legacy installer, new installer does not need it.

      Current process: https://progress.opensuse.org/issues/132053
      We could host new Leap releates notes next to SLES RN http://github.com/SUSE/release-notes

      Relevant Notes from last Release Notes discussion https://etherpad.opensuse.org/p/weeklymeeting20250225-rn
      Example build of SLES Release notes https://susedoc.github.io/release-notes/sles-15_SP4/html/release-notes/#jsc-SLE-21308

      Deliverables:

      Initial Leap release notes in asciidoc http://github.com/SUSE/release-notes
      Leap Release Notes include also SLES release notes content
      Automatic Build and Publish of Release Notes via CI, similar to the current SLES process https://github.com/SUSE/release-notes/actions
      Leap Release Notes have openSUSE theme (similar to https://github.com/openSUSE/release-notes-openSUSE / https://doc.opensuse.org/release-notes/x86_64/openSUSE/Leap/15.6/index.html)
      Preview build on each pull request?
      Mentor:
      @lkocman

      Skills:
      Github, CI / DevOPS, markdown/asiciidoc processing.

      Project Size: Small Sized Project (50 hours)

      ~~~~~~~~~~



      

      
      Support for Ubuntu Snap Packages in Uyuni

      Project Title:
      Support for Ubuntu Snap Packages in Uyuni

      Description:

      Since Ubuntu 20.04 LTS, the Snap package technology has gained significant traction, and with the upcoming Ubuntu 24.04 LTS release, many deb packages are being migrated to Snap.

      With this increasing adoption of Snap packages in Ubuntu, Uyuni lacks native support for managing Snap-based applications. This creates a gap in package management, especially as more software is distributed via Snap.

      Goals:

      Introduce Snap support in Uyuni, allowing users to:

      Install, update, and remove Snap packages.

      Manage Snap channels (stable, candidate, beta, edge).

      Handle Snap package management in airgapped environments.

      Deliverables:

      The code as a PR to the Uyuni repository
      Design decisions and evaluation as a Wiki page in Uyuni Wiki

      Mentor:

      @m-czernek , @wweellddeerr

      Skills:

      Java knowledge
      Python knowledge
      Good SQL knowledge
      Familiarity with PostgreSQL
      Skill Level: Medium

      Project Size: Medium Sized Project (125 hours)


      ~~~~~~~~~~
      



      Uyuni database optimisiation
      Project Title:

      Uyuni database optimization

      Description:

      Uyuni is an open source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API.

      Uyuni is based on an older project without much database refactoring and optimizations and so its database design is rather old. Previous design decisions are no longer state of the art and are now rather hurting the performance.

      Database was designed for more database engines which Uyuni no longer supports, for old postgresql version without useful features added in later version.

      Ultimately this project aims for overall database schema refactoring and optimizations, but given scale of the project, actual deliverables will be probably smaller.

      Goals:

      database in majority uses NUMERIC datatype as an ID column tied with custom sequence generator. NUMERIC is slow datatype for joins and selects and a plan how to migrate from NUMERIC to BIGINT type and autogenerated sequences instead of custom sequence generator. This includes:
      changes in database schema
      changes in mapped Java objects
      migration workflow
      performance evaluation of schema migrations
      replace VARCHARs with list constrains to ENUMs
      replace CHAR(1) to BOOLEANs
      Stretch goals:

      identify cross joins and replace them by inner or left or right joins when possible
      identify possible table decompositions
      or on the other hand where decomposition went too far and hurts performance
      explore using postgresql partitioning on large tables to improve performance
      Deliverables:

      The code as a PR to the Uyuni repository
      Design decisions and evaluation as a Wiki page in Uyuni Wiki
      Mentor:

      @aaannz
      Skills:

      Java knowledge
      Good SQL knowledge
      Familiarity with PostgreSQL
      Skill Level: Medium

      Project Size: Medium Sized Project (125 hours)

      Get started:

      Join GitHub Discussions and chatrooms: uyuni-project/devel uyuni-project/users
      Get familiar with uyuni
      Set up a development Uyuni server VM, e.g. with sumaform
      Uyuni schema and how updates are done

      ~~~~~~~~~~



      kubectl-like get command for mgrctl

      Project Title:

        kubectl-like get command for mgrctl

        Description:

        Uyuni is an open source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API.

        mgrctl is a tool meant to offer API access to the Uyuni server. At the moment it provides a limited set of features and only covers raw API calls.

        The goal of this task is to implement a get command that works like the one from kubectl. So users could query the API using a command like: mgrctl get <object_type> [options].

        The first object types to implement could be system, group as those are central concepts of Uyuni.
        The options would provide search by name, filtering using some of the object properties and output format options.
        For instance mgrctl get system -f cpu=x86_64 -o yaml would return a YAML file with the systems that have an x86_64 CPU.

        Note, this idea already exists as an uyuni-tools issue: uyuni-project/uyuni-tools#238

        Deliverable:

        The code as a PR in uyuni-tools repository.
        Documentation for the new command at least in the mgrctl get --help.
        Mentor:

        @cbosdo
        Skills:

        Good Golang knowledge.
        Skill Level: Medium

        Project Size: Medium Sized Project (125 hours)

        Beware this could easily turn into a rabbit hole: properly define the limits of the project with the mentor. Better have only a few objects covered correctly than a lot with many missing pieces.

        Get started:

        Join GitHub Discussions and chatrooms: uyuni-project/devel uyuni-project/users
        Get familiar with uyuni
        Get familiar with the mgrctl code. Starting with the api command code could be a good idea.
        Check the Uyuni API docs
        Set up a development Uyuni server VM, e.g. with sumaform. This page can help you getting started. The crucial part is the network setup as it would lead to various strange problems later. Make sure to read https://github.com/uyuni-project/uyuni/wiki/Libvirt-DNS-and-DHCP-without-Avahi to help with this.
      

      ~~~~~~~~~~
      AI-Driven Test Selection on Pull Request acceptance tests

      Project Title
      AI-Driven Test Selection on Pull Request acceptance tests

      Description
      Large test suites can slow down CI/CD pipelines, leading to longer feedback loops and inefficient resource usage. This project aims to leverage machine learning (ML) to predict which tests should be executed based on product code pre-processing, recent code changes, commit history, past test failures, and code coverage.

      By analyzing this data we can train an ML model to prioritize high-risk tests and reduce overall test execution time. The goal is to reduce the Pull Request acceptance tests execution time by running only the most relevant tests using this ML model.

      This project is a continuation of our current work in the Uyuni project, that will be presented during the SeleniumConf 2025

      The project will involve
      Extracting commit history to identify impacted files.
      Analyzing test execution history to track past failures.
      Processing code coverage data to map tests to code changes
      Research if we can process and integrate some parts of the product code, i.e. dependency graphs.
      Training a machine learning model (e.g., Random Forest, XGBoost) to recommend which tests to run.
      Integrating the trained model into our GH actions to dynamically select tests for each Pull Request.
      This approach ensures that tests are executed intelligently, reducing test cycle time while maintaining high test coverage.

      Deliverables
      Data extraction scripts for:
      Commit history from Git (files changed, commit messages)
      Test execution logs (pass/fail results, error messages)
      JaCoCo Code coverage reports
      A trained ML model that predicts which tests should run based on commit history and past test results.
      Integration with GitHub actions to automate test selection.
      Comprehensive documentation on setup, training, and deployment of the model.
      Mentor
      Oscar Barrios (@srbarrios)

      Skills Required
      Ruby (for test framework integration).
      Machine Learning Basics (feature engineering, model training).
      Python + Scikit-Learn/Pandas (for ML model development).
      GitHub actions (to integrate test selection into pipelines).
      Cucumber/Selenium Testing (understanding of automated tests).
      Skill Level
      Medium – Requires knowledge of Ruby (for test integration) and basic ML concepts (training and using models).
      Prior experience with CI/CD and automated testing is a plus.
      Project Size
      Medium-Sized Project (160 hours)

      Get Started
      Data Sources:

      Uyuni Git Commit History: Includes code changes, affected files, and commit messages.
      Test Execution Logs: Stores past test results, including failures, execution time, and errors. This content it gonna be publicly available through a web server located in AWS, for now we are publishing only the Cucumber reports here.
      Code Coverage Data: Tracks which tests touch specific parts of the codebase. This is available in a Redis database, and already in use in our GH actions
      Steps

      Data Collection & Preprocessing
      Extract Commit History
      Extract Test Execution History
      Extract Code Coverage Data
      Use Python + Scikit-Learn for training a model using all the data collected.
      Prepare Training Data
      Train a Classification Model
      Integrate it as GitHub action into every Pull Request
      Enhance the current GH action using the ML model.
      Useful links

      Scikit-Learn Guide
      Facebook article 1
      Facebook article 2
      Blog post
      Efficacy Presubmit

      


      ~~~~~~~~~~
      Refactoring Hibernate Queries in Uyuni: Towards a Unified Approach

      Project Title:

      In Hibernate's long history, there have been several ways to define a query:

      Description:

      HQL: Hibernate Query Language (HQL)
      Hibernate Criteria Queries: Documentation
      JPA Criteria Queries: Baeldung Guide
      Native SQL Queries
      Depending on the type used, queries can be defined in:

      An hbm.xml file
      An orm.xml file
      A JPA annotation
      Hardcoded in Java code
      Currently, Uyuni's codebase uses all of these approaches.
      Deliverable:

      Refactoring all queries to Named Native Queries using annotations: Example
      Adjust/create new hibenate entity (if required)
      Adding unit tests (if missing or applicable)
      Preventing developers from adding queries that are not Named Native Queries with annotations (e.g., via Checkstyle or another enforcement mechanism)
      Mentor:

      @mbussolotto

      Skills:

      Good Java knowledge.
      Good SQL knowledge.
      Hibernate, or motivation to learn it.
      JPA, or motivation to learn it.
      Skill Level: Easy/Medium

      Project Size: Medium Sized Project (125 hours)

      Get started:

      Join GitHub Discussions and chatrooms: uyuni-project/devel uyuni-project/users
      Get familiar with uyuni, especially with the Java code
      Hibernate documentation https://hibernate.org/orm/documentation/6.6/
      

      ~~~~~~~~~~
      UI Plugin infrastructure

      Project Title:

      UI plugin infrastucture

      Description:

      Uyuni is an open source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API.

      The user interface is currently implemented in a mix of Spring (old code) and TypeScript (what we aim at). Users may want to ship extensions to the UI, like adding a new entry in the main menu and displaying their application in the main content area.

      The project is about implementing such an extension mechanism. The basic workflow would be:

      Configure a remote location where to pull the extension from (already built)
      The extension would be stored in one of the container existing volumes
      Load entry points in the menu and main content area.
      Deliverable:

      The code UI extension implementation
      An example extension
      Documentation on how to create an extension
      Mentor:

      @cbosdo
      Skills:

      Good Java and TypeScript knowledge.
      Skill Level: Medium/Hard

      Project Size: Medium Sized Project (125 hours)

      Get started:

      Join GitHub Discussions and chatrooms: uyuni-project/devel uyuni-project/users
      Get familiar with uyuni, especially with the menu tree definition and the web UI loading mechanism.
      Set up a development Uyuni server VM, e.g. with sumaform
      

      ~~~~~~~~~~
      Remove use of Java raw types

      Project Title:

      Remove the use of Java raw types

      Description:

      Uyuni is an open source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API.

      The Java code of Uyuni evolved over the years but still contains raw types uses. This project is about removing them all! This may sound an easy task, but this requires quite some code reading and patience to achieve it.

      Here is a list of the reported uses: https://sonarcloud.io/project/issues?languages=java&rules=java%3AS3740&issueStatuses=OPEN%2CCONFIRMED&id=uyuni-project_uyuni

      Deliverable:

      The code without the raw types.
      SonarCloud reporting no raw type use any more: https://sonarcloud.io/project/issues?languages=java&rules=java%3AS3740&issueStatuses=OPEN%2CCONFIRMED&id=uyuni-project_uyuni
      Mentor:

      @cbosdo
      Skills:

      Good Java knowledge.
      Skill Level: Easy/Medium

      Project Size: Small Sized Project (90 hours)

      Get started:

      Join GitHub Discussions and chatrooms: uyuni-project/devel uyuni-project/users
      Get familiar with uyuni, especially with the Java code
      Set up a development Uyuni server VM, e.g. with sumaform
      

      ~~~~~~~~~~
      Log Detective for openSUSE / OBS

      Project Title: Log Detective for openSUSE

      Description: Fedora project has a project to train an AI model to help with rpm build errors: https://log-detective.com/. The

      The goal of this project is to explore different ways of contributing to Log Detective with some semi-automated data and investigate interesting ways of integrate the model in openSUSE development workflow, it could be with a new osc plugin, implementing some integration in OBS webpage, or any other tooling around building packages and reading logs of failing builds.

      Deliverable: The result of this project will be documentation with the research results about the usage of AI model to debug failing builds, experimental tools / scripts to feed log-detective.com and to use the model easily for openSUSE packagers.

      Mentor: @danigm

      Communication channels:

      Matrix direct message: @danigm:gnome.org
      Matrix openSUSE chat channel: mention me (danigm) openSUSE Chat
      Email: daniel.garcia@suse.com
      Be patient and wait one or two days before reping, I'll try to answer as soon as possible, but it's not always possible answer in the same day.

      Skills: AI, python, rpm, packaging, git, Linux

      Skill Level: Medium

      Get started:

      Get familiar with https://log-detective.com website
      Study log-detective API and source code, and open build service to start to think about different ways of integration.
      

      
      


      

      ~~~~~~~~~~
      Extract and containerize Uyuni Salt event processor

      Project Title:

      Extract and containerize Uyuni Salt event processor

      Description:

      Uyuni is an open-source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API.

      Salt project is used for the communication and management layer. Data is transferred between servers and is minions in the form of events. The events that arrive on the Uyuni server need more processing than the ones performed by salt master.

      The processing of Salt event cannot block the salt master. For this reason, salt is configured to save the salt events on the database to be asynchronously processed. Currently, the process responsible for this is Tomcat. However, tomcat should be focused on serving the web application and not processing the salt events.

      This project is focused on extracting the salt-event processing to an external process and containerizing it. The extraction is partially done in here.

      The major work will be focused on containerization and deployment using uyuni-tools project.

      Deliverable:

      Container image that can process the salt-event stream.
      Uyuni tools being able to deploy this container.
      Mentor:

      @rjmateus @mackdk @renner

      Skills:

      Java knowledge
      Go knowledge
      knowledge of containerized applications
      Skill Level:

      Medium,

      Project Size:

      Medium Sized Project (175 hours)

      Get started:

      Join GitHub Discussions and chatrooms: uyuni-project/devel uyuni-project/users
      Get familiar with uyuni
      Get familiar with uyuni-tools
      Set up a development Uyuni server VM, e.g. with sumaform
      

      ~~~~~~~~~~
      Packit support for OBS

      Project Title:

      Packit support for OBS

      Description:

      Packit is a CI system that builds rpms out of upstream projects. Currently it only supports building rpms in COPR and Koji. It would be beneficial for packit to gain support to build in OBS, as it would give access to more distributions and would allow packit to send submissions to openSUSE.

      Deliverable:

      Implement support for the packit CLI to build on OBS (finish OBS build support packit/packit#2067)
      Add support for the packit server to build on OBS
      stretch goals:

      implement support for sending submit requests on OBS via packit
      Mentor:

      @dcermak
      @lachmanfrantisek

      Skills:

      Python knowledge
      packaging rpms is beneficial
      Skill Level:

      Medium to Hard

      Project Size:

      Large Sized Project (350 hours)

      Get started:

      get acquainted with OBS and the OBS API
      learn the basics of building RPMs in COPR, koji and OBS
      give packit a try
      

      ~~~~~~~~~~
     
      Improve test coverage in rpmlint

      Project Title: Improve test coverage in rpmlint

      Description: The rpmlint project has a lot of tests. The past year during the GSoC we extend the test tools to make it easy to write tests mocking rpm files, but there are still a lot of tests that uses binary rpm files for tests.

      The goal of this project is to try to reduce the number of binary .rpm files in the repository and replace tests with mock and extend the test suite to increase the code coverage.

      Deliverable: The result of this project will be multiple pull requests to the rpmlint repository with new tests.

      Mentor: @danigm

      Communication channels:

      Matrix direct message: @danigm:gnome.org
      Matrix openSUSE chat channel: mention me (danigm) openSUSE Chat
      Email: daniel.garcia@suse.com
      Be patient and wait one or two days before reping, I'll try to answer as soon as possible, but it's not always possible answer in the same day.

      Skills: python, RPM, packaging, git, Linux

      Skill Level: Medium/Hard

      Get started:

      Get familiar with the rpmlint code base and current way of testing: https://github.com/rpm-software-management/rpmlint
      Study python testing and get familiar with options we can utilize
      Links

      Replace existing binary rpm in tests with FakePkg rpm-software-management/rpmlint#1105
      Create test FakePkgs to use in different tests  rpm-software-management/rpmlint#1104
      All the objects we have in place should have some basic tests rpm-software-management/rpmlint#156
      

      ~~~~~~~~~~
      Provide a library for determining keylength security

      Project Title: Project title, short enough to catch attention

      Provide a library for determining keylength security

      Description: General information about the project, avoid one Liners, the description should be as detailed as possible.

      The project would be writing a library for looking at keylength of algorithms and measuring their security according to different standards. For example RSA-4096 is currently considered secure, but RSA-1024 not. We want a library which embedds this knowledge and can be requested. Furtheron we want to be able to enhance the library or write a program which does scan keys or certificates and determines their security strength. This should be done according to different standards, think NIST standards or IETF or BSI standards.

      There's already a website which does this similarly, called keylength.com, but this is not usable as a library, nor cannot be used in a pipeline or an offline program

      This library could be done in Rust but the most important point is, that it can be linked to other (lowlevel) languages

      Deliverable: Expectations from the student at the end of the project

      The first task is reading and understanding the different Standards and Papers regarding keylengths for cryptographic primitives and their security
      The second task is implementing this knowledge into a library
      The third task would be to write a program which uses this library to scan keys or certificates so the program can say if the used primitives and their keylengths are secure according to specific standards
      Mentor: Who is the mentor? Who is the Co-Mentor? Also please assign the issue to the mentor!

      Dennis Knorr (dennis.knorr@suse.com)
      Martin Sirringhaus (martin.sirringhaus@suse.com)

      Skills: Which skills are needed? Programming languages, frameworks, concepts etc.

      have a bit knowledge in cryptography
      being somewhat able reading papers and standards about keylengths and their respective security
      being familiar with programming
      Skill Level: Easy, Medium, Hard

      Medium

      Prject Size: Medium Sized Project (175 hours), Large Sized Project (350 hours)

      As reading and grokking the papers might take some time and also writing a program which scans keys needs parsing, this is more a large project

      Get started: Tasks that mentors may want to suggest students so that they can start contributing to the code base (e.g. junior jobs, low hanging fruits, discussion on the mailing list)

      Get familiar with standards like https://infoscience.epfl.ch/record/164539/files/NPDF-32.pdf or https://infoscience.epfl.ch/record/164526/files/NPDF-22.pdf (you do not have to read them all now, just be aware of it)
      Get familiar with the language you want to do this with (we would prefer rust)
      

      ~~~~~~~~~~
      Migrate download endpoint to a independent service

      Project Title:

      Develop a new service to manage package download.

      Description:

      Uyuni is an open source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API.

      One of the main features of uyuni is package installation in managed machines (more information about the project at: https://www.uyuni-project.org/).
      To be able to install packages systems need to download information from the server: metadata and package files. All these calls go through the download endpoint which validates the user authentication and then provides the requested data.
      Being the most used endpoint this project has the goal to extract it to an independent service prepared to scale and run in a container.

      We would like to containerize this feature at the same time keeping the same proven business logic.

      Deliverable:

      The main goals/delivers would be:

      Extract the download endpoint to an independent service
      Run the new service in a container
      Replace the existing implementation of the feature with the containerized one
      Mentor:

      @rjmateus (co-mentor to be defined)

      Skills:

      Good knowledge of the Java programming language and best practices
      Good knowledge of web development worflow
      Knowledge of containers technology
      Skill Level:

      Medium. The java to validate the download data already exists.

      Prject Size:

      Medium Sized Project (175 hours)
      Get started: Tasks that mentors may want to suggest students so that they can start contributing to the code base (e.g. junior jobs, low hanging fruits, discussion on the mailing list)

      Set up a development environment for Uyuni locally using sumaform
      Container image with a running server is being prepared
      How to Contibut
      Select a good first bug from
      ... have fun :)
      

      ~~~~~~~~~~
      Migrate the Uyuni build process from Ant to Maven

      Project Title:

      Migrate the Uyuni build process from Ant to Maven

      Description:

      Uyuni is an open source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API. The Uyuni Java code is built using Ant since a long time for the purpose of building official packages for installation, but also for development usage. We would like to achieve the following while preserving all of the existing use cases:

      Move all the Java code and tests to a maven like structure
      Use maven for the build process for developers and official releases
      Use maven to run checkstyle and unit tests on the Java code locally and in CI
      Deliverable:

      It should be possible to build and deploy the code to a local development server using maven
      It should be possible to run checkstyle and the unit tests locally or in CI (e.g. in Jenkins or GH Actions)
      The official package build process should be migrated to maven (see the spec file)
      Ant buildfiles should become obsolete and should finally be removed from the repo
      Mentor:

      @mackdk with @cbosdo as co-mentor.

      Skills:

      Very good knowledge of the Java programming language and best practices
      Expertise with both of the most common Java build tools (Ant and Maven)
      Experience with packaging software for Linux, ideally using the Open Build Service
      Skill Level:

      Be aware that even though it might sound rather easy, the skill level here is Medium / Hard. The reason is that the codebase is huge, there is a lot of dependencies (that we are resolving from OBS rather than from maven central), the package build process is very complex and this migration is a huge change for everyone involved, especially developers and release engineers.

      Project Size:

      Large Sized Project (350 hours)

      Get started:

      Set up a development environment for Uyuni locally using sumaform
      Get familiar with the dependency resolution mechanism used in the project and respective tools (especially obs-to-maven)
      Use the Open Build Service to build packages with maven, or migrate an existing package
      

      ~~~~~~~~~~
      
      Refresh Uyuni's YourRHN page

      Project Title: Refresh Uyuni's YourRhn page

      Description:

      The current landing page of a user, called Your RHN is written in JSP and the data it shows may not be super helpful.
      The old JSP pages in Uyuni are slowly being rewritten using ReactJS and this one is yet another on the waiting list.

      While changing this page, the idea is to provide more useful data like stats about the systems needing upgrades or reboots or the number of scheduled or failed actions. Ideas of data to show there are welcomed: the list is not fixed.

      Here is what the current page looks like:

      image

      Code pointers:

      Java code behind the JSP: https://github.com/uyuni-project/uyuni/blob/master/java/code/src/com/redhat/rhn/frontend/action/YourRhnAction.java
      JSP code: https://github.com/uyuni-project/uyuni/blob/master/java/code/webapp/WEB-INF/pages/yourrhn.jsp
      Code of existing ReactJS pages: https://github.com/uyuni-project/uyuni/tree/master/web/html/src/manager and https://github.com/uyuni-project/uyuni/tree/master/web/html/src/components
      Deliverable:

      The page is converted to ReactJS and shows some stats on the user's systems and quick actions.

      Mentor: @cbosdo, @wweellddeerr

      Skills: ReactJS and Java. Hibernate and SQL are a plus.

      Skill Level: Hard

      Get started:

      Installing the development environment:

      https://github.com/uyuni-project/uyuni/wiki/Java-Development-Environment
      https://github.com/uyuni-project/uyuni/wiki/Frontend-Development-Environment
      Installing a test environment:

      https://github.com/uyuni-project/uyuni/wiki/Uyuni-development-in-no-time

      Slides on how to get started developing Uyuni: https://bosdonnat.fr/slides/openSUSEAsiaSummit19/#/about

      Uyuni Wiki:

      Introduction to Uyuni and systems management (presentation): https://github.com/uyuni-project/uyuni/wiki/Presentations
      Uyuni development in no time: https://github.com/uyuni-project/uyuni/wiki/Uyuni-development-in-no-time
      Development pages: https://github.com/uyuni-project/uyuni/wiki/

      ~~~~~~~~~~
      
      Analytics Edge Ecosystem Workloads

      Project Title: Create open source sample microservice workload deployments and interfaces, spanning distributed edge-core-cloud infrastructure to address chosen market verticals to provide relevant analytics per market verticals

      Description: In the context of this Analytics Edge Ecosystem, such a digital transformation approach to cloud-native containerizing addresses how one can help strategically iterate and perform the necessary and even more comprehensive business/usage analytics requirements. This can be done across a truly distributed compute infrastructure (with various resource options), leveraging compute elements closer to where data is generated, validated or provided initially or in addition. Then you can more rapidly adapt the reaction, formulate predictions and forecasts, and have a larger context of all the elements that can potentially impact and internally secure your business positively plus for consumers, providers, and partners.

      Deliverable: Provide an opensource-based example deployment of a trained/tested/functional workload available for use cases:

      General
      Interact in sprint meetings, sharing progress, issues, and plans (via lightning talk approach) and peer reviews of other contributors or examples
      Provide content in a usable, accessible GitHub repo example for the team to access
      (Bonus Points) : publish blog/demo/documentation or webinar/conference sessions with an overview of why certain paths were chosen and how it was done
      Phase I (Bonding Period)
      Learn and interact plus become familiar with the overall application infrastructure layers (network + hardware + storage technology, operating system, containers, kubernetes, AI/ML/GenAI examples)
      Phase II (first coding)
      Pick a target role plus an interesting business vertical, research an existing example and deploy to learn about what underlying aspects are needed and what to provide above it
      Then either stay in same role, picking another vertical and retry or adopt another role to more completely adapt or provision it
      Phase III (second/final coding)
      Brainstorm and research an end-to-end example approach for a desired business vertical of your own personal interest
      Potentially port aspects/portions of other found examples to further improve the functionality and address better analytics plus multiple user case needs
      Deploy in multiple environments to validate usability
      Mentor: @bwgartner + more/others (Ann, Terry, plus maybe some previous GSoC contributors)

      Skills / Layers / (Roles):

      Application Infrastructure (ITOps, AIOps, Platform Engineering
      Network/Computing/Storage Platforms
      Operating System
      Programming languages (your choice)
      Bash, JavaScript, Java, Jupyter, Python, R, Ruby, ollama, LLM, RAG, Vector Databases...
      Build packages, virtual machines, container runtime and image creation, manifests/helm charts
      Cloud-Native Kubernetes leveraging Rancher offerings
      Data Pipeline (Data/Ops Analysis)
      Ingest, cleanse, validate, stream, flow, curate, conform
      Machine Learning Pipeline (MLOps)
      Train, test, flow, evaluate, secure AI (Artificial Intelligence)/ML (Machine Learning)/DL (Deep Learning)/LLM (Large and Small Language Models)
      User, Consumer, Operator, Programmer Interfaces, (DevOps/GitOps)
      Example business verticals
      agriculuture/environmental/weather, automotive, healthcare, retail, federal/military, finance, manufacturing, media/entertainment, smart building/city/home/light/parking, telecommunications, ...
      Skill Level: Easy, Medium

      Get started:

      Container Guide ( https://documentation.suse.com/container/all/single-html/SLES-container/ ) and access to registries
      Kubernetes ( https://rancher.com/learn-the-basics https://rancherdesktop.io/ )
      Datasets ( https://www.kaggle.com/datasets )
      Code/Data Science ( https://www.kaggle.com/code )
            

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/opensuse-project/
    idea_list_url: https://github.com/openSUSE/mentoring/issues

  - organization_id: 183
    organization_name: rocket.chat
    no_of_ideas: 23
    ideas_content: |
      
      
      💡Maestro as Mobile UI Testing Framework
      👥 Mentor(s): Diego Mello
      💬 Description:
      Migrate Rocket.Chat Mobile app's UI testing framework from Detox to Maestro. Maestro is a modern mobile UI testing framework that offers several advantages over Detox:
      More reliable test execution with fewer flaky tests
      Better debugging capabilities with detailed test reports and video recordings
      Simpler test writing syntax using YAML
      Cross-platform support for both iOS and Android
      Active community and development
      This migration will help improve the reliability and maintainability of our mobile app testing suite while reducing the time spent debugging flaky tests.
      💪 Desired Skills:
      Experience with mobile app testing
      Knowledge of React Native
      Familiarity with YAML syntax
      Understanding of CI/CD concepts
      Basic knowledge of iOS and Android development
      Good problem-solving skills
      Experience with Git and GitHub
      🎯 Goals/Deliverables:
      Setting up Maestro testing infrastructure in the mobile repo
      Converting existing Detox tests to Maestro format
      Creating new tests to improve coverage
      Implementing CI/CD pipeline integration on Github Actions
      Documentation of testing practices and guidelines
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Intermediate

      ~~~~~~~~~~


      🚀 Hugging Face Management Assistant for Rocket.Chat
      👥 Mentor(s): Prisha Gupta
      📢 Communication Channel: idea-HuggingFace-Management-Agent
      💬 **Description: **
      Managing models, datasets, and Spaces on Hugging Face can be challenging, especially within teams. This Rocket.Chat app will integrate with Hugging Face Hub APIs to allow users to list, update, and monitor HF resources directly from Rocket.Chat.
      The App will enable:
      Viewing available models, datasets, and Spaces
      Updating model metadata (e.g., descriptions, tags)
      Managing repository settings (private/public, visibility)
      Get updates on Space build status
      Manage PRs
      Real-time notifications for updates on Repos
      By integrating management functionalities directly into Rocket.Chat, teams can streamline collaboration and reduce the need to switch between multiple platforms.
      Bonus nice-to-haves are any additional innovative features that leverage generative AI (LLMs) to facilitate in-channel interactions with Hugging Face.
      💪 Desired Skills:
      Rocket.Chat Apps Engine and TypeScript
      Hugging Face Hub API
      API authentication and security
      🎯 Goals/Deliverables:
      A Rocket.Chat App that allows users to manage Hugging Face repositories, models, datasets, and Spaces efficiently through chat commands. It will provide an intuitive interface for listing, updating, and tracking resources with real-time notifications.
      ⏳ Project Duration: 90 hours (Small)

      ~~~~~~~~~~
      💡Real Time Message Rendering in Message Composer
      👥 Mentor(s): Martin Schoeler
      💬 Description:
      Any rich text content is rendered in its text form - for example emojis will be rendered as :grin: instead of 😬, Bold markdown highlight will be rendered as **Bold** while composing a message using Rocket.Chat.
      This project should upgrade the composer to support real-time in-message rendering of rich content while editing.
      Most of the complexity of this project comes from properly converting the existing Message Composer to display rich content, while integrating with ALL existing functionality of the Composer component
      💪 Desired Skills:
      Understanding of the composer component
      Understanding of Rocket.Chat's message rendering pipeline
      Advanced Typescript
      Good understandng of DOM elements and it's intricacies
      Desire to work on high impact projects (benefiting every single RC user)
      🎯 Goals/Deliverables:
      Having a working MVP of real time message rendering in the message composer
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Intermediate/Advanced

      ~~~~~~~~~~
      💡 Frequently Asked Questions (FAQ) Detection Assistant
      👥 Mentor(s): Aman Negi
      📢 Communication Channel: idea-Frequently-Asked-Questions-Detection-Assistant
      💬 Description:
      New contributors to open source often ask very similar questions. Answering similar questions repeatedly can be a tiring and tedious task for maintainers (or mentors).
      This LLM powered assistant will solve the problem by:
      monitoring Github webhooks or a set of specified Rocket.Chat channels for questions
      determine if the incoming question is similar to one in a set of configured FAQ
      if a match is found, do one of the following configurable action:
      notify one or more configured users of the incoming question
      notify one or more configured users of the incoming question via DM, providing a summarized answer as a suggestion
      notify one or more configured downstream LLM driven agents
      same as ii., but provide the capability for the notified users to "approve" the automated reply of the summarized answer; some final editing before reply should be possible
      answer the incoming question with a summarized answer; then notify one of the configured users in DM
      Considerations:
      the assistant must be designed to be 100% fail safe; it should never answer unrelated question or answer with hallucinations (nor answer with harmful content)
      the assistant should be designed to be functional in all FAQ/templated answers/Quick-reply situations, increasing its utility
      this project will involve very clever prompting and optimized prompt chaining (instead of tedious volumous Typescript code)
      💪 Desired Skills:
      Rocket.Chat Apps Development (Typescript)
      Github/Gitlab webhooks development
      Advanced prompt engineering
      Passion for creating LLM driven assistive applications
      🎯 Goals/Deliverables:
      A useful assistant in many automated public group chat/forum context with configurable abilities to help in handling frequently asked questions.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~

      💡Server Setup Agent
      👥 Mentor(s): Aditya Singh
      📢 Communication Channel: idea-Server-Setup-Agent
      💬 Description:
      As an administrator setting up a production Rocket.Chat server, one is typically required to create user accounts, create and assign roles, create default channels, possibly starting threads, starting discussions and populating with initial messages.
      These sort of tedious tasks are also often required in the testing and quality assurrance of Rocket.Chat or Rocket.Chat related apps/projects. Furthermore, they are also required in many demo and training situations.
      This project is a Setup Agent App that automates all of the above based on either a series of slash commands or by loading an automated script.
      The script should conform to an easy to learn, intuitive and simple DSL (Domain Specific Langauge) of the contributor's design.
      The language needs to incorporate basic variables, and be able to handle simple counted loops. Conditionals and conditional loops are nice to have.
      The agent should be tested to handle very large scripts that may involve the creation of thousands of objects and messages.
      DSL will be checked for LLM-generation suitability; although AI generation of the script is outside the scope of this project.
      💪 Desired Skills:
      Interest in DSL and AST (Domain Specific Language and Abstract Syntax Trees)
      Rocket.Chat Apps development (Typescript)
      Familiarity with Rocket.Chat's REST APIs
      🎯 Goals/Deliverables:
      A Rocket.Chat App "agent" that can help setup servers (or for QA or demo or training) by executing an automated script.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~
      💡Natural Language Bridge to Legacy Email (powered by Generative AI)
      👥 Mentor(s): Vipin Chaudhary
      📢 Communication Channel: idea-Natural-Language-Bridge-to-Legacy-Email
      💬 Description:
      Messaging systems such as Rocket.Chat were supposed to be replacing legacy email for communications and collaboration since the early nineteen nineties. But even after three decades of evolution and struggle, half the world still hangs onto legacy email worldwide despite most have grown up with SMS and asynchronous messaging.
      This project bridges the great divide most naturally with a Rocket.Chat App that responds to natural language instructions and brings the legacy email world right into every Rocket.Chat conversation for every user.
      The app will respond to command such as:
      /xuebot summarize this thread and send it as email to my boss who refuses to use chat
      OR:
      /xuebot post in the channel for everyone the budget for 2025 email pdf received between 11/1/2024 and 12/24/2024
      Details:
      You will be using the function calling/tools capabilities of modern LLMs, plus some extremely clever prompting, as well as some hardcore Typescript coding to realize this app.
      The agent must be able to perform the following reliably as a minimum:
      summarize thread/channel/discussion and send as email to specified recipient(s)
      search emails by date range and keywords and present in-channel as message and/or extract attachment and upload to channel
      report on daily email statistics
      secured per-user email connection over TLS
      💪 Desired Skills:
      Rocket.Chat Apps (Typescript) Development
      Advanced prompt engineering skills
      Familiarity with Gmail and other mail provider APIs
      Familiarity with LLM function calling / tools capabilities
      Note: This project is inspired by the prior work of our 2025 contributor ZilongXue -> claude-post
      🎯 Goals/Deliverables:
      A natural language bridge to legacy email system that every single Rocket.Chat user can use.
      ⏳ Project Duration: 90 hours (short)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~

      💡 AI Enhanced Message Composer Component
      👥 Mentor(s): Gabriel Engel, Ashutosh Singh Chauhan
      📢 Communication Channel: idea-AI-Enhanced-Message-Composer-Component
      💬 Description:
      This high impact project upgrades the Rocket.Chat message composer component to be fully AI powered. It empowers Rocket.Chat users to leverage all that modern AI technologies can offer while they are composing their message. These facilities, in 2025, may include:
      grammar corrections
      context sensitive spelling correction
      re-wording/re-phrasing for clarity / jargon-match
      tone Adjustments
      tone matching with messages in channel
      language translation
      message emojification
      message summarization and/or message verbose-tization
      and many more to come in 2025/2026
      Features:
      Inline Suggestions: Highlight areas needing improvement (grammar, clarity). Click to apply changes.
      Tone Selector: Add a dropdown to adjust the tone (e.g., formal or casual), and apply the change automatically.
      Message Preview: Allow users to toggle between the original and enhanced/translate message.
      Hinting: Display suggestions as subtle highlights or underlines, ensuring a smooth, non-intrusive experience.
      AI Integration Consideration
      This project / upgraded component will not include the LLM access mechanism. It is a pure UI component project. However, care must be taken to design it in such a way that it can be totally compatible with all kinds of LLM access -- client-side, server-side on-premises, server-side third party, cloud, and so on.
      💪 Desired Skills:
      Advanced understanding of Rocket.Chat Composer Component
      Advanced understanding of UI/Kit and Fuselage design philosophy
      Advanced JavaScript/TypeScript**
      Like coding, love design
      Love to work in maximum impact projects
      🎯 Goals/Deliverables:
      AI Enhancements in the Message Composer.
      UI/UX Polish for a seamless experience.
      Cross-Platform Support across web, mobile, and electron clients.
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Advanced

      ~~~~~~~~~~

      💡 Project Management Integration via Asana
      👥 Mentor(s): Gustavo Bauer
      📢 Communication Channel: idea-Project-Management-via-Asana-Integration
      💬 Description:
      Integrate Asana with Rocket.Chat to boost team collaboration. Instead of duplicating Asana’s complex task creation, focus on contextual notifications and quick access to task updates. Rocket.Chat project management users can stay informed collaborating within Rocket.Chat, while complex workflows that are better handled by Asana's rich UI remains in Asana. The transition to and from Asana should be seamless.
      Details:*
      Setup & Authentication
      Implement OAuth and channel configuration.
      Contextual Notifications
      Real-time alerts for task updates and deadlines.
      Quick Commands & Summaries
      Slash commands for task details and simple updates.
      Deep Linking
      Direct links from notifications to tasks in Asana.
      Optional Activity Feed
      A mini feed for recent Asana activity in channels.
      💪 Desired Skills:
      Experience with Rocket.Chat Apps Engine (TypeScript)
      OAuth and REST API experience
      🎯 Goals/Deliverables:
      An app delivering userful integration workflows for project management teams collaborating on Rocket.Chat. Including minimally contextual task notifications and summaries.
      For workflows that are better handled with Asana's rich UI, seamless redirect to Asana and seamless return to the Rocket.Chat collaboration context (channel / thread / discussions).
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy/Intermediate
      🔑 Passkey-Based WebAuthn Authentication for Rocket.Chat
      👥 Mentor(s): Julio Araujo, Dnouv
      📢 Communication Channel: idea-Passkey-Based-WebAuthn-Authentication-for-Rocket-Chat
      💬 Description:
      The WebAuthn standard, now widely available on modern Android and iOS devices, enable convenient passwordless authentication satisfying 2FA (biometrics and "have device"). Frequently this involves scanning a QR code followed by unintrusive biometrics such as FaceID on iOS. This project aims to integrate WebAuthn in Rocket.Chat authentication to offer a passwordless, secure login experience. The implementation needs to be aligned with Rocket.Chat’s existing authentication system while ensuring backward compatibility with all existing login methods.
      💪 Desired Skills:
      Node.js
      React.js
      WebAuthn API
      MongoDB
      Keen interest in cybersecurity
      Authentication & Security Best Practices
      🎯 Goals/Deliverables:
      Implement passkey-based authentication using WebAuthn
      Support QR Codes and Bluetooth hybrid transport
      Modify authentication modules to support passkey registration and login
      Update the frontend for seamless passkey interactions
      Ensure secure storage of public keys in the user database
      Conduct extensive testing across different devices and browsers
      Provide detailed documentation and promote community awareness
      ⏳ Project Duration: 175 hours (Medium)
      Server Guide Agent
      👥 Mentor(s): Gabriel Casals, Jeffery Yu
      📢 Communication Channel: idea-Server-Guide-AI-Agent
      💬 Description:
      As a new user joins a Rocket.Chat server there is not much guidance on what to do or where to go.
      Right now, the only mechanism is a passive landing page that may display resources for each grouping (persona) of users.
      For example, on the open.rocket.chat server, a user may be:
      A Rocket.Chat server administrators looking to connect with other administrators
      An end-user of Rocket.Chat looking to resolve problem or receive support information.
      A new community contributor looking for Google Summer of Code program information
      others
      Each one of these personas demand different style of conversation and would need to know about/join different sets of channels and other resources.
      Details:
      The project aims to replace the boring "easy to miss, difficult to understand" landing page, with an AI guide agent. This agent should start a conversation with the new user and then using modern LLM's discrimination/classification ability to positively identify the persona (users grouping/ sub-communities on a server) that the new user belongs to. The agent should continue to tune the conversation to the lingo-preferred of that persona, and finally guide the user to all the resources and channels available for that persona. This agent must be configurable (via Rocket.Chat Apps configuration) to handle any arbitrary persona and related resources set.
      Recommended Approach:
      The agent should be able to add (and join) the appropriate channel for the new user, after confirming the action with the new user. A default/catch-all persona should be used to precisely scoped the project and ensure the LLM can converge onto a useful result. Since direct user input will be passed to the LLM for analysis, the agent MUST make sure that there is no prompt-injection possibility. Safety of server operation must be taken into account as this agent has ability to change the state of the server permanently.
      💪 Desired Skills:
      Experience with Natural Language Processing (NLP) systems
      Rocket.Chat Apps Engine (TypeScript)
      Rocket.Chat messaging APIs
      Advanced prompt engineering skills
      Experience with tools/function-calling capabilities of modern LLMs
      Understanding of how to implement "safety first" when creating AI apps that may permanently change the state of a production system
      🎯 Goals/Deliverables:
      An AI Agent that will help to onboard new users.
      ⏳ Project Duration: 175 hours (Medium)

      ~~~~~~~~~~
      💡 Code Review Assistant for Open Source projects
      👥 Mentor(s): Felipe Scuciatto, Samad Kahn
      📢 Communication Channel: idea-Code-Review-Agent-for-Open-Source-projects
      💬 Description:
      Finding reviewers for contributors' PRs on open source projects can often be difficult. Slow response can possibly result in the loss of a communtiy contributor.
      This assistant will monitor new pull requests (either via incoming github integration messages in a channel or directly via github events) and identify the most suitable maintainer to review the PR based on a statistical scoring system. It will follow up with a friendly yet frequent reminder (“nagging”) mechanism to ensure timely reviews.
      Additionally, the bot will leverage code-specialized LLMs to perform an initial review, automatically filtering out minor improvements before they reach human reviewers.
      This will streamline the review process, reduce unnecessary delays, and ensure that only meaningful changes require manual attention.
      💪 Desired Skills:
      Rocket.Chat Apps Engine and TypeScript
      Knowledge of general statistics
      Prompt engineering with code-specialized LLMs
      Ideally GitHub API
      🎯 Goals/Deliverables:
      A Rocket.Chat App that will interact with open source maintainers and monitors open pull requests, assigns the most suitable reviewer based on past reviews, persistently reminds them until the review is completed, and leverages AI for initial code assessments.
      ⏳ Project Duration: 175 hours (Medium)

      ~~~~~~~~~~
      💡 Embedded Chat 2025
      👥 Mentor(s): Zishan Ahmad
      📢 Communication Channel: idea-Embedded-Chat-2025
      💬 Description:
      Improvement to the EmbeddedChat project this year includes:
      Upgrading the current API and authentication packages to the latest Rocket.Chat SDKs, such as ddp-client. Other components will be aligned with updated abstractions and SDKs. For reference, see this link. These packages will be managed internally by Rocket.Chat moving forward.
      Ensuring compatibility with the latest Rocket.Chat API versions to keep the integration updated and error-free.
      Upgrading to the latest stable versions of React, Node.js, and other libraries for long-term maintainability.
      Making the EmbeddedChat fully mobile-responsive for a seamless experience across all devices.
      Improving the UI and adding more customization options to enhance the user experience.
      Aligning the design and features of the EmbeddedChat Web Client with the React Native Client, which is already built but needs updates for complete consistency.
      Welcoming any other creative ideas that improve the project.
      💪 Desired Skills:
      Strong understanding of Rocket.Chat APIs and SDKs
      Love for coding and UI design
      React.Js
      🎯 Goals/Deliverables:
      Integration of the latest Rocket.Chat SDK packages
      Fully mobile-responsive EmbeddedChat
      Improved UI with more customization options
      Native app development
      Increased stability and maintainability
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Intermediate

      ~~~~~~~~~~
      💡 Smart Market Bot for Rocket.Chat
      👥 Mentor(s): Zishan Ahmad, TBD
      📢 Communication Channel: idea-Smart-Market-Bot-for-Rocket-Chat
      💬 Description:
      An interactive Rocket.Chat app that fetches real-time prices for cryptocurrencies, stocks, and forex using open-source APIs. It provides insights, summaries, and predictions while ensuring fail-proof accuracy—if the bot is unsure, it withholds speculative responses.
      Key Features:
      Live Price Updates – Fetch real-time data for crypto, stocks, and forex using free and open APIs.
      Market Alerts – Get notifications on significant price movements, trends, or unusual activities.
      Smart Insights & Summaries – Summarize asset trends, news, and market behavior.
      Predictive Analysis – Provide data-backed forecasts and trends (without unreliable speculations).
      Fail-Safe AI Responses – Ensures that if the LLM is uncertain, it explicitly avoids misinformation.
      Custom Asset Watchlists – Users can create personalized lists to track selected assets.
      Interactive Commands – Users can request price comparisons, asset history, and more via Rocket.Chat commands.
      💪 Desired Skills:
      JavaScript / TypeScript
      Rocket.Chat App Development
      API Integration (REST/WebSockets)
      🎯 Goals/Deliverables:
      Functional Rocket.Chat app with real-time asset tracking.
      Market alert system for price fluctuations and significant events.
      Intelligent summarization and prediction module.
      Fail-proof mechanism to avoid incorrect or misleading AI responses.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~

      💡 Receipts Processor and Reporting App powered by Multi-modal LLMs
      👥 Mentor(s): Maria Khelli, Sing Li
      📢 Communication Channel: idea-Receipts-Processor-and-Reporting-App-powered-by-Multi-modal-LLMs
      💬 Description:
      While attending a busy conferences or event, the need to keep track of receipts and then having to adding them up manually to fill in expense reports is a very common and tedious problem. This project is a Rocket.Chat app that completely automate the process.
      Details:
      The user will be able to take pictures of restaurant receipts on their phone and upload it into a specific channel (representing a single event, duration of time, or trip, and so on...).
      Upon request, the app should read and sum all the receipts producing a detailed report. Ideally, the input format and image size should be flexible and the report format should be customizable via templates.
      The app should never produce erraneous result under any circumstances, it should be able to recognize its limitation and decline to complete the task instead of giving potentially erraneous output.
      💪 Desired Skills:
      Rocket.Chat Apps Engine (TypeScript)
      Intermediate prompt engineering Skills
      Experience with image reasoning capabilities of available open source multi-modal LLMs
      🎯 Goals/Deliverables:
      A working Rocket.Chat app that will scan and sum all the restaurant receipts uploaded to a specific channel.
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~
      💡 Perfect AI Docs Assistant App
      👥 Mentor(s): Dnouv, Jeffery Yu
      📢 Communication Channel: idea-Perfect-AI-Docs-Assistant-App
      💬 Description:
      This project aims to build a Rocket.Chat App that provides a natural language interface for querying Rocket.Chat Docs (docs.rocket.chat). Instead of manually searching for answers, users can simply ask the app, and it will return a perfect, relevant response extracted and summarized from the documentation.
      For the very small dataset that we are working with, we aim to tune and optimize the well-known RAG agentic workflow for our specific purpose; ideally producing an optimized and perfect Ask the Docs Assistant for this subset of the Rocket.Chat documentation.
      Consider possibly:
      Retrieval-Augmented Generation (RAG) agentic workflow the AI/ML design pattern we're all familiar with
      Local embedding model needs to run in memory/CPU for maximum efficiency
      In-memory vector store run in the client with no persistence, subject of further optimization (chunking, match-selection, metadata) to tune for perfect results
      Context-aware follow-up responses not required but nice to have
      💪 Desired Skills:
      Rocket.Chat Apps Engine (TypeScript)
      Modern agentic workflows (including classic-RAG)
      Web Storage & IndexedDB (for caching, if needed)
      Intermediate prompt engineering
      Keen interest in contemporary applications of LLMs
      🎯 Goals/Deliverables:
      generation/creation of a perfect validation dataset, consisting of (1500, 5000, 10000) queriies and corresponding answer, that will be used in the benchmark/validation of the final assistant
      a fine-tuned compact LLM to be used in the last stage of the RAG agentic workflow (fine-tuned minimally on the dataset above)
      the perfect "ask the docs assistant" for our small dataset, running mostly on the client without heavy compute overhead, ideally scoring 90% plus on the benchmark
      (we like to thank our early community for helping us to fine-tune this set of deliverables)
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Intermediate/Advanced

      ~~~~~~~~~~
      💡Google Summer of Code Community Hub 2025
      👥 Mentor(s): Anjaneya Gupta
      📢 Communication Channel: idea-Google-Summer-of-Code-Community-Hub-2025
      💬 Description:
      Continuing our work on a "full stack component framework" in which a scalable website can be created by non-technical users using drag-and-drop components that not only include UI and client-side logic, but also pre-scaled server-side behaviors (or serverless impl).
      The ultimate use-case we have been working on is the community hub for Rocket.Chat Google Summer of Code. It will link all the despearate servers into one easy to customize and maintain uniform scalable web app (comprise of a set of full-stack components).
      This year's work will include:
      rebasing of the existing platform and components on Svelte 5
      moving the WYSIWYG "Syntax Sweetening" work done last year to this new platform
      implementation of auth via OIDC
      migrate over the event poster component (used for our demo day)
      migrate over the video-meet-your-mentor component
      implement the gsoc leaderboard component
      implement embeddedchat component
      💪 Desired Skills:
      Advanced Typescript
      Svelte 5
      AST concepts
      🎯 Goals/Deliverables:
      A functional community hub website that we will use for 2026; showcasing the platform and new components.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~
      💡AI Chat Workflows Automation App with multi-step reasoning
      👥 Mentor(s): Hardik Bhatia
      📢 Communication Channel: idea-AI-Chat-Workflows-Automation-App-with-multi-step-reasoning
      💬 Description:
      Build a Rocket.Chat app that will monitor messages in specified channels (possibly sent by specified individuals, possibly within certain specified time period, and so on... ) and then (as a second step) perform additional messaging operations based on those messages. Command should be issued in simple English. Bonus point for more than 2 steps in the reasoning.
      Some examples:
      "whenever @sing.li posts any welcome messages in #gsoc2025, immediately DM him with a thank-you note"
      
      "if any picture is uploaded to the #pets channel, send a message that says meow! if the pet is a cat, and a woof! otherwise"
      
      "whenever a message is posted that contains a four letter word beginning with letter F, delete that message immediately"
      
      "if my wife messaged with 'arrived' before I do, DM her sorry I will be late after 1 minute" 
      Recommended approach:
      leverage the latest open source specialized multi-step reasoning LLMs such as the DeepSeek distilled models
      make intelligent use of tools/function-calling and structured inference
      be sure to built in safety to offset erraneous output and/or hallucinations
      💪 Desired Skills:
      Rocket.Chat Apps Engine (TypeScript)
      Rocket.Chat messaging APIs
      Advanced prompt engineering Skills
      Experience with image reasoning capabilities of available open source multi-modal LLMs
      Experience working with multi-step reasoning LLMs
      Experience with tools/function-calling capabilities of modern LLMs
      Expereince with code generation and code completion LLMs
      Understanding of how to implement "safety first" when creating AI apps that may permenantly change the state of a production system
      🎯 Goals/Deliverables:
      Platform for generating functional automated chat workflows using LLMs.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Intermediate/Advanced
      📅 Message Timestamp Date Picker Components
      👥 Mentor(s): Martin Schoeler
      📢 Communication Channel: idea-Message-Timestamp-Date-Picker-Components
      💬 Description: Currently Rocket.Chat has a feature that allows users to send timestamps on messages, but not in an intuitive way. To send a timestamp you need to manually write it down with the correct date code. For example <t:1732557600:t>. This feature was added for Rocket.Chat Apps engine, but users can benefit from this too. The objective of this project is to create a new MessageToolBar item that displays a calendar and let the users select the date and time they would like to share, both in the desktop app and mobile apps.
      Some examples of the usage of the timestamp feature (you can test them today on the open.rocket.chat server!)
      Pattern: <t:{timestamp}:?{format}>
      {timestamp} is a Unix timestamp
      {format} is an optional parameter that can be used to customize the date and time format.
      Formats
      Format Description Example
      t Short time 12:00 AM
      T Long time 12:00:00 AM
      d Short date 12/31/2020
      D Long date Thursday, December 31, 2020
      f Full date and time Thursday, December 31, 2020 12:00 AM
      F Full date and time (long) Thursday, December 31, 2020 12:00:00 AM
      R Relative time 1 year ago
      The creation of tests for the new component is also expected, both end to end and unit if applicable.
      💪 Desired Skills: React, Typescript, React Native
      🎯 Goals/Deliverables: A new component on the MessageToolBar that allows users to add timestamps to their messages, both in desktop and mobile.
      ⏳ Project Duration: 90 hours. (Small)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~
      💡 Messages scheduling
      👥 Mentor(s): Ricardo Swarovsky
      📢 Communication Channel: idea-Message-Scheduling
      💬 Description:
      Add a native Rocket.Chat feature that lets users schedule messages to be sent later, directly integrated with the current send button. Since we serve users across multiple time zones, this feature will make it easier to schedule messages for the right time, no matter where they are.
      💪 Desired Skills:
      Awareness of Rocket.Chat server and client codebase (NodeJS and React)
      🎯 Goals/Deliverables:
      A Rocket.Chat feature that will allow users to schedule messages to be sent in the future
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Advanced

      ~~~~~~~~~~
      💡Client-side AI Support
      👥 Mentor(s): Sing Li, Ashutosh Singh Chauhan
      📢 Communication Channel: idea-Client-side-AI-Support
      💬 Description:
      This project adds applicaton API access to LLMs running in-browser, on-device and distributes the AI compute load from the server - allowing AI applications to scale massively.
      Not all client devices are capable of handling LLM loads, the deployment flow must detect and behave accordingly.
      Details:
      Modify current server deployment flows to install client-side LLMs as an option.
      Extend Apps Engine to support client-side logic; (optional) loading of the LLMs; and API access to the in-browser/on-device LLMs.
      Essential background:
      recent high performance lightweight models became available (Llama 3.2, Intern LM 2, Phi 3 mini, Qwen 2.5, Smol LM, Gemma 2b, DeepSeek distlled, and so on) requiring ONLY about 2GB additional memory and reasonable compute load
      breakthrough webgpu and webllm technology matured; and in-browser inference and LLM API access (WASM'ed Python code on top of HTML5/WebGPU standard) is a stable working reality
      big-tech vendors (phone and OS vendors such as Apple, Samsung, Microsoft, and so on ... ) are rapidly bringing client-side CLOSED SOURCE inference capability to their own applications with no roadmap in 2025 for general access
      💪 Desired Skills:
      Rocket.Chat Deployment Flows (DevOps)
      Advanced Typescript
      Awareness of WASM and webllm
      Python magician
      Good system design mindset
      🎯 Goals/Deliverables:
      Empower the development of scalable open source AI applications running in-browser for all Rocket.Chat users
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Advanced

      ~~~~~~~~~~
      💡End to End Encrypted Message Handling for Ruqola
      👥 Mentor(s): Montel Laurant, Aaron Ogle
      📢 Communication Channel: idea-E2E-messages-handling-for-Ruqola
      💬 Description:
      Add end to end encrypted message feature to the Ruqola client from KDE. Ruqola is the de-facto standard Rocket.Chat client running on KDE. This project will be co-mentored by an expert mentor from the KDE progject.
      Details:
      some UI elements to handle E2E encrypted messages is already in place
      careful consideration for key management is essential to a successful implementation
      how does the user get the key? what happens when he/she loses the key?
      what UI is needed to support re-generation of key?
      how does one display a channel with messages that may be encrypted by different keys?
      see End to End Encryption Specification
      💪 Desired Skills:
      Rocket.Chat API programming (REST and DDP)
      Solid experience with C++ programming
      Experience with large and complex C++ projects
      Working experience with KDE on Linux (such as kubuntu)
      Ideally already user of Ruqola
      🎯 Goals/Deliverables:
      Add support for E2E Encrypted messages in Ruqola.
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Advanced

      ~~~~~~~~~~
      💡 AI Google Forms / Typeform Survey Integration App
      👥 Mentor(s): Abhinav kumar
      📢 Communication Channel: idea-AI-Google-Forms-Typeform-Survey-Integration-App
      💬 Description:
      This app integrates any one of the popular survey tools (Google Forms, Typeform etc.) into Rocket.Chat to allow teams to create, distribute, and analyze quick polls or feedback forms without leaving the chat. Users can launch surveys, receive immediate notifications when responses are submitted, and have summary reports automatically posted to designated channels.
      Using natural language to create forms would be a huge plus for the project. Example - "Create a form to accept registration for the Annual Tech Conference. It should collect full name, email address, company, and dietary restrictions. Validate the email field, send me a notification on each new registration, and post a summary report in the #conference-registrations channel."
      Key Features:
      Slash Commands: Launch new surveys or share form links directly from Rocket.Chat.
      Inline Notifications: Receive real-time alerts when survey responses are submitted.
      Automated Reporting: Generate and post periodic summary reports in designated channels.
      Use Case:
      Enables teams to capture immediate feedback and conduct internal polls seamlessly within Rocket.Chat, enhancing decision-making and team engagement.
      💪 Desired Skills:
      Proficiency with Rocket.Chat Apps Engine (TypeScript)
      Experience with REST APIs and third‑party service integrations
      Familiarity with survey platforms (Google Forms, Typeform) and their APIs
      🎯 Goals/Deliverables:
      Develop a Rocket.Chat App that connects to Google Forms/Typeform.
      Implement slash commands for survey creation and sharing.
      Integrate real-time notifications for survey responses.
      Automate the generation and posting of summary reports.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~
      💡Trip Helper App
      👥 Mentor(s): Yuriko Kikuchi, Sing Li
      📢 Communication Channel: idea-Trip-Helper-App
      💬 Description:
      This LLM-powered app will suggest interesting events and happenings for users during their trip.
      Details:
      While on trip in a foreign place, a user can take a photo of his surroundings and upload it to a channel
      The app will first process the image by passing it to an image reasoning multi-modal LLM to ascertain the location or point of interest or event venue (perhaps reinforced by GPS location information).
      Then in a second step an(other) LLM's tools/function-calling capability is used to fetch up-to-date events and happening information over the Internet, catering for the user's current interest.
      Finally, a friendly summary report is produced by an(other) LLM as the last step of a RAG pipeline.
      This app should never produce erraneous output. It should know its own limitaion and decline to report if in doubt.
      💪 Desired Skills:
      Rocket.Chat Apps Engine (TypeScript)
      Familiarity with the "RAG" agentic workflow
      Intermediate prompt engineering Skills
      Experience with image reasoning capabilities of modern open source multi-modal LLMs
      Experience with tools/function-calling capabilities of modern LLMs
      🎯 Goals/Deliverables:
      A working Rocket.Chat App that assists users with latest happenings around them wherever they may be while on any trip.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Intermediate/Advanced

      ~~~~~~~~~~
      💡 AI Transcription and Translation for Voice Messages App
      👥 Mentor(s): Dhurv Jain, Abhinav Kumar
      📢 Communication Channel: idea-AI-Transcription-and-Translation-for-Voice-Messages-App
      💬 Description:
      Rocket.Chat already supports sending voice messages. This project enhances that feature by providing on-demand or real-time transcription and translation of voice messages. Users can choose to transcribe voice messages to text and optionally translate into their preferred language, thereby boosting accessibility and making communication more inclusive.
      Possible Milestones:
      UI/UX Enhancements:
      Integrate options into the existing voice message interface for triggering transcription and translation.
      Backend Processing:
      Integrate with a speech-to-text service (e.g., Google Cloud Speech-to-Text or open‑source alternatives like Vosk) to transcribe voice messages.
      Translation Integration:
      Connect with a translation API (e.g., Google Translate or LibreTranslate) to convert transcriptions into the target language.
      Performance & Accuracy Tuning:
      Optimize for low latency and high transcription accuracy, ensuring the system gracefully handles slow or unavailable external APIs.
      💪 Desired Skills:
      Experience with Rocket.Chat Apps Engine (TypeScript)
      Familiarity with speech-to-text and translation APIs
      Skills in mobile and web UI/UX enhancement
      Ability to optimize performance and implement robust error handling
      🎯 Goals/Deliverables:
      A Rocket.Chat App that enhances the existing voice message feature with transcription and translation capabilities.
      Seamless integration with external speech-to-text and translation services.
      An intuitive interface that allows users to trigger transcription and translation on demand or in real time.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Intermediate/Advanced

      ~~~~~~~~~~
      💡Improve Private Team and Private Channel Administration
      👥 Mentor(s): John Crisp
      📢 Communication Channel: idea-Private-Teams-and-Private-Channels-Adminitration-Improvements
      💬 Description:
      While it is possible to create private team and private channels in Rocket.Chat, the ability for the server's administrator to perform administrative tasks on them are currently very limited (unless the server admin is part of the private channel or private team). This was done by the original "team designer" to afford some local privacy for these these users.
      This project aims to improve this situation by adding the ability for the server administrator to (optionally) override (via configuration on admin panel) to directly access and administer private team and private channels.
      This should include minimally the following abilities:
      add/remove users in private channels
      assign and change the roles of private channel users
      add/remove/rename private team channels
      add/remove/modify the members of private teams
      assign and change the roles of private team users
      access private channels and private teams in the Directory
      💪 Desired Skills:
      In depth understanding of Rocket.Chat core
      Advanced Typescript
      Familiarity with Rocket.Chat UI/Ux
      Interest in administration and management of sub-communities on large chat servers (our Team concept)
      🎯 Goals/Deliverables:
      Ability for server administrator to better administer private teams and private channels.
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Intermediate

      ~~~~~~~~~~
      💡Channel Header Customization
      👥 Mentor(s): TBD
      💬 Description:
      Currently, all elements on the channel header are fixed and mandatory.
      This project aims to make the channel header customizable, allowing the owner/administrator to hide some components (where it makes sense).
      One should be able to hide any combination of the buttons in the header.
      Implementation must take UI/Ux design into consideration to ensure the elements showing are still consistent with the overall Rocket.Chat design aesthetics.
      💪 Desired Skills:
      Understanding of Rocket.Chat core
      UI/Ux development
      Advanced Typescript
      Like coding, love design
      🎯 Goals/Deliverables:
      Fully customizable channel header for Rocket.Chat.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy

      ~~~~~~~~~~
      💡Fine-grained upload/download permissions
      👥 Mentor(s): TBD
      💬 Description:
      Add and implement permissions to make possible the fine-grained control of who can upload or download files/attachments. The implementation must enable the per user control of upload, download individually (or in combination) when users are on mobile, desktop, or web app. (and any combinations of)
      💪 Desired Skills:
      Understanding of Rocket.Chat core
      Understanding of Rocket.Chat's role and permission system
      Advanced Typescript
      Interest in cyber security
      🎯 Goals/Deliverables:
      Ability for administrators to control the upload/download capability per user, in combination with access client type.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Intermediate
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/rocket.chat/
    idea_list_url: https://github.com/RocketChat/google-summer-of-code/blob/main/google-summer-of-code-2025.md#-project-ideas

  - organization_id: 184
    organization_name: stdlib
    no_of_ideas: 43
    ideas_content: |
      
      Implement a broader range of statistical distributions
      Linked issue: #2
      Idea
      The goal of this idea is to implement all distributions found in SciPy stats. Distribution support will entail implementing APIs for computing PDFs, CDFs, quantiles, and other distribution properties. Additionally, stdlib should support APIs for drawing random variates from any implemented distributions.
      Expected Outcomes
      stdlib users will be able to construct, and compute various properties of, every statistical distribution present in SciPy in JavaScript.
      Involved Software
      No runtime dependencies should be necessary. SciPy will be necessary in order to provide reference test results.
      Prerequisite Knowledge
      JavaScript, Node.js. Familiarity with C/C++/Fortran would help.
      Difficulty
      Intermediate. Difficulties may arise for distributions whose properties and moments have complicated formulations. Developing JavaScript implementations will likely require consulting C/C++ and possibly Fortran code.
      Project Length
      350 hours.

      ~~~~~~~~~~
      Provide APIs for computing Fast Fourier Transforms
      Linked issue: #3
      Idea
      The goal of this idea is to expose a set of Fast Fourier Transform (FFT) interfaces similar to those available in NumPy and as documented in the Data APIs Array API specification. Similar to stdlib's BLAS interfaces, we may want to allow switching out the FFT backend.
      One potential reference implementation which could form the basis of this idea is pocketfft, as done in NumPy:
      https://github.com/mreineck/pocketfft
      https://gitlab.mpcdf.mpg.de/mtr/pocketfft
      Expected Outcomes
      stdlib users would be able to evaluate FFT operations on stdlib ndarrays. Ideally, we'd also provide a set of C APIs.
      Involved Software
      Will need to consult reference implementations in C/Fortran.
      Prerequisite Knowledge
      JavaScript, Node.js, C/C++/Fortran
      Difficulty
      Hard. This may be a straightforward port, or it may not be. More R&D is needed.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @rreusser @Pranavchiku @czgdp1807

      ~~~~~~~~~~
      Developer dashboard for tracking ecosystem build failures
      Linked issue: #4
      Idea
      The stdlib project encompasses over 3500 repositories which are orchestrated via a centralized repository. While orchestration largely works as intended, build failures do happen, and quickly detecting and resolving build failures in standalone repositories is critical to prevent downstream breakages and ensure ecosystem integrity.
      The goal of this idea is to build a developer dashboard to display in real-time standalone repository build failures. We currently have the backend database which collects build results in real-time; however, we have yet to build a frontend for viewing and analyzing such data.
      The expected roadmap is as follows:
      Build a Node.js backend for querying a PostgreSQL database.
      Build a frontend dashboard which interfaces with the backend. As this will be a developer facing application, the choice of technologies is greenfield. Potential options may include ESBuild, tailwind, etc.
      Add support for filtering the dashboard based on build status and other features.
      Allow for quick navigation to repository resources and build artifacts.
      Extend the dashboard to support historical overviews and other drill down metrics.
      Expected Outcomes
      stdlib developers will be able to navigate to a webpage and see the build status for all repositories at once.
      Involved Software
      This will involve building a frontend application and interfacing with a backend for querying a PostgreSQL database. We may want to try more "cutting edge" technology here, such as ESBuild, tailwind, etc.
      Prerequisite Knowledge
      JavaScript, Node.js, CSS, HTML, JSX.
      Difficulty
      Intermediate. Requires a fair amount of frontend engineering knowledge and modern frontend application development.
      Project Length
      175/350 hours. A skilled contributor may be able to execute on this faster. If so, scope could be expanded to include analytics and historical overviews.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Expand support for additional pseudorandom number generators
      Linked issue: #5
      Idea
      The goal of this idea is to implement a variety of PRNGs for use within stdlib to generate pseudorandom numbers. The project currently uses Mersenne Twister as its default PRNG; however, this PRNG, while common, is not ideal given its comparatively large internal state. Would be great to have a collection of PRNGs, such as PCG, Philox, Xorshift, and more.
      Expected Outcomes
      stdlib users will have a wide selection of PRNGs from which to choose from based on their individual needs and considerations. Having a large selection of PRNGs will useful when replicating the results of numerical simulations which may use a PRNG which is not one of the currently supported stdlib PRNGs. Additionally, a desired outcome would be if we could replace MT19937 with a new default PRNG.
      Involved Software
      No other software should be necessary. We may be a bit constrained based on 32-bit limitations in JS. This would not, however, stop us from implementing in C for use in generating arrays of random numbers.
      Prerequisite Knowledge
      JavaScript, Node.js. Familiarity with C/C++/Fortran would help.
      Difficulty
      Intermediate/Hard. Depends. Some PRNGs may be straightforward to implement. Others, not so much.
      Project Length
      175/350 hours. This idea can be adjusted according to needs and availability.
      Potential Mentors
      @kgryte @Planeshifter @Pranavchiku

      ~~~~~~~~~~
      Add support for visualizing benchmark results
      Linked issue: #6
      Idea
      While we currently support running benchmarks, we have yet to provide a means for easily visualizing and comparing benchmark results. Previously, when wanting to visualize and compare benchmark results, one has needed to manually parse TAP results and then plug into some other software (e.g., vega or Plotly).
      The idea for this project would be to 1) implement a TAP parser with support for the latest TAP specification and 2) provide a plot frontend for consuming parsed TAP results. The plot frontend could be as simple as a Unicode bar chart plotter, which would be in line with our existing Unicode plotting facilities.
      Expected Outcomes
      Developers will be able to run benchmarks and visually compare benchmark results based on the namespace and parameterization. Ideally, the plot would include small multiple/facet visualizations.
      Involved Software
      No other software or dependencies should be necessary. Will need to consult a reference TAP parser implementation (e.g., node-tap).
      Prerequisite Knowledge
      JavaScript and Node.js.
      Difficulty
      Intermediate.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Develop a project test runner
      Linked issue: #7
      Idea
      Currently, stdlib uses tape. The goal of this idea is to migrate away from tape and develop a test runner in-house, similar to @stdlib/bench/harness. This has long been on our TODO list and would allow us to have a simple test runner which is oriented toward stdlib conventions (e.g., we don't use most of the assertion methods in tape).
      Bonus points if we can migrate away from istanbul to nyc or c8; however, this may be tricky if we want to support older Node.js versions.
      Expected Outcomes
      All unit tests have migrated to the in-house runner.
      Involved Software
      No additional runtime deps. Will need to consult tape as a reference implementation, along with our existing @stdlib/bench/harness implementation.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate.
      Project Length
      175/350 hours. The scope of this idea can be adjusted depending on availability.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Reimagine the stdlib plot API and implementation
      Linked issue: #8
      Idea
      Currently, stdlib has a bespoke plot API which is useful for fast static rendering. However, our implementation is quite limited in the types of plots it can produce. The goal of this idea is to refactor our plot API to build atop of vega (or its specifications). For this, we'd need to migrate to an async plot generation API, which is probably necessary regardless if we want to support WebGL or some other async rendering engine.
      Ideally, we would retain the same plot API and internally generate a vega specification.
      Expected Outcomes
      We can generate simple plots using the new plot implementation.
      Involved Software
      This will involve using vega (or something similar depending on whether vega is sufficiently maintained). We will want to transpile to ES5 and vendor in order to ensure that we can support our supported Node.js versions.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate/Hard.
      Project Length
      350 hours. This project has the potential to spiral out of control, as there are many unknowns we'd need to answer. Mentor would likely need to be actively involved in order to perform R&D and properly scope.
      Potential Mentors
      @kgryte @Planeshifter @rreusser

      ~~~~~~~~~~
      Achieve feature parity with async.js
      Linked issue: #9
      Idea
      Currently, stdlib has a limited set of dedicated "async" APIs for performing various utility operations. The goal of this idea is to achieve feature parity with async.js, a popular library providing callback-based async APIs.
      Motivation for this idea stems from certain advantages afforded by callback-based asynchronous programming. Notable among them is superior performance and the ability to more readily return and inspect status objects.
      Expected Outcomes
      stdlib will have more or less 1:1 feature parity with async.js APIs.
      Involved Software
      async.js will serve as a reference implementation for API design. Will want to modify to match stdlib conventions.
      Prerequisite Knowledge
      JavaScript.
      Difficulty
      Beginner. Would benefit from someone with JavaScript experience.
      Project Length
      175/350 hours. Can be scoped accordingly.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Achieve feature parity with builtin Node.js fs module
      Linked issue: #10
      Idea
      Achieve feature parity with Node.js fs package. We currently only support a limited selection of fs methods. Would be useful to support more.
      Part of this work involves providing an abstraction layer of Node.js built-ins in order to support newer functionality (e.g., options and/or behavior) not present in older Node.js versions. This is similar in concept to the userland readable-stream package.
      Expected Outcomes
      stdlib will have complete feature parity with Node.js built-ins.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate. Could require some creative solutions to ensure that abstractions work for older Node.js versions.
      Project Length
      175/350 hours. Can be scoped accordingly.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Add support for the multivariate normal distribution
      Linked issue: #11
      Idea
      The goal of this idea is to implement the multivariate normal distribution. This distribution is fundamental in a wide variety of statistical applications and will help unblock stdlib in offering additional statistics APIs.
      As a starting point, SciPy's multivariate normal distribution API and implementation could provide a suitable point of reference:
      https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html
      Expected Outcomes
      Users will be able to evaluate the PDF, CDF, logPDF, and logCDF and be able to draw random variates from a specified distribution.
      Involved Software
      No other software is necessary. Will require reading reference implementations written in Python, R, and Julia.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate.
      Project Length
      175/350 hours. Can be scoped accordingly. A skilled contributor should be able to complete in 175 hours with the potential of using their implementation to implement higher order statistics APIs.
      Potential Mentors
      @kgryte @Planeshifter @Pranavchiku

      ~~~~~~~~~~
      Develop a Google Sheets extension which exposes stdlib functionality
      Linked issue: #13
      Idea
      The goal of this idea is to allow users to call stdlib APIs from within Google Sheets. This will allow users to perform linear algebra and various machine learning operations directly on spreadsheet data and all within the browser.
      In order to execute on this idea, we'll want to support
      two-dimensional array broadcasting semantics
      performant element-wise iteration APIs
      input argument validation tailored to the Sheets context
      Fused operations to avoid unnecessary network calls
      documentation and tutorials demonstrating API usage
      good generation and automation for creating extension builds
      testing and performance measurement to guard against regressions
      Expected Outcomes
      Google Sheets users will be able to install an extension which exposes stdlib functionality, run statistical tests, evaluate mathematical functions, and perform linear algebra operations using stdlib.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Beginner/Intermediate.
      Project Length
      175/350 hours. Can be scoped accordingly. A skilled contributor can work on a strategy for performant fused operations.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Stdlib API dependency explorer
      Linked issue: #14
      Idea
      stdlib is a large (and growing!) project, which can make project navigation challenging. The goal of this idea is to provide a visual representation of an API's dependency graph directly in the stdlib API documentation. Initial thinking is that would be an interactive network diagram in which nodes present package dependencies and allow for navigation; however, other visual representations may be possible.
      By providing such a means for navigating the project, users could more readily deepen their understanding of the stdlib code base, identify potential issues, and better understand how underlying APIs are used.
      Expected Outcomes
      A user will be able to navigate to a package's documentation page, click to display a network graph, and then click on nodes within that graph to explore the documentation of package dependencies.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js, HTML/CSS, JSX.
      Difficulty
      Beginner/Intermediate.
      Project Length
      175 hours.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Add support for bootstrap and jackknife resampling
      Linked issue: #15
      Idea
      Manually constructing confidence intervals and other statistical properties can be useful when no analytic solution exists. The goal of this idea to implement APIs for bootstrap and jackknife resampling.
      Expected Outcomes
      Users will be to resample provided datasets.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Beginner/Intermediate.
      Project Length
      175/350 hours. Can be scoped accordingly. Scope can be expanded to implement different bootstrap algorithms.
      ~~~~~~~~~~
      Develop a Jupyter backend for interfacing with the stdlib REPL
      Linked issue: #16
      Idea
      Jupyter is a dominate force in scientific computing. While some effort has been done to expose JavaScript kernels to Jupyter/JupyterLab, most of these kernels are under-developed or lack numerical functionality.
      The goal of this idea would be to develop a Jupyter backend based on stdlib.
      Expected Outcomes
      A JupyterLab user will be able to connect to a stdlib kernel and invoke stdlib operations.
      Involved Software
      This goal will require interfacing with the Jupyter technology stack, including ZeroMQ and implementing messaging protocols.
      Prerequisite Knowledge
      JavaScript, Node.js. Experience with Python would be very helpful.
      Difficulty
      Hard.
      Project Length
      350 hours. This idea has many unknowns and will be hard to scope.
      Potential Mentors
      @kgryte @Planeshifter

      ~~~~~~~~~~
      Implement additional statistical tests
      Linked issue: #17
      Idea
      Implement various statistical tests which are not currently implemented in stdlib, but are implemented in other envs such as R, Python (SciPy, statsmodels), Julia, and MATLAB.
      Expected Outcomes
      stdlib will have a broader array of statistical tests which can operate on ndarrays.
      Involved Software
      No other software should be necessary. However, we will need to do a needs analysis to determine which prerequisite packages/functionality is necessary in order to allow these tests to be implemented (e.g., BLAS, ndarray slicing, etc).
      Prerequisite Knowledge
      JavaScript, Node.js. Familiarity with R, Python, C/C++ would be very useful, as will need to consult reference implementations.
      Difficulty
      Hard. Depends on the reference implementation requirements and algorithmic difficulty.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @Pranavchiku

      ~~~~~~~~~~
      Generate web documentation from JSDoc comments
      Linked issue: #19
      Idea
      stdlib relies heavily on JSDoc comments to document its source code. Currently, the project has only rudimentary support for generating HTML docs from those comments. The goal of this idea would be to
      Write an in-house JSDoc parser.
      Generate HTML documentation from the parsed comments which is capable of supporting project conventions and its embrace of radical modularity.
      JSDoc comments are oriented toward JavaScript source files; however, stdlib also uses similar documentation practices for documenting C source files and make files. A possible extension to the in-house JSDoc parser would be to support these other source file types. As those file types may require separate AST parsers, supporting other file types is likely to require writing separate comment parsers for each source type.
      Expected Outcomes
      In addition to the current API documentation, a user will be able to navigate to a package's JSDoc documentation to gain more insight into supported input and output dtypes and implemented algorithms. This would be especially useful for rendering the extended JSDoc comment of elementary mathematical functions.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js, HTML/CSS.
      Difficulty
      Intermediate.
      Project Length
      350 hours. The length can likely be scaled down; however, there are several unknowns, and it may not be straightforward to develop an in-house parser which caters to the unique structure and setup of stdlib. For advanced contributors, possibility to explore support for source file types other than JavaScript (e.g., C and make).
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Refactor generated TypeScript interface documentation
      Linked issue: #20
      Idea
      Currently, stdlib publishes TypeScript interface documentation in its web-based API documentation. The generated documentation monkey-patches tsdoc to handle generating documentation across the entire mono-repo. The goal of this project is to refactor/rethink this approach and provide a solution capable of addressing the unique constraints of the stdlib project.
      Expected Outcomes
      At a base level, it would be great if we had a working documentation render which did not require monkey-patching. A more difficult, but potentially more desirable, outcome would be if TypeScript documentation was not rendered as a separate website, but rather was integrated within the docs as simply another page/fragment.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js, HTML/CSS, TypeScript, JSX/React.
      Difficulty
      Intermediate.
      Project Length
      175/350 hours. Length will depend on the nature of the proposed solution (e.g., needing to write a custom TypeScript parser vs modifying the existing tsdoc library).
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Use ES6 modules for running unit tests and benchmarks in web browsers
      Linked issue: #21
      Idea
      Currently, when generating stdlib API documentation, we generate UMD bundles for unit tests and benchmarks. When a user navigates to our package documentation, they can load unit tests and benchmarks and have those run without needing to setup a local environment. The pain point here is that creating separate bundles for each package is time consuming and adds significant heft to the www repo.
      The goal of this idea is to refactor the way we support unit tests and benchmarks to use ES6 modules and potentially skip bundling altogether. This has the downside of not supporting older browsers which don't support the <module> tag, but is probably fine considering that running package unit tests and benchmarks is likely a forward looking concern.
      Expected Outcomes
      Users will be able to run unit tests and benchmarks directly in their web browsers by navigating to project API documentation and what is loaded are ES6 modules, not UMD bundles.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js, HTML/CSS, JSX/React.
      Difficulty
      Intermediate.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @steff456
      
      ~~~~~~~~~~
      Migrate web API documentation to use matomo and instrument for better understanding user navigation behavior
      Linked issue: #22
      Idea
      Currently, the stdlib web-based API docs use GA for analytics and have only minimal integration. E.g., the API docs application is a SPA which uses React and the app does not record changes in page views; we only record first hits.
      The goal of this idea is to migrate to using matomo and take advantage of its privacy features. The work will involve instrumenting the API documentation application and integrating with matomo. A potential stretch goal would be to setup dashboards for reporting so that we can better understand user behavior and continue to improve project documentation.
      Expected Outcomes
      All user interaction data is logged to matomo and stored in a hosted database.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js, HTML/CSS, JSX/React.
      Difficulty
      Intermediate.
      Project Length
      350 hours. Can be adjusted depending on skill and ability.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~

      Improve the REPL presentation framework
      Linked issue: #23
      Idea
      stdlib currently offers a REPL presentation framework for authoring presentations for use directly in the REPL. This is particularly useful for creating interactive tutorials illustrating how to use stdlib functionality for data analysis and visualization from the terminal. Some functionality is missing which would be quite useful. E.g.,
      ASCII plotting
      ASCII animations
      syntax highlighting
      pretty printing tables
      speaker notes
      multiplexing
      theming
      Expected Outcomes
      The REPL presentation framework will have additional features similar to those in WYSIWYG presentation applications.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate.
      Project Length
      175/350 hours. Can be scoped according to project length.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Functions for numerical integration and differentiation
      Linked issue: #24
      Idea
      The goal of this idea is to add functions for numerical integration or differentiation to stdlib as building blocks for downstream algorithms. The functions could be ported from permissively licensed open-source libraries in other languages such as C or Fortran or alternatively be implemented from scratch by consulting the literature and reference implementations from various languages.
      Some work along these lines has been started in the scijs ecosystem, which can be used for initial inspiration (e.g., https://github.com/scijs/ode45-cash-karp), and more generally in SciPy (e.g., https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.ode.html).
      Expected Outcomes
      stdlib will have a range of robust functions for performing numerical integration or differentiation
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @rreusser @Pranavchiku @czgdp1807

      ~~~~~~~~~~
      Symbolic Math
      Linked issue: #25
      Idea
      The goal of this idea is to add basic support for symbolic math operations in stdlib.
      Expected Outcome
      Users have the ability to perform basic symbolic math operations in JavaScript, such as solving equations, simplifying expressions, and using mathematical functions.
      Involved Software
      No other software should be necessary.
      Prerequisite Knowledge
      JavaScript, Node.js, and an understanding of mathematics and calculus.
      Difficulty
      Intermediate
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @rreusser

      ~~~~~~~~~~
      Make code blocks on website documentation interactive
      Linked issue: #26
      Idea
      Currently, all code blocks in the documentation at https://stdlib.io/docs/api/latest are static. To make example code more useful and engaging, it would be nice to have interactive code shells on the website that could be edited and would provide real-time return annotations.
      Some initial brainstorming has been done to inform how this would work, but, at minimum, we'd need to
      convert READMEs to structured data to allow for more straightforward transformation
      support dynamic loading of relevant stdlib packages used in example code blocks
      lazily integrate a code editor into documentation pages
      implement security measures to prevent malicious usage
      Expected Outcomes
      Improved user experience on the website, as the code examples would become editable and interactive. Return annotations would have to update in real-time, and additional contextual help could be provided via overlays etc. Another outcome would be to make it easy to switch between ES5 and ES6 for code blocks.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, HTML/CSS, React + JSX
      Difficulty
      Hard.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Optimization Algorithms
      Linked issue: #27
      Idea
      We currently do not have optimization algorithms in stdlib. Having support for Linear Programming, Convex Optimization, Quadratic Programming, and/or Non-Linear Optimization algorithms would be a great addition.
      Expected Outcomes
      stdlib will have a broad array of optimization algorithms for solving problems.
      Involved Software
      No other software should be necessary. However, we will need to do a needs analysis to determine which prerequisite packages/functionality is necessary in order to allow these algorithms to be implemented (e.g., BLAS).
      Prerequisite Knowledge
      JavaScript, Node.js. Familiarity with R, Python, C/C++ would be very useful, as will need to consult reference implementations.
      Difficulty
      Hard. Depends on the reference implementation requirements and algorithmic difficulty.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @rreusser @Pranavchiku @czgdp1807
      
      ~~~~~~~~~~
      Linear Algebra Functionality
      Linked issue: #28
      Idea
      Currently, support for linear algebra operations in stdlib is limited. The goal of this idea would be to implement algorithms for linear algebra operations such as matrix multiplication, calculating the matrix inverse, eigenvalue calculation, singular value decomposition, Cholesky & LU Decomposition, and the like. This overlaps with the goal of increasing the amount of BLAS and LAPACK that is available in stdlib.
      Expected Outcomes
      stdlib will have extended support for linear algebra operations which can be used to solve problems involving matrices and vectors.
      Involved Software
      No other software should be necessary. However, we will need to do a needs analysis to determine which prerequisite packages/functionality is necessary in order to allow these operations to be implemented (e.g., BLAS, ndarray slicing, etc).
      Prerequisite Knowledge
      JavaScript, Node.js. C, Fortran. Familiarity with linear algebra would be very useful, as will need to consult and understand reference implementations.
      Difficulty
      Hard. Depends on the reference implementation requirements and algorithmic difficulty.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @Pranavchiku @czgdp1807 @rreusser

      ~~~~~~~~~~
      Achieve ndarray API parity with built-in JavaScript arrays
      Linked issue: #33
      Idea
      Built-in JavaScript arrays (and typed arrays) have a number of methods for creating, transforming, and manipulating array contents (e.g., forEach, map, reverse, slice, filter, etc). These APIs provide base level functionality forming a default vocabulary for working with array data.
      The goal of this idea is to create functional analogs of array methods for working with ndarrays, which are efficient data structures for operating on multi-dimensional data. The main difficulty in implementing analogs is in ensuring efficient iteration of non-contiguous data. The main patterns for such iteration have been established in stdlib, but work remains to apply such patterns for top-level array-equivalent APIs.
      Expected Outcomes
      Users will be able to use functional APIs (exposed as part of individual packages) for operating on ndarrays in a manner similar to how users can use prototype methods available on built-in arrays and typed arrays.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      For APIs not accepting callbacks, certain kernels can be implemented in C, as time and scope allow.
      Difficulty
      Intermediate. Writing the loop kernels can be involved, but, once understood, are straightforward to apply.
      Project Length
      90/175/350 hours. Can be scoped accordingly. Scope can be expanded to implement additional ndarray kernels outside of Array method equivalents.
      Potential Mentors
      @kgryte @Planeshifter @steff456 @rreusser

      ~~~~~~~~~~
      Develop C implementations for base special mathematical functions
      Linked issue: #34
      Idea
      This idea builds on the work outlined in stdlib-js/stdlib#649. Namely, implementing base special mathematical functions in C. Currently, all special mathematical functions have JavaScript implementations, which are often ports from other languages.
      The goal of this idea is to port all JavaScript implementations to C. Having such implementations will allow stdlib to provide Node.js native add-ons for higher performance ndarray computation and is more generally necessary for achieving NumPy/SciPy parity.
      Expected Outcomes
      Users will be able to leverage C implementations for use in Node.js native add-ons, and stdlib will be able to expose element-wise APIs for evaluating base special math functions over ndarrays.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      C, JavaScript, Node.js.
      Difficulty
      Intermediate. Familiarity with C is beneficial. This idea mainly involves porting existing implementations (many of which are written in C/C++) and doing so in a manner which conforms with stdlib conventions.
      Project Length
      90/175/350 hours. Can be scoped accordingly. Scope can be expanded to implement new special mathematical functions.
      Potential Mentors
      @kgryte @Planeshifter @steff456 @rreusser @Pranavchiku @czgdp1807

      ~~~~~~~~~~
      Develop an Excel add-on which exposes stdlib functionality
      Linked issue: #35
      Idea
      The goal of this idea is to allow users to call stdlib APIs from within Excel. This will allow users to perform linear algebra and various machine learning operations directly on spreadsheet data and all within the browser.
      In order to execute on this idea, we'll want to support
      two-dimensional array broadcasting semantics
      performant element-wise iteration APIs
      input argument validation tailored to the Sheets context
      Fused operations to avoid unnecessary network calls
      documentation and tutorials demonstrating API usage
      good generation and automation for creating extension builds
      testing and performance measurement to guard against regressions
      This idea is the Excel version of #13.
      Expected Outcomes
      Excel users will be able to install an extension which exposes stdlib functionality, run statistical tests, evaluate mathematical functions, and perform linear algebra operations using stdlib.
      Involved Software
      No other software is necessary; however, access to a local copy of Excel will be beneficial. While Microsoft 360 can be used, debugging is more difficult and less stable.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Beginner/Intermediate.
      Project Length
      175/350 hours. Can be scoped accordingly. A skilled contributor can work on a strategy for performant fused operations.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Add BLAS bindings and implementations for linear algebra
      Linked issue: #36
      Idea
      BLAS routines are standard building blocks for performing basic vector and matrix operations. These building blocks are leveraged by most modern numerical programming languages and libraries, including NumPy, SciPy, Julia, MATLAB, R, and others.
      The goal of this idea is to
      reimplement reference BLAS routines in free-form Fortran 95
      port reference BLAS routines to C
      port reference BLAS routines to JavaScript
      write Node.js bindings to allow calling BLAS routines in compiled C/ Fortran from JavaScript
      Expected Outcomes
      Users will be able to call BLAS routines from JavaScript. In web browsers, BLAS routines will be in JavaScript. In Node.js, provided native bindings have been compiled, BLAS routines will either be ported reference implementations or hardware optimized system libraries.
      Involved Software
      No other software is necessary apart from standard compilers (GCC, gfortran).
      Prerequisite Knowledge
      C, Fortran, JavaScript, Node.js.
      Difficulty
      Intermediate. Familiarity with C and Fortran will be beneficial. This idea mainly involves porting existing implementations and doing so in a manner which conforms with stdlib conventions.
      Project Length
      90/175/350 hours. Can be scoped accordingly.
      Potential Mentors
      @kgryte @Planeshifter @steff456 @rreusser @Pranavchiku @czgdp1807
      
      ~~~~~~~~~~
      Implement incremental (online) machine learning algorithms
      Linked issue: #37
      Idea
      The goal of this idea is to implement incremental machine learning algorithms to allow for real-time regression and classification. Such online algorithms would allow for point-by-point data processing and avoid the sometimes costly overhead of batch processing. Online algorithms are particularly useful in data streaming contexts (e.g., user clicks, photon collection, etc).
      While stdlib includes some incremental algorithms (binary classification, k-means, and stochastic gradient descent regression), the project would benefit from additional algorithms.
      Individuals interested in pursuing this idea should be prepared to research possible algorithms and propose specific APIs.
      Expected Outcomes
      stdlib will expose one or more additional APIs for incremental machine learning.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate. In order to implement ML algorithms, individuals will likely need to consult reference implementations written in other languages. Porting from these implementations may not be straightforward depending on the features involved.
      Project Length
      90/175/350 hours. Can be scoped accordingly.
      Potential Mentors
      @kgryte @Planeshifter
      
      ~~~~~~~~~~
      Add support for string arrays in stdlib
      Linked issue: #44
      Idea
      Similar to what's described in #43, a need exists to expand array data type support beyond numeric data types. One such data type is a string data type. The rationale for having a dedicated string data type is for better interoperation between JavaScript and C, and this is particularly paramount for supporting ndarrays having a string data type, as much of ndarray iteration machinery is written in C.
      Accordingly, the goal of this project is to add a dedicated string typed array called a StringArray, which will support variable-length strings. This new array type should follow a similar path to that of @stdlib/array/complex64, which provides a typed array dedicated to single-precision complex floating-point numbers; namely, StringArray should support standard typed array methods, as well as provide accessors for getting and setting array elements.
      Note, however, that a StringArray should be a typed array. A StringArray should not wrap a "generic" array. Instead, the array should be backed by fixed length memory, similar to how @stdlib/array/complex64 is backed by a Float32Array. One possibility is backing StringArray instances with Node.js Buffer objects, which are, in turn, Uint8Arrays.
      There are, however, some design considerations; namely, how to handle setting of array elements. In particular, what happens when a user attempts to update a StringArray element with a larger string? Does that lead to a new memory allocation and data copy? Or should elements have a fixed allocation to allow for elements to grow until some maximum size?
      As part of this project, not only will a new StringArray be added to the project, but it will be integrated throughout stdlib. This will entail adding support for StringArrays wherever arrays are accepted/used, following the same precedent established by @stdlib/array/complex64 and other custom array types in stdlib. This includes adding support for string arrays in ndarray APIs.
      Prior Art
      Recent work in NumPy adding UTF-8 variable length string support: https://numpy.org/neps/nep-0055-string_dtype.html
      Expected outcomes
      The expected outcomes of this idea should be (1) creation of a new @stdlib/array/string package exposing a new typed array constructor, (2) support for StringArray instances throughout @stdlib/array/*, (3) support for StringArray instances as backing arrays for ndarrays (which may involve working with various C APIs), and (4) any other integration opportunities.
      Status
      While no work has been done to create a new @stdlib/array/string package, there exists prior art for adding custom typed arrays to stdlib; namely, Complex64Array and Complex128Array.
      Involved software
      No special software for initial work. Once work has progressed to ndarray support, will need access to a C compiler, as documented in the project development guide.
      Technology
      JavaScript, C, nodejs, native addons
      Other technology
      n/a
      Difficulty
      Intermediate/Advanced
      Difficulty justification
      This project is ambitious, as there are many design considerations which need to be addressed in order to ensure performance and allow for efficient JS/C interoperation.
      Additionally, there will be difficulty beyond the creation of a new StringArray class in finding all the various bits of code throughout the project which need to be updated in order to more universally support StringArray instances throughout stdlib on equal footing with other array data types.
      Prerequisite knowledge
      Familiarity and comfort with JavaScript would be highly recommended, given that this project will require considerable programming in JavaScript. Some familiarity with C would also be good, especially for string array integration with ndarrays.
      Project length
      350hrs, as will likely involve a decent amount of R&D.
      Potential mentors
      @kgryte @Planeshifter

      ~~~~~~~~~~
      ESLint 9 Migration for JSON and YAML Linting
      Linked issue: #90
      Idea
      We will migrate stdlib-js to ESLint 9 to take advantage of new features, performance improvements, and enhanced file type support (including JSON and YAML). Additionally, this idea posits that we will create new ESLint rules that enforce project-specific coding standards for stdlib. This dual approach ensures both modern linting capabilities and adherence to stdlib’s code expectations and style guidelines.
      Expected outcomes
      ESLint 9 Integration: A full migration of the linting infrastructure to ESLint 9.
      Extended File Support: Ability to lint not just JavaScript but also JSON and YAML files with the help of ESLint.
      New Custom Rules: New rules to enforce more of stdlib’s conventions.
      Enhanced Code Quality: Improved consistency and code quality by enforcing additional project-specific standards across the codebase.
      Updated Configurations: Comprehensive configuration updates that incorporate both ESLint 9 changes and the new custom rules.
      Status
      stdlib currently uses ESLint 8. The stdlib project already has an extensive collection of custom lint rules.
      Involved software
      No additional external dependencies aside from ESLint.
      Technology
      nodejs, JavaScript
      Other technology
      n/a
      Difficulty
      3
      Difficulty justification
      Migrating to ESLint 9 requires a detailed review of current linting configurations and potential refactoring of custom rules. The project will involve understanding new semantics and breaking changes introduced in ESLint 9, addressing compatibility issues, and integrating support for additional file types such as JSON and YAML and bespoke rules for these new file types. Additionally, thorough testing across various scenarios is necessary to ensure stability, making this a task that is intermediate in complexity.
      Prerequisite knowledge
      A thorough understanding of ESLint, including its configuration system and plugin architecture, is essential. Familiarity with JavaScript and Node.js is required, along with experience in developing custom linting rules. Additionally, knowledge of continuous integration and automated testing practices is recommended to ensure that any new linting rules integrate smoothly into stdlib’s development workflow.
      Project length
      175

      ~~~~~~~~~~
      Improve stdlib publishing pipeline
      Linked issue: #92
      Idea
      stdlib is composed of thousands of individual packages. Managing this complexity requires an intricate publishing pipeline that handles automatic updates to repositories, generation of various bundle types, publishing packages to the npm registry, changelog generation, and more.
      The project aims to refactor the current workflows by breaking down the monolithic, feature-rich scripts (example) into discrete, standalone tooling packages in the _tools namespace, which can be independently tested and maintained.
      In addition, while we still will lean on GitHub Actions for the publishing flow, this project will ensure that our publishing pipeline will not be tightly coupled with it anymore.
      Goals of the refactoring will also include to improve logging and observability, enable rigorous testing and checkpointing, and the ability to trigger all steps locally via a CLI tool.
      Expected outcomes
      Having the publishing pipeline fully composed into modular packages.
      Each module having its own suite of unit tests.
      Integration tests and end-to-end tests for the entire workflow.
      Enhanced observability and diagnostic tools integrated into the publishing process.
      A reduction in the complexity of the existing scripts by making GitHub Actions interactions explicit and manageable.
      Better error recovery, collection of statistics, and a more maintainable architecture.
      Status
      No effort has been undertaken to start modularizing the publishing pipeline architecture, but there is agreement among the TSC that this is a desirable goal.
      Involved software
      GitHub Actions, Bash.
      Technology
      JavaScript, nodejs
      Other technology
      None.
      Difficulty
      3
      Difficulty justification
      The project involves a large refactor of an existing, complex system.
      Decoupling the interwoven dependencies of the current monolithic script requires careful planning and modular design.
      Handling platform variability between local development and GitHub Actions orchestration, including differences between Linux and MacOS, adds complexity.
      Introducing enhanced testing and observability requires integrating new tools and extending the current functionality.
      Prerequisite knowledge
      Proficiency in JavaScript and Node.js development as well as Bash scripting.
      Familiarity with GitHub Actions and CI/CD pipeline design.
      Understanding of modular design principles and software refactoring techniques.
      Project length
      350

      ~~~~~~~~~~
      Add support for Float16Array
      Linked issue: #94
      Idea
      With Float16Array now on track for stage 4 approval in JavaScript (see tc39/proposal-float16array#7), it is time we start thinking about adding support for Float16Array in stdlib. We have prior experience adding new array types, such as array/bool, array/complex128, and array/complex64, and this idea is a continuation of those efforts.
      The expected roadmap is as follows:
      add a new array/float16 package which includes a polyfill for backward compatibility support. The polyfill should expose all common methods and properties as found on other typed array constructors. This package should contain complete tests, documentation, and benchmarks, as found in other typed array packages (e.g., array/bool).
      add support for float16 array dtypes throughout the array/* namespace.
      add support for float16 array dtypes throughout the strided/* namespace.
      add support for float16 array dtypes throughout the ndarray/* namespace.
      Expected outcomes
      stdlib users will be able to create and operate on Float16Array instances the same way they do throughout the project, with Float16Array on equal footing with all other typed array classes.
      Status
      No work has been done on this idea; however, we expect that this should follow as similar path to array/bool and its integration throughout the project.
      Related: #43
      Involved software
      No special software for initial work. Once work has progressed to ndarray support, will need access to a C compiler, as documented in the project development guide.
      Technology
      JavaScript, C, nodejs, native addons
      Other technology
      None.
      Difficulty
      4
      Difficulty justification
      Implementing the polyfill will likely take some time, with the need for adding additional functionality to support the implementation (e.g., bit manipulation utilities, math utils, etc).
      This project is ambitious, as arrays are fundamental to a lot of stdlib functionality; however, many of the more difficult integration aspects have already addressed given the widespread support for other array types throughout the project. The main project difficulty beyond the creation of a new Float16Array class will be finding all the various bits of code throughout the project which need to be updated.
      Prerequisite knowledge
      Familiarity and comfort with JavaScript would be highly recommended, given that this project will require considerable programming in JavaScript. Some familiarity with C would also be good, especially for float16 array integration with ndarrays.
      Project length
      350
      
      ~~~~~~~~~~  
      Add LAPACK bindings and implementations for linear algebra
      Linked issue: #95
      Idea
      LAPACK routines are standard building blocks for performing basic vector and matrix operations. These building blocks are leveraged by most modern numerical programming languages and libraries, including NumPy, SciPy, Julia, MATLAB, R, and others.
      The goal of this idea is to
      reimplement reference LAPACK routines in free-form Fortran 95
      port reference LAPACK routines to pure C
      port reference LAPACK routines to pure JavaScript
      write Node.js bindings to allow calling LAPACK routines in compiled C/ Fortran from JavaScript
      Expected outcomes
      Users will be able to call LAPACK routines from JavaScript. In web browsers, LAPACK routines will be in JavaScript. In Node.js, provided native bindings have been compiled, LAPACK routines will either be ported reference implementations or hardware optimized system libraries.
      Status
      Some work has begun toward this effort. See https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/lapack/base.
      Involved software
      No other software is necessary apart from standard compilers (GCC, gfortran).
      Technology
      C, JavaScript, Fortran, nodejs, native addons
      Other technology
      None.
      Difficulty
      4
      Difficulty justification
      Familiarity with C and Fortran will be beneficial. This idea mainly involves porting existing implementations and doing so in a manner which conforms with stdlib conventions. Some of the reference implementations are likely to be quite involved and testing the correct output can be tricky, especially for lower-level helper routines.
      Prerequisite knowledge
      C, Fortran, JavaScript, Node.js.
      Project length
      350

      ~~~~~~~~~~

      Extend stdlib's doctesting approach to C examples
      Linked issue: #96
      Idea
      We heavily rely on doctesting (see https://github.com/stdlib-js/stdlib/blob/develop/docs/doctest.md) to ensure that our Markdown and JSDoc examples are correct and do not become out-of-date. However, we currently have no such framework for ensuring that our C source code and Markdown examples are correct.
      The goal of this project would be to implement doctesting for C source code and associated Markdown examples. While the approach is likely to be similar (e.g., parsing source code in scripts, Markdown code blocks, and in DOXYGEN examples), the technology stack is likely to be different and will require some R&D, especially as we won't be able to rely on things like ESLint. Instead, we'll need other tooling for identifying // returns annotations, instrumenting examples to collect return values, resolving source files to compile, compiling source files, executing scripts, and asserting that the output results match expectation.
      Expected outcomes
      As part of our CI workflows and in local development, developers will be able to test that their C examples are correct.
      Status
      stdlib has its own doctesting framework for checking JavaScript examples. This should serve as inspiration and provide an idea of what we are looking for.
      Involved software
      C compilers, AST generators, and stdlib tooling.
      Technology
      C
      Other technology
      None.
      Difficulty
      5
      Difficulty justification
      There is likely a need for R&D to determine the best tools and approach. For JavaScript examples, we are able to rely on the fact that we can lint and execute within the same JavaScript runtime. In this case, there will be additional steps needed to separately instrument, create temporary files, compile, execute, and collect.
      Prerequisite knowledge
      Experience with C and creating tooling will be beneficial.
      Project length
      350

      ~~~~~~~~~~
      Add WebAssembly implementations for extended BLAS routines
      Linked issue: #97
      Idea
      We've worked toward compiling BLAS routines to WebAssembly and offering ergonomic APIs for interfacing between JavaScript and WebAssembly binaries (see https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/blas/base/wasm). The goal of this project would be to extend these efforts to the blas/ext/base namespace, such that, for each typed interface in blas/ext/base/(d|s|c|z|)*, there would be a corresponding WebAssembly package in blas/ext/base/wasm/*.
      Expected outcomes
      Users wanting to potentially accelerate computation of extended BLAS routines will be able to consume a corresponding WebAssembly API.
      Status
      Work has primarily happened in https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/blas/base/wasm. The efforts there would need to be replicated for the blas/ext/base/wasm/* namespace.
      Involved software
      Emscripten, which is necessary for compiling C to WebAssembly. stdlib already offers tooling for automatically installing the emsdk and getting things up and running.
      Technology
      C, JavaScript
      Other technology
      None.
      Difficulty
      3
      Difficulty justification
      Given that most blas/ext/base/* routines are straightforward one-dimensional strided array interfaces, developing the wasm packages should be similarly straightforward. The main time-consuming task will be writing tests and documentation.
      Prerequisite knowledge
      Some familiarity with WebAssembly will be helpful. Experience with JavaScript.
      Project length
      90/175/350. Can be scoped accordingly.
      
      ~~~~~~~~~~
      Add WebAssembly implementations for stats/strided routines
      Linked issue: #98
      Idea
      We've worked toward compiling BLAS routines to WebAssembly and offering ergonomic APIs for interfacing between JavaScript and WebAssembly binaries (see https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/blas/base/wasm). The goal of this project would be to extend these efforts to the stats/strided namespace, such that, for each typed interface in stats/strided/(d|s|c|z|)*, there would be a corresponding WebAssembly package in stats/strided/wasm/*.
      Expected outcomes
      Users wanting to potentially accelerate computation of strided statistics routines will be able to consume a corresponding WebAssembly API.
      Status
      Work has primarily happened in https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/blas/base/wasm. The efforts there would need to be replicated for the stats/strided/* namespace.
      Involved software
      Emscripten, which is necessary for compiling C to WebAssembly. stdlib already offers tooling for automatically installing the emsdk and getting things up and running.
      Technology
      C, JavaScript
      Other technology
      None.
      Difficulty
      3
      Difficulty justification
      Given that most stats/strided/* routines are straightforward one-dimensional strided array interfaces, developing the wasm packages should be similarly straightforward. The main time-consuming task will be writing tests and documentation.
      Prerequisite knowledge
      Some familiarity with WebAssembly will be helpful. Experience with JavaScript.
      Project length
      90/175/350. Can be scoped accordingly.

      ~~~~~~~~~~
      Create a prototype for transpiling a subset of TypeScript to C with automatic add-on generation
      Linked issue: #99
      Idea
      Drawing on some of the recent innovations in the numerical Python ecosystem (e.g., see pyccel), the goal of this project would be to see if we can define a restricted subset of TypeScript which can be transpiled to C for faster execution in Node.js and other server runtimes.
      There is some prior art here; namely, AssemblyScript, which provides a TypeScript-like language which compiles to WebAssembly. However, we should be able to go farther here, especially in leveraging stdlib's richer collection of types (in particular, complex number dtypes). From this restricted subset, we can then automate transpilation of TypeScript to C, with the ability to automatically generate Node.js native add-ons bindings similar to what can be found in, e.g., https://github.com/stdlib-js/stdlib/blob/954e7c1e1716bfdd15903b4be7039741396927eb/lib/node_modules/%40stdlib/blas/base/dcopy/src/addon.c.
      There would be some puzzle pieces to put together here. Namely,
      defining a richer set of numeric types. Currently, stdlib uses number, boolean, Float64Array, and other built-in types, along with a couple of custom types, such as Complex128 and Complex64. We'd like want to create named aliases for specific numeric types, such as int64, int32, etc (similar to AssemblyScript). These would not impact consumption of project type declarations in TypeScript; although, they would have the benefit of signaling expected types.
      updating the TypeScript declarations for various packages (e.g., blas/ext/base) to use the newly defined types.
      creating tooling which can resolve and read a TypeScript declaration for an exported function and then automatically generate an addon.c file. If we can reproduce the addon.c file in blas/base/dcopy, that would be a win.
      potentially porting a subset of JavaScript implementations to TypeScript using the aliases defined above.
      from the ports, creating tooling which can, with high fidelity, generate one or more JavaScript implementations.
      from the ports, creating tooling which can, with high fidelity, generate one or more C implementations.
      Note that, when transpiling from TypeScript to C, we'd need to properly determine appropriate stdlib includes and dependencies. If we could auto-generate a basic manifest.json file, that could also be useful.
      We could also explore a TypeScript to Fortran transpiler.
      Expected outcomes
      A working end-to-end prototype which is capable of transpiling stdlib-flavored TypeScript to C and which can reproduce hand-authored C and JavaScript code.
      Status
      No work has begun on this.
      Involved software
      TypeScript and C/Fortran compilers.
      Technology
      C, JavaScript, native addons, Fortran
      Other technology
      None.
      Difficulty
      4
      Difficulty justification
      This idea is exploratory, and, while conceptually straightforward, the project does involve a number of unknowns, particularly around how easy it will be to reproduce hand-optimized code. Given that the blas/base/*, blas/ext/base/*, and stats/strided/* namespaces provide a relatively contained environment for API design, it's possible that this will be achievable, but we won't know the best approach until after some R&D.
      Prerequisite knowledge
      TypeScript, C, and JavaScript experience would be beneficial.
      Project length
      350
      
      ~~~~~~~~~~
      Add matrix format parsers and data loaders
      Linked issue: #100
      Idea
      The goal of this project would be to implement various matrix and multi-dimensional format parsers and data loaders. E.g.,
      Matrix Market
      NumPy npy
      DLPack
      MATLAB mat
      others?
      Implementing these parsers and loaders would facilitate array data interchange with other numerical computing ecosystems.
      Expected outcomes
      Users will be able to load multi-dimensional array data saved in other numerical computing environments into stdlib's ndarray data structure.
      Status
      No work has begun on this.
      Involved software
      Access to MATLAB/Octave would be useful for implementing the MAT-file parser. One would likely need to use Python and NumPy in order to save and work with npy files.
      Technology
      JavaScript
      Other technology
      None.
      Difficulty
      4
      Difficulty justification
      Some of the file format specifications can be quite involved. It is also likely that we may encounter situations in which we cannot support particular formats in full due to dtype incompatibility, etc.
      Prerequisite knowledge
      Familiarity with JavaScript, Python, and MATLAB would be useful. Experience writing parsers and performing IO will also be beneficial.
      Project length
      90/175/350. Can be scoped accordingly.
      
      ~~~~~~~~~~
      Add support for working with arrays backed by memory-mapped files
      Linked issue: #101
      Idea
      Memory-mapped files allow accessing small segments of large disks stored on disk, without reading the entire file into memory. Not only can this be advantageous for memory performance, but it also facilitates shared memory between processes (e.g., operating on the same array in both Node.js and Python running in two separate processes).
      The goal of this project is to add support for working with typed arrays backed by memory-mapped files. Memory-mapped-backed typed arrays should support all the APIs of built-in typed arrays, with the exceptions that the constructors will need to support mmap-related arguments (e.g., filename, mode, offset) and indexing will require accessors, not square bracket syntax. The project is well-prepared to support accessors (see array/bool, array/complex128, etc), such that, provided a memory-mapped typed array supports the accessor protocol, passing to downstream utilities should just work.
      Similar to how we've approached fixed-endian typed arrays (see array/fixed-endian-factory), we can likely create a package exposing a constructor factory and then create lightweight wrappers for type-specific constructors (e.g., array/little-endian-float64).
      This project may require figuring out a strategy for C-JS iterop which can be used across constructors.
      Expected outcomes
      Ideally, we would have the following constructors:
      Float64ArrayMMap
      Float32ArrayMMap
      Int32ArrayMMap
      Int16ArrayMMap
      Int8ArrayMMap
      Uint32ArrayMMap
      Uint16ArrayMMap
      Uint8ArrayMMap
      Uint8ClampedArrayMMap
      BooleanArrayMMap
      Complex128ArrayMMap
      Complex64ArrayMMap
      Additionally, the following constructors would also be useful:
      DataViewMMap
      Status
      None.
      Involved software
      C compiler such as GCC or Clang.
      Technology
      C, JavaScript, nodejs, native addons
      Other technology
      None
      Difficulty
      5
      Difficulty justification
      Figuring out an effective bridge between JavaScript and C for working with memory-mapped files will likely require some R&D. It is not clear whether we'd need to first develop separate dedicated mmap(2)-like functionality in JavaScript or whether we can directly interface into C. Once the lower-level details are determined, the next steps will be implementing all the user-facing APIs expected from typed arrays. This should be straightforward; however, there may be some unexpected challenges and constraints surrounding read-only access, etc.
      Prerequisite knowledge
      C, JavaScript, and Node.js experience will be useful.
      Project length
      350
      
      ~~~~~~~~~~
      Improve project supply chain security by bringing production dependencies in-house
      Linked issue: #102
      Idea
      stdlib currently depends on 14 external packages. Ideally, we'd reduce this number to 0 in order to (a) reduce the risk of supply-chain security vulnerabilities and (b) ensure that all production code used within stdlib follows the "stdlib way" (i.e., docs, tests, examples, benchmarks, backward-compatibility guarantees, etc).
      Accordingly, this project seeks to bring external packages "in-house" by implementing stdlib equivalents which can replace their usage within stdlib. Immediate targets are dependencies such as debug, glob, resolve, and minimist which we'd like to bring in-house for their own sake.
      Bringing acorn and friends in-house would likely require more work and impose an increased maintenance burden, so we'd want to be careful in determining whether we want to prioritize a stdlib implementation. That said, having a stdlib suite of JavaScript AST manipulators would be useful. The main concern is simply keeping up with yearly ECMAScript versions. If we stayed close enough to acorn, we could potentially just mirror changes into stdlib. Regardless, some thought would be required to determine whether we want to model any stdlib implementation after acorn or some other high-quality and performant AST parser third-party package.
      For d3-* and friends, these would likely go away once we migrated our plot functionality to use vega. So their priority is lower.
      For vdom-to-html and virtual-dom, these have been useful in the past; however, it is not clear whether these deserve inclusion in stdlib. They are currently used in the stdlib plot API. Similar to the d3-* packages, they might just naturally go away after migrating plot functionality to vega.
      readable-stream is a harder package to migrate. First and foremost, one should evaluate how much we actually need readable-stream and whether we can still retain desired backward compatible behavior with built-in Node.js streams. It is possible that the answer is yes; however, historically, using readable-stream has been critical in ensuring consistent behavior across Node.js versions.
      Expected outcomes
      Third-party party production dependencies would have equivalent stdlib implementations, and we can remove them as dependencies in the project package.json.
      Status
      No work has begun on this.
      Involved software
      None.
      Technology
      JavaScript, nodejs
      Other technology
      None.
      Difficulty
      4
      Difficulty justification
      It depends on which dependencies are prioritized. Some, such as acorn, could be quite involved and require extensive testing. Others, such as resolve should be more straightforward. glob is likely to require significant R&D in order to understand and determine an ideal API.
      Prerequisite knowledge
      Experience and a high degree of comfort with JavaScript and Node.js.
      Project length
      90/175/350. Scope can be tailored accordingly.

      ~~~~~~~~~~
      Automated Code Reviews and Fixes via LLM-powered stdlib-bot
      Linked issue: #103
      Idea
      Maintaining a large-scale open-source project like stdlib requires code review and automated tooling for linting, running tests, etc. Many small but important code fixes, such as formatting corrections, documentation improvements, and minor refactorings, are often flagged by maintainers but require manual intervention from contributors. This creates overhead and slows down the resolution of trivial issues.
      This project aims to leverage LLM-powered automation to streamline these processes. The core idea is to enhance stdlib-bot with the ability to not only surface review comments but also propose and submit fixes in the form of automated pull requests.
      In addition to automated code fixes, the project will explore fine-tuning an LLM on historical PR reviews and code comments to build an automated PR review assistant. This would allow stdlib-bot to provide real-time feedback on pull requests, flagging common mistakes based on past code review patterns and enforcing best practices in a scalable way.
      A broader goal of the project is to make stdlib more LLM-friendly. This may involve adding llms.txt, refining documentation formatting, and curating structured datasets (think of maintaining Cursor rules) to improve compatibility with AI-driven tooling.
      Expected outcomes
      stdlib-bot automatically creates pull requests with suggested fixes based on commit comments; can be extended as an agent able to iteratively fix lint failures, formatting issues and test errors from CI workflow runs.
      Fine-tuning or retrieval-augmented generation (RAG) for automated PR review using past stdlib review comments (optional)
      Enhanced codebase compatibility with LLMs and AI code assistance (e.g., adding llms.txt or Cursor rules).
      Metrics to evaluate LLM-generated fixes and PR reviews.
      Integration with GitHub Actions for seamless automation.
      Status
      Currently, the stdlib-bot only reports necessary changes by creating issues, requiring human intervention. No automation of fixes or PR reviews exists yet.
      Involved software
      GitHub Actions
      LLM APIs (e.g. OpenAI)
      GitHub REST or GraphQL API to collect data from past stdlib PR reviews
      Technology
      JavaScript, nodejs
      Other technology
      Depending on skill set and ambition of candidate, this can involve fine-tuning a model via the OpenAI Fine-Tuning APIs or from
      Difficulty
      4
      Difficulty justification
      Requires integrating LLMs with structured commit comments and generating meaningful PRs.
      Need to come up with robust validation strategy to ensure correctness of auto-generated fixes.
      Fine-tuning an LLM on past stdlib code review comments involves data collection, preprocessing, and iterative testing.
      Prerequisite knowledge
      Knowledge of Node.js / JavaScript, experience with GitHub Actions and CI/CD, understanding of LLM APIs and optionally fine-tuning methodologies. Familiarity with automated code refactoring tools is a plus.
      Project length
      350
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/stdlib/
    idea_list_url: https://github.com/stdlib-js/google-summer-of-code/blob/main/ideas.md

  - organization_id: 185
    organization_name: webpack
    no_of_ideas: 3
    ideas_content: |
      


      Tooling: Unified Webpack Dev Tools
      Difficulty: Medium
      Project Size: 175 hours
      Mentors: Alexander, Nitin
      Introduction

      Let's simplify and enhance Webpack's development tools! Currently, we have webpack-dev-server, webpack-hot-middleware, and webpack-dev-middleware, leading to duplication and suboptimal user experiences. The objective is to unify these tools into a more cohesive structure.

      What We Need:
      Extract hot and client logic from webpack-dev-server into a dedicated middleware package (let's call it webpack-hmr-middleware).
      Move relevant options and logic from webpack-hot-middleware to webpack-hmr-middleware.
      Deprecate webpack-hot-middleware.
      Transform webpack-dev-server into a monorepo with three packages: webpack-dev-middleware, webpack-hmr-middleware, and webpack-dev-server itself.


      Prerequisites
      JavaScript, NodeJS, CSS, HTML


      ~~~~~~~~~~













      Webpack: ESM Module Output
      Difficulty: Hard
      Project Size: 350 hours
      Mentors: Alexander, Nitin
      Introduction

      We want to enhance Webpack's core functionality by refining how it handles module output. This project targets a more streamlined approach, optimizing build outputs to support features like tree-shaking and ensuring smooth transitions from CommonJS to ESM. Our goal is to elevate the developer experience with clearer warnings and improved runtime consumption.


      Related Issue(s): #17121

      Prerequisites
      JavaScript, NodeJS, CSS, HTML

      Webpack: Universal Targets
      Difficulty: Hard
      Project Size: 350 hours
      Mentors: Alexander, Nitin
      Introduction


      This project aims to enhance the versatility of Webpack's targets. Currently, there are limitations, and a web bundle doesn't seamlessly fit into Node.js or a web worker environment. The proposal is to introduce a Universal Target that incorporates runtime code suitable for web, web worker, and Node.js. While this may increase code size slightly, the benefit is the ability to create Universal Module Definition (UMD) bundles that work seamlessly across all environments. Additionally, this enhancement facilitates sharing chunks between web and web worker environments.

      Related Issue(s): #6525

      Prerequisites
      JavaScript, NodeJS, CSS, HTML

      ~~~~~~~~~~







      Webpack: Destructuring
      Difficulty: Hard
      Project Size: 175 hours
      Mentors: Alexander, Nitin
      Introduction

      This project revolves around enhancing Webpack's support for destructuring in various contexts. Currently, we're looking to extend this support to plugins such as EnvironmentPlugin, DefinePlugin, ImportMetaPlugin (with partial support), and potentially other plugins. Additionally, we aim to improve the tree shaking capabilities when using destructuring with dynamic imports, namespace objects, and JSON files. Webpack should seamlessly support destructuring on the parser level, allowing developers to utilize this modern language feature across different plugins and scenarios.


      Related Issue(s): #14800 and #16872

      Prerequisites
      JavaScript, NodeJS, CSS, HTML





      Webpack: Benchmark Tooling
      Difficulty: Hard
      Project Size: 90 hours
      Mentors: Alexander, Nitin
      Introduction

      Revamp Webpack's performance tracking! We need a solid CI system to run benchmarks on every webpack PR. This ensures maintainers easily assess performance impacts, blocks significant regressions, and provides contributors clear feedback. Join us in building a reliable benchmarking system for Webpack's continuous improvement!


      Related Issue(s): #16827

      Prerequisites
      JavaScript, NodeJS, CSS, HTML



    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/webpack/
    idea_list_url: https://docs.google.com/document/d/1JOtAdpoqHGieg_nJpjkWDv1BoErPQ9L1GnZmX55E-W0/edit?usp=sharing


  




  


  

 
