organizations:
  - organization_id: 1
    organization_name: 52°North Spatial Information Research GmbH
    no_of_ideas: 3
    ideas_content: |
                1. KomMonitor
                Angular migration of the KomMonitor Web Client
                Explanation
                KomMonitor is a web based tool that combines methods of GIS (Geographic information System) and statistical data and helps in providing a simpler and easier way to monitor geo-spatial data. Many municipalities have established KomMonitor to address a wide range of challenges in fields such as urban planning, environmental management, and disaster response. The current version of the KomMonitor Web Client has been developed using AngularJS, which has served as a reliable foundation for its functionalities. However, AngularJS has been deprecated for some years now. Therefore, relying on the current code base has several potential drawbacks associated with using AngularJS, such as compatibility issues, limited community support, reduced performance, and version support. To overcome these challenges and take KomMonitor to the next level, it is necessary to adopt the KomMonitor Web Client to the more modern and widely-supported framework Angular. As part of GSoC 2023, essential work has been done by developing a general approach for the Angular migration. The Web Client has been restructured so that it can be deployed as a hybrid web application, which runs both legacy AngularJS components and migrated or new Angular components. This year, the project aims to continue the migration tasks. Hence, the goal of this project is to reimplement several selected components of the KomMonitor Web Client by using the Angular framework.

                Expected Results
                As a result of the project, it is expected that several selected components of the KomMonitor Web Client will have been reimplemented with the Angular framework. The resulting UI of the reimplemented components should be as close as possible to the previous design to preserve the current look&feel. As an additional requirement, the reimplementation should take into account best practices and common design patterns in Angular. This results in also restructuring some of the existing components rather than simply transferring a component from AngularJS to Angular. Finally, the hybrid Web Client, including legacy AngularJS components and new Angular components side-by-side, should run properly without any bugs.

                Code Challenge
                Migrate the kommonitorToastHelperService of the KomMonitor Web Client to Angular and make use of it in a new Angular component as part of the Web Client. Follow the steps below:

                Create a fork of https://github.com/KomMonitor/web-client and checkout the GSoC2025 Branch
                Create a new Angular service as part of the KomMonitor Web Client that provides the same functionality as the existing AngularJS version of the kommonitorToastHelperService
                Create a new Angular component that makes use of the previously implemented kommonitorToastHelperService. Take into account these requirements:
                The component should be opened and closed by clicking on a button on the left sidebar.
                The component should include a text area and a button.
                The required functionality should be to display a message as toast on the screen by filling the text area and clicking on the button. For this purpose the kommonitorToastHelperService should be used.
                Push the code to your fork at GitHub
                Link to the fork within your official GSoC application. Your GSoC application should also include a description of which components you plan to migrate during GSoC as well as an estimation of time required for implementing it.


                Community and Code License
                Apache Software License, Version 2

                Mentors
                Sebastian Drost (s.drost @52north.org), Christoph Wagner (c.wagner @52north.org)

                Project Duration
                The duration of the project is estimated at 175 hours. An extension is possible.

                Chat
                TBD

                ~~~~~~~~~~

                2. LLM and GeoData
                Explanation
                During 52°North’s Student Innovation Challenge in 2024, a first open-source implementation connecting spatial data and Large Language Models (LLM) was developed.

                The ambition was to address the pain points of searchability in Research and Spatial Data Infrastructures (RDI/SDI). Search functionality in such systems is typically limited to a metadata-based approach. However, geospatial data – whether vector or raster based – provides a wealth of interesting data that can currently only be identified by looking at the individual dataset. The challenge of the 2024 Student Innovation Prize was to develop a concept and a possible implementation that allows searching within datasets of/and RDI/SDI, e.g. on the attribute level. There are many interesting aspects related to this challenge: technical solutions, taxonomies and semantics, language/i18n, searching in raster data, and many more such as LLMs.

                The available Proof of Concept (PoC) features a prompt that makes it easier to search and access to spatial data. More user stories are documented in the Innovation Prize project backlog on GitHub: https://github.com/52North/innovation-prize.

                Expected Results
                The PoC should be hardened and developed beyond its current state. For example, less verbose prompts are needed as more sophisticated LLMs emerge. Also, improved software frameworks may provide a better development experience. Various extensions are possible and a selection should be outlined in the proposal. Additional user stories from the backlog in the github project (see above) could be addressed. Another interesting extension could also entail a federated architecture. Furthermore, the use of different LLMs is also a possible option for further development.

                Code Challenge
                Set up the entire working environment based on the existing open source code

                https://github.com/52North/innovation-prize/tree/2024

                and add two more data sets. Share the code and the deployed system.

                Community and Code License
                TBChecked: Apache Software License, Version 2

                Mentors
                Henning Bredel (h.bredel @52north.org), Simeon Wetzel

                Project duration
                The duration of the project is estimated at 175 hours. An extension is possible.

                ~~~~~~~~~~

                3. Weather Routing Tool
                Explanation
                The open-source 52°North Weather Routing Tool (WRT) was initially developed during the MariData project. It provides means to find an optimal ship route that minimizes fuel consumption under varying weather conditions. In the optimization process, several constraints can be integrated, e.g. water depth and traffic separation zones. Currently, there are two algorithms available: an isofuel algorithm and a genetic algorithm. Details of the MariData project and example applications of the Weather Routing Tool can be found in the following publication: https://proceedings.open.tudelft.nl/imdc24/article/view/875.

                Expected Results
                The Weather Routing Tool should be extended by new features and its robustness should be improved. There are three major directions of possible developments:

                Ship speed optimization
                Currently, only the geometry of the route is optimized while the ship speed is assumed to be constant. To cover a broader range of real-world use cases, the Weather Routing Tool should provide the option to optimize ship speed. This could be along a fixed route or simultaneous with the route geometry.
                Genetic algorithm
                The implementation of the genetic algorithm is still very basic. Possible improvements include the generation of the initial population and the strategies for crossover and mutation. Moreover, a multi-objective optimization could be implemented.
                General consumption model
                An important aspect of the Weather Routing Tool is the underlying (fuel) consumption model. The best results can generally be obtained by using a consumption model which is developed specifically for a ship, e.g. based on hydrodynamic modeling or machine learning models. However, developing such specific models is cumbersome and restricts the applicability of the tool. Thus, having a general consumption model which only requires a few characteristics of a ship (e.g. type of vessel, length, breadth, displacement) would be a great improvement. The model should have reasonable accuracy. As this feature includes research aspects and can only be successfully developed with the necessary background knowledge, interested candidates have to provide a clear plan of their approach.
                The features can be implemented in different ways. How they are implemented is up to the candidate and might include deterministic, machine learning or AI methods.

                Code Challenge
                New ship class:

                Implement a new ship class
                It should inherit from the Boat base class
                The get_ship_parameters method has to be implemented; it should return a “synthetic” fuel rate which depends on at least one environmental parameter (e.g. wave height)
                Make sure the fuel rates (kg per second) are within a reasonable value range. Besides the weather conditions, typical fuel rates also depend on the ship size, type (e.g. container ship, tanker, fishing vessel) and speed.
                The choice of the considered environmental parameters and the type of the function is free
                You can take the ConstantFuelBoat class as an example
                Prepare weather conditions
                Options:
                Create your own synthetic weather conditions
                Download actual historical or forecast data from public portals (Copernicus, NOAA, …). You can use the Python package maridatadownloader directly or indirectly by setting “DATA_MODE” to “automatic“.
                Run the Weather Routing Tool with your new ship class and a route of your free choice
                Hint: because the Python package mariPower is not publicly available, you need to comment or delete the corresponding lines in ship.py.
                Configuration:
                Set “ALGORITHM_TYPE” to “isofuel”
                Provide the expected results for review
                Mandatory:
                Final route as GeoJSON file
                Python code of new ship class
                Optional:
                Log file (info.log)
                Snapshots of routing steps (WRT_FIGURE_PATH)
                Used weather data
                Community and Code License
                MIT License

                Mentors
                Martin Pontius (m.pontius @52north.org), Katharina Demmich (k.demmich @52north.org)

                Project Duration
                The duration of the project is estimated at 175 hours. An extension is possible.

                TBD

                Cloud Native OGC SensorThings API 2
                enviroCar
    totalCharacters_of_ideas_content_parent: 10019
    totalwords_of_ideas_content_parent: 1397
    totalTokenCount_of_ideas_content_parent: 2059
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/52north-spatial-information-research-gmbh/
    idea_list_url: https://52north.org/outreach-dissemination/google-summer-of-code/project-ideas/


  - organization_id: 2
    organization_name: AFLplusplus
    no_of_ideas: 4
    ideas_content: |
      Proposal 1: Tool for Automated generic/bounds simplification
        Create a (general, not LibAFL-specific) rust tool to simplify/minimze bounds

        Description
        As commented by many users and maintainers of LibAFL, our codebase is absolutely full of complicated generics. We use these to allow for structured and statically-checked compatibility between various components provided in our codebase, and is a critical part of how LibAFL is structured.

        Unfortunately, these can be very difficult to maintain. Our goal is to develop a tool capable of assisting developers in this maintenance process.

        Please check out issue #2868 for more details.

        Expected Outcomes
        A tool that works on any rust code, tries to minimize the used bounds, and fixes the code

        Skills Expected
        Rust
        A good understanding of Generics and the Rust Type system
        Possible Mentors
        @addisoncrump
        @tokatoka
        Expected size of the project
        The project is expected to take either 175 or 350 hours.

        Difficulty Rating
        The overall difficulty of this project is expected to be medium.
        ~~~~~~~~~~
        Proposal 2: Adapt qemuafl Frontend to LibAFL QEMU
        The project consists of adapting the frontend of qemuafl, the AFL++'s QEMU fork, with LibAFL QEMU.

        Description
        The end goal of this project would be to run fuzzers built for qemuafl while using LibAFL QEMU as the backend, in a retrocompatible way.
        A draft PR is already available and can be used as a starting point by the student.
        Ideally, the student would measure the performance (in terms of exec/s and coverage) of the new qemuafl adaptation with some fuzzers to evaluate how the final implementation compares with the reference.

        Expected Outcomes
        In short, we expect the student to make the new frontend work for most fuzzers developed for qemuafl while maintaining (at least) similar performance.

        See #1983 for an initial implementation that still lacks features.

        The main tasks the student would have to perform are the following:

        Speak the AFL++ forkserver protocol (check the draft PR).
        Add TCG caching to the LibAFL QEMU forkserver
        Use LibAFL QEMU snapshots where possible
        Add as many env variable features as possible
        Skills Expected
        We expect the student to:

        have a strong background in the Rust and C languages.
        be familiar with fuzzing.
        ideally, have some experience using AFL++ and / or LibAFL.
        ideally, have prior experience with the QEMU project.
        Possible Mentors
        The possible mentors for this project are:

        @domenukk
        @rmalmain
        Expected size of the project
        The project is expected to take either 175 or 350 hours.

        Difficulty Rating
        The overall difficulty of this project is expected to be medium.

        Original post
        This proposition is mostly an adaptation of issue #2964.
        ~~~~~~~~~~
        Proposal 3: Network Emulation for LibAFL_QEMU
        Implement syscall emulation for filesystem and network in libafl_qemu.

        Description
        The student must implement something similar to preeny and FitM to hook the network API and an emulator filesystem that can be snapshot-restored always hooking the syscall in libafl_qemu user mode

        Expected Outcomes
        A working network emulation layer for LibAFL_QEMU

        Required Skills
        Good understanding of Rust, C, system programming
        Ideally: prior knowledge in emulators and fuzzing
        Difficulty Rating
        The overall difficulty of this project is expected to be medium.

        Possible mentors
        @domenukk
        @rmalmain
        Expected size of the project
        The project is expected to take either 175 or 350 hours, depending on details
        ~~~~~~~~~~
        Proposal 4: Remote Worker Stage
        Mutations and execution of a Stage is always on the machine LibAFL runs at. For very slow targets it may be beneficial to offload the actual executions to stateless worker.

        Description
        We could add a RemoteWorkerLauncherStage that builds n work packages, each including a next scheduled corpus entry, all metadata for this Testcase, the current feedback state, as well as additional random corpus entries for splicing.
        The work package should then be posted to Redis or some other queue db (very much like celery, whatever a rust alternative is).
        After the execution, the results should be collected in an extra stage

        Expected Outcome:
        The implementation and a set of working examples, including:
        LibAFL Workers / RemoteWorkerLauncherStage + RemoteWorkerCollectorStage

        Required Skills
        Rust
        Prior knowledge in distributed computing and/or fuzzing are a plus
        Difficulty Rating
        easy to medium

        Possible mentors
        @domenukk
        @tokatoka
        @addisoncrump
        Length
        175 hours
    totalCharacters_of_ideas_content_parent: 4418
    totalwords_of_ideas_content_parent: 600
    totalTokenCount_of_ideas_content_parent: 1003
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/aflplusplus/
    idea_list_url: https://github.com/AFLplusplus/LibAFL/issues/2992

  - organization_id: 3
    organization_name: AOSSIE
    no_of_ideas: 13
    ideas_content: |
      Agora Blockchain
        Project Type: Medium
        Description:
        Agora Blockchain is a decentralized voting platform designed to enhance electoral integrity and accessibility. It enables transparent, tamper-proof voting through smart contracts, leveraging Chainlink CCIP for cross-chain functionality. Agora ensures fair participation and trust in election results by eliminating centralized control and providing a verifiable, immutable ledger of votes.

        Key features include:

        Multi-algorithm voting: Supports different voting mechanisms like ranked choice, quadratic voting, and stake-based voting.
        Cross-chain voting: Uses Chainlink CCIP to enable voting across multiple blockchains.
        Gas-efficient smart contracts: Optimized Solidity contracts reduce transaction costs.
        Decentralized governance: Community-driven elections and decision-making.
        User-friendly interface: Built with Next.js, Wagmi, and MetaMask for seamless interaction.
        Expected Outcomes:
        Smart Contract Enhancements:

        Implement private elections for confidential voting.
        Further optimize election factory contracts for gas efficiency.
        Cross-Chain Expansion:

        Extend Chainlink CCIP integration to support multiple blockchains.
        Frontend & dApp Integration:

        Build an intuitive UI using Next.js and Wagmi.
        Ensure smooth wallet connectivity and real-time vote updates.
        Analytics & Insights:

        Develop a real-time dashboard for election statistics.
        Track voter participation and engagement metrics.
        Required Skills:
        Solidity
        Hardhat
        Chainlink CCIP
        Next.js
        MetaMask
        Wagmi
        TailwindCSS
        Zustand
        Mentors:
        Ronnie

        ~~~~~~~~~~

        BabyNest
        Project Type: Large
        Description:
        Pregnancy is a life-changing journey filled with crucial medical appointments, tests, and healthcare decisions. However, expecting parents often struggle to keep track of these milestones, which can lead to missed appointments and added stress. Studies show that adherence to prenatal checkups directly impacts pregnancy outcomes, yet there is no universally accessible tool to assist parents in navigating healthcare requirements based on their country and trimester.

        BabyNest is designed to solve this problem through a minimalist React Native app integrated with an AI-powered assistant. This intelligent assistant acts as a personal pregnancy planner and guide, ensuring that expecting parents stay informed, organized, and stress-free.

        Users can benefit from features such as:

        Automated tracking of trimester-specific medical appointments
        Country-specific healthcare requirement notifications
        Offline access to pregnancy care guidelines
        AI-powered personalized recommendations and reminders
        Expected Outcomes:

        Mobile application built with React Native for cross-platform support
        AI agent integration for intelligent pregnancy milestone scheduling, reminders and tracking
        Offline-first architecture with local storage of healthcare guidelines
        Required Skills:

        Frontend Development (React Native)
        Backend Development (Node.js, FastAPI)
        AI and NLP (Python, LangChain)
        Database Management (SQLite, Pinecone)
        Mentors: Bhavik Mangla

        ~~~~~~~~~~
        DebateAI
        Project Type: Large
        Description:
        DebateAI is an interactive, AI-enhanced debate game platform designed to improve users communication skills through structured competitive debates. Users can engage in real-time debates against both human opponents and AI-driven challengers on a wide range of real-world topics. The platform mimics formal debate competition structures, making it an effective practice and competitive tool.

        Expected Outcomes:
        User vs. User Debates:

        Real-time interaction using WebSockets and WebRTC for audio, video, and text communication.
        Structured debate formats with timed rounds, including opening statements, rebuttals, cross-examinations, and closing arguments.
        User vs. AI Debates:

        AI-driven opponents using LLMs to generate realistic counterarguments and adapt to user inputs.
        User Management and Profiles:

        Secure authentication and access control.
        Personal dashboards to track debate history and manage settings.
        Elo rating system for matchmaking and ranking users.
        Custom Debate Spaces:

        Users can create private rooms to debate on topics of their choice.
        Platform Enhancement & Codebase Refactoring:

        Refactor the existing codebase for better maintainability, scalability, and performance.
        Improve real-time communication efficiency and backend services.
        Required Skills:
        ReactJS
        TypeScript
        GoLang
        Python
        Databases
        LLMs
        Mentors:
        Bruno Keshav


        ~~~~~~~~~~
        Devr.AI
        Project Type: Large
        Description:
        Devr.AI is an AI-powered Developer Relations (DevRel) assistant designed to seamlessly integrate with open-source communities across platforms like Discord, Slack, GitHub, and Discourse. It acts as a virtual DevRel advocate, helping maintainers engage with contributors, onboard new developers, and provide real-time project updates.

        By leveraging LLMs, knowledge retrieval, and workflow automation, the assistant enhances community engagement, simplifies contributor onboarding, and ensures open-source projects remain active and well-supported.

        Expected Outcomes:
        AI-Driven Contributor Engagement

        Automates interactions, welcomes new contributors, and guides them through onboarding.
        Automated Issue Triage & PR Assistance

        Helps maintainers prioritize issues and assists contributors in resolving them efficiently.
        Knowledge Base & FAQ Automation

        Provides instant answers to common queries, reducing repetitive maintainer workload.
        AI-Powered Community Analytics

        Tracks engagement metrics, identifies active contributors, and generates insights.
        Required Skills:
        GenAI
        Supabase
        FastAPI
        Integrations:
        Discord
        Slack
        GitHub
        Mentors:
        Chandan


        ~~~~~~~~~~
        DocPilot
        Project Type: Large
        Description:
        Build a new age EMR application using conversational AI at its best. Existing EMR solutioning is Age-old! Doctors resist the overwhelming software which is high on costs and difficult to operate. Last innovation was made in 1990's. DocPilot listens to the whole consultation conversation between a doctor and patient, and generates a prescription for the doctor to just sign, print and save digitally.

        The app should be able to separate out things like symptoms, diagnosis, medications and tests from the conversation it listens to. These are just the basic requirements. Research more on OPD appointments and include them in our solutioning.

        Expected Outcomes:
        Conversational AI-powered EMR that listens and auto-generates prescriptions.
        Eliminates outdated, complex, and costly software for doctors.
        Affordable and easy to use, reducing resistance from medical professionals.
        Extracts symptoms, diagnosis, medications, and tests from conversations.
        Allows doctors to review, sign, print, and save prescriptions digitally.
        Integrates OPD appointment management for a seamless experience.
        A modern solution replacing decades-old EMR systems.
        Required Skills:
        Flutter
        AI
        Appwrite
        Mentors:
        Jaideep

        ~~~~~~~~~~

        EduAid
        Project Type: Medium
        Description:
        EduAid is an AI-driven tool designed to enhance online learning by generating quizzes from educational content, helping students improve retention and engagement. Currently available as a browser extension, we aim to expand it into a full-fledged platform with a website, optimized model pipelines, and better system performance.

        Our current model supports difficulty-controlled quizzes for short-answer and multiple-choice questions (MCQs). We plan to extend this functionality to other formats, including fill-in-the-blanks, boolean, and match-the-following, by improving our models for diverse question generation. Additionally, we seek to integrate EduAid with other educational platforms to make it a seamless part of the learning ecosystem.

        Expected Outcomes:
        Fully deploy the EduAid browser extension and website.
        Optimize model pipelines for better accuracy and response time.
        Improve system performance for a smoother user experience.
        Expand difficulty-controlled question generation to new formats.
        Enhance UI/UX for better usability.
        Integrate with other educational platforms for wider adoption.
        Required Skills:
        Frontend Development
        Backend Development
        PyTorch & NLP
        System Design & Architecture
        Mentors:
        Aditya Dubey


        ~~~~~~~~~~
        Ell-ena
        Project Type: Large
        Description:
        Ell-ena is an AI-powered product manager that automates task management by creating to-do items, tickets, and transcribing meetings while maintaining full work context. It is input-agnostic and features a chat interface where users can interact naturally.

        Users can ask Ell-ena to perform tasks such as:

        Create a ticket to work on the dark mode feature.
        Add a to-do list item for my math assignment.
        The AI understands the context and adds relevant details automatically. Advanced algorithms like Graph RAG can be leveraged for efficient context retrieval and decision-making.

        Expected Outcomes:
        AI-powered system that generates tasks, tickets, and meeting transcriptions.
        Seamless chat-based interface for intuitive user interactions.
        Context-aware automation to enrich task details automatically.
        Implementation of Graph RAG or similar techniques for intelligent processing.
        Scalable backend to support real-time task creation and management.
        Required Skills:
        ReactJS / NextJS
        NodeJS / Any backend tech stack
        AI / NLP
        Graph RAG
        Mentors:
        Jaideep


        ~~~~~~~~~~

        Inpact
        Project Type: Large
        Description:
        Inpact is an AI-powered creator collaboration and sponsorship matchmaking platform designed to connect content creators, brands, and agencies through data-driven insights. This open-source platform enables influencers to discover relevant sponsorship deals, collaborate with like-minded creators, and optimize brand partnerships.

        By leveraging GenAI, audience analytics, and engagement metrics, Inpact ensures highly relevant sponsorship opportunities for creators while maximizing ROI for brands investing in influencer marketing.

        Expected Outcomes:
        AI-Driven Sponsorship Matchmaking

        Automatically connects creators with brands based on audience demographics, engagement rates, and content style.
        AI-Powered Creator Collaboration Hub

        Facilitates partnerships between creators with complementary audiences and content niches.
        AI-Based Pricing & Deal Optimization

        Provides fair sponsorship pricing recommendations based on engagement, market trends, and historical data.
        AI-Powered Negotiation & Contract Assistant

        Assists in structuring deals, generating contracts, and optimizing terms using AI insights.
        Performance Analytics & ROI Tracking

        Enables brands and creators to track sponsorship performance, audience engagement, and campaign success.
        Required Skills:
        ReactJS
        GenAI
        Supabase
        FastAPI
        Mentors:
        Chandan

        ~~~~~~~~~~
        Monumento
        Project Type: Large
        Description:
        Monumento is an AR-integrated social app that transforms how you connect with the world’s most iconic landmarks. Through Monumento, you can check in to popular monuments, explore famous sites, and discover new people, all within a social platform dedicated to cultural and historical experiences. Whether you're a traveler or a history enthusiast, Monumento offers an immersive way to engage with the world’s most treasured locations.

        Expected Outcomes:
        Improved UI responsiveness

        Improve the app's responsiveness across different devices and screen sizes.
        Ensure a seamless user experience on various platforms.
        Better social system

        Improve the social aspect of the app by improving the feed and user profiles and the ability to interact with other users.
        Introduce new features like events, communities to keep users engaged
        Make Popular Monumnets Dynamic

        Introduce a dynamic system where popular monuments can be updated with new information and images by the users.
        Allow users to add new monuments to the app and make them available for users to check in to.
        Itineray

        Introduce a itinerary feature to help users plan their trips and discover new places.
        Allow users to save their favorite monuments and create personalized itineraries.
        Required Skills:
        Flutter
        Appwrite/Pocketbase/Supabase
        Generative AI
        ARCore/ARKit
        UI/UX Design
        Mentor:
        Mohammed Mohsin

        ~~~~~~~~~~

        Neurotrack
        Project Type: Medium
        Description:
        Neurotrack is an AI-powered platform designed for schools and therapy centers to detect, assess, and manage neurodevelopmental conditions like Autism, ADHD, and learning difficulties. By automating assessments, personalized education plans, and therapy tracking, it empowers educators, therapists, and parents to provide more effective, data-driven support.

        Expected Outcomes:
        AI-Powered Student Grouping

        Identifies patterns and groups students with similar needs for tailored interventions.
        Automated Individualized Education Plans (IEPs)

        Creates personalized learning strategies with AI-driven recommendations.
        Digital Assessments

        Conducts efficient, research-backed evaluations to track progress.
        Real-Time Reports & Insights

        Provides actionable data for educators, therapists, and parents.
        Comprehensive Therapy Tracking

        Logs sessions, progress, and improvements over time.
        Parent Support Assistant

        AI-driven chat support for guidance and resource recommendations.
        Seamless Scheduling

        Simplifies session planning for educators and therapists.
        Required Skills:
        GenAI
        Supabase/Appwrite
        Flutter
        Mentors:
        Mohsin
        ~~~~~~~~~~
        Perspective
        Project Type: Large
        Description:
        In today's digital landscape, personalized content algorithms and social media feeds often create echo chambers of various news and different perspectives and narratives. Users are repeatedly exposed to viewpoints confirming their beliefs. This reinforcement of confirmation bias leads to increased polarization and limits critical thinking.

        The Perspective app tackles the issue of echo chambers and confirmation bias by actively presenting users with well-researched, alternative viewpoints alongside their regularly consumed content. It analyzes the current narrative of a news article, social media post, or online discussion, then curates counterarguments from credible sources. This exposure encourages critical evaluation and helps users see beyond the single perspective they might be constantly fed, ultimately fostering a more balanced and nuanced understanding of complex facts. You don't need to rely on truncated news, get complete facts.

        Users can benefit from features such as:

        Counter-perspective: Instantly see counterarguments and narration of why other perspective.
        Reasoned Thinking: The tool will provide a counter-narrative of the same fact with strongly connected facts.
        Updated Facts: With the help of context-aware LLMs, we will provide the latest facts and counter-facts.
        Seamless Integration: Works with news, blogs, and social media applications.
        Real-Time Analysis: You don't need to wait for any author, make Perspective your companion for immediate insights as you browse.
        Expected Outcomes:

        Less Bias in narratives: Break out of echo chambers.
        Wider Perspectives: Broaden your understanding of the news you are watching.
        Better Discourse: More balanced discussions.
        Sharper Analysis: Improved critical thinking and decreased your mind's polarisation.
        Required Skills:

        Frontend Development (ReactJS)
        Backend Development (Python, FastAPI)
        AI and NLP (Python, LangChain, Langgraph, Prompt Engineering)
        Database Management (Any VectorDB)
        Mentors: Manav Sarkar

        ~~~~~~~~~~

        Pictopy
        Project Type: Medium
        Description:
        Pictopy is currently built using Tauri, relying on Rust, but it comes with platform-specific dependencies that make it difficult to containerize and ship. Electron has been considered as an alternative, but issues with rendering local machine photos and bypassing security have caused challenges in the past. This has led to difficulty in onboarding new contributors as many give up during the setup process, resulting in fewer active contributors.

        The backend has been stable but stagnant and could use refactoring and design enhancements to improve its growth and functionality. While the backend is working without issues, there is potential for improvement and future scaling.

        Expected Outcomes:
        Rework the frontend to explore other options that can simplify setup and containerization.
        Address issues related to Electron, including photo rendering and security bypassing.
        Increase contributions from new developers by simplifying the setup process.
        Refactor and enhance the backend for better growth and scalability.
        Provide design improvements to the backend for smoother development and future expansions.
        Required Skills:
        Rust
        Electron
        Backend Development
        Frontend Development
        Mentors:
        Pranav Aggarwal
        ~~~~~~~~~~
        Resonate
        Project Type: Medium
        Description:
        Resonate is an open-source social voice platform designed to enable real-time audio interactions, storytelling, and voice-based social networking. The project is built with a strong focus on open collaboration, accessibility, and innovation in voice communication. Whether it's live discussions, pair chats, or immersive story experiences, Resonate is designed to put voice at the center of social engagement.

        Expected Outcomes:
        Expanded Audio Story Marketplace

        Develop a fully-fledged marketplace for audio stories, allowing users to create, browse, and follow creators.
        Implement profile pages with a follower system, showcasing user content and social interactions.
        User & Creator Search Functionality

        Enhance the explore page by adding user search functionality.
        Enable users to follow creators, view their profiles, and stay updated on their latest audio stories.
        Friend System for Personal Communication

        Implement a friend request and acceptance system.
        Enable direct personal chats and voice calls between friends.
        Improved Pair Chat Experience

        Introduce a lobby system where users can see the number of people waiting before joining a pair chat.
        Improve UI/UX to enhance user engagement and interaction.
        Required Skills:
        Flutter
        Appwrite
        LiveKit
        WebRTC
        UI/UX Design
        Mentor:
        Aarush Acharya
    totalCharacters_of_ideas_content_parent: 17886
    totalwords_of_ideas_content_parent: 2039
    totalTokenCount_of_ideas_content_parent: 3492
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/aossie/
    idea_list_url: https://aossie.org/ideas

  
  - organization_id: 4
    organization_name: API Dash
    no_of_ideas: 10
    ideas_content: |

          1. DashBot
          Related Issue - #621

          Develop DashBot - the AI assistant for API Dash which supercharges developer productivity by helping developers automate tedious tasks, follow best practices, interact & obtain contextual suggestions, all via natural-language input. DashBot must be designed in a modular and extensible manner and provide the following list of features (suggestive, not exhaustive):

          Explain responses & identify any discrepancy
          Debug requests based on Status codes & Error messages
          Generate API documentation
          Understand API and generate tests
          Generate plots & visualizations for API responses along with ability to customize
          Generate API integration frontend code for frontend frameworks like React, Flutter, etc.
          For each of the tasks you are also required to prepare benchmark evaluations so that it is easier for end users to choose the right backend LLM.

          Skills: AI, Agent, LLM Evaluation, Testing, Python, Dart, Flutter
          Difficulty: Medium-High
          Length: 175 hours

          ~~~~~~~~~~

          2. AI Agent for API Testing & Tool Generation
          Related Issue - #620

          Develop an AI Agent which leverages the power of Large Language Models (LLMs) to automate and enhance the process of testing APIs. Also, simplify the process of converting APIs into structured tool definitions to enable seamless integration with popular AI agent frameworks like crewAI, smolagents, pydantic-ai, langgraph, etc.

          Traditional API testing involves manually crafting requests, validating responses, and writing test cases. However, AI Agents can significantly streamline this process by generating test cases, validating API responses against expected outputs, and even suggesting improvements based on API documentation. Developers can describe test scenarios in natural language, and the agent can automatically generates API requests, parameter variations, and edge cases. It can also interpret API responses, checking for correctness, consistency, and performance benchmarks. This reduces manual effort while increasing coverage and efficiency, making API testing smarter and more efficient.

          You are also required to prepare benchmark dataset & evaluations so that the right backend LLM can be selected for the end user.

          Skills: AI, Agent, LLM Evaluation, Testing, Python, Dart, Flutter
          Difficulty: Medium-High
          Length: 175 hours

          ~~~~~~~~~~

          3. API Explorer
          Related Issue - #619

          This project is designed to enhance the API Dash user experience by integrating a curated library of popular and publicly available APIs. This feature allows users to discover, browse, search, and directly import API endpoints into their workspace for seamless testing and exploration. Developers can access pre-configured API request templates, complete with authentication details, sample payloads, and expected responses. This eliminates the need to manually set up API requests, reducing onboarding time and improving efficiency. APIs spanning various domains—such as AI, finance, weather, and social media—are organized into categories, making it easy for users to find relevant services. You are required to develop the entire process backend in the form of an automation pipeline which parses OpenAPI/HTML files, auto-tag it to relevant category, enrich the data, create templates. You can also add features such as user ratings, reviews, and community contributions (via GitHub) to ensure accurate and up-to-date resources.

          Skills: UX Design, OpenAPI, Automation, Dart, Flutter
          Difficulty: Low-Medium
          Length: 175 hours

          ~~~~~~~~~~

          4. AI API Eval Framework
          Related Issue - #618

          Develop an end-to-end AI API eval framework and integrate it in API Dash. This framework should (list is suggestive, not exhaustive):

          Provide an intuitive interface for configuring API requests, where users can input test datasets, configure request parameters, and send queries to various AI API services
          Support evaluation AI APIs (text, multimedia, etc) across various industry task benchmarks
          Allow users to add custom dataset/benchmark & criteria for evaluation. This custom scoring mechanisms allow tailored evaluations based on specific project needs
          Visualize the results of API eval via tables, charts, and graphs, making it easy to identify trends, outliers, and performance variations
          Allow execution of batch evaluations
          Work with both offline & online models and datasets
          Skills: AI, Evaluations, Dart, Python, Flutter
          Difficulty: Medium-High
          Length: 175 hours

          ~~~~~~~~~~

          5. API Testing Support for - WebSocket, SSE, MQTT & gRPC
          Related Issue - #15 #115 #116 #14

          Testing WebSocket, MQTT (Message Queuing Telemetry Transport), and SSE (Server-Sent Events) protocols is crucial for ensuring the reliability, scalability, and security of real-time communication systems. Whereas, gRPC (Remote Procedure Call) facilitates efficient communication between distributed systems using Protocol Buffers (protobuf) as its interface definition language (IDL) and offers features such as bi-directional streaming, authentication, and built-in support for load balancing and health checking. Each of these API protocols/styles serves different purposes and is utilized in various applications ranging from finance to web applications to IoT (Internet of Things) devices. The objective of this project is to design the architecture of the core library, understand the specs & implement the support for testing, visualization & integration code generation of these APIs in API Dash.

          Skills: Understanding Specs/Protocols, UX Design, Dart, Flutter
          Difficulty: Medium-High
          Length: 350 hours

          ~~~~~~~~~~

          6. AI UI Designer for APIs
          Related Issue - #617

          Develop an AI Agent which transforms API responses into dynamic, user-friendly UI components, enabling developers to visualize and interact with data effortlessly. By analyzing API response structures—such as JSON or XML—the agent automatically generates UI elements like tables, charts, forms, and cards, eliminating the need for manual UI development. One can connect an API endpoint, receive real-time responses, and instantly generate UI components that adapt to the data format. It must also support customization options, allowing developers to configure layouts, styles, and interactive elements such as filters, pagination, and sorting. Finally, users must be able to easily export the generated UI and integrate it in their Flutter or Web apps.

          Skills: AI, UX, Parsing, XML, JSON, Python, Dart, Flutter
          Difficulty: Easy-Medium
          Length: 90 hours

          ~~~~~~~~~~

          7. API Testing Suite, Workflow Builder, Collection Runner & Monitor
          Related Issues - #96 #100 #120

          The objective of this project to design and implement an API testing & workflow builder suite which allows various types of API testing:

          Validation Testing: Verify that the API meets functional and business requirements. Automate the testing & validation of responses received from an API against predefined expectations (assertions), Schema validations, etc.
          Integration Testing: Checks proper interaction between different APIs
          Security Testing: Identifies vulnerabilities and safeguards data
          Performance Testing: Measures speed, responsiveness, and stability under varying loads
          Scalability Testing: Evaluates the system's ability to grow with demand
          Users should be able to easily create collections of APIs for testing. It will also be useful to provide a API workflow builder (a drag and drop environment) to create API workflows and chain requests. The UI must allow users to execute this collection of API requests and test it in a systematic and automated manner (Collection Runner) and finally monitor the results.

          Skills: UI/UX Design, Automation, Testing, Dart, Flutter
          Difficulty: Medium-High
          Length: 350 hours

          ~~~~~~~~~~

          8. Adding Support for API Authentication Methods
          Issue - #609

          Add support for various API authentication methods:

          Basic authentication: Sending a verified username and password with API request Add API Auth: Basic authentication #610
          API key: Sending a key-value pair to the API either in the request headers or query parameters Add API Auth: API key #611
          Bearer token: Authenticate using an access key, such as a JSON Web Token (JWT) Add API Auth: Bearer token #612
          JWT Bearer: Generate JWT bearer tokens to authorize requests Add API Auth: JWT Bearer #613
          Digest Auth: Client must send two requests. First request sent to the server receives a nonce value, which is then used to produce a one-time-use hash key to authenticate the request Add API Auth: Digest Auth #614
          OAuth 1.0 Add API Auth: OAuth 1.0 #615
          OAuth 2.0 Implement OAuth 2.0 authentication #481
          Skills: Authentication, Dart, Flutter
          Difficulty: Low-Medium
          Length: 90 hours

          ~~~~~~~~~~

          9. mem0 for Dart
          mem0 is the goto memory layer for developing personalized AI Agents in Python. It offers comprehensive memory management, self-improving memory capabilities, cross-platform consistency, and centralized memory control. It leverages advanced LLMs and algorithms to detect, store, and retrieve memories from conversations and interactions. It identifies key information such as facts, user preferences, and other contextual information, smartly updates memories over time by resolving contradictions, and supports the development of an AI Agent that evolves with the user interactions. When needed, mem0 employs a smart search system to find memories, ranking them based on relevance, importance, and recency to ensure only the most useful information is presented.

          Currently, we lack this memory layer in Flutter AI applications and your task is to port mem0 to Dart.

          Skills: AI, Database, Data Structures, Python, Dart, Flutter
          Difficulty: Medium-High
          Length: 175 hours

          ~~~~~~~~~~    

          10. API Dash Feature Improvements
          We always believe in improving our core features to help the end user. A suggestive list of features that can be improved are:

          Adding pre-request script/post request script Pre-request and post-request for api collections #557
          Importing from/Exporting to OpenAPI/Swagger specification Importing Requests from OpenAPI Specification file #121
          Adding support for more content types in request Support for application/x-www-form-urlencoded Content-Type as body type formdata currently only supports multipart/form-data #337 Support File as Request Body #352
          JSON body syntax highlighting, beautification, validation - Enhance Request Body Editor: JSON formatting, syntax highlighting, validation and other features #22 Add option to automatically/manually beautify JSON request body #581 Add syntax highlighting for JSON request body #582 Add validation for JSON request body #583 Add environment variable support in request body #590 Env. Variable Support for Text request body #591 Env. Variable Support for JSON request body #592 Env. Variable Support for Form request body #593
          Support for comments in JSON body Support comments in JSON request body #599
          Reading environment variables from OS environment Reading environment variables directly from OS environment #600
          Adding color support for environments (like RED for prod, GREEN for dev) Adding color support for environments #601
          Tab & whitespace settings
          Notification when new app updates are available [feat] in-app update check #373
          Better GraphQL editor
          Beautify and expand/collapse feature for GraphQL query
          Allow inspecting GraphQL schema
          Support for GraphQL variables, fragments, mutation, subscription, etc.
          More widget & integration tests
          More code coverage
          Skills: UX Design, Dart, Flutter
          Difficulty: Easy-Medium
          Length: 175 hours
    totalCharacters_of_ideas_content_parent: 12602
    totalwords_of_ideas_content_parent: 2654
    totalTokenCount_of_ideas_content_parent: 2473
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/api-dash/
    idea_list_url: https://github.com/foss42/apidash/discussions/565


  
  - organization_id: 5
    organization_name: AboutCode
    no_of_ideas: 10
    ideas_content: |
        PURLdb - DeadCode: track End-Of-Life code
        Code Repositories: https://github.com/aboutcode-org/purldb

        Description:

        Eventually old code goes unmaintained and dies. The goal of this project are:

        To add data structures, models, and APIs in purldb to track end-of-life code and in general package and projects activities
        To improve purl coverage at endoflife.date, see https://github.com/endoflife-date/endoflife.date/issues/763
        To import and sync data from projects such as https://github.com/endoflife-date/endoflife.date
        To design a module that can detect when
        a project is turning end-of-life (using the above)
        a project is unmaintained (use metrics from scorecard/other tools)
        Note that on the endoflife.date side, we need to help improve PURL coverage of the database there, as this would be key to integrate with purldb. There

        Priority: High

        Size: Large

        Difficulty Level: Advanced

        Tags:

        Python
        Django
        PostgreSQL
        EOL
        End of life
        Mentors:

        @pombredanne
        @JonoYang
        @AyanSinhaMahapatra
        Related Issues:

        https://github.com/aboutcode-org/purldb/issues/42
        https://github.com/aboutcode-org/vulnerablecode/issues/722
        https://github.com/endoflife-date/endoflife.date/issues/763

        ~~~~~~~~~~
        PURLdb - PopularCode - Find and track actually used and most popular open source code
        Code Repositories: https://github.com/aboutcode-org/purldb

        Description:

        There are between 100 and 200 million open source projects and repos out there. Not all of them are equal. Some are much more useful than others, and some could be safely ignored. For instance, the linux kernel is more important, used and popular than a 1st year computer student school assignment project. The goal of this project is to determine when a project is popular and what are the most popular projects. If we do not know what code is used, we can spend a lot of resources to index less used code.

        There are some simple approaches to this, using available statistics for downloads or Github stars, but that is not satisfying alone.

        An idea would be to consider multiple factors to rank popularity and usage.

        For instance: create a (current and updated) graph of dependencies and compute something like a pagerank but for packages
        Then create with a metric on the freshness of the code like when last release and how much downloaded or based on git activity (excluding bots). This would grow for used code and decay for declining packages
        Then combine this with the dependencies "connectedness"
        Or, just a use the graph connections and no download stats, just a giant graph on top of purldb

        Or something like this:

        Finding strongly connected components
        Relate packages ignoring versions
        Find most connected
        Discount distant connections, boost closest
        Apply decay based on version freshness or git activity
        The approach would be to start small with a single ecosystem as PoC and then extend this to all packages types.

        Ideally, this should be exposed in PurlDB API and integrated in data collection operations.

        Priority: High

        Size: Large

        Difficulty Level: Advanced

        Tags:

        Python
        Django
        PostgreSQL
        Popularity
        Mentors:

        @pombredanne
        @JonoYang
        @AyanSinhaMahapatra

        ~~~~~~~~~~
        VulnerableCode project ideas
        There are two main categories of projects for VulnerableCode:

        A. COLLECTION: this category is to mine and collect or infer more new and improved data. This includes collecting new data sources, inferring and improving existing data or collecting new primary data (such as finding a fix commit of a vulnerability)

        B. USAGE: this category is about using and consuming the vulnerability database and includes the API proper, the GUI, the integrations, and data sharing, feedback and curation.

        VulnerableCode: Process unstructured data sources for vulnerabilities (Category A)
        Code Repositories:

        https://github.com/aboutcode-org/vulnerablecode
        Description:

        The project would be to provide a way to effectively mine unstructured data sources for possible unreported vulnerabilities.

        For a start this should be focused on a few prominent repos. This project could also find Fix Commits.

        Some sources are:

        mailing lists
        changelogs
        reflogs of commit
        bug and issue trackers
        This requires systems to "understand" vulnerability descriptions: as often security advisories do not provide structured information on which package and package versions are vulnerable. The end goal is creating a system which would infer vulnerable package name and version(s) by parsing the vulnerability description using specialized techniques and heuristics.

        There is no need to train a model from scratch, we can use AI models pre-trained on code repositories (maybe https://github.com/bigcode-project/starcoder?) and then fine-tune on some prepared datasets of CVEs in code.

        We can either use NLP/machine Learning and automate it all, potentially training data masking algorithms to find these specific data (this also involved creating a dataset) but that's going to be super difficult.

        We could also start to craft a curation queue and parse as much as we can to make it easy to curate by humans and progressively also improve some mini NLP models and classification to help further automate the work.

        References: https://github.com/aboutcode-org/vulnerablecode/issues/251

        Priority: Medium

        Size: Large

        Difficulty Level: Advanced

        Tags:

        Python
        Django
        PostgreSQL
        Security
        Vulnerability
        NLP
        AI/ML
        Mentors:

        @pombredanne
        @tg1999
        @keshav-space
        @Hritik14
        @AyanSinhaMahapatra
        Related Issues:

        https://github.com/aboutcode-org/vulnerablecode/issues/251

        ~~~~~~~~~~
        VulnerableCode: Add more data sources and mine the graph to find correlations between vulnerabilities (Category A)
        Code Repositories:

        https://github.com/aboutcode-org/vulnerablecode
        Description:

        See https://github.com/aboutcode-org/vulnerablecode#how for background info. We want to search for more vulnerability data sources and consume them.

        There is a large number of pending tickets for data sources. See https://github.com/aboutcode-org/vulnerablecode/issues?q=is%3Aissue+is%3Aopen+label%3A"Data+collection"

        Also see tutorials for adding new importers and improvers:

        https://vulnerablecode.readthedocs.io/en/latest/tutorial_add_new_importer.html
        https://vulnerablecode.readthedocs.io/en/latest/tutorial_add_new_improver.html
        More reference documentation in improvers and importers:

        https://vulnerablecode.readthedocs.io/en/latest/reference_importer_overview.html
        https://vulnerablecode.readthedocs.io/en/latest/reference_improver_overview.html
        Note that this is similar to this GSoC 2022 project (a continuation):

        https://summerofcode.withgoogle.com/organizations/aboutcode/projects/details/7d7Sxtqo
        References: https://github.com/aboutcode-org/vulnerablecode/issues?q=is%3Aissue+is%3Aopen+label%3A"Data+collection"

        Priority: High

        Size: Medium/Large

        Difficulty Level: Intermediate

        Tags:

        Django
        PostgreSQL
        Security
        Vulnerability
        API
        Scraping
        Mentors:

        @pombredanne
        @tg1999
        @keshav-space
        @Hritik14
        @jmhoran
        Related Issues:

        https://github.com/aboutcode-org/vulnerablecode/issues?q=is%3Aissue+is%3Aopen+label%3A"Data+collection"

        ~~~~~~~~~~
        VulnerableCode: On demand live evaluation of packages (Category A)
        Code Repositories: https://github.com/aboutcode-org/vulnerablecode

        Description:

        Currently VulnerableCode runs importers in bulk where all the data from advisories are imported (and reimported) at once and stored to be displayed and queried.

        The objective of this project is to have another endpoint and API where we can dynamically import available advisories for a single PURL at a time.

        At a high level this would mean:

        Support querying a specific package by PURL. This is not for an approximate search but only an exact PURL lookup.

        Visit advisories/package ecosystem-specific vulnerability data sources and query for this specific package. For instance, for PyPi, the vulnerabilities may be available when querying the main API. An example is https://pypi.org/pypi/lxml/4.1.0/json that lists vulnerabilities. In some other cases, we may need to fetch larger datasets, like when doing this in batch.

        This is irrespective of whether data related to this package being present in the db (i.e. both for new packages and refreshing old packages).

        A good test case would be to start with a completely empty database. Then we call the new API endpoint for one PURL, and the vulnerability data is fetched, imported/stored on the fly and the API results are returned live to the caller. After that API call, the database should now have vulnerability data for that one PURL.

        This would likely imply to modify or update importers to support querying by purl to get advisory data for a specific package. The actual low level fetching should likely be done in FetchCode.

        This is not straightforward as many advisories data source do not store data keyed by package, as they are not package-first, but they are stored by security issue. See specific issues/discussions on these importers for more info. See also how things are done in vulntotal.

        Priority: Medium

        Size: Medium/Large

        Difficulty Level: Intermediate

        Tags:

        Python
        Django
        PostgreSQL
        Security
        web
        Vulnerability
        API
        Mentors:

        @pombredanne
        @tg1999
        @keshav-space
        Related Issues:

        https://github.com/aboutcode-org/vulnerablecode/issues/1046
        https://github.com/aboutcode-org/vulnerablecode/issues/1008

        ~~~~~~~~~~
        ScanCode.io project ideas
        ScanCode.io: Create file-system tree view for project scans
        Code Repositories:

        https://github.com/aboutcode-org/scancode.io
        Description:

        When large packages/containers are scanned in scancode.io it is useful to have a tree-view to explore thorugh the file-tree for that package/container to look into scan data for a particular subset of the file-tree/directory or to research more into detections and detection issues.

        This would be something similar to what we have at scancode-workbench for example: https://scancode-workbench.readthedocs.io/en/develop/ui-reference/directory-tree.html

        I.e. we need the following features:

        To be able to toggle showing the directory contents from the directory icon
        Show nested directory contents in a tree like structure
        Have this view ideally in a pane left to the table-view of resources
        Show only info from the selected directory in the table-view of resources
        Note that we do have a ProjectCodebaseView in the projects page currently in scancode.io but this is fairly limited as it only lets you browse through the codebase one directory at a time (only shows the files/directories in one directory), and lets you navigate to directories in the current directory or the parent directory from there.

        Priority: High

        Size: Large

        Difficulty Level: Intermediate

        Tags:

        Python
        Django
        UI/UX
        File-system
        Navigation
        Mentors:

        @tdruez
        @pombredanne
        @AyanSinhaMahapatra
        Related Issues:

        https://github.com/aboutcode-org/scancode.io/issues/697

        ~~~~~~~~~~
        ScanCode.io: Add ability to store/query downloaded packages
        Code Repositories:

        https://github.com/aboutcode-org/scancode.io
        Description:

        Packages which are downloaded and scanned in SCIO can be optionally stored and accessed to have a copy of the packages which are being used for a specific product for reference and future use, and could be used to meet source redistribution obligations.

        The specific tasks would be:

        Store all packages/archives which are downloaded and scanned in SCIO
        Create an API and index by URL/checksum to get these packages on-demand
        Create models to store metadata/history and logs for these downloaded/stored packages
        Additionally support and design external storage/fetch options
        There should be configuration variable to turn this on to enable these features, and connect external databases/storage.

        Priority: Low

        Size: Medium

        Difficulty Level: Intermediate

        Tags:

        Python
        Django
        CI
        Security
        Vulnerability
        SBOM
        Mentors:

        @tdruez
        @keshav-space
        @jyang
        @pombredanne
        Related Issues:

        https://github.com/aboutcode-org/scancode.io/issues/1063


        ~~~~~~~~~~

        ScanCode.io: Update SCIO/SCTK for use in CI/CD:
        Code Repositories:

        https://github.com/aboutcode-org/scancode.io
        https://github.com/aboutcode-org/scancode-action
        Description:

        Enhance SCIO/SCTK to be integrated into CI/CD pipelines such as Github Actions, Azure Piplines, Gitlab, Jenkins. We can start with any one CI/CD provider like GitHub Actions and later support others.

        These should be enabled and configured as required by scancode configuration files to enable specific functions to be carried out in the pipeline.

        There are several types of CI/CD pipelines to choose from potentially:

        Generate SBOM/VDRs/VEX with scan results:

        Scan the repo to get all purls: packages, dependencies/requirements
        Scan repository for package, license and copyrights
        Query public.vulnerablecode.io for Vulnerabilities by PackageURL
        Generate SPDX/CycloneDX SBOMs from them with scan and vulnerability data
        License/other Compliance CI/CD pipelines

        Scan repo for licenses and check for detection accuracy
        Scan repo for licenses and check for license clarity score
        Scan repo for licenses and check compliance with specified license policy
        Check for OpenSSF scorecard data and specified policy on community health metrics
        The jobs should pass/fail based on the scan results of these specific cases, so we can have:
        a special mode to fail with error codes
        description of issues and failure reasons, and docs on how to fix these
        ways to configure and set up for these cases with configuration files
        Dependency checkers/linters:

        download and scan all package dependencies, get scan results/SBOM/SBOMs
        check for vulnerable packages and do non-vulnerable dependency resolutuion
        check for test failures after dependency upgrades and add PR only if passes
        Jobs which checks and fixes for misc other errors:

        Replaces standard license notices with SPDX license declarations
        checks and adds ABOUT files for vendored code
        We have an initial CI runner at https://github.com/nexB/scancode-action but we need to improve this with more functions, specially checking against predefined policies and failing/successful CI based on that.

        References:

        https://github.com/aboutcode-org/scancode.io/issues/599
        https://github.com/aboutcode-org/scancode.io/issues/1582
        Priority: High

        Size: Large

        Difficulty Level: Intermediate

        Tags:

        Python
        Django
        CI
        Security
        License
        SBOM
        Compliance
        Mentors:

        @pombredanne
        @tdruez
        @keshav-space
        @tg1999
        @AyanSinhaMahapatra
        Related Issues:

        https://github.com/aboutcode-org/scancode.io/issues/599

        ~~~~~~~~~~
        ScanCode Toolkit project ideas
        Have variable license sections in license rules:
        Code Repositories:

        https://github.com/aboutcode-org/scancode-toolkit
        Description:

        There are lots of variability in license notices and declarations in practice, and one example of modeling this is the SPDX matching guidelines. Note that this was also one of the major ways scancode used to detect licenses earlier.

        Support grammar for variability in license rules (brackets, no of words)
        Do a massive analysis on license rules and check for similarity and variable sections This can be used to add variable sections (for copyright/names/companies) and reduce rules.
        Support variability in license detection post-processing for extra-words case
        Add scripts to add variable sections to rules from detection issues (like bsd detections)
        Priority: Medium

        Size: Medium

        Difficulty Level: Intermediate

        Tags:

        Python
        Licenses
        LicenseDetection
        SPDX
        Matching
        Mentors:

        @AyanSinhaMahapatra
        @pombredanne
        @jyang
        @DennisClark
        Related Issues:

        https://github.com/aboutcode-org/scancode-toolkit/issues/3601

        ~~~~~~~~~~

        Mark required phrases for rules automatically using NLP/AI:
        Code Repositories:

        https://github.com/aboutcode-org/scancode-toolkit
        Description:

        Required phrases are present in rules to make sure the rule is not matched to text in a case where the required phrase is not present in the text, which would be a false-positive detection.

        We are marking required phrases automatically based on what is present in other rules and license attributes, but this still leaves a lot of rules without them. See https://github.com/aboutcode-org/scancode-toolkit/pull/3924 where we are also adding a script to add required phrases as individual rules if applicable and also adding required phrases added to other rules.

        research and choose a model pre-trained on code (StarCoder?)
        use the dataset of current SCTK rules to train a model
        Mark required phrases in licenses automatically with the model
        Test required phrase additions, improve and iterate
        Bonus: Create a minimal UI to review rule updates massively
        Priority: Medium

        Size: Medium

        Difficulty Level: Advanced

        Tags:

        Python
        ML/AI
        Licenses
        Mentors:

        @AyanSinhaMahapatra
        @tg1999
        @pombredanne
        Related Issues:

        https://github.com/aboutcode-org/scancode-toolkit/issues/2878

          
    totalCharacters_of_ideas_content_parent: 19350
    totalwords_of_ideas_content_parent: 4455
    totalTokenCount_of_ideas_content_parent: 4378
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/aboutcode/
    idea_list_url: https://github.com/aboutcode-org/aboutcode/wiki/GSOC-2025-Project-Ideas




  - organization_id: 6
    organization_name: Accord Project
    no_of_ideas: 7
    ideas_content: |
        1. Linter for Concerto
        Write a linter in TypeScript for Concerto Source files. It should make use of existing functionality to validate the Concerto DSL syntax and JSON AST of Concerto model against a set of rules. Rules should be defined in Typescript and which rules are run should be configurable. You may be able to make use of a tool like Spectral as the framework for defining our own rules over the Concerto AST (JSON).

        Expected Outcomes:
        A tool that allow users to:

        Specify the naming of declarations. E.g. all names of scalars should be in camel case.
        Specify the naming of properties, enum cases e.t.c
        Specify which language features can be used. E.g. disallow maps, disallow forward references in regex validators.
        Enforce the use of certain features. E.g. all string properties should have a length validator.
        Enforce the use of @Term decorators on all declarations and properties e.t.c
        All concepts in a namespace should extend a given concept
        All concepts in a namespace must have unique names across multiple namespaces
        Skills required/preferred:
        Algorithms, Functional programming, Back end development, NodeJS, TypeScript

        Possible Mentors:
        Jamie Shorten, Sanket Shevkar

        Expected size of project:
        175 hours (medium)

        Expected difficulty:
        Medium

        ~~~~~~~~~~

        2. Decorator Command Set JSON<->YAML Convertor
        Design and implement a convertor that would convert Decorator Command Sets JSON Objects to a much more human readable YAML format and vice-versa. Currently DCS JSON objects are very verbose to read, write and edit. With the new custom YAML format we aim to make DCS objects much more easier to read, write and edit.

        Expected Outcomes:
        A utility/method in DecoratorManager to convert DCS JSON to YAML and from YAML to JSON.
        1:1 conversion is not expected. YAML should have a custom format that is less verbose and more readable.
        Skills required/preferred:
        NodeJS, Typescript, Javascript, Basic understanding of Data Formats like JSON and YAML

        Possible Mentors:
        Sanket Shevkar

        Expected size of project:
        175 hours (medium)

        Expected difficulty:
        Medium

        ~~~~~~~~~~

        3. Accord Project Agreement Protocol
        The Accord Project Agreement Protocol (APAP) defines the protocol used between a document generation engine or contract management platform and an agreement server that provides agreement features like template management, document generation, format conversion etc.

        Expected Outcomes:
        Updated Open API specification
        Updated reference implementation for the specification
        Address (some of) open issues
        Skills required/preferred:
        NodeJS, Typescript, Javascript, REST API design

        Possible Mentors:
        Dan Selman, Niall Roche

        Expected size of project:
        350 hours (large)

        Expected difficulty:
        Medium

        ~~~~~~~~~~

        4. Specification Conformance Tests
        Our specification conformance testing is in need of an overhaul! We'd like to migrate to a robust, proven testing framework like Vitest which would support ESM, and be performant and have a new dedicated concerto package used for Concerto conformance testing. An AI tool may be useful in helping with the migration, so feel free to mention how AI could help you with this project! The goal is to have a set of tests that can be run against any Concerto implementation to assess whether it is conformant with the specification.

        Expected Outcomes:
        Migration to Vitest (or other appropriate framework)
        Consolidation of testing methodology and tooling
        New concerto package for tests, focused on conformance
        Build a set of tests for the Concerto validation rules
        Skills required/preferred:
        Node / Javascript
        Unit testing (Mocha / Jest for example)
        Behaviour driven testing (optional, Cucumber, for example)
        Possible Mentors:
        Dan Selman, Ertugrul Karademir

        Expected size of project:
        175 hours (medium)

        Expected difficulty:
        Medium

        ~~~~~~~~~~

        5. Incorporating AI into Template Playground
        Our Template Playground web application is used to help onboard users to our technologies. We'd love to make this even easier by adding AI features to make it easier to create, edit, and preview contract templates. This project will build upon the work that was carried out last year in the context of VS Code.

        Expected Outcomes:
        Allow users to upload a file and we'd use AI to convert it to an Accord Project template
        Possibly incorporate auto-complete suggestions when editing using the code editors built into the web app
        Skills required/preferred:
        ReactJS, AI tooling

        Possible Mentors:
        Diana Lease

        Expected size of project:
        350 hours (large)

        Expected difficulty:
        Medium

        ~~~~~~~~~~

        6. Testing for Code Generation Targets
        We have tools that allow users to generate code from their Concerto models, supporting several languages. We would like to introduce a way of testing this code generation that compiles code for each language we are generating.

        Expected Outcomes:
        Set of Docker images for each code generation target
        Run code gen tests within the correct image using GitHub actions, for example, generate Java code and then compile and run it using javac to ensure the generated code is correct
        Skills required/preferred:
        Systems engineering, CI/CD
        Docker, Docker compose
        GitHub actions
        Possible Mentors:
        Dan Selman, Ertugrul Karademir

        Expected size of project:
        175 hours (medium)

        Expected difficulty:
        Medium

        ~~~~~~~~~~

        7. Migration of Template Playground to use Tailwind CSS
        As mentioned previously, our Template Playground web application is used to help onboard users to our technologies. By using a popular, well-maintained CSS framework like Tailwind, we could improve performance and code maintainability.

        Expected Outcomes:
        Template Playground updated to use Tailwind CSS
        Existing UI tests updated
        Possibly other UI changes to make user experience better, more performant, and/or optimized for multiple screen sizes
        Skills required/preferred:
        ReactJS, Tailwind CSS

        Possible Mentors:
        Diana Lease

        Expected size of project:
        175 hours (medium) - 350 hours (large)

        Expected difficulty:
        Medium


          
    totalCharacters_of_ideas_content_parent: 6850
    totalwords_of_ideas_content_parent: 1663
    totalTokenCount_of_ideas_content_parent: 1391
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/accord-project/
    idea_list_url: https://github.com/accordproject/techdocs/wiki/Google-Summer-of-Code-2025-Ideas-List



  - organization_id: 7
    organization_name: Alaska 
    no_of_ideas: 15
    ideas_content: |
        [1] Automated coastline extraction for erosion modeling in Alaska.

        Mentors: Frank Witmer (fwitmer -at- alaska.edu) and Rawan Elframawy (rawann.elframawy -at- gmail.com)

        Overview: The rapidly warming Arctic is leading to increased rates of coastal erosion, placing hundreds of Alaska communities at the frontline of climate change. Understanding current rates of coastline change and accurately forecasting future changes is critical for communities to mitigate and adapt to these changes. Current modeling approaches typically use a simple linear model based solely on historical coastline positions to measure rates of change and extrapolate them into the future. In doing so, these models fail to capture the dynamic effects associated with decreasing sea ice, increasing annual wave energy, and increasing temperatures. To improve the quality of these coastal models, we need to increase the quantity of digitized coastlines, but manual photointerpretation is slow and laborious.

        Current Status: An initial model and pipeline have been developed to automatically extract coastlines from PlanetLabs imagery. An auto-download script is available to retrieve PlanetLabs imagery (3-5m spatial resolution) by specifying any timeframe, cloud coverage percentage, and geometry. Additionally, NDWI with a majority sliding window has been introduced, allowing a specific threshold for each window to improve water detection accuracy. The DeepWaterMap algorithm was originally trained with the Global Surface Water (GSW) dataset at 30 m resolution from Landsat imagery, but the model did not not work well applied to PlanetLabs imagery. We are working to re-train the model using PlanetLabs imagery automatically labeled using the NDWI thresholding method. This project extends and expands on the progress made in 2024.

        Potential areas of improvement:

        Data Expansion (Deering 2017–2019 and Beyond): Currently using data from 2017 to 2019 for Deering; we plan to include more recent data to extend the time series.
        Improved Cliff Area Segmentation: Enhance segmentation performance specifically in steep or cliff-like coastal areas.
        Handling Challenging Conditions: Improve segmentation in regions with water shadows, buildings, satellite artifacts, and other data quality issues.
        SWIR and Elevation Data Integration: Investigate combining short-wave infrared (SWIR) data and elevation data (e.g., DEMs) to further refine segmentation accuracy.
        Expected Outcomes: A finished model with high accuracy that automatically extracts a vectorized coastline representation from PlanetLabs satellite imagery. Then, the model can be applied to large amounts of imagery to model coastline changes over time.

        Required Skills: Python

        Code Challenge: Experience with multi-band satellite imagery, geospatial data processing, and machine learning.

        Source Code: https://github.com/fwitmer/CoastlineExtraction

        Discussion Forum: https://github.com/fwitmer/CoastlineExtraction/discussions

        Effort: 350 Hours

        Difficulty Level: Medium

        ~~~~~~~~~~

        [2] Support for Logarithmic Number Systems in a Deep-Learning Framework.

        Mentors: Mark Arnold (markgarnold -at- yahoo.com), Ed Chester (ed.chester -at- gmail.com), and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: The Logarithmic Number System (LNS) is an alternative to built-in Floating Point (FP), which makes multiplication and division easy at the expense of more difficult addition. Using overloaded operators, xlns provides an open-source Python library for LNS arithmetic. Interest in fabricating LNS hardware has grown since it may reduce power consumption for applications that tolerate approximate results, such as deep learning (see [1]-[5]). The problem is deep learning often relies on open-source Python frameworks (like Tensorflow or Pytorch) that are hardcoded to use FP hardware. A key feature of these frameworks is the ability to automatically compute gradients (based on the chain rule) by recording extra information about the computation stored in FP format. Such gradients are used during backpropagation training to update network weights.

        Current Status: xlns, Tensorflow and Pytorch are all interoperable with the widely-used open-source Numpy library, but xlns is not interoperable with the Tensorflow and Pytorch frameworks because both frameworks are hard coded to use built-in int or FP data internally instead of LNS.

        Expected Outcomes: The goal of this project is to provide support for a deep learning framework that uses xlns instead of FP internally (including network specification, automatic gradient, forward inference, and back-propagation training) while keeping high-level compatibility with the framework. This might be as part of xlns, or as a forked version of the chosen framework, or both. The contributor may choose either Pytorch or Tensorflow. The contributor should justify these decisions as part of the proposed design.

        Required Skills: Calculus, Python, Numpy, and either Pytorch or Tensorflow

        Code Challenge: The following three challenges illustrate the breath of issues involved. Each involves only a few lines of Python. Each involves working with both xlns and the framework. Doing all three in both Tensorflow and Pytorch might give evidence for which framework is more likely to lead to the expected outcome.

        Currently, when the data starts in xlns format, Pytorch/Tensorflow converts to FP. As part of the code challenge, we expect the contributor to provide short Python code snippets that demonstrate that if the data starts in xlns format, the computation cannot be carried out in the xlns format.

        xlns/examples/arn_generic.py is a hard-coded illustration of training a fully connected MLP with 28*28 input nodes, 100 hidden nodes and 10 output nodes using MNIST digit set. The hidden layer uses RELU and the output layer uses softmax. The FP weights for this are initialized as:

        W1 = np.array((list(np.random.normal(0, 0.1, (785, 100)))))                    
        W2 = np.array((list(np.random.normal(0, 0.1, (101, 10)))))
        Because there is an extra weight for a constant 1.0 input in each layer, the number of rows is one larger than the inputs to the layer. The example can be run with various data types, for example with xlnsnp (LNS internally implemented with int64 Numpy ufuncs):

        python3 arn_generic.py --type xlnsnp --num_epoch 7
        or more conventionally

        python3 arn_generic.py --type float --num_epoch 7
        The code challenge is to implement a similar size fully connected network (in FP) using the provided features of Pytorch or Tensorflow and compare its convergence with arn_generic.py (Note: arn_generic.py uses manual differentiation, ie, the derivative of RELU is a constant, which depends on the sign of the argument, and elementary backpropagation implements the chain rule).

        Consider LNS addition (1+2=3 and 3-1=2). The following illustrates the overloaded operator and xlnsnp internal representation (sign is LSB of the int64 value; the log portion is the rest):
        >>> import xlns as xl
        >>> x=xl.xlnsnp([2.0, 3.0])
        >>> x
        xlnsnp([xlns(1.9999999986889088) xlns(2.9999999688096786)])
        >>> x.nd
        array([16777216, 26591258])
        By default, the log portion here is given with 23 bits of precision (see help for xl.xlnssetF for details on how to lower the precision as would be useful in machine learning), which is why the log(2.0) is given as 16777216.

        >>> 2*np.int64(np.log2([2.0, 3.0])*2**23)
        array([16777216, 26591258])
        The expression with log2 double checks the answer for x in 23-bit format (with the additional *2 to make room for the sign bit). Had the +2.0 been -2.0, the representation would have been 16777217.

        >>> y=xl.xlnsnp([1.,-1.])
        >>> y
        xlnsnp([xlns(1.0) xlns(-1.0)])
        >>> y.nd
        array([0, 1])
        The above illustrates that the log(1.0)=0, and that the sign bit is one for negative values.

        >>> x+y
        xlnsnp([xlns(2.9999999688096786) xlns(1.9999999986889088)])
        >>> (x+y).nd
        array([26591258, 16777216])
        Although the Pytorch/Tensorflow frameworks don’t support LNS, LNS can be constructed from int64 and float operations (which is how xlnsnp works). In xlns/src/xlns.py, there is a function sbdb_ufunc_ideal(x,y). If you call this with the following code:

        >>> import numpy as np
        >>> def myadd(x,y):  
                  return np.maximum(x,y)+xl.sbdb_ufunc_ideal(-np.abs(x//2-y//2), (x^y)&1) ))
        it performs the same operation internally on int64 values as the overloaded operator:

        >>> myadd(x.nd,y.nd)
        array([26591258, 16777216])
        Such operations are supported by the frameworks (rather than here from np). This code challenge is to do a similar toy example within the tensor types provided by the framework, which gives a small taste of the difficulty involved in this project. (The code above for myadd is a slight oversimplification of xl.xlnsnp.__add__; see this for details on the treatment of 0.0.)

        References:

        [1] G. Alsuhli, et al., “Number Systems for Deep Neural Network Architectures: A Survey,” https://arxiv.org/abs/2307.05035, 2023.

        [2] M. Arnold, E. Chester, et al., “Training neural nets using only an approximate tableless LNS ALU”. 31st International Conference on Application-specific Systems, Architectures and Processors. IEEE. 2020, pp. 69–72. https://doi.org/10.1109/ASAP49362.2020.00020

        [3] O. Kosheleva, et al., “Logarithmic Number System Is Optimal for AI Computations: Theoretical Explanation of Empirical Success”, https://www.cs.utep.edu/vladik/2024/tr24-55.pdf

        [4] D. Miyashita, et al., “Convolutional Neural Networks using Logarithmic Data Representation,” https://arxiv.org/abs/1603.01025, Mar 2016.

        [5] J. Zhao et al., “LNS-Madam: Low-Precision Training in Logarithmic Number System Using Multiplicative Weight Update,” IEEE Trans. Computers, vol. 71, no. 12, pp.3179–3190, Dec. 2022, https://doi.org/10.1109/TC.2022.3202747

        Source Code: https://github.com/xlnsresearch/xlns

        Discussion Forum: https://github.com/xlnsresearch/xlns/discussions

        Effort: 350 Hours

        Difficulty Level: Hard

        ~~~~~~~~~~

        [3] Developing Distributed Algorithm for Metagenomic Error Correction and Assembly.

        Mentors: Arghya Kusum Das (akdas -at- alaska.edu) and Yali Wang (ywang35 -at- alaska.edu)

        Overview: A metagenomics study of Alaska would explore the diverse microbial communities in its unique environments, including the Arctic, marine, and terrestrial ecosystems. Such research could uncover insights into microbial adaptation to extreme conditions and contribute to understanding environmental and climate-related changes in the region. Metagenomic study has an immense impact on multiple science and engineering projects in Alaska such as, arctic healthcare, arctic water pollution, bio leaching on rare earth elements, arctic environmental sustainability and resilience, understanding boreal forest dynamics, wildfire mitigation, and so on. The list is never ending. Shotgun metagenomics, which involves sequencing DNA from a mixed sample of genomes within a community, offers a high-throughput approach to examine the genomic diversity of microbial populations. A key step in metagenomic analysis is assembling the shotgun reads into longer contiguous sequences, or contigs. However, genome assemblies from short reads are often highly fragmented, potentially generating millions of contigs per sample, especially in diverse communities. This challenge arises due to issues like sequence repeats within and between genomes, low coverage of certain species, and strain variability.

        Current Status: Because of the variability in abundance in multiple species in the mixed sample of genomes, it is hard to design a theoretically solid algorithm to rectify the error in the sample and assemble it accurately. The low abundance species in the mixed sample are often wrongly classified as error if we use a traditional/existing algorithms that can rectify the error in a single species’ whole genome sequence. For the similar reason, the existing metagenomic assemblers are perform sub-optimally. Further, the existing software are limited in terms of their data handling capability. Most of them are capable to operate in a single node only. So, their data nailing is severely limited by the RAM available in one node. Also the time consumed for large datasets are often unreasonable.

        Expected Outcomes: In this project, we will address the first two steps in metagenomic analysis i.e., error correction and assembly which are paramount for any downstream project. Metagenomic data is often large in size spanning to hundreds of gigabytes to terabyte scale. Our motivation is to develop distributed, HPC compatible solution for metagenomic error correction and assembly

        (1) We are looking for working solutions (a solid algorithm and its implementation) for metagenomic error correction and assembly. The solutions should be theoretically justifiable and/or biologically meaningful. (2) The algorithm and the software implementation for both error correction and assembly should be distributed in nature. (3) We are open for AI/ML-enabled solutions but that is not a requirement. (4) GPU-enabled solutions are also encouraged but, it’s also not a requirement.

        Required Skills: Python and experience with Deep Neural Networks

        Code Challenge: Prior experience creating deep learning models is expected.

        Source Code: https://github.com/akdasUAF/Metagenome

        Discussion Forum: https://github.com/akdasUAF/Metagenome/discussions/

        Effort: 350 Hours

        Difficulty Level: Medium/Hard

        ~~~~~~~~~~

        [4] Telehealth over L4S.

        Mentors: Kolawole Daramola (koladaramola -at- icloud.com) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: Low Latency, Low Loss, and Scalable Throughput (L4S) Internet Service 1, 2, 3 has shown promising performance, by rethinking congestion control. Can we have a telehealth deployment with pairs of L4S nodes? Perhaps starting with something simple, such as two DICOM endpoints to send radiographic images in between? Linux kernel with L4S patches can be a good point to start for the endpoints. How L4S, with telehealth and other applications, as well as classic non-L4S traffic, share the network will be an interesting test.

        Current Status: A prototype has been built as part of the GSoC 2024. As rural Alaska is largely unconnected by the road network, people often need to fly into larger towns such as Fairbanks and Anchorage for their healthcare needs. This state of affairs has steered the telehealth initiatives in Alaska much more than elsewhere in the US. Our research partners from healthcare organizations such as Alaska Native Tribal Health Consortium (ANTHC) utilize telehealth in their daily operations. Improved telehealth access and performance can significantly benefit the patients and providers in terms of patient satisfaction and comfort.

        Expected Outcomes: This project will review the latest advances from the research, deployment, and testing perspectives with using L4S in telehealth. The contributor will look into how this can be deployed in practice for various telehealth applications – sending DICOM images for diagnostics (high volume of data but tolerance for high latency), telemonitoring via wearable devices (low volume of data but demand for low latency), televisits (a video call through apps such as Zoom – high volume of data and demand for high latency). As a result of this project, we will understand whether we need any optimizations for L4S to use for telehealth applications and potential alternative approaches.

        Required Skills: Python

        Code Challenge: Experience with network protocols and installing Linux servers is a plus. Coding experience demonstrating such experiences is considered positive.

        Source Code: https://github.com/KathiraveluLab/L4SBOA

        Discussion Forum: https://github.com/KathiraveluLab/L4SBOA/discussions

        Effort: 350 Hours

        Difficulty Level: Hard

        ~~~~~~~~~~

        [5] Creating shareable "albums" from locally stored DICOM images

        Mentors: Ananth Reddy (bananthreddy30 -at- gmail.com) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: DICOM data sets downloaded from PACS environments typically remain in the local environments, such as a research server or a cluster where the DICOM retriever (C-MOVE) is run. To use this data, researchers must identify certain subsets of data. This can be achieved by querying the retrieved data. DICOM images consist of textual metadata. By querying the metadata, subsets of images can be identified. However, currently, creating "albums" from locally stored DICOM images is not seamless.

        Current Status: This feature does not exist in our open-source frameworks. We share images through other orthogonal approaches (via rclone, for example). This project will implement a stand-alone utility to effectively create albums from locally stored DICOM images.

        Expected Outcomes: Several approaches to implementing such album features exist. One approach is to use Kheops to provide an interface to create and view the albums. MEDIator can be extended to create subsets and share the images via a unique URL as well. The proposed feature will make the images accessible to more researchers for their experiments by replacing the current manual data sharing efforts. Moreover, Kheops natively integrates with OHIF Viewer. As such, images retrieved locally can be viewed through OHIF Viewer by creating albums with Kheops. Contributors are encouraged to use Kheops or alternatives rather than reinventing the wheel (unless there is a convincing reason).

        Required Skills: Python and Java.

        Code Challenge: Experience working with DICOM images from previous projects or through a sample dummy project will be a plus.

        Source Code: https://github.com/KathiraveluLab/Diomede (New Project).

        Discussion Forum: https://github.com/KathiraveluLab/Diomede/discussions

        Effort: 350 Hours

        Difficulty Level: Easy

        ~~~~~~~~~~

        [6] Beehive: Integrated Community Health Metrics Framework for Behavioral Health to Supplement Healthcare Practice in Alaska.

        Mentors: David Moxley (dpmoxley -at- alaska.edu) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: This project, a collaboration between the University of Alaska Anchorage Departments of Computer Science and Human Services, seeks to create a digital approach to translating the digitalization of art and photographic images into a digital database that stores in retrievable formats those images for use in advancing the delivery of human services and health care to people who experience considerable vulnerability and marginalization within the community. One of the project goals is to create a digital repository of these images, many of which reflect Outsider Art since the people who produce them are not formally trained as artists and experience considerable discrimination. The repository can be used to support research on Outsider art and Outsider Artists, education of health and human services practitioners about the impact of negative stereotypes on the health and well-being of people who are highly vulnerable, and arts programs devoted to advancing the health of vulnerable people.

        This project aims to develop Beehive, a prototype implementation as an open-source data federation framework that can be used in research environments in Alaska and elsewhere.

        Current Status: A prototype has been built as part of Alaska Season of Code. We are researching the approach for its use with our community partners in Anchorage, aiming to support marginalized folks such as the unhoused.

        Expected Outcomes: In this project, the contributor will develop the Beehive platform for (1) translating digital images into the database, (2) developing the database to support user interactions with content, and (3) facilitating retrieval of images. The contributor will obtain an orientation to the project, instruction in how the arts and photography can represent health and well-being, and insight into using digital representations as an advocacy tool for improving the well-being of highly vulnerable people.

        Required Skills: Database (MySQL or Mongo) and Python or Java. A build management tool such as Apache Maven is recommended if using Java.

        Code Challenge: Prior experience with database management through established coding examples.

        Source Code: https://github.com/kathiraveluLab/beehive.

        Discussion Forum: https://github.com/KathiraveluLab/Beehive/discussions/

        Effort: 350 Hours

        Difficulty Level: Medium

        ~~~~~~~~~~

        [7] DICOM Image Retrieval and Processing in Matlab.

        Mentors: Ananth Reddy (bananthreddy30 -at- gmail.com) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: DICOM (Digital Imaging and Communications in Medicine) is a radiographic imaging standard for how various modalities of scanners, PACS (Picture archiving and communication system) and other imaging systems communicate. As a storage protocol, it defines how images are stored in a standard way. It also functions as a messaging protocol, an extension to TCP.

        Many DICOM processing tools exist. They support receiving images from the scanners and PACS to a research cluster in real-time as an imaging stream or on-demand selectively. They also provide means to anonymize the DICOM images to preserve patient privacy, export the DICOM images into a format such as PNG or JPEG, and extract the textual metadata from DICOM files to store it in a CSV file format or a database. Machine learning pipelines cannot be executed in clinical systems such as scanners and PACS. Therefore, the DICOM images and their metadata in the research clusters can be used to run machine learning pipelines.

        Matlab has some out-of-the-box support for certain DICOM functions, and it could make our job easy in certain projects. This facilitates processing the files from the file system 2. Region-of-Interest is natively supported for DICOM-RT files in Matlab 3. It also supports deep learning on DICOM and NifTi files 4. Matlab currently does not support receiving images from DICOM systems such as PACS and Scanners over the network. Matlab used to have functions that utilize the Dicom toolkit to pull images from another server. It was available through Matlab's file exchange at one point called "dicom server connection." This is not publicly available anymore. However, we have the implementation available locally. The code was not recently tested, and therefore, its usability with the latest Matlab versions needs to be confirmed.

        Current Status: This project is currently in the research stage.

        Expected Outcomes: This project aims to create an easy-to-use open-source Matlab DICOM processing framework. We start with processing DICOM images since the current status of the DICOM networking in Matlab is unknown. But we will explore it, if possible and time permitting. Since this is a research project, we should study the existing projects first to avoid re-inventing the wheel. From Google Scholar, we see many processing and pipelines (ROI, deep learning, ...) on DICOM/DICOM-RT have been implemented using Matlab. Regardless of the scientific novelty, we can get an open-source solution to help with further ML stuff using Matlab on the DICOM files. However, we should also observe how this could be a scientific contribution and its merits beyond what is already available. We can use readily available public DICOM data sources to test our implementations, such as the Cancer Imaging Archive (TCIA), as that avoids having to deal with sensitive patient data with PHI. We will narrow down on a specific research use case to highlight the framework's usage in research.

        Required Skills: Matlab

        Code Challenge: Experience working with DICOM images from previous projects and prior experience with Matlab, as demonstrated through code examples, will be a plus.

        Source Code: https://github.com/KathiraveluLab/Diomede (New Project).

        Discussion Forum: https://github.com/KathiraveluLab/Diomede/discussions

        Effort: 350 Hours

        Difficulty Level: Hard


        ~~~~~~~~~~

        [8] Making ZeroMQ a first-class feature of concore.

        Mentors: Shivang vijay (shivangvijay -at- gmail.com), Rahul Jagwani (rahuljagwani1012 -at- gmail.com), and Mayuresh Kothare (mvk2 -at- lehigh.edu)

        Overview: concore is a lightweight framework for closed-loop peripheral neuromodulation control systems. concore consists of a file-sharing based concore protocol to communicate between the programs in a study. concore also allows a shared-memory based communication between programs. This project will implement a ZeroMQ-based communication between programs, as an alternative to the file-sharing based and shared-memory based communications. ZeroMQ is a message-oriented middleware implemented in multiple languages, which natively supports communications across computing nodes. Such an implementation will improve the usability of concore in distributed environments.

        The study with 0MQ

        Current Status: We experimented with an osparc-control based communication as an alternative to this default file-sharing based concore protocol. osparc-control is an extension of ZeroMQ. Our experimental osparc-control based implementation replaces the file-sharing mechanism restricted to one local machine with message queues that can be transmitted between locally networked machines. The contributor will use this osparc-control based communication as an inspiration for the proposed ZeroMQ-based implementation, which will function as a first-class approach to implement the edges of concore without using osparc-control. In our current experimental osparc-control based implementation, these ZeroMQ edges are not visible in the concore editor, the browser-based visual editor for concore. Consequently, studies with osparc-control are represented as forests instead of directed hypergraphs due to the "invisible" ZeroMQ communication. This also means to run a concore study with ZeroMQ communication, we have to run each hypergraph in the forest separately.

        Expected Outcomes: We need to promote a unified experience in concore, whether the edges are implemented via the default file-sharing approach, shared-memory approach, or through this ZeroMQ message-based approach. In the concore file-sharing approach, we label the edges with alphabetical characters. In the concore shared-memory approach, we label the edges starting with positive decimal integers (specifying the memory channels used for the sharing). Therefore, to denote the concore ZeroMQ-based edges, the contributor should assume that all the ZeroMQ-edges must start with "0" in their labels, followed by a hexadecimal port, followed by an underscore (_). For example, edge 0x1234_Y assigns the logical Y to port 1234 and edge 0xabcd_U assigns the logical U to port abcd. Once such a graph with ZeroMQ-edges is made (a single directed hypergraph, rather than a forest with disjoint two or more directed hypergraphs), we should be able to seamlessly build and run the study regardless of the underlying communication mechanism. Thus, we aim to demonstrate the possibility of a seamless local vs. distributed execution in a cluster through ZeroMQ.

        As the expected outcome of this project, we propose a ZeroMQ-based communication for concore with Python. In addition, the contributor may also implement the ZeroMQ-based communication with other programming languages supported by concore such as Matlab and C++. The contributor may also get inspiration from how the shared-memory based communication is implemented in concore.

        Required Skills: Python

        Code Challenge: Prior experience in Python must be demonstrated. Prior experience with message-oriented middleware frameworks such as ZeroMQ can be a plus, although not mandatory.

        Source Code: https://github.com/ControlCore-Project/concore

        Discussion Forum: https://github.com/ControlCore-Project/concore/discussions

        Effort: 350 Hours

        Difficulty Level: Medium


        ~~~~~~~~~~

        [9] Dynamic DICOM Endpoints.

        Mentors: Ananth Reddy (bananthreddy30 -at- gmail.com) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: DICOM (Digital Imaging and Communications in Medicine) is a radiographic imaging standard for how various modalities of scanners, PACS (Picture archiving and communication system), and other imaging systems communicate. As a storage protocol, it defines how images are stored in a standard way. It also functions as a messaging protocol, an extension to TCP. DICOM implementations often have a queue to hold the images sent from the source. Since this is a networking communication, a queue may degrade the performance or introduce data loss. DICOM communications are defined by static source, query, and destination endpoints. Each endpoint is defined by hostname/IP address, port, and AE (Application Entity) Title. A DICOM endpoint such as a PACS or a scanner usually has these endpoints statically configured to ensure security and patient privacy.

        This project attempts to send data from a source to dynamic destinations based on the queue and the performance. This can be a use case for teleradiology with multiple remote healthcare/radiologist sites present or a potential framework to enable federated learning on radiographic images. Orthanc can be set up as a DICOM endpoint that mimics a PACS 1. With multiple Orthanc servers configured, such a federated deployment can be prototyped. Ultimately, this project aims to study the possibilities and opportunities of supporting dynamic DICOM endpoints in practice.

        Current Status: This project is currently in the research stage.

        Expected Outcomes: A prototype implementation that supports dynamic DICOM endpoints.

        Required Skills: Python

        Code Challenge: Experience working with DICOM images from previous projects or through a sample dummy project will be a plus.

        Source Code: https://github.com/KathiraveluLab/Diomede (New Project).

        Discussion Forum: https://github.com/KathiraveluLab/Diomede/discussions

        Effort: 350 Hours

        Difficulty Level: Hard

        ~~~~~~~~~~

        [10] Bio-Block: A Blockchain-based Data Repository and Payment Portal.

        Mentors: Chalinda Weerasinghe (chalindaweerasinghe -at- gmail.com), Erik Zvaigzne (erik.zvaigzne-at-gmail.com), and Forrester Kane Manis (Forrester-at-headword.co)

        Overview: Most biological, genomic, genetic, medical, and behavioral data are currently collected, stored, and sold by vendors who initially offer products and services to clients in order to accumulate this data. The data, once given to companies, remains the property of the company, with very little compensation and autonomy offered to customers who provided the data in the first place. Can we create a secure, decentralized, and scalable data repository of such information for humans and animals, a true bio-block available to all and open-sourced, whereby the data owners get directly compensated? This project offers a response in the affirmative and leverages blockchains for data distribution, archiving, recording, and payments using a dual-chain structure on the Ethereum blockchain.

        Current Status: This project is currently in the research stage.

        Expected Outcomes: This overall project will be one of the first offerings of an open-source platform for all biological/medical/genomic/behavioral data that leverages the advantages of blockchains. While proprietary dual-chain blockchain architectures are used by companies in this space, our endeavor, through its sub-projects, aims to proof up the architecture that can be scaled and extended to all forms of client-submitted data and multiple retrieval and payment options. A proof of concept of the architecture will be tested using multivariate, heterogenous synthetic data.

        Required Skills: Python is proposed as the programming language. However, students can also propose their preferred alternative programming language and frameworks. Prior experience developing on Ethereum is a plus.

        Code Challenge: Prior experience in Python (or the proposed alternative language) and, preferably, Ethereum blockchain through established coding examples. Students are expected to establish their experience with Blockchain technologies and architecting and programming them through previous projects - ideally through their respective GitHub repository (or similar code repositories).

        Source Code: https://github.com/bio-block/healthy (New Project).

        Discussion Forum: https://github.com/bio-block/healthy/discussions

        Effort: 350 hours

        Difficulty Level: Hard

        ~~~~~~~~~~

        [11] Adopting Nunaliit for Alaska Native Healthcare Practices.

        Mentors: Jessica Ross (jmross2 -at- alaska.edu) and Maria Williams (mdwilliams6 -at- alaska.edu)

        Overview: Nughejagh is an Alaska Native holistic healthcare application. It uses Nunaliit as its map-based interface to store its data. The data is curated from various sources in the form of images, stories, and videos - which are stored using the Nunaliit map-based interface, supported by its CouchDB database. However, currently, Nunaliit lacks several desired features for Nughejagh. This project aims to fill the gap by implementing those features and developing scripts to automate the installation, configuration, and data loading process.

        Current Status: This project is currently in the research stage.

        Expected Outcomes: The expected goal is to have Nunaliit fine-tuned and configured to run Nughejagh with all its requirements. The project outcome might be a new stand-alone repository that uses Nunaliit, a forked version of Nunaliit, or more likely both. The contributor should justify their design decisions as part of the proposed design.

        Required Skills: Prior experience in Javascript, Java, and Python.

        Code Challenge: Deploy and configure Nunaliit locally and share a screenshot of a locally-running Nunaliit instance. Nunaliit runs well on Ubuntu 24.04.

        Source Code: https://github.com/Nughejagh/nughejagh (New Project).

        Discussion Forum: https://github.com/Nughejagh/nughejagh/discussions

        Effort: 350 hours

        Difficulty Level: Medium

        ~~~~~~~~~~

        [12] AWANTA: A Virtual Router based on RIPE Atlas Internet Measurements.

        Mentors: Ananth Reddy (bananthreddy30 -at- gmail.com) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: RIPE Atlas is an Internet Measurement network composed of small network devices, known as RIPE Atlas Probes and Anchors, connected to the participating volunteers' routers. Using RIPE Atlas, we can measure the Internet latency and routing path through ping and traceroute measurements. This project aims to develop a software router that dynamically uses RIPE Atlas measurements to change the scheduling path. Before the implementation of the project, we should study the existing works on using RIPE Atlas probe for such network optimization tasks at the Internet scale to quickly understand the state-of-the-art and ensure scientific novelty in our approach.

        Current Status: A prototype has been built as part of the GSoC 2024. We observe the use of such a framework in the Circumpolar North. Such an approach can provide significant benefits, especially in Alaska and the Canadian North, where Internet connectivity can be spotty.

        Expected Outcomes: This project extends the RIPE Atlas client to use the measurements in network scheduling decisions. First, the measurements should be streamlined to perform periodically across several probes set as sources and destinations. The measurements across several probes in a single city can provide a more generalized measurement for a city rather than restricting to individual changes of any given probe when multiple such probes are available to a given city. Second, we will build a virtual router to use these measurements to dynamically influence the network scheduling decisions across several nodes. As the network performance changes with time, we can observe how the network path changes with time. We have more than 60 million RIPE Atlas credits that we accumulated by hosting a RIPE Atlas probe for the past five years. So, we have sufficient resources for these Internet measurement experiments.

        Required Skills: Python.

        Code Challenge: Prior experience in Python through established coding examples.

        Source Code: https://github.com/KathiraveluLab/AWANTA

        Discussion Forum: https://github.com/KathiraveluLab/AWANTA/discussions/

        Effort: 350 Hours

        Difficulty Level: Medium


        ~~~~~~~~~~

        [13] Alaska Wildfire Prediction Using Satellite Imagery.

        Mentors: Yali Wang (ywang35 -at- alaska.edu) and Arghya Kusum Das (akdas -at- alaska.edu)

        Overview: Given Alaska’s unique wildfire patterns, where large-scale fires occur annually in boreal forests, tundra, and remote wilderness, predicting fire-prone areas can help mitigate disasters and optimize resource allocation. The presence of vegetation (fuel) is necessary for a fire, but the determining factors are weather conditions (humidity, wind speed, temperature) and an ignition source (lightning, human activity, etc.). This project aims to develop a hybrid deep learning model to predict wildfire risk in Alaska by integrating optical, thermal, and synthetic aperture radar (SAR) satellite imagery with ground-based weather data. Traditional wildfire prediction relies on weather data, historical fire records, and human observations, which can be delayed or inaccurate in remote areas like Alaska. In contrast, satellite imagery provides real-time, high-resolution insights into vegetation health, thermal anomalies, burn severity mapping, soil moisture, fuel dryness, and even cloud-penetrating fire detection.

        Satellite choices:

        Satellite	Resolution	Revisit Frequency	Why Use It?
        Landsat 8 & 9 (NASA/USGS)	30m (multispectral), 100m (thermal)	16 days	Tracks pre/post-fire vegetation and burn severity with great detail.
        Sentinel-2 (ESA)	10m (RGB, NIR), 20m (SWIR)	5 days	High-resolution images for fire risk classification and early warnings.
        MODIS (Terra/Aqua, NASA)	250m (fire detection), 1km (thermal)	Daily	Provides historical fire perimeters and active fire locations.
        VIIRS (Suomi NPP & NOAA-20)	375m (fire detection), 750m (thermal)	Daily	Real-time fire monitoring, capturing active hotspots.
        Sentinel-1 (ESA)	5m - 20m	6-12 days	SAR imaging for vegetation moisture & burned area mapping.
        ALOS-2 (JAXA)	10m - 100m	14 days	L-band SAR for detecting dry fuel and terrain changes.
        Additional ground data sources:

        1). ERA5 Climate Reanalysis (ECMWF): Provides historical & real-time temperature, wind, and humidity data.

        2). NOAA NWS Weather Data: Near real-time humidity, wind, and temperature.

        3). Alaska Fire Service (AFS) Wildfire Data: Historical ignition source data (lightning, human activity).

        Current Status: This project is currently in the research stage.

        Expected Outcomes: This project aims to develop a deep-learning model that predicts wildfire risk in Alaska using a combination of satellite and ground-based weather data. The expected outcome of this project would involve both the dataset preprocessing pipeline and the performance of the developed model. Especially, the dataset preprocessing would include how to process the pre-fire and post-fire images efficiently and integrate the ground-based data with satellite imagery. Expected outcomes include:

        Minimum viable product (MVP):

        Fire risk classification: Given pre-fire satellite images, the model predicts the probability of a fire occurring within a defined time frame like 1 month, 3 months, or 6 months. The classifications should be "High Fire Risk," "Moderate Risk," or "No Risk."

        1). Data pipeline development:

        Preprocessing satellite images: Band selection, geospatial cropping, cloud removal (For this step, we are mostly interested in analyzing Sentinel-2 data);

        Synthetic Aperture Radar (SAR) analysis: Extracting fuel moisture & terrain features (For this step, we are mostly interested in extracting information like vegetation density and soil moisture from Sentinel-1 SAR data);

        Time-series weather data integration: Incorporating temperature, wind, and humidity. We have access to past decades of weather data for almost the past 30 years for multiple different places in Alaska.

        2). Model training and prediction:

        A hybrid model such as CNN-LSTM that analyzes satellite data and time-series weather trends (CNN-LSTM is just an example. We are open to multiple different types of analysis methodology);

        A web-based GIS dashboard to visualize fire-prone regions in Alaska;

        A report on model performance and fire risk metrics.

        Required Skills: Python. Experience with deep learning and machine learning.

        Code Challenge: Experience with multi-band satellite imagery, geospatial data processing (like ArcGIS Pro), and remote sensing.

        Source Code: https://github.com/YaliWang2019/AK-Satellite-Imagery-Wildfire-Prediction (New Project)

        Discussion Forum: https://github.com/YaliWang2019/AK-Satellite-Imagery-Wildfire-Prediction/discussions

        Effort: 350 Hours

        Difficulty Level: Medium/Hard

        You are welcome to propose new open-source project ideas, especially those that serve the state of Alaska and its people. Please use the below template to create new project ideas. However, if you are proposing a new project idea as a contributor, make sure they are relevant to Alaska specifically and the circumpolar north in general. Also, contact potential mentors from the above-listed mentors and confirm their interest in your project idea before drafting an entire proposal based on your own idea.

        ~~~~~~~~~~
        
        [14] Support for Logarithmic Number Systems in Large Language Models.

        Mentors: Mark Arnold (markgarnold -at- yahoo.com) and Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu)

        Overview: The Logarithmic Number System (LNS) is an alternative to built-in Floating Point (FP), which makes multiplication and division easy at the expense of more difficult addition. Using overloaded operators, xlnscpp provides an open-source C++ library for both 16- and 32-bit LNS arithmetic. Interest in fabricating LNS hardware has grown since it may reduce power consumption for applications that tolerate approximate results, such as deep learning (see [1]-[5]). Although LNS has been studied extensively for feed-forward networks, only recently [6] has LNS been considered for Large Language Models (LLMs).

        LLMs consist of two main computations: a) feed-forward neural networks for which LNS has been shown to be useful, and b) an operation known as attention. The training of an LLM produces weights for both of these computations, which are often quantized to reduce data storage requirements. These quantized weights are reconstructed (usually in either 16- or 32-bit FP) and operated on by vectors of tokens (usually in similar FP format).

        Existing LLM engines, such as the open-source llama.cpp, perform vector/matrix/tensor operations (mostly matrix multiply) between the FP tokens and the weights (in a variety of formats, not including LNS).

        llama.cpp uses a library called ggml to do the actual math. The design of ggml supports a variety of FP hardware, such as CPUs and GPUs.

        Current Status: xlnscpp is not supported by llama.cpp or ggml. Weights can be stored in a variety of built-in int or FP formats instead of LNS. Matrix operations are carried out in FP.

        Expected Outcomes: The goal of this project is to provide support for xlnscpp instead of FP in ggml (and indirectly) llama.com. At a minimum, this involves modifying ggml to support a "virtual" LNS "machine" using xlnscpp to perform the actual LNS computation, but which appears to the calling llama.cpp like another hardware platform, like a GPU. The storage format of the quantized weights would still be the same, but they would be converted to LNS for computations like attention on LNS-format tokens. It is not expected that the speed would be as fast as if hardware FP were used, although a design that minimizes the slowdown is desirable (for instance, converting to LNS once, and reusing LNS many times, much as data is transferred to GPU memory and reused many times there). The purpose is a proof of concept that LNS yields valid output from an LLM. The design needs to implement enough ggml features to support an actual LLM, like Deepseek.

        Required Skills: C++ and some familarity with LLMs

        Code Challenge:

        Run the xlns16test.cpp and xlns32test.cpp examples.

        Go through the ggml example for 32-bit FP matrix multiplication on CPU ( https://huggingface.co/blog/introduction-to-ggml) which illustrates concepts like: ggml_backend (the code that does the computation on a GPU or CPU), ggml_context (a "container" that holds data), ggml_cgraph: (what computation the backend performs), ggml_backend_buffer: (hold the data of multiple tensors), and ggml_backend_buffer_type: (a "memory allocator" connected to each ggml_backend). This is quite involved because of the ggml_backend concept. Such experience will help you design a new ggml_backend for LNS (which your design proposal will describe as running on CPU using xlnscpp).

        Write a standalone C++ program that has a function to do 32-bit FP matrix multiply with a main program that prints the FP result. Test it with the same matrix data as the previous ggml example. (Hint: use nested for loops to compute the sum of products that form the matrix product).

        Modify this program to include xlns32.cpp (define xlns_ideal first) and perform the internal computation in LNS format. The main program and the signature of the function it calls remain the same (32-bit FP), which requires that the function convert to/from LNS before and after the matrix multiply. (Hint: if you do it properly, the overloaded xlnscpp assignment operator takes care of this automatically.) The sum of products should be computed entirely in LNS (not FP). Notice the numeric results are close to what FP produces.

        Modify the program to include xlns16.cpp instead. Notice the numeric results are slightly less accurate (the 16-bit LNS product is stored in the 32-bit FP result). This illustrates the tradeoff of using reduced precision LNS, which is what we want to experiment with in this project.

        These code challenges provide possible insight as to how the LNS-CPU backend your design proposal will describe can "look like" an FP backend to llama.cpp. When data would be transferred to the backend, it is converted to LNS. When data is transfered back to llama.cpp, it is converted back to 32-bit FP. This is one idea for this project. You may incorporate improvements to this concept in your design proposal that considers the features of ggml.

        References:

        [1] G. Alsuhli, et al., “Number Systems for Deep Neural Network Architectures: A Survey,” https://arxiv.org/abs/2307.05035, 2023.

        [2] M. Arnold, E. Chester, et al., “Training neural nets using only an approximate tableless LNS ALU”. 31st International Conference on Application-specific Systems, Architectures and Processors. IEEE. 2020, pp. 69–72. https://doi.org/10.1109/ASAP49362.2020.00020

        [3] O. Kosheleva, et al., “Logarithmic Number System Is Optimal for AI Computations: Theoretical Explanation of Empirical Success”, https://www.cs.utep.edu/vladik/2024/tr24-55.pdf

        [4] D. Miyashita, et al., “Convolutional Neural Networks using Logarithmic Data Representation,” https://arxiv.org/abs/1603.01025, Mar 2016.

        [5] J. Zhao et al., “LNS-Madam: Low-Precision Training in Logarithmic Number System Using Multiplicative Weight Update,” IEEE Trans. Computers, vol. 71, no. 12, pp.3179–3190, Dec. 2022, https://doi.org/10.1109/TC.2022.3202747

        [6] P. Haghi, C. Wu, Z. Azad, Y. Li, A. Gui, Y. Hao, A. Li, and T. T. Geng, “Bridging the Gap Between LLMs and LNS with Dynamic Data Format and Architecture Codesign ,” in 2024 57th IEEE/ACM International Symposium on Microarchitecture (MICRO). Los Alamitos, CA, USA: IEEE Computer Society, Nov. 2024, pp. 1617–1631. https://doi.ieeecomputersociety.org/10.1109/MICRO61859.2024.00118

        Source Code: https://github.com/xlnsresearch/xlnscpp

        Discussion Forum: https://github.com/xlnsresearch/xlnscpp/discussions

        Effort: 350 Hours

        Difficulty Level: Hard

        ~~~~~~~~~~

        [15] Time and Ordering in Beehive.

        Mentors: Pradeeban Kathiravelu (pkathiravelu -at- alaska.edu) and David Moxley (dpmoxley -at- alaska.edu)

        Overview: Beehive was initiated as a collaboration between the University of Alaska Anchorage Departments of Computer Science and Human Services, but grew largely into a software platform through open-source contributions. Beehive seeks to create a digital approach to translating the digitalization of art and photographic images into a digital database that stores in retrievable formats those images for use in advancing the delivery of human services and health care to people who experience considerable vulnerability and marginalization within the community. One of the project goals is to extend the current Beehive software as a repository of photomemories (a 2D projection of 3D spaces) X time. This project aims to extend Beehive with these additional capacities and develop data mining algorithms to support this use case of photos as frozen snapshots in an individual's life.

        Current Status: The current Beehive prototype does not consider the complexities of time and ordering in the use of behavioral patterns and narratives in the journey to recovery.

        Expected Outcomes: In this project, the contributor will (1) extend the Beehive platform to support time and ordering as attributes across images, (2) develop algorithms to understand the impact of past events through the series of images and their narratives, and (3) implement data mining algorithms that could fetch and understannd evolving narratives around photomemories. We see spaces as 3D or 2D if we are referring to geolocations. Photos are 2D projections of a 3D space. There is one dimension that we omit in most of these projections. That is time. Time as a 4th dimension is not entirely new in research and applications. A search on spatiotemporal data and space-time continuum will give you plenty of examples, from climate change to science novels. Time, or more specifically, ordering, is an essential variable in behavior. Don't you wonder how you see places differently just because you have seen the same or something similar before? Where it gets more interesting or challenging (depending on how you see it) is how the time affects the exact location and even those "near" it. When we say "near," it is in terms of data, not necessarily in terms of geographical proximity. Sometimes, it is just a minor change, and the location is the same! In data mining, we call this "near duplicates." A change in the name of a place (can be a city or a restaurant!). Other times, these are two entirely different places. Perhaps, Kivalina has moved over time due to the Arctic Erosion (sadly). But that is still geographical proximity. For instance, your visit to Portugal will influence your visits to other Portuguese-speaking nations (such as Angola and Brazil) because they share a language and culture, although they are oceans apart. On a smaller scale, your experience in a library will impact how you perceive another library in a different location. How do we consider time (or in a more accurate sense, "relative time" or "ordering") in our analysis/perception? This is intertwined as the 4th dimension (or 3rd dimension, if you are already projecting the 3D world into a 2D map/photo). This project aims to understand these complexities in a prototype version over simulated/synthetic data.

        Required Skills: Database (MySQL or Mongo) and Python or Java. Experience and interest in data mining is a plus.

        Code Challenge: Prior experience with database management through established coding examples.

        Source Code: https://github.com/kathiraveluLab/beehive.

        Discussion Forum: https://github.com/KathiraveluLab/Beehive/discussions/

        Effort: 350 Hours

        Difficulty Level: Medium

        [N] PROJECT TITLE.

        Mentors: FIRSTNAME1 LASTNAME1 (email-address) and FIRSTNAME2 LASTNAME2 (email-address)

        Overview:

        Current Status:

        Expected Outcomes:

        Required Skills:

        Code Challenge:

        Source Code:

        Discussion Forum:

        Effort: 90/175/350 Hours

        Difficulty Level: Easy/Medium/Hard


          
    totalCharacters_of_ideas_content_parent: 54320
    totalwords_of_ideas_content_parent: 9380
    totalTokenCount_of_ideas_content_parent: 12130
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/alaska/
    idea_list_url: https://github.com/uaanchorage/GSoC




  - organization_id: 8
    organization_name: AnkiDroid
    no_of_ideas: 5
    ideas_content: |
    
          Multiple Profiles (175 hours)
          Problem
          Currently, AnkiDroid only allows a single profile as opposed to Anki (Desktop) and AnkiMobile (iphone) which allow multiple profiles. In particular, a family using a shared device will be able to have one profile per user, instead of sharing data. If you have multiple ankiweb accounts, you can sync all of them on your android. You can see discussion about this topic on https://github.com/ankidroid/Anki-Android/issues/2545.


          Expected Outcomes
          A user should be able to add a profile, sync this profile with an ankiweb account, switch between those accounts, and update the preference on a profile-by-profile level.
          Each profile should have its own collection, as in Anki. 

          There are at least three big questions that you need to consider. The UI, the backend, and the data structure. 
          The UI
          Firstly, you should design the UI. Your proposal should show us what would be the path the user will take to add a second profile, and switch to another profile. 
          The data structure
          AnkiDroid follows anki data structure. We have a folder, called Ankidroid, which contains all the files used to store user data. We should figure out a way to change the data structure in order to allow us to store data of multiple profiles.
          When the device does not use scoped storage, the AnkiDroid folder is in the top level general purpose folder of the AndroidDevice. We expect and hope most users understand this folder is used by ankidroid and leave it alone. We can’t just add other top level folders as this may clutter the user storage system and increase the risk a user delete folder, hence losing their data.
          The backend
          We need to figure out everything that will need to be changed. At the very least:
          We need a way to determine which profile is currently being used, and remember this information when ankidroid is restarted
          Each access to the data structure needs to take the profile into account, in order to access the right collection and media folder. This information should be available to the backend; so we should determine whether any change to the backend is required (probably not)
          We need to determine which preferences are profile based and which are used by the whole app. We need to update all preferences access to ensure we use the profile ones. We probably will need a lint rule that ensure that most preferences are profile-dependent unless there is a good reason not to. When creating an account, we need to determine whether to use default preferences or copy existing ones.


          Stretch goals
          If you have remaining time after the main project is done, there are two extensions that could be worth considering.

          Advertise this feature

          On the first update where multiple accounts are available, show a message to the user inviting them to add other accounts. This message should be similar to the message to new users.
          Saving space by avoiding to duplicate the media

          If multiple accounts have the same media (let’s say, the device is used by multiple users, who all should learn Ultimate Geography or Anking deck), ensure that the media are not duplicated in order to save storage on the device. This may require collaboration with the backend, because this optimization is not done on desktop. 
          It is probably worth doing it because storage is very precious on mobile.
          Language:
          Kotlin & XML
          Potentially some rust if we need to touch the backend for the stretch goal
          Difficulty: Medium
          Mentor(s):
          Arthur Milchior
          Shridhar Goel



          ~~~~~~~~~~



          Review Reminder (175 hours)
          Problem
          The user can request AnkiDroid to send them a daily notification in Android to remind them to review their cards if there are cards to review today.
          At least in theory. In practice those notifications have been broken for a long time. We tried years ago to solve the issue. Our solution was to remove most features, but what remains is still far from ideal.  It’s now clear that we should just scratch the current notification system and recreate one from scratch (and automatically migrate users from the previous feature to the new one). 
          Expected Outcomes
          In your proposal, you should tell us what the notification system will look like.
          We need to know what user interface you plan to implement. Every journey the user can take.

          The most basic idea is to have a notification shown if any card is due. This is what we currently have. Also let the user decide at which hour the notification should be shown. Maybe the notification should have a snooze button, to remind the user later (when?)
          We could also consider adding notification for specific decks.
          If so, there should probably be a way to see all notifications currently planned, in order to easily remove them, or edit them together.
          We should also find a way to test those notifications, manually and with automated tests. Ensuring they only trigger once a day in order not to overwhelm the user.
          You may consider reaching users over reddit and the forum in order to gather feedback 

          Language:
          EITHER:
          Kotlin & XML
          Difficulty: Hard
          Mentor(s):
          Arthur Milchior
          criticalAY


          ~~~~~~~~~~

          Note Editor: Note Type Preview (175 hours)
          Problem
          AnkiDroid is a flashcard app with a complex HTML/field-based templating engine. We currently have difficulties explaining a number of concepts to new users, both while onboarding, and for intermediate users:
          The unexpected fact that the user adds ‘notes’ to the app, not ‘cards’
          One note can generate multiple cards
          Various ‘Note Types’ have unique properties
          A user can create or download additional note types
          Currently, the user is provided with a text-based selection screen:

          Expected Outcomes
          In order to resolve the above issues, we want to modify this screen to provide a preview of each note type available in the system, showing
          The number of cards which will be produced when the note type is used
          A visual preview of how each of the cards will look
          Each card has a separate HTML template, so the designs may vary
          Taking into account some special features: 
          A note type may request that the user types in the answer
          Cloze deletions: 1 input produces 1…n cards
          Image occlusion: 1 input
          The ability to open our Card Template Editor
          The screen should allow a user to open up our Note Type Management screen and our manual. We should aim for the screen to prefer graphical elements over text
          Language:
          EITHER:
          Kotlin & XML
          If the screen is Android-specific
          Svelte (Typescript + HTML)
          If the screen is to be integrated into all Anki clients
          Difficulty: Medium
          Mentor(s):
          David Allison
          criticalAY

          ~~~~~~~~~~



          Tablet & Chromebook UI (175/350 hours)
          Problem
          AnkiDroid was initially designed for Android mobile phones. Over the years, Android has come to tablets and Chromebooks, but our UI has continued to be designed around the mobile phone.

          We currently have ~10% of our users on Tablets or Chromebooks, and we want to improve their user experience using the app, both with the aim to improve the user experience for our existing users, and increasing the number of users who can effectively use our app on larger devices

          Sanjay Sargam greatly improved the user experience on table and chromebook through GSoC 24’, and I invite you to read his report. Still, much remains to do, and what was done can certainly be polished.
          Expected Outcomes
          This primarily depends on your proposal. 
          Any screen in the app is open for your suggestions. 

          Suggestions
          Show NoteEditor and Previewer Side by Side
          Currently, the NoteEditor and Previewer are separate screens in AnkiDroid. On mobile devices, this makes sense due to limited scree n space. However,on tablets and Chromebooks, users have larger displays, and constantly switching between editing and previewing can feel cumbersome.

          Resizable Layout in DeckPicker and CardTemplateEditor
          The goal is to introduce a draggable slider that lets users dynamically adjust the size of two sections.

          Language: Kotlin, XML
          Difficulty: Medium
          Mentor(s):
          David Allison
          Arthur Milchior
          Sanjay Sargam


          ~~~~~~~~~~

          Additional Widgets (175/350 hours)
          Problem
          Widgets were introduced to AnkiDroid in 2010. These provide significant benefit to our power users and we started using them through GSoC 24. I invite you to read last year’s contributor’s report to see what was done.

          
          Expected Outcomes
          Android 12 Widget-based functionality is evaluated and integrated with the widgets when appropriate


          The GSoC proposal is expected to propose additional widgets that would be useful to our users
          Language: Kotlin, XML, UI & UX
          Difficulty: Medium
          Mentor(s):
          David Allison
          criticalAY





          
    totalCharacters_of_ideas_content_parent: 9691
    totalwords_of_ideas_content_parent: 2448
    totalTokenCount_of_ideas_content_parent: 1986
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/ankidroid/
    idea_list_url: https://docs.google.com/document/d/1Va6IWEYcWTkK4KDtyoFxtOKzpdcYe54GdrVpuMcFvlI/edit?pli=1&tab=t.0



  - organization_id: 9
    organization_name: Apache DataFusion
    no_of_ideas: 11
    ideas_content: |
        
        Implement Continuous Monitoring of DataFusion Performance
        Description and Outcomes: DataFusion lacks continuous monitoring of how performance evolves over time – we do this somewhat manually today. Even though performance has been one of our top priorities for a while now, we didn’t build a continuous monitoring system yet. This linked issue contains a summary of all the previous efforts that made us inch closer to having such a system, but a functioning system needs to built on top of that progress. A student successfully completing this project would gain experience in building an end-to-end monitoring system that integrates with GitHub, scheduling/running benchmarks on some sort of a cloud infrastructure, and building a versatile web UI to expose the results. The outcome of this project will benefit Apache DataFusion on an ongoing basis in its quest for ever-more performance.

        Category: Tooling

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): alamb and mertak-synnada

        Skills: DevOps, Cloud Computing, Web Development, Integrations

        Expected Project Size: 175 to 350 hours*

        ~~~~~~~~~~

        Supporting Correlated Subqueries
        Description and Outcomes: Correlated subqueries are an important SQL feature that enables some users to express their business logic more intuitively without thinking about “joins”. Even though DataFusion has decent join support, it doesn’t fully support correlated subqueries. The linked epic contains bite-size pieces of the steps necessary to achieve full support. For students interested in internals of data systems and databases, this project is a good opportunity to apply and/or improve their computer science knowledge. The experience of adding such a feature to a widely-used foundational query engine can also serve as a good opportunity to kickstart a career in the area of databases and data systems.

        Category: Core

        Difficulty: Advanced

        Possible Mentor(s) and/or Helper(s): jayzhan-synnada and xudong963

        Skills: Databases, Algorithms, Data Structures, Testing Techniques

        Expected Project Size: 350 hours

        ~~~~~~~~~~

        Improving DataFusion DX (e.g. 1 and 2)
        Description and Outcomes: While performance, extensibility and customizability is DataFusion’s strong aspects, we have much work to do in terms of user-friendliness and ease of debug-ability. This project aims to make strides in these areas by improving terminal visualizations of query plans and increasing the “deployment” of the newly-added diagnostics framework. This project is a potential high-impact project with high output visibility, and reduce the barrier to entry to new users.

        Category: DX

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): eliaperantoni and mkarbo

        Skills: Software Engineering, Terminal Visualizations

        Expected Project Size: 175 to 350 hours*

        ~~~~~~~~~~

        Robust WASM Support
        Description and Outcomes: DataFusion can be compiled today to WASM with some care. However, it is somewhat tricky and brittle. Having robust WASM support improves the embeddability aspect of DataFusion, and can enable many practical use cases. A good conclusion of this project would be the addition of a live demo sub-page to the DataFusion homepage.

        Category: Build

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): alamb and waynexia

        Skills: WASM, Advanced Rust, Web Development, Software Engineering

        Expected Project Size: 175 to 350 hours*

        ~~~~~~~~~~

        High Performance Aggregations
        Description and Outcomes: An aggregation is one of the most fundamental operations within a query engine. Practical performance in many use cases, and results in many well-known benchmarks (e.g. ClickBench), depend heavily on aggregation performance. DataFusion community has been working on improving aggregation performance for a while now, but there is still work to do. A student working on this project will get the chance to hone their skills on high-performance, low(ish) level coding, intricacies of measuring performance, data structures and others.

        Category: Core

        Difficulty: Advanced

        Possible Mentor(s) and/or Helper(s): jayzhan-synnada and Rachelint

        Skills: Algorithms, Data Structures, Advanced Rust, Databases, Benchmarking Techniques

        Expected Project Size: 350 hours

        ~~~~~~~~~~

        Improving Python Bindings
        Description and Outcomes: DataFusion offers Python bindings that enable users to build data systems using Python. However, the Python bindings are still relatively low-level, and do not expose all APIs libraries like Pandas and Polars with a end-user focus offer. This project aims to improve DataFusion’s Python bindings to make progress towards moving it closer to such libraries in terms of built-in APIs and functionality.

        Category: Python Bindings

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): timsaucer

        Skills: APIs, FFIs, DataFrame Libraries

        Expected Project Size: 175 to 350 hours*

        ~~~~~~~~~~

        Optimizing DataFusion Binary Size
        Description and Outcomes: DataFusion is a foundational library with a large feature set. Even though we try to avoid adding too many dependencies and implement many low-level functionalities inside the codebase, the fast moving nature of the project results in an accumulation of dependencies over time. This inflates DataFusion’s binary size over time, which reduces portability and embeddability. This project involves a study of the codebase, using compiler tooling, to understand where code bloat comes from, simplifying/reducing the number of dependencies by efficient in-house implementations, and avoiding code duplications.

        Category: Core/Build

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): comphead and alamb

        Skills: Software Engineering, Refactoring, Dependency Management, Compilers

        Expected Project Size: 175 to 350 hours*

        ~~~~~~~~~~

        Ergonomic SQL Features
        Description and Outcomes: DuckDB has many innovative features that significantly improve the SQL UX. Even though some of those features are already implemented in DataFusion, there are many others we can implement (and get inspiration from). This page contains a good summary of such features. Each such feature will serve as a bite-size, achievable milestone for a cool GSoC project that will have user-facing impact improving the UX on a broad basis. The project will start with a survey of what is already implemented, what is missing, and kick off with a prioritization proposal/implementation plan.

        Category: SQL FE

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): berkaysynnada

        Skills: SQL, Planning, Parsing, Software Engineering

        Expected Project Size: 350 hours


        ~~~~~~~~~~

        Advanced Interval Analysis
        Description and Outcomes: DataFusion implements interval arithmetic and utilizes it for range estimations, which enables use cases in data pruning, optimizations and statistics. However, the current implementation only works efficiently for forward evaluation; i.e. calculating the output range of an expression given input ranges (ranges of columns). When propagating constraints using the same graph, the current approach requires multiple bottom-up and top-down traversals to narrow column bounds fully. This project aims to fix this deficiency by utilizing a better algorithmic approach. Note that this is a very advanced project for students with a deep interest in computational methods, expression graphs, and constraint solvers.

        Category: Core

        Difficulty: Advanced

        Possible Mentor(s) and/or Helper(s): ozankabak and berkaysynnada

        Skills: Algorithms, Data Structures, Applied Mathematics, Software Engineering

        Expected Project Size: 350 hours

        ~~~~~~~~~~

        Spark-Compatible Functions Crate
        Description and Outcomes: In general, DataFusion aims to be compatible with PostgreSQL in terms of functions and behaviors. However, there are many users (and downstream projects, such as DataFusion Comet) that desire compatibility with Apache Spark. This project aims to collect Spark-compatible functions into a separate crate to help such users and/or projects. The project will be an exercise in creating the right APIs, explaining how to use them, and then telling the world about them (e.g. via creating a compatibility-tracking page cataloging such functions, writing blog posts etc.).

        Category: Extensions

        Difficulty: Medium

        Possible Mentor(s) and/or Helper(s): alamb and andygrove

        Skills: SQL, Spark, Software Engineering

        Expected Project Size: 175 to 350 hours*

        ~~~~~~~~~~

        SQL Fuzzing Framework in Rust
        Description and Outcomes: Fuzz testing is a very important technique we utilize often in DataFusion. Having SQL-level fuzz testing enables us to battle-test DataFusion in an end-to-end fashion. Initial version of our fuzzing framework is Java-based, but the time has come to migrate to Rust-native solution. This will simplify the overall implementation (by avoiding things like JDBC), enable us to implement more advanced algorithms for query generation, and attract more contributors over time. This project is a good blend of software engineering, algorithms and testing techniques (i.e. fuzzing techniques).

        Category: Extensions

        Difficulty: Advanced

        Possible Mentor(s) and/or Helper(s): 2010YOUY01

        Skills: SQL, Testing Techniques, Advanced Rust, Software Engineering

        Expected Project Size: 175 to 350 hours*

        *There is enough material to make this a 350-hour project, but it is granular enough to make it a 175-hour project as well. The student can choose the size of the project based on their availability and interest.

          
    totalCharacters_of_ideas_content_parent: 10170
    totalwords_of_ideas_content_parent: 1940
    totalTokenCount_of_ideas_content_parent: 2086
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/apache-datafusion/
    idea_list_url: https://datafusion.apache.org/contributor-guide/gsoc_project_ideas



  - organization_id: 10
    organization_name: ArduPilot
    no_of_ideas: 6 
    ideas_content: |
          Non-GPS Position Estimation Using 3D Camera and Pre-Generated Map¶
          Skills required: Python, C++

          Mentor: Randy Mackay

          Expected Size: 175h

          Level of Difficulty: Hard

          Expected Outcome: Copter with low-cost 3D camera estimates its local position by comparing the camera point cloud to a pre-generated 3D map

          The goal of this project is to allow a Copter to estimate its local position using a low-cost 3D camera (e.g. Intel D465) by comparing the camera’s point cloud to a pre-generated 3D map. The steps involved include:

          Create a tool to capture a 3D map of the flight area. The resulting map should be loaded onto the vehicle’s companion computer (e.g. RPI5)

          Mount a low-cost 3D camera (e.g. Intel D465) onto an ArduPilot copter (e.g. EDU650 or similar) equipped with a companion computer

          Write localisation software (e.g. python code) to compare the output of the 3D camera to the pre-generated 3D map and send the estimated position to the vehicle’s EKF (see Non-GPS Position Estimation)

          Implement a simulator of the system (e.g. gazebo)

          Document the setup and operation for future developers and users

          Funding will be provided for hardware including a copter (e.g. Hexsoon EDU650), companion computer and 3D camera (e.g. Intel D465) if necessary

          ~~~~~~~~~~

          AI Chat WebTool for use with MP and/or QGC
          Skills required: JavaScript, OpenAI, Google Gemini

          Mentor: Randy Mackay

          Expected Size: 175h

          Level of Difficulty: Medium

          Expected Outcome: Web tool capable following a pilot’s verbal commands and converting them to MAVLink in order to control an ArduPilot multicopter

          This project involves re-implementing the MAVProxy’s AI chat module (see blog here) to run as a WebTool

          Once complete the WebTool should be capable of:

          Connecting to the vehicle via Mission Planner or QGC

          Responding to verbal or written questions and commands from the pilot

          Arming the vehicle

          Issuing takeoff commands and flying the vehicle a specified distance in any direction

          Changing the vehicle’s flight mode

          Most of the development can be completed using the SITL simulator and any OpenAI or Google Gemini usage costs will be covered

          ~~~~~~~~~~
           
          AI Chat Integration with all WebTools¶
          Skills required: JavaScript, OpenAI, Google Gemini

          Mentor: Randy Mackay

          Expected Size: 175h

          Level of Difficulty: Medium

          Expected Outcome: All WebTools include AI chat to help users understand and use the tool

          This project involves adding an OpenAI or Google Gemini chat window into some or all of the ArduPilot Webtools

          Once complete some or all of the WebTools should:

          Include a new chat widget allowing users to ask an AI assistant questions about the tool using text or voice

          Allow the AI assistant to operate the tool based on user input (e.g. push buttons, change zoom of graphs, etc)

          The top priority WebTool is the “UAV Log viewer” although simpler tools like the “Hardware Report” could be a good starting point

          Most of the development can be completed using the SITL simulator and any OpenAI or Google Gemini usage costs will be covered
          ~~~~~~~~~~


          Gazebo Plug-in Model of a Motor¶
          Skills required: Gazebo, C++

          Mentor: Nate Mailhot

          Expected Size: 175h

          Level of Difficulty: Medium

          Expected Outcome: ArduPilot Gazebo plugin simulates a Motor

          As part of the ArduPilot_Gazebo plugin, we ask a student to model the electromechanical properties of a motor (no thrust/aero, just the motor angular acceleration/power itself)
          ~~~~~~~~~~

          SITL AI Reinforcement Learning Concept Script¶
          Skills required: Gaazebo, Lua, AI

          Mentor: Nate Mailhot

          Expected Size: 175h

          Level of Difficulty: Medium

          Expected Outcome: Lua script that uses re-inforcement learning to automate changing some parameters

          An AP-SITL reinforcement learning script concept, focuses on using Lua applets or some python to automate parameter changes according to some basic implementation of online reinforcement learning (actor-critic/SARSA/Q-learning)
          ~~~~~~~~~~

          SITL Test Script for Controls Testing¶
          Skills required: Gaazebo, Python

          Mentor: Nate Mailhot

          Expected Size: 175h

          Level of Difficulty: Medium

          Expected Outcome: Python code that allows easily setting up an AP vehicle in SITL for controls testing

          A safe “for education/rookies” SITL test script that strips away the majority of complexity in set-up and gives a Copter (and Plane if time permits) that requires some basic tuning and gives hints/pointers in a UI (this could lower the threshold for earlier year mech/electrical engineers to get their hands dirty on some software and try out basic controls testing)

          
    totalCharacters_of_ideas_content_parent: 5201
    totalwords_of_ideas_content_parent: 1290
    totalTokenCount_of_ideas_content_parent: 1143
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/ardupilot/
    idea_list_url: https://ardupilot.org/dev/docs/gsoc-ideas-list.html


  - organization_id: 11
    organization_name: AsyncAPI
    no_of_ideas: 9
    ideas_content: |
          1) Enhancing Performance and Reliability of AsyncAPI CLI
          Improve the AsyncAPI CLI by optimizing performance, enhancing test reliability, and introducing long-requested features such as publishing and syncing AsyncAPI files with remote repositories.

          🎯 Outcome: Achieve a faster CLI execution, stable tests, file sync/publish support, and enhanced validation.
          🛠️ Skills Required: JavaScript/TypeScript, Node.js, Testing Frameworks, API, and testing automation.
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @AayushSaini101 | @Souvikns
          ⏳ Length: 175 Hours


          ~~~~~~~~~~
          2) AI-Powered Assistant for AsyncAPI
          Build an AI-powered assistant fine-tuned on AsyncAPI to provide accurate answers, generate code snippets, debug specifications, and recommend best practices.

          🎯 Outcome: A fine-tuned LLM-powered chatbot integrated with AsyncAPI’s ecosystem for enhanced developer support.
          🛠️ Skills Required: Javascript/Typescript, Machine Learning (LLMs), NLP, OpenAI/Llama, Chatbot Integration.
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @AceTheCreator
          ⏳ Length: 175 Hours

          ~~~~~~~~~~
          3) AsyncAPI Generator Maintainership
          This initiative aims to guide you from contributing to maintaining the project. You'll gain insight into the responsibilities of a maintainer, which involve tasks beyond mere coding.

          🎯 Outcome: Responsible for the project's future and continuous improvement.
          🛠️ Skills: JavaScript/TypeScript, testing libraries, Docker, virtualization, and test automation.
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @derberg
          ⏳ Length: 350 Hours

          ~~~~~~~~~~
          4) AsyncAPI Conference Website UI Kit Development
          Develop a comprehensive UI Kit to enhance design consistency, modularity, and maintainability of the AsyncAPI Conference website.

          🎯 Outcome: A structured UI Kit with reusable components, Storybook integration, and improved design consistency.
          🛠️ Skills Required: React, TypeScript, Storybook, UI/UX Design, Component Development.
          🧩 Difficulty: Medium
          👩🏿‍🏫 Mentor(s): @AceTheCreator
          ⏳ Length: 175 Hours

          ~~~~~~~~~~
          5) VS Code Extension Maintainership
          This initiative will guide you from contributing to becoming a maintainer of the VS Code AsyncAPI Preview extension. You'll learn the responsibilities of a maintainer, including code contributions, issue triaging, release management, and community engagement.

          🎯 Outcome: Taking ownership of the VS Code extension to ensure its long-term stability and improvement.
          🛠️ Skills Required: TypeScript/JavaScript, VS Code Extensions, Spectral Linting, Testing, and Open Source Contribution.
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @ivangsa
          ⏳ Length: 350 Hours

          ~~~~~~~~~~
          6) Java + Quarkus Template for AsyncAPI Generator
          Develop a new AsyncAPI Generator template for Java with Quarkus, leveraging its growing adoption in cloud-native development.

          🎯 Outcome: A fully functional Java + Quarkus template for generating AsyncAPI-based applications.
          🛠️ Skills Required: Java, Quarkus, Templating Engines (Nunjucks/Handlebars), AsyncAPI Generator.
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @AayushSaini101, @Souvikns
          ⏳ Length: 350 Hours
          ~~~~~~~~~~
          7) Refactor the Scripts inside the website and add Integration tests
          Add the script execution to a new folder inside the website, and add integration tests for those scripts.

          🎯 Outcome: A full Unit + Integration tests setup will be added for the scripts to fully test the functionalities
          🛠️ Skills Required: Typescript, Node js, Jest, Github actions
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @akshatnema
          ⏳ Length: 350 Hours
          ~~~~~~~~~~
          8) Add E2E tests for the Website critical flows
          Add E2E tests for the website where some of the critical flows (that are centered around user experience are tested thoroughly).

          🎯 Outcome: This project will ensure that we are not breaking any critical flows where user experience is our topmost priority
          🛠️ Skills Required: Typescript, Node js, E2E Testing, Github actions
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @sambhavgupta0705
          ⏳ Length: 175 hours
          ~~~~~~~~~~
          9) Redesign of website and addition of Dark theme
          Create new designs for the website pages based on the theme chosen by @Mayaleeeee and replicate those designs inside the website, along with the Dark mode theme.

          🎯 Outcome: This project will ensure that we are not breaking any critical flows where user experience is our topmost priority
          🛠️ Skills Required: Typescript, Node js, Figma, TailwindCSS
          🧩 Difficulty: Medium/Hard
          👩🏿‍🏫 Mentor(s): @Mayaleeeee, @devilkiller-ag
          ⏳ Length: 350 hours

          
    totalCharacters_of_ideas_content_parent: 5231
    totalwords_of_ideas_content_parent: 1242
    totalTokenCount_of_ideas_content_parent: 1147
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/asyncapi/
    idea_list_url: https://github.com/asyncapi/community/blob/master/mentorship/summerofcode/2025/asyncapi-gsoc-ideas-page.md



  - organization_id: 12 
    organization_name: BRL-CAD 
    no_of_ideas: 25
    ideas_content: |
          Improving the k-File to BRL-CAD Converter
          Outline
          In the past years, we put some effort in the development of a LS-DYNA keyword file to BRL-CAD converter. Although we made great progress there, we still can't convert every k-file to g, i.e. the native BRL-CAD format. The goal of this project is to increase the number of covertable k-files.

          Details
          The sources of the current k-file to BRL-CAD converter can be found in the brlcad repository at src/conv/g. You have to compile BRL-CAD from its sources to work on this project and see the effects of your changes.

          Examples of k-files, which cannot be converted with k-g, can be found here: THUMS You can however use your own examples.

          Expected Outcome
          We expect an improved k-g LS-DYNA keyword file to BRL-CAD converting program as the outcome from this project.

          Project Properties
          Skills
          C/C++
          LS-DYNA or a similar FE solver software, which can read k-files (needed as reference for how the geometry should look like)
          Difficulty
          medium

          Size
          This project could have any size, short (90h), medium (175h) or long (350h), depending on the amount of functionality you want to add.

          Additional Information
          Potential mentor(s):
          Ali Haydar
          Daniel Rossberg
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com

          ~~~~~~~~~~

          Development and Build Support for Native Windows
          Outline
          OpenSCAD is multi-platform desktop application, with official support for Windows, macOS and Linux, and unoffical support for various other Unix-like OSes like FreeBSD.

          While OpenSCAD does support Windows, Windows development and build setup is a bit suboptimal:

          Windows binaries are built on Linux using the MXE cross compilation environment (https://mxe.cc). Build setup
          Windows native builds, including tests are done on msys2 (https://www.msys2.org) Build setup
          Goal of this project is to improve Windows support for native Windows development.

          Details
          Adjust OpenSCAD source code as needed to build OpenSCAD using MSVC
          Adjust the CMake build system as needed to support MSVC
          Find a way of managing building (and packaging if needed) 3rd party dependencies. OpenSCAD depends on a number of 3rd party packages (e.g. Qt, QScintilla2, CGAL, Manifold, GMP, MPFR, boost, OpenCSG, GLEW, Eigen, glib2, fontconfig, freetype2, harfbuzz, libzip, Bison, Flex, double-conversion). Not all of these have great Windows build support.
          Integrate library building/packaging into our Continuous Integration framework (e.g. GitHub Actions or CircleCI).
          Build OpenSCAD on MSVC + run tests natively for every PR, as we do for other build environments. This to make sure contributions don't fall out of maintenance.
          Establish support for debugging OpenSCAD in the MSVC debugger, and documentation on how to set that up, if necessary
          Write/update documentation on how to establish a native WIndows development environment
          Consider switching the official OpenSCAD Windows build to use MSVC.
          Prior work: openscad/openscad#4976

          Expected Outcome
          A native MSVC build environment for OpenSCAD is reasonable easy to set up, and such an environment is continuously integrated.

          Project Properties
          Skills
          Good understanding of the Windows OS and native components (DLLs, executables) on a low enough level to be able to debug odd behaviors.
          Experience using MSVC and native Windows development for C++ projects
          Good understanding of how 3rd party libraries are built and distributed.
          Experience with or interest in acquiring skills using CMake and writing custom CMake configs and macros
          Experience with GitHub CI or CircleCI is a bonus
          Difficulty
          medium

          Size
          long (350h)

          Additional Information
          Potential mentor(s): Marius Kintel (IRC: kintel), Torsten Paul (IRC: teepee)
          Note: None of the mentors have relevant Windows skills, but have excellent understanding on how all the relevant technologies work and how they are integrated with OpenSCAD. It's important that the candidate is able to acquire any necessary Windows-specific skills independently.
          Organization website: https://www.openscad.org/

          ~~~~~~~~~~

          Integrated language help feature in OpenSCAD #100
          Outline
          Add more interactive help features for built-in functions and modules. Right now there's already a nice summary of parameters linked as cheat sheet. Scope of this projects would be to use this information in extended form and make it available in a more direct way in the editor.

          Details
          Convert the cheat sheet information into machine readable format
          Find a way to generate the existing HTML format based on the core data
          Add context help to editor giving help for built-in functions and modules, e.g. by adding formatted help output to the console window, including the links to further documentation like the language manual on Wikibooks
          Expected Outcome
          Cheat sheet is integrated into the application and additional context help for built-in functions and modules is available.

          Project Properties
          Skills
          Programming language is C++
          GUI programming with the Qt framework
          Difficulty
          Easy

          Size
          Medium (175h)

          Additional Information
          Potential mentor(s): Marius Kintel (IRC: kintel), Torsten Paul (IRC: teepee)
          Organization website: https://www.openscad.org/


          ~~~~~~~~~~

          Create a compelling interface and functionality for the IfcOpenShell WASM / pyodide module #99

          Outline
          http://wasm.ifcopenshell.org/

          Details
          Expected Outcome
          Future Possibilities
          Project Properties
          Skills
          Difficulty
          Size
          Additional Information
          Potential mentor(s): NAME
          Organization website: https://
          Communication channels: https://******.zulipchat.com


          ~~~~~~~~~~

          Authoring interface for IFC4.3 alignment geometry in Bonsai #98
          Outline
          Industry Foundation Classes (IFC) offer the ability for rich information exchanges between modeling, analysis, planning, and other software tools in the Architecture, Engineering, and Construction (AEC) industry. Specifically, the latest release of IFC (version 4.3, also referred to as IFC4X3) adds linear referencing via alignment modeling, which is core to describing the construction and maintenance of infrastructure assets such as roads, bridges, and railways.

          Details
          Alignment import (read) capabilities have been added to IfcOpenShell and the Bonsai add-in for Blender. They have reached a state of maturity such that the next logic step is to enable alignment authoring (write) capabilities.

          Expected Outcome
          Alignment authoring will take place in Blender via the Bonsai add-in. A user-focused workflow has been developed and documented, along with preliminary user interface mockups. This project would add alignment authoring capabilities via new panels and other items within Blender. The ifcopenshell.api namespace will also need to be enhanced incrementally to support the new user interface tools.

          Project Properties
          Skills
          Understanding and general working knowledge of python.

          Difficulty
          Medium

          Size
          Medium (175 h)
          The participant focuses on authoring horizontal alignments via the PI method. This could be via interactive icons or primarily through a table-based interface. The user would need to be able to add, edit, and remove PI (point of intersection) points. Additionally the user would need to be able to adjust the radius that corresponds to each PI point. Though not strictly required for this project, the authoring tool would also enable definition and editing of entry and exit transition curve type (clothoid, sine spiral, polynomial spiral, etc.) and length.

          Long (350 h)
          PI-based alignment would be added for vertical and cant as well. A basic corridor modeling UI tools would be implemented to allow for sweeping geometry (open or closed profile) along an alignment curve to generate 3D linear geometry via IfcSectionedSolidHorizontal and related IFC entities.

          Additional information
          Mentors: Rick Brice @RickBrice & Scott Lecher @civilx64

          Organization website: https://ifcopenshell.org

          Communication channels: https://github.com/IfcOpenShell/IfcOpenShell/discussions

          Technical resources:

          https://docs.bonsaibim.org/guides/development/index.html

          Blender 4.3: Precise Modeling for Architecture, Engineering, and 3D Printing

          Python Scripting in Blender


          ~~~~~~~~~~

          Manifoldness repair 
          Outline
          Repair triangle soup that are not manifold.

          Details
          Basically, a valid solid mesh should be both manifold and has no self-intersection. However, models from the internet may contain defects. This project is about coming up with an algorithm that converts and repair a triangle soup into a manifold mesh.

          This will contain a lot of heuristics, basically what we need is:

          Stitching faces together, and maybe join faces that are close enough.
          Fill holes.
          Duplicate vertices and edges such that the result is a manifold in terms of connectivity.
          Expected Outcome
          Implementation of said algorithm.

          Future Possibilities
          Project Properties
          Skills
          C++
          Graph data structure.
          Algorithms.
          Difficulty
          Hard.

          Size
          Long (350h)

          Additional Information
          Potential mentor(s): @elalish @pca006132
          Organization website: https://manifoldcad.org/
          Communication channels: https://github.com/elalish/manifold/discussions

          ~~~~~~~~~~

          Overlap removal
          Outline
          Remove overlaps in meshes that contain self-intersection, assuming the mesh is a manifold.

          Details
          Basically, a valid solid mesh should be both manifold and has no self-intersection. However, models from the internet may contain defects. This project is about coming up with an algorithm that removes self-intersections.

          See elalish/manifold#289 for details about ideas for the algorithm.

          Expected Outcome
          Implementation of said algorithm.

          Future Possibilities
          Project Properties
          Skills
          C++
          Graph data structure.
          Algorithms.
          Difficulty
          Hard.

          Size
          Long (350h)

          Additional Information
          Potential mentor(s): @elalish
          Organization website: https://manifoldcad.org/
          Communication channels: https://github.com/elalish/manifold/discussions

          ~~~~~~~~~~

          Creation of an IFC geometry library in IfcOpenShell that uses Manifold

          Outline
          For the past 10 years, IfcOpenShell has had a tight coupling with OpenCASCADE as its only geometry library and OCCT providing the datatypes in the IfcOpenShell C++ APIs.

          In IfcOpenShell v0.8 an additional abstraction is introduced over the geometric concepts in IFC (taxonomy.h) and the evaluation of such concepts using pre-existing geometry libraries (AbstractKernel).

          Also in v0.8, CGAL is introduced as an additional runtime selectable choice besides OpenCASCADE, because of (a) it's extensive set of modules for analysis (e.g convex decomposition, skeleton, ...) and (b) it's arbitrarily robust (and precise) implementation of boolean operations using Nef polyhedra on a number type represents a binary tree of operands taking part in the construction of that number.

          Both OpenCASCADE and CGAL are high quality efforts, but quite complex and resulting in fairly large compiled object sizes. This project proposal aims at introducing Manifold as a 3rd geometry library implementation. Manifold is modern, efficient and robust.

          https://github.com/elalish/manifold

          cc @elalish just fyi.

          Expected Outcome
          Another AbstractKernel implementation that uses Manifold to evaluate a small set of geometrical concepts (boolean, extrusion, brep for example) in IFC. Expecting reasonable outcomes on a small building model (such as the Duplex A model) without necessarily resolving all complexities and corner cases encountered in that model.

          Future Possibilities
          Comparison between implementations and development of a hybrid composition of these libraries that based on prior inspection picks the most suitable implementation for a specific IfcProduct or representation item. For example, OpenCASCADE will likely still excel at curved surfaces (e.g nurbs), but suffers a monumental performance overhead when ingesting detailed triangular meshes (that are also prevalent in IFC) due the overheads of it BRep data model.

          Additional Information
          Potential mentor(s): Thomas Krijnen (aothms)



          ~~~~~~~~~~

          Turn BlenderBIM into a client for remote BIM-collaboration on existing OpenCDE-API-server with a graph backend

          Outline
          The project aim is to turn BlenderBIM into a client for remote BIM-collaboration and a client for remote BIM-model-sharing through a Common Data Environment (a CDE working as BIM/IFC-server) using the already developed OpenCDE API server and the OpenCDE API specifications provided by buildingSMART: BCF API and Documents API.

          OpenCDE API:s are open standards. This project will hence enable usage of BlenderBIM as a client on other BIM-servers that implements the OpenCDE API:s.

          Details
          An OpenCDE API server that implements all buildingSMART OpenCDE API:s (BCF API, Documents API and Foundation API) has been developed in python and the FastAPI framework. Solibri Office was used as a client for testing this server software during development.

          The code of the OpenCDE server is located in the IfcOpenShell repository here: https://github.com/IfcOpenShell/IfcOpenShell/tree/v0.7.0/src/opencdeserver

          The OpenCDE API:s is a set of open API-specifications provided by buildingSMART. https://github.com/buildingSMART/OpenCDE-API

          BIM Collaboration Format (BCF) API is used for collaboration on shared BIM models through a remote BCF-server. BCF API has the same purpose as BCF XML (which is a file format) but the difference is that the data is communicated as JSON through a BCF-server, instead of sending XML-files. https://github.com/buildingSMART/BCF-API
          Documents API is used communication between a client and a CDE (acc. ISO 19650-1). The purpose is a common data environement for sharing models, documents et.c. https://github.com/buildingSMART/documents-API
          Foundation API is used for authentication et.c. and must be implemented by any client or server that implements anyone of the other two OpenCDE API:s. https://github.com/buildingSMART/foundation-API
          To summarize: The model (the IFC data) will normally be shared to the server using Documents API, and downloaded form the server using Documents API. BCF API can be used for remote collaboration on the models located on the server et.c.

          The purpose of the open API specification is to enable independent development of clients and servers that can communication with eachother. A server has already been developed and shared as open source on IfcOpenShell. However, at the moment there is no open source client with a graphical user interface for the OpenCDE API:s. A python library for BCF API communication is available: https://pypi.org/project/bcf-client/.

          The aim of this project is to turn BlenderBIM into a OpenCDE-client (a client that already have BIM-capabilities) that can communicate remotely with (and make use of) the existing open source OpenCDE-server on: https://github.com/IfcOpenShell/IfcOpenShell/tree/v0.7.0/src/opencdeserver

          An add-on for GIT-collaboration have already been developed:

          https://blenderbim.org/docs/users/git_support.html
          https://www.youtube.com/watch?v=cJZhSCSSWdA
          Collaboration using Documents API and BCF API is just another way of collaboration. This way of collaboration might be more suitable for AEC-professionals who does not have experience of GIT. Som features of GIT are not possible. But other features that are possible when using the OpenCDE API:s are not possible using GIT.

          Expected Outcome
          The BlenderBIM can connect as a client to the OpenCDE API server using the Foundation API
          User management functionality is added to OpenCDE API server: Register, invite, delete users
          BlenderBIM is a BCF API client - can collaborate on BIM-models remotely using the already developed OpenCDE-server
          BlenderBIM is a Documents API client - can share/download BIM-models remotely with the already developed OpenCDE-server
          User interface in BlenderBIM for setting up OpenCDE-server on localhost and user management (inviting collegues, adding/deleting users et.c.)
          User interface in BlenderBIM for remote BIM collaboration using BCF API
          User interface in BlenderBIM for remote model download and sharing using Documents API
          Simplify the process of turning your computer into an OpenCDE-server and inviting colleages to collaborate on your BIM model
          Simplify the process of deploying the OpenCDE-server as a BIM-server to the cloud for remote collaboration with BlenderBIM as a client
          Extra: Implement som of the routes/endpoints of the OpenCDE API specifications that Solibri Office does not support. I.e. implement the full official buildingSMART open specifications using the open source server (OpenCDE API server) and open source client (BlenderBIM).

          Future Possibilities
          IFC-server capabilities: Round-tripping of IFC data between IFC STEP (or python or C++ objects in IfcOpenShell) and the OpenCDE API server graph DB. More info on storing IFC data as label property graph (LPG) here: https://www.sciencedirect.com/science/article/pii/S0926580523000389
          Potential synergies with the other GSoC project "Web-based UI integration with Blender" Web-based UI integration with Blender #87 because the Web-based UI could be hosted by the same OpenCDE API server as in this project.
          Visualization of IFC data as graph in that Web-based UI. For example using pyviz or similar tools.
          Project Properties
          Skills
          Python, including how to setup a minimal basic server on localhost using FastAPI. https://fastapi.tiangolo.com/
          Blender Python API to develop user interfaces in BlenderBIM.
          Cypher query language and any graph DB that implements Cypher (such as Neo4j or MemGraph). https://neo4j.com/docs/cypher-manual/current/introduction/
          API development.
          Difficulty
          Hard

          Size
          Long (350h)

          Additional Information
          Potential mentor(s): [Martin Wiss]
          Organization website: https://blenderbim.org/ http://ifcopenshell.org/
          Communication channels: OSArch

          ~~~~~~~~~~

          Geometry Verification and Validation GUI in Qt (AI Project)

          Outline
          Help develop a new GUI application that checks geometry for common issues and/or helps fix them.

          Details
          A new GUI is in prototype development (built on Arbalest) that checks geometry files for common verification and validation (V&V) issues such as topology errors, solidity errors, and more. It's very much an experimental work in progress and we'd like your help to make it complete. The overarching goal of this effort is to extend our prototype in a significant way, either improving usability, checking for more issues, improving the Qt GUI infrastructure integration, integrating workflow(s) for review and repair, or leveraging AI to identify and/or fix issues.

          Expected Outcome
          You will propose a complete project description that identifies the specific objectives you'll aim to achieve. It's expected that you'll leverage the previous work (talk with us to get access to those materials). The proposal should identify 3-10 primary objectives that are researched and specific, starting with our previous effort.

          We essentially want a tool that "compiles" geometry reporting warnings and errors for issues encountered, akin to compiling source code in Visual Studio or Eclipse. There are questions of application architecture to resolve (e.g., whether to extend 'arbalest', integrate 'qged', integrate 'gist', etc). We want the tool to be graphical and interactive. We want it to have the ability to generate reports for auditing. Some of those capabilities exist in isolation, but none exist as a tool tailor-made for 3D geometry V&V.

          Future Possibilities
          This is a long term priority project with future possibilities in:

          GUI infrastructure
          AI integration
          geometry healing and repair workflows
          geometry auditing
          geometry standards development
          Skills
          Qt, C/C++

          Difficulty
          Easy or Medium depending on the objectives

          Size
          long (350h) preferred, but medium (175h) also possible

          Additional Information
          Potential mentor(s): Sean Morrison
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com
          https://brlcad.org/design/v&v/


          ~~~~~~~~~~

          Blender UI / integration with voxelisation toolkit software

          Outline
          There is software known as the Voxelisation Toolkit (pip install voxec). It converts the 3D model into voxels (e.g. 3D cubes that represent geometry), analyses and transforms those voxels, and outputs statistics (e.g. distance between voxels, etc).

          Image

          Image

          Voxels are super cool and can be used to calculate head heights, resolve complex non-manifold geometry, egress distances, or concrete formwork areas and strutting distances, and air volume for mechanical calculations. All of this stuff is useful for engineers and construction professionals.

          This project is to add a UI in Blender to start making this general purpose analysis tool available to non-programmers.

          Details
          You will be expected to design an interface for the voxelisation toolkit, prepack some simple recipes, and write scripts that take the output (currently visualised as images or plots) and instead visualise the results in 3D by generating 3D coloured meshes that represent the output.

          Expected Outcome
          Bundle the voxelisation toolkit software with Blender.
          A UI to execute the voxelisation toolkit.
          Simple presets to run the toolkit.
          Visualise the output of the voxelisation analysis as a 3D coloured mesh.
          Future Possibilities
          Bundle scripts for common usecases, like formwork calculation, air volume calculation, or external / internal metadata addition.

          Project Properties
          Skills
          Python
          Difficulty
          Medium

          Size
          Medium to Long

          Additional Information
          Potential mentor(s): Dion Moult, Thomas Krijnen
          Organization website: https://blenderbim.org http://ifcopenshell.org
          Communication channels: https://osarch.org/chat


          ~~~~~~~~~~

          Features for CG artists to visualise beautiful IFC models in Blender 
          Outline
          The architecture, engineering, and construction industry creates 3D models of buildings. These models are generally quite poor and do not contain any textures, lighting, or high quality objects that are suitable for 3D rendering. They often hire artists to help create beautiful renders of their designs.

          This project will build utility functions and workflows to easily get beautiful pictures of 3D models.

          Details
          3D artists typically do the following steps to make a 3D model look beautiful. They:

          Set camera angles with specific camera settings, with "clay" (e.g. all white colours) materials.
          Add lights and sun / sky settings.
          Add simple colours and textures.
          Remodel low quality geometry
          Add new objects (e.g. entourage) to decorate the scene, like trees, grass, people, extra furniture, walruses, shrimp, etc.
          Set common compositing and post processing rules
          You will use the Blender Python API to set simple presets for most of these steps to allow less skilled artists to quickly setup renders. You will also setup a workflow to guide artists on how to organise their files relative to the IFC model and keep the IFC model separate so that when the IFC model is changed, the artists doesn't need to start from scratch or play spot the difference.

          You do not need to be an expert in 3D modeling or CG visualisation or rendering. You will be taught what type of settings and options are appropriate for presets and the details of the workflow. However, you will be expected to automate that detail (every aspect of the Blender settings can be set using Python trivially).

          You will also be expected to create a Blender interface to interact with the settings, e.g. a button to add camera, a button to set a preset sky, etc.

          Expected Outcome
          Note: scope is flexible and you may achieve less or more or different to the below:

          A graphical interface in Blender that relate to the 6 steps above
          Buttons to add cameras, set common camera aspect ratios and settings. Buttons to add common types of lights, set sun angles and sky settings with bundled HDRI textures.
          Buttons to add simple material presets.
          Buttons to mark an object to be replaced by another
          A few preset assets using Blender's built in asset tools to drag and drop in entourage.
          Future Possibilities
          Project Properties
          Skills
          Python (definitely required!)
          Artistic sense (do you like 3D graphics? rendering?) If you have ever rendered a 3D scene before, this is the project for you!
          Difficulty
          Easy to Medium

          Size
          Medium to Long

          Additional Information
          Potential mentor(s): Dion Moult
          Organization website: https://blenderbim.org http://ifcopenshell.org
          Communication channels: https://osarch.org/chat

          ~~~~~~~~~~

          Implement 3D mesh offset
          Outline
          Implement efficient 3D mesh offset, instead of using minkowski sum with high resolution spheres. (elalish/manifold#192)

          Details
          3D mesh offset is a useful feature that many users asked for, but is difficult to implement efficiently. Many users use minkowski sum with sphere to perform positive offset, but this can be very slow due to the need for exact convex decomposition.

          Our approach will only work for positive offset, negative offset can be implemented by performing additional mesh boolean operations, so this is not an issue. The approach has four phases:

          Figure out all pairs of faces that do not share any vertex and may overlap after offsetting. (let's call them conflict pairs)
          Cut the mesh in a way such that for each part, no two faces are in the same conflict pair. (decomposition step, requires monte carlo tree search)
          Perform the positive offset on each part, using a modified algorithm from Offset Triangular Mesh Using the Multiple Normal Vectors of a Vertex. Note that we need to figure out how to blend the surfaces for smooth results.
          Union the parts.
          Expected Outcome
          A fast 3D mesh decomposition algorithm!

          Project Properties
          Skills
          C++
          Graph data structure.
          Algorithms.
          Difficulty
          Hard.
          Size
          Long.
          Additional Information
          Potential mentor(s): @elalish @pca006132 @zalo
          Organization website: https://manifoldcad.org/
          Communication channels: https://github.com/elalish/manifold/discussions


          ~~~~~~~~~~

          Add fuzzing tests

          Outline
          Add more fuzzing tests for both 2D and 3D operations.

          Details
          Fuzzing is an effective technique to expose bugs in software. Fuzzing tests randomly generate structured inputs (according to specification), and test if the program crashes/failed assertions.

          This project aims to test 2D and 3D CSG operations on geometrically valid polygons/meshes. To do this, we will define a very simple AST for our CSG operations, and use the recursive domain feature of fuzztest for the tests.

          We will also randomly apply slight perturbation to make the valid geometry only epsilon-valid, to test for robustness of the algorithm.

          Expected Outcome
          Fuzz tests that test for union, intersection, difference, 2D extrude/revolve, etc.

          Project Properties
          Skills
          C++
          Basic understanding of graph data structure.
          Difficulty
          Medium
          Size
          Medium
          Additional Information
          Potential mentor(s): @pca006132
          Organization website: https://manifoldcad.org/
          Communication channels: https://github.com/elalish/manifold/discussions


          ~~~~~~~~~~

          Physically-Based Rendering (PBR) advanced shaders
          Outline
          Get BRL-CAD physically-based rendering working with advanced shaders.

          Details
          BRL-CAD recently integrated with Appleseed which provides physically-based rendering. It's presently a command-line renderer called 'art'. For art rendering to work, a shader and colors are specified on geometry. BRL-CAD has preliminary support for material objects including OSL shaders and MaterialX shaders in art, however their support has only been tested with basic shaders such as the Disney Principled Shader. It's hard-wired to single-file shaders.

          Expected Outcome
          The goal of this task will be to make art read and work with any OSL or MaterialX shader networks, including ones using texturing, emission, subsurface scattering, etc. applied to BRL-CAD geometry.

          Project Properties
          Skills
          Decent C/C++ skills
          Some basic familiarity with PBR.
          Basic familiarity with shaders.
          Difficulty
          medium

          Size
          long

          Additional Information
          Potential mentor(s): Sean Morrison
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com


          ~~~~~~~~~~

          Improve FreeCAD Hidden Line Removal
          Outline
          FreeCAD's Technical Drawing module (TechDraw) relies heavily on the OpenCascade Hidden Line Removal algorithms. These algorithms can be very slow, do not provide progress reporting and do not provide any linkage between the input shape and the output.

          Details
          The TechDraw module provides projections, section views and detail views of 3D model components and assemblies developed in FreeCAD modules such as Part, PartDesign and Draft.

          Expected Outcome
          a) develop new code for projecting shapes and creating the geometry for technical drawings.
          -or-
          b) modify the existing OpenCascade code as an enhancement.

          Project Properties
          Both OpenCascade and TechDraw are written in C++.

          Skills
          The student should have a good knowledge of C++ and be familar with graphics topics such as the painters algorithm, face detection and hidden line removal.
          Knowledge of technical drawing standards and previous exposure to Qt will be helpful. Familiarity with OpenCascade is a definite plus.

          Difficulty
          Hard

          Size
          long

          Additional Information
          Potential mentor(s): wandererfan
          Organization website: https://freecadweb.org
          Communication channels: https://forum.freecadweb.org


          ~~~~~~~~~~

          Continuation of a prior BRL-CAD GSoC effort
          Outline
          BRL-CAD has been participating in GSoC for over 10 years with nearly 100 students! Any past accepted projects can be submitted as a continuation project.

          Details
          You can find all past participants documented on BRL-CAD's wiki by selecting a given year (e.g., 2018). Even the most successful and completely integrated projects have room for improvement! If any of those past efforts for any prior year sound very interesting to you, you can propose a continuation effort for it.

          Of course, you will need to research the prior effort to determine the status of the work, whether code was integrated or is sitting pending integration in a patch, whether it's functional or was in an intermediate state, etc. You'll also want to come chat with us on Zulip to make sure there is mentoring support for it, but there usually is if you're passionate and independently productive.

          For your proposal, note that it's a continuation effort. Explain what you are doing and how it relates to the prior effort. It's strongly recommended that your development plan focus on production-quality integration aspects such as making sure there are no usability or user experience (UX) issues, no build integration issues, that testing is covered adequately, and with focus on UX.

          Expected Outcome
          The expected outcome of a continuation effort is new capability and features that are "complete", integrated, bug-free, and issue-free, in the hands of users. This means your project covers all vertical integration aspects of development integration including build system and usability / UX concerns. Not prototyped. Not simply rewritten or re-attempted.

          If the prior effort was integrated, your outcome will be specific polish, adaptiveness, and robustness improvements.

          If the prior effort was not integrated, your outcome will be issue-free integration that addresses prior issues preventing integration (which will require research and understanding on your part).

          Project Properties
          Skills
          This varies greatly by continuation. There are continuation projects for C/C++, Python, Javascript/Node.js, Tcl/Tk, OpenCL, OpenGL, Qt, GPGPU, and more.

          Difficulty
          Varies.

          Size
          You are welcome to scope your project medium (175h) or long (350h) depending on the objectives and development scope.

          Additional Information
          Potential mentor(s): Morrison (contact devs@brlcad.org)
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com

          ~~~~~~~~~~

          Implement AP242 STEP geometry importer for BRL-CAD
          Outline
          Implement a geometry importer for the ISO 10303 STEP AP242 standard.

          Details
          BRL-CAD has geometry import support for STEP AP203 (v1), but AP242 has emerged as its industry replacement. This project entails implementing as comprehensive import support as possible in BRL-CAD.

          In order to track implementation progress and manage development risk, you will need to track implementation coverage by setting up a dashboard similar to what is used by the CAx-IF -- it can be a simple text file or web page.

          Existing conversion support can be examined for AP203 and other formats in BRL-CAD's repository under src/conv/step

          Expected Outcome
          New AP242 importer that converts STEP entities into BRL-CAD's .g geometry file format.

          Future Possibilities
          AP242 export support...

          Project Properties
          Skills
          C/C++
          STEPcode

          Difficulty
          Hard.

          Size
          This project can be scoped medium (175h) or long (350h) depending on your familiarity and expertise, or you can propose a subset of entities in a shorter timeframe (note though that advanced boundary representation entities should be prioritized).

          Additional Information
          Potential mentor(s): Morrison (contact devs@brlcad.org)
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com

          ~~~~~~~~~~

          BRL-CAD Python bindings
          Outline
          Implement bindings for the BRL-CAD functionality to Python programming language

          Details
          There are long time on-going efforts to wrap BRL-CAD functionality with python code, e.g.

          https://github.com/kanzure/python-brlcad
          https://github.com/nmz787/python-brlcad-tcl
          These projects are however still in early development stages.

          Expected Outcome
          A Python module which can read and write BRL-CAD databases, and provide access to their contents to read, create, and modify the objects.

          Project Properties
          Skills
          C/C++
          Python
          Difficulty
          This project may be of easy or medium difficulty, depending on your familiarity and expertise.

          Size
          This project can be scoped medium (175h) or long (350h), depending on the amount of functionality you want to include.

          Additional Information
          Potential mentor(s):
          Daniel Rossberg
          Sean Morrison
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com


          ~~~~~~~~~~

          Webapp to create and check BIM project exchange requirements for IfcOpenShell
          Outline
          When projects exchange data, we often need to set contractual requirements about what data we expect to see in their CAD or Building information data. The is an international standard for describing project requirements in XML called the Information Delivery Specifications (IDS).

          There is a half-built webapp which allows viewing and minor editing of IDS files here: https://blenderbim.org/ifctester/

          Your job would be to finish this web app, building features for more editing, drag and drop from a library of specifications, adding and removing requirements, etc.

          Expected Outcome
          A working example of the web application.

          Project Properties
          Skills
          HTML, CSS, and vanilla Javascript (i.e. no frameworks).
          Difficulty
          Easy

          Additional Information
          Potential mentor(s): Dion Moult
          Organization website: https://ifcopenshell.org
          Communication channels: https://community.osarch.org , ##architect on Freenode , and https://github.com/IfcOpenShell/IfcOpenShell/issues


          ~~~~~~~~~~

          Scripts for generating simple animations (e.g. appear / disappear, bounce, appear left to right, fade in from above, etc)

          Outline
          Often, construction firms need to visualise animations of construction sequencing. A project timeline will be created, and related to individual model elements. For example, when a concrete slab is poured, it is linked to a 3D object called a slab. We need the ability to automatically generate animations from Blender where objects appear / disappear in various different ways when they start / end their task in the project timeline. The systems for describing project timelines is already in place, so now we need a little animation generator!

          Details
          Expected Outcome
          A series of small scripts that take objects and can automatically animate the visibility, locations, or staggered appearances of building elements, as well as sub elements, and basic scripts that correlate real world time to animation frames, and frames per second, and generate an animated timeline bar in various styles.

          Future Possibilities
          This animation system can be then used from BIM models either in Blender, FreeCAD, or via other software altogether, so it has quite a large impact on the ecosystem.

          Skills
          Basic knowledge of the principles of animation (keyframing)
          Basic Blender animation (you can do some tutorials and get up to speed pretty quick)
          Python
          Artistic sense! We should offer beautiful and elegant animations!
          Difficulty
          Easy

          Additional Information
          Potential mentor(s): Dion Moult
          Organization website: https://ifcopenshell.org
          Communication channels: https://community.osarch.org , ##architect on Freenode , and https://github.com/IfcOpenShell/IfcOpenShell/issues


          ~~~~~~~~~~

          NURBS Editing Support in BRL-CAD

          Outline
          Implement the prerequisites for NURBS editing in BRL-CAD's GUIs

          Details
          BRL-CAD has support for raytracing of NURBS surfaces implemented, but they are handed over as BLOBs to the openNURBS library. Beyond basic operations such as rotation and translation, the BRL-CAD core has no ability to edit them. This project would implement support for editing NURBS curves and surfaces in the BRL-CAD core, thus creating the prerequisites to handle them with higher level (i.e. GUI) tools.

          See this task's description in former GSoCs for some more information: https://brlcad.org/wiki/NURBS_Editing_Support

          The key-feature would be to have ged command(s) that lets you build NURBS objects from scratch. This could be done by having a declarative ASCII description of these entities and/or wrapping the openNURBS library by a scripting language.

          Describe in your proposal which approach you want to use and why. You may let inspire you by solutions in other programs:

          NURBS-Python: https://github.com/orbingol/NURBS-Python
          Blender: https://blender.stackexchange.com/questions/7020/create-nurbs-surface-with-python
          Web3D: https://www.web3d.org/x3d/content/examples/Basic/NURBS/
          3DSMax/Maya: https://help.autodesk.com/view/3DSMAX/2016/ENU/?guid=__files_GUID_75CD4DE9_8024_4E25_B147_0A0EC8B10031_htm
          Ayam: http://ayam.sourceforge.net/docsdraft/ayam-6.html
          Expected Outcome
          Implementing the necessary logic for NURBS handling in librt, libbrep, and libged

          Future Possibilities
          Implementing a visual NURBS editor in a BRL-CAD GUI (mged, Archer, Arbalest)

          Project Properties
          Skills
          C/C++
          Difficulty
          medium

          Size
          long (350h)

          Additional Information
          Potential mentor(s): Daniel Rossberg, Sean Morrison
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com


          ~~~~~~~~~~

          New BRL-CAD GUI

          Outline
          Develop further the new GUI for BRL-CAD!

          Details
          BRL-CAD has two main graphical applications called 'mged' and 'archer' which look like they were developed in the 80's and 90's respectively (because they were). We need a modern GUI, ideally using Qt.

          This new GUI will need to leverage our existing libraries in a big way. This includes the C++ coreInterface ( see https://brlcad.org/wiki/Object-oriented_interfaces) or its successor MOOSE (see https://github.com/BRL-CAD/MOOSE) and LIBGED (see src/libged). The latter is basically all commands available to both mged and archer.

          During past GSoCs an amazing start was made with arbalest. Based on this, the development of a GUI called 'qged' (see src/qged) was started, which you should include in your considerations too. This program implements the traditional BRL-CAD workflow under a modern Qt-based user interface.

          You may propose a complete different approach, but we recommend to use arbalest as starting point for your work. Which additions would you like to program in this years GSoC? You can use the results of the former prototype CAD GUI Google Code-in tasks (http://brlcad.org/gci/data/uncategorized/, search for CAD_GUI there) for inspiration.

          Keep your proposal lean and simple. The main emphasis should be on adding features and/or improvements to our next generation GUI.

          Expected Outcome
          An improved BRL-CAD GUI.

          Project Properties
          Skills
          C/C++
          Qt
          Difficulty
          medium

          Size
          This project can be scoped medium (175h) or long (350h), depending on the amount of functionality you want to include.

          Additional Information
          Potential mentor(s):
          Daniel Rossberg
          Himanshu Sekhar Nayak
          Sean Morrison
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com

          ~~~~~~~~~~

          Online Geometry Viewer (OGV)

          Outline
          Write a proposal that leverages rewrite of the existing application in the latest tech stack for frontend and backend.

          Details
          We have been working on OGV for over many years. It started with PHP and then was revamped to meteor.js. We want to focus on the backend of OGV, making sure it works properly, converts the models properly, and basically finish a 1.0 version of OGV so we can launch it for the masses! For that, we are planning to change the legacy backend to be rewritten along with the frontend.

          You can use any tech stack (react, vue) for frontend and node, C/C++ for the backend. We faced some problems like removing certain deprecated dependencies and adding new features with Meteor. We are planning to port the application and add all specified features.

          Possible New Features
          Integrating BRL-CAD GCV(Geometry Conversion Vocabulary) to add support for more file formats like .stl, .obj, and .3dm.
          Automated Conversion for Web Display. Convert uploaded files automatically into polygonal formats for web visualization. Ensure smooth rendering and compatibility with web-based 3D viewers.
          Implementing a Model Repository based project architecture for storing and downloading 3d models.
          Conduct a full STIG compliance audit (Security Technical Implementation Guide), which involves ~200+ security checks.
          Run security scans using OWASP and Dependency-Check, addressing any reported vulnerabilities.
          However, you don't have to limit yourself to those ideas.

          Checklist to write proposal for OGV
          Download and clone OGV from https://github.com/BRL-CAD/OGV-meteor
          Setup and Run OGV on your local machine.
          Fork OGV repo
          Understand the flow of existing application
          Talk to mentors
          Choose list of issues that you would like to solve this summer
          Make a detailed weekly implementation plan
          Share your proposal with your mentors
          Submit it to the GSoC website
          Expected Outcome
          You're expected to propose an outcome useful to end-users. That is a broad range of possibilities that will depend on your interests and experience level. For example, you might propose focusing on the backend conversion to triangles for display (C/C++/Node.js). Or you might propose changing the backend to NURBS surfaces (C/C++) and using verbnurb or three.js (Javascript) to display them instead of triangles. Or you might propose keeping the backend the way it is and focus on front-end robustness (Vue, React), website features, or deployment infrastructure. You hopefully get the idea.

          Project Properties
          Skills
          JavaScript (Vue, React)
          Node.js (required)
          C/C++ (optional)
          Verbnurb (optional)
          Three.js (optional)
          Difficulty
          Hard

          Size
          This project can be scoped medium (175h) or long (350h), depending on the amount of functionality you want to include.

          Additional Information
          Potential mentor(s):
          Amanjot Singh
          Daniel Rossberg
          Divyanshu Garg
          Sean Morrison
          Organization website: https://brlcad.org
          Communication channels: https://brlcad.zulipchat.com

          ~~~~~~~~~~

          Add OpenSCAD support for exporting models in STEP format
          Outline
          The STEP format is widely used in the industry to transfer CAD data between different systems. Currently OpenSCAD does not support STEP import or export. Adding STEP export would open up a number of new usecases or simplify the workflow as no external conversion tools are needed to convert to STEP. This includes the design of 3D models for other CAD tools, e.g. for KiCAD where STEP models are used to render 3D representations of PCBs. Other use cases are for manufacturing where sometimes only STEP files are accepted as input, e.g. for CNC milling services.

          Details
          The main focus of this project is to get the ground work done for exporting more detailed models, as opposed to just exporting the fully rendered single mesh which is the normal case right now.

          Topics that need to be solved

          Research options of usable libraries
          Investigate what type of STEP files are accepted as input by various tools
          Select library and integrate into OpenSCAD
          Implement base functionality to export single meshes
          Add test cases to verify the new export functionality
          Update build system to include the new library into installers
          Prototype how more advanced models can be exported
          Expected Outcome
          OpenSCAD supports exporting single meshes as STEP
          (optional) Understanding/Plan of how to support additional features supported by STEP
          Project Properties
          Skills
          Programming language is C++
          Understand and use APIs from external libraries
          Integrate new libraries into the build system for the 3 supported platforms
          Add test cases with files using the new features to allow regression testing
          Difficulty
          Hard

          Size
          Long (350h)

          Additional Information
          Potential mentor(s): Marius Kintel (IRC: kintel), Torsten Paul (IRC: teepee)
          Organization website: https://www.openscad.org/
          Known libraries:

          StepCode - http://stepcode.org/ (https://github.com/stepcode/stepcode)
          OpenCASCADE - https://www.opencascade.com/


          
    totalCharacters_of_ideas_content_parent: 51942
    totalwords_of_ideas_content_parent: 12320
    totalTokenCount_of_ideas_content_parent: 10905
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/brl-cad/
    idea_list_url: https://github.com/opencax/GSoC/issues?q=is%3Aissue+is%3Aopen+label%3A%22GSoC+2025%22



  - organization_id: 13
    organization_name: BeagleBoard.org
    no_of_ideas: 5
    ideas_content: |
        Deep Learning 
        Medium complexity 175 hours

        A Conversational AI Assistant for BeagleBoard using RAG and Fine-tuning
        BeagleBoard currently lacks an AI-powered assistant to help users troubleshoot errors. This project aims to address that need while also streamlining the onboarding process for new contributors, enabling them to get started more quickly.

        Goal: Develop a domain-specific chatbot for BeagleBoard using a combination of RAG and fine-tuning of an open-source LLM (like Llama 3, Mixtral, or Gemma). This chatbot will assist users with troubleshooting, provide information about BeagleBoard products, and streamline the onboarding process for new contributors.
        Hardware Skills: Ability to test applications on BeagleBone AI-64/BeagleY-AI and optimize for performance using quantization techniques.
        Software Skills: Python, RAG, Scraping techniques, Fine tuning LLMs, Gradio, Hugging Face Inference Endpoints, NLTK/spaCy, Git
        Possible Mentors: Aryan Nanda

        ~~~~~~~~~~



        Linux kernel improvements
         Medium complexity 350 hours

        Update beagle-tester for mainline testing
        Utilize the beagle-tester application and Buildroot along with device-tree and udev symlink concepts within the OpenBeagle continuous integration server context to create a regression test suite for the Linux kernel and device-tree overlays on various Beagle computers.

        Goal: Execution on Beagle test farm with over 30 mikroBUS boards testing all mikroBUS enabled cape interfaces (PWM, ADC, UART, I2C, SPI, GPIO and interrupt) performing weekly mainline Linux regression verification
        Hardware Skills: basic wiring, embedded serial interfaces
        Software Skills: device-tree, Linux, C, OpenBeagle CI, Buildroot
        Possible Mentors: Deepak Khatri, Anuj Deshpande, Dhruva Gole

        ~~~~~~~~~~

        Linux kernel improvements
         Medium complexity 175 hours

        Upstream wpanusb and bcfserial
        These are the drivers that are used to enable Linux to use a BeagleConnect Freedom as a SubGHz IEEE802.15.4 radio (gateway). They need to be part of upstream Linux to simplify on-going support. There are several gaps that are known before they are acceptable upstream.

        Goal: Add functional gaps, submit upstream patches for these drivers and respond to feedback
        Hardware Skills: wireless communications
        Software Skills: C, Linux
        Possible Mentors: Ayush Singh, Jason Kridner

        ~~~~~~~~~~

        Automation and industrial I/O Medium complexity 175 hours

        librobotcontrol support for newer boards
        Preliminary librobotcontrol support for BeagleBone AI, BeagleBone AI-64 and BeagleV-Fire has been drafted, but it needs to be cleaned up. We can also work on support for Raspberry Pi if UCSD releases their Hat for it.

        Goal: Update librobotcontrol for Robotics Cape on BeagleBone AI, BeagleBone AI-64 and BeagleV-Fire
        Hardware Skills: basic wiring, motors
        Software Skills: C, Linux
        Possible Mentors: Deepak Khatri, Jason Kridner

        ~~~~~~~~~~

        RTOS/microkernel imporvements
        Medium complexity 350 hours

        Upstream Zephyr Support on BBAI-64 R5
        Incorporating Zephyr RTOS support onto the Cortex-R5 cores of the TDA4VM SoC along with Linux operation on the A72 core. The objective is to harness the combined capabilities of both systems to support BeagleBone AI-64.

        Goal: submit upstream patches to support BeagleBone AI-64 and respond to feedback
        Hardware Skills: Familiarity with ARM Cortex R5
        Software Skills: C, RTOS
        Possible Mentors: Dhruva Gole, Nishanth Menon
        Upstream Repository: The primary repository for Zephyr Project

          
    totalCharacters_of_ideas_content_parent: 3803
    totalwords_of_ideas_content_parent: 786
    totalTokenCount_of_ideas_content_parent: 816
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/beagleboard.org/
    idea_list_url:  https://gsoc.beagleboard.io/ideas/


  - organization_id: 14
    organization_name: Blender
    no_of_ideas: 15
    ideas_content: |
        Flamenco¶
        Flamenco is Blender's render farm management system. For all the ideas below, a requirement is that you've set up Flamenco for yourself and used it to render things. Of course also some experience with Blender itself is needed.

        Statistics¶
        Description: Design & build a system for Flamenco to collect and display statistics.
        The goal is to show per-job, per-task, and per-worker statistics.
        This should make it possible for users to predict how long a render job will be, as they can look up things like render times of similar render jobs.
        The underlying design should be generic enough to store all kinds of statistics and events, not specific to Blender render times only.
        This project would include the technical design of this feature, the frontend / UI / UX design, and the implementation of both front- and back-end.
        Optional: record more statistics, such as per-frame render time, memory usage, etc.
        Optional: show progress of jobs in the jobs list.
        Expected outcomes: A way for users to get a better understanding of how a new render job will behave, as they can look up information about past & currently running jobs.
        Skills required: Familiarity with Go and unit testing. Familiarity with web languages (HTML/CSS/JavaScript, VueJS).
        Possible mentors: Sybren Stüvel.
        Expected project size: 350 hours
        Difficulty: hard

        ~~~~~~~~~~
        RNA Overrides¶
        Description: Render jobs should be able to specify "RNA overrides" (#101569). In other words, the job definition should be able to include some Python code that sets certain properties in Blender to certain values.
        Design a way to include this in a job definition, and how it affects tasks & commands.
        This could include the ability to add new RNA overrides to existing jobs.
        This should include the ability to update those override values via the web interface.
        Design how such additions / changes affect already-created tasks/commands in the database. Or a way to make this work without changing things in the database?
        This can be used both when a user wants to change something (like re-rendering with increased sample count), or for Flamenco itself to adjust things in the blend file without having to save those values in the blend file itself (#104264)
        Expected outcomes: Give users a simpler way to configure Flamenco for their needs.
        Skills required: Familiarity with Blender (for making the RNA overrides themselves work). Familiarity with Go and unit testing for adjusting Flamenco. Familiarity with web languages (HTML/CSS/JavaScript, VueJS) for the web frontend.
        Possible mentors: Sybren Stüvel.
        Expected project size: 350 hours
        Difficulty: hard

        ~~~~~~~~~~
        Configuration Web Interface¶
        Description: Flamenco's configuration file can be created via its Setup Assistant, but that's only for the initial configuration. For managing more complex things, like the two-way variables for cross-platform support, users still have to manually edit the YAML file. This project is about introducing a configuration editor in the web frontend, and potentially new backend API functions to support that.
        New tab in the frontend for managing the configuration.
        A way to retrieve and visualise the configuration.
        New front-end widgets to represent these, including more complex cases like one-way and two-way variables.
        A way to save the edited configuration.
        Optional: A validator for the configuration options, so that changes can be checked before they take hold.
        Optional: A way for Flamenco Manager to load and apply the configuration without restarting the process.
        Optional: A custom job type for validating configuration paths, so that, for example, a macOS path can be actually checked on a Worker running macOS.
        Expected outcomes: Give users a simpler way to configure Flamenco for their needs.
        Skills required: Familiarity with web languages (HTML/CSS/JavaScript, VueJS, OpenAPI). Potentially also familiarity with Go in case of backend work.
        Possible mentors: Sybren Stüvel.
        Expected project size: 350 hours
        Difficulty: hard

        ~~~~~~~~~~
        Polish & Shine¶
        Description: Fix various issues & implement missing pieces to solve common bumps in the road.
        Reconsider some design aspects of the web frontend, so that it works better on narrower / smaller screens.
        Allow finishing setup assistant without Blender on Manager (#100195).
        Introduce per-Worker logs on the Manager, for introspection and debugging.
        Fix issues with two-way variables (#104336, #104293)
        Add a web interface for the mass deletion of jobs. There is already an API call for this, which deletes all jobs older than a certain timestamp.
        Other issues from the tracker.
        Expected outcomes: Improve the overall experience people have when working with Flamenco.
        Skills required: Familiarity with web languages (HTML/CSS/JavaScript, VueJS) for front-end work. Familiarity with Go and OpenAPI for backend work.
        Possible mentors: Sybren Stüvel.
        Expected project size: 175 hours
        Difficulty: medium

        ~~~~~~~~~~
        Geometry Nodes¶
        Regression Testing¶
        Description: As people build more assets on top of Geometry Nodes, it becomes more and more important to ensure good backwards compatibility. This project focuses on improving our regression tests to cover more issues as early as possible. This involves:
        Adding new tests in our existing test framework.
        Extending the test framework to cover node tools, baking and maybe other areas we still have to find.
        Preparing more complex production files for use in regression tests.
        Expected outcomes: Improved stability of Geometry Nodes.
        Skills required: Good in C/C++ and Python.
        Possible mentors: Jacques Lucke, Hans Goudey
        Expected project size: 90 or 175 hours depending on how many of the mentioned areas are covered
        Difficulty: Easy (using existing framework) and Medium (extending framework)

        ~~~~~~~~~~
        Modeling¶
        Improve Edit-Mesh Mirror¶
        Description: Blender's mesh mirroring in mesh edit-mode works for basic transformations, but does not work for most other operations such as sliding, smoothing, marking seams, etc. In practice, this makes the edit-mode mirror only useful in very specific circumstances and not for general modeling.

        While supporting every operation isn't practical, enabling it for a subset of operators such as those that only adjust existing geometry (rather than adding or removing geometry) would be immediately useful for artists.

        Expected outcomes: Improved edit-mesh mirror support for existing tools.
        Skills required: Proficient in C/C++.
        Possible mentors: Campbell Barton
        Expected project size: 175 or 350 hours
        Difficulty: medium

        ~~~~~~~~~~
        Sculpt & Paint¶
        Mesh Sculpting Performance Improvements¶
        Description: Last year's sculpting rewrite project gave a large improvement in performance, but the team didn't have the time to pursue everything. This task lists possible future improvements. This GSoC project would explore one or more of those ideas with in depth performance testing and experimentation.
        Expected outcomes: More interactive sculping with large meshes
        Skills required: Proficient in C++, familiarity with data-oriented-design.
        Possible mentors: Hans Goudey
        Expected project size: 175 or 350 hours
        Difficulty: medium or hard
        
        ~~~~~~~~~~
        VFX & Video¶
        Hardware accelerated video encoding/decoding¶
        Description: Currently Blender encodes and decodes video though ffmpeg C libraries, on the CPU. ffmpeg also has support for hardware video processing (various kinds depending on platform), this project would enable usage of that.
        Build ffmpeg with hardware video processing support included.
        Note: Blender can't include "non-free" ffmpeg libraries (which means cuda_nvcc, cuda_sdk, libnpp can't be used).
        On Blender's video decoding and encoding side, implement code that would use any relevant ffmpeg C libraries parts for hardware video processing, when supported.
        Decide which additional UI settings need to be exposed to the user, to control hardware video processing.
        Implement code needed to transfer video frames between hardware memory and CPU memory as needed (the rest of VSE processing pipeline is purely on CPU currently).
        Expected outcomes: Video encoding or decoding is more efficient by using dedicated hardware.
        Skills required: Proficient in C/C++, familiarity with ffmpeg.
        Possible mentors: Aras Pranckevicius
        Expected project size: 350 hours
        Difficulty: medium

        ~~~~~~~~~~
        High Dynamic Range (HDR) support for video¶
        Description: This project has several partially dependent parts that are all about HDR support within VSE:
        Make Sequencer preview window be able to display HDR content on a capable display (like 3D viewport or Image window can).
        Make blender movie reading code be able to decode HDR videos into proper scene-linear or sequencer color space as needed. HDR video data might be PQ or HLG encoded, and this might need special decoding into destination color space.
        Make blender movie writing code be able to encode HDR videos. Blender already can encode 10/12 bit videos, but only for regular LDR. Additional PQ or HLG data encoding and necessary video metadata is not currently done.
        Expected outcomes: HDR video handling is improved within Blender.
        Skills required: Proficient in C/C++, familiarity with ffmpeg, knowledge of color spaces and color science.
        Possible mentors: Aras Pranckevicius
        Expected project size: 350 hours
        Difficulty: medium

        ~~~~~~~~~~
        VSE: OpenTimelineIO support¶
        Description: built-in support for OpenTimelineIO import/export within Blender VSE. Blender Studio has experimented with it in 2021, by using and extending a 3rd party addon vse_io. It might be useful to have built-in support for this.
        Expected outcomes: Blender VSE can import and export .otio files.
        Skills required: Proficient in C/C++, familiarity with video editing workflows.
        Possible mentors: Aras Pranckevicius
        Expected project size: 350 hours
        Difficulty: medium

        ~~~~~~~~~~
        VSE: Pitch correction for sound playback¶
        Description: Currently when audio is retimed, the pitch changes, would be nice to have an option to preserve pitch. Different approaches could be researched and implemented (e.g. pitch correction for mostly human speech might be different from pitch correction of music). Might need integration of some 3rd party library if it is suitable for the task, or implementing the correction algorithms manually.
        Expected outcomes: Retimed sound playback has options to preserve original pitch.
        Skills required: Proficient in C/C++, sound processing algorithms.
        Possible mentors: Aras Pranckevicius
        Expected project size: 350 hours
        Difficulty: medium

        ~~~~~~~~~~
        VSE: Animation retiming¶
        Description: Modify animation of strips, when changing their playback speed. Retiming allows changing playback speed of strips, but when strips are animated, the animation keys are fixed in position. These could be moved, such that animation is seemingly mapped to frames of the content.
        Expected outcomes: Animation proportionally is scaled with strip when retiming.
        Skills required: Proficient in C++.
        Possible mentors: Richard Antalik
        Expected project size: 175 hours
        Difficulty: medium

        ~~~~~~~~~~
        VSE: Keyframing in preview¶
        Description: Open workflow quick animation in VSE preview region. In 3D viewport it is possible to transform object and press I key to add key for its position. This also could be done in sequencer preview. This feature should follow same rules and preferences.
        Expected outcomes: Possibility of quick and easy animation in VSE preview
        Skills required: Proficient in C++.
        Possible mentors: Richard Antalik
        Expected project size: 90 hours
        Difficulty: medium

        ~~~~~~~~~~
        Compositor: Implement new nodes¶
        Description: The compositor has been rewritten to be more efficient and future proof. Moving forward, it would be nice to implement new nodes to make the compositor as powerful as it can be. Interested students are encouraged to propose their own ideas. Some example nodes include:
        Define low / high points
        Expected outcomes: Implemented one or more nodes for both CPU and GPU backends.
        Skills required: Good in C/C++, image processing algorithms, familiarity with shaders.
        Possible mentors: Habib Gahbiche / Omar Emara
        Expected project size: 90 or 175 hours depending on the node
        Difficulty: Easy or Medium depending on the node

        ~~~~~~~~~~
        Compositor: UI improvements¶
        Description: The compositor has been rewritten to be more efficient and future proof. It would be nice to improve the UI of some nodes as well as the workflow overall. Interested students are encouraged to suggest ideas. Some examples include:
        Implement 2D gizmos for exisiting nodes.
        Re-design the UI of exisiting nodes
        Expected outcomes: Improved UI within node editors.
        Skills required: Proficient in C/C++, familiarity with design patterns.
        Possible mentors: Habib Gahbiche / Omar Emara
        Expected project size: 90 or 175 hours depending on the scope of the project
        Difficulty: Easy or Medium depending on the scope

          
    totalCharacters_of_ideas_content_parent: 14181
    totalwords_of_ideas_content_parent: 3076
    totalTokenCount_of_ideas_content_parent: 2963
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/blender-foundation/
    idea_list_url: https://developer.blender.org/docs/programs/gsoc/ideas/

  - organization_id: 15
    organization_name: CCExtractor Development
    no_of_ideas: 13
    ideas_content: |
      
        CCExtractor Release 1.00	This is our ambitious project for the summer - work directly with the core team to prepare 1.00 - our first major version bump ever, by getting our PR's from last year vetted, tested and integrated	Some of these: Rust, C, Flutter, Docker, GitHub actions	The rest from the previous list.	Hard	350 hours
        ~~~~~~~~~~
        Ultimate Alarm Clock III	The ultimate alarm clock, with features no other one has. And free!	Flutter	Good application design	Medium	350 hours
        ~~~~~~~~~~
        Beacon Watch Companion	Beacon was started in 2021 and it got a great push also during 2022 and 2024. It aims to ease the group travelling (or hiking). This project is intended to be a companion for the beacon project for smart watches.	Flutter	Scalability	Medium	175 hours
        ~~~~~~~~~~
        Ultimate Alarm Clock Watch Companion	Ultimate Alarm Clock launched in 2023 and gained significant momentum in 2024. It aims to offer unique features that set it apart from other alarm clock apps—all for free!. This project is intended to be a companion for the ultimate alarm clock project for smart watches.	Flutter	Scalability	Medium	175 hours
        ~~~~~~~~~~
        Smart Health Reminder	A fun and interactive health tracking app with smart reminders, challenges, and gamification. Stay healthy effortlessly!	Flutter	Gamification & UX design	Medium	350 hours
        ~~~~~~~~~~
        support more torrent clients	We'd like to add support for other clients to our ruTorrent mobile interface (which of course will get a new name): Flood and Deluge.	Flutter	API, Teamwork	Medium	Discuss
        ~~~~~~~~~~
        URL shortener, with a twist	A URL shortener converts a long URL into a shorter one. There are many use cases. Some times it's just the shortening itself we want, for example to share it on twitter. Other times it's about obfuscation. We want to create our own, but with some unique features.	Any language you want	Internet infrastructure	Medium	175 hours
        ~~~~~~~~~~
        COSMIC Session For Regolith	COSMIC is a wayland based desktop environment written from scratch in rust, with modularity in mind. We're interested in swapping the GNOME components of Regolith DE with COSMIC.	Rust	Wayland, Iced, DBus, etc	Medium	350 hours
        ~~~~~~~~~~
        Add complex layouts to sway	Sway is a drop-in replacement for i3, a popular windows manager for Linux that finally gets rid of the ancient X11 protocol. It's fantastic, but it's still missing support for complex scenarios. We'd like you to work on that support.	C	Sway	Hard	350 hours
        ~~~~~~~~~~
        Expose ectool functionality as a library	ectool is a CLI that lets you interact with an embedded controller for laptops. Expose its functionality as a library so it's possible to use it without spawning the CLI.	C, Python	Interlanguage connectivity	Medium	350 hours
        ~~~~~~~~~~
        CCSync	This project aims to develop a comprehensive platform that can be used sync tasks with taskserver.A hosted solution for syncing your TaskWarrior client.Setting up your own TaskServer takes some effort.And platforms like inthe.am,freecinc have shut down their services.So we want to create a platform similar to inthe.am , freecinc and wingtask.	Any language you want	Internet infrastructure	Medium	175 hours
        ~~~~~~~~~~
        Mouseless for Linux v2 - i3 edition	Mouseless is a nice tool to practice keyboard shortcuts for a few popular apps. Unfortunately it's only available for Mac. Last year we created an open source one that runs on Linux. Using that work or not (this is your choice) we want to create one that helps use i3vm (the fantastic windows manager) using keys only.	Your choice	??	Unknown	175 hours
        ~~~~~~~~~~
        Desktop Actions in Ilia	Desktop Actions defined in .desktop files are used by app launcher to provide access to additional functionalities, typically via context menus. Ilia is an app launcher that currently doesn't support for Desktop Actions due to its keyboard based approach.	Vala, GTK	GTK	Medium	175 hours




          
    totalCharacters_of_ideas_content_parent: 4077
    totalwords_of_ideas_content_parent: 734
    totalTokenCount_of_ideas_content_parent: 964
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/ccextractor-development/
    idea_list_url: https://ccextractor.org/docs/ideas_page_for_summer_of_code_2025/

  - organization_id: 16
    organization_name: CERN-HSF
    no_of_ideas: 37
    ideas_content: |
          Precision Recovery in Lossy-Compressed Floating Point Data for High Energy Physics
          Description
          ATLAS is one of the particle physics experiments at the Large Hadron Collider (LHC) at CERN. With the planned upgrade of the LHC (the so-called High Luminosity phase), allowing for even more detailed exploration of fundamental particles and forces of nature, it is expected that the recorded data rate will be up to ten times greater than today. One of the methods of addressing this storage challenge is data compression. The traditional approach involves lossless compression algorithms such as zstd and zlib. To further reduce storage footprint, methods involving lossy compression are being investigated. One of the solutions in High Energy Physics is the reduction of floating point precision, as stored precision may be higher than detector resolution. However, when reading data back, physicists may be interested in restoring the precision of the floating point numbers. This is obviously impossible in the strict sense, as the process of removing bits is irreversible. Nevertheless, given that the data volume is high, some variables are correlated, and follow specific distributions, one may consider a machine learning approach to recover the lossy-compressed floating-point data.

          Task ideas
          Perform lossy compression of data sample from the ATLAS experiment
          Investigate ML techniques for data recovery, prediction and upscaling
          Integrate the chosen technique into HEP workflow
          Expected results
          Implementation of ML-based procedure to restore precision of lossy-compressed floating-point numbers in ATLAS data
          Evaluation of the method’s performance (decompression accuracy) and its applicability in HEP workflow
          Requirements
          C++, Python, Machine Learning
          Links
          IEEE_754
          Implementation of FloatCompressor in Athena
          Mentors
          Maciej Szymański - ANL
          Peter Van Gemmeren - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: July-September
          Corresponding Project
          ATLAS
          Participating Organizations
          ANL
          CERN

          ~~~~~~~~~~

          The rise of the machine (learning) in data compression for high energy physics and beyond
    

          Short description of the project
          The Large Hadron Collider (LHC) hosts multiple large-scale experiments, LHC experiments such as ATLAS, ALICE, LHCb, and CMS. These together produce roughly 1 Petabyte of data per second, but bandwidth and storage limitations force them to only pick the most interesting data, and discard the rest. The final data stored on disk is roughly 1 Petabyte per day [1]. Despite such steep methods of data reduction, the upgraded High Luminosity LHC in 2029 will produce 10 times more particle collisions. This is a great improvement for the potential to discover new physics, but poses a challenge both for data processing and data storage, as the resources needed in both departments are expected to be 3 and 5 times larger than the projected resources available [2][3].

          Data compression would be the go-to solution to this issue, but general data formats used for big data and the ROOT data format used at the LHC are already highly compressed, meaning that the data does not compress much under normal loss-less compression methods like zip [4]. However, since the observables in these experiments benefit from more events and higher statistics, lossy compression is a good alternative. By using lossy compression some data accuracy is lost, but the compression will allow for the storage of more data which will increase the statistical precision of the final analysis.

          BALER is a compression tool undergoing development at the particle physics division of the University of Manchester. BALER uses autoencoder and other neural networks as a type of lossy machine learning-based compression to compress multi-dimensional data and evaluate the accuracy of the dataset after compression.

          Since data storage is a problem in many fields of science and industry, BALER aims to be an open source tool that can support the compression of data formats from vastly different fields of science. For example, catalog data in astronomy and time series data in computational fluid dynamics.

          This project aims to work on the machine learning models in BALER to optimize performance for LHC data and evaluate its performance in real LHC analyses.

          Task ideas
          This internship can focus on a range of work packages, and the project can be tailored to the intern. Possible projects include:

          New auto-encoder models could be developed, better identifying correlations between data objects in a given particle physics dataset entry (event, typically containing thousands of objects and around 1MB each). New models could also improve performance on live / unseen data. These could include transformer, GNN, probabilistic and other tiypes of networks.
          Existing models could be applied on an FPGA, potentially significantly reducing latency and power consumption, opening the possibility of live compression before transmission of data on a network.
          BALER could also be integrated into standard research data storage formats and programs used by hundreds of thousands of physics researchers (ROOT).
          Finally the compression could be applied to particle physics datasets and the effect on the physics discovery sensitivity of an analysis could be assessed and compared to the possible increased sensitivity from additional data bandwidth.
          Ideas from the intern are also welcomed.

          Expected results
          An improved compression performance with documentation and figures of merit that may include:

          Plots made in matplotlib that demonstrate the performance of the new models compared to the old
          Documentation of the design choices made for the improved models
          Documented evaluation of a physics analysis on data before and after compression
          Requirements
          The candidate should have experience with the python language and a Linux environment, familiarity with AI fundamentals, and familiarity with PyTorch.

          Desirable skills include familiarity with AI fundamentals including transformers and/or graph neural networks, particle physics theory and experiments, PyTorch, FPGA programming and/or simulation.

          Links
          BALER GitHub
          BALER Paper

          Previous work:
          Thesis by Eric Wulff, Lund University
          Thesis by Erik Wallin, Lund University
          GSOC 2020 project: Medium post by Honey Gupta
          GSOC 2021 project: Zenodo entry by George Dialektakis
          ROOT
          Jupyter
          PyTorch
          Mentors
          James Smith - UManchester
          Caterina Doglioni - CERN
          Leonid Didukh
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-August
          Corresponding Project
          baler
          Participating Organizations
          baler
          UManchester
          CERN

          ~~~~~~~~~~

          Probabilistic circuit for lossless HEP data compression
          

          Short description of the project
          Neural data compression is an efficient solution for reducing the cost and computational resources of data storage in many LHC experiments. However, it suffers from the ability to precisely reconstruct compressed data, as most of the neural compression algorithms perform the decompression with the information loosage. On another hand, the lossless neural data compression schemas (VAE, IDF) have a lower compression ratio and are not fast enough for file IO. This project’s task is to overcome the disadvantages of the neural compression algorithm by using the probabilistic circuit for HEP data compression.

          Task ideas
          Implement the probabilistic circuit using the PyTorch
          Train and compress the HEP data (Higgs data, TopQuark Dataset)
          Measure the cost and quantify the optimal compression ratio of the probabilistic circuit
          Perform the benchmark, and compare the results with AE, Transformer
          Expected results
          An improved compression performance with documentation and figures of merit that may include:

          Implemented model of the probabilistic circuit
          Documentation of the benchmark and experiment of compression of the HEP data
          Requirements
          Required: Good knowledge of UNIX, Python, matplotlib, Pytorch, Julia, Pandas, ROOT.

          Links
          Previous work:

          GSOC 2021 project: Zenodo entry by George Dialektakis
          Baler – Machine Learning Based Compression of Scientific Data
          ROOT
          Jupyter
          Lossless compression with probabilistic circuits
          iFlow: Numerically Invertible Flows for Efficient Lossless Compression via a Uniform Coder
          Integer Discrete Flows and Lossless Compression
          Mentors
          Leonid Didukh
          Caterina Doglioni - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October (with 3 weeks mentor vacation where student will work independently with minimal guidance)
          Corresponding Project
          baler
          Participating Organizations
          CERN

          ~~~~~~~~~~
          Agent-Based Simulation of CAR-T Cell Therapy Using BioDynaMo
          Description
          Chimeric Antigen Receptor T-cell (CAR-T) therapy has revolutionized cancer treatment by harnessing the immune system to target and destroy tumor cells. While CAR-T has demonstrated success in blood cancers, its effectiveness in solid tumors remains limited due to challenges such as poor tumor infiltration, immune suppression, and T-cell exhaustion. To improve therapy outcomes, computational modeling is essential for optimizing treatment parameters, predicting failures, and testing novel interventions. However, existing models of CAR-T behavior are often overly simplistic or computationally expensive, making them impractical for large-scale simulations.

          This project aims to develop a scalable agent-based simulation of CAR-T therapy using BioDynaMo, an open-source high-performance biological simulation platform. By modeling T-cell migration, tumor engagement, and microenvironmental factors, we will investigate key treatment variables such as dosage, administration timing, and combination therapies. The simulation will allow researchers to explore how tumor microenvironment suppression (e.g., regulatory T-cells, hypoxia, immunosuppressive cytokines) affects CAR-T efficacy and what strategies such as checkpoint inhibitors or cytokine support can improve outcomes.

          The final deliverable will be a fully documented, reproducible BioDynaMo simulation, along with analysis tools for visualizing treatment dynamics. The model will provide insights into the optimal CAR-T cell dosing, tumor penetration efficiency, and factors influencing therapy resistance. This project will serve as a foundation for in silico testing of immunotherapies, reducing the need for costly and time-consuming laboratory experiments while accelerating the development of more effective cancer treatments.

          Expected plan of work:
          Phase 1: Initial Setup & Simple T-cell Dynamics
          Phase 2: Advanced CAR-T Cell Behavior & Tumor Interaction
          Phase 3: Integration of Immunosuppressive Factors & Data Visualization
          Expected deliverables
          A fully documented BioDynaMo simulation of CAR-T therapy.
          Analysis scripts for visualizing tumor reduction and CAR-T efficacy.
          Performance benchmarks comparing different treatment strategies.
          A research-style report summarizing findings.
          Requirements
          C++ (for BioDynaMo simulations)
          Agent-based modeling (understanding immune dynamics)
          Basic immunology & cancer biology (optional but helpful)
          Data visualization (Python, Matplotlib, Seaborn)
          Links
          Mapping CAR T-Cell Design Space Using Agent-Based Models
          BioDynaMo: A Modular Platform for High-Performance Agent-Based Simulation
          Computational Modeling of Chimeric Antigen Receptor (CAR) T-Cell Therapy of a Binary Model of Antigen Receptors in Breast Cancer
          Investigating Two Modes of Cancer-Associated Antigen Presentation in CAR T-Cell Therapy Using Agent-Based Modeling
          BioDynaMo: Cutting-Edge Software Helps Battle Cancer
          Mentors
          Vassil Vassilev
          Lukas Breitwieser - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          BioDynamo
          Participating Organizations
          CERN
          CompRes

          ~~~~~~~~~~

          Development of an auto-tuning tool for the CLUEstering library
          Description
          CLUE is a fast and fully parallelizable density-based clustering algorithm, optimized for high- occupancy scenarios, where the number of clusters is much larger than the average number of hits in a cluster (Rovere et al. 2020). The algorithm uses a grid spatial index for fast querying of neighbors and its timing scales linearly with the number of points within the range considered. It is currently used in the CMS and CLIC event reconstruction software for clustering calorimetric hits in two dimensions based on their energy. The CLUE algorithm has been generalized to an arbitrary number of dimensions and to a wider range of applications in CLUEstering, a general purpose clustering library, with the backend implemented in C++ and providing a Python interface for easier use. The backend can be executed on multiple backends (serial, TBB, GPUs, ecc) thanks to the Alpaka performance portability library. One feature currently lacking from CLUEstering and that would be extremely useful for every user, is an autotuning of the parameters, that given the expected number of clusters computes the combination of input parameters that results in the best clustering.
          For this task, one of the options to be explored is “The Optimizer”, a Python library developed by the Patatrack group of the CMS experiment which provides a collection of optimization algorithm, in particular MOPSO (Multi-Objective Particle Swarm Optimization).

          Expected results
          Consider the best techniques and tools for the task
          Develop an auto-tuning tool for the parameters of CLUEstering
          Test it on a wide range of commonly used datasets
          Benchmark and profile to identify the bottlenecks of the tool and optimize it
          Evaluation Task
          Interested students please contact simone.balducci@cern.ch

          Technologies
          C++, Python
          Desirable skills
          Experience with development in C++17/20
          Experience with GPU computing
          Experience with machine learning and optimization techniques
          Experience with development of Python libraries
          Links
          CLUE
          CLUEstering
          Alpaka
          Mentors
          Simone Balducci - CERN UNIBO
          Felice Pantaleo - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Patatrack
          Participating Organizations
          CERN


          ~~~~~~~~~~

          Evaluate Distribution of ML model files on CVMFS
          Description
          Particle physicists studying nature at highest energy scales at the Large Hadron Collider rely on simulations and data processing for their experiments. These workloads run on the “computing grid”, a massive globally distributed computing infrastructure. Deploying software efficiently and reliable to this grid is an important and challenging task. CVMFS is an optimised shared file system developed specifically for this purpose: it is implemented as a POSIX read-only file system in user space (a FUSE module). Files and directories are hosted on standard web servers and mounted in the universal namespace /cvmfs. In many cases, it replaces package managers and shared software areas on cluster file systems as means to distribute the software used to process experiment data.

          Task idea
          CVMFS is optimized for the distribution of software (header files, scripts and libraries), taking advantage of the repeated access pattern for its caching, and the possibility to deduplicate files present in several versions. CVMFS is capable to provide a general read-only POSIX file system view on data in external storage. A very common use case is to make conditions databases available to workloads running in distributed computing infrastructure, but various datasets have been published in CVMFS. How efficient CVMFS can be always depends on the details in these use cases - often the benefit for the users is simply in leveraging the existing server and proxy infrastructure.

          In this project proposal, we’d like to evaluate CVMFS as a means to distribute machine learning model files used in inference, for example .onnx files. The main focus will be on creating a test deployment and benchmarking the access, as well as possible coding utilities and scripts to aid in the deployment of models on CVMFS. We’d also like to contrast CVMFS to existing inference servers like KServe, and see if it could integrate as a backend storage.

          Expected results and milestones
          Familiarization with the CVMFS server infrastructure
          Familiarization with the ML model usage at CERN, Survey of different common inference model file formats.
          Test deployment of models relevant to ML4EP
          Benchmark and evaluation of inference using models served from CVMFS
          Addition of the benchmark to the CVMFS continuous benchmarking infrastructure
          Writing a best practices document for the CVMFS documentation
          Requirements
          UNIX/Linux
          Interest in scientific computing devops
          Familiarity with common ML libraries, in particular ONNX
          Links
          CVMFS
          KServe
          Mentors
          Valentin Volkl - CERN
          Lorenzo Moneta - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 175 hours
          Mentor availability: June-October
          Corresponding Project
          CernVM-FS
          Participating Organizations
          CERN

          ~~~~~~~~~~

          Implement and improve an efficient, layered tape with prefetching capabilities
          Description
          In mathematics and computer algebra, automatic differentiation (AD) is a set of techniques to numerically evaluate the derivative of a function specified by a computer program. Automatic differentiation is an alternative technique to Symbolic differentiation and Numerical differentiation (the method of finite differences). Clad is based on Clang which provides the necessary facilities for code transformation. The AD library can differentiate non-trivial functions, to find a partial derivative for trivial cases and has good unit test coverage.

          The most heavily used entity in AD is a stack-like data structure called a tape. For example, the first-in last-out access pattern, which naturally occurs in the storage of intermediate values for reverse mode AD, lends itself towards asynchronous storage. Asynchronous prefetching of values during the reverse pass allows checkpoints deeper in the stack to be stored furthest away in the memory hierarchy. Checkpointing provides a mechanism to parallelize segments of a function that can be executed on independent cores. Inserting checkpoints in these segments using separate tapes enables keeping the memory local and not sharing memory between cores. We will research techniques for local parallelization of the gradient reverse pass, and extend it to achieve better scalability and/or lower constant overheads on CPUs and potentially accelerators. We will evaluate techniques for efficient memory use, such as multi-level checkpointing support. Combining already developed techniques will allow executing gradient segments across different cores or in heterogeneous computing systems. These techniques must be robust and user-friendly, and minimize required application code and build system changes.

          This project aims to improve the efficiency of the clad tape and generalize it into a tool-agnostic facility that could be used outside of clad as well.

          Expected Results
          Optimize the current tape by avoiding re-allocating on resize in favor of using connected slabs of array
          Enhance existing benchmarks demonstrating the efficiency of the new tape
          Add the tape thread safety
          Implement multilayer tape being stored in memory and on disk
          [Stretch goal] Support cpu-gpu transfer of the tape
          [Stretch goal] Add infrastructure to enable checkpointing offload to the new tape
          [Stretch goal] Performance benchmarks
          Requirements
          Automatic differentiation
          C++ programming
          Clang frontend
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes


          ~~~~~~~~~~

          Enhancing LLM Training with Clad for efficient differentiation
          Description
          This project aims to leverage Clad, an automatic differentiation (AD) plugin for Clang, to optimize large language model (LLM) training primarily in C++. Automatic differentiation is a crucial component of deep learning training, enabling efficient computation of gradients for optimization algorithms such as stochastic gradient descent (SGD). While most modern LLM frameworks rely on Python-based ecosystems, their heavy reliance on interpreted code and dynamic computation graphs can introduce performance bottlenecks. By integrating Clad into C++-based deep learning pipelines, we can enable high-performance differentiation at the compiler level, reducing computational overhead and improving memory efficiency. This will allow developers to build more optimized training workflows without sacrificing flexibility or precision.

          Beyond performance improvements, integrating Clad with LLM training in C++ opens new possibilities for deploying AI models in resource-constrained environments, such as embedded systems and HPC clusters, where minimizing memory footprint and maximizing computational efficiency are critical. Additionally, this work will bridge the gap between modern deep learning research and traditional scientific computing by providing a more robust and scalable AD solution for physics-informed machine learning models. By optimizing the differentiation process at the compiler level, this project has the potential to enhance both research and production-level AI applications, aligning with compiler-research.org’s broader goal of advancing computational techniques for scientific discovery.

          Expected Results
          Develop a simplified LLM setup in C++
          Apply Clad to compute gradients for selected layers and loss functions
          Enhance clad to support it if necessary, and prepare performance benchmarks
          Enhance the LLM complexity to cover larger projects such as llama
          Repeat bugfixing and benchmarks
          Develop tests to ensure correctness, numerical stability, and efficiency
          Document the approach, implementation details, and performance gains
          Present progress and findings at relevant meetings and conferences
          Requirements
          Automatic differentiation
          Parallel programming
          Reasonable expertise in C++ programming
          Background in LLM is preferred but not required
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes


          ~~~~~~~~~~

          Enable Clad on ONNX-based models
          Description
          Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++ source code of a mathematical function, it can automatically generate C++ code for computing derivatives of the function. Clad is useful in powering statistical analysis and uncertainty assessment applications. ONNX (Open Neural Network Exchange) provides a standardized format for machine learning models, widely used for interoperability between frameworks like PyTorch and TensorFlow

          This project aims to integrate Clad, an automatic differentiation (AD) plugin for Clang, with ONNX-based machine learning models. Clad can generate derivative computations for C++ functions, making it useful for sensitivity analysis, optimization, and uncertainty quantification. By extending Clad’s capabilities to ONNX models, this project will enable efficient differentiation of neural network operations within an ONNX execution environment.

          Expected Results
          Enumerate ONNX modules with increasing complexity and analyze their differentiation requirements.
          Develop a structured plan for differentiating the identified ONNX operations.
          Implement forward mode differentiation for selected ONNX operations.
          Extend support to reverse mode differentiation for more complex cases.
          Create comprehensive tests to validate correctness and efficiency.
          Write clear documentation to ensure ease of use and future maintenance.
          Present results at relevant meetings and conferences.
          Requirements
          Automatic differentiation
          Parallel programming
          Reasonable expertise in C++ programming
          Basic knowledge of Clang is preferred but not mandatory
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Enable automatic differentiation of OpenMP programs with Clad
          Description
          Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++ source code of a mathematical function, it can automatically generate C++ code for computing derivatives of the function. Clad is useful in powering statistical analysis and uncertainty assessment applications. OpenMP (Open Multi-Processing) is an application programming interface (API) that supports multi-platform shared-memory multiprocessing programming in C, C++, and other computing platforms.

          This project aims to develop infrastructure in Clad to support the differentiation of programs that contain OpenMP primitives.

          Expected Results
          Extend the pragma handling support
          List the most commonly used OpenMP concurrency primitives and prepare a plan for how they should be handled in both forward and reverse accumulation in Clad
          Add support for concurrency primitives in Clad’s forward and reverse mode automatic differentiation.
          Add proper tests and documentation.
          Present the work at the relevant meetings and conferences.
          Requirements
          Automatic differentiation
          C++ programming
          Parallel Programming
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Integrate Clad to PyTorch and compare the gradient execution times
          Description
          PyTorch is a popular machine learning framework that includes its own automatic differentiation engine, while Clad is a Clang plugin for automatic differentiation that performs source-to-source transformation to generate functions capable of computing derivatives at compile time.

          This project aims to integrate Clad-generated functions into PyTorch using its C++ API and expose them to a Python workflow. The goal is to compare the execution times of gradients computed by Clad with those computed by PyTorch’s native autograd system. Special attention will be given to CUDA-enabled gradient computations, as PyTorch also offers GPU acceleration capabilities.

          Expected Results
          Incorporate Clad’s API components (such as clad::array and clad::tape) into PyTorch using its C++ API
          Pass Clad-generated derivative functions to PyTorch and expose them to Python
          Perform benchmarks comparing the execution times and performance of Clad-derived gradients versus PyTorch’s autograd
          Automate the integration process
          Document thoroughly the integration process and the benchmark results and identify potential bottlenecks in Clad’s execution
          Present the work at the relevant meetings and conferences.
          Requirements
          Automatic differentiation
          C++ programming
          Clang frontend
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Enable automatic differentiation of C++ STL concurrency primitives in Clad
          Description
          Clad is an automatic differentiation (AD) clang plugin for C++. Given a C++ source code of a mathematical function, it can automatically generate C++ code for computing derivatives of the function. This project focuses on enabling automatic differentiation of codes that utilise C++ concurrency features such as std::thread, std::mutex, atomic operations and more. This will allow users to fully utilize their CPU resources.

          Expected Results
          Explore C++ concurrency primitives and prepare a report detailing the associated challenges involved and the features that can be feasibly supported within the given timeframe.
          Add concurrency primitives support in Clad’s forward-mode automatic differentiation.
          Add concurrency primitives support in Clad’s reverse-mode automatic differentiation.
          Add proper tests and documentation.
          Present the work at the relevant meetings and conferences.
          An example demonstrating the use of differentiation of codes utilizing parallelization primitives:

          #include <cmath>
          #include <iostream>
          #include <mutex>
          #include <numeric>
          #include <thread>
          #include <vector>
          #include "clad/Differentiator/Differentiator.h"

          using VectorD = std::vector<double>;
          using MatrixD = std::vector<VectorD>;

          std::mutex m;

          VectorD operator*(const VectorD &l, const VectorD &r) {
            VectorD v(l.size());
            for (std::size_t i = 0; i < l.size(); ++i)
              v[i] = l[i] * r[i];
            return v;
          }

          double dot(const VectorD &v1, const VectorD &v2) {
            VectorD v = v1 * v2;
            return std::accumulate(v.begin(), v.end(), 0.0);
          }

          double activation_fn(double z) { return 1 / (1 + std::exp(-z)); }

          double compute_loss(double y, double y_estimate) {
            return -(y * std::log(y_estimate) + (1 - y) * std::log(1 - y_estimate));
          }

          void compute_and_add_loss(VectorD x, double y, const VectorD &weights, double b,
                                    double &loss) {
            double z = dot(x, weights) + b;
            double y_estimate = activation_fn(z);
            std::lock_guard<std::mutex> guard(m);
            loss += compute_loss(y, y_estimate);
          }

          /// Compute total loss associated with a single neural neural-network.
          /// y_estimate = activation_fn(dot(X[i], weights) + b)
          /// Loss of a training data point = - (y_actual * std::log(y_estimate) + (1 - y_actual) * std::log(1 - y_estimate))
          /// total loss: summation of loss for all the data points
          double compute_total_loss(const MatrixD &X, const VectorD &Y,
                                    const VectorD &weights, double b) {
            double loss = 0;
            const std::size_t num_of_threads = std::thread::hardware_concurrency();
            std::vector<std::thread> threads(num_of_threads);
            int thread_id = 0;
            for (std::size_t i = 0; i < X.size(); ++i) {
              if (threads[thread_id].joinable())
                threads[thread_id].join();
              threads[thread_id] =
                  std::thread(compute_and_add_loss, std::cref(X[i]), Y[i],
                              std::cref(weights), b, std::ref(loss));
              thread_id = (thread_id + 1) % num_of_threads;
            }
            for (std::size_t i = 0; i < num_of_threads; ++i) {
              if (threads[i].joinable())
                threads[i].join();
            }

            return loss;
          }

          int main() {
            auto loss_grad = clad::gradient(compute_total_loss);
            // Fill the values as required!
            MatrixD X;
            VectorD Y;
            VectorD weights;
            double b;

            // derivatives
            // Zero the derivative variables and make them of the same dimension as the
            // corresponding primal values.
            MatrixD d_X;
            VectorD d_Y;
            VectorD d_weights;
            double d_b = 0;

            loss_grad.execute(X, Y, weights, b, &d_X, &d_Y, &d_weights, &d_b);

            std::cout << "dLossFn/dW[2]: " << d_weights[2] << "\n"; // Partial derivative of the loss function w.r.t weight[2]
            std::cout << "dLossFn/db: " << d_b << "\n"; // Partial derivative of the loss function w.r.t b
          }
          Requirements
          Automatic differentiation
          Parallel programming
          Reasonable expertise in C++ programming
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Support usage of Thrust API in Clad
          Description
          The rise of ML has shed light into the power of GPUs and researchers are looking for ways to incorporate them in their projects as a lightweight parallelization method. Consequently, General Purpose GPU programming is becoming a very popular way to speed up execution time.

          Clad is a clang plugin for automatic differentiation that performs source-to-source transformation and produces a function capable of computing the derivatives of a given function at compile time. This project aims to enhance Clad by adding support for Thrust, a parallel algorithms library designed for GPUs and other accelerators. By supporting Thrust, Clad will be able to differentiate algorithms that rely on Thrust’s parallel computing primitives, unlocking new possibilities for GPU-based machine learning, scientific computing, and numerical optimization.

          Expected Results
          Research and decide on the most valuable Thrust functions to support in Clad
          Create pushforward and pullback functions for these Thrust functions
          Write tests that cover the additions
          Include demos of using Clad on open source code examples that call Thrust functions
          Write documentation on which Thrust functions are supported in Clad
          Present the work at the relevant meetings and conferences.
          Requirements
          Automatic differentiation
          C++ programming
          Clang frontend
          Links
          Repo
          Mentors
          Vassil Vassilev
          David Lange
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Clad
          Participating Organizations
          CompRes

          ~~~~~~~~~~
          
          Extending the User Interface
          Description
          Constellation is a framework used for lab setups or small-scale experiments in HEP. One of its most important goals is that the framework should be easy to use for both scientists implementing new devices as well as experiment operators.

          Constellation features a Qt-based User Interfaces to control and monitor all devices in the experimental setup. The focus of this GSoC project is to add new user interfaces to Constellation and extend the current ones.

          Project Milestones
          Creating a new GUI to display monitoring data from devices using Qt Charts
          Modularization of UI elements into reusable Qt widgets
          Adding the monitoring widget to the existing GUI for device control
          Requirements
          Modern C++
          Knowledge of Qt is helpful but not required
          Practical experience with Unix and git
          Links
          Repository
          Documentation
          Mentors
          Stephan Lachnit - DESY
          Simon Spannagel - DESY
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-August
          Corresponding Project
          Constellation
          Participating Organizations
          DESY

          ~~~~~~~~~~

          Implement CppInterOp API exposing memory, ownership and thread safety information
          Description
          Incremental compilation pipelines process code chunk-by-chunk by building an ever-growing translation unit. Code is then lowered into the LLVM IR and subsequently run by the LLVM JIT. Such a pipeline allows creation of efficient interpreters. The interpreter enables interactive exploration and makes the C++ language more user friendly. The incremental compilation mode is used by the interactive C++ interpreter, Cling, initially developed to enable interactive high-energy physics analysis in a C++ environment.

          Clang and LLVM provide access to C++ from other programming languages, but currently only exposes the declared public interfaces of such C++ code even when it has parsed implementation details directly. Both the high-level and the low-level program representation has enough information to capture and expose more of such details to improve language interoperability. Examples include details of memory management, ownership transfer, thread safety, externalized side-effects, etc. For example, if memory is allocated and returned, the caller needs to take ownership; if a function is pure, it can be elided; if a call provides access to a data member, it can be reduced to an address lookup. The goal of this project is to develop API for CppInterOp which are capable of extracting and exposing such information AST or from JIT-ed code and use it in cppyy (Python-C++ language bindings) as an exemplar. If time permits, extend the work to persistify this information across translation units and use it on code compiled with Clang.

          Project Milestones
          Collect and categorize possible exposed interop information kinds
          Write one or more facilities to extract necessary implementation details
          Design a language-independent interface to expose this information
          Integrate the work in clang-repl and Cling
          Implement and demonstrate its use in cppyy as an exemplar
          Present the work at the relevant meetings and conferences.
          Requirements
          C++ programming
          Python programming
          Knowledge of Clang and LLVM
          Links
          Repo
          Mentors
          Aaron Jomy - CompRes
          Vassil Vassilev - CompRes
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          CppInterOp
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Incorporate a Large Language Model to assist users
          Description
          The amount of data that is processed by individual scientists has grown hugely in the past decade. It is not unusual for a user to have data processed on tens of thousands of processors with these located at tens of different locations across the globe. The Ganga user interface was created to allow for the management of such large calculations. It helps the user to prepare the calculations, submitting the tasks to a resource broker, keeping track of which parts of the task that has been completed, and putting it all together in the end.

          As a scripting and command line interface, there will naturally be users that have problems with getting the syntax correct. To solve this, they will often spend time searching through mailing lists, FAQs and discussion fora or indeed just wait for another more advanced coder to debug their problem. The idea of this project is to integrate a Large Language Model (LLM) into the command prompt in Ganga. This should allow the user to describe in words what they would like to do and get an example that they can incorporate. It should also intercept exceptions thrown by the Ganga interface, help the user to understand them and propose solutions.

          We have an interface based on ollama that will build a RAG that contains extra information about Ganga that has not been available for the training of the underlying LLM.

          Task ideas
          Integrate the interaction with the LLM and RAG into Ganga.
          Integrate past input and output in the CLI to provide context for the CLI.
          Setup a server such that the LLM can run on a remote server requiring minimal installation by the user.
          Test which samples are most useful for adding to the RAG (mailing list discussions, manuals, instant messages)
          Develop continuous integration tests that ensures that LLM integration will keep working.
          Expected results
          For the scientific users of Ganga, this will speed up their development cycle as they will get a faster response to the usage queries that they have.

          As a student, you will gain experience with the challenges of large scale computing where some tasks of a large processing chain might take several days to process, have intermittent failures and have thousands of task processing in parallel. You will get experience with how LLMs can be integrated directly into projects to assist users in the use of the CLI and in understanding error messages.

          Evaluation Task
          Interested students please contact Ulrik (see contact below) to ask questions and for an evaluation task.

          Requirements
          Python programming (advanced), Linux command line experience (intermediate), use of git for code development and continuous integration testing (intermediate)

          Links
          Ganga
          Mentors
          Alex Richards - Imperial College
          Mark Smith - Imperial College
          Ulrik Egede - Monash University
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: May-November
          Corresponding Project
          Ganga
          Participating Organizations
          ImperialCollege
          MonashUniversity

          ~~~~~~~~~~

          Implement a deprecation system to keep code up to date
          Description
          The amount of data that is processed by individual scientists has grown hugely in the past decade. It is not unusual for a user to have data processed on tens of thousands of processors with these located at tens of different locations across the globe. The Ganga user interface was created to allow for the management of such large calculations. It helps the user to prepare the calculations, submitting the tasks to a resource broker, keeping track of which parts of the task that has been completed, and putting it all together in the end.

          As code that has developed over many years, there are part of the API that has become redundant. This means that for a period of time there will be both the old and now deprecated API as well as the new way of doing things. At the moment Ganga is missing a formal way of deprecating code. This means that warnings about using something deprecated are non-uniform and there is also very old code that has never been cleaned up.

          The idea in this project is to formalise the way that code can be declared deprecated and then use the continuous integration to ensure that the code eventually is deleted.

          Task ideas
          Have a well defined way of marking plugins, functions etc as deprecated with a warning about when they will be removed. Building on top of the python package deprecated might be an idea.
          Run tests in the testing framework that will alert developers to that certain parts of the code can now be removed.
          Apply in the testing framework a similar system that will identify when deprecated python features are used when moving to a new python version.
          Apply the deprecation system to parts of the code that is already deprecated.
          Expected results
          Obtain a cleaner code base where very old and since long deprecated code is no longer present. Provide the end user with consistent warnings about their use of deprecated code as well as when it will be removed.

          As a student, you will gain experience with the challenges of large scale computing where some tasks of a large processing chain might take several days to process, have intermittent failures and have thousands of task processing in parallel. You will get experience with working within a large code base that has gone through many developments.

          Evaluation Task
          Interested students please contact Ulrik (see contact below) to ask questions and for an evaluation task.

          Requirements
          Python programming (advanced), Linux command line experience (intermediate), use of git for code development and continuous integration testing (intermediate)

          Links
          Ganga
          Mentors
          Alex Richards - Imperial College
          Mark Smith - Imperial College
          Ulrik Egede - Monash University
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: May-November
          Corresponding Project
          Ganga
          Participating Organizations
          ImperialCollege
          MonashUniversity

          ~~~~~~~~~~

          Geant4-FastSim - Data Representation Optimisation for Generative Model-based Fast Calorimeter Shower Simulation
          Description
          High energy physics experiments such as those operated at the Large Hadron Collider (LHC) fundamentally rely on detailed and realistic simulations of particle interactions with the detector. The state-of-the-art Geant4 toolkit provides a means of conducting these simulations with Monte Carlo procedures. However, the simulation of particle showers in the calorimeter systems of collider detectors with such tools is a computationally intensive task. For this reason, alternative fast simulation approaches based on generative models have received significant attention, with these models now being deployed in production by current experiments at the LHC. In order to develop the next generation of fast simulation tools, approaches are being explored that would be able to handle larger data dimensionalities stemming from the higher granularity present in future detectors, while also being efficient enough to provide a sizable simulation speed-up for low energy showers.

          A shower representation which has the potential to meet these criteria is a point cloud, which can be constructed from the position, energy and time of hits in the calorimeter. Since Geant4 provides access to the (very numerous) individual physical interactions simulated in the calorimeter, it also provides a means to create a representation independent of the physical readout geometry of the detector. This project will explore different approaches to clustering these individual simulated hits into a point cloud, seeking to minimise the number of points while preserving key calorimetric observables.

          First Steps
          Gain a basic understanding of calorimeter shower simulation (G4FastSim)
          Try simulating some electromagnetic particle showers with the Key4hep framework (see test)
          Propose different approaches to clustering, with justification
          Project Milestones
          Survey different approaches to clustering
          Implement and experiment with the different methods
          Investigate the impact of varying the detector granularity on the performance of separate clustering algorithms
          If time allows, hadronic showers could also be investigated
          Expected Results
          A comparison of different approaches to clustering, with a performance evaluation in terms of the effect on calorimetric observables.
          An evaluation of the impact of varying the granularity of the detector readout on the performance of the clustering algorithm
          Requirements
          C++, Python
          Familiarity with PyTorch could be an advantage
          Evaluation Tasks and Timeline
          Find the test here. Please submit it by 9:00 CET 17th March 2025 along with a short proposal (2 pages max) describing how you would approach the problem. See submission instructions in the test doc. Please don’t forget to start the subject line with “GSoC’25 FastSim”.
          We will make the selections based on the test, short proposal and resume by 17:00 CET 24th March.
          Selected candidates will then write the full proposal and submit it according to the official GSoC timeline.
          Links
          G4FastSim
          CaloChallenge 2022: A Community Challenge for Fast Calorimeter Simulation
          Mentors
          Peter McKeown - CERN
          Piyush Raikwar - CERN
          Anna Zaborowska - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Geant4
          Participating Organizations
          CERN

          ~~~~~~~~~~

          Using ROOT in the field of genome sequencing
          Description
          The ROOT is a framework for data processing, born at CERN, at the heart of the research on high-energy physics. Every day, thousands of physicists use ROOT applications to analyze their data or to perform simulations. The ROOT software framework is foundational for the HEP ecosystem, providing capabilities such as IO, a C++ interpreter, GUI, and math libraries. It uses object-oriented concepts and build-time modules to layer between components. We believe additional layering formalisms will benefit ROOT and its users.

          ROOT has broader scientific uses than the field of high energy physics. Several studies have shown promising applications of the ROOT I/O system in the field of genome sequencing. This project is about extending the developed capability in GeneROOT and understanding better the requirements of the field.

          Expected results
          Reproduce the results based on previous comparisons against ROOT master
          Investigate and compare the latest compression strategies used by Samtools for conversions to BAM, with RAM(ROOT Alignment Maps).
          Explore ROOT’s RNTuple format to efficiently store RAM maps, in place of the previously used TTree.
          Investigate different ROOT file splitting techniques
          Produce a comparison report
          Requirements
          C++ and Python programming
          Familiarity with Git
          Knowledge of ROOT and/or the BAM file formats is a plus.
          Links
          Latest Presentation on GeneROOT
          ROOT
          GeneROOT
          Mentors
          Martin Vasilev - Uni Plovdiv
          Jonas Rembser - CERN
          Fons Rademakers - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-November
          Corresponding Project
          ROOT
          Participating Organizations
          CERN
          CompRes

          ~~~~~~~~~~

          Highly Granular Quantization for CICADA
          Description
          The CICADA (Calorimeter Image Convolutional Anomaly Detection Algorithm) project aims to provide an unbiased detection of new physics signatures in proton-proton collisions at the Large Hadron Collider’s Compact Muon Solenoid experiment (CMS). It detects anomalies in low-level trigger calorimeter information with a convolutional autoencoder, whose behaviour is transferred to a smaller model through knowledge distillation. Careful quantization of the deployed model allows it to meet the requirement of sub-500ns inference times on FPGAs. While CICADA currently employs Quantization Aware Training with different quantization schemes for each layer of the distilled model, a new gradient-based quantization optimization approach published in 2024 offers the possibility of optimizing quantization at the individual weight level. This project would explore implementing this highly granular quantization method to CICADA’s distilled model and evaluating its effects on both model performance and resource consumption on FPGAs. The work would involve implementing the new quantization approach, comparing it with the current implementation, and investigating the impact on both detection performance and hardware resource utilization while maintaining the strict timing requirements.

          Task ideas
          Transition CICADA’s quantization tool from QKeras to HGQ
          Optimize student model’s quantization with higher granularity
          Compare resulting model’s performance with legacy model
          Emulate deployment on FPGA w/ Vivado to evaluate resource consumption
          Expected results
          Extend existing training / quantization scripts to use HGQ in addition to QKeras
          A trained student model with highly granular quantization
          Estimates of that model’s performance and resource consumption on an FPGA
          Requirements
          Python, Tensorflow, Quantization

          Links
          CICADA (homepage)
          CICADA (code)
          HGQ (Paper)
          HGQ (code)
          Mentors
          Lino Gerlach - CERN
          Isobel Ojalvo - Princeton
          Jennifer Ngadiuba - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: Flexible
          Corresponding Project
          CICADA
          Participating Organizations
          princeton

          ~~~~~~~~~~

          Intelligent Log Analysis for the HSF Conditions Database
          Description
          The nopayloaddb project works as an implementation of the Conditions Database reference for the HSF. It provides a RESTful API for managing payloads, global tags, payload types, and associated data.

          Our current system, composed of Nginx, Django, and database (link to helm chart), lacks a centralized logging solution making it difficult to effectively monitor and troubleshoot issues. This task will address this deficiency by implementing a centralized logging system aggregating logs from multiple components, and develop a machine learning model to perform intelligent log analysis. The model will identify unusual log entries indicative of software bugs, database bottlenecks, or other performance issues, allowing us to address problems before they escalate. Additionally, by analyzing system metrics, the model will provide insights for an optimal adjustment of parameters during periods of increased request rates.

          Steps
          Set up a centralized logging system
          Collect and structure logs from Nginx, Django, and the database
          Develop an ML model for log grouping and anomaly detection
          Implement Kubernetes-based database with replication
          Train an ML model to optimize Kubernetes parameters dynamically
          Expected Results
          A centralized logging system for improved monitoring and troubleshooting
          ML-powered anomaly detection
          ML-driven dynamic configuration for optimal performance
          Requirements
          Python and basic understanding of ML frameworks
          Kubernetes, basic understanding, k8s, Helm, Operators, OpenShift
          Django and Nginx, basic understanding of web frameworks and logging
          Database knowledge, PostgreSQL, database replication
          Links
          Django REST API: https://github.com/BNLNPPS/nopayloaddb
          Automized deployment with helm-chart: https://github.com/BNLNPPS/nopayloaddb-charts
          Mentors
          Ruslan Mashinistov - BNL
          John S. De Stefano Jr. - BNL
          Michel Hernandez Villanueva - BNL
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          HSFCondDB
          Participating Organizations
          BNL

          ~~~~~~~~~~

          Interactive Differential Debugging - Intelligent Auto-Stepping and Tab-Completion
          Description
          Differential debugging is a time-consuming task that is not well supported by existing tools. Existing state-of-the-art tools do not consider a baseline(working) version while debugging regressions in complex systems, often leading to manual efforts by developers to achieve an automatable task.

          The differential debugging technique analyzes a regressed system and identifies the cause of unexpected behaviors by comparing it to a previous version of the same system. The idd tool inspects two versions of the executable – a baseline and a regressed version. The interactive debugging session runs both executables side-by-side, allowing the users to inspect and compare various internal states.

          This project aims to implement intelligent stepping (debugging) and tab completions of commands. IDD should be able to execute until a stack frame or variable diverges between the two versions of the system, then drop to the debugger. This may be achieved by introducing new IDD-specific commands. IDD should be able to tab complete the underlying GDB/LLDB commands. The contributor is also expected to set up the necessary CI infrastructure to automate the testing process of IDD.

          Expected Results
          Enable stream capture
          Enable IDD-specific commands to execute until diverging stack or variable value.
          Enable tab completion of commands.
          Set up CI infrastructure to automate testing IDD.
          Present the work at the relevant meetings and conferences.
          Requirements
          Python & C/C++ programming
          Familiarity debugging with GDB/LLDB
          Links
          IDD Repository
          Mentors
          Vipul Cariappa - CompRes
          Martin Vasilev - University of Plovdiv
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          CppInterOp
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Julia Interfaces to HepMC3
          Description
          In high-energy physics experiments at CERN it is necessary to simulate physics events in order to compare predicted observations with those that the LHC experiments actually observe. A key piece of the software chain used to do that is the HepMC3 event record library, which encodes the output from physics event generators in a standard way, so that they can be used by downstream detector simulation and analysis codes.

          There is now increasing interest in using Julia as a language for HEP software, as it combines the ease of programming in interactive languages, e.g., Python, with the speed of compiled language, such as C++. As part of building up the ecosystem of supporting packages for Julia in high-energy physics, developing interfaces to read, manipulated and write HepMC3 event records in Julia is the aim of this project.

          Task ideas
          This project would develop a wrapper library for HepMC3 allowing the HepMC3 data objects and methods, in C++, to be called from Julia.

          It would utilise the general underlying wrapper interfaces in CxxWrap and the automated wrapper code generator WrapIt! to allow for as easy and maintainable an interface as possible.

          A key outcome would be a set of unit tests and examples, based on the HepMC3 ones, demonstrating how to use the library and proving that the code is correct.

          Expected results and milestones
          Reading of HepMC3 event files
          Particularly the ASCII format will be targeted first
          Access to event data structures
          Access to particle properties
          Navigation of the event and the vertices between parent and child particles
          Access to run information
          Update of HepMC3 data structures
          Creation of new HepMC3 events
          Re-serialisation of these events to file
          Initially ASCII
          Documentation and examples on how to use the Julia interfaces
          HepMC3.jl package registered in the Julia general registry
          Extension of serialisation to ROOT format (stretch goal)
          Requirements
          Programming experience in C++
          Prior experience in Julia (very advantageous)
          A background understanding of high-energy physics (advantageous)
          Evaluation Exercise
          TBD

          Links
          Julia Programming Language
          JuliaHEP HSF Group
          HepMC3 Repository
          CxxWrap
          WrapIt!
          Mentors
          Graeme Stewart - CERN
          Mateusz Fila - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 175 hours
          Mentor availability: June-July- August
          Corresponding Project
          JuliaHEP
          Participating Organizations
          CERN


          ~~~~~~~~~~

          MCnet/MCviz - graph and 3D-viewer tools for simulated particle collisions
          Description
          Simulations are key to particle-physics research: many modern theoretical models have such complex consequences that we test theory not by comparing measurements of particle collisions to predicted functional forms, but by generating simulated collision-events from the theory and analyzing them identically to the real ones from the particle collider.

          This means that event generators are incredibly important to particle physics, as the most-used link between experiment and theory, and as a crucial data format for exchange of ideas. They are also an excellent way to introduce new researchers and the public to particle-physics concepts. However, the toolset for MC event manipulation and visualisation is less powerful and coherent than it should be, and this project seeks to improve that situation!

          Task ideas
          This project will pick up old ideas and code for MC-event visualisation – both of the interaction graph that illustrates the internal theory computation, and the external appearance of the resulting collision decay-products – and produce a new set of tools useful both to physicists and for public outreach.

          Expected results and milestones
          Extend the mcgraph tool to be usable with both the HepMC and LHE MC-event formats.
          Refactor mcgraph into a library capable of rendering to a web browser in a server app.
          Interface the Phoenix event-viewer library to display 3D events (with and without a dummy detector model) to a web browsers.
          Display interactive particle information and jet clustering in graph and 3D view interfaces.
          Requirements
          Command-line tools
          Python
          Web technologies
          Gitlab CI
          git
          Links
          Phoenix event view library
          Old MCview web-based MC event viewer
          MC event-graph viewer
          Old MCviz event-graph viewer
          HepMC3 event format
          LHE event format
          Mentors
          Andy Buckley - CERN
          Chris Gutschow - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          MCnet
          Participating Organizations
          UofGlasgow


          ~~~~~~~~~~

          MCnet/OpenData - tools and exercises for open-data exploration with MC simulations
          Description
          CERN’s experiments are committed to publishing their data in a form that is accessible to all, both for research purposes and for education. For example, the ATLAS experiment provides Jupyter notebook exercises based on live-analysing reduced forms of the real collider data.

          But particle-physics researchers also use simulations of data as a crucial tool for testing theories and for understanding the background processes that new physics effects have to be isolated from. For this we use Monte Carlo (MC) event-generator codes, which are statistical implementations of the fundamental physics theory that sample real-looking events from the predicted particle types and kinematics. These are not yet represented in open-data exercises.

          Task ideas
          In this project we will develop new tools and exercises for extending open-data analysis resources to include MC event simulations. It will both reduce the entry barriers to outreach with open data and enable more engaging exercises with hypothetical new-physics models.

          Expected results and milestones
          Develop a library of wrapper functions to make open-data analysis more approachable for non-experts.
          Create functions and datasets for loading and analysing MC event samples through Jupyter.
          Develop a new Jupyter+Binder worksheet for outreach-oriented open-data MC analysis.
          Requirements
          Python
          Jupyter
          Binder
          Gitlab CI
          git
          Links
          ATLAS open data
          Example open-data analysis notebook
          Jupyter
          Binder
          Mentors
          Andy Buckley - CERN
          Chris Gutschow - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 175 hours
          Mentor availability: June-October
          Corresponding Project
          MCnet
          Participating Organizations
          UofGlasgow


          ~~~~~~~~~~

          Integrating Support for Google XLS in HLS4ML
          Description
          Google XLS (Accelerated Hardware Synthesis) is an advanced open-source framework for high-level hardware design, offering flexible and efficient synthesis for FPGA and ASIC applications. By integrating XLS into HLS4ML, a framework for translating machine learning models into FPGA-friendly code, we can leverage XLS’s optimizing compiler and domain-specific language to improve resource efficiency, performance, and portability. This integration will enable seamless generation of highly optimized hardware implementations for ML models while maintaining the ease of use that HLS4ML provides.

          HLS4ML currently supports traditional HLS tools like Vivado HLS and Intel HLS, but adding XLS can bring further benefits such as better compilation times, improved hardware efficiency, and wider vendor compatibility. This project will focus on developing an interface between HLS4ML and XLS, allowing ML models to be translated into XLS IR and synthesized efficiently.

          Task Ideas
          Develop a backend in HLS4ML that translates neural network layers into XLS Intermediate Representation (IR).
          Implement the key ML operations (e.g., matrix multiplications, activations, and pooling) via XLS’s DSLX language and map them to HLS4ML operations.
          Benchmark and compare performance, resource utilization, and synthesis results against existing HLS4ML backends.
          Extend HLS4ML’s configuration options to allow selection of XLS as a backend, ensuring ease of integration.
          Expected Results
          A prototype of a backend in HLS4ML supporting XLS-based synthesis.
          Conversion scripts to map ML operations to XLS IR.
          Performance evaluation of XLS and existing HLS backends.
          Documentation and tutorials for using XLS with HLS4ML.
          Requirements
          Proficiency in Python and C++.
          Knowledge of hardware and compiler design.
          Basic familiarity with neural networks.
          Familiarity with version control systems like Git/GitHub.
          Links
          hls4ml documentation
          hls4ml Repository
          Google XLS documentation
          Google XLS repository
          Mentors
          Vladimir Loncar - CERN
          Dimitrios Danopoulos - CERN
          Additional Information
          Difficulty level (low / medium / high): medium/high
          Duration: 350 hours
          Mentor availability: Flexible
          Corresponding Project
          ML4EP
          Participating Organizations
          CERN


          ~~~~~~~~~~

          Optimizing Model Splitting in hls4ml for Efficient Multi-Graph Inference
          Description
          hls4ml is an open-source tool that enables the deployment of machine learning (ML) models on FPGAs using High-Level Synthesis (HLS). It automatically converts pre-trained models from popular deep learning frameworks (e.g., Keras, PyTorch, and ONNX) into optimized firmware for FPGA-based inference.

          Traditionally, the entire ML model is synthesized as a monolithic graph, which can lead to long synthesis times and complicated debugging, especially for large model topologies. Splitting the model graph at specified layers into independent subgraphs allows for parallel synthesis and step-wise optimization. However, finding the ‘optimal’ splitting points and optimizing FIFO buffers in between the subgraphs remains a challenge, especially when dealing with dynamic streaming architectures.

          This project aims to investigate optimal splitting strategies for complex ML models in hls4ml, focusing on efficient FIFO depth optimization across multi-graph designs. The goal is to develop methodologies that can be integrated into hls4ml to enable automated and optimal graph splitting for improved performance.

          Task ideas
          The contributor will start by familiarizing themselves with hls4ml and building ML models using multi-graph designs. They will implement profiling techniques (e.g., VCD logging) to measure FIFO occupancy and backpressure in order to develop a FIFO optimization strategy for multi-graph designs. They will also investigate multi-objective optimization algorithms to determine optimal splitting points based on subgraph resource usage or dataflow patterns. Finally, they will integrate these methodologies with hls4ml and run benchmarks to validate improvements in latency, resource utilization, etc.

          Expected results and milestones
          Familiarization with hls4ml: Understand the hls4ml workflow, including synthesis, and simulation.
          Research and Evaluation: Explore FIFO profiling and optimization strategies along with algorithms to partition the model graph given specific optimization objectives.
          Validation: Benchmark against monolithic implementations and compare differences in latency and resource utilization.
          Requirements
          Proficiency with computer architecture, FPGA design and simulation tools (e.g., Vivado)
          Experience with Python
          Understanding of ML concepts is beneficial.
          Familiarity with version control systems like Git/GitHub.
          Links
          hls4ml documentation
          hls4ml Repository
          Vivado Design Implementation
          Mentors
          Vladimir Loncar - CERN
          Dimitrios Danopoulos - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: Flexible
          Corresponding Project
          ML4EP
          Participating Organizations
          CERN

          ~~~~~~~~~~

          RNTuple in JSROOT
          Description
          RNTuple is the next-generation data format for high-energy physics (HEP) data collected from the LHC. It is part of ROOT, a cornerstone software package for the storage, visualization and analysis of scientific data, widely used in the scientific community and particularly in HEP. ROOT is a C++ and Python framework, but it recently became available in the browsers as well through a Javascript implementation of some of its parts: JSROOT. Since RNTuple is still in the experimental phase, it currently lacks a JSROOT interface and its contents cannot be visualized in the browser, a common and desirable property of many ROOT objects. The goal of this project is filling this gap by making JSROOT able to read and display data stored inside an RNTuple.

          Task ideas
          In this project, the student will learn the internals of the RNTuple binary format and use this knowledge to implement a Javascript interface to expose RNTuple to JSROOT.

          Expected results and milestones
          Familiarize with the JSROOT framework, understanding how to integrate new components into it;
          read and implement (a subset of) the RNTuple binary format specifications, in Javascript; this will concretely mean implementing the deserialization code from a binary blob to a RNTuple object that may be used by JSROOT;
          enable the visualization of an RNTuple’s fields in the browser, leveraging the existing framework in JSROOT.
          Requirements
          Knowledge of Javascript / ES6
          Basic knowledge of “low-level” programming (primitive types binary layouts, bit-level manipulations, reinterpreting bytes as different types, …)
          Experience with git / github
          (Bonus): familiarity with any binary format
          Links
          ROOT Project homepage
          ROOT Project repository
          JSROOT homepage
          JSROOT repository
          Introduction to RNTuple
          RNTuple architecture overview
          RNTuple Binary Specification
          Mentors
          Serguei Linev - CERN
          Giacomo Parolini - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          ROOT
          Participating Organizations
          CERN

          ~~~~~~~~~~

          Rucio WebUI Revamp
          Description
          Rucio is an open-source software framework that provides functionality to scientific collaborations to organize, manage, monitor, and access their distributed data and dataflows across heterogeneous infrastructures. Originally developed to meet the requirements of the high-energy physics experiment ATLAS, Rucio has been continuously enhanced to support diverse scientific communities. Since 2016, Rucio has orchestrated multiple exabytes of data access and data transfers globally.

          The Rucio WebUI is a Next.js application utilized by various users within collaborating communities to access, monitor, and manage their distributed data. Key features of the Rucio WebUI include:

          SDK for Streaming: Facilitates seamless data streaming from the Rucio server to page components, ensuring a responsive user interface.
          Typed in TypeScript with Generics: Strict typing ensures code integrity and enhances development efficiency.
          Accessibility and Responsiveness: Designed with accessibility and responsiveness in mind, ensuring usability across various devices.
          Testing and Stability: Extensive testing ensures robustness and reliability in all components.
          Feature Toggles: Dynamic feature toggles provide flexibility in enabling or disabling specific functionalities as needed.
          Component Library: Utilizes Storybook and TailwindCSS to enhance development speed and consistency.
          Tasks
          Upgrade to Next.js 15, React 19, TailwindCSS 4.x:
          Migrate the existing codebase to Next.js 15 to leverage the latest features and performance improvements.
          Utilize Server Side Rendering and React Query in Client Side Components to enhance data-fetching capabilities.
          Migrate tailwind.config.js to new CSS based configuration for TailwindCSS 4.x.
          Enhance User Experience for Site Administrators and Operators:
          Currently the WebUI focuses on List/Get views with the exception of allowing users to Create Rules. Add features to Create/Edit resources for site administrators and operational experts.
          Investigate legacy views in the previous Flask application and migrate them to the new WebUI.
          Redesign these views to be more user-friendly, incorporating feedback from site administrators and operators.
          Migrate Authentication to NextAuth (Auth.js):
          Transition existing x509 and user/password authentication mechanisms to NextAuth.
          Ensure compatibility with various authentication flows, including OAuth and OpenID Connect.
          Develop an RBAC system to ensure users have access only to functionalities relevant to their roles, enhancing security and usability.
          Transition to a Monorepo Structure:
          Migrate the Rucio WebUI to a monorepo structure to improve code organization and facilitate the sharing of common components across different projects.
          Requirements
          Mandatory:

          Proficiency in React.js and Next.js
          Experience with TailwindCSS
          Strong knowledge of JavaScript (ECMAScript 6) and TypeScript
          Familiarity with Python 3 and Flask
          Proficiency with Linux, Git, and Docker
          Good to Have:

          Understanding of NX Monorepos
          Experience with AGGrid Data Tables
          Experience with GitHub Actions
          Knowledge of HTTP REST APIs
          Familiarity with OpenID Connect and x509 protocols
          Expected Results
          By the end of GSoC 2025, we expect to have a revamped Rucio WebUI that:

          Is upgraded to Next.js 15 with integrated React Query.
          Utilizes both client and server-side components as per React 19’s stable features.
          Supports TailwindCSS 4.0 for a modern design system.
          Offers enhanced user experiences tailored for site administrators and operators.
          Employs NextAuth for streamlined authentication processes.
          Implements a robust RBAC system.
          Adopts a monorepo structure for improved code organization and component sharing.
          Links
          Rucio GitHub Repository
          Rucio UI Presentation
          Rucio Documentation
          Rucio System Overview Journal Article (Springer)
          Rucio Operational Experience Article (IEEE Computer Society)
          Mentors
          Mayank Sharma - University of Michigan, Ann Arbor
          Martin Barisits - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-November
          Corresponding Project
          Rucio
          Participating Organizations
          CERN

          ~~~~~~~~~~

          Background Enrichment augmented Anomaly Detection (BEAD) for new physics searches at LHC
          

          Short description of the project
          A long-standing mystery of fundamental physics is the existence of dark matter (DM), a type of matter that has little interaction with ordinary matter but is supported by various astrophysical and cosmological observations and is six times more abundant than ordinary matter in the universe. Several Large Hadron Collider (LHC) experiments are conducting searches aimed at detecting dark matter. Unsupervised and semi-supervised learning outlier detection techniques are advantageous to these searches, for casting a wide net on a variety of possibilities for how dark matter manifests, as they impose minimal constraints from specific physics model details, but rather learn to separate characteristics of rare signals starting from the knowledge of the background they’ve been trained on. Developing innovative search techniques for probing dark matter signatures is crucial for broadening the DM search program at the LHC, and BEAD is a Python package that uses deep learning based methods for anomaly detection in HEP data for such new physics searches. BEAD has been designed with modularity in mind, to enable usage of various unsupervised latent variable models for any task.

          BEAD has five main running modes:

          Data handling: Deals with handling file types, conversions between them and pre-processing the data to feed as inputs to the DL models.

          Training: Trains a model to learn implicit representations of the background data that may come from multiple sources(/generators) to get a single, encriched latent representation of it.

          Inference: Using a model trained on an enriched background, the user can feed in samples where to detect anomalies in.

          Plotting: After running Inference, or Training, one can generate plots. These include performance plots as well as different visualizations of the learned data.

          Diagnostics: Enabling this mode allows running profilers that measure a host of metrics connected to the usage of the compute node to help optimization of the code (using CPU-GPU metrics).

          The package is under active development. The student in this project will work on the machine learning models available in BEAD, and implementing new models to perform anomaly detection, initially on simulated data.

          Task ideas
          Possible projects include:

          New auto-encoder models could be developed, better identifying correlations between data objects in a given particle physics dataset entry (containing event level and/or physics object level information). New models could also improve performance on live / unseen data. These could include transformer, GNN, probabilistic and other tiypes of networks.
          Existing models could be tested on different datasets, potentially identifying distinct latent spaces populated by the different LHC physics processes, that can enable improved anomaly detection.
          Ideas from the student working on this project are also welcome.

          Expected results
          An improved performance of selected models, with documentation and figures of merit that may include:

          Plots made in matplotlib that demonstrate the performance of the new models compared to the old
          Documentation of the design choices made for the improved models
          Documented evaluation of a physics analysis on data before and after compression
          Requirements
          Python
          Linux environment
          ML / unsupervised algorithms key concepts
          PyTorch

          Desired skills: transformers and/or graph neural networks, particle physics theory and experiments, particle physics simulations
          Links
          Paper on unsupervised ML algorithms using HEP datasets
          Review of LHC searches using unsupervised learning
          BEAD GitHub repository (WIP)
          ROOT
          Jupyter
          PyTorch
          Mentors
          Pratik Jawahar - CERN
          Sukanya Sinha - CERN
          Caterina Doglioni - Backup Mentor - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-August
          Corresponding Project
          BEAD
          Participating Organizations
          SMARTHEP
          UManchester

          ~~~~~~~~~~

          Estimating the energy cost of ML scientific software
          Description
          At a time where “energy crisis” is something that we hear daily, we can’t help but wonder whether our research software can be made more sustainable, and more efficient as a byproduct. In particular, this question arises for ML scientific software used in high-throughput scientific computing, where large datasets composed of many similar chunks are analysed with similar operations on each chunk of data. Moreover, CPU/GPU-efficient software algorithms are crucial for the real-time data selection (trigger) systems in LHC experiments, as the initial data analysis necessary to select interesting collision events is executed on a computing farm located at CERN that has finite CPU resources.

          The questions we want to start answering in this work are:

          what is the trade off between performance of a ML algorithm and its energetic efficiency?
          can small efficiency improvements in ML algorithms running on Large Hadron Collider data have a sizable energetic impact?
          how do these energy efficiency improvements vary when using different computing architectures (1) and/or job submission systems (2)?
          Task ideas
          The students in this project will use metrics from the Green Software Foundation and from other selected resources to estimate the energy efficiency of machine learning software from LHC experiments (namely, top tagging using ATLAS Open data) and from machine learning algorithms for data compression (there is another GSoC project developing this code, called Baler). This work will build on previous GSoC / Master’s thesis work, and will expand these results for GPU architectures. If time allows, the student will then have the chance to make small changes to the code to make it more efficient, and evaluate possible savings.

          Expected results and milestones
          Understand and summarise the metrics for software energy consumption, focusing on computing resources at CERN;
          Become familiar with running and debugging the selected software frameworks and algorithms;
          Set up tests and visualisation for applying metrics to the selected software
          Run tests and visualise results (preferably using a Jupyter notebook)
          Vary platforms and job submission systems
          Identify possible improvements, apply them, and run tests again
          Requirements
          Python
          git
          Jupyter notebooks
          PyTorch or equivalent ML toolkit
          Desirable: code profiling experience
          Links
          (1) Green Software Foundation course
          (2) Code by the previous GSoC student
          Mentors
          Caterina Doglioni - CERN
          Tobias Fitschen - Backup Mentor - CERN
          James Smith - Backup Mentor - University of Manchester
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October (with 2-3 weeks mentor vacation where student will work independently with minimal guidance)
          Corresponding Project
          SMARTHEP
          Participating Organizations
          UManchester
          CERN

          ~~~~~~~~~~

          Sustainable Quantum Computing algorithms for particle physics reconstruction
          Description
          Reconstructing the trajectories of charged particles as they traverse several detector layers is a key ingredient for event reconstruction at any LHC experiment. The limited bandwidth available, together with the high rate of tracks per second, makes this problem exceptionally challenging from the computational perspective. With this in mind, Quantum Computing is being explored as a new technology for future detectors, where larger datasets will further complicate this task. Furthermore, when choosing such alternative sustainability will play a crucial role and needs to be studied in detail. This project will consist in the implementation of both Quantum and Classical Machine Learning algorithms for track reconstruction, and using open-source, realistic event simulations to benchmark them from both a physics performance and an energy consumption perspective.

          First steps
          Basic understanding of track reconstruction at LHC using ACTS and/or Allen framework.
          Familiarizing her/himself with trackML simulation datasets https://www.kaggle.com/competitions/trackml-particle-identification/data?select=train_sample.zip.
          Learning how to use the quantum simulator for QML algorithms https://pennylane.ai/.
          Milestones
          Choosing a ML algorithm (or part of) in quantum computing and its classical counterpart for track reconstruction.
          Mapping of track reconstruction problem to Ising-like Hamiltonian.
          Prototype implementation of classical and quantum track reconstruction using trackML simulation inputs.
          Expected results
          Benchmarking physics output and energy consumption of the classical and quantum algorithm.
          Requirements
          CUDA, python, C++
          Evaluation Tasks and Timeline
          To be completed
          Corresponding Project
          QuantumForTracking
          Participating Organizations
          CERN

          ~~~~~~~~~~

          TMVA SOFIE - GPU Support for Machine Learning Inference
          Description
          SOFIE (System for Optimized Fast Inference code Emit) is a Machine Learning Inference Engine within TMVA (Toolkit for Multivariate Data Analysis) in ROOT. SOFIE offers a parser capable of converting ML models trained in Keras, PyTorch, or ONNX format into its own Intermediate Representation, and generates C++ functions that can be easily invoked for fast inference of trained neural networks. Using the IR, SOFIE can produce C++ header files that can be seamlessly included and used in a ‘plug-and-go’ style.

          SOFIE currently supports various Machine Learning operators defined by the ONNX standards, as well as a Graph Neural Network (GNN) implementation. It supports the parsing and inference of Graph Neural Networks trained using DeepMind Graph Nets.

          As SOFIE continues to evolve, there’s a need to enable inference on GPUs. This project aims to explore different GPU stacks (such as CUDA, ROCm, ALPAKA) and implement GPU-based inference functionalities in SOFIE. There is already a SYCL implementation for SOFIE, developed in 2023, which can serve as a reference for future development.

          Task ideas
          In this project, the contributor will gain experience with GPU programming and its role in Machine Learning inference. They will start by understanding SOFIE and running inference on CPUs. After researching GPU stacks and methods of their integration with SOFIE, the contributor will implement GPU support for inference, ensuring the code is efficient and well-integrated with GPU technologies.

          Expected results and milestones
          Familiarization with TMVA SOFIE: Understanding the SOFIE architecture, working with its internals, and running inference on CPUs.
          Research and Evaluation: Analyzing various GPU stacks (CUDA, ROCm, ALPAKA, etc.) and determining their alignment with SOFIE.
          Implementation of GPU Inference: Developing functionalities for GPU-based inference in SOFIE.
          [Optional] Benchmarking: Evaluating the performance of the new GPU functionality by benchmarking memory usage, execution time, and comparing results with other frameworks (such as TensorFlow or PyTorch).
          Requirements
          Proficiency in C++ and Python.
          Knowledge of GPU programming (e.g., CUDA).
          Familiarity with version control systems like Git/GitHub.
          Links
          ROOT Project homepage
          ROOT Project repository
          SOFIE Repository
          Implementation of SOFIE-SYCL
          Accelerating Machine Learning Inference on GPUs with SYCL
          Mentors
          Lorenzo Moneta - CERN
          Sanjiban Sengupta - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: Flexible
          Corresponding Project
          ML4EP
          Participating Organizations
          CERN


          ~~~~~~~~~~

          TMVA SOFIE - HLS4ML Integration for Machine Learning Inference
          Description
          SOFIE (System for Optimized Fast Inference code Emit) is a Machine Learning Inference Engine within TMVA (Toolkit for Multivariate Data Analysis) in ROOT. SOFIE offers a parser capable of converting ML models trained in Keras, PyTorch, or ONNX format into its own Intermediate Representation, and generates C++ functions that can be easily invoked for fast inference of trained neural networks. Using the IR, SOFIE can produce C++ header files that can be seamlessly included and used in a ‘plug-and-go’ style.

          Currently, SOFIE supports various machine learning operators defined by ONNX standards, as well as a Graph Neural Network implementation. It supports parsing and inference of Graph Neural Networks trained using DeepMind Graph Nets.

          As SOFIE evolves, there is a growing need for inference capabilities on models trained across a variety of frameworks. This project will focus on integrating hls4ml in SOFIE, thereby enabling generation of C++ inference functions on models parsed by hls4ml.

          Task ideas
          In this project, the contributor will gain experience with C++ and Python programming, hls4ml, and their role in machine learning inference. The contributor will start by familiarizing themselves with SOFIE and running inference on CPUs. After researching the possibilities for integration with hls4ml, they will implement functionalities that ensure efficient inference of ML models parsed by hls4ml, which were previously trained in external frameworks like TensorFlow and PyTorch.

          Expected results and milestones
          Familiarization with TMVA SOFIE: Understanding the SOFIE architecture, working with its internals, and running inference on CPUs.
          Research and Evaluation: Exploring hls4ml, its support for Keras and PyTorch, and possible integration with SOFIE.
          Integration with hls4ml: Developing functionalities for running inference on models parsed by hls4ml.
          Requirements
          Proficiency in C++ and Python.
          Knowledge of hls4ml
          Familiarity with version control systems like Git/GitHub.
          Links
          ROOT Project homepage
          ROOT Project repository
          SOFIE Repository
          hls4ml documentation
          hls4ml Repository
          Mentors
          Lorenzo Moneta - CERN
          Sanjiban Sengupta - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: Flexible
          Corresponding Project
          ML4EP
          Participating Organizations
          CERN

          ~~~~~~~~~~

          TMVA SOFIE - Enhancing Keras Parser and JAX/FLAX Integration
          Description
          SOFIE (System for Optimized Fast Inference code Emit) is a Machine Learning Inference Engine within TMVA (Toolkit for Multivariate Data Analysis) in ROOT. SOFIE offers a parser capable of converting ML models trained in Keras, PyTorch, or ONNX format into its own Intermediate Representation, and generates C++ functions that can be easily invoked for fast inference of trained neural networks. Using the IR, SOFIE can produce C++ header files that can be seamlessly included and used in a ‘plug-and-go’ style.

          SOFIE currently supports various Machine Learning operators defined by the ONNX standards, as well as a Graph Neural Network (GNN) implementation. It supports the parsing and inference of Graph Neural Networks trained using DeepMind Graph Nets.

          As SOFIE continues to evolve, this project aims to:

          Enhance the Keras parser to support models trained in the latest TensorFlow v2.18.0, which introduces NumPy 2.0 compatibility.
          Integrate JAX/FLAX support, enabling SOFIE to generate C++ inference functions for models developed using JAX/FLAX.
          Task ideas
          In this project, the contributor will gain experience with C++ and Python programming, TensorFlow/Keras and its storage formats for trained machine learning models, and JAX/FLAX for accelerated machine learning. They will begin by familiarizing themselves with SOFIE and its Keras parser. After researching the changes required to support the latest TensorFlow version, they will implement functionalities to ensure the successful generation of inference code for the latest Keras models. In the next phase, they will explore the JAX/FLAX library and investigate its potential integration with SOFIE.

          Expected results and milestones
          Familiarization with TMVA SOFIE: Understand the SOFIE architecture, run inference using the existing Keras parser, and analyze the current parser’s capabilities.
          Researching latest TensorFlow/Keras: Investigate the latest TensorFlow/Keras developments and assess their alignment with SOFIE.
          Improving the Keras Parser: Implement parser enhancements to support the latest TensorFlow version and validate inference results.
          JAX/FLAX Integration: Design and develop a parsing mechanism for JAX/FLAX models, ensuring compatibility with SOFIE’s IR and further generation of inference code.
          Requirements
          Proficiency in C++ and Python.
          Knowledge of TensorFlow/Keras and JAX/FLAX.
          Familiarity with version control systems like Git/GitHub.
          Links
          ROOT Project homepage
          ROOT Project repository
          SOFIE Repository
          Keras: The high-level API for TensorFlow
          JAX Documentation
          FLAX Documentation
          Mentors
          Lorenzo Moneta - CERN
          Sanjiban Sengupta - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: Flexible
          Corresponding Project
          ML4EP
          Participating Organizations
          CERN

          ~~~~~~~~~~

          Implementing Debugging Support
          Description
          xeus-cpp is an interactive execution environment for C++ in Jupyter notebooks, built on the Clang-Repl C++ interpreter, provided by CppInterOp. While xeus-cpp enables a seamless workflow for running C++ code interactively, the lack of an integrated debugging experience remains a gap, especially when dealing with code that is dynamically compiled and executed through LLVM’s JIT(Just-In-Time) infrastructure.

          Jupyter’s debugging system follows the Debug Adapter Protocol (DAP), enabling seamless integration of debuggers into interactive kernels. Existing Jupyter kernels, such as the IPython & the xeus-python kernel, have successfully implemented debugging workflows that support breakpoints, variable inspection, and execution control, even in dynamically executed environments. These implementations address challenges such as symbol resolution and source mapping for dynamically generated code, ensuring that debugging within Jupyter remains intuitive and user-friendly.

          However, debugging C++ inside an interactive environment presents unique challenges, particularly due to Clang-Repl’s use of LLVM’s ORC JIT to compile and execute code dynamically. To integrate debugging into xeus-cpp, the project will explore existing solutions for DAP implementations like lldb_dap and debuggers like lldb that can interface with Jupyter while effectively supporting the execution model of Clang-Repl.

          Project Milestones
          Seamless debugging integration, establishing reliable interactions between xeus-cpp, a Debug Adapter Protocol (DAP) implementation, and a debugger.
          Implement a testing framework through xeus-zmq to thoroughly test the debugger. This can be inspired by an existing implementation in xeus-python.
          Present the work at the relevant meetings and conferences.
          Requirements
          C/C++
          Basic understanding of the Debug Adapter Protocol
          Basic understanding of the stack used by xeus-cpp: xeus, cppinterop, clang-repl
          Research on different DAP implementations like lldb_dap and debuggers like lldb/gdb that can be utilized for the project.
          Links
          Repo
          Debug Adaptor Protocol
          Debugging support through Jupyter:
          https://jupyterlab.readthedocs.io/en/stable/user/debugger.html
          https://jupyter-client.readthedocs.io/en/latest/messaging.html#debug-request
          Mentors
          Anutosh Bhat - QuantStack
          Johan Mabille - QuantStack
          Vipul Cariappa - CompRes
          Aaron Jomy - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Xeus-Cpp
          Participating Organizations
          CompRes

          ~~~~~~~~~~

          Enable GPU support and Python Interoperability via a Plugin System
          Description
          Xeus-Cpp integrates Clang-Repl with the xeus protocol via CppInterOp, providing a powerful platform for C++ development within Jupyter Notebooks.

          This project aims to introduce a plugin system for magic commands (cell, line, etc.), enabling a more modular and maintainable approach to extend Xeus-Cpp. Traditionally, magic commands introduce additional code and dependencies directly into the Xeus-Cpp kernel, increasing its complexity and maintenance burden. By offloading this functionality to a dedicated plugin library, we can keep the core kernel minimal while ensuring extensibility. This approach allows new magic commands to be developed, packaged, and deployed independently—eliminating the need to rebuild and release Xeus-Cpp for each new addition. Initial groundwork has already been laid with the Xplugin library, and this project will build upon that foundation. The goal is to clearly define magic command compatibility across different platforms while ensuring seamless integration. A key objective is to reimplement existing features, such as the LLM cell magic and the in-development Python magic, as plugins. This will not only improve modularity within Xeus-Cpp but also enable these features to be used in other Jupyter kernels.

          As an extended goal, we aim to develop a new plugin for GPU execution, leveraging CUDA or OpenMP to support high-performance computing workflows within Jupyter.

          Project Milestones
          Move the currently implemented magics and reframe using xplugin
          Complete the on-going work on the Python interoperability magic
          Implement a test suite for the plugins
          Extended: To be able to execute on GPU using CUDA or OpenMP
          Optional: Extend the magics for the wasm use case (xeus-cpp-lite)
          Present the work at the relevant meetings and conferences
          Requirements
          Python
          C/C++
          GPU programming; CUDA/OpenMP
          Links
          Repo
          Related Issues:
          https://github.com/compiler-research/xeus-cpp/issues/4
          https://github.com/compiler-research/xeus-cpp/issues/140
          Mentors
          Anutosh Bhat - QuantStack
          Johan Mabille - QuantStack
          Vipul Cariappa - CompRes
          Aaron Jomy - CERN
          Additional Information
          Difficulty level (low / medium / high): medium
          Duration: 350 hours
          Mentor availability: June-October
          Corresponding Project
          Xeus-Cpp
          Participating Organizations
          CompRes

          
    totalCharacters_of_ideas_content_parent: 107186
    totalwords_of_ideas_content_parent: 25550
    totalTokenCount_of_ideas_content_parent: 20259
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/cern-hsf/
    idea_list_url: https://hepsoftwarefoundation.org/gsoc/2025/summary.html


  - organization_id: 17
    organization_name: CGAL Project
    no_of_ideas: 11
    ideas_content: |
          Enhancing the 2D Regularized Boolean Operation Demo
          Mentor: Efi Fogel

          Project description: The new demonstration program of the "2D Regularized Boolean Operations" package demonstrates various operations on polygons, such as, union, intersection, and Minkowski sum. It also demonstrates the application of several operations in a pipeline fashion. The demo has not been published yet; it requires a few enhancements, such as the support of Boolean operations on general polygons bounded by non-linear curves.

          Required Skills: Qt6, geometry, code development tools (e.g., git), and C++14 proficiency

          Contact: efifogel@gmail.com

          Duration: 350h

          ~~~~~~~~~~

          Tetrahedral Isotropic Remeshing Parallelization
          Mentor: Jane Tournois

          Project description:

          The goal of this project is to parallelize the code of the Tetrahedral Remeshing algorithm available in CGAL. This multi-material tetrahedral remeshing algorithm [2] is based on local and atomic operations such as edge collapse, edge split and edge flip, that could be performed in parallel to improve the performances of the code. The 3D Triangulations [3] and Tetrahedral Mesh Generation package [4] provide a framework to implement mesh operations concurrently. The same framework will be used to parallelize the remeshing algorithm, with the Intel TBB library [5].

          Resources:

          [1] CGAL Tetrahedral Remeshing package
          [2] The original publication Multi-Material Adaptive Volume Remesher
          [3] CGAL 3D Triangulations
          [4] CGAL Tetrahedral Mesh Generation package
          [5] Intel Threading Building Blocks
          Required Skills: C++17, Mesh Processing, Computational Geometry, Parallelism with TBB

          Contact: jane.tournois@geometryfactory.com

          Duration: 350h

          ~~~~~~~~~~

          New Mesh Subdivision Methods
          Mentor: Mael Rouxel-Labbé

          Project description:

          Subdivision methods are efficient techniques to produce smooth surfaces from polygonal meshes. Within CGAL [1], a handful of classic subdivision techniques already exist (CatmullClark subdivision, Loop subdivision DooSabin subdivision, Sqrt3 subdivision). The goal of this project is two-fold: (a) implement newer subdivision techniques -- such as Interpolatory SQRT(3) Subdivision [2], which builds upon an algorithm that is already found in CGAL -- and compare them to our existing algorithms (b) Investigate the use of these newer techniques as a preprocessing step in some of CGAL's newer remeshing techniques (such as adaptive remeshing).

          Resources:

          [1] CGAL Subdivision package
          [2] Interpolatory SQRT(3) Subdivision
          [3] Gaussian-Product Subdivision Surfaces
          [4] CGAL's upcoming adaptive remeshing algorithms
          Required Skills: C++17, Mesh Processing

          Contact: mael.rouxel.labbe@geometryfactory.com

          Duration: 350h

          ~~~~~~~~~~

          Enhanced Dual Contouring
          Mentor: Mael Rouxel-Labbé, Pierre Alliez

          Project description:

          A previous GSoC launched the process of adding classic contouring methods to CGAL: Marching Cubes and Dual Contouring. This package is about to be finalized and will be integrated soon into CGAL (https://github.com/CGAL/cgal/pull/6849). Many enhancements exist for the Dual Contouring method to improve its robustness: placement of the dual point, improved conditioning of the SVD matrices, or on-the-fly refinement of the underlying grid [1]. Another aspect is speed, as a grid structure is well adapted to GPU computation.

          The project will first focus on manifold contouring methods and robustness in standard C++. If there is time and the candidate has the required skills, we can also explore runtime aspects and the conversion to a GPU implementation. If there is time and the candidate does not have the required skills, we shall explore the implementation of other contouring methods such as Dual Marching Cubes [2].

          Resources:

          [1] Manifold Dual Contouring
          [2] Dual Marching Cubes
          Feature-Sensitive Subdivision and Isosurface Reconstruction
          Required Skills: C++17, Dual Contouring, linear algebra / quadric error metrics, possibly GPU algorithms

          Contact: mael.rouxel.labbe@geometryfactory.com

          Duration: 350h

          ~~~~~~~~~~

          Topological Filtering of Features in Triangle Meshes
          Mentor: Sebastien Loriot

          Project description:

          Remeshing algorithms in CGAL requires the proper extraction of sharp features so that they can be represented in the output mesh (like here for example). Classical method to detect sharp features are based on collecting edges with sharp dihedral surface angles. However, depending on the quality of the input mesh, some noisy edges might be detected, or some edges might be detected. To workaround these issues, it might be interesting to rely on tools from Topological Data Analysis, like for example persistence. Indeed, extra data or missing data are all related to a notion of scale at which the problem is looked at. The goal of this project is to implement such a strategy for provide curated feature edge graph to the meshing algorithm of CGAL. If time allows, extension to detection of significant handles might also be looked at.

          Resources:

          A Practical Solver for Scalar Data Topological Simplification
          To cut or to fill: a global optimization approach to topological simplification
          Topological Simplification of Nested Shapes
          Gudhi library
          Required Skills: C++17, Mesh Processing, Topological Data Analysis

          Contact: sebastien.loriot@geometryfactory.com

          Duration: 350h

          ~~~~~~~~~~

          Improving ARAP in CGAL
          Mentor: Andreas Fabri

          Project description:

          As-Rigid-As-Possible (ARAP) surface modeling is one of the most well known approach for deformation of surfaces. It has been implemented in CGAL, within the Surface Mesh Deformation package (https://doc.cgal.org/latest/Surface_mesh_deformation/index.html#Chapter_SurfaceMeshDeformation). Since the original paper (Sorkine & Alexa, 2007 - As-Rigid-As-Possible Surface Modeling), which is implemented in CGAL, a number of improvements have been proposed. The goal of this project is to investigate these improvements, and enhance the CGAL implementation. Another direction of interest is the extension of the ARAP formulation to the setting of volume deformation of tetrahedral meshes.

          Resources:

          As-Rigid-As-Possible Surface Modeling
          ARAP Revisited Discretizing the Elastic Energy using Intrinsic Voronoi Cells
          Higher Order Continuity for Smooth As-Rigid-As-Possible Shape Modeling
          Required Skills: C++17, linear algebra

          Contact: andreas.fabri@geometryfactory.com

          Duration: 350h

          ~~~~~~~~~~

          Extending 2D Arrangement Drawings
          Mentor: Efi Fogel

          Project description: The "2D Arrangement" package partially supports limited drawing of a 2D arrangements. The goal of this project is extend the capabilities of 2D arrangement drawing. In particular:

          The drawing is limited. An instance of the the Arrangement_2<Traits,Dcel> template can be used to represent 2D arrangements on the plane. The 2D Arrangement package supports ten traits classes that can substitute the Traits parameter. A traits class determines the family of curves that induce the arrangement, e.g., Bezier curves. Currently, arrangement induced by curves of several families cannot be drawn.
          The drawing is inefficient and should be optimized.
          The drawing of arrangements induced by geodesic arcs on the sphere in 3D is deficient. Currently only the curves are drawn (and the faces are not). The Earth demo exhibit some drawing of such arrangements, but it applies a trick that restricts the drawing to faces that do not cross the equator of the sphere. Addressing this item requires knowledge and experience in 3D graphics.
          Required Skills: Qt6 and 3D graphics, geometry, code development tools (e.g., git), and C++17 proficiency

          Contact: efifogel@gmail.com

          Duration: 350h

          ~~~~~~~~~~

          Hexahedral mesh generation
          Mentor: Guillaume Damiand

          Project description:

          The goal of this project is to implement the method of the paper [1] "A template-based approach for parallel hexahedral two-refinement", Steven J. Owen, Ryan M. Shih, Corey D. Ernst; in CGAL. This method allows to generate a locally refined hexahedral mesh, starting from a coarse grid, and using different templates for refinement. It will be implemented using a 3D linear cell complex [2] as underlying data-structure. To implement the different templates, we can use the volumic Query-replace operation [3]. The project was started last year and a preliminary version of the method already exists. The goal of this project is to finish this development, and to propose an integration in CGAL. To do so, the work to do is: (1) finish the sequential version, adding displacement of new vertices in order to obtain smooth meshes; (2) validate results on many different input meshes; (3) write the doc and the examples; (4) finish the parallel version.

          Resources:

          [1] The paper to be implemented: "A template-based approach for parallel hexahedral two-refinement"
          [2] CGAL Linear cell complex package
          [3] Query-replace operations for topologically controlled 3D mesh editing and the Gitlab repository
          Required Skills: C++17, Geometry Processing, Mesh Processing, Computational Geometry

          Contact: guillaume.damiand@cnrs.fr

          Duration: 175h

          ~~~~~~~~~~

          Cut by plane a volumetric mesh
          Mentor: Guillaume Damiand and Sebastien Loriot

          Project description:

          The goal of this project is to implement a method allowing to cut a 3D volumetric mesh (represented by a 3D linear cell complex) by a plane. There are some code available for the two first steps of the method (insert vertices on the cut edges, and insert edges between the new vertices to split faces); it remains the last step which consists in inserting new faces along path of edges. The method must be robust, i.e. deal with any configuration of volumetric mesh. To do so, the work to do is: (1) implement the 3 steps in CGAL; (2) validate results on many different input meshes; (3) write the doc and the examples.

          Required Skills: C++17, Geometry Processing, Mesh Processing, Computational Geometry

          Contact: guillaume.damiand@cnrs.fr sloriot.ml@gmail.com

          Duration: 175h

          ~~~~~~~~~~

          Improvement of Named Parameters
          Mentor: Sebastien Loriot and Laurent Rineau

          Project description:

          The goal of this project is to continue the work started in the pull-request https://github.com/CGAL/cgal/pull/7966. This change proposal implements a mechanism that allows the user to check at compile time that the options passed are used by the function (currently a flow of our mechanism). The proof of concept is there, but now we need to apply it globally in CGAL to all the functions using named parameters. As the function are documented, one way to tackle this project is to write a (python?) script that will collect for all the function the expected named parameters and add the macro calls in the function. There are also other improvements that can be implemented during this project if time allows (automatic extraction of a subset of options, more friendly developer interface, ...)

          Required Skills: C++17, Scritping Language such as Python, with knowledge in parsing

          Contact: sloriot.ml@gmail.com

          Duration: 175h

          ~~~~~~~~~~

          Adding Support for New File Formats for Meshes
          Mentor: Sebastien Loriot and Mael Rouxel-Labbé

          Project description:

          The CGAL library provides several functions to read and write meshes (surface and volume) in the Stream Support package. The list of currently supported file format is available here. The goal of this project is to add support to more file formats. We could for example add support for glTF, gmsh format, 3mf v2, ... The duration of the project will depend on the file format proposed for addition.

          Required Skills: C++17

          Contact: sloriot.ml@gmail.com

          Duration: 90h, 175h, or 350h

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://github.com/CGAL/cgal/wiki/Project-Ideas
    idea_list_url: https://github.com/CGAL/cgal/wiki/Project-Ideas


  - organization_id: 18
    organization_name: CHAOSS
    no_of_ideas: 
    ideas_content: |
      Idea: Enhance Conversational Topic Modelling Capabilities in CHAOSS Software
      Hours: 350

      Micro-tasks and place for questions

      This project will add GenSIM logic, and other capabilities to the Clustering Worker inside of Augur Software, and be extended into a generalized Open Source Software Conversational Topic Modeling Instrument.

      CHOASS/augur has several workers that store machine learning information derived from computational linguistic analysis of data in the message table. The message table includes messages from issue, pull request, pull request review, and email messages. They are related to their origin with bridge tables like pull_request_message_ref. The ML/CL workers are all run against all the messages, regardless of origin.

      Clustering Worker (clusters created and topics modeled)
      message analysis worker (sentiment and novelty analysis)
      discourse analysis worker (speech act classification (question, answer, approval, etc.)
      Clustering Worker Notes:

      Clustering Worker: 2 Models.

      Models:
      Topic modeling, but it needs a better way of estimating number of topics.
      Tables - repo_topic - topic_words
      Computational linguistic clustering
      Tables - repo_cluster_messages
      Key Needs
      Add GenSim algorithms to topic modeling section #1199
      The topics, and associated topic words need to be persisted after each run. At the moment, the topic words get overwritten for each topic modeling run.
      Description/optimization of the parameters used to create the computational linguistic clusters.
      Periodic deletion of models (heuristic: If 3 months pass, OR there’s a 10% increase in the messages, issues, or PRs in a repo, rebuild the models)
      Establish some kind of model archiving with appropriate metadata (lower priority)
      Discourse Analysis Worker Notes:

      discourse_insights table (select max(data_collection_date) for each msg_id)

      sequence is reassembled from the timestamp in the message table (look at msg_timestamp)
      issues_msg_ref, pull_request_message_ref, pull_request_review_msg_ref
      Message Analysis Worker

      message_analysis
      message_analysis_summary
      augur-tech

      The aims of the project are as follows:

      Advance topic modeling of open source software conversations captured in GitHub.
      Integrate this information into clearer, more parsimonious CHAOSS metrics.
      Automate the management machine learning insights, and topic models over time.
      (Stretch Goal) Improve the operation of the overall machine learning insights pipeline in CHAOSS/augur, and generalize these capabilities.
      
      ~~~~~~~~~~
      IDEA: Implement Conversion Rate Metric in CHAOSS Software
      Hours: 350

      Micro-tasks and place for questions

      Conversion Rate
      Question: What are the rates at which new contributors become more sustained contributors?

      Description
      The conversion rate metric is primarily aimed at identifying how new community members become more sustained contributors over time. However, the conversion rate metric can also help understand the changing roles of contributors, how a community is growing or declining, and paths to maintainership within an open source community.

      Objectives (why)
      Observe if new members are becoming more involved with an open source project
      Observe if new members are taking on leadership roles within an open source project
      Observe if outreach efforts are generating new contributors to an open source project
      Observe if outreach efforts are impacting roles of existing community members
      Observe if community conflict results in changing roles within an open source community
      Identify casual, regular, and core contributors
      Implementation
      This project could be implemented using either the CHAOSS/Augur, or CHAOSS/Grimoirelab (including stack components noted in references) technology stacks.

      The aims of the project are as follows:

      Implement the Conversion Rate Metric in CHAOSS Software
      After discussion, consider which CHAOSS Software Stack you wish to work with
      In collaboration with mentors, define the technology framework, and initial path to a "hello world" version of the metric
      Iterative development of the metric
      Assist in the deployment of this metric for a pre-determined collection of repositories in a publicly viewable website linked to the CHAOSS project.
      Advance the work of the chaoss metrics models working group.
      Difficulty: Medium
      Requirements: Knowledge of Python is desired. Some knowledge of Javascript or twitter/bootstrap is also desired. Key requirement is a keenness to dig into this challenge!
      Recommended: Python experience.
      Mentors: Sean Goggins
      Filters (optional)
      Commits
      Issue creation
      Issue comments
      Change request creation
      Change request comments
      Merged change requests
      Code Reviews
      Code Review Comments
      Reactions (emoji)
      Chat platform messages
      Maillist messages
      Meetup attendance
      Visualizations


      Source: https://chaoss.github.io/grimoirelab-sigils/assets/images/screenshots/sigils/overall-community-structure.png



      Source: https://opensource.com/sites/default/files/uploads/2021-09-15-developer-level-02.png

      Tools Providing the Metric
      Augur
      openEuler Infra
      Data Collection Strategies
      The following is an example from the openEuler community:

      A group of people who attended an offline event A held by the community, can be identified as Group A. Demographic information of Group A could be fetched from an on-line survey when people register for the event. To identify the conversation rate of these participants:
      Some people from Group A started watching and forking the repos, indicating they have shown some interest in this community. We marked them as subgroup D0 (Developer Level 0) as a subset of Group A.
      Conversion rate from the total number of people in Group A to the number of people in subgroup D0 is: D0/Group A
      Some people from subgroup D0 make more contributions beyond just watching or forking, including creating issues, making comments on an issue, or performed a code review. We marked them as subgroup D1 (Developer Level 1) as a subset of D0.
      Conversion rate from the total number of people in Subgroup D0 to the number of people in subgroup D1 is: D1/D0.
      Some people from subgroup D1 continue to make more contributions, like code contributions, to the project. This could include creating merge requests and merging new project code. We marked them as subgroup D2 (Developer Level 2) as a subset of D1.
      Conversion rate from the total number of people in subgroup D1 to the number of people in subgroup D2 is: D2/D1.


      Definition:

      Developer Level 0 (D0) example: Contributors who have given the project a star, or are watching or have forked the repository
      Developer Level 1 (D1): Contributors who have created issues, made comments on an issue, or performed a code review
      Developer Level 2 (D2): Contributors who have created a merge request and successfully merged code
      Conversion Rate (Group A -> D0): CR (Group A -> D2) = D0/Group A
      Conversion Rate (D0 -> D1): CR (D0 -> D1) = D1/D0
      Conversion Rate (D1 -> D2): CR (D1 -> D2) = D2/D1
      References
      https://opensource.com/article/21/11/data-open-source-contributors
      https://github.com/chaoss/augur
      https://gitee.com/openeuler/website-v2/blob/master/web-ui/docs/en/blog/zhongjun/2021-09-15-developer-level.md
      https://chaoss.github.io/grimoirelab-sigils/common/onion_analysis/
      https://mikemcquaid.com/2018/08/14/the-open-source-contributor-funnel-why-people-dont-contribute-to-your-open-source-project/
      Contributors
      Sean Goggins
      Andrew Brain
      John McGinness

      ~~~~~~~~~~
      IDEA: Open Source Software Health Metrics Visualization Exploration
      Hours: 350

      Micro-tasks and place for questions

      The CHAOSS Community currently delivers pre-packaged visualizations of open source software health data through Augur APIs (https://github.com/chaoss/augur/blob/main/augur/routes/pull_request_reports.py and https://github.com/chaoss/augur/blob/main/augur/routes/contributor_reports.py), and the https://github.com/chaoss/augur-community-reports repository. This project seeks to expand, refine, and standardize the visualization of different classes of community health metrics data. Specifically, some analyses are temporal, others are anomaly driven, and in some cases contrasts across repositories and communities are required. In each case, the visualization of data is an essential component for metrics, and what we are now referring to as metrics models (https://github.com/chaoss/wg-metrics-models).

      Additional resources include: http://new.augurlabs.io/ && https://github.com/augurlabs/augur_view which demonsrate the updated twitter/bootstrap Augur frontend.

      The aims of the project are as follows:

      Experiment with standard metrics visualizations using direct Augur database connections, or through the Augur API.
      Refine metrics, and metrics model visualizations using Jupyter Notebooks are similar technology.
      Transform visualizations, as they are completed, into Augur API endpoints, following the pull request, and contributor reports examples.
      Difficulty: Medium
      Requirements: Strong interest in data visualization.
      Recommended: Experience with Python is desirable, and experience designing, or developing visualizations is desirable.
      Mentors: Isaac Milarsky, Andrew Brain

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/chaoss/
    idea_list_url: https://github.com/chaoss/augur/blob/main/gsoc-ideas.md


  - organization_id: 19
    organization_name: CNCF
    no_of_ideas: 22
    ideas_content: |
        etcd
        etcd cache
        Description: Develop a generic, high-performance caching library for etcd, inspired by the Kubernetes watch cache, to facilitate building scalable and efficient etcd-based applications.
        Expected Outcome:
        A well-tested and performant library providing core caching primitives similar to Kubernetes' watch cache, significantly reducing etcd load and latency for generic etcd use cases.
        The library will offer feature parity with Kubernetes watch cache, including support for:
        Caching watch events and demultiplexing requests.
        Caching non-consistent list requests using a B-tree structure, updated via watch events.
        Handling requests during cache initialization and re-initialization.
        Custom encoders/decoders for data serialization.
        Custom indexing for optimized lookups.
        Consistent reads.
        Exact stale reads via B-tree snapshots.
        Comprehensive documentation, examples, benchmarks, and metrics to enable easy adoption and monitoring. This includes e2e and robustness tests.
        Recommended Skills: Go, Distributes Systems
        Expected project size: small
        Mentor(s):
        Marek Siarkowicz (@serathius, siarkowicz@google.com) - primary
        Madhav Jivrajani (@MadhavJivrajani, madhav.jiv@gmail.com)
        Upstream Issue (URL): etcd-io/etcd#19371

        ~~~~~~~~~~
        Harbor
        Enhance Harbor Satellite for Artifact Replication from Remote Registry to Edge
        Description: The Harbor Satellite project aims to enable decentralized artifact replication in edge computing environments. This project currently focuses on Use Case #1, where Harbor Satellite will pull images from a central Harbor registry and store them in a local OCI-compliant registry for use by edge devices. The solution is designed for environments with limited or intermittent internet connectivity, ensuring continuous access to required artifacts by local edge devices even when connectivity is unavailable.
        Expected Outcome:
        Enhance Harbor Satellite to enable reliable artifact replication from a central Harbor registry to a local OCI-compliant registry at the edge.
        Implement secure synchronization between central and local registries, especially in air-gapped environments.
        Optimize configuration management for edge container runtimes to pull images from the local registry.
        Provide clear documentation and setup guides for deploying Harbor Satellite in edge environments.
        Recommended Skills: Go, OCI-Registries, Distribution-spec
        Expected project size: medium (~175 hour projects)
        Mentor(s):
        Vadim Bauer (@vad1mo, vb@container-registry.com) - primary
        Orlin Vasilev (@OrlinVasilev, orlin@orlix.org)
        Prasanth Baskar (@bupd, bupdprasanth@gmail.com)
        Upstream Issue (URL): goharbor/harbor#21605

        ~~~~~~~~~~
        Jaeger
        Service performance analysis on top of Elasticsearch / OpenSearch data
        Description: Jaeger is an open-source, distributed tracing platform designed to monitor and troubleshoot transactions in distributed systems. In its basic deployment it allows collecting tracing data, storing it in a database, and querying & analyzing individual traces in the UI. This workflow is great for deep-diving into individual requests, but it does not answer some higher level questions like "which endpoints in my service are the slowest?" To address those questions Jaeger has a special feature called SPM (Service Performance Management), which allows the user to see the trends of services' and endpoints' performance and to drill down into the outliers. However, this feature requires a more complicated deployment where a special real-time processor is running and extracting metrics from the traces and storing those metrics in a Prometheus-compatible remote storage. Some of the storage backends supported by Jaeger, such as Elasticsearch & OpenSearch, can provide the same aggregate answers directly from the trace data, which can significantly simplify the deployment. This project aims to enable this integration.
        Expected Outcome:
        Support SPM functionality directly in Elasticsearch / OpenSearch backends by implementing the metrics query API
        Enhance existing e2e integration tests to continuously test this new capability
        Recommended Skills: Go, basic familiarity with Elasticsearch
        Expected project size: large (~350 hour projects)
        Mentors:
        Yuri Shkuro (@yurishkuro, github@ysh.us) - primary
        Jonah Kowall (@jkowall, jkowall@kowall.net)
        Upstream Issue (URL): jaegertracing/jaeger#6641

        ~~~~~~~~~~
        KCL
        KCL OCI third-party dependency management enhancement
        Description: KCL is an open-source constraint-based record & functional language mainly used in configuration and policy scenarios. KPM is a package management tool for the KCL language that supports the management of KCL packages in the OCI registry and Git Repo. This topic only applies to third-party dependencies from the OCI registry. Use the layering mechanism in OCI to help KPM implement dependency management of KCL third-party dependencies.

        Expected Outcome:

        Refactor the current KPM dependency management module with the OCI's layered mechanism.
        Recommended Skills: Go, OCI

        Expected project size: medium (~175 hour projects)

        Mentor(s):

        Zhe Zong (@zong-zhe, zongzhe1024@163.com)
        Heipa (@He1pa, he1pa404@gmail.com)
        Upstream Issue (URL): kcl-lang/kpm#598

        ~~~~~~~~~~
        Knative Functions
        Dynamic AI Agent Callbacks
        Description: Knative Functions is well-suited for AI agent integration. The serverless nature and isolated runtime environment of Functions make them ideal for creating lightweight, purpose-built services that can be dynamically invoked and even created by agents.
        Expected Outcome: This project would be a combination of research and practicum. First, an analysis of current AI agent interaction patterns, including emergent protocols and available frameworks. Second, the development of a Proof-of-concept integration between Functions and AI agents. This would involve at a minimum invocation, with a stretch goal of implementation and deployment by the agent based on a human prompt.
        Recommended Skills:
        Strong language and communication skills, with the ability to both research deeply and communicate clearly.
        Experience with AI/ML agents and desire to learn about programmatic LLM integrations.
        Familiarity with the Go programming language (ideal) or Python (secondarily), and web services.
        Familiarity with kubernetes, serveless, and microservices a plus.
        Expected project size: Large
        Mentor(s):
        Luke Kingland @lkingland (kingland AT redhat DOT com) - primary
        Aleksander Slominski @aslom (aslomins AT redhat DOT com)
        Upstream Issue (URL): knative/func#2690
        
        ~~~~~~~~~~
        Konveyor
        Extend usage of Konveyor AI to detect and update deprecated Kubernetes API usage in golang applications
        Description: Konveyor is an application modernization platform that helps organizations migrate legacy applications to Kubernetes at scale. As part of this effort, you will contribute to Konveyor AI (Kai), an intelligent code assistant that automates source code updates using data from static code analysis and changelog histories. Your work will focus on applying Generative AI techniques to detect and update deprecated Kubernetes APIs in Golang applications. You’ll build a tool that uses a LLM to generate Konveyor static code analysis rules from published documentation such as the Kubernetes deprecated API guide. Additionally, you’ll create workflows to identify deprecated API usage in legacy applications and automate code suggestions for updates — all powered by Konveyor AI.

        Expected Outcome:

        Develop a prototype tool to convert Kubernetes API deprecation documentation into static code analysis rules.
        Collaborate with the Konveyor AI team to extend support for Golang applications, identify issues, and contribute improvements.
        Demonstrate Konveyor AI’s ability to detect and suggest fixes for deprecated API usage in Golang projects.
        Recommended Skills: Golang, Python, Kubernetes, Generative AI

        Expected project size: # Large (~350 hours)

        Mentor(s):

        John Matthews (@jwmatthews, jwmatthews@gmail.com) - primary
        Savitha Raghunathan (@savitharaghunathan, saveetha13@gmail.com)
        Upstream Issue (URL): konveyor/kai#644

        ~~~~~~~~~~
        KubeArmor
        Improve KubeArmor Observability Spectrum
        Description: KubeArmor is a security enforcement system that provides runtime protection for Kubernetes workloads. To enhance observability, this task involves exposing key Prometheus metrics related to KubeArmor’s policy enforcement. These metrics will provide insights into security policy activity and alerting within a Kubernetes cluster.

        For starters, the following metrics can be started with:

        Number of Policies Applied
        Number of Alerts Triggered
        List of Active Policies
        Policy Status (Active/Inactive)
        Expected Outcome: Prometheus metrics are successfully integrated into KubeArmor, allowing users to monitor policy enforcement and security events effectively. The metrics should be accessible via a Prometheus endpoint and conform to best practices for Prometheus metric exposition.

        Recommended Skills: Go, Prometheus, Kubernetes.

        Expected project size: 175 hrs

        Mentor(s):

        Rishabh Soni (@rootxrishabh, risrock02@gmail.com)
        Prateek Nandle (@Prateeknandle, prateeknandle@gmail.com)
        Barun Acharya (@daemon1024, barun1024@gmail.com)
        Nishant Singh (@tesla59, talktonishantsingh.ns@gmail.com)
        Upstream Issue (URL): kubearmor/KubeArmor#1902

        ~~~~~~~~~~
        KubeBuilder
        Automating Operator Maintenance: Driving Better Results with Less Overhead
        Description:
        Code-generation tools like Kubebuilder and Operator-SDK have transformed cloud-native application development by providing scalable, community-driven frameworks. These tools simplify complexity, accelerate results, and enable developers to create tailored solutions while avoiding common pitfalls, laying a strong foundation for innovation.
        However, as these tools evolve with ecosystem changes and new features, projects risk becoming outdated. Manual updates are time-consuming, error-prone, and make it challenging to maintain security, adopt advancements, and stay aligned with modern standards.
        This project introduces an automated solution for Kubebuilder, with potential applications for similar tools or those built on its foundation. By streamlining maintenance, projects remain aligned with modern standards, improve security, and adopt the latest advancements. It fosters growth and innovation across the ecosystem, letting developers focus on what matters most: building great solutions.
        Note that the initial idea is to solve this with 3-way Git merges. However, users will face conflicts, and in the first phase, we want to study whether AI could help resolve these conflicts in a future phase to achieve this goal.

        Expected Outcome

        Conduct research on 3-Way Merge & Advanced Merge Options in Git.
        Conduct research on how AI could help resolve conflicts. If open-source solutions are available and align with the proposal, include them for consideration in a second phase.
        Develop a Proof of Concept (POC) implementing a GitHub Action that automatically creates a Pull Request (PR) in a mock repository, demonstrating the feasibility of the proposed solution.
        Successfully complete the proposal for PEP.
        Introduce a new Kubebuilder Plugin that scaffolds the GitHub Action based on the POC. This plugin will be released as an alpha feature, allowing users to opt-in for automated updates. The initial solution does not need to have AI, but AI integration could be a future enhancement if feasible.
        Recommended Skills

        Golang
        GitHub Actions
        Software Automation
        CI/CD
        Git
        IA
        Expected project size: Large (~350 hour projects)

        Mentor(s)

        Camila Macedo (@camilamacedo86, camilamacedo86@gmail.com) - Primary
        Varsha Prasad (@varshaprasad96, varshaprasad1507@gmail.com)
        TianYi(Tony) (@Kavinjsir)
        Upstream Issue: WIP - Proposal: Automating Operator Maintenance: Driving Better Results with Less Overhead
        ~~~~~~~~~~
        KubeStellar
        AI/ML Model Monitoring and Drift Detection in Disconnected Clusters using KubeStellar
        Description: AI/ML models deployed in disconnected environments, such as edge clusters and air-gapped systems, often suffer from model drift—a degradation in model performance due to changes in input data distributions. Without continuous monitoring, models may become inaccurate, leading to unreliable predictions.

        This project aims to integrate model monitoring and drift detection into KubeStellar, enabling Kubernetes-based AI workloads to detect data drift locally and sync monitoring metrics when connectivity is restored. The solution will use lightweight monitoring agents deployed alongside ML models to track data distribution changes and alert mechanisms to trigger model retraining when necessary.

        The system will also include policies for efficient metric storage and synchronization between disconnected and central clusters while minimizing bandwidth usage.

        Expected Outcome:

        A KubeStellar-compatible AI/ML monitoring component that tracks model drift in disconnected clusters.
        Efficient local storage and synchronization of monitoring metrics when connectivity is restored.
        Policies for adaptive model retraining triggers based on drift detection signals.
        Integration with existing ML tools (e.g., Prometheus, TensorFlow Extended, OpenTelemetry).
        Open-source documentation and example workflows demonstrating how KubeStellar manages AI model monitoring across disconnected clusters.
        Recommended Skills:

        Kubernetes and container orchestration
        AI/ML model deployment & monitoring
        Python, Go (for Kubernetes integrations)
        Experience with logging/monitoring tools (Prometheus, OpenTelemetry)
        Familiarity with KubeStellar (preferred but not required)
        Expected Project Size: Large (~350 hours) This project requires implementing multiple components: local monitoring, drift detection, synchronization, and integration with KubeStellar. It also involves research into efficient data synchronization strategies for low-bandwidth environments.

        Mentor(s):

        Andy Anderson (@clubanderson, andy@clubanderson.com) - Primary Mentor
        [Second Mentor's Name] (@second-mentor-github, second-mentor-email)
        Upstream Issue (URL): kubestellar/kubestellar#2791

        ~~~~~~~~~~

        Kubewarden
        Allow policies to be written using JavaScript
        Description: Kubewarden is a Policy Engine powered by WebAssembly policies that enforces security and compliance in Kubernetes clusters. Its policies can be written in CEL, Rego (OPA & Gatekeeper flavours), Rust, Go, YAML, and others.

        Kubewarden does not have a JavaScript SDK yet. Recent work done inside of the Bytecode Alliance made possible to compile Javascript code into WebAssembly . This means It's now possible to create such a SDK. This task consists on writing a JavaScript SDK that provides an idiomatic way to write Kubewarden policies.

        Expected Outcome: A new JavaScript SDK is created. The SDK API is documented, and the policy tutorial as well.

        Recommended Skills: JavaScript, Kubernetes.

        Expected project size: Large

        Mentor(s):

        Victor Cuadrado (@viccuad, vcuadradojuan@suse.com) - primary
        Flavio Castelli (@flavio, fcastelli@suse.com)
        José Guilherme Vanz (@jvanz, jguilhermevanz@suse.com)
        Fabrizio Sestito (@fabriziosestito, fabrizio.sestito@suse.com)
        Upstream Issue (URL): kubewarden/community#37

        ~~~~~~~~~~

        Elevate our .NET SDK into a first class citizen
        Description: Kubewarden is a Policy Engine powered by WebAssembly policies that enforces security and compliance in Kubernetes clusters. Its policies can be written in CEL, Rego (OPA & Gatekeeper flavours), Rust, Go, YAML, and others.

        Kubewarden has a .NET SDK that allows policy authors to write policies in C#. Starting with .NET 8, a big chunk of the work from https://github.com/dotnet/dotnet-wasi-sdk made its way upstream. This means it's a good time to revisit Kubewarden's .NET SDK for policies. This task consists on bringing our .NET SDK up to standard with the rest of our SDKs such as the Go or Rust ones.

        Expected Outcome: Our .NET SDK has been ported to .NET 9, and supports the same capabilities as our other SDKs. The SDK API is documented, and the policy tutorial as well.

        Recommended Skills: C#, .NET, Kubernetes.

        Expected project size: medium

        Mentor(s):

        Victor Cuadrado (@viccuad, vcuadradojuan@suse.com) - primary
        Flavio Castelli (@flavio, fcastelli@suse.com)
        José Guilherme Vanz (@jvanz, jguilhermevanz@suse.com)
        Fabrizio Sestito (@fabriziosestito, fabrizio.sestito@suse.com)
        Upstream Issue (URL): kubewarden/policy-sdk-dotnet#47

        ~~~~~~~~~~
        Lima
        VM plugin subsystem
        Description: Lima (https://lima-vm.io) is a project that provides Linux virtual machines with a focus on running containers. Lima supports several VM backends via built-in drivers: qemu, vz (Apple Virtualization.framework), and wsl2 (see lima/pkg/driverutil/instance.go). The idea for GSoC is to make a plugin subsystem that decouples the built-in VM drivers into separate binaries that communicate with the main Lima binary via some RPC (probably gRPC). This idea will improve the maintainability of the code base, and also help supporting additional VM backends (e.g., vfkit and cloud-based drivers).
        Expected Outcome:
        Design the plugin subsystem and its RPC (probably gRPC)
        Migrate the existing built-in VM drivers to the new plugin subsystem
        Implement additional VM plugins if the time allows
        Recommended Skills: Go, gRPC, QEMU, macOS
        Expected project size: medium (~175 hour projects)
        Mentor(s):
        Akihiro Suda (@AkihiroSuda, suda.kyoto@gmail.com) - primary
        Anders Björklund (@afbjorklund, anders.f.bjorklund@gmail.com)
        Upstream Issue (URL): lima-vm/lima#2007
        
        ~~~~~~~~~~
        LitmusChaos
        Terraform Support for LitmusChaos
        Description: LitmusChaos is an open-source Chaos Engineering platform that helps teams uncover weaknesses and potential outages in their applications by running controlled chaos experiments. However, before injecting chaos, several prerequisite steps must be completed, including user and project creation, connecting target infrastructure, and setting up experiments. To streamline this process, developers and SREs often seek automation, especially when integrating chaos testing into CI/CD pipelines. This Google Summer of Code (GSoC) project proposes developing a Terraform provider for LitmusChaos, enabling users to automate these essential setup steps and seamlessly manage chaos experiments through Terraform.

        Expected Outcome:

        LitmusChaos will have a terraform provider supporting user, project, infrastructure, and experiment resource operations along with proper documentation and usage scripts.
        A stretch goal for the mentee would be to become an official maintainer of the Litmus Terraform provider project.
        Recommended Skills: Golang, Terraform

        Expected project size: large (~175 hour projects)

        Mentor(s):

        Saranya Jena (@Saranya-jena, saranya.jena@harness.io)
        Sarthak Jain (@SarthakJain26, sarthak.jain@harness.io)
        Upstream Issue (URL): litmuschaos/litmus#5042

        ~~~~~~~~~~
        Meshery
        Multi-player Collaboration: Resilient Websockets and GraphQL Subscriptions
        Description: Meshery's current implementation of websockets and GraphQL subscriptions is in need of refactoring for increased reliability and resiliency. This client and server-side refactoring includes use of webworkers and separation of concerns for the client-side, and the use of a message broker for the server-side. The project has implications on Meshery's implementation of multi-player collaboration functionality.

        Expected Outcome: Resilient websockets and GraphQL subscriptions for Meshery, enabling multi-player collaboration functionality.

        Recommended Skills: Golang, Kubernetes, Azure, well-written and well-spoken English

        Expected project size: large (~175 hour project)

        Mentor(s):

        Lee Calcote (@leecalcote, leecalcote@gmail.com)
        Aabid Sofi (@aabidsofi19, mailtoaabid01@gmail.com)
        Upstream Issue: meshery/meshery#13554

        ~~~~~~~~~~

        Support for Azure in Meshery
        Description: Enhance Meshery's existing orchestration capabilities to include support for Azure. The Azure Service OperatorAzure Service Operator (ASO) provides a wide variety of Azure Resources via Kubernetes custom resources. as first-class Meshery Models. This involves enabling Meshery to manage and orchestrate Azure services and their resources, similar to how it handles other Kubernetes resources. The project will also include generating support for Azure services and their resources in Meshery's Model generator.

        Expected Outcome: Meshery will be able to orchestrate and manage all Azure services supported by ASO. This includes the ability to discover, configure, deploy, and operate the lifecycle of Azure services through Meshery. The Meshery Model generator will be updated to automatically generate models for Azure services, simplifying their integration and management within Meshery. This will be an officially supported feature of Meshery.

        Recommended Skills: Golang, Kubernetes, Azure, well-written and well-spoken English

        Expected project size: large (~175 hour project)

        Mentor(s):

        Lee Calcote (@leecalcote, leecalcote@gmail.com)
        Mia Grenell (@miacycle, mia.grenell2337@gmail.com)
        Upstream Issue: meshery/meshery#11244

        ~~~~~~~~~~

        Distributed client-side inference (policy evaluation) with WebAssembly (WASM) and OPA in Meshery
        Description: Meshery's highly dynamic infrastructure configuration capabilities require real-time evaluation of complex policies. Policies of various types and with a high number of parameters need to be evaluted client-side. With policies expressed in Rego, the goal of this project is to incorporate use of the https://github.com/open-policy-agent/golang-opa-wasm project into Meshery UI, so that a powerful, real-time user experience is possible.

        Expected Outcome: The goal of this project is to enhance Meshery's infrastructure configuration capabilities by incorporating real-time policy evaluation using the golang-opa-wasm project. This project will integrate the capabilities of golang-opa-wasm into the Meshery UI, enabling users to experience the existing, powerful, server-side policy evaluation client-side.

        Recommended Skills: WebAssembly, Golang, Open Policy Agent, well-written and well-spoken English

        Expected project size: large (~175 hour project)

        Mentor(s): Lee Calcote (@leecalcote, leecalcote@gmail.com), James Horton (@hortison, james.horton2337@gmail.com)

        Upstream Issue: meshery/meshery#13555

        ~~~~~~~~~~
        Open Cluster Management
        Privacy-preserving and efficient AI model training across multi-cluster
        Description: Open Cluster Management (OCM) streamlines multi-cluster workload management through APIs that align with SIG-Multicluster standards. Beyond traditional workload orchestration, OCM enables scalable AI training and inference across distributed environments.

        As machine learning (ML) expands across clusters, data privacy becomes a critical concern. ML models rely on vast datasets, making it essential to safeguard sensitive information across clusters without compromising model performance.

        This project integrates Federated Learning (FL) into OCM, enabling privacy-preserving, collaborative model training without transferring raw data between clusters. Instead, training occurs locally where the data resides, ensuring compliance, enhancing efficiency, and reducing bandwidth and storage costs.

        By leveraging OCM's Placement, ManifestWork, and other APIs. we standardize FL workflows and seamlessly integrate frameworks like Flower and OpenFL through a unified interface. This approach harnesses OCM's capabilities to deliver scalable, cost-efficient, and privacy-preserving AI solutions in multi-cluster environments.

        Expected Outcome:

        Comprehensive Documentation:
        Define the scenarios addressed by the prototype, highlighting its purpose and value.
        Provide an intuitive and architectural comparison between Federated Learning (FL) and OCM, mapping FL terminology to OCM APIs to showcase OCM’s native support for FL.
        Illustrate the complete Federated Learning workflow within Open Cluster Management.
        Extended Prototype (or CRD) Support:
        Enable model aggregation persistence in AWS S3 (currently supports only native PVC).
        Extend compatibility to support additional Federated Learning frameworks like OpenFL (currently supports Flower). This requires understanding how OpenFL works, containerizing it, and integrating it into the prototype.
        Recommended Skills: Golang, Kubernetes, Federated Learning, Open Cluster Management, Scheduling

        Expected project size: medium (~175 hour projects)

        Mentor(s):

        Meng Yan (@yanmxa, myan@redhat.com) - primary
        Qing Hao (@haoqing0110, qhao@redhat.com)
        Upstream Issue (URL): open-cluster-management-io/ocm#825

        ~~~~~~~~~~    
        ORAS
        Enhance Java ORAS SDK
        Description: The ORAS project aims to enhance its Java SDK to support a broader range of features from the OCI Distribution spec. This involves implementing missing functionality, improving existing features, and expanding the SDK’s overall capabilities.
        Expected Outcome:
        Implement missing features from the OCI Distribution and Image Specifications, such as chunked uploads and the Referrers API
        Improve existing features, robustness and tests to ensure full compatibility with the OCI Distribution and Image Specifications.
        Enhance documentation and provide more comprehensive examples.
        Add support for additional authentication methods, including using credentials from docker config.json
        Recommended Skills: java, oci
        Expected project size: medium (~175 hour projects)
        Mentor(s):
        Valentin Delaye (@jonesbusy, jonesbusy@gmail.com) - primary
        Feynman Zhou (@FeynmanZhou, zpf0610@gmail.com)
        Upstream Issues: https://github.com/oras-project/oras-java/issues
        The Update Framework (TUF)
        Snapshot Merkle trees
        Description: The TUF snapshot role is responsible for consistency proofs in a TUF repository. In certain high-volume repositories, the related snapshot metadata file can become prohibitively large, and thus impose a significant overhead for TUF clients. TAP 16 proposes a method for reducing the size of snapshot metadata a client must download without significantly weakening the security properties of TUF. In this project you will add TAP 16 support to python-tuf.
        Expected Outcome: Snapshot Merkle trees are implemented in python-tuf Metadata API and ngclient
        Recommended Skills: Python, data structures (merkle trees)
        Expected project size: medium (~175 hour projects)
        Mentor(s):
        Lukas Pühringer (@lukpueh) - primary
        Justin Cappos (@JustinCappos)
        Upstream Issue (URL): theupdateframework/taps#134

        ~~~~~~~~~~
        Vitess
        Enhancements for FAQ Chatbot for Vitess
        Description: Vitess is a distributed database system built on MySQL. Developers often need to search through documentation, Slack discussions, and GitHub issues to find answers. We are starting a project to implement an AI-powered FAQ chatbot using Retrieval-Augmented Generation, integrating vector search with an LLM (such as OpenAI, DeepSeek, GPT-4, Mistral, Llama 3). The chatbot will be available via a CLI and Slack bot for developer support.

        In the next phase, which will be implemented in this Summer Of Code (SOC) project, we will be adding more features like:

        Content filtering for chatbot safety and response validation
        Fine-tuning the model for improved accuracy
        Pipelines for refreshing data from new/updated docs
        Caching previous replies to reduce LLM costs
        Rate-limiting
        Better benchmarking for iterative improvements
        User feedback integration to improve relevancy
        Expected Outcome: Improved chatbot that provides accurate Vitess-related answers via CLI and Slack, using indexed documentation and discussions for retrieval.

        Recommended Skills: golang, python, LLM APIs, vector databases

        Expected project size: large (~350 hour projects)

        Mentor(s):

        Rohit Nayak (@rohit-nayak-ps, rohit@planetscale.com)
        Manan Gupta (@GuptaManan100, manan@planetscale.com)
        Upstream Issue: vitessio/vitess#17690

        ~~~~~~~~~~

        WasmEdge
        Virtual filesystem security for WasmEdge plug-ins with exporting WASI APIs
        Description: The WASI proposal defines the variety of rules to guarantee the virtual filesystem security and isolation when executing WASM binaries. However, besides using WASI directly in WASM, developers can also implement the host functions to access the filesystem in their guest programming language. This will break the sandbox of WebAssembly. In this program, our goal is to export the WASI APIs in WasmEdge, and use the APIs in WasmEdge plug-ins to ensure the filesystem security and WebAssembly isolation.
        Expected Outcome:
        Export needed WASI APIs in WasmEdge internal to provide the functions of checking and accessing host filesystem.
        Apply the APIs in some WasmEdge plug-ins which accessing the filesystem, such as WASI-NN.
        Implement test suites to verify the above behaviors.
        Recommended Skills:
        C++
        WebAssembly
        Expected project size: Large (~350 hour projects)
        Mentor(s):
        YiYing He (@q82419 , yiying@secondstate.io) - Primary
        Shen-Ta Hsieh (@ibmibmibm , beststeve@secondstate.io)
        Upstream Issue (URL): WasmEdge/WasmEdge#4012

        ~~~~~~~~~~
        Port WasmEdge and the WASI-NN ggml backend to the s390x platform
        Description: WasmEdge provides cross-platform support for amd64 and arm64 for executing AI/LLM applications. We would like to support as many new hardware platforms as possible, so developers and users will no longer need to worry about the actual hardware. All they need to do is develop their AI agent or LLM applications once and deploy their services anywhere. For more information, please check the upstream issue.
        Expected Outcome:
        Make the WasmEdge toolchain support the s390x platform, including the interpreter and the AOT mode.
        Ensure the WASI-NN ggml plugin can execute without any issues on the s390x platform.
        Implement test suites to verify the above behaviors.
        Write a document discussing the compilation, installation, execution, and verification of the work.
        Recommended Skills:
        C++
        s390x
        LLVM
        Expected project size: Large (~350 hour projects)
        Mentor(s):
        Hung-Ying Tai (@hydai, hydai@secondstate.io) - Primary
        dm4 (@dm4, dm4@secondstate.io)
        Upstream Issue (URL): WasmEdge/WasmEdge#4010

        ~~~~~~~~~~

        Use Runwasi with WasmEdge runtime to test multiple WASM apps as cloud services
        Description: With WasmEdge serving as one of Runwasi’s standard runtimes, and as our C++-implemented library continues to evolve, we also need a verification process integrated into Runwasi to streamline and validate the stability of both container and cloud environments.
        Expected Outcome:
        A concise GitHub workflow demonstrates Runwasi end-to-end testing on Kubernetes.
        Need to design an interactive application scenario that supports multiple nodes
        Try to incorporate the use of the WasmEdge plugin into this scenario
        Document
        Recommended Skills:
        Rust
        C++
        GDB
        git / github workflow
        shell script
        Expected project size: Large (~350 hour projects)
        Mentor(s):
        Vincent (@CaptainVincent, vincent@secondstate.io) - Primary
        yi (@0yi0 yi@secondstate.io)
        Upstream Issue (URL): WasmEdge/WasmEdge#4011

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/cncf/
    idea_list_url: https://github.com/cncf/mentoring/blob/main/programs/summerofcode/2025.md


  - organization_id: 20
    organization_name: CRIU 
    no_of_ideas: 5
    ideas_content: |
        Project ideas
        Add support for memory compression
        Summary: Support compression for page images

        We would like to support memory page files compression in CRIU using one of the fastest algorithms (it's matter of discussion which one to choose!).

        This task does not require any Linux kernel modifications and scope is limited to CRIU itself. At the same time it's complex enough as we need to touch memory dump/restore codepath in CRIU and also handle many corner cases like page-server and stuff.

        Details:

        Skill level: intermediate
        Language: C
        Expected size: 350 hours
        Suggested by: Andrei Vagin <avagin@gmail.com>
        Mentors: Radostin Stoyanov <rstoyanov@fedoraproject.org>, Alexander Mikhalitsyn <alexander@mihalicyn.com>, Andrei Vagin <avagin@gmail.com>

        ~~~~~~~~~~
        Use eBPF to lock and unlock the network
        Summary: Use eBPF instead of external iptables-restore tool for network lock and unlock.

        During checkpointing and restoring CRIU locks the network to make sure no network packets are accepted by the network stack during the time the process is checkpointed. Currently CRIU calls out to iptables-restore to create and delete the corresponding iptables rules. Another approach which avoids calling out to the external binary iptables-restore would be to directly inject eBPF rules. There have been reports from users that iptables-restore fails in some way and eBPF could avoid this external dependency.

        Links:

        https://www.criu.org/TCP_connection#Checkpoint_and_restore_TCP_connection
        https://github.com/systemd/systemd/blob/master/src/core/bpf-firewall.c
        https://blog.zeyady.com/2021-08-16/gsoc-criu
        Details:

        Skill level: intermediate
        Language: C
        Expected size: 350 hours
        Mentors: Radostin Stoyanov <rstoyanov@fedoraproject.org>, Prajwal S N <prajwalnadig21@gmail.com>
        Suggested by: Adrian Reber <areber@redhat.com>

        ~~~~~~~~~~
        Files on detached mounts
        Summary: Initial support of open files on "detached" mounts

        When criu dumps a process with an open fd on a file, it gets the mount identifier (mnt_id) via /proc/<pid>/fdinfo/<fd>, so that criu knows from which exact mount the file was initially opened. This way criu can restore this fd by opening the same exact file from topologically the same mount in restored mount tree.

        Restoring fd from the right mount can be important in different cases, for instance if the process would later want to resolve paths relative to the fd, and obviously resolving from the same file on different mount can lead to different resolved paths, or if the process wants to check path to the file via /proc/<pid>/fd/<fd>.

        But we have a problem finding on which mount we need to reopen the file at restore if we only know mnt_id but can't find this mnt_id in /proc/<pid>/mountinfo.

        Mountinfo file shows the mount tree topology of current mntns: parent - child relations, sharing group information, mountpoint and fs root information. And if we don't see mnt_id in it we don't know anything about this mount.

        This can happen in two cases

        1) external mount or file - if file was opened from e.g. host it's mount would not be visible in container mountinfo
        2) mount was lazily unmounted
        In case of 1) we have criu options to help criu handle external dependencies.

        In case of 2) or no options provided criu can't resolve mnt_id in mountinfo and criu fails.

        Solution: We can handle 2) with: resolving major/minor via fstat, using name_to_handle_at and open_by_handle_at to open same file on any other available mount from same superblock (same major/minor) in container. Now we have fd2 of the same file as fd, but on existing mount we can dump it as usual instead, and mark it as "detached" in image, now criu on restore knows where to find this file, but instead of just opening fd2 from actually restored mount, we create a temporary bindmount which is lazy unmounted just after open making the file appear as a file on detached mount.

        Known problems with this approach:

        Stat on btrfs gives wrong major/minor
        file handles does not work everywhere
        file handles can return fd2 on deleted file or on other hardlink, this needs special handling.
        Additionally (optional part): We can export real major/minor in fdinfo (kernel). We can think of new kernel interface to get mount's major/minor and root (shift from fsroot) for detached mounts, if we have it we don't need file handle hack to find file on other mount (see fsinfo or getvalues kernel patches in LKML, can we add this info there?).

        Details:

        Skill level: intermediate
        Language: C
        Expected size: 350 hours
        Mentor: Pavel Tikhomirov <ptikhomirov@virtuozzo.com>
        Suggested by: Pavel Tikhomirov <ptikhomirov@virtuozzo.com>
        Checkpointing of POSIX message queues
        Summary: Add support for checkpoint/restore of POSIX message queues

        POSIX message queues are a widely used inter-process communication mechanism. Message queues are implemented as files on a virtual filesystem (mqueue), where a file descriptor (message queue descriptor) is used to perform operations such as sending or receiving messages. To support checkpoint/restore of POSIX message queues, we need a kernel interface (similar to MSG_PEEK) that would enable the retrieval of messages from a queue without removing them. This project aims to implement such an interface that allows retrieving all messages and their priorities from a POSIX message queue.

        Links:

        https://github.com/checkpoint-restore/criu/issues/2285
        https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/ipc/mqueue.c
        https://www.man7.org/tlpi/download/TLPI-52-POSIX_Message_Queues.pdf
        Details:

        Skill level: intermediate
        Language: C
        Expected size: 350 hours
        Mentors: Radostin Stoyanov <rstoyanov@fedoraproject.org>, Pavel Tikhomirov <ptikhomirov@virtuozzo.com>, Prajwal S N <prajwalnadig21@gmail.com>
        Suggested by: Pavel Tikhomirov <ptikhomirov@virtuozzo.com>

        ~~~~~~~~~~


        Add support for arm64 Guarded Control Stack (GCS)
        Summary: Support arm64 Guarded Control Stack (GCS)

        The arm64 Guarded Control Stack (GCS) feature provides support for hardware protected stacks of return addresses, intended to provide hardening against return oriented programming (ROP) attacks and to make it easier to gather call stacks for applications such as profiling (taken from [1]). We would like to support arm64 Guarded Control Stack (GCS) in CRIU, which means that CRIU should be able to Checkpoint/Restore applications using GCS.

        This task should not require any Linux kernel modifications but will require a lot of effort to understand Linux kernel and glibc support patches. We have a good example of support for x86 shadow stack [4].

        Links:

        [1] kernel support https://lore.kernel.org/all/20241001-arm64-gcs-v13-0-222b78d87eee@kernel.org
        [2] libc support https://inbox.sourceware.org/libc-alpha/20250117174119.3254972-1-yury.khrustalev@arm.com
        [3] libc tests https://inbox.sourceware.org/libc-alpha/20250210114538.1723249-1-yury.khrustalev@arm.com
        [4] x86 support https://github.com/checkpoint-restore/criu/pull/2306
        Details:

        Skill level: expert (a lot of moving parts: Linux kernel / libc / CRIU)
        Language: C
        Expected size: 350 hours
        Suggested by: Mike Rapoport <rppt@kernel.org>
        Mentors: Mike Rapoport <rppt@kernel.org>, Andrei Vagin <avagin@gmail.com>, Alexander Mikhalitsyn <alexander@mihalicyn.com>

        ~~~~~~~~~~
        Coordinated checkpointing of distributed applications
        Summary: Enable coordinated container checkpointing with Kubernetes.

        Checkpointing support has been recently introduced in Kubernetes, where the smallest deployable unit is a Pod (a group of containers). Kubernetes is often used to deploy applications that are distributed across multiple nodes. However, checkpointing such distributed applications requires a coordination mechanism to synchronize the checkpoint and restore operations. To address this challenge, we have developed a new tool called criu-coordinator that relies on the action-script functionality of CRIU to enable synchronization in distributed environments. This project aims to extend this tool to enable seamless integration with the checkpointing functionality of Kubernetes.

        Links:

        https://github.com/checkpoint-restore/criu-coordinator
        https://lpc.events/event/18/contributions/1803/
        https://sched.co/1YeT4
        https://kubernetes.io/blog/2022/12/05/forensic-container-checkpointing-alpha/
        Details:

        Skill level: intermediate
        Language: Rust / Go / C
        Expected size: 350 hours
        Mentors: Radostin Stoyanov <rstoyanov@fedoraproject.org>, Prajwal S N <prajwalnadig21@gmail.com>
        Suggested by: Radostin Stoyanov <rstoyanov@fedoraproject.org>

        

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/criu/
    idea_list_url: https://criu.org/Google_Summer_of_Code_Ideas
  

  - organization_id: 21
    organization_name: Center for Translational Data Science
    no_of_ideas: 7
    ideas_content: |
        Google Summer of Code - Project Ideas 2025
        #1 Project Name: Towards Personalized Medicine with FHIR Integration and Data Driven Discovery
        Mentor(s): Alex VanTol, Kyle Burton
        Project Description
        FHIR (Fast Healthcare Interoperability Resources, pronounced “fire”) is the standard for ensuring smooth data exchange and interoperability in electronic health records (EHR) and widely used in hospital settings. This project will focus on integrating a FHIR server into an open-source data platform used for managing and analyzing distributed biomedical data and supporting federated AI for data driven discovery.
        As part of this endeavor, you will work on enabling this platform to support FHIR standards, using synthetic data to ensure the functionality of the solutions developed. You will gain valuable experience at the intersection of healthcare and technology, working on tasks that include cloud infrastructure and modern data standards.
        Gain a deep understanding of the FHIR standard and how it supports interoperability of EHR systems.
        Learn about cloud-based architectures for managing and sharing biomedical data.
        Hone your ability to write, translate, and estimate business and technical requirements through user stories, tickets, and epics.
        Develop and deploy code, as well as create integration tests for proof of concept scenarios.
        Contribute to the enhancement of healthcare data interoperability.
        Expand your technical skills by working with cloud infrastructure and standardized data protocols.
        Acquire hands-on experience contributing to an impactful open-source software project.
        Expected Outcomes
        Automated deployment and configuration of a FHIR server within the data platform.
        Capability for the data platform to import and export FHIR data seamlessly.
        Skills Required/Preferred
        Required: 
        Python programming experience
        Some experience with cloud infrastructure

        Preferred:
        Some familiarity with healthcare data
        Java programming experience
        Javascript programming experience
        Expected Size and Difficulty
        350 hours
        Difficulty - Medium

        ~~~~~~~~~~

        #2 Project Name: Supporting an Open-Source Data Lake Architecture with Graph-like Data
        Mentor(s): Alex VanTol, Michael Lukowski
        Project Description
        This project focuses on enhancing a data platform by implementing a versatile solution for data ingestion and storage using a data lakehouse architecture. The aim is to prototype a method for converting graph-structured data into Avro-based files, specifically utilizing a file format called the Portable Format for Biomedical data (PFB). This format supports exporting and importing bulk clinical and other structured data within healthcare data platforms.
        You will engage in designing and developing tooling to convert data from original sources, representing graph-like models, into serialized Avro files for seamless ingestion into a data lake. This project offers a unique opportunity to delve into data lakehouse architectures, graph data models, and serialization techniques, enriching your expertise in these areas.
        Understand and work with data lakehouse architectures for managing diverse datasets.
        Learn to convert data from graph models into an Avro-based serialized format.
        Develop skills in creating extensible methodologies and tooling for data ingestion.
        Gain familiarity with querying and visualizing graph models contained within serialized files.
        Explore the intersection of data management, bioinformatics, and healthcare data platforms.
        Contribute to the development of advanced data ingestion and storage solutions.
        Enhance your understanding of data lakehouses and serialization formats like Avro.
        Acquire hands-on experience with graph data models and their applications.
        Participate in an open-source project that has real-world impact in the healthcare field.
        Expected Outcomes
        Develop methodology and tools for converting graph-structured data into Avro-based serialized files.
        Potentially include tools for querying and visualizing graph models within the serialized format, depending on project scope.
        Skills Required/Preferred
        Required:
        Python programming experience
        Preferred:
        Knowledge of graph models
        Some familiarity with serialization formats (specifically, Avro)
        Knowledge of UX and/or client side tooling
        Expected Size and Difficulty
        175 hours 
        Difficulty - Medium

        ~~~~~~~~~~

        #3 Project Name: Improve Scalable Data Download Functionality Using Globus and an Open-Source Python SDK & CLI
        Mentor(s): Alex VanTol, Pauline Ribeyre
        Project Description
        This project aims to enhance the data download capabilities of a Python SDK & CLI used to interact with a large-scale data management platform. The goal is to create a consistent and efficient tool for researchers to download and stream large biomedical data sets. This involves integrating with existing RESTful APIs and Globus, a service for secure and reliable data transfer.
        You will work on implementing data download functionality within the Python SDK & CLI, writing unit tests to ensure robust code, and optimizing the download process using asynchronous capabilities in Python. This tool will be extensively used by researchers and scientists to stream large data sets to virtual workspaces for analysis.
        Gain experience in enhancing data download functionalities in a scalable manner.
        Learn to work with RESTful APIs and how to interact with them programmatically.
        Get hands-on experience with Globus for secure data transfer.
        Develop skills in Python programming, particularly in creating efficient and asynchronous code.
        Learn to write thorough unit tests to ensure high code quality.
        Understand the challenges and requirements of streaming large biomedical data sets.
        Contribute to improving tools that support large-scale data management and research.
        Enhance your programming skills, particularly in Python and Golang.
        Work on real-world projects that benefit researchers and scientists in the biomedical field.
        Gain experience in using modern data transfer technologies and optimizing performance.
        Expected Outcomes
        Implemented data download functionality within the Python SDK & CLI, integrated with Globus.
        Achieve 100% unit test coverage for the new code.
        Optimized data download process for improved performance.
        Skills Required/Preferred
        Required:
        Ability to read and understand Golang
        Ability to code in Python
        Preferred:
        Familiarity with RESTful APIs
        Familiarity with testing
        Familiarity with command line interfaces and/or UX
        Familiarity with concepts around concurrency
        Expected Size and Difficulty
        175 hours
        Difficulty - Medium

        ~~~~~~~~~~

        #4 Project Name: Towards a Data Commons Operations Center with Observability and Monitoring
        Mentor(s): Jawad Qureshi
        Project Description
        The goal of this project is to develop an Operations Center dashboard (CSOC) to manage multiple standalone and interconnected data commons running Gen3, a well-established open source platform for biomedical research. This dashboard will streamline the deployment, monitoring, and management of Gen3 data commons and meshes through a unified interface. The project will involve creating a distributed system with a Go-based backend and Next.js frontend, integrating with Kubernetes, Grafana, Helm, and Terraform, and ensuring secure server-agent communication.

        Expected Outcomes
        Production-ready Operations Center: A functional dashboard with a Go backend and Next.js frontend.
        RBAC and Security Policy Administration: Implementation of role-based access control (RBAC) and security policies.
        Observability Platform: Complete observability integrated with Prometheus/Grafana for monitoring.
        User-Friendly Dashboard: An intuitive interface for Gen3 commons deployment and management.
        Secure Server-Agent Communication: Infrastructure to ensure secure communication between server and agents.
        Comprehensive Documentation: Detailed system documentation and deployment guides.

        Skills Required/Preferred
        Go programming experience
        React/Next.js development skills / Javascript
        Understanding of Kubernetes, Helm, and Terraform
        Understanding of Cloud Infrastructure
        Experience with gRPC
        Understanding the pillars of observability (metrics, logs, tracing)
        Expected Size and Difficulty
        Number of hours 1000
        Difficulty - (Medium - Difficult)

        ~~~~~~~~~~

        #5 Project Name: Enhance Data Solutions with Native Graph Database Integration
        Mentor(s): Craig Barnes, Andrew Prokhorenkov, Alex VanTol
        Project Description
        This project aims to significantly improve the efficiency and capabilities of our data platform by transitioning from a custom PostgreSQL backend to a native graph database solution. With the increasing reliability and performance of graph databases like neo4j, this transition will enhance how we manage, analyze, and query complex biomedical data.
        Your role will involve developing a new Python-based microservice that supports the same RESTful APIs as our current submission and query services. Additionally, the microservice will dynamically generate GraphQL (or GraphQL-like) APIs based on a configured data schema, facilitating advanced search and query capabilities.
        Expected Outcomes
        Evaluate and analyze the best native graph database solutions for integration.
        Implement the selected graph database to replace the current PostgreSQL backend.
        Develop a new microservice in Python to support the existing RESTful and GraphQL (or GraphQL-like) APIs.
        Ensure seamless data submission, access, and querying within our data platform.
        This project will enhance our data platform's performance and flexibility, offering more robust solutions for managing biomedical data. Your contribution will provide significant improvements in data querying and management capabilities, benefiting the broader biomedical research community.
        Skills Required/Preferred
        Required: 
        Proficiency in Python
        Basic understanding of GitHub or other version control platforms
        Familiarity with RESTful APIs
        Understanding of graph databases
        Knowledge of user authorization and security principles

        Preferred:
        Familiarity with relational databases
        Understanding of microservice architecture, Docker, and containerization
        Expected Size and Difficulty
        Number of hours: 350 hours
        Difficulty - Hard

        ~~~~~~~~~~

        #6 Project Name: GPU Cluster Orchestration and Observability
        Mentors: Salman Sikandar and Bilal Baqar
        Project Description
        This project focuses on developing a CPU-based control plane to orchestrate jobs on an existing GPU cluster used by ML/AI researchers. The current setup is rudimentary, and the goal is to implement an automated job scheduling system along with comprehensive observability. The intern will design and implement a solution using technologies like Slurm for orchestration, and Prometheus/Grafana for monitoring and alerting.
        Expected Outcomes:
        Implement a job scheduler with priority queues and preemption capabilities for GPU workloads
        Develop a centralized dashboard displaying GPU/CPU utilization, job queue status, and thermal metrics
        Create Terraform/Ansible playbooks for reproducible cluster provisioning
        Design and implement automated alerting based on predefined thresholds and anomaly detection
        Skills Required/Preferred
        Required:
        Python or Go programming
        Linux systems administration
        Basic networking concepts
        Containerization (Docker)
        Preferred:
        Experience with Slurm
        Familiarity with Prometheus and Grafana
        GPU architecture knowledge (CUDA/NCCL)
        Experience with distributed systems

        Expected Size and Difficulty
        Number of Hours: 300-350 hours (8-10 weeks)
        Difficulty: Intermediate to Advanced

        ~~~~~~~~~~


        #7 Project Name: Staging Inference Cluster with CI/CD
        Mentors:
        Salman Sikandar and Bilal Baqar
        Project Description
        This project involves building a staging inference cluster to host production versions of ML models with auto scaling capabilities and CI/CD pipelines. The intern will set up an environment that allows for seamless promotion of trained models to production, implementing canary deployments and rollback mechanisms. The project will utilize technologies such as KEDA or Vertical Pod Autoscaler for autoscaling, and ArgoCD or Flux for GitOps-driven CI/CD.
        Expected Outcomes:

        Establish a staging inference cluster with autoscaling triggered by request latency/throughput thresholds
        Implement a GitHub Actions pipeline for model validation, containerization, and deployment
        Develop GitOps-driven CI/CD pipelines using ArgoCD or Flux for automated deployments
        Create a system for canary deployments and automated rollbacks based on performance metrics

        Skills Required/Preferred
        Required:
        Python or Go programming
        CI/CD concepts and tools
        Containerization (Docker)
        Basic understanding of ML workflows
        Preferred:
        Knowledge of ML model serving frameworks
        Familiarity with GitOps principles

        Expected Size and Difficulty
        Number of Hours: 300-350 hours (8-10 weeks)
        Difficulty: Intermediate to Advanced


          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/center-for-translational-data-science/
    idea_list_url: https://docs.google.com/document/d/1kiEDB6tw2xD8Qj3uxpSELjazW35llHM1a9Nt_LQKwHw/edit?usp=sharing

  - organization_id: 22
    organization_name: Ceph Foundation
    no_of_ideas: 7
    ideas_content: |
      
      Teuthology on Podman ¶
      Mentor name(s): Zack Cerza, Kamoltat (Junior) Sirivadhna Aishwarya Mathuria, Vallari Agrawal
      Mentor email(s): zack1@ibm.com, ksirivad@ibm.com, aishwarya.mathuria@ibm.com, vallari.agrawal@ibm.com
      Difficulty: Hard
      Project Hours: 175
      Skills needed: python, containerisation, linux
      Subcomponent of Ceph: Ceph Integration Test Framework
      Description of project:
      ceph-devstack is an in-development tool that uses rootless podman containers to deploy a scaled-down teuthology lab. It has proven useful for testing changes to teuthology and its related services, allowing us to more easily and flexibly make changes to components without worrying about causing outages.
      It has some basic ability to run Ceph tests, but could benefit significantly from more investment in that area.
      Improve and extend ceph-devstack's ability to perform teuthology tests against Ceph builds. This project will involve writing Python code and tests to orchestrate podman containers, and working with security systems like SELinux, CGroups, and Linux capabilities.
      Standup/weekly call mentee could attend?: Teuthology weekly meeting
      Steps to evaluate an applicant for the project: TBD
      1-2 short paragraphs about what first 2 weeks of work would look like during the internship: TBD
      Expected Outcome:
      Extend ceph-devstack's ability to perform teuthology tests

      ~~~~~~~~~~
      smartmontools drivedb.h postprocessor ¶
      Mentor name(s): Anthony D'Atri, Sunil Angadi
      Mentor email(s): anthony.datri@ibm.com, sunil.angadi@ibm.com
      Difficulty: Intermediate
      Project Hours: 90
      Skills needed: c++, maybe python or golang
      Subcomponent of Ceph: Observability
      Description of project:
      smartmontools (smartctl) is pretty much the only game in town for harvesting metrics and counters from storage devices: SMART for SATA, a few things for SAS, and passthrough to nvme-cli for NVMe. It leverages a runtime file named drivedb.h that directs what attributes are to be found with what numeric IDs, and how to interpret them. drivedb.h is a mess, and upstream smartmontools would likely resist wholesale refactoring. For example, SSD wear might be labeled as "lifetime remaining" or "wear level" or multiple other strings. Some devices also report wear used, others wear remaining.
      One task would be to add an interpretation primitive to the c++ code so that a drivedb.h entry can specify that the result should be subtracted from 100.
      The larger task would be to write a postprocessor for drivedb.h that more or less is a sequence of regex invocations that converges the existing freeform attribute label names into a normalized, defined set. Many tools just pass through the text labels, so doing meaningful analysis or queries is difficult; often only a fraction of the data is actually captured as a result. The output also includes numeric attribute IDs, which are less varied, but relying on them instead of the text labels is fraught because these numeric IDs are not strictly standardized either. I have seen drives that report a metric on a different numeric ID than most others, and/or that report a different metric on a specific numeric than most others report on that ID.
      For extra credit, interface with the central telemetry DB as described in project "Public telemetry slice/dice of SMART data".
      Standup/weekly call mentee could attend?: TBD
      Steps to evaluate an applicant for the project: Ability to leverage code libraries and write the glue code.
      1-2 short paragraphs about what first 2 weeks of work would look like during the internship: TBD

      ~~~~~~~~~~
      The More The Merrier ¶
      Mentor name(s): Yuval Lifshitz
      Mentor email(s): ylifshit@ibm.com
      Difficulty: Hard
      Project Hours: 350
      Skills needed: C++, Python
      Subcomponent of Ceph: RGW
      Description of project:
      Detailed description of the project and evalution steps can be found here.
      Persistent bucket notifications are a very useful and powerful feature
      tech talk: https://www.youtube.com/watch?v=57Ejl6R-L20
      usecase example: https://www.youtube.com/watch?v=57Ejl6R-L20
      However, they can pose a performance issue, since the notifications regarding a specific bucket are written to a single RADOS queue (unlike the writes to the bucket which are distributed across multiple bucket shards. So, in case that small objects are written to the bucket, the overhead of the notifications is considerable. In this project, our goal would be to create a sharded bucket notifications queue, to allow for better performance of sending persistent bucket notifications.
      Standup/weekly call mentee could attend?: RGW daily Standup, RGW weekly refactoring meeting
      Steps to evaluate an applicant for the project:
      build ceph from source and run basic bucket notification tests
      fix low-hanging-fruit issues in bucket notifications
      1-2 short paragraphs about what first 2 weeks of work would look like during the internship: TBD
      Expected outcome:
      sharded implementation of persistent topic queue

      ~~~~~~~~~~
      stretch goal: perf test proving performance improvement
      Public telemetry slice/dice of SMART data ¶
      Mentor name(s): Anthony D'Atri
      Mentor email(s): anthony.datri@ibm.com
      Difficulty: Medium
      Project Hours: 175
      Skills needed: Some coding language, Python or Go, jq or JSON parsing or other text library.
      Subcomponent of Ceph: telemetry
      Description of project:
      Public telemetry today offers a few Grafana panels and downloadable archives of anonymized data. One field is a JSON blob of smartctl output. Parse this, apply a normalization layer, deduplicate, and present in one or more formats that facilitate analysis:
      CSV file containing attributes for only the latest report found for a given device
      The number of data points might be too high, but possibly a Grafana dashboard or even spreadsheet with template variables for manufacturer/model, interface type, etc. with various panes:
      Histograms of power_on hours, normalized endurance used or remaining, etc
      histogram or table of endurance remaining vs power on hours or TBW, i.e. allowing one to predict drive lifetime and inform purchase decisions, vs. assuming that SSDs especially QLC lack endurance or that high-endurance SKUs are required.
      reallocated sectors over time, etc.
      Standup/weekly call mentee could attend?: TBD
      Steps to evaluate an applicant for the project: Coding experience beyond Karel
      1-2 short paragraphs about what first 2 weeks of work would look like during the internship:
      Gain familiarity with the data format, including JSON. Discuss input filtering: skip over invalid entries, handle submissions from older smartmontools, uniqify, learn about SMART -- and how dumb it is, the need for nomalization of counters.
      Expected outcome:
      Described above under Description. More specifically, deriving the rate of wear over time for each specific SSD for which we have more than say a month of data: capture the delta between earliest and latest wear levels reported for each given serial number, and the time delta between those samples. Divide the wear delta by the time delta for rate of wear over time.
      
      ~~~~~~~~~~
      Warm and Fuzzy ¶
      Mentor name(s): Yuval Lifshitz, Pritha Srivastava
      Mentor email(s): ylifshit@ibm.com, Pritha.Srivastava@ibm.com
      Difficulty: Medium
      Project Hours: 175
      Skills needed: C++, Python and also depending with the tool
      Subcomponent of Ceph: RGW
      Description of project:
      The RGW's frontend is an S3 REST API server, and in this project we would like to use a REST API fuzzer to test the RGW for security issues (and other bugs). First step of the project would be to select the right tool (e.g. https://github.com/microsoft/restler-fuzzer), feed it with the AWS S3 OpenAPI spec, and see what happens when we let it connect to the RGW. Fixing issues the fuzzer finds would nice, but the real stretch goal would be to integrate these tests into teuthology.
      Standup/weekly call mentee could attend: RGW daily Standup, RGW weekly refactoring meeting
      Steps to evaluate an applicant for the project:
      Detailed description of the project and evalution steps can be found here.
      1-2 short paragraphs about what first 2 weeks of work would look like during the internship: TBD
      Expected outcome:
      find and fix security issues in the RGW found by the fuzzing tool
      stretch goal: integrate tool into automated teuthology runs

      ~~~~~~~~~~
      Ceph Dashboard Usability Improvements ¶
      Mentor name(s): Afreen Misbah
      Mentor email(s): afreen@ibm.com
      Difficulty: Easy
      Project Hours: 175
      Skills needed: Typescript, Angular, and basic understanding of HTML & CSS.
      Subcomponent of Ceph: Dashboard
      Description of project:
      Ceph Dashboard is Ceph's management and monitoring tool. It's a web application tool with Angular/Typescript on frontend side and Python as backend.
      We are in an effort to provide more usability workflows and solve UX issues to make management and monitoring easy for Ceph users.
      The task includes improving the notification system and creating a workflow for managing NVMe-oF devices from dashboard.
      Standup/weekly call mentee could attend?: Dashboard daily sync
      Steps to evaluate an applicant for the project:
      Build ceph dashboard locally via docker-compose and kcli both
      Able to understand issues and ask useful questions
      Eagerness to learn and contribute
      1-2 short paragraphs about what first 2 weeks of work would look like during the internship:
      Learning about ceph and storage and gradually contributing to the dashboard.
      Expected Outcome:
      Improve dashboard usability.

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/ceph-foundation/
    idea_list_url: https://ceph.io/en/developers/google-summer-of-code/

  - organization_id: 23
    organization_name: Checker Framework
    no_of_ideas: 4
    ideas_content: |
      Evaluate a type system or a Checker Framework feature
      These projects evaluate a recently-written type system or a feature used by multiple type systems. Using the type systems on real code is our most important source of new ideas and improvements. Many people have started out “just” doing a case study but have ended up making deep, fundamental contributions and even publishing scientific papers about their discoveries.

      One possible outcome is to identify weaknesses in the type-checker so that we can improve it. Another possible outcome is to provide evidence that the type-checker is effective and convince more users to adopt it. You will probably also discover defects (bugs) in the codebase being type-checked.

      Signature strings
      Determine whether the ASM library, or some other library, properly handles signature strings.

      Some challenging aspects of this case study are:

      Some libraries define their own new signature string formats (!), which you need to define in the Signature String Checker.
      Sometimes the library's documentation is incorrect, and in other cases the string format is not defined.
      Preventing mixed signed/unsigned computations
      An unsigned integer's bits are interpreted differently than a signed integer's bits. It is meaningless to add a signed and an unsigned integer — the result will be nonsense bits. The same is true of printing and of other numeric operators such as multiplication and comparison.

      We have a prototype compile-time verification tool that detects and prevents these errors. The goal of this project is to perform case studies to determine how often programmers make signedness errors (our initial investigation suggests that this is common!) and to improve the verification tool.

      The research questions are:

      How often do programmers make signedness errors?
      Is it feasible to automatically detect signedness errors? What techniques are useful?
      What is the false positive rate of a signedness verification tool — that is, false alarms from the tool?
      How much effort is required from a programmer?
      The methodology is:

      find open-source projects that use unsigned arithmetic
      run the verification tool on them
      for each tool warning, determine whether it is a defect in the project or a limitation of the verification tool. For example, the Signedness Checker does not currently handle boxed integers and BigInteger; these haven't yet come up in case studies but could be worthwhile enhancements. You may also need to write more annotations for libraries such as the JDK.
      submit bug reports against the project, or improve the verification tool
      A good way to find projects that use unsigned arithmetic is to find a library that supports unsigned arithmetic, then search on GitHub for projects that use that library.

      Here are some relevant libraries.

      In the JDK's Integer and Long, these include compareUnsigned, divideUnsigned, parseUnsignedInt, remainderUnsigned, and toUnsignedLong.
      Classes like DataInputStream, ObjectInputStream, and RandomAccessFile have readUnsignedByte.
      Arrays has compareUnsigned. The JDK is already annotated; search for @Unsigned within https://github.com/typetools/jdk.
      In Guava, see its unsigned support, such as UnsignedBytes, UnsignedLong, UnsignedLongs, etc. Guava is already annotated; search for @Unsigned within https://github.com/typetools/guava.
      The jOOU library consists of support for unsigned integers.
      Another possibility is to find Java projects that could use an unsigned arithmetic library but do not. For example, bc-java defines its own unsigned libraries, and some other programs might do direct bit manipulation.

      Whole-program type inference
      A type system is useful because it prevents certain errors. The downside of a type system is the effort required to write the types. Type inference is the process of writing the types for a program.

      The Checker Framework includes a whole-program inference that inserts type qualifiers in the user's program. It works well on some programs, but needs more enhancements to work well on all programs.

      Sound checking by default
      By default, the Checker Framework is unsound in several circumstances. “Unsound” means that the Checker Framework may report no warning even though the program can misbehave at run time.

      The reason that the Checker Framework is unsound is that we believe that enabling these checks would cause too many false positive warnings: warnings that the Checker Framework issues because it cannot prove that the code is safe (even though a human can see that the code is safe). Having too many false positive warnings would irritate users and lead them not to use the checker at all, or would force them to simply disable those checks.

      We would like to do studies of these command-line options to see whether our concern is justified. Is it prohibitive to enable sound checking? Or can we think of enhancements that would let us turn on those checks that are currently disabled by default?

      There is no need to annotate new code for this project. Just use existing annotated codebases, such as those that are type-checked as part of the Checker Framework's Azure Pipeline. In other words, you can start by enabling Azure Pipelines for your fork and then changing the default behavior in a branch. The Azure Pipelines job will show you what new warnings appear.

      Comparison to other tools
      Many other tools exist for prevention of programming errors, such as Error Prone, NullAway, FindBugs, JLint, PMD, and IDEs such as Eclipse and IntelliJ. These tools are not as powerful as the Checker Framework (some are bug finders rather than verification tools, and some perform a shallower analysis), but they may be easier to use. Programmers who use these tools wonder, "Is it worth my time to switch to using the Checker Framework?"

      The goal of this project is to perform a head-to-head comparison of as many different tools as possible. You will quantify:

      the number of annotations that need to be written
      the number of bugs detected
      the number of bugs missed
      the number of false positive warnings
      This project will help programmers to choose among the different tools — it will show when a programmer should or should not use the Checker Framework. This project will also indicate how each tool should be improved.

      One place to start would be with an old version of a program that is known to contain bugs. Or, start with the latest version of the program and re-introduce fixed bugs. (Either of these is more realistic than introducing artificial bugs into the program.) A possibility would be to use the Lookup program that has been used in previous case studies.

      Android support annotations
      Android uses its own annotations that are similar to some in the Checker Framework. Examples include the Android Studio support annotations, including @NonNull, @IntRange, @IntDef, and others.

      The goal of this project is to implement support for these annotations. That is probably as simple as creating aliased annotations by calling method addAliasedTypeAnnotation() in AnnotatedTypeFactory.

      Then, do a case study to show the utility (or not) of pluggable type-checking, by comparison with how Android Studio currently checks the annotations.
      
      ~~~~~~~~~~

      Annotate a library
      These projects annotate a library, so that it is easier to type-check clients of the library. Another benefit is that this may find bugs in the library. It can also give evidence for the usefulness of pluggable type-checking, or point out ways to improve the Checker Framework.
      When type-checking a method call, the Checker Framework uses the method declaration's annotations. This means that in order to type-check code that uses a library, the Checker Framework needs an annotated version of the library.
      The Checker Framework comes with a few annotated libraries. Increasing this number will make the Checker Framework even more useful, and easier to use.
      After you have chosen a library, fork the library's source code, adjust its build system to run the Checker Framework, and add annotations to it until the type-checker issues no warnings.
      Before you get started, be sure to read How to get started annotating legacy code. More generally, read the relevant sections of the Checker Framework manual.
      Choosing a library to annotate
      There are several ways to choose a library to annotate:
      The best way to choose a library is to try to annotate a program and notice that library annotations are needed in order to type-check the program.
      Alternately, you can choose a popular Java library.
      When annotating a library, it is important to type-check both the library and at least one client that uses it. Type-checking the client will ensure that the library annotations are accurate.
      Whatever library you choose, you will need to deeply understand its source code. You will find it easier to work with a library that is well-designed and well-documented.
      You should choose a library that is not already annotated. There are two exceptions to this.
      A library might be annotated for one type system, but you add annotations for a different type system. One advantage of this is that the library's build system is already set up to run the Checker Framework. You can tell which type systems a library is annotated for by examining its source code.
      A library might be annotated, but the annotations have not been verified by running the type-checker on the library source code. You would verify that the annotations in the library are correct.
      Guava library
      Guava is already partially annotated with nullness annotations — in part by Guava's developers, and in part by the Checker Framework team. However, Guava does not yet type-check without errors. Doing so could find more errors (the Checker Framework has found nullness and indexing errors in Guava in the past) and would be a good case study to learn the limitations of the Nullness Checker.
      
      ~~~~~~~~~~
      Create a new type system
      The Checker Framework is shipped with about 20 type-checkers. Users can create a new checker of their own. However, some users don't want to go to that trouble. They would like to have more type-checkers packaged with the Checker Framework for easy use.
      Each of these projects requires you to design a new type system, implement it, and perform case studies to demonstrate that it is both usable and effective in finding/preventing bugs.
      Ownership type system
      The lightweight ownership mechanism of the Resource Leak Checker is not implemented as a type system, but it should be. That would enable writing ownership annotations on generic type arguments, like List<@Owning Socket>. It would also enable changing the Resource Leak Checker so that non-@Owning formal parameters do not have their @MustCall annotation erased.
      We have some notes on possible implementation strategies.
      Non-Empty Checker for precise handling of Queue.peek() and poll()
      The Nullness Checker issues a false positive warning for this code:
      import java.util.PriorityQueue;
      import org.checkerframework.checker.nullness.qual.NonNull;
      
      public class MyClass {
          public static void usePriorityQueue(PriorityQueue<@NonNull Object> active) {
              while (!(active.isEmpty())) {
                  @NonNull Object queueMinPathNode = active.peek();
              }
          }
      }
      The Checker Framework does not determine that active.peek() returns a non-null value in this context.
      The contract of peek() is that it returns a non-null value if the queue is not empty and the queue contains no null values.
      To handle this code precisely, the Nullness Checker needs to know, for each queue, whether it is empty. This is analogous to how the Nullness Checker tracks whether a particular value is a key in a map.
      It should be handled the same way: by adding a new subchecker, called the Nonempty Checker, to the Nullness Checker. Its types are:
      @UnknownNonEmpty — the queue might or might not be empty
      @NonEmpty — the queue is definitely non-empty
      There is a start at this type-checker in branch nonempty-checker. It:
      defines the annotations
      creates the integration into the Nullness Checker
      However, it is not done. (In fact, it doesn't even compile.) For information about what needs to be done, see issue #399.
      When you are done, the Nullness Checker should issue only the // :: diagnostics from checker/tests/nullness/IsEmptyPoll.java — no more and no fewer. You can test that by running the Nullness Checker on the file, and when you are done you should delete the // @skip-test line so that the file is run as part of the Checker Framework test suite.
      Iteration Checker to prevent NoSuchElementException
      A Java program that uses an Iterator can throw NoSuchElementException if the program calls next() on the Iterator but the Iterator has no more elements to iterate over. Such exceptions even occur in production code (for example, in Eclipse's rdf4j).
      We would like a compile-time guarantee that this run-time error will never happen. Our analysis will statically determine whether the hasNext() method would return true. The basic type system has two type qualifiers: @HasNext is a subtype of @UnknownHasNext.
      A variable's type is @HasNext if the program calls hasNext() and it returns true. Implementing this is easy (see the dataflow section in the "How to create a new checker" chapter). The analysis can also permit some calls to next() even if the programmer has not called hasNext(). For example, a call to next() is permitted on a newly-constructed iterator that is made from a non-empty collection. (This special case could build upon the Non-Empty Checker mentioned above.) There are probably other special cases, which experimentation will reveal.
      Parts of this are already implemented, but it needs to be enhanced. Once case studies have demonstrated its effectiveness, then it can be released to the world, and a scientific paper can be written.
      Preventing injection vulnerabilities via specialized taint analysis
      Many security vulnerabilities result from use of untrusted data without sanitizing it first. Examples include SQL injection, cross-site scripting, command injection, and many more. Other vulnerabilities result from leaking private data, such as credit card numbers.
      We have built a generalized taint analysis that can address any of these problems. However, because it is so general, it is not very useful. A user must customize it for each particular problem.
      The goal of this project is to make those customizations, and to evaluate their usefulness. A specific research question is: "To what extent is a general taint analysis useful in eliminating a wide variety of security vulnerabilities? How much customization, if any, is needed?"
      The generalized taint analysis is the Checker Framework's a Tainting Checker. It requires customization to a particular domain:
      rename the @Tainted and @Untainted qualifiers to something more specific (such as @Private or @PaymentDetails or @HtmlQuoted), and
      annotate libraries.
      The first part of this project is to make this customization easier to do — preferably, a user will not have to change any code in the Checker Framework (the Subtyping Checker already works this way). As part of making customization easier, a user should be able to specify multiple levels of taint — many information classification hierarchies have more than two levels. For example, the US government separates information into four categories: Unclassified, Confidential, Secret, and Top Secret.
      The second part of this project is to provide several examples, and do case studies showing the utility of compile-time taint checking.
      Possible examples include:
      SQL injection
      OS command injection
      the @PrivacySource and @PrivacySink annotations used by the Meta Infer static analyzer.
      information flow
      many of the CWE/SANS most dangerous software programming errors (and the "on the cusp" ones too)
      For some microbenchmarks, see the Juliette test suite for Java from CWE.
      Warn about unsupported operations
      In Java, some objects do not fully implement their interface; they throw UnsupportedOperationException for some operations. One example is unmodifiable collections. They throw the exception when a mutating operation is called, such as add, addAll, put, remove, etc.
      The goal of this project is to design a compile-time verification tool to track which operations might not be supported. This tool will issue a warning whenever an UnsupportedOperationException might occur at run time. This helps programmers to avoid run-time exceptions (crashes) in their Java programs.
      The research questions include:
      Is it is possible to build a verification tool to prevent UnsupportedOperationException? What design is effective?
      How difficult is such a tool to use, in terms of programmer effort and number of false alarms?
      Are potential UnsupportedOperationException exceptions pervasive in Java programs? Is it possible to eliminate them?
      The methodology is:
      design a static (compile-time) analysis
      implement it
      evaluate it on open-source projects
      report bugs in the projects, and improve the tool
      Here is a possible design, as a pluggable type system.
        @Unmodifiable
             |
        @Modifiable
      In other words, the @Unmodifiable type qualifier is a supertype of @Modifiable. This means that a @Modifiable List can be used where an @Unmodifiable List is expected, but not vice versa.
      @Modifable is the default, and methods such as Arrays.asList and Collections.emptyList must be annotated to return the less-capable supertype.
      Overflow checking
      Overflow is when 32-bit arithmetic differs from ideal arithmetic. For example, in Java the int computation 2,147,483,647 + 1 yields a negative number, -2,147,483,648. The goal of this project is to detect and prevent problems such as these.
      One way to write this is as an extension of the Constant Value Checker, which already keeps track of integer ranges. It even already checks for overflow, but it never issues a warning when it discovers possible overflow. Your variant would do so.
      This problem is so challenging that there has been almost no previous research on static approaches to the problem. (Two relevant papers are IntScope: Automatically Detecting Integer Overflow Vulnerability in x86 Binary Using Symbolic Execution and Integer Overflow Vulnerabilities Detection in Software Binary Code.) Researchers are concerned that users will have to write a lot of annotations indicating the possible ranges of variables, and that even so there will be a lot of false positive warnings due to approximations in the conservative analysis. For example, will every loop that contains i++ cause a warning that i might overflow? That would not be acceptable: users would just disable the check.
      You can convince yourself of the difficulty by manually analyzing programs to see how clever the analysis has to be, or manually simulating your proposed analysis on a selection of real-world code to learn its weaknesses. You might also try it on good and bad binary search code.
      One way to make the problem tractable is to limit its scope: instead of being concerned with all possible arithmetic overflow, focus on a specific use case. As one concrete application, the Index Checker is currently unsound in the presence of integer overflow. If an integer i is known to be @Positive, and 1 is added to it, then the Index Checker believes that its type remains @Positive. If i was already Integer.MAX_VALUE, then the result is negative — that is, the Index Checker's approximation to it is unsound.
      This project involves removing this unsoundness by implementing a type system to track when an integer value might overflow — but this only matters for values that are used as an array index. That is, checking can be restricted to computations that involve an operand of type @IntRange). Implementing such an analysis would permit the Index Checker to extend its guarantees even to programs that might overflow.
      This analysis is important for some indexing bugs in practice. Using the Index Checker, we found 5 bugs in Google Guava related to overflow. Google marked these as high priority and fixed them immediately. In practice, there would be a run-time exception only for an array of size approximately Integer.MAX_INT.
      You could write an extension of the Constant Value Checker, which already keeps track of integer ranges and even determines when overflow is possible. It doesn't issue a warning, but your checker could record whether overflow was possible (this could be a two-element type system) and then issue a warning, if the value is used as an array index. Other implementation strategies may be possible.
      Here are some ideas for how to avoid the specific problem of issuing a warning about potential overflow for every i++ in a loop (but maybe other approaches are possible):
      The loop checks whether i == Integer.MAX_VALUE before incrementing. This wide-scale, disruptive code change is not acceptable.
      Make the default array size (the length of an unannotated array) be @ArrayLenRange(0, Integer.MAX_VALUE-1) rather than @UnknownVal, which is equivalent to @ArrayLenRange(0, Integer.MAX_VALUE-1). Now, every array construction requires the client to establish that the length is not Integer.MAX_VALUE. I don't have a feel for whether this would be unduly burdensome to users.
      Index checking for mutable length data structures
      The Index Checker is currently restricted to fixed-size data structures. A fixed-size data structure is one whose length cannot be changed once it is created, such as arrays and Strings. This limitation prevents the Index Checker from verifying indexing operations on mutable-size data structures, like Lists, that have add or remove methods. Since these kind of collections are common in practice, this is a severe limitation for the Index Checker.
      The limitation is caused by the Index Checker's use of types that are dependent on the length of data structures, like @LTLengthOf("data_structure"). If data_structure's length could change, then the correctness of this type might change.
      A naive solution would be to invalidate these types any time a method is called on data_structure. Unfortunately, aliasing makes this still unsound. Even more, a great solution to this problem would keep the information in the type when a method like add or remove is called on data_structure. A more complete solution might involve some special annotations on List that permit the information to be persisted.
      Another approach would be to run a pointer analysis before type-checking, then use that information for precise information about what lists might be changed by each call to add or remove. One possible pointer analysis would be that of Doop.
      This project would involve designing and implementing a solution to this problem.
      Nullness bug detector
      Verifying a program to be free of errors can be a daunting task. When starting out, a user may be more interested in bug-finding than verification. The goal of this project is to create a nullness bug detector that uses the powerful analysis of the Checker Framework and its Nullness Checker, but omits some of its more confusing or expensive features. The goal is to create a fast, easy-to-use bug detector. It would enable users to start small and advance to full verification in the future, rather than having to start out doing full verification.
      This could be structured as a new NullnessLight Checker, or as a command-line argument to the current Nullness Checker. Here are some differences from the real Nullness checker:
      No initialization analysis; the checker assumes that every value is initialized.
      No map key analysis; assume that, at every call to Map.get, the given key appears in the map.
      No invalidation of dataflow facts. Assume all method calls are pure, so method calls do not invalidate dataflow facts. Assume there is no aliasing, so field updates do not invalidate dataflow facts.
      Assume that boxing of primitives is @Pure: it returns the same value on every call.
      If the Checker Framework cannot infer a type argument, assume that the type argument is @NonNull.
      Each of these behaviors should be controlled by its own command-line argument, as well as being enabled in the NullnessLight Checker.
      The implementation may be relatively straightforward, since in most cases the behavior is just to disable some functionality of existing checkers.
      Tools such as FindBugs, NullAway, NullnessLight, and the Nullness Checker form a spectrum from easy-to-use bug detectors to sound verification. NullnessLight represents a new point in the design space. It will be interesting to compare these checkers:
      How much easier is it to use? For example, how many fewer annotations need to be written?
      How many more fewer true positives does it report — in other words, how many more false negatives does it suffer?
      How many fewer false positives does it report?
      Uber's NullAway tool is also an implementation of this idea (that is, a fast, but incomplete and unsound, nullness checker). NullAway doesn't let the user specify Java Generics: it assumes that every type parameter is @NonNull. Does Uber's tool provide users a good introduction to the ideas that a user can use to transition to a nullness type system later?
      
      ~~~~~~~~~~
      Enhance the toolset
      Indicate library methods that should be used instead
      Sometimes, the best way to avoid a checker warning is to use an annotated library method. Consider this code:
      @FqBinaryName String fqBinaryName = ...;
      @ClassGetName String componentType = fqBinaryName.substring(0, fqBinaryName.indexOf('['));
      The Signature String Checker issues a warning, because it does not reason about arbitrary string manipulations. The code is correct, but it is in bad style. It is confusing to perform string manipulations to convert between different string representations. It is clearer and less error-prone (the above code is buggy when fqBinaryName is not an array type!) to use a library method, and the checker accepts this code because the library method is appropriately annotated:
      import org.plumelib.reflection.Signatures;
      ...
      @ClassGetName String componentType = Signatures.getArrayElementType(fqBinaryName);
      However, users may not know about the library method. Therefore, the Checker Framework should issue a warning message, along with the error message, notifying users of the library method. For example, the Signature String Checker would heuristically mention the Signatures.getArrayElementType() method when it issues an error about string manipulation where some input is a FqBinaryName and the output is annotated as ClassGetName. It would behave similarly for other library methods.
      Improving error messages
      Compiler writers have come to realize that clarity of error messages is as important as the speed of the executable (1, 2, 3, 4). This is especially true when the language or type system has rich features.
      The goal of this project is to improve a compiler's error messages. Here are some distinct challenges:
      Some type errors can be more concisely or clearly expressed than the standard "found type A, expected type B" message.
      Some types are complex. The error message could explain them, or link to the manual, or give suggested fixes.
      Compiler messages currently show the effective type, which may be different than what the user wrote due to defaulting, inference, and syntactic sugar. For example, a user-written @IndexFor("a") annotation is syntactic sugar for @NonNegative @LTLengthOf("a"), and those types are the ones that currently appear in error messages. It might be good to show simpler types or ones that the user wrote.
      Some checkers combine multiple cooperating type systems; the Nullness Checker and the Index Checker are examples. If there is a problem with a variable's lower bound type, then its upper bound type should not be shown in the error message. This will make the message shorter and more specific, and avoid distracting the user with irrelevant information.
      When a checker has multiple type systems, a type error or the lack of one may depend on facts from multiple type systems, and this should be expressed to the user.
      Replace JavaParser by javac
      The Checker Framework uses JavaParser to parse a Java expressions. However, JavaParser is buggy and poorly maintained. The goal of this project is to replace every use of JavaParser by a use of javac-parse.
      Java expression parser
      A number of type annotations take, as an argument, a Java expression. The representation for these is as a JavaExpression. The goal of this project is to remove it.
      The JavaExpression class represents an AST. There is no need for the Checker Framework to define its own AST when the javac AST already exists and is maintained.
      The goals for the project include:
      Replace every use of JavaExpression by a use of the javac class class com.sun.tools.javac.tree.JCTree.JCExpression.html.
      Replace every use of a subclass of JavaExpression (listed in the "Direct Known Subclasses" section of the JavaExpression API documentation) by a use of a subclass of JCTree.JCExpression.html. For example, replace every use of MethodCall by JCTree.JCMethodInvocation.
      Replace the JavaExpressionParseUtil class and delete ExpressionToReceiverVisitor.
      Direct replacement of the classes is not possible, or we would have done it already. For example, JavaExpression contains some methods that javac lacks, such as isUnassignableByOtherCode. As a first step before doing the tasks listed above, you may want to convert these methods from instance methods of JavaExpression into static methods in JavaExpressions, making JavaExpression more like a standard AST that can be replaced by JavaParser classes. You also need to decide how to store the type field of JavaExpression, when JavaExpression is eliminated. An alternate design (or a partial step in the refactoring process) would be to retain the JavaExpression class, but make it a thin wrapper around javac classes that do most of the real work.
      Another aspect of this project is fixing the issues that are labeled "JavaExpression".
      Dataflow enhancements
      The Checker Framework's dataflow framework (manual here) implements flow-sensitive type refinement (local type inference) and other features. It is used in the Checker Framework and also in Error Prone, NullAway, and elsewhere.
      There are a number of open issues — both bugs and feature requests — related to the dataflow framework. The goal of this project is to address as many of those issues as possible, which will directly improve all the tools that use it.
      Side effect analysis, also known as purity analysis
      A side effect analysis reports what side effects a procedure may perform, such as what variable values it may modify. A side effect analysis is essential to other program analyses. A program analysis technique makes estimates about the current values of expressions. When a method call occurs, the analysis has to throw away most of its estimates, because the method call might change any variable. However, if the method is known to have no side effects, then the analysis doesn't need to throw away its estimates, and the analysis is more precise. Thus, an improvement to the foundational side effect analysis can improve many other program analyses.
      The goal of this project is to evaluate existing side effect analysis algorithms and implementations, in order to determine what is most effective and to improve them. The research questions include:
      What side effect analysis algorithms are most effective? What are their limitations?
      Can the most effective algorithms be combined to become even effective? Or can their limitations be overcome?
      How much does accurate side effect analysis improve other programming tasks?
      The methodology is to collect existing side effect analysis tools (two examples are Soot and Geffken); run them on open-source projects; examine the result; and then improve them.
      Javadoc support
      Currently, type annotations are only displayed in Javadoc if they are explicitly written by the programmer. However, the Checker Framework provides flexible defaulting mechanisms, reducing the annotation overhead. This project will integrate the Checker Framework defaulting phase with Javadoc, showing the signatures after applying defaulting rules.
      There are other type-annotation-related improvements to Javadoc that can be explored, e.g. using JavaScript to show or hide only the type annotations currently of interest.
      
      

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/checker-framework/
    idea_list_url: https://rawgit.com/typetools/checker-framework/master/docs/developer/new-contributor-projects.html

  - organization_id: 24
    organization_name: Chromium
    no_of_ideas:
    ideas_content: |
      1. Interaction to Next Paint (INP) "subparts" (Medium Size)




      Project Description
      The web performance specifications define how browsers are supposed to be behaving when it comes to the various web performance APIs, and the Core Web Vitals (CWV) program uses those apis to automatically measure the performance and UX of most websites in the world, and shares the data publicly via the Chrome User Experience Report (CrUX). Last year a new metric, Interaction to Next Paint (INP), was added to the CWV. This year, we would like your help to give developers additional insights into INP latency issues by also reporting INP "subparts", similar to what we did for LCP last year.  For example: a developer should know if any INP responsiveness issues are caused by: long input delay (maybe the page as blocked and busy)
      event processing times (maybe the interaction event listeners were too complex) rendering/pixel presentation delays (maybe the page content is too complex/bloated) …or other task scheduling issues. We’ve recently instrumented the measurement code (i.e. the Event Timing API) to measure these time points, but we need your help to finish the job: moving the data from Renderer code to Browser code (using Mojo IPC), adding it to field metrics reporting (UKM), and eventually helping teammates integrate into CrUX experimental data – while also writing tests for the above. This is an open source project and some of the contributions will be useful to developers for local lab testing, as well (as for other downstream browsers). Finally, there are also several stretch technical opportunities related to the Event Timing API / INP metric.
      Proposal Doc for more information: Link
      Location to ask project specific questions not answered above: here (preferred), or chromium-gsoc-project1@chromium.org
      Beginner Bugs: https://issues.chromium.org/issues/40858679 
      Requirements: C++, JavaScript, Performance tooling (DevTools performance panel). Time zone flexible but hosts are in Eastern time zone.

      ~~~~~~~~~~


      2. Android Virtual Printer Application (Large Size)


      Project Description
      An Android application which can pretend to be a printer (act as a virtual printer), which can handle interactions between Android devices, software and printer itself. Once this virtual printer Android application is installed, the Android device can detect a new printer, set up the printer via network connection, users can use it to print and change settings based on its capability, and the virtual printer can respond to print jobs. This virtual printer application should allow configuration on printer capabilities, and print job response, in this way it can be used to test different functionalities and validate handling errors.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project2@chromium.org
      Requirements: Android application development, Kotlin, Rust, Java, C++, C

      ~~~~~~~~~~

      3. Chrome Extension APIs (Large Size)

      Project Description
      We have a number of new APIs and features that we would like to add to the Chrome extensions platform but don't currently have prioritized (for example, improvements to the declarative network request API used for network filtering, and new features in the `chrome.sidePanel` API). Many of these involve work in the W3C WebExtensions Community Group. We would like to offer a contributor the opportunity to own a work item from this list.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here  (preferred), chromium-gsoc-project3@chromium.org
      Beginner Bugs: 
      Requirements: C++ for the Chromium codebase.  JavaScript needed for writing extensions.


      ~~~~~~~~~~


      4. Structured DNS Errors (Small Size)

      Project Description
      Chrome should implement enough of the emerging Public DNS Errors standards to allow public DNS servers to indicate to clients when certain DNS resolutions are blocked for legal reasons.
      https://github.com/mnot/public-resolver-errors
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project4@chromium.org
      Beginner Bugs: https://issues.chromium.org/hotlists/6689006
      Requirements: C++, Chromium Net Stack. Must overlap with US East Coast timezone.

      ~~~~~~~~~~


      5. FedCM API Test Coverage and Flakiness (Medium Size)

      Project Description
      The FedCM API comprises of multiple tests which require the bot to go through a federated authentication process. The project consists of documenting the existing test coverage, improving it, and fixing test flakiness.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project5@chromium.org
      Beginner Bugs: https://issues.chromium.org/issues/41482163
      Requirements: C++, as well as a little bit of HTML, JS, Python. US East is preferred but not required


      ~~~~~~~~~~


      6. Add 3rd Party Theme Support for Tab Groups (Small Size)

      Project Description
      Add an API to allow 3rd party theme developers to customize the colors used for tab groups.

      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project6@chromium.org
      Beginner Bugs: https://issues.chromium.org/issues/40711397, https://issues.chromium.org/issues/370416945 https://issues.chromium.org/issues/40929354
      Requirements: C++ prior experience is requested, ability to work in PST is requested.

      ~~~~~~~~~~

      7. ChromeOS Platform Input Device Quality Monitoring (Medium Size)

      Project Description
      ChromeOS devices generally contain user-input devices (touchscreens, touchpads, etc.) that contain firmware and communicate over internal buses. This firmware can have bugs, sometimes needs to be updated in the field, and the communication buses can show errors.

      Improved testing during development, and logging for production devices, can reduce shipped issues and reduction of in-field failures, and improved analysis leading to better OEM response to such issues.

      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project7@chromium.org
      Beginner Bugs: https://issuetracker.google.com/397520373, https://issuetracker.google.com/397521060, https://issuetracker.google.com/397520674
      Requirements: ChromeOS development tech stack (C++, shell scripts), experience or patience to learn ChromeOS build system and loading custom software onto a ChromeBook, moderate overlap with US-Pacific timezone.


      ~~~~~~~~~~


      8. Farfetchd: tracing/replay (Medium Size)

      Project Description
      Preloading files into memory (or prefetch) is a useful mechanism for improving application “cold start” performance. On ChromiumOS, this technique is used via ureadahead to speed up boot times by up to 20%. Farfetchd is a general purpose D-Bus service that allows prefetch of application binaries and associated resources and allows the optimization of cold start times.
      This proposal aims to add support to farfetchd for:
      1) Tracing: via tracefs, tracing file pages that are fetched for an application during a given workload and standardized tracepoints.
      2) Replay: Using the collected trace, preload the specific pages from disk and measure improvements in application performance.

      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project8@chromium.org
      Beginner Bugs: https://issuetracker.google.com/issues/397539111, https://issuetracker.google.com/issues/397539767
      Requirements: C++, linux kernel, tracing, no TZ requirements

      ~~~~~~~~~~


      9. Develop fwupd plugin to handle touch firmware updates (Large Size)

      Project Description
      A number of components like storage devices use fwupd to handle firmware updates in ChromeOS. The platform inputs team would like to start using fwupd to manage and handle firmware updates for touch controllers. This project aims to build out a handful of fwupd plugins for touch controllers.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project9@chromium.org
      Beginner Bugs: https://issuetracker.google.com/issues/172340186, https://issuetracker.google.com/issues/397567795
      Requirements: C, C++

      ~~~~~~~~~~


      10. Debug WebUI For Tabstrip states (Medium Size)

      Project Description
      Tabstrip state and session states for browsers are complicated and rely on correct ordering of tabs in the tabstrip model, groups and sessions to restore tabs in the right position and selection state. As a result this has resulted in numerous bugs and it is often a pain point to figure out if it is a tabstrip model issue or a client issue. A webUI that captures the live state of the backend of the browser and tabstrip models will be really helpful in finding issues and edge cases.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project10@chromium.org
      Beginner Bugs: WebUI TabStrip Bug, Print Preview + Tab Dragging Bug, Keyboard Shortcut Bug
      Requirements: Familiarity with HTML, CSS and JS, Proficiency in C++ codebases and concepts, Working from PST 9:00 AM - 5:00 PM hours

      ~~~~~~~~~~

      11. Improve Chromium Web Audio Testing (Medium Size)

      Project Description
      The audit.js WebAudio test helper library was introduced in 2016 and is currently used by over 300 test files in Chromium’s blink/web_test directory. This library was initially created to run tests sequentially with callback/promise support and to provide utility functions for audio-specific assertions. However, the W3C Test Harness (testharness.js) offers superior support for test runners and assertions, rendering many features in audit.js redundant. Removing audit.js from Chromium would reduce resource consumption in the Chrome team’s Continuous Integration Infrastructure and allow us to leverage the well-supported and well-maintained W3C Test Harness library.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project11@chromium.org
      Beginner Bugs: crbug.com/396477778
      Requirements: Proficiency in JavaScript (reading, writing, debugging), Familiarity with HTML and CSS

      ~~~~~~~~~~
      12. ChromeStatus Search UI Enhancement Project (Medium Size)

      Project Description
      Enhance the search functionality on chromestatus.com and webstatus.dev with several new auto-complete details.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project12@chromium.org
      Beginner Bugs: https://github.com/GoogleChrome/chromium-dashboard/issues?q=is%3Aissue%20state%3Aopen%20label%3Agoodfirstbug
      Requirements: HTML, CSS, TypeScript, Python, Go, Web components, UX / Usability

      ~~~~~~~~~~


      13. Enhancing the webstatus.dev User Experience (Medium Size)


      Project Description
      webstatus.dev is a valuable resource for web developers, providing up-to-date information on the browser compatibility of various web technologies. This project aims to enhance the user experience of webstatus.dev by making it more accessible and user-friendly across a wider range of devices and user preferences, with a particular focus on mobile devices and dark mode support. The project will involve redesigning key pages (overview, feature detail, and stats) for optimal mobile viewing, implementing a comprehensive dark theme, and ensuring compatibility with the Lit framework, Google Charts, and Shoelace components.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project13@chromium.org
      Beginner Bugs: https://github.com/GoogleChrome/chromium-dashboard/issues?q=is%3Aissue%20state%3Aopen%20label%3Agoodfirstbug
      Requirements: Lit, TypeScript, HTML, CSS Google Charts, Shoelace Web Test Runner (for unit tests) Playwright (for E2E testing), Docker (for local environment provisioning)

      ~~~~~~~~~~


      14. WebGPU Texel Buffers (Medium Size)


      Project Description
      WebGPU is a new graphics API, shipped in Chromium in 2023, that brings modern GPU capabilities to the web. The goal of this project is to implement new functionality in Chromium to further advance the capabilities of WebGPU, allowing a broader range of applications to target the API. Specifically, the "texel buffers" feature has already been proposed at the W3C standards committee, and the next steps are to prototype the functionality so that we can get feedback from real users and push the standardization process forwards.
      Proposal Doc for more information: Link
      Location to ask project specific questions: here (preferred), chromium-gsoc-project14@chromium.org
      Beginner Bugs: crbug.com/42250870 and crbug.com/42250968
      Requirements: C++ proficiency, timezone compatible with North American mentors


          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/chromium/
    idea_list_url: https://docs.google.com/presentation/d/1ozDiULkf2Gi4HH1XA_Ad9O7rQpP9SP0yPEs_dpcBZKM/edit?usp=sharing

  - organization_id: 25
    organization_name: CircuitVerse.org
    no_of_ideas: 7
    ideas_content: |
      
      Project 1: Circuit Management & Performance Enhancement
      Duration: 175 hours
      Difficulty: Medium
      Technologies: Ruby on Rails, JavaScript
      This project focuses on refining the organizational structure and performance of the CircuitVerse platform. The objective is to enhance user efficiency by introducing a systematic approach to circuit management and optimizing backend operations. Participants will implement a folder-based system for subcircuits, enabling users to categorize their work effectively. Additionally, the project includes developing a feature for circuits with group-specific visibility, ensuring accessibility within designated teams while maintaining privacy. Performance improvements will involve optimizing Ruby on Rails N+1 queries. The scope also extends to creating a comprehensive circuits explore page with search functionality, integrating a leaderboard for weekly contests, and enabling locale switching from the homepage to improve accessibility.
      Learning Path:
      Acquire proficiency in Ruby on Rails through The Odin Project’s Full-Stack Ruby on Rails Course, covering foundational and advanced concepts.
      Enhance Rails expertise with Pragmatic Studio’s Rails Course for structured, practical training.
      Develop JavaScript skills using JavaScript.info to support frontend enhancements.
      Possible Mentors: Vaibhav Upreti, Smriti Garg

      ~~~~~~~~~~
      Project 2: Desktop Application & Vue Frontend Updates
      Duration: 175 hours
      Difficulty: Medium
      Technologies: VueJS, Ruby on Rails, TypeScript, JavaScript
      This project aims to extend CircuitVerse’s reach by improving our lightweight desktop application using Tauri, ensuring efficient performance across operating systems, and establishing an automated release pipeline for streamlined deployment. Participants will refactor web-based components into reusable, platform-agnostic units suitable for both web and desktop environments, optimizing resource usage for desktop contexts. A reliable update mechanism will be implemented to deliver future improvements seamlessly. The project also entails modernizing the frontend by converting the JavaScript codebase to TypeScript, replacing jQuery with Vue’s reactivity system, and addressing issues in the Verilog module and layout rendering. Enhancements to the TestBench will improve usability and output compatibility, supported by thorough testing with Vitest. Synchronization with the main CircuitVerse repository will ensure consistency across platforms.
      Learning Path:
      Gain expertise in VueJS via the Vue.js Official Guide for reactive frontend development.
      Study TypeScript fundamentals at TypeScript Documentation to facilitate codebase migration.
      Learn Tauri application development through its Official Docs.
      Prepare for testing with Vitest Documentation covering unit, integration, and end-to-end tests.
      Possible Mentors: Vedant Jain, Aryann Dwivedi, Niladri Adhikary

      ~~~~~~~~~~
      Project 3: Migrate to View Components & Improve Search Experience
      Duration: 175 hours
      Difficulty: Easy
      Technologies: HTML, CSS, JavaScript, Figma, Ruby on Rails
      This project focuses on modernizing CircuitVerse’s technical foundation and enhancing the user experience. Participants will migrate UI elements to ViewComponents for better maintainability and scalability. Responsive design principles will be applied to ensure compatibility across devices. Candidates will also utilize Figma to design and implement UI improvements while refactoring CSS to reduce redundancy and effectively use grid and flexbox with Bootstrap utility classes.
      Additionally, the project includes an initiative to improve the search experience within CircuitVerse. This will involve analyzing existing search functionality, optimizing query performance, and enhancing the UI/UX to make search results more intuitive and accessible.
      Learning Path:
      Build foundational skills in HTML, CSS, and JavaScript with FreeCodeCamp’s Responsive Web Design.
      Learn UI/UX design with Figma through Figma’s Official Tutorials.
      Study Rails ViewComponents at ViewComponent Docs and Hotwire via Hotwire Docs.
      Possible Mentors: Aman Asrani, Siddhant-K-code

      ~~~~~~~~~~
      Project 4: Assignment Suite Enhancement
      Duration: 175 hours
      Difficulty: Easy
      Technologies: Ruby on Rails, JavaScript
      This project seeks to advance CircuitVerse’s educational tools by enhancing classroom and assignment management capabilities. The scope includes developing a multi-level classroom structure, allowing students to form subgroups for collaborative projects, and creating a flexible assignment management system for both individual and group submissions. Participants will introduce features such as pre-built circuit submissions with integrated test cases, incorporate auto-verification from practice sessions, and refine the assignment submission process for efficiency. Integration with Canvas LMS will be improved to strengthen CircuitVerse’s utility in academic settings, supporting educators and students with robust, user-friendly tools.
      Learning Path:
      Develop Rails proficiency with The Odin Project’s Ruby on Rails Course.
      Enhance JavaScript knowledge at MDN Web Docs for dynamic functionality.
      Review Canvas LMS integration through its Developer Docs.
      Learning tools interoperability (LTI)[https://en.wikipedia.org/wiki/Learning_Tools_Interoperability]
      Possible Mentors: Aman Asrani, Siddharth Asthana, Yashika Jotwani

      ~~~~~~~~~~
      Project 5: Enhanced Verilog Support & Stability
      Duration: 175 hours
      Difficulty: Hard
      Technologies: JavaScript, Canvas
      This project targets the enhancement of CircuitVerse’s Verilog module and overall simulator stability. The goal is to refine the Verilog interface, making it more intuitive and enabling users to generate, view, edit, and test circuits comprehensively. Detailed documentation will accompany these improvements to assist users. Additional enhancements include adding play/pause functionality to simulations, implementing a full-screen view for the Boolean Logic Table This project requires a strong focus on technical precision to strengthen a critical component of the platform.
      Learning Path:
      Master JavaScript for simulation logic with Eloquent JavaScript.
      Learn Canvas rendering techniques at MDN Canvas Tutorial.
      Possible Mentors: Vedant Jain, Niladri Adhikary, Josh Varga

      ~~~~~~~~~~
      Project 6: Open Hardware Component Library
      Duration: 90 hours
      Difficulty: Hard
      Technologies: JavaScript, Ruby on Rails
      This project aims to expand CircuitVerse’s digital component library and introduce hardware integration capabilities. Participants will enrich the platform by adding components such as shift registers, sensors, and counters, broadening its appeal to hardware-focused users. The initiative also involves enabling serial device connectivity to facilitate interaction with physical hardware. Though shorter in duration, this project demands a high level of technical skill and innovation to advance CircuitVerse’s utility in hardware education.
      Learning Path:
      Strengthen Rails knowledge with Rails Guides.
      Study hardware integration concepts via Arduino Tutorials.
      Deepen JavaScript proficiency at You Don’t Know JS.
      Possible Mentors: Smriti Garg
      ~~~~~~~~~~
      Project 7: Flutter Upgrade
      Duration: 90 hours
      Difficulty: Easy
      Technologies: Dart, JavaScript
      This project focuses on updating the CircuitVerse mobile application to ensure compatibility with the latest Flutter framework. Participants will upgrade the app to the current Flutter version, optimizing its performance, and implement circuit embedding functionality to enhance mobile usability. This concise project offers an opportunity to contribute to the platform’s mobile presence with a focus on modern development practices.
      Learning Path:
      Learn Flutter development at Flutter Official Docs.
      Study Dart essentials with the Dart Language Tour.
      Review JavaScript fundamentals at MDN JavaScript Guide.
      

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/circuitverse.org/
    idea_list_url: https://github.com/CircuitVerse/CircuitVerse/wiki/GSoC'25-Project-List


  - organization_id: 26
    organization_name: CloudCV
    no_of_ideas: 3
    ideas_content: |
     
      
      Enhanced Test Suite and Improved User Experience
      SQL Django AngularJS AWS
      This project is focused on significantly improving EvalAI’s usability by enhancing exsiting comprehensive test suite alongside a series of user experience enhancements. By increasing our test coverage, automating critical workflows, and refining the platform’s interface and documentation, this initiative aims to create a more robust, user-friendly, and resilient environment for both challenge hosts and participants.
      The enhanced test suite will ensure that all core functionalities, from challenge creation to submission processing are verified, reducing bugs and increasing system reliability. In parallel, targeted user experience improvements will simplify navigation, enhance error reporting, and streamline user interactions, leading to a more intuitive and supportive EvalAI ecosystem.
      Project Size: Medium (175 hours)
      Difficulty Rating: Medium
      Participate in the issue corresponding to this project to get started
      Enhanced Test Suite and Improved User Experience together with gautamjajoo Yes, let's do it

      ~~~~~~~~~~
      Mitigating Biases & Prompt Effects in Vision-Language Models
      Python PyTorch/TensorFlow NLP Vision-Language Models LLMs Bias and Fairness in AI
      This research project aims to investigate how prompt engineering influences the behaviour and outputs of Vision-Language Models (VLLMs), with a particular focus on the emergence and amplification of biases. By systematically studying the relationship between prompt formulations and model responses, the project seeks to uncover the mechanisms through which biases are introduced and propose effective mitigation strategies.
      Project Size: Medium (175 hours)
      Difficulty Rating: Medium to Advanced
      Sorry but currently we don't have any mentoring project ...

      ~~~~~~~~~~
      RAG-Based Chat Bot for Enhanced Challenge Support
      Python Natural Language Processing (NLP) Machine Learning Retrieval Augmented Generation (RAG) Django SQL
      This project aims to enhance the user experience for both challenge hosts and participants by developing an intelligent, RAG (Retrieval Augmented Generation) based chatbot. The chatbot will efficiently address queries related to challenge hosting, guidelines, troubleshooting, and FAQs. By integrating state-of-the-art NLP techniques with robust retrieval mechanisms, the solution will ensure prompt, accurate, and context-aware responses that reduce support overhead and streamline communication.
      Using the RAG approach, the chatbot will retrieve relevant information from challenge documentation and combine it with generative models to create coherent and helpful answers. This will empower hosts to manage challenges more effectively and assist participants in resolving queries, ultimately contributing to a smoother and more interactive challenge experience.
      Project Size: Medium (175 hours)
      Difficulty Rating: Medium
      Participate in the issue corresponding to this project to get started
      RAG-Based Chat Bot for Enhanced Challenge Support together with gautamjajoo Yes, let's do it
      

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/cloudcv/
    idea_list_url: https://gsoc.cloudcv.org/


  - organization_id: 27
    organization_name: D Language Foundation
    no_of_ideas: 4
    ideas_content: |
      Translate DRuntime Hooks to Templates
      Mentor: Teodor Duțu

      Spec	Details
      Difficulty Level	hard
      Project Duration	350 hours
      Number of Contributors	2
      Prerequisites	Familiarity with compilers, build systems; low-level programming
      Description
      High-level language constructs are often compiled into lower-level function calls that implement the same functionality. This process is called lowering It simplifies compiler design by offloading complex code into simpler function calls. These functions are implemented in D’s runtime library (called DRuntime) and are commonly called runtime hooks.

      Below is an example of such a runtime hook:

      struct S { ... }

      S[3] a, b;

      // Original code
      b = a;  // b is a copy of a 

      // Resulting DRuntime hook
      _d_arrayassign_l(b, a)  // copies a into b

      _d_arrayassign_l handles array (re)allocation and assignment operators according to the types of a and b (S[3]) to simplify the compiler’s work.

      As shown in the example above, runtime hooks require type information, such as which assignment operator to call and the arrays’ sizes. D supports templates, but runtime hooks pre-date the introduction of templates to D. Therefore, they retrieve the necessary type information at runtime by receiving an extra argument, whose type is TypeInfo. This object contains the size, constructors, destructors and overloaded operators of a given type. However, because this information is processed at run time, this approach is slower than the alternative of having the compiler send it to the runtime hook via template arguments. Due to D’s high flexibility regarding metaprogramming, translating each hook to a template function would allow its code to specialise according to the types of its arguments at compile time.

      In general, these are the steps required to convert a runtime hook to a template:

      Implement a new template version of the hook in DRuntime.
      Change the lowering in the compiler to use the new hook.
      Run a benchmark to measure the increase in performance generated by using the new hook.
      Remove the old hook from DRuntime.
      The hooks that are yet to be templated can be split into 2 categories:

      rt/aa.d implements associative arrays as language builtins. This module is made up of multiple hooks, all of them using TypeInfo. Therefore, this module is to be reimplemented using templates. Associative arrays are defined as an opaque structure called Impl. It receives a TypeInfo argument in its constructor. This structure is accessed via the runtime hooks listed below. The plan for this direction is the following:
      Template the hooks below and temporarily extract the TypeInfo structure required by Impl from the template arguments using typeid. Each hook will require changes to DRuntime and the compiler.
      Template the Impl structure and modify the previously templated hooks to use the template arguments itself instead of TypeInfo.
      The list of hooks for associative arrays is:

      _aaApply
      _aaApply2
      _aaDelX
      _aaEqual
      _aaGetRvalueX
      _aaGetX
      _aaInX
      _aaLen
      _d_assocarrayliteralTX

      Somewhat more independent hooks, which still have interdependencies. They are mostly implemented in rt/lifetime.d. A goal of this project is to remove this file and replace all its code with templated implementations. Each hook can be handled individually and separately. There was previous work on _d_arrayliteralTX so it might be a good starting point. Another promising starting point are _d_arrayset{capacity,lengthT,lengthiT} or _d_arrayappendcTX. The latter three already have wrapper template hooks that call the functions from rt/lifetime.d. What is needed in their case is to fully move the underlying implementation to the template hooks. The full list of hooks is below:

      _d_arraysetcapacity
      _d_arraysetlengthiT
      _d_arraysetlengthT
      _d_arrayshrinkfit
      _d_arrayappendcTX
      _d_arrayliteralTX
      _d_interface_cast
      _d_isbaseof
      _d_isbaseof2
      _adEq2

      Resources
      Initial project proposal and discussion
      PRs converting some of the DRuntime hooks to templates
      Weekly reports regarding the earlier work
      DConf presentations from 2022 and 2024 on the work on DRuntime hooks
      Instructions on how to build the reference compiler - DMD

      ~~~~~~~~~~

      Separate Semantic Routines From AST Nodes
      Mentor: Razvan Nitu

      Spec	Details
      Difficulty Level	easy-medium
      Project Duration	175 hours
      Number of Contributors	1
      Prerequisites	Familiarity with compiler organization, visitor pattern, object oriented programming
      Description
      In the DMD compiler codebase, AST nodes are defined as classes within various files. The ideal structure for these nodes is to have minimal fields and methods focused solely on field queries. However, the current state of the DMD frontend deviates from this ideal. AST nodes are laden with numerous methods that either perform or are dependent on semantic analysis. Furthermore, many AST node files contain free functions related to semantic analysis. Our objective is to decouple AST nodes from these functions.

      How to start working on this project
      Clone the compile repository - check this guideline.
      Choose an AST node file: start by selecting a file from this list of AST node definition files.
      Examine Imports: open your chosen file and scrutinize the top-level imports.
      Isolate semantic imports: temporarily comment out one of the imports that includes semantic routines, particularly those ending in sem (e.g., dsymbolsem, expressionsem, etc.).
      Build and identify dependencies: compile DMD and observe any unresolved symbols that emerge.
      Relocate functions: shift the functions reliant on the unresolved symbols to the semantic file where the import was commented out.
      Move and test a function: select a function for relocation and ensure it functions correctly in its new location.
      Submit a Pull Request: Once you’re satisfied with the changes, create a PR that follows the guidelines.
      Check this PR for an illustration of the above steps.

      Sometimes, more intricate solutions are required. For instance, if an overridden method in an AST node calls a semantic function, it can’t be simply relocated. In these cases, using a visitor to collate all overrides, along with the original method, into the appropriate semantic file is the way forward. A notable instance of this approach is detailed in this pull request.

      Other complex scenarios may arise, especially when dealing with AST nodes that interact with the backend. Finding solutions to those will be the fun part of the project.

      This project helps advance the development of the compiler library by creating a clear separation between compilation phases.

      This project is ideal for someone that has no prior experience with real-life compilers but wants to start by doing valuable work.

      Resources
      Compiler codebase
      List of files that need to have semantic separated out of them
      How to start
      Building the compiler

      ~~~~~~~~~~

      Performance Regression Publisher
      Mentor: Dennis Korpel

      Spec	Details
      Difficulty Level	easy-medium
      Project Duration	175 hours
      Number of Contributors	1
      Prerequisites	Github actions, webdev, performance testing
      Description
      The D compiler currently does not have an automated performance regression test. Oftentimes pull requests that claim to improve compiler performance are being made (be it spatial or temporal). However, it’s up to the reviewer to actually believe the committer or to test things on their own. To make things simpler and more transparent, we want to implement a bot that monitors all the pull requests made to the compiler codebase and analyzes the compiler’s performance with and without the pull request.

      The list of stats should include, but not be limited to:

      size of some predefined binaries (like a “hello world” program)
      compile time of popular projects
      compiler size
      runtime of test suite
      Adding more performance tests, such as stress tests also falls under the scope of this project. Ideally the bot could also store a history of performance regressions within a web page.

      Project milestones:
      Analyze the best way to publish the results: it could be a GitHub action, a bot that sends data to a website. Depending on your skills and preferences, we expect you propose something and toghether we will decide what’s best.
      Implement the initial part that simply collects how long running the testing pipeline took and publishes the result.
      Decide on other metrics that need to be collected and implement them.
      Add more stress tests to the compiler testing suite.
      Resources
      Compiler pull request queue

      ~~~~~~~~~~
      Json Library
      Mentor: Adam Wilson

      Spec	Details
      Difficulty Level	medium
      Project Duration	175 hours
      Number of Contributors	1
      Prerequisites	json, parsers, object oriented programming
      Description
      D currently does not have a json parser integrated in the standard library and it is the year 2025. There are 3rd party libraries that implement some pieces to a certain extent, however they are not at industry level requirements. The purpose of this project is to create a json library that offers all the facilities required for working with json objects. The goal is to eventually integrate it in the standard library, however, an initial step is to publish as a dub (D package manager) package.

      Although there is no json library in the D ecosystem, there are multiple json parser implementations. We can start by picking up a notable json parser as a basis for our implementation. Next, we can built higher level functionalities on top of the existing parser.

      This project is of high priority and impact, as json objects essentially rule the world.

      Project Milestones
      Initial Package Setup and Porting from jsoniopipe.
      Object Model Design/Implementation.
      Object Model Serialization/Deserialization
      Streaming Serialization/Deserialization
      Stretch Goal: Object Serialization/Deserialization (Direct serialization/deserialization from a D object instead of using the object model.)
      Resources
      jsoniopipe

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/d-language-foundation/
    idea_list_url: https://dlang.github.io/GSoC/gsoc-2025/project-ideas.html


  - organization_id: 28
    organization_name: DBpedia
    no_of_ideas: 5
    ideas_content: |
      Towards Amharic DBpedia
      Description
      DBpedia is a collaborative initiative focused on extracting structured information from Wikipedia and presenting it as Linked Open Data. This is a continuation of GSoC 2024. In GSoC 2024, we successfully integrated Amharic parsers and extractors into the DBpedia chapter. However, due to time constraints, we could not add sufficient mappings to extract data from Wikipedia. This year, we plan to add more new mappings, build a robust landing page for presentation, and clean the existing data.

      Goal
      The primary goal of this project is to enhance the Amharic DBpedia chapter 3:

      Extend the existing Amharic DBpedia chapter in the DBpedia knowledge graph with data from Amharic Wikipedia.
      Add additional mappings.
      Extend the DBpedia extraction framework to extract citations, disambiguation, personal data, topical concepts, anchor text, and shared resources from Amharic Wikipedia.
      Create an automatic extraction framework and mapping.
      Make the knowledge graph available to end users via a web page.
      Create documentation for processes, tools, and techniques used for sustainable development, following FAIR principles.
      Impact
      Enable users to access and utilize structured data in Amharic DBpedia more effectively.
      This will promote linguistic diversity and support research, education, and applications that rely on multilingual knowledge graphs.
      NLP downstream tasks: Apply knowledge graphs from DBpedia to NLP applications such as machine translation and sentiment analysis.
      Community engagement: Encourage the community to contribute and collaborate in sustaining and expanding Amharic DBpedia.
      Warm-up tasks
      Please read the following papers:
      GitHub Repository 6

      Amharic Wikipedia 1
      Arabic DBpedia 1
      Korean DBpedia
      German DBpedia 1
      Skills Required
      A good understanding of Java and Python
      Optionally, good knowledge of SPARQL, RDF, and other Semantic Web technologies
      Good documentation and communication skills
      Project Size
      350 hours

      Mentors
      Hizkiel Alemayehu 3

      Tilahun Tafa 2

      Ricardo Usbeck 1

      Keywords
      Amharic DBpedia, Semantic Web, Extraction Framework

      ~~~~~~~~~~

      DBpedia Hindi Chapter - GSoC 2025

      DBpedia is an open knowledge graph in continuous evolution. Unlike Wikidata, where the RDF content is directly edited as a wiki, DBpedia relies strictly on Wikipedia, meaning that every single triple in DBpedia — except for ontology statements — can be traced back to some infobox, sentence or table cell in Wikipedia.

      The graph exposed at the root domain of DBpedia is derived solely from English Wikipedia (e.g. https://dbpedia.org/page/India 4). Purpose of this project is to create a graph derived solely from Hindi Wikipedia. Methods to generate triples rely on the Extraction Framework 15 6 for infobox extraction or through novel NLP-based approaches such as the Neural Extraction Framework 2. Unfortunately, the latter approach only supports the English language. We thus welcome NLP and/or LLM-based solutions to target multilingual text. We have proposed the first edition on DBpedia Hindi Chapter in 2024 GSoC proposal for Configuring different extractors for hindi in DBpedia extraction framework and included a neural pipeline for extracting tuples directly from hindi wiki. In this proposal we are extending the first edition of DBpedia Hindi Chapter with extended goals.

      Goal
      Extending the DBpedia Chapter in Hindi language to be reached at hi.dbpedia.org 4. In particular:

      Create the knowledge graph with data from Hindi Wikipedia 6by including more indic neural extractor. It aims for extracting information in the form of relational triples(subject → predicate → object) from unstructured text in hindi Wikipedia articles that can be added to the DBpedia knowledge base
      Automating the knowledge graph with the availability of new LLMs by creating Indic embeddings, so that missing links can be generated automatically.
      Create a SPARQL endpoint to make it queryable.
      Material
      See Warm-up tasks.

      Project size
      This project is medium-sized (175 hours).

      Impact
      Cultural and Educational Enrichment: Empower Hindi-speaking users with culturally relevant and easily accessible knowledge, fostering educational enrichment and linguistic inclusivity.
      Semantic Search and NLP Applications: Enable advanced semantic search and natural language processing (NLP) applications in Hindi, opening avenues for innovation in information retrieval and analysis.
      Community Engagement: Encourage community contributions, feedback, and collaboration in maintaining and expanding the Hindi ontology, ensuring continuous improvement and relevance.
      In summary, this project seeks to contribute significantly to linguistic diversity in the semantic web domain by extending the DBpedia ontology to Hindi, promoting a more inclusive and accessible knowledge landscape
      for Hindi-speaking users.

      Warm-up tasks
      Please read carefully our overview on creating new DBpedia Chapters 11.
      Read the paper Internationalization of Linked Data: The case of the Greek DBpedia edition 7 by Kontokostas et al.
      Learn about the DBpedia Extraction Framework 6, the software used to transform Wikipedia infobox data into RDF triples.
      Check the mapping in Hindi of the DBpedia ontology 8 and Indic embeddings.
      Go through the list of current chapters can be found at this address 7 to get an idea of how they are structured.
      Get familiar with SPARQL on the DBpedia endpoint 7.
      Run a local DBpedia Virtuoso endpoint 5.
      Mentors
      Sanju Tiwari (@tiwarisanju18), Debarghya Dutta, Ananya, Ronak Panchal


      ~~~~~~~~~~

      This project started in 2021 and is looking to its 5th participation in DBpedia’s GSoC.

      Description
      Every Wikipedia article links to a number of other articles. In DBpedia, we keep track of these links through the dbo:wikiPageWikiLink property. Thanks to them, we know that the :Berlin_Wall 3 entity (at the time of writing this) is semantically connected to 299 base entities.

      However, only 9 out of 299 base entities are linked from :Berlin_Wall via also another predicate. This suggests that in the large majority of cases, it is not clear what kind of relationship exists between the entities. In other words, DBpedia does not know what specific RDF predicate links the subject (in our case, :Berlin_Wall) to any of the objects above.

      Currently, such relationships are extracted from tables and the infobox (usually found top right of a Wikipedia article) via the Extraction Framework 4. Instead of extracting RDF triples from semi-structured data only, we want to leverage information found in the entirety of a Wikipedia article, including page text.

      wiki-meme
      wiki-meme
      500×683 108 KB
      The repository where all source code will be stored is the following:


      GitHub

      GitHub - dbpedia/neural-extraction-framework: Repository for the GSoC project... 32
      Repository for the GSoC project 'Towards a Neural Extraction Framework' - dbpedia/neural-extraction-framework

      Goal
      The goal of this project is to develop a framework for predicate resolution of wiki links among entities.

      During GSoC 2022, we employed a suite of machine-learning models 7 to perform joint entity-relation extraction on open-domain text.
      During GSoC 2023, we implemented an end-to-end system 4 that translates any English sentence into triples using the DBpedia vocabulary.
      Last year, we improved the quality of output triples using a chain-of-thought approach powered by a large language model.
      However, the current algorithm still has the following issues. Now, we want to devise a method that can solve as many of them as possible.

      When an RDF property representing the predicate is not found, our algorithm cannot make any suggestions for the creation of a new property.
      The current models are not efficient enough to scale to millions of entities.
      The extracted relations are not categorised with respect to their semantics (e.g. reflexive/irreflexive, symmetric/antisymmetric/asymmetric, transitive, equivalence).
      The generated triples were not validated against the DBpedia ontology and may thus lead to inconsistencies in data.
      Our algorithm should be able to adapt its output not only to the DBpedia vocabulary but to any specified one (e.g., SKOS, schema.org, Wikidata, RDFS, or even a combination of many).
      Extraction examples
      The current pipeline targets relationships that are explicitly mentioned in the text. The contributor may also choose to extract complex relationships, such as:

      Causality. (Addressed during GSoC 2021, but not completed.) The direct cause-effect between events, e.g., from the text
      The Peaceful Revolution (German: Friedliche Revolution) was the process of sociopolitical change that led to the opening of East Germany’s borders with the west, the end of the Socialist Unity Party of Germany (SED) in the German Democratic Republic (GDR or East Germany) and the transition to a parliamentary democracy, which enabled the reunification of Germany in October 1990.

      extract: :Peaceful_Revolution –––dbo:effect––> :German_reunification

      Issuance. An abstract entity assigned to some agent, e.g., from the text
      Messi won the award, his second consecutive Ballon d’Or victory.

      extract: :2010_FIFA_Ballon_d'Or –––dbo:recipient––> :Lionel_Messi 1

      Material
      The contributor may use any Python deep learning framework and/or existing tool. The following resources are recommended (but not compulsory) for use in the project.

      The project repository linked above and the machine-learning models mentioned in the readme files found in each GSoC folder.
      Last year’s 9 and the 2023 blog 4 to understand the project status quo.
      Python Wikipedia 1 makes it easy to access and parse data from Wikipedia.
      Huggingface Transformers for Natural Language Inference 1 can be extremely useful to extract structured knowledge from text or perform zero-shot classification.
      DBpedia Lookup is a service available both online and offline (e.g., given a string, list all entities that may refer to it).
      DBpedia Anchor text is a dataset containing the text and the URL of all links in Wikipedia; the indexed dataset will be available to the student (e.g., given an entity, list all strings that point to it).
      An example of an excellent proposal 11 that was accepted a few years ago.
      Project size
      The size of this project can be either medium or large. Please state in your proposal the number of total project hours you intend to dedicate to it (175 or 350).

      Impact
      This project will potentially generate millions of new statements. This new information could be released by DBpedia to the public as part of a new dataset. The creation of a neural extraction framework could introduce the use of robust parsers for a more accurate extraction of Wikipedia content.

      Warm-up tasks
      Get familiar with SPARQL on the DBpedia endpoint 8.
      Understand the science behind relation extraction 4.
      Run and understand the pipeline implemented last year 8.
      Mentors
      @tsoru, @zoelevert, TBD

      ~~~~~~~~~~

      Containerized Installers for Data-centric Services using Databus Collections
      Project Description:
      This GSoC project aims to develop containerized installers for data-centric services utilizing Databus collections. Databus collections provide a framework for managing and sharing datasets across distributed systems, offering versioning, replication, and access control features.

      One exemplary application of this project is integrating Databus collections with the Virtuoso Open-Source triple store, a widely used RDF service. This integration enables seamless deployment and loading of RDF datasets into Virtuoso instances within containerized environments.

      Additionally, the project entails both designing and documenting best practices for deploying other Databus-driven services, along with implementing more deployment-ready containers. These containers will encapsulate the necessary components for pulling data from Databus collections and installing them with associated services, ensuring ease of deployment and scalability.

      Furthermore, the project may explore integration options with the Databus frontend or even metadata, enhancing discoverability and interoperability of the deployed services within the Databus ecosystem.

      Key Objectives:
      Integrate Databus collections with the Virtuoso Open-Source Triple Store as a first use case. This can be done by building upon the Virtuoso Quickstarter repository (GitHub - dbpedia/virtuoso-sparql-endpoint-quickstart: creates a docker image with Virtuoso preloaded with the latest DBpedia dataset)

      Design and document best practices for deploying Databus-driven services.

      Implement 4-5 deployment-ready containers for data-centric services utilizing Databus collections. Services could, for instance, be chosen from a list of Semantic Web applications and services here: GitHub - semantalytics/awesome-semantic-web: A curated list of various semantic web and linked data resources.

      Explore integration possibilities with the Databus frontend or metadata systems for enhanced functionality and interoperability.

      Expected Outcome:
      A well-documented Databus-driven Virtuoso Quickstarter container that focuses on ease of deployment.

      Documentation outlining best practices and guidelines for implementing, deploying and managing Databus-driven services.

      4-5 Containerized installers for deploying data-centric services leveraging Databus collections.

      Design proposal for integration of these services with the Databus frontend.

      [Optional] integration with Databus frontend or even metadata for improved discoverability and usability.

      Skills Required:
      A good understanding of SPARQL, RDF and other Semantic Web technologies

      Some proficiency in containerization technologies (e.g., Docker, Kubernetes).

      Knowledge of the core concepts of the DBpedia Databus (see Overview | Databus Gitbook 4)

      Good documentation and communication skills

      Project Size:
      Estimated anywhere between 90 to 180 hours, depending on expertise and number of tackled tasks.

      ~~~~~~~~~~

      Automatically adding Wikimedia Dumps on the Databus — GSoC 2025


      Project Description:
      Wikimedia publishes their dumps via https://dumps.wikimedia.org 6 . At the moment, these dumps are described via HTML, so the HTML serves as the metadata and it is required to parse to identify whether new dumps are available. To automate retrieval of data, the Databus (and also MOSS as its extension Databus and MOSS – Search over a flexible, multi-domain, multi-repository metadata catalog 5 ) has a metadata knowledge graph, where one can do queries like “check whether a new version of x is available”. Since DBpedia uses the dumps to create knowledge graphs, it would be good to put the download links for the dumps and the metadata on the Databus.

      Key Objectives

      Build a docker image that we can run daily on our infrastructure to crawl dumps.wikimedia.org 3 and identify all new finished dumps, then add a new record on the Databus.
      Goal is to allow checking for new dumps via SPARQL. go to OIDC Form_Post Response 2 , then example queries, then “Latest version of artifact”.
      this would help us to 1. track new releases from wikimedia, so the core team and the community can more systematically convert them to RDF as well as to 2. build more solid applications on top, i.e. DIEF or other
      process wise I would think that having an early prototype is necessary and then plan iterations from this.
      Skills
      The task is not very complex per se, but requires some experience in executing a software project. This includes a clean project setup, good code, tests and also a simple, but well-thought out process. (simple because it will be more robust and maintainable than sth. complicated). We would prefer coding in scala, but python or other would also be ok. Some devOp skills are required to produce good docker (swarm), but they can be learned during the project as well.

      Size
      120 to 180 hours to do it properly. I would estimate that the final deployment also takes a week to make it effective and thoroughly evaluate that the final result is working well.









          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/dbpedia/
    idea_list_url: https://forum.dbpedia.org/tag/gsoc2025-ideas

  

  - organization_id: 29
    organization_name: Dart
    no_of_ideas: 5
    ideas_content: |
      
      Idea: Exception testing for package:webcrypto
      Possible Mentor(s): jonasfj@google.com,
      Difficulty: Hard
      Project size: Large (350 hours)
      Skills: Dart, FFI, JS
      Description: package:webcrypto (github.com/google/webcrypto.dart) is a cross-platform implementation of the Web Cryptography API. It is important that it behaves the same way whether it's running on Windows, Linux, Mac, Android, iOS, Chrome, Firefox, or Safari. Towards that end, it has a lot of test cases. We could and should probably make more test cases. But we should also test that it throws the types of exceptions when given incorrect parameters. This probably needs a small test framework to ensure good test coverage.
      We expect a proposal for this project to include:
      A sample showing how to test exceptions for RsaPssPrivateKey.generateKey. Ideally, the sample project includes parts of a generalized framework for testing exceptions.
      An outline of what kind of exceptions should be tested?
      A design for extending TestRunner, or creating a new framework, to test exceptions thrown by all methods.
      Illustrative code for how test cases would be configured
      Pros and cons of the design (especially when multiple choices are available)
      Timeline for the project
      Good Sample Project: Write a test cases that tests the different kinds of errors and exceptions that can be thrown by RsaPssPrivateKey.generateKey, run the tests across desktop, Chrome and Firefox. Consider extending the tests to cover all members of RsaPssPrivateKey. Try to generalize these test cases to avoid repetitive code, see the existing TestRunner for inspiration.
      Expected outcome: PRs that land in package:webcrypto and increases our confidence in correctness cross-platforms.
      
      
      ~~~~~~~~~~
      Idea: Use an LLM to translate Java/Kotlin tutorial snippets into Dart JNIgen code
      Possible Mentor(s): dacoharkes@google.com, yousefi@google.com
      Difficulty: Hard
      Project size: Large (350 hours)
      Skills: Dart, FFI, Java
      Description: This project will be very exploratory. We’ll explore how much is needed to make an LLM generate Dart snippets that call JNIgen-generated code. The snippets should be the equivalent of the original native code. How much will be needed? Is a single shot prompt enough? Or do we need to teach an AI how to run JNIgen and make it generate code that is subsequently analyzed with the Dart analyzer and the errors are fed back in to the AI to improve its answer.
      If we get this working, we’ll want to explore how to make such a tool useful to users. For example, we could make a browser extension that automatically adds the generated code snippets to documentation websites.
      Inspired by this issue: dart-lang/native#1240
      Good Sample Project:
      Get a Gemini API key https://ai.google.dev/gemini-api/docs/api-key
      Follow https://developers.google.com/learn/pathways/solution-ai-gemini-getting-started-dart-flutter
      Write a Dart script that invokes the API with a prompt containing a Java snippet (for example from https://developer.android.com/media/camera/camerax/take-photo#take_a_picture) and try to come up with a prompt that will make it generate code that would work on the Dart API generated with JNIgen for this Java/Kotlin API.
      Expected outcome: A tool for translating code samples usable by users.
      
      
      ~~~~~~~~~~
      Idea: package:coverage + LLM = test generation
      Possible Mentor(s): liama@google.com
      Difficulty: Medium
      Project size: Medium (175 hours)
      Skills: Dart, LLMs
      Description: This is a very experimental project. The idea is to use package:coverage to identify uncovered code, use an LLM to decide if that code needs a test (not all code actually needs to be tested), then use an LLM to write tests that hit those cases, and then use package:coverage to verify that those lines are covered.
      Good Sample Project:
      Get a Gemini API key https://ai.google.dev/gemini-api/docs/api-key
      Follow https://developers.google.com/learn/pathways/solution-ai-gemini-getting-started-dart-flutter
      Try generating tests for any old Dart API. Don't try to integrate package:coverage yet.
      Expected outcome: A package on pub.dev for increasing test coverage.
      
      
      ~~~~~~~~~~
      Idea: Secure Paste Custom Actions on iOS
      Possible Mentor(s): huanlin@google.com, jmccandless@google.com
      Difficulty: Hard
      Project size: Large (350 hours)
      Skills: Dart, Objective-C
      Description: Support custom action items for native edit menu on iOS. It's a pretty impactful project requested by many developers (main issue here: flutter/flutter#103163). This project is one of the key milestones: flutter/flutter#140184.
      Project:
      Prepare: Learn basic git commands; Setup flutter engine dev environment; Read style guide, etc;
      Design new dart API for custom items in context menu (Related API: https://api.flutter.dev/flutter/widgets/SystemContextMenu-class.html)
      Design engine <-> framework communication API using method channel
      Implement both framework part (in Dart) and engine part (in Objective-C)
      Go through code review process and land the solution
      The final product should allow developers to add custom items to the iOS native edit menu.
      Good Sample Project: ...
      Build a sample project in Flutter with a text field that shows custom actions in the context menu. (Hint: use https://docs.flutter.dev/release/breaking-changes/context-menus).
      Build a sample project in UIKit that shows custom actions in the native edit menu (Hint: use https://developer.apple.com/documentation/uikit/uieditmenuinteraction?language=objc). You can either use ObjC or Swift, but ObjC is preferred.
      Expected outcome: A PR merged in Flutter
      
      
      ~~~~~~~~~~
      Idea: TUI framework for dart
      Possible Mentor(s): mudit.somani00@gmail.com
      Difficulty: Medium
      Project size: Medium (175 hours)
      Skills: Dart, CLIs
      Description: Dart is already used to create GUI applications through Flutter, it would be great if it can also be used to develop good looking TUI applications. Currently the language of choice for TUI development would be either Golang or Python due to their developed package ecosystems (like charm or textual) so a package that makes TUI development easier and faster on dart would increase its adoption in that space.
      Project:
      Design composable methods to render components and text on the terminal
      Include popular components like inputs, checkboxes and tables by default
      Intuitive way to create your own custom components for the terminal
      Ensure library works with popular state management libraries in dart
      Good Sample Project:
      Composable methods to style text on the terminal (kinda like libgloss).
      Component based model to render and interact with terminal based text inputs and checkboxes (kinda like bubbles).
      Expected outcome: A package on pub.dev with terminal primitives like text styling, inputs, checkboxes, tables, layouts, spinners etc.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/dart/
    idea_list_url: https://github.com/dart-lang/sdk/blob/main/docs/gsoc/Dart-GSoC-2025-Project-Ideas.md


  - organization_id: 30
    organization_name: Data for the Common Good
    no_of_ideas: 9
    ideas_content: |
      
      Title Enhancing the SMART on FHIR Backend for Patient-Controlled Data Sharing
      Description The goal of this project is to improve and extend the backend of a SMART on FHIR application that empowers patients to autonomously access, share, and manage their electronic health records (EHR). The application serves as a data interoperability layer, allowing users to seamlessly transfer their healthcare data to meet various needs, such as research participation, second opinions, or personal health tracking.
      Expected Outcomes One or both of the following: Improving the integration with diverse FHIR servers and refining data transformation capabilities. Building APIs or plugins to support additional healthcare applications and third-party services.
      Skills Java, python
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating medium


      ~~~~~~~~~~
     
      Title Enhancing the SMART on FHIR Frontend for Patient-Controlled Data Sharing
      Description This project aims to improve the frontend user interface for a SMART on FHIR application that enables patients to autonomously access, manage, and share their electronic health records (EHR). The focus is on making the UI more intuitive, accessible, and user-friendly, ensuring a seamless experience for users connecting to the backend service.
      Expected Outcomes Improved User Experience (UX)
      Skills Javascript, Node
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating medium

      ~~~~~~~~~~
     
      Title Developing a FHIR Resource Tabular Viewer for Efficient Data Exploration
      Description This project aims to build a FHIR Resource Tabular Viewer, an application that transforms complex, nested FHIR data structures into an easy-to-navigate tabular format. This tool will allow users—such as researchers, clinicians, and developers—to efficiently search, filter, and analyze FHIR resources, improving accessibility and usability of healthcare data.
      Expected Outcomes Tabular Representation of FHIR Data and Search & Filtering Capabilities.
      Skills Python, Javascript
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating medium

      ~~~~~~~~~~
     
      Title Developing Custom Jupyter Notebooks for AVRO File Processing and QA/QC Analysis
      Description This project aims to create custom Jupyter notebooks that help users efficiently unpack AVRO files, perform quality assurance (QA) and quality control (QC) checks, and run basic data analyses. The goal is to provide a user-friendly, interactive environment where users can explore, validate, and analyze AVRO-formatted data without requiring deep expertise in data engineering.
      Expected Outcomes AVRO File Handling on startup, QA/QC Checks, Basic Data Analysis.
      Skills Python, networking
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating medium

      ~~~~~~~~~~
     
      Title Extending the HAPI FHIR Server for Enhanced Functionality and Interoperability
      Description This project aims to extend the HAPI FHIR Server, a leading open-source implementation of the FHIR standard, to improve its functionality, scalability, and interoperability. The enhancements will support advanced healthcare use cases, making it easier for developers and organizations to manage and exchange FHIR-compliant health data efficiently.
      Expected Outcomes Custom FHIR Operations & Extensions
      Skills Java, FHIR
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating medium

      ~~~~~~~~~~
     
      Title Developing a Translation Service to Connect GEARBOx API with mCODE Trial Matching Service
      Description This project aims to build a translation service that connects the GEARBOx API with the mCODE (Minimal Common Oncology Data Elements) trial matching service. The goal is to enable seamless translation of oncology data between GEARBOx and mCODE, allowing healthcare providers, researchers, and clinical trial platforms to effectively match patients to relevant clinical trials based on their mCODE-compliant health data.
      Expected Outcomes Data Mapping & Transformation, Interoperability & Validation
      Skills Python, Typescript
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating medium

      ~~~~~~~~~~
     
      Title Building a Chatbot for Generating GraphQL and Custom Queries for Cohort Descriptions
      Description This project aims to develop a chatbot powered by ChatGPT or another large language model (LLM) that allows users to describe a cohort of patients and automatically generates GraphQL queries or custom queries based on the input for the PCDC. The goal is to simplify the process of building complex queries for patient data by allowing users to interact with the chatbot in natural language, rather than navigating through a UI or manually searching for filters.
      Expected Outcomes GraphQL Query Generation
      Skills LLM, Javascript
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating hard

      ~~~~~~~~~~
     
      Title Developing a Cross-Platform App for User Consent and Data Sharing from Apple Health and CommonHealth Using React Native
      Description This project focuses on creating a cross-platform mobile app (iOS and Android) using React Native that allows users to consent and share their health data from both Apple Health and CommonHealth. The app will enable users to manage their data sharing preferences, securely transmit health information, and empower them to participate in research or share data with healthcare providers.
      Expected Outcomes Initial App version
      Skills React Native, Android, iOS
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating hard

      ~~~~~~~~~~
     
      Title Enhancing the Cohort Discovery Chatbot
      Description This project aims to enhance a cohort discovery chatbot by improving its accuracy, usability, and query generation capabilities. Enhancements will focus on refining natural language understanding (NLU), improving query accuracy, supporting more complex filters, and integrating feedback mechanisms to learn from user interactions.
      Expected Outcomes Improved chatbot accuracy in understanding and generating cohort queries
      Skills LLM, Javascript
      Mentors TBD - One of the Senior Developer in the team.
      Project Size 350 hours
      Rating hard
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/data-for-the-common-good/
    idea_list_url: https://docs.pedscommons.org/GSoC/ideas
  

  - organization_id: 31
    organization_name: Debian
    no_of_ideas: 11
    ideas_content: |
     
 
      Quality assurance and continuous integration for biological and medical applications inside Debian
      Description of the project: The Debian Med Blend has packaged a lot of applications used in medicine and biology for Debian. To enhance and continuously ensure the quality of the packaged software we try to implement Continuous Integration tests for all our packages. This was accomplished thanks to several past interns. These tests are of specific importance since only a very small share of the developers inside the Debian Med project are actual users of the software and thus automated testing is required to provide our users with the quality we like to approach. Interns are also not necessarily comfortable with the topic of medicine and biology - reading documentation or publications or directly contact the authors of the software frequently gives sensible ideas how to write a test for the software.
      Confirmed Mentor: Andreas Tille
      How to contact the mentor: tille@debian.org
      Confirmed co-mentors: Emmanuel Arias <eamanu@debian.org>, Étienne Mollier <emollier@debian.org>
      Difficulty level: medium
      Project size: Depending from students availability this project can be medium or large. The advantage of the project is it can be split into small pieces
      Deliverables of the project:Continuous integration tests for Debian Med applications lacking a test, Quality Assurance review and bug fixing if issues might be uncovered
      Desirable skills: Background in bioinformatics, medical imaging could be an advantage, but interest in scientific software and reading relevant documentation and papers might be sufficient. Debian packaging skills are an extra plus but can be taught in the project run.
      What the intern will learn: Detailed insight into the software maintained by the Debian Med team, bug triaging in scientific software, Debian packaging skills, optimising bioinformatics and other scientific tools
      Application tasks: Pick bugs like 1035121, 1035175, 1035178, 1035182, 1035188, 1035200, 1035277, 1036500, 1036506 and try fixing it - asking the mentor for help is perfectly fine and actually recommended. This is on one hand proof that the student is able to understand Debian packaging and understands the actual topic at a sufficient level.
      Related projects: SummerOfCode2016/Projects/BioToolsTesting, SummerOfCode2017/Projects/QA_BiologyApps, ?Continuous_Integration_for_biological_applications_inside_Debian, SummerOfCode2019/ApprovedProjects/CIforDebianMed SummerOfCode2020/ApprovedProjects/DebianMedQAGSoC and Outreachy Project Proposal: Quality Assurance and Continuous integration for applications in life sciences and medicine
      [SummerOfCode2025/ApprovedProjects/DebianMedQA][edit]

      ~~~~~~~~~~
      Device-specific Tweaks Management
      Description of the project: A significant number of non-x86 Linux-capable devices made it to the market in the past few years, especially ARM64 laptops, mobile phones and tablets. Most of those, inheriting their design from embedded systems (and therefore lacking support for software interfaces such as ACPI/UEFI), need device-specific "tweaks" (configuration files/fragments, shell scripts...). As the number of supported devices grows rapidly, providing device-specific Debian packages containing those tweaks doesn't scale, and limits our ability to provide a generic system image/rootfs.
      This project aims at researching and implementing a more flexible way of managing those tweaks, by creating a service capable of identifying the exact device it's running on, selecting the appropriate tweaks based on its configuration file, and installing them to the system. Reaching this goal will ultimately ease supporting new devices in Debian.
      Confirmed Mentor: Arnaud Ferraris (UTC+2)
      How to contact the mentor: Matrix (a-wai on mobian-dev:matrix.org or email (aferraris@debian.org)
      Difficulty level: Mostly medium, although difficulty level is expected to increase over the project's course
      Project size: The whole project is a large (350 hours) one, although its scope could be reduced to fit either a 90 hours or a 175 hours project.
      Deliverables of the project:
      Analysis and discussion of the current state of device tweaks management in Debian and Mobian
      Proposal for a unified, run-time approach
      Initial implementation of a "tweaks management" service
      Packaging of this service and tweaks data/configuration for at least one device
      Desirable skills:
      Familiarity with ARM64 devices (RPi 3+, Pine{Book,Phone,Tab} etc)
      Basic understanding of Linux systems (common services and middleware, user/admin/distro-specific configuration...)
      Shell scripting and basic programming skills
      (optional) basic Rust knowledge
      What the intern will learn: Through this project, the intern will improve their analysis and project management skils, gain a better understanding of Linux systems from a low-level perspective along with basic embedded software skills. They will also learn about Debian development (on both technical and philosophical levels) and likely learn/improve their Rust knowledge.
      Application tasks:
      Locate current tweaks packages (in both Debian and Mobian) targeting mobile devices and their source code
      Briefly analyze one or several of those tweaks and either:
      Explain their use
      Rework them, ideally making them more generic
      Offer to remove them, explaining the reasoning
      Related projects:
      Mobian
      DebianOnMobile team
      mobile-tweaks
      tweakster
      [SummerOfCode2025/ApprovedProjects/DeviceTweaksManagement][edit]

      ~~~~~~~~~~
      Enhancing Debian packages with ROCm GPU acceleration
      Description of the project: There now exists a solid foundation of AMD ROCm components packaged within Debian, so it is time to start making use of them! This project would consist of enhancements to existing packages that have AMD GPU support available upstream but not enabled in Debian, or the packaging of new tools and libraries that would be useful for AMD GPU users. A (non-exhaustive) list of potential packages include: adios2, blaspp, cp2k, cupy, dbcsr, elpa, gloo, hpx, hypre, jax, kokkos, lammps, lapackpp, magma, mfem, mpich, onnxruntime, papi, paraview, petsc, pyfr, pytorch, slepc, spfft, sundials, superlu-dist, or trilinos. There are a lot of options of varying difficulty, so it may be possible to tune the project to the skills and time available to the contributor.
      Confirmed Mentor: Cordell Bloor
      How to contact the mentor: cgmb@slerp.xyz
      Difficulty level: Medium
      Project size: Large (350 hours) if attempting to enhance as many packages as possible, but the scope could be reduced to fit a Medium (175 hour) or Small (90 hour) project
      Deliverables of the project:
      New Debian packages with GPU support
      Enhanced GPU support within existing Debian packages
      More autopackagetests running on the Debian ROCm CI
      Desirable skills:
      Strong familiarity with Debian and/or Ubuntu
      Proficiency with CLIs
      Some experience with build systems (e.g. CMake)
      What the intern will learn:
      Debian packaging (.deb) and maintenance within the Debian ecosystem
      Interacting with a broad variety of other groups within Debian, for example the Release Team and ftp-master
      How to work with ROCm (the AMD alternative to CUDA)
      Application tasks:
      Read the Debian New Maintainer's Guide and the Developer's reference
      Analyze which packages you would target
      Try to enhance one Debian package with AMD ROCm support
      Related projects:
      AMD ROCm GitHub
      [SummerOfCode2025/ApprovedProjects/EnhancingPackagesWithROCm][edit]

      ~~~~~~~~~~
      Make Debian for Raspberry Build Again
      Description of the project: There is an available set of images for running Debian in Raspberry Pi computers (all models below the 5 series)! However, I (the maintainer) am severely lacking time to take care for them; I called for help for somebody to adopt them, but have not been successful. The image generation scripts might have bitrotted a bit, but it is mostly all done. And there is a lot of interest and use still in having the images freshly generated and decently tested! This GSoC project is about getting the [[https://raspi.debian.net/ | Raspberry Pi Debian images] site working reliably again, and ideally making it easily deployable to be run in project machines.
      Confirmed Mentor: Gunnar Wolf
      How to contact the mentor: gwolf@debian.org, IRC: gwolf on OFTC
      Difficulty level: Easy
      Project size: Medium
      Deliverables of the project:
      Refreshing the set of daily-built images
      Having the set of daily-built images become automatic again — that is, go back to the promise of having it daily-built
      Write an Ansible playbook / Chef recipe / Puppet whatsitsname to define a virtual serve and have it build daily
      Do the (very basic!) hardware testing on several Raspberry computers. Do note, naturally, this will require having access to the relevant hardware.
      Desirable skills:
      Understanding the early-boot process of a single-board computer
      Declarative configuration (for vmdb2 as well as for Ansible/Chef/Puppet)
      Writing systemd units and timers
      What the intern will learn: The Raspberry Pi family of computers are ARM-based computers, which have a boot process quite different from “traditional” UEFI-based PCs. You will get acquinted with how a different architecture (that is growing in importance!) boots, how Device Tree maps the hardware for the operating system to use it (and maybe even how to work with overlays). You will also learn how deployment of production-level code is done to servers so they run reliably.
      Application tasks:
      We try to diverge the least possible from regular Debian installs with these images, but the RPi's way of working forces us to take some decisions.
      How much do we differ?
      Do you think all of our modifications make sense, or we might be carrying over some cruft that could be removed?
      We use the vmdb2 image building system. It is not much known outside Debian. How do you compare it with other image building tools?
      Related projects: We are filling approximately the same role as our debian-installer tool, but generating for a series of computers where users often flash ready-to-use images instead of doing an explicit install. Of course, the images we provide could be compared to what Raspberry Pi OS offers, but giving the quality and free-software guarantees that Debian has.
      [SummerOfCode2025/ApprovedProjects/MakeDebianForRaspberryBuildAgain][edit]

      ~~~~~~~~~~
      Package LLM Inference Libraries
      Description of the project: Package Large Language Model (LLM) inference libraries, in particular vLLM. It is needless to explain how LLMs are important. Currently, in the Debian archive, we only have ?PyTorch, but downstream applications are still missing. One of the most promising downstream applications is LLM inference. There are already people working on llama.cpp and Ollama, but vLLM still lacks lots of dependencies to land onto Debian. For multi-GPU inference and concurrency, vLLM has its advantages over llama.cpp. The missing packages are, for instance, transformers, huggingface-hub, etc. We would like to trim the dependency tree a little bit at the beginning until we get a minimum working instance of vLLM. Such, this project involves the Debian packaging work for vLLM and its dependencies that are missing from Debian, as well as fixing issues (if there is any) in existing packages to make vLLM work.
      Confirmed Mentor: Mo Zhou
      How to contact the mentor: lumin@debian.org
      Confirmed co-mentors: Christian Kastner (ckk@debian.org), Xuanteng Huang (xuanteng.huang@outlook.com). On the other hand, Debian Deep Learning Team (debian-ai@lists.debian.org) could offer help.
      Difficulty level: Medium (There might be some hard bits. Some packages that we are going to deal with have a clearly above-average difficulty than general Debian packages.
      Project size: 350 hour (large). I get this rough estimate by looking at the pipdeptree of the vllm package. The tree is a little deep.
      Deliverables of the project: Eventually I hope we can make vLLM into Debian archive, based on which we can deliver something for LLM inference out-of-the-box. If the amount of work eventually turns to be beyond my expectation, I'm still happy to see how far we can go towards this goal. If the amount of work required for vLLM is less than I expected, we can also look at something else like SGLang, another open source LLM inference library.
      Desirable skills: Long term Linux user (familiarity with Debian family is preferred), Python, ?PyTorch, and experience of running Large Language Models locally.
      What the intern will learn: Through this project, the intern will learn about the Debian development process, and gain more experience of running LLMs locally, including the inference performance tuning.
      Application tasks: Analyze how ?PyTorch is packaged in Debian, including how the CUDA variant of ?PyTorch is prepared. Those details are very important for the whole reverse dependency tree. And, the intern also needs to setup vLLM locally using pip or uv, and run the LLM inference locally for reference.
      Related projects: The ?PyTorch packaging repository is here: https://salsa.debian.org/deeplearning-team/pytorch
      [SummerOfCode2025/ApprovedProjects/PackageLLMInferenceLibraries][edit]
      
      ~~~~~~~~~~
      Autopkgtests for the rsync package
      Description of the project: A recent series of breakages caused in the rsync package as part of CVE fixes exposed the lack of testing coverage on Debian, e.g.: https://github.com/RsyncProject/rsync/issues/702. The rsync package on Debian has no autopkgtest. This project is for adding these tests to the rsync package, covering as many usecases as possible, making impossible for regressions to go unnoticed. These tests will also be submitted to stable through the proposed-updates mechanism.
      Confirmed Mentor: SamuelHenrique
      How to contact the mentor: samueloph@d.o, @samueloph:matrix.org, samueloph @ OFTC.
      Confirmed co-mentors: N/A
      Difficulty level: Easy
      Project size: 90 hour (small project)
      Deliverables of the project: Autopkgtests for the rsync package
      Desirable skills: Debian packaging, autopkgtest, shell scripting, rsync.
      What the intern will learn: How the Debian project does CI, how to write CI tests for the rsync package.
      Application tasks: Debian packaging contributions. It is required to have a non-virtualized machine running Debian Stable or Testing (no WSL, no containers, no VMs).
      Related projects: N/A
      More Resources: https://salsa.debian.org/ci-team/autopkgtest/-/blob/master/doc/README.package-tests.rst
      [SummerOfCode2025/ApprovedProjects/RsyncAutopkgtests][edit]

      ~~~~~~~~~~
      Salsa CI in Debian
      Description of the project: Salsa CI is a custom-built continuous integration framework that is used in the Debian Gitlab instance (Salsa) and helps Debian maintainers manage roughly 9,000 projects. The Salsa CI pipeline emulates the Debian build process and runs several Debian quality tests, helping to increase the probability that packages can migrate from Debian Unstable to Testing reliably, quickly, and without issue. When new source code triggers a Salsa CI pipeline, 17 different jobs run to build and test it automatically. Salsa CI checks to see whether the to-be-uploaded packages build on multiple architectures (at the moment, amd64 and i386, and optionally on Arm), runs autopkgtest test suites to try to identify potential regressions, and checks for common errors with our custom linter, lintian, among other tests.
      Confirmed Mentor: Otto Kekäläinen
      How to contact the mentor: otto@debian.org
      Confirmed co-mentors: Emmanuel Arias <eamanu@debian.org>
      Difficulty level: Medium
      Project size: Medium sized (175 hours). Depending on the student's availability, this project can be medium or large. The advantage of the project is it can be split into small pieces.
      Deliverables of the project: Fix and discuss issues reported to Salsa CI. Specially Labels "Nice-to-have", "Accepting MRs".
      Desirable skills: Awareness of GitLab CI. Working with git. Basic knowledge of Debian packaging.
      What the intern will learn: Debian Release process, Debian package building, Debian CI process, Basic QA of Debian packages.
      Application tasks: Pick issues from here, discuss with the team and try to fix them.
      More resources:
      https://debconf20.debconf.org/talks/47-where-is-salsa-ci-right-now/
      https://about.gitlab.com/blog/2023/09/19/debian-customizes-ci-tooling-with-gitlab/
      https://debconf19.debconf.org/talks/148-salsa-ci-debian-pipeline-for-developers/
      [SummerOfCode2025/ApprovedProjects/SalsaCI][edit]

      ~~~~~~~~~~
      
      Unapproved Projects with confirmed mentors
      findutils: Finish Support
      Description of the project: Complete the Rust implementation of GNU Findutils, ensuring full compatibility with all options and passing GNU tests. This project focuses on refining and finalizing the Rust-based reimplementation of key utilities from the Findutils package, which are essential for file searching and manipulation in Unix-like systems. The goal is to achieve full feature parity with the GNU versions while maintaining performance and correctness.
      To improve your chances of being selected, please contribute a few changes to the project to demonstrate your commitment and understanding.
      Confirmed Mentor: Sylvestre Ledru
      How to contact the mentor: sylvestre@debian.org
      Confirmed co-mentors: Daniel Hofstetter <daniel.hofstetter@42dh.com>
      Difficulty level: Large
      Project size: 350 hours
      Deliverables of the project:
      A fully functional Rust implementation of the Findutils suite, including:
      /usr/bin/find - search for files in a directory hierarchy
      /usr/bin/locate - find files by name in a prebuilt index
      /usr/bin/updatedb - update the locate database
      /usr/bin/xargs - build and execute command lines from input
      Full compatibility with GNU Findutils
      Passing all relevant GNU tests
      Desirable skills:
      Rust expertise
      Knowledge of file systems and directory traversal
      Understanding of command-line utilities and Unix system interactions
      What the intern will learn:
      How file search utilities work
      Efficient directory traversal and filtering techniques
      Optimization strategies for large-scale file searches
      Application tasks:
      Implement or improve one of the Findutils utilities from the uutils/findutils project: https://github.com/uutils/findutils
      [SummerOfCode2025/PendingProjects/rust-bsdutils][edit]

      ~~~~~~~~~~
      login: Reimplementation of Login Infrastructure Tools in Rust
      Description of the project: Create Rust versions of login infrastructure tools, with a focus on full option compatibility and passing GNU tests. This project involves the Rust-based reimplementation of essential login infrastructure tools that provide functionality for logins and changing effective user or group IDs. The objective is to implement these tools as drop-in replacements for the original shadow-utils suite, ensuring full compatibility with all options and passing all relevant tests. To improve your chances to be selected, please contribute a few changes to the project to demonstrate your commitment and understanding of the project.
      Confirmed Mentor: Sylvestre Ledru
      How to contact the mentor: sylvestre@debian.org
      Confirmed co-mentors: Daniel Hofstetter <daniel.hofstetter@42dh.com>
      Difficulty level: Large
      Project size: 350 hours
      Deliverables of the project: Robust login infrastructure tools, including:
      /bin/login - the program that invokes a user shell on a virtual terminal
      /usr/bin/faillog - tool for displaying and maintaining failure records
      /usr/bin/lastlog - examine the last login record
      /usr/bin/newgrp - change to a new group
      /usr/sbin/nologin - a dummy shell for disabled user accounts
      /usr/bin/sg - execute command with different group ID
      Desirable skills: Rust expertise, knowledge of Linux authentication systems, user/group management, and security considerations.
      What the intern will learn: How login infrastructure works, system security concepts, authentication mechanisms, and privilege management.
      Application tasks: Implement or improve one of the login tools from the shadow-utils project: https://github.com/shadow-maint/shadow
      [SummerOfCode2025/PendingProjects/rust-login][edit]

      ~~~~~~~~~~
      procps: Development of System Monitoring, Statistics and Information Tools in Rust
      Description of the project: Create Rust versions of system monitoring and statistics tools, with a focus on full option compatibility and passing GNU tests. This project involves the Rust-based development of system monitoring and statistics tools: top, vmstat, tload, w, and watch. And process management and information tools: ps, pgrep, pidwait, pkill, skill, and snice. The objective is to achieve full compatibility with all options and to pass GNU tests, ensuring these tools provide accurate and reliable system insights. To improve your chances to be selected, please contribute a few changes to the project to demonstrate your commitment and understanding of the project. Debian can lead in this space with security and Rust!
      Confirmed Mentor: Sylvestre Ledru
      How to contact the mentor: sylvestre@debian.org
      Confirmed co-mentors:Daniel Hofstetter <daniel.hofstetter@42dh.com>
      Difficulty level: Large
      Project size: 350 hours
      Deliverables of the project: Robust tools for system monitoring and statistics, fully compatible with existing options and verified by GNU tests.
      Desirable skills: Rust expertise, knowledge of system performance metrics, familiarity with GNU testing frameworks.
      What the intern will learn: How the Coreutils work, the low level part of the OS
      Application tasks: Fix one or more GNU test listed on: https://uutils.github.io/coreutils/book/test_coverage.html
      [SummerOfCode2025/PendingProjects/rust-procps][edit]

      ~~~~~~~~~~
      util-linux: Development of System Utilities in Rust
      Description of the project: Create Rust versions of util-linux tools, with a focus on full option compatibility and passing GNU tests. This project involves the Rust-based reimplementation of various util-linux tools, including system information tools (dmesg, lscpu), filesystem tools (mountpoint, fsfreeze), partition management tools, process management tools, and utility tools. The objective is to achieve full compatibility with all options and to pass GNU tests, ensuring these tools function as drop-in replacements for the original util-linux suite. To improve your chances to be selected, please contribute a few changes to the project to demonstrate your commitment and understanding of the project.
      Confirmed Mentor: Sylvestre Ledru
      How to contact the mentor: sylvestre@debian.org
      Confirmed co-mentors: Daniel Hofstetter <daniel.hofstetter@42dh.com>
      Difficulty level: Large
      Project size: 350 hours
      Deliverables of the project: Robust tools for system utilities, fully compatible with existing options and verified by GNU tests.
      Desirable skills: Rust expertise, knowledge of system utilities and Linux internals, familiarity with GNU testing frameworks.
      What the intern will learn: How util-linux tools work, the low level part of the OS, system management, and filesystem operations
      Application tasks: Implement or improve one of the tools listed in the util-linux repository: https://github.com/uutils/util-linux
      [SummerOfCode2025/PendingProjects/rust-util-linux][edit]
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/debian/
    idea_list_url: https://wiki.debian.org/SummerOfCode2025/Projects

  - organization_id: 32
    organization_name: DeepChem
    no_of_ideas: 10
    ideas_content: |
      
      Length: Small (90 hours)
      Description: DeepChem has been moving towards first class layers and now has a collection of general layers. We still need to improve the documentation for existing layers to make them more useful for the community. This project should add tutorials for using existing layers to the DeepChem tutorial series, and should plan to add a few new layers that would be useful to the community.
      Educational Value: Students will learn to improve their technical communication skills and learn how to construct useful Jupyter/Colab tutorials. Layers are easier to add than full models since they are effectively functions.
      Potential Mentors: Aryan, Jose, Riya, Maithili, Nimisha, Shreyas
      Note: This was also a 2024 project, but there remains more work to be done for 2025 expanding tutorials/ideas.
      
      ~~~~~~~~~~
      Improving New Drug Modality Support
      Length: Small (90 hours)
      Description: DeepChem at present doesn’t have much tooling or support for working with emerging drug modalities. These include PROTACs, Antibody-drug-conjugates, macrocycles, oligonucleotides and more. This project would add new tutorials introducing these new drug modalities and provides examples of how to work with them with deepchem. It would also be useful to identify and process relevant datasets.
      Educational Value: New drug modalities drive many emerging startups in the space. Improving DeepChem’s support for these new modalities of therapeutics could help drive discovery of new medicine at the cutting edge. It would prepare students to potentially find jobs at these up-and-coming biotech firms as well.
      Potential Mentors: Jose, David, Bharath
      Note: This was also a 2024 project, but there remains more work to be done for 2025 expanding support for new modalities.
      
      ~~~~~~~~~~
      Improving support for drug formulations
      Length: Small (90 hours)
      Description: Drug formulations are a rich area of industrial study that is often critical for actually bringing a drug to patients. See https://drughunter.com/resource/the-modern-medicinal-chemist-s-guide-to-formulations/ 65 for example for a guide. In this project, you will build a tutorial introducing readers to the study of drug formulations along with DeepChem examples of how you can computationally help design a potential formulation.
      Educational Value: Formulations are critical for bringing drugs to patients. Improving DeepChem’s support for these new modalities of therapeutics could help drive discovery of new medicine at the cutting edge. It will prepare students to find jobs at large biotech/pharma firms as well.
      Potential Mentors: Jose, David, Bharath
      Intermediate Projects
      These projects require some degree of hacking, but likely won’t raise challenging engineering difficulties.
      
      ~~~~~~~~~~
      Improve Equivariance Support
      Length: Medium (175 hours)
      Description: DeepChem has limited support for equivariant models. This project would extend support for equivariance to DeepChem and add additional equivariant model such as tensor field networks to DeepChem
      Educational Value: Equivariance is one of the most interesting ideas in modern machine learning and underpins powerful systems like AlphaFold2. Contributors will learn more about this field and could potentially write a research paper about their work on this project.
      Potential Mentors: Aryan, Riya, Nimisha, Bharath, Shreyas
      Note: This was also a 2024 project, but this project was not taken up by a student last year.
      
      ~~~~~~~~~~
      Numpy 2.0 Upgrade
      Length: Large (175 hours)
      Description: DeepChem is currently on Numpy < 2.0. The upgrade to 2.0 is not backwards compatible. We need to fix any broken compatibilities.
      Educational Value: Complex version upgrades take a lot of sophistication and will teach students challenging debugging skills.
      Potential Mentors: Bharath
      
      ~~~~~~~~~~
      Conversion of Smiles to IUPAC and IUPAC to smiles
      Length: Large(300 hours)/Medium(175 hours)
      Description: This project focuses on developing tools within DeepChem to enable accurate, bidirectional conversion between SMILES (Simplified Molecular Input Line Entry System) strings and IUPAC (International Union of Pure and Applied Chemistry) names. The final deliverables will include user-friendly APIs, thorough documentation, and comprehensive testing to facilitate reliable molecular representation transformations.
      Educational Value: Deepening of understanding of chemical data structures, algorithm optimization for molecular conversions, and contributing to the Deepchem ecosystem.
      Potential Mentors: Shreyas, Bharath
      
      ~~~~~~~~~~
      Advanced Projects
      These projects raise considerable technical and engineering challenges. We recommend that students who want to tackle these projects have past experience working in large codebases and tackling code reviews for complex code.
      Implement a Wishlist Model
      Length: Large (300 hours)
      Description: DeepChem has an extensive wishlist of models (https://github.com/deepchem/deepchem/issues/2680 193). Pick a model from the wishlist and implement it in DeepChem. We suggest tackling a model such as Hamiltonian or Lagrangian Neural networks or Physics Inspired Neural Operators (PINO) that will improve DeepChem’s physics support.
      Educational Value: Implementing a machine learning model from scratch or from an academic reference into a production grade library like DeepChem is a challenging task. Doing so requires understanding the base model, dealing with numerical issues in implementation, and benchmarking the model correctly. Multiple past GSoC contributors have leveraged their implementations to write papers on their work and have gained skills that they have used subsequently in industry or in academia.
      Potential Mentors: Depends on model.

      ~~~~~~~~~~
      PyTorch Porting
      Length: Medium (175 hours)
      Description: DeepChem has mostly shifted to PyTorch as its primary backend, but a couple models are still implemented in TensorFlow, in particular our Chemception implementation. This project would port Chemception and do final testing to fix issues with PyTorch/DeepChem compatibility on implementations. https://github.com/deepchem/deepchem/issues/2863. 77
      Educational Value: Porting models while preserving numerical properties requires a strong understanding of deep learning implementations. It serves as a test of machine learning know-how that will serve students well in future machine learning positions in academia or industry.
      Potential Mentors: Aryan, Jose, Riya, Nimisha, Bharath, Shreyas
      
      ~~~~~~~~~~
      HuggingFace-style easy pretrained-model Load
      Length: Large (300 hours)
      Description: DeepChem requires you to know the parameters used to train a model in order to reload it from disk. This is unfriendly for distributing pretrained models. In this project, you will implement an easy 
      HuggingFace-style function call to load weights from disk without having to know training parameters. To do this, you will set a standard metadata format for saving model parameters that can be used behind the scene to autoload models from disk.
      Educational Value: This is a technically challenging project which will require understanding metadata formats and changing saving/reloading for existing models.
      Potential Mentors: Aryan, Bharath
      
      ~~~~~~~~~~
      Model-Parallel DeepChem Model Training
      Length: Large (300 hours)
      Description: DeepChem now has good support for training LLM models through huggingface. At present though, these models cannot be too large and must fit on a single GPU. In this project, you will implement basic support for model parallel training to train models with weights that don’t fit on a single GPU.
      Educational Value: This is a technically challenging project which will require understanding multi-GPU training methods. You may need to explore existing PyTorch frameworks for model-parallel training and adapt them to DeepChem.
      Potential Mentors: Aryan, Bharath
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/deepchem/
    idea_list_url: https://forum.deepchem.io/t/deepchem-gsoc-2025-project-ideas/1568

  - organization_id: 33
    organization_name: Department of Biomedical Informatics, Emory University
    no_of_ideas: 5
    ideas_content: |
      
      [1] Title: Securing Linux Storage with ACLs: An Open-Source Web Management Interface for Enhanced Data Protection
      Mentor(s): Robert Tweedy and Mahmoud Zeydabadinezhad, PhD (mzeydab -at- emory.edu)
      Overview:
      While the traditional POSIX permissions used by nearly all common Linux filesystems allow for simple data permissions management based on group membership, this can become complicated to manage in a large research environment where a project's directory tree may not be efficiently structured to permit access via the simple group management achievable via POSIX permissions, especially when a research PI would like to grant different levels of access to a file to users who are otherwise in the same group. Linux ACLs, while a de-facto standard rather than a formally defined one like POSIX, can be used to resolve these types of situations but have a higher learning curve & far fewer management tools available for a large-scale storage system than tools managing POSIX permissions, relying mainly on the command line tools "setfacl" and "getfacl" to view any details. While there is a GUI tool known as "eiciel" that can adjust Linux ACLs, its audience & feature set is aimed towards an individual user on their personal machine & thus is not suitable for large-scale storage system management. This project aims to develop an application with a web-based GUI that can be deployed on a research network's storage system to provide PIs with a graphical overview of all their research data & allow management of the Linux ACLs to grant appropriate levels of access to the PI's research team members.
      Current Status: New project
      Expected Outcomes:
      A self-contained application (ie. the application should not require external APIs/javascript/etc. to be queried by the end-user's web browser at runtime & should have any relevant scripts packaged with it; the underlying back-end should only access local network resources & not need external Internet connectivity) that allows an end-user to view and manage the access permissions of a large research storage network at a fine-grained level via a web GUI. Both the back-end logic & front-end web interface are in scope of this project.
      The application should support authentication via different modules, with a minimum of LDAP-based authentication.
      The application should support deployment behind a reverse proxy running on Apache or Nginx
      The application must be Linux distribution agnostic as much as possible, but at a minimum should support both running on both RedHat Enterprise Linux (or free derivatives like Rocky Linux) and Debian Linux (or other derivatives like Ubuntu Server) as a SystemD service.
      The application must support running under a limited service account & not as the root user; if special permissions are required for the service account (ie. AmbientCapabilities defined in the SystemD service script) these should be stated in the application's documentation.
      Documentation explaining a basic overview of application usage & installation steps for use by research network system administrators.
      The code and documentation for the application will be made publicly available on a platform such as GitHub & licensed under an Open-Source license such as GPLv3.
      Required Skills:
      Strong web application/frontend development skills using lightweight web frameworks (ie. this should not be a Java application that requires Tomcat/Glassfish/etc.). Strong backend/logic development skills in any standard language commonly available by default on Linux systems (Python, C, C++, Rust, etc.) A good understanding of POSIX and Linux ACL file permissions. A security-focused mindset to ensure that the application's coded to only permit users to view/modify permissions on their own files & not those of others. Familiarity with databases (PostgreSQL and/or MySQL) may be beneficial depending on the approach used to develop the application and track user permissions for the application itself. Familiarity with standard web servers like Apache or Nginx, especially with the concept of reverse proxies.
      Source Code: New Project
      Discussion Forum: https://github.com/NISYSLAB/Emory-BMI-GSoC/discussions
      Effort: 350 Hours
      Difficulty Level: Hard

      ~~~~~~~~~~
      [2] Title: Open-Source Framework for Advanced EEG Data Analysis Using Pre-trained Foundation Models
      Mentor(s): Babak Mahmoudi, PhD and Mahmoud Zeydabadinezhad, PhD (mzeydab -at- emory.edu)
      Overview:
      A foundation model refers to a large-scale model that is pre-trained on extensive, often unlabeled data, capturing a broad understanding of that data. Recent studies have indicated that foundation models could potentially offer enhanced robustness and versatility in the analysis of complex patterns within Electroencephalography (EEG) data. This is particularly relevant in scenarios where EEG data for specific downstream tasks is limited in quantity. This project aims to create an open-source foundation model for EEG data analysis. It will involve developing algorithms for EEG signal processing, automatic feature extraction, and implementing deep learning-based algorithms for pre-training a foundation model on publicly available EEG datasets.
      Current Status: In Progress.
      Expected Outcomes:
      Literature Review: Research and review existing open-source foundation models for medical data, specifically EEG data. Identify the current limitations and challenges in this field.
      A robust, open-source EEG foundation model.
      Documentation and examples demonstrating the model's usage.
      A report detailing the methodologies used and the performance of the model.
      The model weights and code will be made publicly available on a platform such as GitHub.
      Required Skills:
      Strong programming skills, preferably in Python.
      Experience with deep learning frameworks, preferably PyTorch.
      Knowledge of self-supervised learning and large language models
      Knowledge in signal processing, neuroscience, or related fields.
      Source Code: In Progress
      Discussion Forum: https://github.com/NISYSLAB/Emory-BMI-GSoC/discussions
      Effort: 350 Hours
      Difficulty Level: Hard

      ~~~~~~~~~~
      [3] Python Expansion of the Open Source Electrophysiological Toolbox
      Mentor(s): Reza Sameni, PhD
      Overview:
      Standardized, open-source codes are indispensable in advancing biomedical engineering and biomedical informatics. The Open-Source Electrophysiological Toolbox (OSET) [https://github.com/alphanumericslab/OSET] was conceived in 2006 with this perspective, aiming to offer researchers an open-source codebase for biomedical signal processing. The toolbox has incrementally evolved and expanded over the years. Many researchers have utilized this toolbox for their research. Notably, some modules of OSET have been translated to C/C++ and Python and integrated into medical devices and cloud-based automatic diagnostic systems for large data. It operates under a permissive open license, encouraging community-driven development. The project aims to continue the Python expansion of OSET to convert it into a standard Python package, broadening access and maintaining consistency across platforms. The planned upgrades include comprehensive cross-language unit tests (between MATLAB and Python), documentation, example codes, installation, and maintenance mechanisms, with a modern software-engineered architecture and objective microbenchmarks. Through this expansion, we aim to extend OSET's benefits to a broader community of AI researchers, also contributing to the training of the next generation of biomedical engineers in the AI era. OSET will be maintained under the 3-Clause BSD License, a permissive open-source license that allows the redistribution and use of software in any form with adequate disclaimer clauses, offering flexibility for both open-source and commercial use, while minimizing legal complexities.
      Current Status: Ongoing project.
      Expected Outcomes:
      A Python package for OSET, with standard unit tests, installation guidelines and documentation. The codebase should operate exactly identical to the current MATLAB implementation.
      Key features:
      Open-source code development for biomedical engineering and biomedical informatics.
      Identical cross-language performance
      Standardized unit tests
      Required Skills:
      Proficiency in Python and MATLAB.
      A background in signal processing
      Experience in biomedical signal processing
      Source Code: https://github.com/alphanumericslab/OSET
      Discussion Forum: https://github.com/NISYSLAB/Emory-BMI-GSoC/discussions
      Effort: 350 Hours
      Difficulty Level: Medium

      ~~~~~~~~~~
      [4] Health-AI Ethics Atlas
      Mentor(s): Selen Bozkurt, PhD
      Overview:
      This project aims to develop an interactive global map that visualizes the application and development of ethical principles in medical AI across different countries. It will highlight the diversity in ethical standards, regulatory approaches, and implementation practices in healthcare AI worldwide.##
      Key features:
      Interactive world map displaying medical AI ethics initiatives.
      Filters for different ethical principles and AI applications.
      Country-specific data on AI healthcare policies and ethics.
      Time-lapse feature to observe changes over time.
      Case studies and detailed reports linked to map locations.
      Dynamic interface allowing users to explore technological ethical dimensions.
      Current Status: New project.
      Expected Outcomes:
      A comprehensive resource for understanding global trends in medical AI ethics.
      Enhanced awareness of ethical diversity in medical AI applications.
      Tool for researchers and policymakers to identify global best practices and gaps.
      Required Skills:
      Proficiency in web development (e.g., HTML, CSS, JavaScript).
      Experience with data visualization tools and libraries (e.g., D3.js, Leaflet).
      Understanding of GIS and mapping software.
      Knowledge in data analysis and handling large datasets.
      Interest or background in AI ethics, particularly in healthcare.
      Source Code: New Project.
      Discussion Forum: https://github.com/NISYSLAB/Emory-BMI-GSoC/discussions
      Effort: 350 Hours
      Difficulty Level: Medium

      ~~~~~~~~~~
      [5] Advancing Brain Decoding and Cognitive Analysis: Leveraging Diffusion Models for Spatiotemporal Pattern Recognition in fMRI Data
      Mentor(s): Babak Mahmoudi, PhD and Ozgur Kara
      Overview:
      Functional Magnetic Resonance Imaging (fMRI) is a neuroimaging technique that measures brain activity by detecting changes in blood flow, providing high-dimensional, time-series data representing brain function. By leveraging diffusion models—probabilistic generative models originally designed for image synthesis—this project aims to learn complex spatiotemporal patterns in fMRI data, enabling downstream tasks such as brain decoding, disease prediction, and cognitive state classification.
      Current Status: New project
      Expected Outcomes:
      Data Preprocessing:
      Preprocess data using standard pipelines to normalize, denoise, and align brain scans.
      Convert the data into a structured representation suitable for diffusion training, such as voxel-wise time series or connectivity matrices.
      Model Architecture & Training:
      Adapt diffusion models to the temporal and spatial characteristics of fMRI data.
      Use a U-Net or transformer-based architecture to model the evolution of brain signals.
      Train the model with a denoising diffusion probabilistic approach, learning to reconstruct fMRI signals from noise.
      Explore conditioning techniques, such as using behavioral or task labels, to guide model learning.
      Required Skills:
      Strong programming skills, preferably in Python.
      Experience with deep learning frameworks, preferably PyTorch.
      Knowledge in signal processing, neuroscience, or related fields.
      Source Code: New Project
      Discussion Forum: https://github.com/NISYSLAB/Emory-BMI-GSoC/discussions
      Effort: 350 Hours
      Difficulty Level: Hard
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/department-of-biomedical-informatics-emory-university/
    idea_list_url: https://github.com/NISYSLAB/Emory-BMI-GSoC/?tab=readme-ov-file#list-of-ideas

  - organization_id: 34
    organization_name: Django Software Foundation
    no_of_ideas: 4
    ideas_content: |
      
      Django Templates: Bring django-template-partials into core
      Difficulty Medium
      Size 350hrs
      Potential Mentors Carlton Gibson
      Key Skills Django Template Language, template tags
      The third-party app django-template-partials allows for reusable named inline partials for the Django Template Language. These named inline partials can be used multiple times within a template or included in other templates. They are particularly useful when using libraries such as HTMX. It would be good to have support built-in to core.
      Outcome would be a PR adding this into Django. In addition there would be preparatory work on the Django-template-partials repo to smooth the migration for existing users. There is a tracking issue on the repo that can be used for guidance.
      
      ~~~~~~~~~~
      Automate processes within Django contribution workflow
      Difficulty Medium
      Size 350hrs
      Potential Mentors Lily Foote
      Key Skills GitHub actions, scripting, Jenkins
      The contribution workflow within Django has several manual processes. These are error prone and take up valuable time from contributors. This project would seek to automate these processes, such as automating releases, identifying active PRs and managing aging PR queue.
      Part of this project will involve working with the Fellows to determine which of their tasks and the community's tasks are the best candidates for automation.
      Outcome would be one to several PRs automating these workflows, depending on how many are accomplished.
      ~~~~~~~~~~
      Expand django-stubs coverage
      Difficulty Hard.
      Size Variable
      Potential Mentors 2024 mentor: Adam Johnson
      Key Skills Python typing and Django-stubs
      django-stubs is an external project that adds type hints to Django. It may be possible to work on it under GSoC if you can show experience with Python’s type hints and Mypy.
      django-stubs uses Mypy’s stubtest tool to check that its type hints align with Django’s source, per its contributing documentation. The “todo” list contains ~1600 functions and classes missing type hints. A proposal targeting a specific, significant subset of the missing types is likely to be accepted.
      
      
      ~~~~~~~~~~
      Django Admin: Add Command palette
      Difficulty Medium
      Size Variable
      Potentia mentors Tom Carrick
      Key Skills UI/UX
      Many dashboards nowadays have command palettes, often associated with the CTL+K keyboard shortcut. This allows for quicker, easier and more accessible navigation. This project is about adding such a feature to the Django admin.
      This would allow power users to e.g. very quickly find a particular object in the database to edit. The overall goal is to improve the user-experience for keyboard and keyboard-only users.
      This feature already has an accepted ticket. However, this work needs to be done carefully to ensure that all shortcuts are useful, documented in the admin, and work across browsers without shadowing browser shortcuts. In addition, shortcuts should be easily extensible by developers.
      Some initial work has been done to add keyboard shortcuts to core. The 175 hour version of this project would be to get this project finished and merged into Django. The 350 hour version would be to build this into a full command palette.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/django-software-foundation/
    idea_list_url: https://code.djangoproject.com/wiki/SummerOfCode2025

  - organization_id: 35
    organization_name: Drupal Association
    no_of_ideas: 9
    ideas_content: |

    Proposal 2025: Augmentor DALL·E 3 module
    Project Description
    This project aims to ship the Augmentor plugin with seamless integration to the DALL·E 3 service, enabling users to generate high-quality images directly from text prompts. By combining Augmentor's flexible plugin architecture with DALL·E 3’s advanced AI capabilities, the solution will empower content creators to effortlessly transform ideas into compelling visual content. The integration will focus on delivering a user-friendly interface, efficient performance, and robust error handling to cater to both technical and non-technical users.

    Project Goal
    Functional Changes:
    Integrate the DALL·E 3 API into the Augmentor plugin for real-time image generation from text inputs.
    Develop an intuitive interface for configuring image generation parameters and previewing results.
    Implement error handling and optimization strategies to ensure reliability and performance.
    Provide comprehensive documentation and usage guides to facilitate seamless adoption.
    Mentor Details
    Name: Naveen Valecha & Murrayw
    Email / Slack: @naveenvalecha, @murrayw

    Project Size
    175 hours

    Project Difficulty
    Intermediate

    Project Skills/Prerequisite
    Expertise in plugin development within the Augmentor ecosystem.
    Proficiency in JavaScript, Python, or other relevant programming languages.
    Familiarity with RESTful APIs and integrating third-party AI services.
    Experience with DALL·E 3 or similar AI image generation APIs is a plus.
    Understanding of UI/UX design principles to create an engaging and intuitive user interface.
    Project Resources
    DALL·E 3 Documentation
    Augmentor Plugin Developer Guide
    OpenAI API Reference
    Web API Documentation
    R&D Tasks
    Research the DALL·E 3 API, including authentication methods, rate limits, and usage policies.
    Design and develop a modular integration layer within the Augmentor plugin.
    Create a user-friendly interface for inputting text prompts and previewing generated images.
    Implement error handling, logging, and performance optimizations to ensure a seamless user experience.
    Document the integration process, including setup instructions and usage tutorials.

    ~~~~~~~~~~

    Proposal 2025: Open Source AI Content Generation
    
    Project Description
    This project focuses on advancing the integration of open-source AI models into existing Drupal modules, streamlining the creation of structured content based on user prompts. By embedding AI-powered content generation directly into Drupal, the solution aims to automate and simplify the content creation process. Site builders and content creators will benefit from a seamless workflow that transforms text inputs into well-organized, coherent content.

    Project Goal
    Functional Changes:
    Develop an integration layer that connects Drupal content creation modules with open-source AI models.
    Create an intuitive interface where users can input prompts or guidelines to generate structured content.
    Implement mechanisms to format and validate the generated content according to predefined templates.
    Optimize the integration for performance and reliability, including robust error handling and logging.
    Document the integration process and provide comprehensive usage guides for end users.
    Mentor Details
    Name & Slack: Gaurav & Anushri Kumari
    Email / Slack: @gauravvvv, @anushrikumari

    Project Size
    350 hours

    Project Difficulty
    Intermediate

    Project Skills/Prerequisite
    Proficiency in PHP and Symfony for backend development.
    Experience in JavaScript for front-end interface development.
    Familiarity with AI models and APIs, including experience working with open-source AI frameworks.
    Understanding of Drupal module development and integration patterns is a plus.
    Project Resources
    Drupal Documentation
    Symfony Documentation
    Hugging Face – Open Source AI Models
    JavaScript Guide
    R&D Tasks
    Research and evaluate suitable open-source AI models that can generate structured content from text prompts.
    Identify the optimal integration points within existing Drupal content creation modules.
    Develop the backend integration using PHP and Symfony, ensuring smooth communication with the AI APIs.
    Create a user-friendly front-end interface using JavaScript that allows users to input prompts and preview generated content.
    Implement error handling, logging, and performance optimizations to enhance the overall user experience.
    Document the integration process and produce detailed guides for installation, configuration, and usage.
    Issue fork gsoc-3419059
    Command icon Show commands
    About issue forks

    ~~~~~~~~~~

    Proposal 2025: Assisting Modules in Drupal 11 Compatibility


    Project Description
    Taking on a project idea from 2023. Many important Drupal modules are still not ready for Drupal 11. This makes it harder for developers and site owners to upgrade smoothly.

    This project aims to assist in making Drupal modules Drupal 11-ready by identifying top-used but outdated modules, categorizing them, and streamlining their migration process. The project will include:

    Prioritization of the top most-used yet incompatible modules.
    Categorization based on functionality (e.g., e-commerce, security, SEO).
    Automated compatibility checks and migration guides.
    By ensuring these modules are compatible, this project will significantly ease the transition to Drupal 11, benefiting developers and site owners alike.

    Project Goal
    Functional Changes:
    Analyze and prioritize high-impact modules needing Drupal 11 updates.
    Ensure code consistency and adherence to modern Drupal standards.
    Provide clear documentation for developers migrating modules.
    User Experience Improvements:
    Enhance documentation for easier adoption.
    Provide a clear roadmap for Drupal 11 compatibility efforts.
    Code & Performance Enhancements:
    Ensure PSR standards compliance.
    Mentor Details
    Name : [To be assigned]

    Email / Slack: [To be assigned]

    Project Size
    350 hours

    Project Difficulty
    Intermediate

    Project Skills/Prerequisite
    Proficiency in PHP and JavaScript
    Experience in Drupal module development
    Familiarity with upgrading Drupal modules to newer versions
    Understanding of Drupal's API and best practices
    Experience with Git and version control
    Project Resources
    Drupal Contributor Guide
    R&D Tasks
    Identify top-used modules that need compatibility updates.
    Analyze and categorize modules based on their functionality.
    Document compatibility issues and solutions for developers.
    Test migrated modules for performance and stability.

    ~~~~~~~~~~

    Proposal 2025: FAISS Vector Search Integration for Drupal

    Project Description
    Drupal currently lacks support for FAISS (Facebook AI Similarity Search), a high-performance library designed for efficient vector-based similarity search. This project aims to develop a FAISS provider module that enables advanced content discovery, documentation deduplication, and AI-powered search capabilities within Drupal.

    The solution will integrate with existing Drupal AI modules and Search API, providing a robust foundation for vector-based similarity search. By implementing FAISS as a local vector database, we can significantly improve content discovery while reducing dependency on external APIs.

    Current Scenario / Pain Points
    No native FAISS support in Drupal for vector similarity search
    External API calls causing latency in embedding generation
    Cost implications with third-party embedding services
    Growing documentation duplication without automated detection
    Performance bottlenecks in large-scale content similarity matching
    Why This Matters
    This integration will revolutionize how Drupal handles content discovery and similarity detection:

    Cost Efficiency: Local vector operations eliminate expensive API calls
    Performance: FAISS is optimized for rapid similarity search at scale
    Independence: Reduced reliance on external services
    Scalability: Handles millions of vectors efficiently
    Future Impact
    The FAISS provider will enable next-generation features in Drupal:

    Intelligent Documentation Management
    Automated duplicate detection
    Content relationship mapping
    Smart content suggestions
    Enhanced Module Discovery
    Similar module detection
    Functionality matching
    Better developer experience
    AI-Powered Search
    Semantic search capabilities
    Context-aware results
    Improved content relevance
    Project Goal
    Develop a FAISS provider module (ai_provider_faiss) for vector storage and similarity search
    Create an embedding pipeline using HuggingFace model
    Integrate with Search API for enhanced content discovery
    Implement a dashboard for visualizing similarity scores and content relationships
    Mentor Details
    Name: [To be assigned]
    Email / Slack: [To be assigned]

    Project Size
    350 Hours

    Project Difficulty
    INTERMEDIATE

    Project Skills/Prerequisites
    Strong PHP and Drupal module development experience
    Understanding of vector embeddings and similarity search concepts
    Familiarity with Search API and HuggingFace integration
    Experience with performance optimization and scalable solutions
    Project Resources
    FAISS GitHub Repository
    HuggingFace Documentation
    Original Feature Request

    ~~~~~~~~~~

    Proposal 2025: Appwrite Integration Module for Drupal

    Project Description
    Appwrite is an open-source Backend-as-a-Service (BaaS) that offers a comprehensive suite of tools—ranging from authentication and storage to databases and serverless functions—through easy-to-use APIs. This project aims to develop a Drupal module that integrates Appwrite’s services, giving Drupal developers a robust alternative for handling key backend functionalities. The module will primarily focus on connecting Drupal with Appwrite’s authentication system, object storage, and document database, while also laying the groundwork for future integrations like serverless functions, messaging, and real-time event handling.

    Many Drupal sites currently rely on local media storage or traditional cloud services, but with Appwrite’s flexible architecture, we can streamline media management and content handling. The solution will include a dedicated configuration interface within Drupal, making it simple for site administrators to set up and manage Appwrite settings.

    Project Goal
    Functional Changes:
    Develop a Drupal module that connects with Appwrite’s OAuth-based authentication system (supporting providers like Google, GitHub, Apple, etc.).
    Enable media file management by integrating with Appwrite's object storage APIs, reducing the dependency on traditional cloud storage solutions.
    Integrate Appwrite’s document database to store and retrieve structured Drupal content efficiently.
    Create an intuitive configuration interface within Drupal for managing all Appwrite-related settings.
    Mentor Details
    Name: stanzin
    Email / Slack: @stan

    Project Size
    TBD

    Project Difficulty
    INTERMEDIATE

    Project Skills/Prerequisite
    Experience with PHP and Symfony for Drupal backend development.
    Understanding of Drupal module development, including hooks, services, and dependency injection.
    Knowledge of JavaScript for interacting with the Appwrite SDK and APIs.
    Familiarity with REST APIs to facilitate seamless integration of external services with Drupal.
    Understanding of OAuth and authentication protocols for implementing secure Appwrite authentication.
    Project Resources
    Appwrite Official Website
    Drupal Module Development Guide
    R&D Tasks
    Research and evaluate the Appwrite API, focusing on authentication, storage, and document database functionalities.
    Design a modular integration approach to connect Drupal with Appwrite’s services.
    Develop and test the OAuth-based authentication workflow within Drupal using Appwrite.
    Implement media storage integration to manage file uploads and retrievals via Appwrite’s object storage.
    Integrate Appwrite’s document database to support Drupal’s content management and retrieval.
    Create a user-friendly configuration interface in Drupal to manage Appwrite settings and integrations.
    Document the integration process and provide comprehensive user guides and technical documentation.
    
    ~~~~~~~~~~

    

    Proposal 2025: AI-Powered Media Caption Generator

    Project Description
    Currently, Drupal lacks a built-in AI-powered solution for generating media captions, alt tags, and metadata. Manual captioning and tagging are time-consuming, inconsistent, and impact accessibility, SEO, and media discoverability.

    The AI-Powered Media Enhancement Module will integrate with AI APIs for NLP and computer vision to automatically generate captions, alt tags, and relevant media tags based on content analysis. This module will include:

    Adaptive feedback learning: Continuously improves caption accuracy based on user interactions.
    Batch processing: Allows handling multiple media files efficiently.
    Customizable AI model selection: Users can choose different AI services (OpenAI, Hugging Face, Google Vision, etc.).
    By automating captioning and metadata generation, this project will improve accessibility, SEO, and user engagement, reducing manual effort and making media content more discoverable.

    Project Goal
    Functional Changes:
    Develop a Drupal module capable of generating AI-powered captions, alt tags, and media metadata.
    Integrate NLP models for text-based caption generation.
    Implement computer vision models for object detection and image recognition.
    Enable an adaptive feedback loop where user edits refine AI-generated captions over time.
    Support batch processing to handle multiple media files at once.
    Allow users to choose and configure AI models based on their needs (e.g., OpenAI, Hugging Face, etc.).
    User Interface Changes:
    AI settings page: Configure AI model selection and preferences.
    Caption preview & edit section: Users can review and modify AI-generated captions.
    Bulk processing interface: Manage and process multiple media files at once.
    API Changes:
    Integration with AI APIs for NLP, image recognition, and metadata generation.
    Implement an adaptive feedback system where user corrections improve AI results.
    Data Model Changes:
    New database fields to store generated captions, alt tags, media tags, and user feedback for adaptive learning.
    Mentor Details
    Name : Binal Patel, [Senior / Experienced Drupal Developer - To be assigned]

    Email / Slack: @Binal Patel, [To be assigned]

    Project Size
    350 hours

    Project Difficulty
    Intermediate

    Project Skills/Prerequisite
    Proficiency in PHP and JavaScript
    Familiarity with Drupal module development
    Experience with AI/ML models and API integration (OpenAI, Hugging Face, Google Vision, etc.)
    Experience with Git, containerization (Docker), and RESTful APIs
    Good understanding of UI/UX principles and responsive design
    Project Resources
    Hugging Face Transformers
    OpenAI API Docs
    Google Cloud Vision API
    R&D Tasks
    Research AI models for caption generation, image recognition, and metadata extraction.
    Develop backend integration with AI APIs.
    Design and implement a user-friendly UI for media caption management.
    Ensure compliance with accessibility standards (WCAG, ARIA, etc.).
    Write module documentation and conduct testing.


    ~~~~~~~~~~

    Proposal 2025: AI-Powered Unified Accessibility Compliance Suite for Drupal

    Project Description
    This project aims to create an AI-driven Drupal module that audits and remediates accessibility issues across text, layout, and media content. Currently, Drupal administrators struggle with time-consuming manual accessibility audits that often miss context-dependent issues. The module will leverage computer vision, OCR, and NLP models to automatically scan pages for ADA/WCAG compliance issues, generate actionable remediation reports, and provide a dynamic dashboard to monitor issues, prioritize fixes based on impact severity, and implement one-click remediations where possible.

    Project Goal
    Dynamic Dashboard:
    Create a user-friendly dashboard to monitor website accessibility status and track remediation progress.
    Provide visualizations and reports for compliance documentation.
    Implement severity-based issue prioritization with configurable thresholds.
    Functional Changes / User Interface Changes:
    Integrate AI and accessibility APIs (e.g., Deque Axe) for automated scans of text, layout, and media.
    Use NLP models to suggest context-aware alt-text for media as part of remediation.
    Create an inline editor for quick fixes to identified accessibility issues.
    DB Changes / API Changes:
    Design database schema for storing accessibility audit results and remediation history.
    Create RESTful APIs for integration with external accessibility testing tools.
    Implement caching mechanisms to improve performance of repeated scans.
    Workflow Integration:
    Allow for the export of reports in common formats such as CSV, PDF, and WCAG-compatible documentation.
    Create a feedback system for users to rate AI-generated remediation suggestions.
    Integrate with Drupal's content workflow to include accessibility checks in the publishing process.
    Mentor Details
    Name: [To be assigned]
    Email / Slack: [To be assigned]

    Project Size
    350 Hours (Large)

    Project Difficulty
    Intermediate

    Project Skills/Prerequisite
    Expertise in Drupal module development and Drupal APIs.
    Proficiency in PHP, JavaScript, and Python for AI integration.
    Familiarity with AI frameworks (e.g., Hugging Face Transformers, OpenAI APIs).
    Experience with accessibility standards (WCAG 2.1/ADA) and tools like Axe.
    Understanding of semantic HTML and ARIA attributes.
    Technologies: PHP, JavaScript, Python, React, AI Frameworks, Axe Core, Drupal theme system.
    Project Resources
    Drupal Accessibility Handbook
    Deque Axe Accessibility Tools
    Drupal Module Development Guide
    GPTBot – AI Chatbot Integration for Drupal
    WCAG Guidelines and Resources
    Accessibility Checker for Drupal
    Axe Core GitHub Repository
    R&D Tasks
    Research AI models for accessibility analysis (e.g., Deque Axe, Hugging Face).
    Implement backend integrations with accessibility-focused AI providers.
    Design a UI for audit reporting and remediation, aligned with Drupal's accessibility standards.
    Evaluate existing accessibility modules like Siteimprove and Monsido for potential integration.
    Research automated testing frameworks that can validate accessibility fixes.
    Investigate machine learning approaches to recognize patterns in accessibility issues specific to Drupal sites.
    Similar Projects for Inspiration
    Editoria11y - In-CMS Accessibility Checker
    Site Audit - Framework for analyzing Drupal sites
    Microsoft Accessibility Insights
    Tota11y for Drupal

    ~~~~~~~~~~

    Proposal 2025: SARIF Integration for Error Reporting

    Project Description
    This project aims to enhance Drupal’s automated testing and error reporting ecosystem by integrating support for the Static Analysis Results Interchange Format (SARIF). SARIF is a standardized format for static analysis tool output, and by incorporating it into Drupal, developers will have a more consistent and efficient way to debug and analyze issues in both Drupal core and contributed modules. The proposed integration will enable Drupal’s CI pipeline to export error messages, linting reports, and test failures in SARIF format, making these results easily consumable by tools like GitHub Code Scanning, VS Code’s SARIF Viewer, and GitLab Security Dashboards.

    By developing a SARIF-compatible module or integration layer, the project will streamline the debugging process and facilitate better collaboration among developers, ultimately improving code quality and reducing turnaround time for fixes.

    Project Goal
    Functional Changes:
    Design and implement a conversion layer to translate Drupal’s CI output (errors, linting reports, test failures) into SARIF format.
    Develop a Drupal module or integration that automates the export of SARIF reports from the CI pipeline.
    Integrate the solution with popular CI/CD platforms such as GitHub Actions and GitLab CI for seamless workflow integration.
    Ensure compatibility with external tools including GitHub Code Scanning, VS Code’s SARIF Viewer, and GitLab Security Dashboards.
    Provide comprehensive documentation and usage guides to support adoption and future enhancements.
    Mentor Details
    Name & Slack: Royal Pinto
    Email / Slack: @royalpinto007

    Project Size
    350 hours

    Project Difficulty
    Intermediate

    Project Skills/Prerequisite
    Strong proficiency in PHP and JavaScript with hands-on experience in Drupal module development.
    Experience using Git for version control.
    Knowledge of compiler concepts and static analysis techniques, including ASTs and tokenization.
    Familiarity with CI/CD platforms, particularly GitHub Actions and GitLab CI.
    Understanding of standardized reporting formats and integration strategies.
    Project Resources
    SARIF Specification on GitHub
    Drupal Official Website
    Drupal Module Development Guide
    GitHub Actions Documentation
    GitLab CI Documentation
    R&D Tasks
    Research the SARIF specification and analyze Drupal’s existing CI output formats.
    Design a conversion layer that maps error messages, linting reports, and test failures to SARIF.
    Develop and integrate the SARIF module with Drupal’s CI pipeline to automate report generation.
    Establish integrations with GitHub Actions and GitLab CI to ensure seamless usage of SARIF reports.
    Conduct thorough testing, optimize performance, and prepare detailed documentation and tutorials for end users.


    ~~~~~~~~~~

    Proposal 2025: Entity Display Manager Module

    Project Description
    This project is focused on developing the Entity Display Manager Module for Drupal, designed to enhance field display customization by offering extended control over HTML structures, field output rewrites, and entity view mode configurations. The module addresses common development pain points by enabling site builders to manage field rendering without resorting to custom theming or complex preprocess hooks. By streamlining the display management process, the module aims to significantly speed up development workflows and improve the overall flexibility of Drupal's presentation layer.

    Project Goal
    Functional Changes:
    Introduce custom field display settings with options to enable or disable the Field HTML wrapper, Label HTML wrapper, and default field classes.
    Implement a template override mechanism for advanced customization of field output.
    Provide robust field rewrite options to allow custom text overrides, transformation of fields into clickable links, character limit trimming, HTML tag stripping, and removal of extraneous whitespace.
    Extend entity view modes by allowing bundle-specific configurations and custom display settings per view mode.
    Seamlessly integrate the new settings into Drupal’s UI under the Manage Display section, utilizing field formatters or preprocess hooks as needed.
    Mentor Details
    Name: stanzin

    Email / Slack: @stan

    Project Size
    350 hours

    Project Difficulty
    Intermediate

    Project Skills/Prerequisite
    Strong proficiency in Drupal module development and a deep understanding of Drupal's entity and field systems.
    Expertise in PHP and familiarity with Drupal’s theming system, including template overrides and preprocess hooks.
    Experience with front-end technologies such as HTML, CSS, and JavaScript for effective UI integration.
    Understanding of configurable display settings and the nuances of entity view mode configurations.
    Knowledge of best practices in module design and development to ensure maintainability and performance.
    Project Resources
    Drupal Documentation
    Understanding Drupal’s Entity API
    Drupal Theming Guide
    R&D Tasks
    Analyze current limitations in Drupal's field display customization and identify key areas for enhancement.
    Design the module architecture to introduce extended control over HTML wrappers, field classes, and output rewrites.
    Develop custom configuration settings within the Manage Display interface, including checkboxes and template override options.
    Implement comprehensive field rewrite functionalities such as custom text, link transformations, character limit trimming, HTML stripping, and whitespace normalization.
    Extend entity view mode configurations to support bundle-specific custom display settings.
    Conduct thorough testing across different Drupal environments and document configuration guidelines and usage instructions.
    Key Features
    Custom Field Display Settings:
    Enable/disable field and label HTML wrappers.
    Remove default field classes.
    Provide template override options for advanced customization.
    Field Rewrite Options:
    Override field output with custom text.
    Transform fields into custom links.
    Implement character limit trimming for field values.
    Strip HTML tags and remove unnecessary whitespace from field output.
    Entity View Mode Configuration:
    Extend entity view modes to support custom display settings.
    Allow bundle-specific configurations per entity view mode.
    Integration with UI:
    Add settings under "Manage Display" in the entity form display.
    Implement a field formatter or use preprocess hooks for modifications.















      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/drupal-association/
    idea_list_url: https://www.drupal.org/project/issues/gsoc?text=2025&status=All&priorities=All&categories=All&version=All&component=All


  - organization_id: 36
    organization_name: Eclipse Foundation
    no_of_ideas: 4
    ideas_content: |
        Agentic UI Framework for Eclipse LMOS
        Description 
        Eclipse LMOS has established a strong foundation for multi-agent backend architecture, enabling true backend agents that operate independently. However, the user interface (UI) has not yet been designed with the same agentic principles. This project aims to create an Agentic UI Framework specifically for agent builders using LMOS. The framework will provide a unified, configurable interface for deploying, managing, and configuring backend agents, allowing agent builders to efficiently oversee agent operations.

        The goal is to design a UI system where agent builders interact with their deployed agents in a natural, goal-driven manner, rather than manually configuring settings or navigating complex menus. This would involve:

        UI agents that dynamically emerge based on the context and operational needs of agent builders.
        A single, centralized interface for managing all LMOS agent deployments and configurations.
        Extensible UI components that align with agentic principles, enabling customization for different agent use cases.
        Benefits to the Community

        Empowers agent builders with an intuitive UI for configuring and managing LMOS agents.
        Simplifies interactions for non-technical users by abstracting complexity while providing advanced controls for experienced developers.
        Creates a specialized UI framework that aligns with LMOS’s multi-agent backend and enhances agent deployment workflows.
        Enables flexible, adaptive user interfaces that evolve based on agent builder requirements.
        Links to Eclipse Project
        Eclipse LMOS @ EF PMI
        Eclipse LMOS Website
        Expected outcomes 
        Initial Agentic UI Framework – A set of UI components that dynamically instantiate based on agentic needs.
        Prototype Interface for Agent Control – A single UI where users can control, configure, and observe agent activity.
        Integration with ARC View – Extending the ARC View to function as a local dev platform for UI-driven agent workflows.
        Extensibility Support – Ensuring that new agents can seamlessly introduce new UI components.
        Skills required/preferred 
        React & Modern Frontend Expertise: Strong skills in React, JavaScript, HTML, and CSS for building the UI.
        Dynamic & Adaptive UI Design: Ability to create UIs that change based on context and user needs.
        Agent System Understanding: Basic knowledge of agent concepts to build an effective agent-focused UI.
        Extensible Component Architecture: Skill in designing modular UI components that can be easily expanded.
        Project size 
        175 hours or 350 hours (scope can be adjusted)

        Possible mentors: 
        Arun Joseph
        Robert Winkler
        Patrick Whelan
        Kai Kreuzer

        ~~~~~~~~~~


        [Eclipse 4diac] Improving the Usability of the 4diac IDE's State Machine Editor


        Description 
        Over the last years, the several graphical editors in 4diac IDE were reworked to make them more usable and to reduce the number of user interactions. These are, for example, the FB network editor or the FB interface editor. One editor that didn't get this treatment is the state machine editor. With this project, we would like to explore what issues we have in this editor and how we can improve the usability of this editor. Topics of a potential project are:

        identify usability issues
        group them regarding implementation effort
        fix usability issues
        document results


        Links to Eclipse Project

        Both to the Eclipse 4diac and Project Repository.

        Expected outcomes 

        List of usability issues
        List of potential improvements
        Improved editor
        Documentation of results


        Skills required/preferred 
        Strong programming skills in Java and knowledge of Eclipse GEF Classic are required.

        Project size 
        175 hours or 350 hours (scope can be adjusted)

        Possible mentors: 
        Alois Zoitl

        Rating 
        Hard

        ~~~~~~~~~~

        GlitchWitcher: AI-assisted Bug Prediction



        Description 
        Defects exist in source code.  Some defects are easily found during code reviews, some are revealed by proper unit or integration testing.  Before code is reviewed and the code is executed during testing, there are other ways to detect where bugs may be lurking.
        The intent of this project is to trial and compare 2 approaches to predicting where defects live in source code.  There are a lot of different research papers that exist that discuss different algorithms that assist in finding defects.  This project will focus on implementation of 2 approaches.

        Approach 1: Predicting Faults from Cached History
        This first approach is a relatively simple, inexpensive technique for predicting where bugs live.  It is outlined in this research paper [1].  We would revive an earlier prototype of BugTools [2], which is a utility that applies the BugCache/FixCache algorithm to selected Github repositories to return scores against the different files in the repositories, as per the algorithm outlined in the paper.  Those with the highest hit rates are the most likely to contain defects, so are the more important to cover thoroughly with tests.
        This phase of the project is not expected to take very long, it is really to warm up to the idea of analyzing source code and integrating a new verification ‘check’ into a workflow of a Github repository.  This utility would report top 10 files that are most likely to contain defects.

        Approach 2: Reconstruction Error Probability Distribution (REPD) model
        The 2nd approach utilizes a supervised anomaly detection/classification model outlined in this research paper [3] to categorize defective and non-defective code.  This approach is much more involved.  Section 3 of the paper describes the model in use, while section 4 describes the methodology.  They train against datasets from NASA ESDS Data Metrics project [4].
        As part of this project, participants are asked to try and reproduce the REPD model described in this paper and apply it to both the data used by the researchers to see if similar results are found and then apply it to a separate C/C++ code base such as OpenJ9 [5] or OpenJDK [6] (or both).
        Ideally, one of the outcomes of this project would be to compare the results found with Approach A versus Approach B when applied against the same codebase.  A second outcome of this work would be to incorporate an interim verification check against a source code repository, perhaps on the cadence of every time a new tag is applied.

        Reference Links
        [1] https://web.cs.ucdavis.edu/~devanbu/teaching/289/Schedule_files/Kim-Predicting.pdf
        [2] https://github.com/adoptium/aqa-test-tools/tree/master/BugPredict/BugTool
        [3] https://www.sciencedirect.com/science/article/abs/pii/S0164121220301138
        [4] https://www.earthdata.nasa.gov/about/data-metrics
        [5] https://github.com/eclipse-openj9/openj9
        [6] https://github.com/adoptium/jdk

        Links to Eclipse Projects / Repositories

        https://projects.eclipse.org/projects/adoptium.aqavit
        https://projects.eclipse.org/projects/adoptium.temurin
        https://projects.eclipse.org/projects/technology.openj9
        https://github.com/adoptium/aqa-tests
        https://github.com/adoptium/aqa-test-tools
        https://github.com/eclipse-openj9/openj9
        https://github.com/adoptium/jdk (mirror of upstream repository)

        Expected outcomes 


        Trialing 2 different approaches (implemented as static analysis 'utilities’) to predict source code defects in a given source code base


        A comparison of the 2 approaches (do they identify the same files in a code base as ‘most likely’ containing bugs)


        An additional way to flag areas of code that need more scrutiny during code reviews and a greater emphasis during testing


        A verification check (or workflow, a.k.a. GlitchWitcher) that runs these static analysis utilities against pull requests in a repository



        Skills required/preferred 


        Languages & Frameworks: Python (for ML and automation), Git APIs, NLP libraries (e.g., SpaCy, BERT, GPT-based models).  Awareness of different classifiers (Gaussian Naive Bayes, logistic regression, k-nearest-neighbors, decision tree, and Hybrid SMOTE-Ensemble) and statistical analysis will be helpful.


        CI/CD Integration: GitHub Actions, Jenkins


        Database & Storage: MongoDB (or PostgreSQL/MySQL) for storing historical build data and test results.


        Deployment: integration with current development workflow and pipelines



        Project size 
        350 hours

        Possible mentors: 

        Lan Xia lan_xia@ca.ibm.com

        Longyu Zhang longyu.zhang@ibm.com

        Shelley Lambert slambert@redhat.com



        Rating 
        medium - hard


        ~~~~~~~~~~

        CommitHunter: AI-Powered Commit Debugger

        Description 
        The goal of this project is to develop an automated system that identifies problematic Git commits causing test failures in both performance and non-performance test scenarios. Given a "Good" build (where tests pass) and a "Bad" build (where tests fail), the system will analyze all intermediate commits to pinpoint the problematic commit(s). The approach will evolve from rule-based methods to AI-driven models for higher accuracy.
        Phase 1: Rule-Based Approach
        Use Rule based approach and below are some examples:

        String Matching: Identify test failure messages and correlate them with commit messages, logs, or diffs.
        Binary Search for Performance Tests: Implement a binary search approach to efficiently narrow down the commit range in performance test failures.

        Phase 2: Machine Learning Model

        Train an ML model using historical build data, commit logs, and failure reports.
        Utilize supervised learning techniques to classify commits as "Likely Problematic" or "Safe."
        Use natural language processing (NLP) to analyze commit messages and correlate them with test failures.

        Phase 3: Automation and Integration

        Integrate the approach with Git repositories (e.g., GitHub) via APIs.
        Develop a bot to automatically comment on Git issues with the identified problematic commit(s) if confidence levels meet a reliability threshold.
        Provide a dashboard for tracking identified problematic commits and their validation over time.


        Links to Eclipse Project


        https://github.com/eclipse/openj9
        https://github.com/adoptium/aqa-tests
        https://github.com/adoptium/aqa-test-tools
        https://projects.eclipse.org/projects/technology.openj9
        https://projects.eclipse.org/projects/adoptium.aqavit


        Expected outcomes 

        Reduction in manual effort needed to debug and triage test failures.
        Faster identification of problematic commits leading to improved development efficiency.
        A scalable system that can be expanded with improved AI models that can apply to other project and team.


        Skills required/preferred 

        Languages & Frameworks: Python (for ML and automation), Git APIs, NLP libraries (e.g., SpaCy, BERT, GPT-based models).
        CI/CD Integration: GitHub Workflow, Jenkins
        Database & Storage: MongoDB (or PostgreSQL/MySQL) for storing historical build data and test results.
        Deployment: integration with current development workflow and pipelines.


        Project size 
        350 hours

        Possible mentors: 

        Shelley Lambert slambert@redhat.com

        Lan Xia lan_xia@ca.ibm.com

        Longyu Zhang longyu.zhang@ibm.com



        Rating 
        Medium - hard







      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/eclipse-foundation/
    idea_list_url: https://gitlab.eclipse.org/eclipsefdn/emo-team/gsoc-at-the-ef/-/issues/?sort=due_date&state=opened&label_name%5B%5D=Project%20Idea&label_name%5B%5D=GSoC%202025&first_page_size=50


  - organization_id: 37
    organization_name: Electron
    no_of_ideas: 7
    ideas_content: |
    
       Electron Documentation PR Previews
      Size: 175 Hours (Medium)
      Difficulty: Medium
      Tags: JavaScript, Static Site Generators, MDX, Automation, GitHub Actions
      Scope: Electron maintains its documentation as MDX files in the main electron/electron repository, but the website lives in a separate repo that pulls in the docs as content via webhook.
      There’s a disconnect in our system between when docs get merged and when they appear on the website, so it’s easy for formatting issues to appear. This project would aim to create automation tooling that would create an ephemeral deployment of the website for each PR containing doc changes which previews the website with the changes, and link it as a comment on the PR.
      A previous version of this project idea referenced Heroku Review Apps as the technology of choice for implementation. While we still have access to Heroku deployments, the website has migrated its PR deploys to use Cloudflare Pages instead. Either technology would be available for a GSoC project.
      Success Criteria: A successful project will produce documentation PR previews and create a comment on PRs linking that preview. Ideally, previews from PRs coming from forks would still work.
      Skills:
      TypeScript/JavaScript (required)
      Resources:
      Website Repo: https://github.com/electron/website
      Heroku Review App APIs: Platform API Reference | Heroku Dev Center
      Cloudflare Preview Deployments
      Mentors:
      @dsanders11
      @erickzhao
      @yangannyx

      ~~~~~~~~~~
       Save/Restore Window State API
      Size: 175 Hours (Medium)
      Difficulty: Hard
      Tags: Electron Core, Feature, Chromium, C++, API development
      Scope: Currently Electron does not have any built-in mechanism for saving and restoring the state of BrowserWindows, but this is a very common need for apps that want to feel more native. Create an API in Electron to save, restore, and clear window state: position, size, maximized state, etc.
      Success Criteria:
      API spec is accepted by Electron’s API working group
      New window state API is added to the BrowserWindow module and merged into the main branch for a future Electron release
      Proper API documentation is added
      Skills:
      C++ (required)
      Resources:
      GitHub issue tracker discussion: https://github.com/electron/electron/issues/526
      Popular userland module for this feature: GitHub - mawie81/electron-window-state: A library to store and restore window sizes and positions for your Electron app https://github.com/mawie81/electron-window-state
      Electron’s BrowserWindow API docs
      Mentors:
      @dsanders11
      @vertedinde
      @georgexu99

      ~~~~~~~~~~
       Electron Forge CLI UX Improvements
      Size: 175 Hours (Medium)
      Difficulty: Medium
      Tags: Electron Forge, TypeScript, Node.js, Bash, CLI tools
      Scope: Electron Forge is a complete tool for building and publishing Electron applications. In 2022, Forge became the official packaging tool for Electron. However, Forge’s CLI is not as user friendly and modern as other tools in the JS ecosystem. This project would update the UX for the Forge CLI to make it easier for developers to create new Electron apps entirely from the command line.
      Success Criteria:
      The Electron Forge CLI is updated to include accurate flows from init, start, package and other major commands and expanded to allow configuring the options most commonly used by users.
      A new interactive mode to allow for a more user friendly experience.
      Tested cross-platform on Mac, Windows and Linux
      Stretch goals would include adding new features to the CLI
      Skills:
      Typescript/Javascript (required)
      Bash (recommended)
      Node.js (recommended)
      Resources:
      Electron Forge Documentation: https://www.electronforge.io/
      Forge Docs Repo: https://github.com/electron-forge/electron-forge-docs
      Mentors:
      @dsanders11
      @erickzhao
      @blackhole1

      ~~~~~~~~~~
       Electron Fiddle in VS Code
      Size: 175 Hours (Medium)
      Difficulty: Medium
      Tags: Electron Fiddle, TypeScript, Node.js, VS Code
      Scope: Electron Fiddle is a standalone tool used daily by Electron maintainers to help debug and fix issues reported in Electron, and is the best way for developers to provide minimal repro cases for their bug reports. This project would involve taking the internals of Electron Fiddle and integrating them as a VS Code extension, to allow using Fiddle’s logic without leaving the IDE, and more easily use Fiddle with a local build of Electron. This would require a reimagining of the Electron Fiddle UX to work within the constraints of the UI/UX available to VS Code extensions, rather than a 1:1 port of the UI from the standalone Electron Fiddle.
      Success Criteria:
      A working VS Code extension which integrates @electron/fiddle-core to provide an Electron Fiddle experience, with emphasis on more easily working with local builds of Electron.
      Ability to import/export GitHub Gists, integrating with VS Code’s existing GitHub auth.
      Skills:
      TypeScript/JavaScript (required)
      Node.js (preferred)
      Resources:
      Electron Fiddle: https://electronjs.org/fiddle
      fiddle-core repo, with Fiddle’s core logic: https://github.com/electron/fiddle-core
      Visual Studio Code Extension API
      Mentors:
      @dsanders11
      @blackhole1
      @georgexu99

      ~~~~~~~~~~
       Releases Working Group Calendar Website
      Size: 175 Hours (Medium)
      Difficulty: Easy/Medium
      Tags: Electron, web, APIs
      Scope: Electron’s Releases Working Group currently have several tracks of automation that help us track and communicate details about Electron’s major stable releases. However, the various tracks of automation are currently disjointed, and don’t always communicate with each other. Additionally, we depend on an upstream Chromium release schedule that we update manually, a process we would like to automate.
      Success Criteria: This project asks the contributor to 1) add new automation to allow Electron to pull dates from Chromium’s upstream API and 2) make a barebones Release calendar website that the Electron team can view, based on Chromium's alpha, beta and stable release dates.
      Going above and beyond could include:
      Creating a page on releases.electronjs.org with the information
      Setting up a bot that allows the Electron team to update the calendar automatically or add additional dates and details
      Alerting #wg-releases and updating the calendar automatically if upstream dates change
      Skills:
      TypeScript/JavaScript (required)
      Express (preferred)
      HTML/CSS (preferred)
      Resources:
      Chromium’s releases API - https://chromiumdash.appspot.com/schedule
      Releases website - https://releases.electronjs.org/
      Release website repo - https://github.com/electron/release-status
      Mentors:
      @dsanders11
      @vertedinde
      @yangannyx

      ~~~~~~~~~~
       Electron Fiddle Support for Fuses
      Size: 175 Hours (Medium)
      Difficulty: Easy/Medium
      Tags: Electron Fiddle, TypeScript, Node.js
      Scope: Electron Fiddle is a standalone tool used daily by Electron maintainers to help debug and fix issues reported in Electron, and is the best way for developers to provide minimal repro cases for their bug reports. Electron fuses are feature toggles that are set when packaging an Electron app to enable / disable certain features / restrictions. Currently Electron Fiddle has no support for setting these fuses when running a fiddle, so it cannot be used to to provide repro cases for bug reports involving specific fuse settings. This project would add support to Fiddle for setting fuses before running the fiddle, and include the fuse values in any fiddles uploaded to GitHub Gists.
      Success Criteria:
      An intuitive UI is added to Electron Fiddle which allows users to view and toggle values for Electron fuses to be set on the next run.
      Fuse values are included in fiddles uploaded to a GitHub gist, and fuse values are set when loading a fiddle from a GitHub gist.
      Skills:
      TypeScript/JavaScript (required)
      Node.js (preferred)
      React (preferred)
      HTML/CSS (preferred)
      Resources:
      Electron Fiddle: https://electronjs.org/fiddle
      fiddle-core repo, with Fiddle’s core logic: https://github.com/electron/fiddle-core
      Electron fuses repo: https://github.com/electron/fuses
      Electron’s fuses docs
      Mentors:
      @dsanders11
      @erickzhao  
      @vertedinde

      ~~~~~~~~~~
       Restore Electron Devtron Extension
      Size: 175 Hours (Medium)
      Difficulty: Medium
      Tags: JavaScript, TypeScript, Chrome Extension, IPC, Developer Tool
      Scope: Inter-process communication (IPC) is a key part of building feature-rich desktop applications in Electron. App developers getting started with Electron often struggle in understanding IPC concepts and how to work with them; multiple processes and finding where IPC is sent and received isn’t straightforward. Devtron was a Chrome extension available for Electron which brought visibility to IPC events by adding a new tab under Chrome DevTools where each IPC event was logged. It was eventually deprecated due to a lack of available maintainers, and an aging codebase. This project would modernize the existing Devtron codebase or create a new Chrome extension from scratch (many APIs in Chrome and Electron have changed in the 10 years since Devtron was created) to fill this continuing need for app developers.
      Success Criteria:
      A successful project will produce a Chrome extension that, when installed to Electron, displays IPC events sent between processes.
      Skills:
      TypeScript/JavaScript (required)
      Chrome Extensions (preferred)
      Resources:
      Deprecated Devtron: 
      Chrome Extensions: Extend DevTools
      Electron’s IPC docs
      Mentors:
      @dsanders11
      @samuelmaddock
      @yangannyx
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/electron/
    idea_list_url: https://electronhq.notion.site/Electron-Google-Summer-of-Code-2025-Ideas-List-1851459d1bd1811894dad8b48a68596d

  - organization_id: 38
    organization_name: FFmpeg
    no_of_ideas: 6
    ideas_content: |
      
      WebRTC-HTTP ingestion protocol (WHIP)
      Description: The WHIP task only requires the implementation of basic streaming capabilities as outlined in https://www.ietf.org/archive/id/draft-ietf-wish-whip-16.txt. Given that WebRTC itself is extremely large and complex, FFmpeg has no plans to fully implement WebRTC capabilities in the short term. Therefore, it will only support the most basic ICE interaction capabilities, the most basic DTLS capabilities, and minimal modifications to FFmpeg's RTP/RTCP workflow to enable WHIP support.
      Expected results: This will allow FFmpeg users to quickly utilize FFmpeg for WHIP streaming.
      Prerequisites: Good C code, basic familiarity with Git, and basic knowledge of network transport protocols.
      Difficulty: Medium to Hard
      Qualification Task: Fix a random bug in an existing muxer, demuxer or protocol.
      Mentor: Steven Liu (lingjiujianke at gmail dot com)
      Backup Mentor: Zhao Jun (barryjzhao at tencent dot com)
      Duration: 350 hours

      ~~~~~~~~~~
      ProRes Vulkan decoder
      Description: Decoding of ProRes is quite important, as its the default mezzanine codec used in production. The bandwidth and CPU requirements for 4k and 8k streams are high, therefore, having a Vulkan-based implementation would be able to speed up the workflow of users, particularly those who do editing.
      Expected results: Write a ProRes decoder in Vulkan, specifically supporting the ap4h and ap4x profiles.
      Prerequisites: Good C, GLSL, and Vulkan knowledge.
      Difficulty: Hard
      Qualification Task: Write and validate the ProRes DCT transform in GLSL.
      Mentor: Lynne (Lynne in #ffmpeg-devel on Libera.Chat IRC)
      Backup Mentor: Niklas Haas (haasn in #ffmpeg-devel on Libera.Chat IRC)
      Duration: 350 hours

      ~~~~~~~~~~
      VVC wasm simd optimization
      Description: Using WASM SIMD to optimize VVC decoding performance in WASM environment (web browser or wasi)
      Expected results: Add ALF, inter, and SAO implementation. More is better.
      Prerequisites: Good C knowledge, basic shell script skills and understanding of compilation and build processes.
      Difficulty: Medium.
      Qualification Task: Fix a random bug in FFmpeg. Build and run ffmpeg checkasm in wasm. It's easy to be done with wasi runtime like wasmtime.
      Mentor: Zhao Zhili (zhilizhao at tencent dot com)
      Backup Mentor: Nuo Mi (nuomi2021 at gmail dot com)
      Duration: 350 hours

      ~~~~~~~~~~
      VVC ARM simd optimization
      Description: Using ARM simd to optimize VVC decoding performance in arm64 environment.
      Expected results: Implement inverse transform and intra prediction using arm64 instructions.
      Prerequisites: Good C knowledge. Basic ARM assembly programming skills.
      Difficulty: Hard.
      Qualification Task: Fix a random bug in FFmpeg. Build and run ffmpeg checkasm in arm64.
      Mentor: Zhao Zhili (zhilizhao at tencent dot com)
      Backup Mentor: Nuo Mi (nuomi2021 at gmail dot com)
      Duration: 350 hours

      ~~~~~~~~~~
      VVC x86 simd optimization
      Description: Using x86 simd to optimize VVC decoding performance in x86 environment.
      Expected results: Implement inverse transform or intra prediction using x86 instructions.
      Prerequisites: Good C knowledge. Basic x86 assembly programming skills.
      Difficulty: Hard.
      Qualification Task: Any patch merged by ffmpeg
      Mentor: Nuo Mi (nuomi2021 at gmail dot com)
      Backup Mentor: Lynne (Lynne in #ffmpeg-devel on Libera.Chat IRC)
      Duration: 350 hours
      
      ~~~~~~~~~~
      VP6 encoder
      Description: Write a basic non-performant progressive VP6 encoder, starting with keys frames and adding motion compensation frames later.
      Expected results: Bitstreams produced by the encoder are decodable using FFmpeg VP6 decoder and original On2 VP6 decoder binary.
      Prerequisites: Good C knowledge, some understanding of MPEG-type video compression would be useful.
      Difficulty: Medium.
      Qualification Task: Fix a random bug in FFmpeg _or_ extend libavcodec/vpx_rac.h to support encoding
      Mentor: Peter Ross (pross at xvid dot org)
      Backup Mentor: will be choosen before project begin, the admins will serve as backup before that
      Duration: 350 hours
     
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/ffmpeg/
    idea_list_url: https://trac.ffmpeg.org/wiki/SponsoringPrograms/GSoC/2025

  - organization_id: 39
    organization_name: FLARE
    no_of_ideas: 10
    ideas_content: |
      


      capa: add Binary Ninja Explorer plugin
      size: medium, estimated 175 hours
      difficulty: medium
      mentors: @williballenthin
      link: mandiant/capa#169
      capa is the FLARE team's open-source tool to identify program capabilities using an extensible rule set.
      Binary Ninja (Binja) is a modern disassembler and reverse engineering tool with a robust Python API that facilitates plugin development. A capa Explorer plugin for Binary Ninja would significantly enhance the workflow of reverse engineers who use Binja, allowing them to seamlessly identify and analyze program capabilities within their preferred environment. This project would not only benefit Binja users but also expand the reach and adoption of capa within the reverse engineering community.
      The core functionality of the plugin would be to:
      Use capa's existing Binary Ninja backend to find capabilities in the currently open binary.
      Display the capa results in a user-friendly manner within Binary Ninja. This includes displaying matching rules, the locations of matched features, and potentially the associated source code (if debug information is available).
      Allow users to navigate from the capa results to the corresponding locations in the disassembly view. This is crucial for efficient analysis, enabling users to quickly jump to the code responsible for a detected capability.
      Deliverables:
      Results Display:
      Implement a custom dock widget (view) in Binary Ninja to display the capa results.
      Display a hierarchical tree view of matching rules, grouped by namespace (e.g., "anti-analysis", "communication").
      Show the rule name, description (short summary), and match status.
      Display the locations (addresses) of matched features within each rule.
      Implement filtering and searching capabilities within the results view. Allow users to filter rules by namespace, ATT&CK technique, or keyword.
      Highlight matched features directly in the disassembly view using Binary Ninja's highlighting API.
      Navigation:
      Enable double-clicking on a rule or feature location in the results view to navigate to the corresponding address in the Binary Ninja disassembly view. Highlight the relevant instruction(s).
      Add tags/bookmarks for the matches.
      Rule Selection:
      Basic UI for user to select a file path that contains the rulesets they'd like to use.
      Testing and Documentation:
      Write basic unit tests for the plugin's core functionality.
      Create user documentation explaining how to install and use the plugin.
      Blog Post:
      Document the development process and findings in a blog post suitable for publication on the Mandiant blog or a similar platform.
      Required Skills:
      Solid knowledge of Python 3.
      Experience with Binary Ninja's API (or strong willingness to learn).
      Basic understanding of reverse engineering concepts (disassembly, assembly language, executable file formats).
      Experience with Git and GitHub.
      Potential Challenges and Mitigation Strategies:
      Binary Ninja API Learning Curve: Binary Ninja's API is extensive, but well-documented. The contributor should allocate time for learning the API and exploring existing plugins. The mentors can provide guidance and point to relevant examples.
      Performance Optimization: Running capa on large binaries can be time-consuming. The plugin should be designed to handle large analysis results efficiently and provide progress feedback to the user. Asynchronous execution and caching strategies can be employed.
      UI Design: Provide the user an intuitive way to interact with the plugin.
      
      ~~~~~~~~~~
      capa: add Ghidra Explorer plugin
      size: medium, estimated 175 hours
      difficulty: medium
      mentors: @mike-hunhoff
      link: mandiant/capa#1980
      capa is the FLARE team's open-source tool to identify program capabilities using an extensible rule set. Currently, analysts often invoke capa as a command-line tool or via the capa Explorer plugin for IDA Pro. This project aims to bring the interactive rule exploration experience of capa Explorer to Ghidra, a powerful and extensible reverse engineering platform developed by the NSA.
      Ghidra is a free and open-source software reverse engineering (SRE) framework. It includes a suite of tools for analyzing compiled code on a variety of platforms. Ghidra's extensibility is a key feature, and recently, the PyGhidra project has provided Python bindings for the Ghidra API, enabling plugin development in Python. A capa Explorer plugin for Ghidra would greatly enhance the workflow of reverse engineers who rely on Ghidra, allowing them to seamlessly integrate capa's capability detection into their analysis process. This project would benefit both Ghidra users and expand the user base of capa.
      The core functionality of the plugin would be to:
      Use capa's existing Ghidra backend to find capabilities in the currently open binary.
      Display the capa results in a user-friendly manner within Ghidra. This includes showing matching rules, the locations of matched features (addresses, function names, etc.), and potentially linking to the relevant decompiler output.
      Allow users to navigate from the capa results to the corresponding locations in the Ghidra disassembly listing and decompiler views. This is critical for efficient analysis, enabling users to quickly jump to the code associated with a detected capability.
      Deliverables:
      Results Display:
      Implement a custom Ghidra Tool window or panel to display the capa results.
      Display a hierarchical tree view of matching rules, grouped by namespace (e.g., "anti-analysis", "communication").
      Show the rule name, description, and match status.
      Display the locations of matched features within each rule.
      Implement filtering and searching capabilities within the results view. Allow users to filter rules by namespace, ATT&CK technique, or keyword.
      Highlight matched features directly in the Ghidra listing view using Ghidra's highlighting API.
      Navigation:
      Enable double-clicking on a rule or feature location in the results view to navigate to the corresponding address in the Ghidra disassembly listing view.
      Highlight the relevant instructions.
      Rule Selection:
      Provide a basic UI for the user to select the file path containing the desired rulesets.
      Testing and Documentation:
      Write basic unit tests for the plugin's core functionality.
      Create user documentation explaining how to install and use the plugin.
      Blog Post:
      Document the development process, challenges and finding in a blog post.
      Required Skills:
      Solid knowledge of Python 3.
      Experience with Ghidra and PyGhidra (or strong willingness to learn). Familiarity with Java is a plus, but not strictly required due to PyGhidra.
      Basic understanding of reverse engineering concepts (disassembly, assembly language, executable file formats).
      Experience with Git and GitHub.
      Potential Challenges and Mitigation Strategies:
      PyGhidra Learning Curve: While PyGhidra simplifies Ghidra plugin development, the student will still need to learn the PyGhidra API and how it interacts with Ghidra's underlying Java API. The mentors can provide guidance and point to relevant examples.
      Performance Optimization: Running capa on large binaries can be time-consuming. The plugin should handle large results efficiently and provide feedback to the user. Asynchronous execution and caching can help.
      UI Design: Design the user interface to be intuitive within the Ghidra environment.

      ~~~~~~~~~~
      capa: add Frida dynamic analysis for Android
      size: large, estimated 350 hours
      difficulty: hard
      mentors: @larchchen
      capa is the FLARE team's open-source tool to identify program capabilities using an extensible rule set.
      Frida is a popular dynamic instrumentation toolkit for developers, reverse-engineers, and security researchers, allowing custom scripts injected into black box processes thus monitoring program behaviors. Frida is a particularly preferred option to analyze Android Apps by launching Apps in Android Emulator and intercepting certain function calls.
      In addition to the capa's dependencies on CAPE sandbox during dynamic capabilities detection, Frida is a more friendly alternative for mobile App analysis. With the possibilities of using existing Frida scripts and/or developing new Frida scripts, extending capa's dynamic detection upon logs generated from Frida logs would be a good start. Integrating capa rule matching engine with Frida scripts could be another bonus approach. The goal of this project is to support capa rule matching capabilities in Android via Frida instrumentation framework.
      Deliverables
      Research
      Review capa's existing support of dynamic capabilities detection
      Review Frida's instrumentation framework
      Identify Additions, Changes, and Improvements
      Suggest technical roadmaps to support Frida-capa detection
      Discuss ideas with mentors and capa user community
      Implementation
      Implement ideas aligned with finalized roadmaps
      Evaluation and Knowledge Sharing
      Test deliverables and gather feedback from users
      Write blog post about experience and project achievements
      Required Skills
      Solid knowledge of Python 3
      Solid knowledge of one of JavaScript/C/Go
      Basic understanding of reverse engineering / malware analysis
      Basic understanding of Git
      Basic understanding of Android App analysis using Android Emulator
      Basic understanding of Frida

      ~~~~~~~~~~
      capa: migrate to PyGhidra
      size: small, estimated 90 hours
      difficulty: low
      mentors: @mike-hunhoff
      link: mandiant/capa#2600
      This project aims to modernize the existing capa Ghidra backend by migrating it from the third-party Ghidrathon Python bindings to the officially supported PyGhidra bindings, released with Ghidra 11.3. Since PyGhidra is distributed with Ghidra, we expect this to have better long term support and be easier for users to access. This migration will ensure the long-term maintainability and compatibility of the capa plugin with future Ghidra releases.
      Deliverables:
      Port Existing Functionality: Migrate the existing capa Ghidra backend's code to use the PyGhidra API. This primarily involves updating API calls and adapting to any differences in how PyGhidra interacts with Ghidra.
      Testing: Thoroughly test the migrated plugin to ensure that all existing features function correctly with PyGhidra.
      Documentation Updates: Update the plugin's documentation to reflect the change to PyGhidra and provide installation instructions for users.
      Required Skills:
      Basic Python programming skills.
      Familiarity with Ghidra and its scripting capabilities, or willingness to learn.
      Experience with Git and GitHub.
      Understanding of capa is a plus, but not required for this project.

      ~~~~~~~~~~
      capa: add ARM support to IDA Pro, Ghidra, and/or Binary Ninja backends
      size: small to large
      difficulty: medium
      mentors: @mr-tz
      link: mandiant/capa#1774
      This project aims to extend capa's support for analyzing programs targeting the ARM architecture across its major analysis backends: IDA Pro, Ghidra, and Binary Ninja. While capa's core analysis engine (via the BinExport2 backend) already supports ARM, the backends for these popular disassemblers currently lack direct feature extraction for this architecture. This project will bridge that gap, enabling users to analyze ARM binaries seamlessly within their preferred reverse engineering environments.
      The core task involves extending the existing backends to extract relevant features (instructions, API calls, constants, etc.) from ARM binaries loaded in IDA Pro, Ghidra, and Binary Ninja. This will leverage the respective disassembler APIs to access the disassembled code and program information. The extracted features will then be formatted and passed to capa's core analysis engine.
      Deliverables:
      update capa IDA Pro backend (optional, pick 1-3)
      update capa Ghidra backend (optional, pick 1-3)
      update capa Binary Ninja backend (optional, pick 1-3)
      Testing: Develop test cases (ARM binaries with known capabilities) and verify that capa correctly identifies capabilities in these binaries through each of the extended plugins.
      Documentation: Update the documentation for each plugin to reflect the added ARM support.
      Required Skills:
      Solid Python programming skills.
      Familiarity with at least one of: IDA Pro, Ghidra, or Binary Ninja, and their respective plugin APIs (or willingness to learn quickly).
      Basic understanding of the ARM architecture and assembly language.
      Experience with Git and GitHub.

      ~~~~~~~~~~
      FLOSS: extract language specific strings (.NET, Swift, Zig, ...)
      size: large, estimated 350 hours
      difficulty: medium
      mentors: @mr-tz
      link: mandiant/flare-floss#718
      Various programming languages embed the constant data, like strings, used within executables in different ways. Most tools, like strings.exe, just look for printable character sequences. This doesn't work well for files compiled from Go or Rust.
      Here we propose to extend FLOSS to include a framework to extract language specific strings from executables. After identifying the language, a specific extractor can use specialized logic to pull out the strings embedded into a program by the author. When possible, the extractor should indicate library and runtime-related strings. For example, the extractor may parse debug information to recognize popular third party libraries and annotate the related strings appropriately.
      Today, FLOSS automatically deobfuscates protected strings found in malware. Better categorization of its output would make its users more efficient. Extracting language-specific strings would make FLOSS more useful and manifest success as the default tool used by security analysts.
      Deliverables
      Develop language identification module
      Initial focus on .NET
      Consider also Swift, Zig, …
      Research language string embeddings and create extractor code
      We can share existing knowledge and code to bootstrap this
      Identify strings related to runtime and library code for targeted programming languages
      Extend standard output format and render results
      Required Skills
      Medium knowledge of Python 3
      Basic understanding of reverse engineering (focus: Windows PE files)
      Experience with .NET or Swift (internals) is a plus, but not required
      Interest in malware analysis with focus on static analysis
      Basic understanding of Git

      ~~~~~~~~~~
      FLOSS: QUANTUMSTRAND
      size: large, estimated 350 hours
      difficulty: medium
      mentors: @williballenthin
      link: mandiant/flare-floss#943
      Extend FLOSS to use the rendering techniques pioneered by QUANTUMSTRAND.
      QUANTUMSTRAND is an experiment that augments traditional strings.exe output with context to aid in malware analysis and reverse engineering. For example, we show the structure of a file alongside its strings and mute/highlight entries based on their global prevalence, library association, expert rules, and more.
      FLOSS is a tool that automatically extracts obfuscated strings from malware, rendering the human-readable data in a way that enables rapid reverse engineering.
      We propose to extend FLOSS to use the techniques pioneered by QUANTUMSTRAND to highlight important information while muting common and/or analytically irrelevant noise. The project will provide an opportunity to dig into the PE, ELF, and/or Mach-O file formats, finding ways to make technical details digestible. If successful, FLOSS will continue to be the tool that malware analysts turn to when triaging unknown files.
      Deliverables
      Brand new output format released as part of FLOSS v4 in late 2025.
      Research
      Review Quantumstrand functionality
      Evaluate most useful features for integration into FLOSS
      Identify and Propose Improvements
      Suggest improvements for the user interface and experience
      Discuss ideas with mentors and FLOSS user community
      Implementation
      Implement improved functionality
      [stretch goal]: Work on a GUI to interactively display FLOSS results
      Evaluation and Knowledge Sharing
      Test improvements and gather feedback from users
      Write blog post about experience and project achievements
      Required Skills
      Solid knowledge of Python 3
      Basic understanding of reverse engineering / malware analysis
      Basic understanding of Git
      Experience or interest with file formats such as PE, ELF, and/or Mach-O
      Experience or interest in user interface and/or user experience design

      ~~~~~~~~~~
      BinDiff: rearchitect Binary Diff Server and port to PyQt
      size: large, estimated 350 hours
      difficulty: hard
      mentors: @cblichmann
      link: google/bindiff#17
      This project aims to modernize BinDiff by re-architecting it as a cross-platform "diffing service" with a unified UI layer. The core idea is to separate the diffing engine from the user interface. A "diff server," implemented (likely in C++ or Rust for performance), will handle the core diffing logic. This server will load BinExport files and perform the diffing computations. It will communicate with client plugins via a protocol like gRPC.
      Client plugins will be developed for IDA Pro and Binary Ninja, using a shared Python codebase and PyQt for the UI. Each disassembler will have a small, platform-specific module to handle tasks like symbol porting. This architecture promotes code reuse and simplifies maintenance. Keeping the diff server running in the background allows for dynamic re-diffing as binaries are modified, and opens up possibilities for improved flow graph visualization by combining data from multiple functions.
      The project scope is intentionally flexible, allowing the student and mentors to collaboratively define the specific features and implementation details. The focus will be on establishing a solid foundation for the new architecture and demonstrating its feasibility.
      Deliverables (Flexible, to be refined during the project):
      Diff Server Prototype:
      Design and implement a basic "diff server" that can load BinExport files and perform a simple diffing algorithm.
      Implement a communication protocol (e.g., gRPC) for interaction with client plugins.
      Shared UI Library (Python/PyQt):
      Develop a shared Python library using PyQt that provides the core UI components for displaying diffing results. This includes views for function lists, matched/unmatched functions, and potentially basic flow graph comparisons.
      IDA Pro and Binary Ninja Plugins:
      Create basic plugins for IDA Pro and Binary Ninja that utilize the shared UI library and communicate with the diff server.
      Implement symbol porting.
      Demonstrate basic diffing functionality within each disassembler.
      Proof of Concept:
      Demonstrate the ability to load two BinExport files, perform a diff, and display the results in both IDA Pro and Binary Ninja.
      Documentation:
      Document the design, architecture, and API of the diff server and client plugins.
      Required Skills:
      Solid knowledge of Python 3 and C++ and/or Rust.
      Experience with or willingness to learn PyQt.
      Experience with or willingness to learn gRPC.
      Basic understanding of binary diffing concepts.
      Familiarity with IDA Pro and Binary Ninja APIs (or strong willingness to learn).
      Experience with Git and GitHub.
      Potential Challenges:
      Defining the Scope: The open-ended nature of the project requires careful planning and communication between the student and mentors to define achievable goals.
      Inter-process Communication: Choosing and implementing an efficient and reliable communication protocol between the diff server and client plugins will be crucial.

      ~~~~~~~~~~
      XRefer: Build a Multi-Backend Abstraction Layer with Binary Ninja Support
      size: large, estimated 360 hours
      difficulty: medium
      mentors: @m-umairx
      XRefer is tightly coupled with IDA Pro, making it challenging to adapt for use with other popular reverse-engineering platforms like Ghidra or Binary Ninja. This project aims to refactor XRefer's core analyzer component, creating a new backend abstraction layer that standardizes how different platforms interact with the plugin's logic. Additionally, the project aims to aid support for Binary Ninja by implementing a new PoC backend.
      Note: This project focuses on creating and demonstrating an abstraction layer for XRefer's underlying analysis engine only. The user interface is not included in the project scope.
      Deliverables:
      Code Review
      Identify and document all places where IDA-specific APIs or data structures are used within the analyzer and lang components.
      Assess the feasibility and scope of decoupling those calls into a new abstraction layer.
      Design a Backend Interface
      Specify the APIs needed for core tasks (e.g., disassembly, cross-references, function discovery, flow analysis) that different backends must implement.
      Draft an interface or set of classes that each supported platform (IDA, Ghidra, Binary Ninja, etc.) can plug into with minimal friction.
      Refactor XRefer
      Migrate IDA-specific logic into a separate module or wrapper.
      Adapt XRefer's main codebase to use the newly created backend interface rather than direct IDA calls.
      Proof-of-Concept for Additional Backends
      Implement a PoC backend using Binary Ninja's API.
      Demonstrate how XRefer can run independently of IDA using the newly defined backend interface to generate a .xrefer analysis file.
      Outline best practices for future contributors to add and maintain backends.
      Required Skills
      Proficiency in Python programming language.
      Experience with (or strong willingness to learn) IDA's Python API.
      Experience with (or strong willingness to learn) Binary Ninja's API.
      Basic understanding of reverse engineering and underlying concepts (disassembly, functions, cross-references) and executable file formats.
      Basic knowledge of Git/Github.

      ~~~~~~~~~~
      XRefer: HTML Exporter and Visualizer for XRefer's Cluster Analysis
      size: medium, estimated 160 hours
      difficulty: low
      mentors: @m-umairx
      The goal of this project is to design and implement an HTML export module for XRefer. The module will convert XRefer's internal cluster analysis data into a dynamic HTML visualization. This interactive output should allow users to:
      View Cluster Graphs: Render detailed graphs illustrating the relationships between clusters.
      Read Semantic Descriptions: Provide natural language explanations for each cluster and its contained functions.
      Interact with Data: Offer interactive controls (e.g., zoom, pan, node selection, filtering) to explore and analyze clusters in depth.
      Deliverables:
      Design and Architecture
      Develop an intuitive UI/UX design that outlines how clusters and their semantic descriptions will be presented. Consider interactive elements such as zoomable graphs, clickable nodes, and filtering options.
      Evaluate and choose suitable front-end libraries or frameworks (e.g., D3.js, Cytoscape.js) for rendering graphs and managing interactivity.
      Develop the HTML Export Module
      Create a Python module to convert XRefer's cluster analysis data into a format consumable by the front-end (e.g., JSON).
      Develop a responsive HTML template that integrates the chosen visualization libraries. The template should include placeholders for cluster graphs, semantic descriptions, and interactive controls.
      Implement features such as zoom, pan, node highlighting, and tooltips to enhance the user's exploratory experience.
      Integrate the export module into the existing XRefer workflow so that a .html file is generated as part of the analysis process.
      Documentation
      Document the design decisions, data transformation process, and integration steps to help future contributors extend or maintain the module.
      Required Skills
      Proficiency in Python programming language.
      Familiarity with HTML, CSS, and JavaScript for building interactive web interfaces.
      Experience with visualization libraries (e.g., D3.js, Cytoscape.js) or willingness to learn how to implement interactive graphs.
      Ability to conceptualize and design an intuitive user interface that effectively presents complex data.
      Basic knowledge of Git/Github.
      GoReSym: project in scope
      mentors: @stevemk14ebr
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/flare/
    idea_list_url: https://github.com/mandiant/flare-gsoc/blob/2025/doc/project-ideas.md


  - organization_id: 40
    organization_name: FOSSASIA
    no_of_ideas: 15
    ideas_content: |

        1. Enhance Usability of the eventyay Badge Creator
        Description: The goal of this project is to streamline the process of generating and printing badges for eventyay. Organizers often need to print badges on the spot for attendees and speakers during check-in. The project will focus on adding a user-friendly badge customization feature in the frontend, ensuring seamless badge generation in the backend, and integrating with the check-in system to allow for on-site printing. Specifically, the tasks include:
        Badge Design and Customization
        Backend API Enhancements
        Check-In App Integration for On-Site Printing
        Print Service and Configuration
        Containerization & Deployment
        Performance and Scalability
        Documentation and Testing
        Repository URLs: 
        1. https://github.com/fossasia/eventyay-tickets
        2.https://github.com/fossasia/eventyay-tickets-exhibitors 


        Expected outcome: 
        Organizers can create custom badges for different user groups (speakers, attendees, volunteers, etc.).
        Attendees are able to check in quickly and receive a printed badge on the spot via the integrated check-in app.
        The system is fully documented and containerized, making it easy to set up for events of varying sizes.
        Comprehensive tests ensure reliability and maintainability of the new badge-related features.


        Skills required/preferred: 
        Python (Django backend)
        JavaScript (Ember.js for frontend in open-event-frontend)
        Docker & Kubernetes (containerization and deployment)
        CI/CD (to automate builds, tests, and deployments)
        Familiarity with printing workflows and/or label printing software (preferred)
        Possible mentors: hongquan, marcoag, norbusan, cweitat, DonChiaQE, shaunBoahCodes
        Expected Size: 350 hours
        Difficulty level: Intermediate

        ~~~~~~~~~~
        2. Convert eventyay-tickets VueJS implementation to Single Page application
        Description: The current eventyay-tickets system, built with VueJS, uses a traditional multi-page approach. While functional, this architecture can lead to slower page transitions, higher latency, and a less responsive user experience. The proposed project aims to refactor the existing implementation into a full Single Page Application (SPA) that leverages modern VueJS techniques for client-side routing, state management, and lazy loading.
        Key components of the project include:
        Routing and Navigation
        Integrate Vue Router to handle all in-app navigation without full page reloads.
        Design a smooth and intuitive navigation experience that includes dynamic routing for ticket details, user profiles, and event overviews.
        State Management
        Utilize Vuex (or an equivalent state management solution) to manage application-wide state.
        Ensure that ticket data, user sessions, and event information are synchronized across all components.
        Performance Optimization
        Implement code splitting and lazy loading to minimize initial load times and improve overall performance.
        Optimize API interactions to efficiently fetch and update data without redundant network requests.
        UI/UX Enhancements
        Redesign critical user interfaces to align with SPA principles, offering a more fluid and interactive experience.
        Enhance error handling, loading indicators, and overall responsiveness to create a seamless experience for users on various devices.
        Progressive Enhancement and Backward Compatibility
        Ensure that the new SPA implementation gracefully degrades for users with JavaScript disabled or limited browser support.
        Provide fallbacks and clear communication for any features that depend on modern browser capabilities.
        Testing and Documentation
        Develop a suite of unit, integration, and end-to-end tests to ensure robust functionality throughout the transition.
        Update documentation to reflect the new SPA architecture and guide future contributors in maintaining the codebase.
        Repository URL
        eventyay-tickets Repository
        Expected Outcome
        At the end of the project, the eventyay-tickets system will:
        Operate as a fully functional Single Page Application, resulting in faster navigation and a more engaging user experience.
        Offer a robust and maintainable codebase with modern state management and routing practices.
        Include comprehensive testing and clear documentation to facilitate future development and onboarding of contributors.
        Seamlessly integrate with existing eventyay services while ensuring backward compatibility where needed.
        Skills Required/Preferred
        JavaScript & VueJS: Deep understanding of VueJS, including Vue Router and Vuex (or similar state management libraries).
        Front-End Development: Strong grasp of modern front-end development best practices, including component-based architecture and performance optimization.
        Testing Frameworks: Experience with testing tools (e.g., Jest, Cypress) for ensuring code reliability and robustness.
        API Integration: Familiarity with RESTful APIs and efficient data handling in client-side applications.
        UI/UX Design: Ability to create intuitive and responsive interfaces, with attention to detail for user experience improvements.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 350 hours
        Difficulty level: Advanced

        ~~~~~~~~~~
        3. Implement eventyay features as a plugin in eventyay-talk
        Description: The goal of this project is to enhance the design and functionality of eventyay-talk and to integrate it more closely with eventyay-tickets and eventyay-video. While in the first version we already implemented some integration features, this project aims to expand on that work by decoupling the custom functionalities from the core eventyay-talk component. The approach will be to create a modular, admin-manageable plugin that provides seamless integrations without compromising upstream updates.
        Objectives:
        Modular Plugin Architecture:
        Develop an independent admin plugin that encapsulates all eventyay-specific integrations. This ensures that custom features remain separate from the core eventyay-talk codebase, facilitating easier updates and maintenance.
        Enhanced Integration with eventyay-tickets and eventyay-video:
        Integrate ticketing data to display attendee information, session details, and speaker profiles within the discussion threads of eventyay-talk.
        Integrate video content so that related event sessions or live streams are readily accessible from within the talk platform.
        Synchronize user profiles and session metadata across these services for a consistent experience.
        Improved Design and Usability:
        Enhance the overall UI/UX of eventyay-talk to match the branding and design language of the eventyay ecosystem.
        Provide a centralized admin interface where event organizers can configure and control integrations, toggle features, and manage settings without modifying core code.
        Future-Proof and Maintainable Code:
        Keep the integration functionality in-line with upstream eventyay-talk releases, ensuring compatibility and ease of updates.
        Write comprehensive documentation and tests to support long-term maintenance and community contributions.
        Repositories:
        eventyay-talk Repository
        eventyay-tickets Repository
        eventyay-video Repository
        Expected Outcome:
        At the end of the project, the eventyay-talk platform will have a standalone, well-documented plugin that:
        Integrates ticketing and video functionalities directly within the environment.
        Offers a seamless and consistent user experience across eventyay components.
        Is easily configurable through an admin interface, reducing the need to modify core eventyay-talk code.
        Maintains alignment with upstream changes, ensuring long-term compatibility and simplified maintenance.
        Includes robust testing and clear documentation to facilitate future enhancements and community contributions.
        Skills Required/Preferred:
        JavaScript & Frameworks: Strong knowledge of JavaScript and experience with the framework used in eventyay-talk using Vue.js).
        Plugin Architecture: Familiarity with creating modular plugins and extension points in a larger application ecosystem.
        API Integration: Experience with RESTful APIs and backend integrations.
        UI/UX Design: Ability to enhance user interfaces for better usability and consistency across platforms.
        DevOps: Familiarity with Docker, CI/CD, and automated testing to ensure reliable deployment and maintenance.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 175 hours
        Difficulty level: Intermediate

        ~~~~~~~~~~
        4. Upgrade eventyay-video to a Single Page Application with Dashboard, Settings, and Configuration Options for Organisers and Admins
        Description: The current eventyay-video implementation provides basic video functionalities for event streaming and management. However, it lacks an integrated, user-friendly dashboard and administrative interface. This project aims to transform eventyay-video into a modern Single Page Application (SPA) that offers comprehensive dashboards and configuration options for organisers and admins. By upgrading the UI/UX and incorporating advanced settings, the platform will allow seamless management of video content and live sessions, as well as integration with the broader eventyay ecosystem.
        Objectives:
        SPA Conversion and Modernization:
        Refactor the existing eventyay-video codebase to a Single Page VueJS Application.
        Implement client-side routing, lazy loading, and state management to ensure fast, smooth interactions and a responsive user experience.
        Dashboard and Administrative Interface:
        Develop intuitive and fully functional dashboards for organisers and admins to manage video sessions, live streams, and related content.
        Create comprehensive settings and configuration panels that allow users to customize video parameters, manage integrations, and monitor streaming analytics.
        Ensure that the dashboards are secure, scalable, and aligned with eventyay’s overall design language.
        Integration with eventyay Ecosystem:
        Seamlessly integrate with eventyay-tickets and other eventyay modules to synchronize data (e.g., event schedules, session details, user profiles).
        Enable automated configuration and updates from central eventyay administration systems, reducing manual maintenance.
        Enhanced UI/UX and Performance Optimization:
        Redesign the video interface to be more interactive and user-friendly, with emphasis on accessibility and responsiveness across devices.
        Optimize performance using code splitting, efficient API calls, and caching strategies to support large-scale live events and high traffic.
        Testing, Documentation, and Deployment:
        Write comprehensive unit, integration, and end-to-end tests to ensure reliability and performance.
        Document the new features, installation procedures, and administration guides to support future development and community onboarding.
        Leverage Docker and CI/CD pipelines to automate the build, testing, and deployment process, ensuring a robust development workflow.
        Repositories:
        eventyay-video Repository
        Expected Outcome:
        By the end of the project, eventyay-video will:
        Be transformed into a Single Page Application.
        Offer fully functional dashboards for organisers and admins, including robust settings and configuration options.
        Seamlessly integrate with the broader eventyay ecosystem to synchronize event data and manage video content efficiently.
        Include comprehensive testing and documentation, ensuring ease of maintenance and further development.
        Skills Required/Preferred:
        JavaScript & SPA Frameworks: Expertise in VueJS for SPA development, including client-side routing and state management.
        Front-End Development: Strong experience with modern UI/UX design principles and performance optimization.
        Backend Integration: Familiarity with RESTful APIs and integrating front-end applications with backend services.
        DevOps & CI/CD: Knowledge of Docker, Kubernetes, and continuous integration/deployment pipelines.
        Testing & Documentation: Experience writing comprehensive tests (unit, integration, e2e) and maintaining technical documentation.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 350 hours
        Difficulty level: Intermediate

        ~~~~~~~~~~
        5. Add New Integrations of Talks and Speakers component with eventyay Video
        Description: The goal of this project is to seamlessly integrate eventyay-talk with the eventyay-video component, ensuring a unified experience for event organisers and attendees. The project focuses on automating the synchronization between talks and video rooms, as well as enhancing speaker integration. For instance, when rooms are created in eventyay-talk, they should automatically appear in eventyay-video. Additionally, event organisers will have the ability to assign team members as MCs (Masters of Ceremonies) for different rooms, streamlining room management and improving live event coordination. This integration will reduce manual work, ensure data consistency, and provide a coherent user experience across eventyay components.
        Objectives:
        Automatic Room Synchronization:
        Develop functionality to automatically sync room creation and updates from eventyay-talk to eventyay-video.
        Ensure that any changes in the talk component (e.g., room details, schedule updates) reflect in real time on the video side.
        Speaker and Talk Data Integration:
        Integrate detailed talk and speaker information within the eventyay-video interface.
        Display session titles, descriptions, and speaker profiles alongside corresponding video rooms, providing context for viewers.
        MC Assignment Feature:
        Create an admin dashboard interface that enables organisers to assign team members as MCs for various video rooms.
        Implement notifications and role-based permissions to ensure that MCs have the tools and access needed to manage live sessions effectively.
        Unified User Experience:
        Design a consistent and intuitive UI/UX that bridges the gap between eventyay-talk and eventyay-video.
        Include visual cues and real-time status updates to help users navigate between talk sessions and their video counterparts.
        Backend Synchronization & API Enhancements:
        Enhance existing APIs or develop new endpoints to facilitate seamless data exchange between eventyay-talk and eventyay-video.
        Ensure robust error handling and data validation to maintain system reliability.
        Testing, Documentation, and Maintenance:
        Develop comprehensive unit, integration, and end-to-end tests covering all new integration functionalities.
        Provide clear documentation for developers and administrators to ensure ease of future maintenance and onboarding.
        Repositories:
        eventyay-talk Repository
        eventyay-video Repository
        Expected Outcome:
        At the end of the project, the eventyay ecosystem will benefit from:
        Automatic synchronization of rooms between eventyay-talk and eventyay-video, reducing manual intervention.
        Enhanced display of talk and speaker information in the video component.
        A dedicated admin interface for assigning MCs to rooms, ensuring better event management.
        A unified and consistent experience across the eventyay platforms, bolstered by robust API integrations, thorough testing, and clear documentation.
        Skills Required/Preferred:
        JavaScript & Front-End Frameworks: Experience with modern JavaScript frameworks (e.g., Vue.js) used in eventyay components.
        Backend Development: Experience in RESTful API design and integration.
        Integration Development: Experience in connecting disparate systems and ensuring smooth data synchronization.
        UI/UX Design: Strong skills in creating intuitive, responsive, and consistent user interfaces.
        Testing & Documentation: Ability to write comprehensive tests (unit, integration, and end-to-end) and maintain clear technical documentation.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 175 hours (medium project)
        Difficulty level: Intermediate
        
        ~~~~~~~~~~  
        6. Extend Features of the Exhibition Plugin for eventyay
        Description: eventyay currently includes an exhibition system designed to showcase exhibitors during events. This project aims to significantly enhance the existing exhibition plugin by expanding its feature set and improving its usability for both exhibitors and organizers. The new features will empower exhibitors to register and manage their own profiles, add detailed content, embed video links, and link to their social media channels. At the same time, event organizers will gain better control over exhibitor signups, payments, and the publication process. Additionally, the plugin will support integration with event sessions, allowing related sessions to be showcased on the exhibitor’s page, along with the ability to feature an exhibitor video directly on their profile.
        Objectives:
        Enhance the Exhibitor Registration & Profile Management:
        Develop a user-friendly registration process for exhibitors, allowing them to submit detailed profiles, including company information, content, and social media links.
        Allow exhibitors to edit and update their profiles through a dedicated dashboard.
        Integration of Multimedia Content:
        Enable exhibitors to embed video links (e.g., from YouTube or Vimeo) directly on their public exhibitor page.
        Support the addition of rich content (images, descriptions, documents) to provide a comprehensive overview of each exhibitor.
        Organizers’ Administrative Tools:
        Create an admin interface that enables organizers to review, approve, and manage exhibitor signups.
        Integrate payment processing options to manage exhibitor fees, if applicable, ensuring a secure and streamlined financial workflow.
        Provide tools for organizers to publish approved exhibitor profiles to the public website.
        Integration with Event Sessions:
        Implement a feature to associate related event sessions with exhibitor profiles. This will allow attendees to see relevant sessions alongside exhibitor details, fostering deeper engagement.
        Design intuitive navigation between exhibitor pages and session details.
        Responsive & Modern UI/UX:
        Redesign the exhibitor plugin interface to align with eventyay’s overall design language, ensuring a modern, accessible, and responsive user experience across all devices.
        Focus on usability for both exhibitors and event organizers through clear workflows and consistent design elements.
        Robust Testing & Documentation:
        Develop comprehensive unit, integration, and end-to-end tests to ensure reliability of all new features.
        Write detailed documentation for both developers and end-users to support future maintenance and community contributions.
        Repository:
        eventyay-tickets-exhibitors
        Expected Outcome:
        Upon completion of the project, the extended exhibition plugin will provide:
        A complete exhibitor registration system with rich profile management capabilities.
        An administrative interface for organizers to manage exhibitor applications, process payments, and publish profiles.
        Enhanced exhibitor pages that integrate multimedia content, social media links, and related event sessions.
        A modern, responsive UI that offers a seamless experience for both exhibitors and event attendees.
        Comprehensive testing and documentation that ensure maintainability and facilitate future enhancements.
        Skills Required/Preferred:
        Web Development: Strong experience with front-end technologies (JavaScript frameworks, HTML, CSS) and back-end development.
        Frameworks & Libraries: Familiarity with frameworks used in eventyay (e.g., Ember.js, Vue.js, or similar) and RESTful API integration.
        Payment Integration: Knowledge of integrating payment systems (e.g., Stripe, PayPal) for secure transaction processing.
        UI/UX Design: Ability to create intuitive and responsive interfaces.
        Testing & Documentation: Experience with writing unit, integration, and end-to-end tests as well as technical documentation.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 175 hours (medium size)
        SUSI Interpretation Project
        
        ~~~~~~~~~~
        1. SUSI Interpretation Project: Develop a Prototype for Real-Time AI Live-Interpretation of Event Videos
        Description: The SUSI AI Translator project aims to build an interpretation assistant that leverages large language models (LLMs) to enable automated, real-time live interpretation on top of the eventyay video component. The system integrates advanced speech-to-text technology with AI-powered language translation, allowing for the seamless display of interpreted text (e.g., translated subtitles) during live event video sessions. By bridging the gap between live audio streams and real-time translation, this project will significantly enhance accessibility and engagement for multilingual audiences at events.
        Scope: 
        The scope of your specific work on this project should be discussed with your mentor.
        Objectives:
        Real-Time Speech Recognition:
        Integration: Evaluate and integrate state-of-the-art speech-to-text engines (such as OpenAI’s Whisper or other open-source alternatives) to capture live audio streams from event videos with minimal latency.
        Optimization: Optimize for high accuracy and performance under varying noise and speech conditions.
        AI-Powered Translation & Interpretation:
        LLM Integration: Leverage large language models or dedicated translation APIs to interpret and translate the transcribed text in near real-time.
        Context Preservation: Ensure that the translation maintains context and clarity, offering accurate subtitles that enhance audience understanding.
        Subtitle Overlay & UI Integration:
        Eventyay Video Integration: Develop a module that overlays interpreted subtitles onto the live video stream from the eventyay video platform.
        Customization: Provide configurable options (e.g., font size, color, position, language selection, and toggle controls) to optimize subtitle display for diverse event settings.
        System Optimization and Latency Reduction:
        Pipeline Efficiency: Optimize data pipelines and processing workflows to minimize end-to-end latency, ensuring a smooth live interpretation experience.
        Caching & Asynchronous Processing: Implement techniques to handle network delays and processing loads effectively.
        Testing, Documentation, and Community Engagement:
        Comprehensive Testing: Develop unit, integration, and end-to-end tests to ensure system reliability and performance across various scenarios.
        Documentation: Create detailed guides on system setup, configuration, troubleshooting, and customization.
        Tutorials & Demos: Produce step-by-step tutorials and demo videos showcasing how to deploy and use the live interpretation feature.
        Additional Features (Exploratory):
        Admin Controls: Design an admin panel for event organizers to manage language pairs, thresholds, and real-time translation settings.
        Multi-Language Support: Expand the system to support multiple target languages and easy language switching during live events.
        Repositories:
        SUSI Translator Repository
        eventyay-video Repository
        (Additional modules or repositories may be created as the project evolves.)
        Expected Outcome:
        An improved prototype fully integrated, real-time AI live interpretation system that displays translated subtitles on the eventyay video platform.
        Enhanced accessibility and engagement for multilingual audiences through automated, low-latency speech recognition and translation.
        A robust, well-documented codebase accompanied by comprehensive tests and tutorials, fostering further community contributions and improvements.
        Skills Required/Preferred:
        Speech Recognition & Audio Processing: Familiarity with integrating and optimizing speech-to-text systems.
        AI & Machine Learning: Experience working with large language models, translation APIs, or similar AI-driven solutions.
        Programming & API Integration: Proficiency in Python and/or other relevant languages for backend processing and API development.
        Front-End Development: Skills in integrating real-time UI overlays within video platforms.
        DevOps & Testing: Experience with CI/CD pipelines and automated testing frameworks.
        Open Source Collaboration: Prior experience contributing to or managing open-source projects.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 350 hours

        ~~~~~~~~~~
        Scrum Helper
        1. Extend Features of the Scrum Helper Chrome Extension
        The Scrum Helper Chrome extension currently assists users in writing daily scrums within Google Groups by automatically fetching data from the GitHub API. It retrieves information such as pull requests, issues, and reviewed PRs based on the user’s GitHub username and pre-fills scrum reports accordingly. The proposed project aims to expand the extension's usability by:
        Adding support for popular web email clients like Gmail, Yahoo, and Outlook.
        Implementing a standalone pop-up interface that can be used independently of any email provider.
        This will allow users who do not utilize Google Groups or specific web email services to seamlessly generate and edit their scrum reports. The project focuses on extending API integrations, enhancing user interfaces, and ensuring compatibility across multiple platforms and environments.
        Objectives:
        Multi-Email Client Integration:
        Gmail, Yahoo, and Outlook Support:
        Integrate the extension with these popular web email clients by detecting the email interface and injecting necessary UI components to allow scrum report generation.
        Authentication & Permissions:
        Adapt OAuth flows or other authentication methods where necessary to securely connect to these platforms while preserving user privacy and data security.
        Standalone Pop-Up Interface:
        Development of a Standalone UI:
        Build a responsive, easy-to-use pop-up interface that operates independently of any specific email provider.
        User Experience Enhancements:
        Provide options to input GitHub username, dates, and other relevant details directly in the pop-up, pre-fill scrum data via the GitHub API, and allow users to edit the content before copying or exporting it.
        Customization Options:
        Allow users to configure which sections appear in their scrum reports and to save templates for future use.
        Enhanced GitHub Integration:
        Robust Data Fetching:
        Optimize API calls to fetch PRs, Issues, and reviewed PRs with error handling and caching mechanisms for a smoother user experience.
        User Customization:
        Offer additional filtering or sorting options for the fetched data, enabling users to fine-tune the information that populates their scrum reports.
        Cross-Platform Compatibility & Performance:
        Responsive Design:
        Ensure the extension’s UI adapts to different screen sizes and resolutions across various email clients.
        Performance Optimization:
        Optimize the extension for minimal load times and resource usage, ensuring a smooth experience even when processing large amounts of data.
        Testing, Documentation, and Community Engagement:
        Comprehensive Testing:
        Write unit, integration, and end-to-end tests to cover new functionalities, ensuring robustness and ease of maintenance.
        Documentation:
        Update technical and user documentation to guide future contributors and end users.
        Community Feedback:
        Engage with the community to gather feedback and iterate on the features, ensuring that the extension meets the evolving needs of its users.
        Repository:
        Scrum Helper Repository
        Expected Outcome:
        By the end of the project, the Scrum Helper Chrome extension will:
        Support integration with Gmail, Yahoo, and Outlook, enabling users to generate and send scrum reports directly from these platforms.
        Include a fully functional standalone pop-up interface for users who prefer not to rely on specific email providers.
        Enhance GitHub integration to provide robust, customizable data fetching and pre-filling of scrum reports.
        Feature an intuitive, responsive, and optimized UI that works seamlessly across different platforms.
        Be accompanied by comprehensive testing and detailed documentation, facilitating future contributions and maintenance.
        Skills Required/Preferred:
        Chrome Extension Development: Experience building and maintaining Chrome extensions.
        Front-End Development: Experience in HTML, CSS, JavaScript (and frameworks/libraries as needed) for building responsive UIs.
        API Integration: Knowledge of integrating third-party APIs (especially GitHub and web email clients) and handling OAuth authentication.
        Back-End Integration & Optimization: Ability to design robust data-fetching mechanisms and implement caching/error handling strategies.
        Testing & Documentation: Experience with writing automated tests and maintaining clear technical documentation.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 90 hours (small project)
        Difficulty level: Easy

        ~~~~~~~~~~
        FOSSASIA.ORG
        1. Revamp FOSSASIA.org with WordPress for a Modern, Maintainable Website
        Description: The goal of this project is to develop a new version of the FOSSASIA.org website using WordPress. The new website will adhere to the existing FOSSASIA brand guidelines, utilizing the core colors of red, gray, and white to maintain brand identity. By leveraging standard WordPress plugins and best practices, the project aims to create a website that is easy to update and maintain, ensuring a future-proof and scalable online presence for the community. The revamped site will showcase FOSSASIA's projects, events, news, and community initiatives in an engaging, responsive, and user-friendly manner.
        Objectives:
        Design & Branding:
        Develop a modern, responsive design for FOSSASIA.org that respects the current color scheme (red, gray, white).
        Create custom layouts and a theme that reflect the FOSSASIA identity, ensuring visual consistency across all pages.
        Plugin & Functionality Integration:
        Utilize standard, well-supported WordPress plugins to handle essential functionalities such as:
        Blog and news feeds.
        Contact forms and newsletter sign-ups.
        Social media integration and sharing.
        Keep customization minimal to simplify future updates and maintenance.
        Content & Information Architecture:
        Structure the site to clearly present FOSSASIA’s projects, events, community news, and resources following the current structure.
        Ensure easy navigation and a seamless user experience across devices.
        Performance, SEO, and Security:
        Optimize the site for speed and responsiveness.
        Implement SEO best practices and integrate tools for analytics.
        Ensure the website adheres to current security standards and best practices for WordPress.
        Documentation & Future-Proofing:
        Provide comprehensive documentation on theme customization, plugin management, and content updates.
        Create guidelines for future developers and maintainers to ensure the website remains current and easy to update.
        Expected Outcome:
        By the end of the project, the new FOSSASIA.org website will:
        Feature a fresh, modern design that maintains brand consistency with red, gray, and white as the primary colors.
        Leverage standard WordPress plugins to deliver a robust, feature-rich experience including event management, blog updates, contact forms, and social media integration.
        Be optimized for performance, SEO, and security, providing a seamless experience across all devices.
        Include detailed documentation to facilitate ongoing maintenance and future enhancements, ensuring longevity and scalability.
        Skills Required/Preferred:
        WordPress Development: Proficiency in WordPress theme development, PHP, and customizing plugins.
        Front-End Technologies: Experience with HTML, CSS, JavaScript, and responsive design principles.
        UI/UX Design: Ability to translate branding guidelines into a modern, user-friendly design.
        SEO & Performance Optimization: Understanding of web performance best practices and SEO fundamentals.
        Documentation: Strong technical writing skills for creating comprehensive developer and user guides.
        Repository:
        A new repository for the FOSSASIA.org WordPress theme and related assets will be maintained under the FOSSASIA GitHub organization.
        Possible mentors: hongquan, marcoag, norbusan, cweitat, mohit
        Expected Size: 175 hours (intermediate project)
        Difficulty level: Intermediate

        ~~~~~~~~~~  
        LED Badge Magic
        The Badge Magic Android app lets you create moving text and draw clipart for LED name badges. The app provides options to portray names, cliparts, and simple animations on the badges. For the data transfer from the smartphone to the LED badge it uses Bluetooth.
        Project Ideas
        1. Enhance the feature set of the Flutter Badge Magic Application 
        Description: Badge Magic is a Flutter-based application that controls LED name badges via Bluetooth, allowing users to display names, graphics, and simple animations. Currently available on GitHub and major app stores, the app provides basic functionalities to customize LED displays. The goal of this project is to significantly expand its feature set to offer a richer, more customizable experience. New features include support for various fonts, games, and additional LED badge screen sizes and color options. Users will also benefit from advanced badge configuration options (such as Bluetooth always-on mode) and the ability to manage up to 8 storage slots for text and animations, including making animations editable and storable. Additionally, the project will streamline deployment by integrating automated support for additional app stores (e.g., Aptoide, App Gallery) and extend the app’s availability across all platforms supported by Flutter (Windows, Linux, MacOS, and Websites). Furthermore, existing bugs should be solved and feature enhancements made to ensure robust functionality and an improved user experience.
        Objectives:
        Multi-Font, Color, and Content Support:
        Integrate a diverse range of fonts and color palettes to allow users to customize the appearance of text, graphics, and animations on their LED badges.
        Enhance content management by enabling editable storage for animations—allowing users to store, edit, and reapply animations to 8 storage slots of the badge.
        Enable Interactive Games Integration:
        Provide an option to integrate simple, engaging mini-games that can be displayed on the LED badges.
        Support for Multiple LED Badge Screen Sizes:
        Enhance the app to automatically adapt content for various LED badge screen sizes and resolutions.
        Advanced Badge Configuration Options supported by the firmware:
        Implement detailed configuration settings, such as enabling/disabling Bluetooth always-on mode, and other badge-specific options to provide greater control over the device behavior.
        Solve existing bugs and improve feature enhancements to refine overall functionality.
        Automated Multi-Platform Deployment:
        Improve the automated deployment pipeline that facilitates the submission of the app to additional app stores (e.g., Aptoide, App Gallery) as well as all platforms supported by Flutter.
        Ensure that installation files for Windows, Linux, MacOS, and Websites are autogenerated and maintained in the project's app branch.
        Enhanced UI/UX Improvements:
        Provide clear visual feedback and customization options across all supported platforms.
        Comprehensive Testing and Documentation:
        Implement unit, integration, and end-to-end tests to ensure all new features work as expected and existing bugs are resolved.
        Update technical and user documentation to assist future contributors and end users, ensuring long-term maintainability.
        Repository:
        https://github.com/fossasia/badgemagic-app 
        Expected Outcome:
        At the end of the project, the Flutter Badge Magic Application will:
        Support a wide range of fonts, colors, and display options for highly customizable badge presentations.
        Feature interactive games and advanced configuration settings, including a “Bluetooth always on” mode.
        Allow users to store, edit, and manage animations in up to 8 dedicated storage slots.
        Automatically adapt to various LED badge screen sizes, ensuring optimal content display.
        Support automated multi-platform deployment, generating installation files for Windows, Linux, MacOS, and Websites on the app branch.
        Provide a robust, bug-free experience with a modern, user-friendly interface and comprehensive documentation.
        Skills Required/Preferred:
        Flutter/Dart: Advanced knowledge in Flutter development and Dart programming.
        Bluetooth Communication: Experience with Bluetooth integration in mobile applications.
        UI/UX Design: Strong design skills for building intuitive and responsive mobile interfaces.
        Mobile and Multi-Platform App Development: Proven experience in Android, iOS, and cross-platform development (Windows, Linux, MacOS, and Web).
        CI/CD & Deployment: Familiarity with automated deployment pipelines and multi-app store submissions.
        Testing & Documentation: Experience in writing unit, integration, and end-to-end tests, as well as maintaining detailed project documentation.
        Possible mentors: Aditya, MarioB, cweitat
        Expected Size: 175 hours (median project)
        Difficulty level: Easy
        
        ~~~~~~~~~~
        Magic ePaper Badge
        1. Improve the Magic ePaper Badge app into a User friendly Functional App
        Description: The Magic ePaper Badge is a unique hardware platform featuring a tri-color ePaper display, NFC capabilities, and battery-free operation. The goal of this project is to build an open source Flutter application that allows users to interact with and control the badge with rich, customizable content. The app will enable users to create and edit content through drawing tools, text inputs, emojis, and image import functionalities—with various effects (none, semi-transparent, block, portrait). Additional features include adjusting contrast, colors, image rotation, and text customization (font and size). Finally, the app will support transferring the composed content to the badge via NFC. This project is especially suited for contributors with an electronics background who are also interested in modern mobile app development using Flutter.
        Objectives:
        User Interface & Drawing Tools:
        Develop an intuitive Flutter UI for creating badge content.
        Implement drawing functionalities, text input, and emoji insertion.
        Integrate a color picker to easily change colors by tapping on a color button.
        Image Import and Editing:
        Enable users to import images from their devices.
        Support multiple image display effects: none, semi-transparent, block, and portrait.
        Provide features for rotating images and adjusting brightness, contrast, and overall color balance.
        Text Customization:
        Allow users to change fonts and text sizes to match their design needs.
        Ensure text overlays are compatible with the tri-color ePaper display.
        NFC-Based Content Transfer:
        Integrate NFC functionalities to enable the transfer of created content from an NFC-enabled phone directly to the Magic ePaper Badge.
        Ensure a smooth, secure, and reliable connection between the mobile device and the badge hardware.
        Support for Tri-Color ePaper Displays:
        Ensure that all drawing, text, image, and animation functionalities are fully optimized for the unique constraints of tri-color ePaper displays.
        Testing, Bug Fixes & Feature Enhancements:
        Identify and resolve existing bugs, particularly issues around storing and editing animations.
        Continuously refine and enhance features based on user feedback and testing results.
        Multi-Platform Deployment & Automation:
        Adapt the app to run on all platforms supported by Flutter (Android, iOS, Windows, Linux, MacOS, and Web).
        Set up an automated deployment pipeline to generate installation files in the app branch for all target platforms.
        Ensure that the deployment process is smooth and maintainable for future updates.
        Documentation & Community Engagement:
        Produce comprehensive documentation covering installation, usage, and NFC transfer processes.
        Provide guidelines for future contributions and ensure robust testing strategies are in place.
        Repository:
        Magic ePaper App Repository
        Resources:
        Waveshare ePaper Sample App
        Expected Outcome:
        By the end of the project, the Magic ePaper Badge Flutter App will:
        Offer a complete suite of content creation tools (drawing, text, emoji, image editing) tailored for the tri-color ePaper display.
        Provide robust customization options including color adjustments, image effects, and text formatting.
        Seamlessly transfer content to the badge via NFC.
        Run across all major platforms supported by Flutter, with autogenerated installation files maintained in the app branch.
        Include comprehensive documentation, a solid testing framework, and a refined UI/UX for an engaging user experience.
        Skills Required/Preferred:
        Flutter & Dart Development: Knowledge in building cross-platform apps with Flutter.
        Mobile & Multi-Platform App Development: Experience in deploying applications on Android, iOS, Windows, Linux, MacOS, and Web.
        NFC Integration: Understanding of NFC communication and its implementation on mobile devices.
        UI/UX Design: Skills in creating intuitive and responsive user interfaces.
        Image Processing & Drawing: Experience with image editing, drawing functionalities, and handling various display effects.
        Electronics & ePaper Displays: Basic knowledge of ePaper technology and hardware integration is a plus.
        Testing & Documentation: Proven ability to write comprehensive tests and maintain clear, detailed documentation. 
        Possible mentors: Aditya, MarioB, cweitat
        Expected Size: 350 hours (large project)
        Difficulty level: Intermediate
        
        ~~~~~~~~~~
        2. Enhance the Firmware of the Magic epaper Badge 
        Description: The Magic Epaper Firmware is a fully customizable and efficient firmware designed to control FOSSASIA's ePaper displays. It serves as the backbone for smart signage, dashboards, IoT devices, and various applications that require low-power, high-performance e-ink display control. The firmware is optimized for FOSSASIA ePaper displays, ensuring smooth rendering while consuming minimal power, and features a modular codebase that allows easy adaptation to different e-paper sizes and types. With flexible connectivity options supporting SPI, I2C, or UART interfaces, and compatibility with various microcontrollers, the firmware is capable of rich content rendering including text, images, and custom graphics—with support for grayscale and partial refresh (depending on display capabilities). Fully open-source under the Apache2 license, the firmware invites contributors to extend its capabilities and enhance its reliability.
        Objectives:
        Reliability and Stability Enhancements:
        Audit the current firmware codebase to identify and resolve bugs affecting rendering, connectivity, and power consumption.
        Optimize the code for smoother rendering and enhanced stability across various hardware configurations.
        Modular Codebase Improvements:
        Refactor and document the modular components to simplify customization for different e-paper display sizes and types.
        Enhance configurability to allow easier integration with new microcontrollers and communication protocols (SPI, I2C, UART).
        Low-Power Optimization:
        Fine-tune power management routines to further reduce energy consumption, making the firmware even more suitable for battery-powered devices.
        Implement advanced sleep and wake-up cycles tailored for e-ink display operations.
        Advanced Content Rendering:
        Improve support for rich content rendering including text, images, and custom graphics.
        Enhance grayscale rendering capabilities and optimize partial refresh functionality to reduce ghosting and improve update speed.
        Connectivity and Integration Enhancements:
        Ensure robust communication over SPI, I2C, or UART, adding diagnostics or fallback mechanisms to handle connection interruptions.
        Develop test cases and debugging tools to facilitate easier firmware integration with different hardware setups.
        Documentation and Community Support:
        Update and expand technical documentation, providing detailed guides on customizing and extending the firmware.
        Create a set of example projects and usage scenarios for smart signage, dashboards, and IoT devices to encourage community contributions.
        Repository:
        Magic ePaper Firmware Repository
        Expected Outcome:
        By the end of the project, the enhanced Magic Epaper Firmware will:
        Deliver a more stable and reliable performance with optimized rendering and low-power operation.
        Feature a thoroughly documented and modular codebase that simplifies customization for various e-paper displays and microcontrollers.
        Offer improved content rendering capabilities, including refined support for grayscale and partial refresh.
        Provide robust connectivity with diagnostics and enhanced support for SPI, I2C, and UART interfaces.
        Include comprehensive documentation and example projects, fostering further development and community engagement.
        Skills Required/Preferred:
        Embedded Systems & Firmware Development: C/C++ or similar languages used in microcontroller programming.
        Electronics & Hardware Integration: Experience with ePaper displays, low-power device design, and understanding of communication protocols (SPI, I2C, UART).
        Optimization & Debugging: Skills in debugging firmware and optimizing performance for resource-constrained devices.
        Documentation & Open-Source Collaboration: Ability to write clear technical documentation and collaborate with a global open-source community.
        Possible mentors: fcartegnie, Benjamin Henrion, Simon Budig, danielm
        Expected Size: 350 hours
        Difficulty level: Difficult

        ~~~~~~~~~~
        Pocket Science Lab
        In the Pocket Science Lab Project we create phone and desktop applications to collect measurements and data to solve global problems with science and build a sustainable world. With the PSLab mobile and desktop apps it is possible to use sensors of a phone or desktop PC to collect measurements and data. The app comes with a built-in Oscilloscope, Multimeter, Wave Generator, Logic Analyzer, Power Source, and we are constantly adding more digital instruments or even robotic controls. With PSLab applications your phone or PC becomes like many devices in one. 
        Project Ideas
        1. Complete the Port of the PSLab app to Flutter
        The Pocket Science Lab (PSLab) project has empowered countless students to explore science hands-on with affordable, versatile instruments. Currently, the PSLab mobile app is available only for Android, limiting its accessibility. In response to feedback from educational institutions and schools, this project aims to develop a cross-platform Flutter application that works seamlessly on Android, iOS, desktop (Windows, macOS, Linux), and web. The new app will provide support for popular scientific instruments such as the Oscilloscope, Logic Analyzer, Multimeter, and robot controls. Additionally, due to Apple's restrictions on USB connections, the project will include robust configuration options and WiFi connectivity to enable data transmission on Apple devices.
        Objectives:
        Cross-Platform Development:
        Porting/Implementation: Rebuild the existing Android app using Flutter to support iOS, desktop, and web platforms.
        Optimization: Ensure the app performs smoothly across different devices and screen sizes.
        Core Instrument Functionality:
        Oscilloscope, Logic Analyzer, Multimeter, and Robot Controls: Implement and integrate these instrument features with consistent behavior and accuracy across all platforms.
        Data Visualization: Develop clear, interactive visualizations and controls for each instrument, enabling real-time monitoring and analysis.
        Enhanced Connectivity:
        USB and WiFi Support:
        Retain USB connectivity for Android while implementing configuration options for WiFi-based data transmission.
        Address Apple’s limitations by enabling WiFi connectivity, ensuring seamless communication between the PSLab hardware and the app on iOS devices.
        Robust Communication Protocols: Ensure secure and reliable data transfer through efficient connection management.
        User Interface & Experience:
        Responsive UI: Design an intuitive, responsive interface that adapts to mobile, desktop, and web environments.
        User-Centric Design: Prioritize ease of use, especially for educational settings, with clear navigation and instrument control layouts.
        Testing, Documentation, and Deployment:
        Comprehensive Testing: Develop unit, integration, and end-to-end tests to validate functionality across all supported platforms.
        Automated Deployment: Set up CI/CD pipelines to automate building and deployment for mobile (App Store/Google Play), desktop installers, and a web version.
        Documentation: Create detailed user and developer documentation, including setup guides and usage examples, to foster community engagement and future contributions.
        Repository:
        PSLab Android Repository (Check the flutter branch)
        Expected Outcome:
        By the end of the project, PSLab will have a robust, cross-platform Flutter application that:
        Runs seamlessly on Android, iOS, desktop (Windows, macOS, Linux), and web.
        Provides essential scientific instrument functionalities (Oscilloscope, Logic Analyzer, Multimeter, Robot Controls) with intuitive, real-time visualizations.
        Supports both USB (for Android) and WiFi connectivity (for iOS and other platforms) to overcome hardware limitations.
        Offers a user-friendly interface tailored for educational use, complete with comprehensive testing, documentation, and automated multi-platform deployment.
        Skills Required/Preferred:
        Flutter/Dart Development: Knowledge in building cross-platform applications.
        Mobile, Desktop & Web Development: Experience in deploying apps across various platforms.
        Hardware & IoT Integration: Understanding of connectivity protocols (USB, WiFi) and interfacing with scientific instruments.
        UI/UX Design: Ability to design responsive and intuitive interfaces.
        Testing & CI/CD: Experience with automated testing frameworks and deployment pipelines.
        Open Source Collaboration: Familiarity with contributing to and managing open-source projects.
        Possible mentors: padmal, bessman
        Expected Size: 350 hours
        Difficulty level: Difficult

        ~~~~~~~~~~

        2. Advanced Robot Control and Python Integration for the PSLab Android App
        Description: The PSLab Android app currently allows users to control a robotic manipulator with 4 degrees of freedom via connected servo motors. In parallel, similar control functionalities are available using Python, offering flexibility for custom automation and scripting. This project aims to enhance the robot control features within the PSLab Android app while seamlessly bridging the gap between mobile and Python environments. Key enhancements include advanced control options, import/export capabilities for Python scripts, and storage of user-defined robot controls. Additionally, comprehensive documentation and a web-based UI guide will be developed to showcase how to transfer control data and operate the robot through a web interface.
        Objectives:
        Enhanced Robot Control Features:
        Upgrade the existing robot control module within the PSLab Android app to support advanced manipulation options.
        Improve the user interface for intuitive control over the 4 degrees of freedom, including real-time feedback and fine-tuning capabilities.
        Implement additional control modes, presets, and customizable parameters for servo motor movements.
        Python Script Integration:
        Develop functionality for exporting the current robot control configurations and commands from the Android app as a Python script.
        Implement an import feature that allows users to load Python scripts into the Android app, enabling them to execute predefined control sequences.
        Ensure that the Python integration maintains consistency with the PSLab Python library and adheres to best practices.
        Data Storage & Management:
        Introduce a storage mechanism for users to save and manage their custom robot control profiles and scripts within the app.
        Provide a clear and accessible user interface to review, edit, and organize stored controls.
        Documentation & Web UI Integration:
        Create comprehensive, step-by-step documentation detailing the transfer of control data between the Android app and Python scripts.
        Develop a web-based UI guide that demonstrates how to control the robot via a browser, highlighting the integration process and potential use cases.
        Include troubleshooting guides and best practices to help users optimize their control setups.
        Repository:
        PSLab Android App
        PSLab Python
        Expected Outcome:
        At the end of the project, the PSLab Android app will feature:
        Enhanced and more intuitive robot control capabilities with advanced options.
        Seamless import and export functionalities for Python scripts, allowing bi-directional control and integration.
        Robust storage of user-defined control profiles for quick access and customization.
        Comprehensive documentation and a web UI guide that illustrate the control data transfer process and provide additional insights on operating the robot.
        Skills Required/Preferred:
        Android Development: Android app development with a strong understanding of Java/Kotlin and Flutter (if applicable).
        Python Programming: Experience with Python scripting and integrating Python functionalities within mobile applications.
        Robotics & IoT: Familiarity with robotic control systems, servo motors, and interfacing with hardware.
        UI/UX Design: Ability to design intuitive user interfaces that enhance user interaction and control.
        Documentation & Testing: Experience with writing clear documentation and performing robust testing to ensure a stable release.
        Possible mentors: padmal, orangecms, bessman
        Expected Size: 90 hours
        Difficulty level: Intermediate

        ~~~~~~~~~~
        3. Create a Firmware Prototype for PSLab Mini: A Compact Oscilloscope & Multimeter
        The PSLab Mini aims to be a streamlined, cost-effective version of the Pocket Science Lab, specifically designed to offer dedicated Oscilloscope and Multimeter functionalities in a compact form factor. This project involves developing a firmware prototype based on the existing PSLab firmware. The prototype will be optimized to run on resource-constrained hardware while delivering precise data acquisition, processing, and visualization for oscilloscope and multimeter measurements. As an alternative, if a dedicated PSLab Mini hardware is not available, an ARM development board can be used to simulate the target environment. This project is ideal for students with embedded systems and firmware development experience, and it will help extend PSLab’s reach into classrooms and educational settings.
        Objectives:
        Firmware Analysis and Requirements Definition:
        Review the existing PSLab firmware to understand its architecture and core functionalities.
        Identify the essential modules for Oscilloscope and Multimeter operations.
        Define the performance and resource requirements for the PSLab Mini.
        Prototype Development:
        Refactor and streamline the current firmware to create a lightweight version that focuses on Oscilloscope and Multimeter features.
        Implement core functionalities such as high-speed data acquisition, signal processing, and measurement display.
        Integrate a basic user interface for real-time visualization of measurements (using an onboard display or external interface).
        Hardware Optimization & Alternative Platform Integration:
        Optimize the firmware for low-power consumption and efficient operation on minimal hardware.
        If a dedicated PSLab Mini device is unavailable, port and test the firmware on an ARM development board as a substitute platform.
        Testing and Validation:
        Develop comprehensive test cases to ensure the accuracy and reliability of oscilloscope and multimeter functions.
        Benchmark the firmware’s performance against standard measurement devices.
        Iterate based on testing feedback to fine-tune responsiveness and accuracy.
        Documentation and Community Engagement:
        Document the firmware architecture, development process, and hardware requirements.
        Provide step-by-step guides for setting up the firmware on the PSLab Mini (or ARM development board).
        Engage with the community for feedback and further enhancements.
        Repository:
        PSLab Firmware Repository: [Insert Repository URL here]
        (If a dedicated repository for the PSLab Mini firmware prototype is created, it will be added to the FOSSASIA GitHub organization.)
        Expected Outcome:
        A fully functional firmware prototype for the PSLab Mini that supports oscilloscope and multimeter features.
        Optimized firmware tailored for resource-limited hardware with low power consumption and reliable performance.
        Comprehensive documentation and test suites for further development and community contributions.
        Optionally, a demonstration of the firmware running on an ARM development board if dedicated hardware is unavailable.
        Skills Required/Preferred:
        Embedded Systems & Firmware Development: Proficiency in C/C++ and experience with ARM Cortex or similar microcontrollers.
        Hardware Interfacing: Familiarity with analog-to-digital conversion, sensor interfacing, and low-level hardware communication protocols.
        Optimization Techniques: Ability to optimize firmware for performance and low power consumption on resource-constrained devices.
        Testing & Debugging: Experience in developing unit tests and debugging firmware in embedded environments.
        Documentation: Strong technical writing skills to produce clear, comprehensive documentation.
        Possible mentors: bessman
        Expected size: 350 h (large project)
        Difficulty level: Intermediate

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/fossasia/
    idea_list_url: https://docs.google.com/document/d/1Tz1KxYefreKzBr98C4vbCv9UwnchZoyTwO8rBrz_lmg/edit?tab=t.0#heading=h.9sjk3ie7l2o2
  

  - organization_id: 41
    organization_name: FOSSology
    no_of_ideas: 13
    ideas_content: |
      
      Data pipelining for safaa project
      Goal: Automate the process of model training using pipelining.
      Currently in Safaa Project data was manually curated And we see that most of the things are manual here. the project should concentrate on creating a pipeline, Utilizing LLMS if required to increase the accuracy, use deep learning techniques to improve.
      Scripts to copy copyright data automatically(group's data or some users data) from fossology instance to train the model.
      
      Test cases needs to be provided as well.
      Category Rating
      Low Hanging Fruit **
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development *
      Project Infrastructure **
      Project size Large
      Preferred contributor Student/professional
      Skills needed Python, ML And Data
      Contact @Kaushl2208 @GMishx @shaheemazmalmmd

      ~~~~~~~~~~
      License Detection Using Large Language Models
      Goal: To automate license detection using license dataset and ensure accurate and up-to-date results by leveraging a Retrieval-Augmented Generation (RAG) approach.
      We have previously tried semantic similarity approach for license detection #104-Atarashi. Which used text processing and prompt engineering. We have tried multiple LLM models for license statement types. Visit Weekly Reports for more performance details
      What we want to achieve?
      Utilize SPDX or SAFAA Database for licenses.
      To create RAG knowledge Base, For model to understand specifics of licenses.
      High Accuracy on Random license texts(Input provided need not to be a full fledged statement). Confidence score if necessary
      Needs to be a Language Agnostic Solution.
      Pipeline to Fetch New License Data (If available) from SPDX Database or SAFAA so RAG Knowledge Base should always be up to date.
      Category Rating
      Low Hanging Fruit **
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development *
      Project Infrastructure **
      Project size Medium/Large
      Preferred contributor Student/professional
      Skills needed Python, LLMs, Fine-tuning, Documentation
      Contact @Kaushl2208 @GMishx @shaheemazmalmmd

      ~~~~~~~~~~
      Transforming Nirjas into a Technical Documentation tool Using Large Language Models (LLMs)
      Goal: To transform Nirjas into a comprehensive technical documentation tool using LLMs by automatically generating, improving, and structuring documentation for source code files. This will include comments, function documentation, and metadata extracted using Nirjas, ensuring consistency, clarity, and quality in technical documentation.
      We have previously worked on extracting metadata and comments using regex-based approaches in Nirjas. While this method provided structured results, it can also be used to generate high-quality documentation. Leveraging LLMs with metadata extraction from Nirjas.
      What we want to achieve?
      Integrate LLMs for Documentation Generation
      Use Existing Knowledge Sources for Training
      Implement a Retrieval-Augmented Generation (RAG) Approach
      Automatic Summarization and Quality Scoring
      Seamless Integration with Existing Tools
      Category Rating
      Low Hanging Fruit **
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development **
      Project Infrastructure **
      Project Size Medium/Large
      Preferred Contributor Student/Professional
      Skills Needed Python, LLMs, Fine-tuning, Data Engineering, Documentation Standards
      Contact @hastagAB @GMishx @Kaushl2208

      ~~~~~~~~~~
      Overhauling scheduler design
      Goal: Improving FOSSology scheduler or replacing with OTS solution
      The existing scheduler design is causing new issues which need to be addressed. Moreover, existing scheduler design is not touched in years.
      Concerning points
      The scheduler is written in C which makes it next to impossible to find cause of a failure.
      The C language does not support exception handling out of the box. It makes code less readable and prone to errors.
      The linear queue design causes issue when there should be only one instance of an agent running for an upload, but overall the agent is not mutually exclusive.
      For example, if the monkbulk has a limit set to 1, it should be implied for only single upload. But with linear queue, this monkbulk job will block all other agents from executing even when they are not effected by the results of monkbulk.
      This essentially makes the agent mutually exclusive even though, there is a special flag EXCLUSIVE for the very same purpose: https://github.com/fossology/fossology/wiki/Job-Scheduler#agentconfs
      One idea on redesigning the queue, it can be broken into buckets per upload each maintaining its own priority queue. There can be another queue for global operations like maintenance, delagent, etc.
      Doing so, each bucket can be traversed in round-robin and pick first pending job and check against host limit. This will eliminate the scenario mentioned in point 3. Also, exclusive agents can be sent to global queue.
        upload specific queue
      |-<upload_2> -> nomos, copyright, ojo, keyword
      |-<upload_3> -> monkbulk, decider, monkbulk, decider
      |-<upload_4> -> reuser, decider
      
      global queue
      -> delagent,
      Since the FOSSology is released, there can be number of new scheduling libraries being released which needs to be explored. They can be a nice addition to the project.
      There have been some work already done in GSoC 2024, Can be visited here
      Category Rating
      Low Hanging Fruit -
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development ***
      Project Infrastructure *
      Project size Large
      Preferred contributor Professional
      Skills needed Go
      Contact @GMishx @Kaushl2208 @avinal @shaheemazmalmmd

      ~~~~~~~~~~
      Debian packaging for Debian repository
      Goal: Improve Debian packaging and make it acceptable for APT
      The existing effort to put FOSSology under Debian packaging list needs to be taken forward. A repository under Debian Salsa was setup initially but not maintained any more: https://salsa.debian.org/fossology-team/fossology It is configured to use gbp.
      Blockers
      The Debian building mechanism does not allow installation from sources other than apt. The Composer packages need to be packed as Debian packages and shipped with FOSSology.
      Packaging and shipping other tools needs to satisfy their licensing terms.
      The versions of packages in APT and actual versions used are different.
      APT also provides JS libraries like JQuery and DataTables but RHL does not.
      See also
      https://github.com/fossology/fossology/pull/2075
      https://wiki.debian.org/PackagingWithGit
      https://wiki.debian.org/SimplePackagingTutorial
      https://wiki.debian.org/Diagrams
      https://wiki.debian.org/PHP
      https://peertube.debian.social/videos/watch/0fb2dbc4-f43d-477e-8b14-20c426f970de
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure ***
      Project size Small
      Preferred contributor Student/Professional
      Skills needed Debian, APT, CMake
      Contact @GMishx @shaheemazmalmmd @Kaushl2208

      ~~~~~~~~~~
      User & Developer Assistant Chatbot using Large Language Models
      Goal: To develop an intelligent assistant chatbot that leverages Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) techniques to provide comprehensive support for both end-users and developers of our tool. The assistant will bridge the gap between users, documentation, and the codebase to ensure an interactive and efficient problem-solving experience.
      The chatbot will be designed to interactively assist new and existing users with various aspects of the tool, including:
      Feature Discovery:
      Answer questions about available features, their functionalities, and usage.
      Provide contextual information derived from the tool's wiki and feature documentation.
      Problem Resolution and Recommendations:
      Assist users during the project setup phase by identifying common setup errors.
      Provide troubleshooting steps for known issues by integrating knowledge from GitHub issues.
      Developer Support:
      Answer codebase-related queries by identifying relevant classes, methods, or functions.
      Enhance developers' understanding of the project by linking features to the corresponding implementation in the code.
      The chatbot will utilize LangChain, RAG, and a Vector Database for retrieval, enabling contextual conversations. A seamless pipeline will integrate multiple data sources, including documentation, GitHub issues, and the codebase.
      What We Want to Achieve:
      For End-Users:
      Improved Onboarding:
      Enable new users to quickly understand the tool's features and capabilities through interactive conversations.
      Efficient Problem Resolution:
      Provide real-time recommendations for known issues encountered during project setup.
      Reduce reliance on manual troubleshooting by surfacing relevant GitHub issues.
      Enhanced User Engagement:
      Increase user satisfaction by offering a conversational interface that adapts to their queries and knowledge level.
      For Developers:
      Codebase Exploration:
      Allow developers to query the codebase for insights into specific classes or functions, fostering faster understanding and debugging.
      Knowledge Consolidation:
      Create a unified interface where feature descriptions, documentation, and implementation details converge.
      Broader Objectives:
      Reduce the time spent on documentation searches.
      PS: There are some features which aligns with the goal but not be possible in short time interval. Topics like: Knowledge Consolidation & Codebase Exploration but the development should be done by taking all this in mind
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory *
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure **
      Project size Large
      Preferred contributor Student/professional
      Skills needed Python, LLMs, Documentation Standards
      Contact @Kaushl2208 @GMishx @shaheemazmalmmd
      
      ~~~~~~~~~~
      Support text phrases and bulk based scanning for MONK a like agent
      Goal: Adding text phrases from UI to database and use existing bulk phrases and provide ability to scan them using MONK and identify files if the match is 100%
      FLOW :
      Create a UI Where user can add multiple text phrases associated with license(FROM FOSSology License Database).
      Use existing bulk phrases table from database.
      Create a new agent like existing MONK agent which not only identifies the matches but also decides the files.
      Test cases needs to be provided as well.
      Category Rating
      Low Hanging Fruit **
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development *
      Project Infrastructure **
      Project size Medium
      Preferred contributor Student/professional
      Skills needed PHP, C++
      Contact @GMishx @shaheemazmalmmd
      
      ~~~~~~~~~~
      Enhance atarashi ability
      Goal: Improve license identification of atarashi
      Improve existing model which have 80 % accuracy.
      Use some model to identify the license-possibility using keywords.
      Once there is some license possibility pass this to existing trained model to identify the accurate license.
      If the trained model miss to find the license then add license-possibility to file so that users checks the file and clarify.
      Work on the existing branch(https://github.com/fossology/fossology/pull/1634) and make sure that this gets merged.
      Know more about atarashi.
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure ***
      Project size Small
      Preferred contributor Student/Professional
      Skills needed Python, ML , CMake
      Contact @GMishx @shaheemazmalmmd @Kaushl2208 @hastagAB
      
      ~~~~~~~~~~
      Integrating Open Source Review Toolkit
      Goal: Using ORT to fetch dependencies and generate SBOM
      Build systems fetch the required dependencies (library/artifact) for a project while building the project. Its important to get an insight of these dependencies for license compliance check.
      The OSS Review Toolkit is an open source project helps to find dependencies in a project.
      The goal of this project is to render the project dependencies created by ort and display those in the fossology-UI. Dependencies can be scheduled directly from the UI and scan with fossology.
      Also vice versa integrate FOSSology to ORT to scan the opensource dependencies.
      Category Rating
      Low Hanging Fruit -
      Risk/Exploratory -
      Fun/Peripheral **
      Core Development ***
      Project Infrastructure *
      Project size Large
      Preferred contributor Student/Professional
      Skills Needed PHP, Cmake, Kotlin
      Contact @GMishx @shaheemazmalmmd @Kaushl2208
      
      ~~~~~~~~~~
      Complete microservices infrastructure for FOSSology
      Goal: Continue the work from previous GSoC and bring FOSSology to a working state on Kubernetes
      As part of GSoC 2021, a large portion of work was done to bring FOSSology to work on Kubernetes. Since then, there have been countless changes to the codebase and the build system. Here are a few objectives we expect to be achieved:
      Go through the changes in the codebase and devise strategies for integrating them
      Inspect the changes in #2086 and complete the work
      By the end, we should have a fully working FOSSology installation on Kubernetes
      Create documentation for setting up FOSSology on a cluster and all the options available
      Stretch goal: Create an all-in-one script for easy Kubernetes setup with FOSSology
      Stretch goal: Add mechanism for health checks of the installation
      Stretch goal: Expose usage and performance metrics
      References
      #2086
      #2075
      https://summerofcode.withgoogle.com/archive/2021/projects/4661860250419200
      Category Rating
      Low Hanging Fruit -
      Risk/Exploratory ***
      Fun/Peripheral *
      Core Development *
      Project Infrastructure ***
      Project Size Medium/Large
      Preferred Contributor Professional
      Skills Needed Kubernetes, Docker/Podman, CMake, Bash
      Contact @avinal @GMishx @shaheemazmalmmd @Kaushl2208
      
      ~~~~~~~~~~
      Rewrite FOSSology UI using React
      Goal: Rewrite FOSSologyUI using react.
      Existing code is old. and needs a fix.
      Implementation of new API'S to existing code.
      Implementation designed templates.
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure ***
      Project size Small
      Preferred contributor Student/Professional
      Skills needed php, react, CMake
      Contact @GMishx @shaheemazmalmmd @Kaushl2208 @deo002
      
      ~~~~~~~~~~
      FOSSology UX and UI design
      Goal: Redesign the FOSSology UX and UI to modernize its interface and enhance user-friendliness.
      Understand the Primary Users
      Identify user personas: Determine who the key users of FOSSology are, such as developers, compliance officers, or open-source contributors.
      Analyze pain points: Conduct surveys, interviews, or user studies to understand the challenges users face while using the current system.
      Analyze the Current Interface
      Evaluate usability issues: Identify areas where the current interface is difficult to use or navigate.
      Highlight outdated design elements: Assess visual components and workflows that no longer align with modern design standards or user expectations.
      Identify Redesign Requirements
      Define goals: Establish clear objectives for the redesign, such as improving efficiency, accessibility, or ease of use.
      Prioritize features: Focus on addressing critical pain points and implementing high-impact improvements.
      Design Reusable Components
      Catalog interface elements: List existing components and determine which can be updated or replaced.
      Ensure consistency: Create reusable design components to maintain a cohesive user experience and simplify scalability.
      Draft Layouts and Workflows
      Streamline user journeys: Map out key workflows to reduce complexity and improve navigation.
      Prototype layouts: Create wireframes or mockups to visualize potential improvements and gather early feedback.
      Establish a Cohesive Design System
      Define visual guidelines: Standardize elements such as colors, typography, and spacing for a unified aesthetic.
      Componentize the UI: Build a library of modular components for easier development and maintenance.
      Gather Feedback and Refine
      Conduct usability testing: Engage users to validate the new designs and identify areas for improvement.
      Iterate based on feedback: Refine layouts, workflows, and components to ensure the redesign meets user needs effectively.
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure ***
      Project size Medium/Large
      Preferred contributor Student/Professional
      Skills needed wireframe and other design techniques
      Contact @EttingerK @GMishx @shaheemazmalmmd @Kaushl2208
      
      ~~~~~~~~~~
      New single file view page to accommodate license + copyright clearing
      Goal: To Redesign & develop new single file view page accommodate all the clearings.
      Have a folder tree with blue & red buttons to indicate the clearing.
      Integrate drag and drop functionality to copy the clearing decisions from one file to another.
      Have a histogram feature to accommodate license groups in the current upload.
      Have a file view page with highlights of all the findings (licenses + copyrights + keywords + ECC).
      Refer the screenshot of the design.
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure ***
      Project size Small
      Preferred contributor Student/Professional
      Skills needed wireframe and other design techniques
      Contact @EttingerK @GMishx @shaheemazmalmmd @Kaushl2208
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/fossology/
    idea_list_url: https://fossology.github.io/gsoc/docs/2025/GSoC-projects

  - organization_id: 42
    organization_name: Fedora Project
    no_of_ideas:
    ideas_content: |
      Fedora Mentored Projects
      Google Summer of Code
      2025
      Ideas
      en-US
      Contents
      Supporting Mentors
      Idea List
      AI-Powered Log Triage and Security Alert Aggregator for Fedora
      Create a service to get a new project to Fedora more easily
      Ideas for Student Projects for 2025
      Fedora is proud to have been accepted as a GSoC mentoring organization. Student applications open on March 24 2025 1800 UTC. Please make sure you carefully read through the general information and application process pages before applying.
      If you are a student looking forward to participating in Google Summer of Code with Fedora, please feel free to browse this idea list. There may be additional ideas added during the application period.
      Now please go read the What Can I do Today section of the main page. This has the answers to your questions and tells you how to apply
      Do not hesitate to contact the mentors or contributors listed on this page for any questions or clarification. You can find helpful people on the Matrix channel, or use the mailing list. can be used for getting help with programming problems.
      Supporting Mentors
      The following contributors are available to provide general help and support for the GSoC program If a specific project mentor is busy, you can contact one of the people below for short-term help on your project or task. add yourselves and your wiki page).
      Sumantro Mukherjee (General development, quality, general Linux, Fedora community, GSoC alumnus, questions about program, misc. advice)
      Fernando F. Mancera (GSoC, general linux, Fedora community, Mentoring, Networking)
      Idea List
      Ideas are subject to change as additional mentors are onboarded.
      AI-Powered Log Triage and Security Alert Aggregator for Fedora
      Create a service to get a new project to Fedora more easily
      AI-Powered Log Triage and Security Alert Aggregator for Fedora
      Difficulty : Easy
      Type : 1 person full time 350hrs (12 weeks)
      Technology : python, bash, scikit-learn, pytorch, tensorflow, security, AI, LLMs
      Mentor : Huzaifa Sidhpurwala
      Email : huzaifas@redhat.com
      Description
      This project aims to automatically parse, classify, and prioritize security-related logs on a Fedora system. The tool will aggregate logs from multiple sources (e.g., SELinux, systemd journal, audit logs) and apply basic machine learning (ML) or natural language processing (NLP) techniques to identify and prioritize potential security events. It will help administrators quickly spot critical alerts while reducing noise from routine messages.
      Deliverables
      As a GSoC intern, you will be responsible for the following :
      Source Code Repository: A publicly accessible GitHub/GitLab project containing all scripts, models, and integration logic.
      Packaged RPM: A Fedora-compliant RPM package that users can install to deploy the log triage tool.
      Documentation: Concise instructions covering installation, usage, configuration, and development/contribution guidelines.
      Demonstration/Prototype: A working setup (CLI or basic UI) showcasing how logs are collected, classified, and prioritized in real time.
      Testing & Evaluation Results: A set of tests (unit/integration) plus any benchmarking or evaluation reports on model performance and accuracy.
      Create a service to get a new project to Fedora more easily
      Difficulty : Easy
      Type : 1 person full time 350hrs (12 weeks)
      Technology : Python, Git, git-forges knowledge and Linux
      Mentor : František Lachman
      Email : flachman@redhat.com
      Description
      This project aims to help people with less experience add a project (=package) to Fedora Linux by using pull-request workflow to be able to get feedback both from tools and more experienced packagers.
      Deliverables
      Source Code Repository: Either a contribution to existing tools (e.g. FedoraReview, Fedora review service and/or Packit) and/or another publicly accessible GitHub/GitLab project containing all the code and scripts.
      Documentation: Concise instructions covering the service and its deployment, testing and development but also usage.
      Demonstration/Prototype: A working setup showcasing how this service works and integrating at least a single automatic feedback.
      Testing & Evaluation Results: A set of tests (unit/integration) of the new code.
      Deployment: The service is deployed and running or it is available to be run and deployed in the form of a container.
      Want to help? Learn how to contribute to Fedora Docs ›
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/fedora-project/
    idea_list_url: https://docs.fedoraproject.org/en-US/mentored-projects/gsoc/2025/ideas/

  - organization_id: 43
    organization_name: Fortran-lang
    no_of_ideas: 26
    ideas_content: |
      
      Version Constraint Resolution (fpm)
      The current decentralized package system in fpm allows dependencies to be fetched via a git repository URL. As part of this, a git tag or commit can be given to require a specific version of a dependency. There is however no way of specifying version compatibility requirements (e.g. >= 1.0.0, <2.0.0) and no way to resolve such requirements across a dependency tree.
      This project will involve:
      Defining a manifest syntax for version compatibility matching
      Implementing support in fpm for solving a set of version compatibility constraints
      A possible approach would be to interface with an existing satisfiability solver such as:
      libsolv: interface via iso_c_binding as a separate fpm package
      See also: existing options for version matching syntax:
      conda
      npm
      cargo
      Expected outcomes: Implemented a working version constraint mechanism in fpm
      Skills preferred: Fortran programming, experience with one or more build systems
      Difficulty: Intermediate, 350 hours
      Mentors: Brad Richardson (@everythingfunctional), Sebastian Ehlert (@awvwgk), Umashankar Sivakumar (@usivakum)
      
      ~~~~~~~~~~
      Build Process Enhancements (fpm)
      Fortran Package Manager (fpm) is pivotal for long-term Fortran success. This GSoC project aims to improve fpm’s build process by improving dependency detection, optimizing linking, implementing shared libraries, ensuring safe concurrent builds, and introducing external Makefile generation.
      The project will address the following tasks:
      Custom flags and configurations
      Implement custom and compiler-dependent flags, and configurations
      External build system Generation:
      Enable generation of external Makefiles akin to cmake -G for advanced project configuration.
      Linking Optimization:
      Replace one-liner linking with static libraries to prevent line buffer overflow in Windows builds.
      Shared Library Implementation:
      Introduce support for shared library targets for project flexibility.
      Dependency Detection:
      Enhance fpm’s dependency detection to minimize rebuilds by parsing or hashing module/submodule files or parsing procedure interfaces in module files. fpm should not rebuild dependencies to a module whose public interface has not changed.
      Expected Outcomes:
      Enhanced dependency tracking and reduced rebuild times.
      Improved reliability in linking, particularly in Windows.
      Increased project versatility with shared library support.
      Safer concurrent builds through file locking.
      Greater project configuration flexibility with external Makefile generation.
      Difficulty: Intermediate, 175 hours.
      Skills preferred: Fortran programming, experience with one or more build systems
      Mentors: Federico Perini (@perazz), José Alves (@jalvesz), Henil Panchal (@henilp105)
      
      ~~~~~~~~~~
      Extended Testing Support (fpm)
      The aim of this project is to create a manifest specification to provide defaults to executable targets in fpm projects. Information can be passed as environment variables, command-line arguments or as a runner. Desired features include:
      Programs should have a way to find resources of which the relative position within the project source directory is known.
      The current binary directory to access other targets within a project.
      Default runners like mpirun/cafrun or scripts from test frameworks should be usable to launch programs.
      A general syntax to define environment variables and command-line arguments should be defined.
      Some features should be implemented directly in fpm, while more elaborated functionality could be implemented in a separate fpm package as an official Fortran-lang fpm package.
      Related issues:
      fpm#179: Testing with fpm test
      Related discussions:
      fpm#328: Example which requires external data
      Expected outcomes: fpm has broader and deeper testing functionality
      Skills preferred: Fortran programming and writing unit tests
      Difficulty: Easy, 175 hours
      Mentors: Sebastian Ehlert (@awvwgk), Brad Richardson (@everythingfunctional)
      
      ~~~~~~~~~~
      Export build order and compile_commands.json (fpm)
      fpm has the ability to automatically determine the build order of a project's source files. This information is valuable to third party tools such as language servers and code analysis tools. The goal of this project is to export the build order of a project's source files in the compile_commands.json.
      The second leg of this project is to implement the full syntax of compile_commands.json as described in the Clang documentation. This would bring fpm a step closer to being compatible with other build tools.
      Expected outcomes: fpm will export a complete compile_commands.json file.
      Skills preferred: Fortran programming, experience with one or more build systems
      Difficulty: Hard, 350 hours
      Mentors: Giannis Nikiteas (@gnikit)
      
      ~~~~~~~~~~
      Support of external third-party preprocessors
      Adding support for external third-party preprocessors is important for fpm due to the additional flexibility they provide when building complex packages. In particular, the Fortran-lang stdlib project exploits the powerful fypp preprocessor for code generation and the support of fypp by fpm is required for stdlib to eventually be compatible as an fpm package.
      This project will require to:
      Modify fpm to optionally invoke a third-party preprocessor before compiling sources;
      Extend the current manifest syntax of fpm for defining preprocessor variables in a preprocessor-independent manner, if necessary;
      Extend the current manifest syntax of fpm for specifying a third-party preprocessor and the corresponding file suffixes, if necessary;
      Passe defined preprocessor variables to built-in preprocessors if necessary;
      Third-party preprocessors should be specified on a per-project basis, i.e. multiple preprocessors might be required, and fpm should be able to report useful errors for missing third-party preprocessors.
      Related issues:
      fpm#78: support for third-party preprocessors (e.g. fypp)
      fpm#308: Fortran-based smart code generation in fpm
      fpm#469: Source pre-processing prior to determining dependencies
      Expected outcomes: fpm has a working preprocessing capability
      Skills preferred: Fortran, C, or Python programming, experience using one or more preprocessors
      Difficulty: easy, 175 hours
      Mentors: Laurence Kedward (@lkedward), Milan Curcic (@milancurcic), Federico Perini (@perazz), Jeremie Vandenplas (@jvdp1)

      ~~~~~~~~~~
      File system library (stdlib)
      Currently, file system operations such as listing contents of directories, traversing directories, and similar, are restricted to 3rd party libraries and compiler extensions that are platform-specific and not portable. This project will entail designing and implementing a cross-platform solution for file system operations.
      Related issues:
      stdlib#201: File system operations
      stdlib#220: API for file system operations, directory manipulation
      WIP implementation:
      stdlib_os
      Expected outcomes: Implemented an stdlib module that provides cross-platform file-system utilities
      Skills preferred: Fortran and C programming, experience using Linux, macOS, and Windows
      Difficulty: Intermediate, 350 hours
      Mentors: Arjen Markus (@arjenmarkus), Milan Curcic (@milancurcic)

      ~~~~~~~~~~
      Library to work with OS processes (stdlib)
      Cross-platform solution to abstract POSIX and Windows API for creating subprocesses.
      Related issues:
      stdlib#22: Interface to POSIX I/O API
      stdlib#308: Subprocesses and Multiprocessing
      Discourse thread:
      Ideas for command module
      Skills preferred: Fortran and C programming, experience using Linux, macOS, and Windows
      Difficulty: Intermediate, 350 hours
      Mentors: Sebastian Ehlert (@awvwgk)

      ~~~~~~~~~~
      Linear algebra and sparse matrices (stdlib)
      Improve dense and sparse linear algebra APIs in the Fortran Standard Library.
      The API development should closely follow the developements on dense linear algebra in order to keep a coherent interface for sparse and dense matrices.
      Related issue: #931 #930 #910 #898 #891 #763 #934
      WIP implementations: #915 #844 FSPARSE
      Expected outcomes: Improved linear algebra and sparse matrix functionality in the stdlib_linalg module
      Skills preferred: Fortran programming, understanding of linear algebra
      Difficulty: Hard, 350 hours
      Mentors: Ondřej Čertík (@certik), Ivan Pribec (@ivan-pi), Jeremie Vandenplas (@jvdp1), Jose Alves (@jalvesz), Federico Perini (@perazz)
      
      ~~~~~~~~~~
      String to number conversion (stdlib)
      This project will enhance stdlib's string handling capabilities for fast number parsing in Fortran.
      Recently, a new module was added to stdlib called stdlib_str2num which implements fast routines for converting strings to numerical types. The participant would get familiar with these implementations and subsequently:
      Create a full benchmark suite for the string to number conversion, across compiler vendors, operating systems, and CPU architectures.
      Explore ways to improve robustness and efficiency, e.g. error handling.
      Propose a shallow interface for the string_type facility in stdlib.
      Propose an enhancement to the loadtxt facility function to speed-up file reading.
      Depending on the advancement, the participant is also encouraged to include a roadmap for inclusion of the inverse conversion by following the intitiative in this thread ryu-based to_string function
      Relevant thread on Fortran Discrouse: Faster string to double
      Expected outcomes: Enhancement of stdlib fast string to number conversion
      Skills preferred: Fortran and C programming, understanding of floating-point arithmetic
      Difficulty: Hard, 350 hours
      Mentors: Jose Alves (@jalvesz), Carl Burkert (@carltoffel) Brad Richardson (@everythingfunctional), Ivan Pribec (@ivan-pi)
      
      ~~~~~~~~~~  
      Compile benchmarking code written in Fortran with LFortran and improving LFortran's performance on these benchmarks (LFortran)
      https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/fortran.html contains all the benchmark codes written for various problems such as n-body, sepctral norm, mandelbrot. The workflow would involve first doing bug fixes to compile the code (modifying the input code would be okay) with LFortran and producing correct outputs. Then, improving LFortran to perform better or equivalent to other Fortran compilers such as GFortran.
      n-body already compiles with workarounds with LFortran main. See, https://github.com/lfortran/lfortran/pull/1213. More work needs to be done for other benchmark codes.
      Expected outcomes: LFortran can compile as many benchmark codes as possible. Performing better than other compilers would be an additional plus.
      Skills preferred: Fortran and C++ programming
      Difficulty: intermediate/hard, 350 hours
      Mentors - Gagandeep Singh (Github - @czgdp1807)
      
      ~~~~~~~~~~
      Compile any Fortran code (LFortran)
      The primary goal is to compile as many codes as possible. We have identified and listed those at label:code-to-be-compiled.
      This project aims to pick up a code and get it compiled to ASR, then to LLVM, binary and assure that values align with GFortran (or other Fortran compilers). We can have several of these projects at the same time.
      Expected outcomes: LFortran can compile chosen code.
      Skills preferred: Fortran and C++ programming
      Difficulty: intermediate/hard, 350 hours
      Mentors - Pranav Goswami
      
      ~~~~~~~~~~
      Compiling SciPy with LFortran (LFortran)
      Currently LFortran compiles about 60% of all SciPy Fortran packages and can parse all the Fortran source code in SciPy. The goal of this project is to compile the rest of them. This project involves implementing the rest of the semantics that is needed to compile the Fortran files with LFortran.
      Being able to compile SciPy with LFortran would make a huge impact on both LFortran and SciPy.
      Expected outcomes: LFortran can compile all Fortran code in SciPy.
      Skills preferred: Fortran and C++ programming
      Difficulty: intermediate, 350 hours
      Mentors - Ondřej Čertík, Pranav Goswami
      
      ~~~~~~~~~~
      Compiling LAPACK with LFortran (LFortran)
      Progressing towards beta we need to compile as much of the LAPACK routines as possible. The goal of this project is to compile LAPACK Fortran codes. It involves implementing the rest of the semantics that is needed to compile the Fortran files with LFortran.
      Expected outcomes: LFortran can compile all code in LAPACK.
      Skills preferred: Fortran and C++ programming
      Difficulty: intermediate, 350 hours
      Mentors - Ondřej Čertík, Pranav Goswami
      
      ~~~~~~~~~~
      Allow running Fortran in the browser (LFortran)
      We have LFortran running in the browser using WASM here: https://dev.lfortran.org/, the goal of this project would be to improve the user interface. Here is a list of issues that the project can work on fixing: https://github.com/lfortran/lcompilers_frontend/issues
      This project would entail working with LFortran, LLVM, Emscripten, and Webassembly to allow running Fortran in the browser.
      Skills preferred: Fortran and C++ programming
      Difficulty: intermediate, 350 hours
      Mentors - Ondřej Čertík
      
      ~~~~~~~~~~
      Implementation of features on the ASR and LLVM level (LFortran)
      The roadmap https://gitlab.com/lfortran/lfortran/-/issues/272 issue contains a list of Fortran features that we want implemented. Each feature should be implemented at the ASR level and in the LLVM backend to be complete. If AST is missing for a given feature, then it has to be implemented also.
      Here you can pick a feature or a set of features from the list and propose it as a GSoC project. In other words, this project idea can accommodate multiple student projects.
      List of resources for more information and background:
      ASR.asdl, the comment at the top explains the design motivation
      asr_to_llvm.cpp is the LLVM backend
      ast_to_asr.cpp is the AST -> ASR conversion where all semantics checks are being done and compiler errors reported to the user
      Developer Tutorial
      If you have any questions, please do not hesitate to ask, we can discuss or provide more details.
      Mentors: Ondrej Certik (@certik)
      
      
      
      ~~~~~~~~~~
      MPI support (fortls)
      fortls has support for Fortran intrinsics, Standard modules and OpenMP. It does not however support MPI. The goal of this project is to add full support for completions, hover and signature help for MPI variables, subroutines and functions.
      Due to the size of the MPI standard, the process of extracting the necessary information from the standard such as names, interfaces and documentation will be automated. The student will be responsible for creating a scraper/parser to fetch the necessary information from the MPI standard and then create the serialised data (JSON) to be used by fortls.
      Discourse thread: MPI documentation and interfaces
      Expected outcomes: fortls will have completion and hover support for MPI.
      Skills preferred: Python programming and understanding of Fortran
      Difficulty: Intermediate, 175 hours
      Mentors: Giannis Nikiteas (@gnikit)
      
      
      ~~~~~~~~~~
      Semantic highlighting and collapsable scopes (fortls)
      As part of this project the student will add support to fortls for the Semantics Tokens request, which is used to provide improved syntax highlighting and the Folding Range request, which is used to provide collapsable scopes.
      Related Issues:
      fortls#56
      Expected outcomes: fortls will serve for semantic highlighting and collapsable scopes requests.
      Skills preferred: Python programming and understanding of Fortran
      Difficulty: Intermediate, 175 hours
      Mentors: Giannis Nikiteas (@gnikit)
      
      ~~~~~~~~~~
      Replace explicit LSP interface with pygls (fortls)
      fortls uses explicit interfaces to the Language Server Protocol (LSP). To decrease code duplication and increase maintainability, the work of maintaining the explicit interfaces should be replaced with the use of pygls' module.
      Related Issues:
      fortls#96
      Expected outcomes: fortls uses pygls' to define LSP interfaces, types and requests.
      Skills preferred: Python programming and understanding of the Language Server Protocol
      Difficulty: Hard, 350 hours
      Mentors: Giannis Nikiteas (@gnikit)
      
      
      ~~~~~~~~~~
      Python environment manager (vscode-fortran-support)
      In the Modern Fortran for VS Code extension, the use of Python as a means to install third party tools is essential. The goal of this project is to create a robust Python environment manager for installing and running third party tools such as fortls, fpm, findent, etc., taking into account the user's setup (venv, conda, system Python, etc.).
      Expected outcomes: Modern Fortran for VS Code will have a robust Python environment manager for installing and running third party tools.
      Skills preferred: Typescript, Python programming
      Difficulty: Hard, 175 hours
      Mentors: Giannis Nikiteas (@gnikit)
      
      
      ~~~~~~~~~~
      vscode integration with fpm (vscode-fortran-support)
      The goal of this project is to allow fpm integration with the Modern Fortran extension for Visual Studio Code, similar to how CMake and Meson are integrated in VS Code.
      Using an Activity bar icon, the user will be able to build and run projects, tests and examples. The student will be responsible for creating the GUI integration and the necessary backend to communicate with fpm.
      Expected outcomes: Modern Fortran for VS Code will have a GUI integration with fpm to build and run projects, tests and examples.
      Skills preferred: Typescript, Fortran programming
      Difficulty: Hard, 350 hours
      Mentors: Giannis Nikiteas (@gnikit)
      
      ~~~~~~~~~~
      Standard Conformance Suite
      Fortran compilers' support for ISO Fortran standards generally lag the publication of the standard by several years or longer. Fortran consultants Ian Chivers and Jane Sleightholme periodically publish a paper containing a table detailing the standard features supported by 10 compilers. Gathering the tabulated data requires a considerable amount of effort on the part of the authors and the compiler developers. The chosen venue for publishing the table also puts it behind a paywall: access requires a subscription to ACM SIGPLAN Fortran Forum. The project will automate the generation of the table, make it more detailed and empower the community to contribute to by submitting small tests to an open-source conformance test suite.
      Prior work:
      fortran-compiler-tests
      flibs chkfeatures
      Defunct
      Fortran Testsuite Proposal
      Expected outcomes: A comprehensive test suite that generates a report of standard conformance for any Fortran compiler. The suite is not expected to be 100% complete by the end of the project, but should be significant in terms of standard coverage.
      Skills preferred: Fortran programming, experience reading and interpreting the Fortran Standard, and writing tests
      Difficulty: Hard, 350 hours
      Mentors: Damian Rouson (@rouson), Arjen Markus (@arjenmarkus), Ondřej Čertík (@certik)
      
      ~~~~~~~~~~
      Coarray Fortran Framework of Efficient Interfaces to Network Environments (Caffeine)
      This project would add support for grouping images (parallel processes) into teams that allow submodes to execute independently. Caffeine 0.1.0 uses the GASNet-EX networking middleware software as a back end for supporting most of the non-coarray parallel features of Fortran 2018 except for the intrinsic derived team_type and related features. Work is underway to support the coarray features that most applications will need for expressing custom parallel algorithms. The teams feature set is the one significant non-coarray parallel group of features not yet implemented in Caffeine.
      Expected outcomes: Caffeine can be used to create images groups in execution parallel programs
      Skills preferred: Fortran and C programming
      Difficulty: Intermediate, 175 hours
      Mentors: Damian Rouson (@rouson)
      
      ~~~~~~~~~~
      Get fortran-lang/minpack to be used in SciPy
      fortran-lang/minpack #14
      The participant would work with Fortran-lang and SciPy teams toward implementing fortran-lang/minpack in SciPy.
      Expected outcomes: fortran-lang/minpack is incorporated into SciPy.
      Skills preferred: Fortran-C interop, Python programming
      Difficulty: Easy, 175 hours
      Mentors: Sebastian Ehlert (@awvwgk)
      
      ~~~~~~~~~~
      Improving fastGPT: Making it Faster, Easier to Use, and More General
      The fastGPT project is a Fortran implementation of GPT-2 that is comparable in speed to PyTorch. Although it is already very fast on CPUs, there is still room for improvement in terms of usability and performance on CPU and other architectures, such as GPUs.
      This project aims to explore various aspects of fastGPT to improve its usability and performance. Some potential areas of exploration include:
      Parallelism: Investigate the use of parallelism in fastGPT, including MPI and coarrays, to potentially make it even faster. Given that GPT inference is dominated by large matrix-matrix multiplications over a few layers, we will carefully investigate which parallel approach is the best (whether MPI, coarrays, OpenMP or just parallel BLAS that we already have).
      Reduced precision models: Experiment with using reduced precision models (e.g., 16-bit or 8-bit floats) instead of the default 32-bit to potentially speed up inference.
      GPU acceleration: Explore how to optimize fastGPT for GPU architectures to potentially make it even faster.
      UI improvements: Add a chat mode (similar to chatGPT). Explore how to make it easier to use as a grammar checker, or creating summaries, or other areas where GPT-2 is strong. Make it a nice Fortran library, installable using fpm, usable in other projects. Investigate how to use it with the neural-fortran project.
      Expected outcomes: Create an improved fastGPT implementation that is faster, easier to use, and more general.
      Skills preferred: Fortran, linear algebra
      Difficulty: Intermediate, 175 hours
      Mentors: Ondřej Čertík (@certik), Milan Curcic (@milancurcic)
      
      ~~~~~~~~~~
      Fortran Graphics Library
      Fortran does not have native graphics handling capabilities. While several bindings interfacing Fortran to graphics and plotting libraries are available (e.g., f03gl, sdl, pyplot, dislin, plplot ), no up-to-date open-source graphics package with a pure, modern Fortran API is available.
      The aim of this project is to lay out the basics of an object-oriented "canvas" representation in object-oriented Fortran. The contributor would implement, document, and test basic graphics classes (2d points, lines, brushes, etc.), an abstract graphics canvas API with backends to both file and graphics devices (i.e., bitmap, PNG, OpenGL, SVG, etc.) The outcome of this project would be a contribution to the development of a platform-agnostic graphics library for Fortran.
      Expected outcomes: Design and implement classes for 2d graphics primitives, a unified graphics canvas API, and several backend implementations.
      Skills preferred: Fortran, C, 2D graphics basics
      Difficulty: Intermediate, 350 hours
      Mentors: Federico Perini (@perazz)*
      
      
      ~~~~~~~~~~
      Improved generation of Fortran interfaces for PETSc
      PETSc, the Portable, Extensible Toolkit for Scientific Computation, pronounced PET-see, is for the scalable (parallel) solution of scientific applications modeled by partial differential equations (PDEs). It has bindings for C, Fortran, and Python (via petsc4py). PETSc also contains TAO, the Toolkit for Advanced Optimization, software library. It supports MPI, and GPUs through CUDA, HIP, Kokkos, or OpenCL, as well as hybrid MPI-GPU parallelism; it also supports the NEC-SX Tsubasa Vector Engine.
      Currently, only a part of the Fortran interfaces can be generated automatically using bfort. Since the manual generation of the remaining interfaces is tedious and error prone, this project is about an improved generation of Fortran interfaces from PETSc's C code.
      The main tasks of this project are
      Definition of a robust and future-proof structure for the Fortran interfaces
      Selection and/or development of a tool that creates the interfaces automatically
      More specifically, the first task is about finding a suitable structure of the C-to-Fortran interface that reduces the need of 'stubs' on the C and Fortran side making use of modern Fortran features where appropriate. This task will involve evaluating different approaches found in other projects taking into account the object-oriented approach of PETSc. Prototypes will be implemented manually and evaluated with the help of the PETSc community. The second task is then the automated generation of the Fortran interfaces using the approach selected in the first task. To this end, it will be evaluated whether an extension of bfort, the use of another existing tool, or the development of a completely new tool (probably in Python) is the most suitable approach.
      Links:
      PETSc
      bfort
      Fortran Wiki: Generating C Interfaces
      Fortran Discourse: ISO_C_binding
      Expected outcomes: Stable and robust autogeneration of Fortran interfaces for PETSc that works for almost all routines
      Skills preferred: Programming experience in multiple languages, ideally C and/or Fortran
      Difficulty: Intermediate, 350 hours
      Mentors: Martin Diehl (@MarDiehl)
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/fortran-lang/
    idea_list_url: https://github.com/fortran-lang/webpage/wiki/GSoC-2025-Project-ideas

  - organization_id: 44
    organization_name: Free and Open Source Silicon Foundation
    no_of_ideas: 19
    ideas_content: |
      
      ZynqParrot RISC-V Tracer
      ZynqParrot (https://github.com/black-parrot-hdk/zynq-parrot) is a framework for doing self-contained, FPGA-based "hostless" ASIC accelerator development. It is designed to be extremely general and has been used to prototype IP from individual ASIC/FPGA cores to full multicore processors. In addition, ZynqParrot has been used to bringup N=1 ASIC silicon in the lab.
      RISC-V provides a trace format specification (https://github.com/riscv-non-isa/riscv-trace-spec) which can be used for diagnostic performance and debugging. This project will design and integrate a RISC-V Trace implementation into the ZynqParrot environment, requiring SystemVerilog implementation + testing, Block Diagram (Vivado IPI) design and well as writing C++ driver to work in both Co-Simulation and Co-Emulation.
      Skill level: intermediate
      Project length: medium (175 hours)
      Mentors: Dan Petrisko
      Language/Tools: SystemVerilog, C++, some knowledge of computer architecture. RISC-V knowledge preferred but not required. FPGA tools such as Vivado strongly encouraged but not required.
      
      ~~~~~~~~~~
      Surfer memory and wide array support
      Surfer (https://surfer-project.org) is an open source waveform viewer designed to be snappy and extensible. Waveform viewers work well for visualizing individual signals, but for large arrays or memories users are often more interested in changes to individual elements rather than the whole array.
      For this, a separate UI element where memory content can be visualized as a table would be much more useful. Beyond just visualizing the content, also having the ability to highlights elements that have changed between timestamps or around the cursor would be extra useful.
      Skill level: intermediate
      Project Length: medium (175 hours)
      Mentors: Frans Skarman Oscar Gustafsson
      Languages/Tools: Rust. Familiarity with hardware design is helpful to have some context of what the tool is used for is helpful, but the project itself is pure software. Some familiarity with egui is also helpful though certainly not required.
      
      ~~~~~~~~~~
      cocotb v2 Code Migration Helper
      The upcoming cocotb v2.x release will have quite some breaking changes (see https://docs.cocotb.org/en/latest/release_notes.html), so users and extension developers will have to actively migrate existing code.
      A code migration helper tool would be helpful, even if it is not perfect.
      Some links:
      https://libcst.readthedocs.io/
      https://lukeplant.me.uk/blog/posts/tools-for-rewriting-python-code/
      Skill level: Intermediate/Advanced
      Duration: medium (175 hours)
      Language/Tools: Python, cocotb
      Mentor: Kaleb Barrett

      ~~~~~~~~~~
      Generate Counter Examples for Bounded Model Checks in CIRCT
      The CIRCT project has its own bounded model checking tool, circt-bmc. It takes a hardware design described in CIRCT's MLIR dialects and translates it into a program that uses the Z3 SMT solver to formally prove assertions. If it finds a way how assertions can be violated, it simply terminates with an error message. This is not very useful for a user that is trying to debug a hardware design that they have written. Instead, we would like circt-bmc to produce a counter-example, essentially a signal trace that shows and example of how the assertions can be violated. The Z3 SMT solver actually provides a counter-example as part of its checking, circt-bmc just does not use that yet.
      We would love you to extend circt-bmc with a counter-example feature that produces a signal trace for violated assertions, ideally a VCD waveform as a starting point. This will require you to modify the lowering pass that translates a hardware design to Z3 solver calls: in addition to the asserts that need to be checked, you will also want to translate any named ports, wires, registers into the corresponding Z3 solver expressions. The bounded model check can then take a snapshot of all these expressions in every time step. When Z3 finds a counter-example, you can go through every time step, evaluate all the solver expression for all user-visible names, and write them to a waveform.
      This may also be an excellent opportunity to introduce a waveform writing library for CIRCT. Eventually, we'd want different tools in CIRCT to be able to write various waveform formats such as VCD, FST, etc. It would be great if there is a common interface for waveform writers, and if CIRCT could then provide various implementations for different waveform formats. Tools like Arcilator, circt-bmc, and circt-lec would then use this library to produce signal traces.
      CIRCT is based on MLIR and LLVM, and are implemented in C++. So you'll definitely want to have some experience writing C++ code, since LLVM-based projects often follow a fairly peculiar and performance-conscious style of C++. You may also benefit from knowing a little bit about SAT and SMT solvers, and how bounded model checks can be implemented incrementally using these solvers.
      Skill Level: Medium
      Duration: 175 hours or 350 hours
      Language/Tools: C++, CIRCT, MLIR, LLVM
      Mentor: Fabian Schuiki,  Martin Erhart, and others in the CIRCT community

      ~~~~~~~~~~
      Spike + Sim-X
      The project is to interface Spike with Sim-X. Spike is a functional RISC-V ISA simulator and Sim-X is a high-level simulator for the Vortex GPGPU.
      Existing work allowed us to integrate the Vortex GPGPU RTL in the OpenPiton multi-core research platform (https://cea.hal.science/cea-04772235/document). To ease programming though, we would like to test software correctness using a high-level simulator. It would be faster than relying on RTL simulation. Interfacing Spike with Sim-X would allow us to simulate functionaly our heterogeneous CPUs+GPU shared-memory architecture, hence allowing us to ease future software development.
      Skill level: Intermediate
      Duration: medium (175 hours)
      Language/Tools: C++, RISC-V GNU Cross-compiler, Vortex LLVM compiler
      Mentor: Davy Million

      ~~~~~~~~~~
      OpenRISC Linux Feature Development
      The OpenRISC Linux kernel support is under constant development but there are certain Linux facilities that are not yet used or available on the OpenRISC platform.
      This project will have the student developing, testing and sending patches up to the Linux kernel. This includes:
      Use the cacheinfo API for reporting CPU details in OpenRISC Linux.
      Add tracing facilities to OpenRISC Linux including: jump_label, ftrace, kprobes, eBPF etc.
      Skill level: Advanced
      Project Length: large
      Language/Tools: Linux, C, Assembly, OpenRISC architecture
      Mentor: Stafford Horne
      
      ~~~~~~~~~~
      Generic MinimumLinuxBoot for RTL Simulations
      This project consists of booting Linux in Qemu, save the memory state, thencontinue the simulation in an RTL Simulation of OpenPiton. The first part of the project consists of understanding what states need to be saved, probably a combination of the TLB and MMU states as an starting point could be enough. Then, this state needs to be saved in a file format that the checkpoint mechanism of Verilator understand or create a synthetic benchmark that makes the proper MMU configuration. The second part of the project is adding the necessary support in OpenPiton Simulation infrastructure to continue the simulation and being able to launch some applications.
      OpenPiton uses different languages like Verilog, Python, Perl, and C. Verilator C++. Additionally, some background in hardware design is useful.
      Skill Level: Medium/Advanced
      Duration: 350 hours
      Language/Tools: Verilog, C++, SystemVerilog
      Mentors: Guillem López Paradís and Jonathan Balkind
      
      ~~~~~~~~~~
      Using AI to Improve Open-Source IP
      What if we could instantly improve all the existing open-source Verilog by reducing its size, improving its maintainability, making it more configurable, identifying bugs, and creating visualization for it? How could you possibly do all those things over one summer as a student? Well, you can't. But you could help to make significant strides in that direction.
      Transaction-Level Verilog (TL-Verilog) models are smaller, cleaner, and less bug-prone than their Verilog counterparts. But there's not much TL-Verilog in the wild yet. If you ask ChatGPT to convert your code today, you won't be happy with the results. But with careful coaching, AI models can be trained for the job.
      Since LLMs understand Verilog better than TL-Verilog, we do as much as possible with the Verilog to prepare it for conversion to TL-Verilog. An initial flow has been put in place for this. A Python program iterates through a recipe of prompts, each performing an incremental refactoring step. After each step, formal equivalence verification (FEV) is used to ensure functional correctness. Human intervention is possible and is currently needed at almost every step.
      Your project will be to use and enhance this flow to refactor an open-source Verilog project like SERV. In the process, you'll contribute to the automation, and your work will become training data to improve future LLMs for this task.
      Skill level: Intermediate/Advanced
      Duration: 350 hours
      Language/Tools: Verilog, Python, TL-Verilog
      Repo: https://github.com/stevehoover/conversion-to-TLV
      Mentor: Steve Hoover

      ~~~~~~~~~~
      Metro-MPI++
      Metro-MPI is a generic methodology to distribute RTL simulation and unlock SoCs’ inherent parallelism. We partition well-defined blocks within designs into isolated simulation processes that communicate via MPI message passing. Metro-MPI works particularly well with replicated blocks of comparable size, such as manycores with NoCs. Verilator is an open-source Verilog simulator and linting tool that translates Verilog HDL code into optimized C++ or SystemC code, allowing for fast, cycle-accurate simulation of digital circuits.
      Automatic partitions with Metro-MPI We want to add the automatic support of metro-MPI inside other tools, like Verilator or Essent. The idea would be to detect the top modules that are suitable to be interfaced with metro-MPI. An automatic partition algorithm would be ideal although we can start with a user-guided approach like pragmas. The project will be divided into two big milestones: the initial task is to use the methodology from Metro-MPI to speed up the simulation (e.g. using messages with MPI to communicate between partitions); the second task would be to influence the partitions of the design to ease the usage of MPI between them.
      Metro-MPI @FPGA We would like to explore the same methodology that Metro-MPI introduces but to connect multiple FPGAs with MPI.
      We are also open to other improvements on metro-MPI:
      Explore the support of OpenMP instead of openMPI
      Explore making the simulations faster with statistical analysis: predict values that will take the MPI messages on a certain simulation, making checkpoints and rolling back in case of predicting wrong.
      Improve current Verilator support from v4 to v5.
      Scale Simulations up to 10K cores (currently we support up to 1024 cores)
      Metro-MPI uses Verilog and C++. Additionally, some background in hardware design is useful.
      Skill Level: Medium/Advanced
      Duration: 350 hours
      Language/Tools: C++, MPI, SystemVerilog
      Mentors: Guillem López Paradís and Jonathan Balkind

      ~~~~~~~~~~  
      OpenLane Web-based Graphical User Interface
      Details: OpenLane is the premier open source RTL-to-GDSII flow. Versions 2.0 or higher's modular architecture allows for constructing complex flows using nodes called "steps," Users who are adept in Python can create many such complex flows, including flows that are parallel. A web-based GUI of some kind (based on a library such as ReactFlow https://reactflow.dev) would greatly enhance the ability of novice users to create custom OpenLane-based flows with ease.
      Skill level: Beginner or Intermediate
      Duration: 175 hrs.
      Language/Tools:: TypeScript (React), Python
      Mentor: Mohamed Gaber, Mohamed Shalan
      ~~~~~~~~~~
      LiteX SMP SoC for OpenRISC
      The LiteX project makes creating FPGA-based SoCs easy. LiteX supports creating SoCs containing OpenRISC CPU cores. Up until now however, there have been no LiteX SoCs that support running OpenRISC multicore/SMP Linux. The linux-on-litex-vexrisc project provides a good example of how to develop and document getting Linux up and running on a LiteX SoC; including multicore.
      Using linux-on-litex-vexrisc as an example, this project will have the student creating a project to help people get up and running with OpenRISC. The final goal shall be to have a documented multicore OpenRISC LiteX SoC running Linux SMP.
      Skill level: Advanced
      Project Length: large
      Language/Tools: Verilog, LiteX, Linux, Python, OpenRISC architecture
      Mentor: Stafford Horne

      ~~~~~~~~~~
      Improve CIRCT's Verilog Frontend
      The CIRCT project uses the Slang frontend to parse the SystemVerilog hardware description language. The sv-tests project runs many SystemVerilog frontends on a benchmark suite of input files to test their quality. We would love you to use the sv-tests results as a starting point to find key missing features that you can add to circt-verilog and fix failing tests. Tests often fail for similar reasons, and fixing small things can cause large numbers of tests to start passing.
      SystemVerilog is a complicated language and CIRCT builds a deep stack of intermediate representations using MLIR to process it. The Slang frontend produces an Abstract Syntax Tree which the ImportVerilog pass converts into the Moore dialect, the first IR level in circt-verilog. Various optimizations are already performed at this level. Then the MooreToCore conversion pass lowers the Moore dialect to the HW, Comb, Seq, and LLHD dialects for further processing. Finally, several optimization passed implemented on the LLHD dialect analyze the hardware design and detect common structures. If you want to sink your teeth into compiler and IR design, this is the perfect project for you!
      Slang and CIRCT are based on MLIR and LLVM, and are implemented in C++. So you'll definitely want to have some experience writing C++ code, since LLVM-based projects often follow a fairly peculiar and performance-conscious style of C++.
      Skill Level: Advanced
      Duration: 175 hours or 350 hours
      Language/Tools: C++, CIRCT, MLIR, LLVM
      Mentor: Fabian Schuiki, Martin Erhart, and others in the CIRCT community

      ~~~~~~~~~~
      Architectural Improvements to OpenPiton+Ariane for RISC-V Profile Compliance
      OpenPiton+Ariane is a permissively-licensed RISC-V manycore processor, built as a collaboration between the PULP Platform from ETH Zürich and the OpenPiton Platform from Princeton University. We would like to co-optimise OpenPiton and Ariane/CVA6 in their combined platform, to improve performance of the processor both in FPGA emulation systems and for eventual silicon chips. We are particularly interested in moving the platform toward RISC-V RVA23 profile compliance and so developing any new extension support needed for this purpose would be a great GSoC opportunity!
      Skill level: Intermediate
      Duration: 175 or 350 hours
      Language/Tools: Verilog, SystemVerilog, RISC-V
      Mentor: Jonathan Balkind, Nils Wistoff
      
      ~~~~~~~~~~
      Cohort++
      Cohort is a framework designed to integrate hardware accelerators into software systems while maximizing efficiency seamlessly. It introduces Software-Oriented Acceleration (SOA), a paradigm that simplifies and optimizes interactions between software and hardware accelerators. By leveraging existing software abstractions—such as shared-memory queues—Cohort enables a streamlined, high-performance communication channel between software components and accelerators.
      This project consists of improving the performance of OpenPiton memory hierarchy to better suit Cohort. For example, there is prior work on supporting wider NoCs, and cachelines in OpenPiton; we changing the Cohort engine's interaction with the coherence protocol; multiple MMU outstanding requests for higher performance.
      We have other ideas to work more on Cohort software support and we are also open to new proposals. Some examples:
      Support for other data structures instead of only queues
      Connect the openMP and/or openMPI runtime library to use Cohort queues
      Add the support for PRGA to be used with Cohort
      Skill Level: Medium/Advanced
      Duration: 350 hours
      Language/Tools: C++, SystemVerilog
      Mentors: Guillem López Paradís , Davy Million and Jonathan Balkind
      
      ~~~~~~~~~~
      Seamless multi-frontend support for OpenLane
      Details: OpenLane is the premier open source RTL-to-GDSII flow. Versions 2.0+ currently support handling multiple frontends for compilation:
      Yosys Default - Verilog
      Synlig - SystemVerilog
      GHDL - VHDL (x86-64-only)
      However, in the cases of VHDL and Verilog specifically– there is no way to mix and match Verilog and VHDL in one design, for example, which is common when reusing IPs.
      This task proposes a retool to OpenLane synthesis to, instead of having two different flows (Classic and VHDLClassic), have one flow accepting a heterogeneous list of files, which can then be inspected to determine the proper frontend to be used.
      The project may involve enhancements to one or more of the C++-based Yosys frontends, as well as the addition of more frontends for languages such as Chisel and Amaranth.
      Skill level: Intermediate
      Duration: 175 hrs.
      Language/Tools: Python, Verilog, C++, Nix
      Mentor: Kareem Farid, Mohamed Shalan

      ~~~~~~~~~~
      OpenRISC Benchmarking and Performance improvements
      The OpenRISC CPU architecture has multiple CPU implementations including the mor1kx and marocchino. Recent testing has shown that memory access on the marocchino is slightly slower compared to the mor1kx.
      This project will have the student:
      Continue from where the 2024 GSoC student left off.
      Use tools like the Embench modern benchmark suite to measure OpenRISC processor and compiler toolchain performance.
      Document the OpenRISC performance at Embench IoT results to be able to compare OpenRISC vs other popular CPUs.
      Track down and improve OpenRISC CPU performance by finding and fixing deficiencies in the verilog designed cores.
      Skill level: Advanced
      Project Length: large
      Language/Tools: Verilog, Shell scripting, C, Assembly, Python
      Mentor: Stafford Horne

      ~~~~~~~~~~
      OpenLane Flow Declaration GUI
      Details: OpenLane is the premier open source RTL-to-GDSII flow. Versions 2.0 or higher's modular architecture allows for constructing complex flows using nodes called "steps."
      Users who are adept in Python can create many such complex flows, including flows that may run multiple steps in parallel, but those who are not may face difficulty doing so.
      A web-based GUI of some kind (based on a library such as ReactFlow https://reactflow.dev) would greatly enhance the ability of novice users to create custom OpenLane-based flows with ease.
      Skill level: Beginner to Intermediate
      Duration: 175 hrs.
      Language/Tools:: TypeScript (React), Python
      Mentor: Mohamed Gaber, Mohamed Shalan
      
      ~~~~~~~~~~
      Adding TL-Verilog Support to Surfer
      Details: Surfer is a modern open-source waveform viewer that evolved alongside the Spade HDL. It has gained broader popularity beyond the Spade ecosystem, and adding support for other emerging HDL capabilities will benefit the community.
      TL-Verilog models have higher-level knowledge that can be reflected in a waveform viewer to enhance the debugging experience. Most notably, TL-Verilog signals can be "invalid". Invalidity is, in some respects, similar to dont-care state. One distinction is that validity is compatible with two-state simulators, like Verilator.
      This project will focus on two main features to enhance TL-Verilog waveforms in Surfer:
      Displaying TL-Verilog-style signal and hierarchy names in TL-Verilog standard colors.
      Reflecting validity on signal values.
      These two features can currently be seen in the Makerchip IDE's waveform viewer.
      Skill level: Medium/advanced
      Language/Tools: Rust
      Duration: 350 hrs
      Repo: https://gitlab.com/surfer-project/surfer
      Mentors: Frans Skarman (creator of Surfer and Spade), Oscar Gustafsson, Steve Hoover (creator of TL-Verilog & Makerchip)
      
      ~~~~~~~~~~
      Device-Under-Test Python Typing Stub Generator for cocotb tests
      cocotb tests manipulate the signals of the Device-Under-Test (DUT) to verify the design, but what was the name of that signal I needed to wiggle???
      If we had a Python typing stub for the DUT, we could get the Pylance VS Code extension to help us by listing the signals in the DUT in an autocomplete pop-up; we could use Python static type checkers like mypy to ensure we didn't fat-finger the name of some module; or use generated typing stubs to create abstract bus definitions that users could "mock out" when needed.
      cocotb has existing DUT introspection capabilities that could be leveraged to generate Python typing stubs. However, existing features may not be enough, and additional features may need to be added, in addition to the generator itself. Perhaps even, this code could be set up for future use by a language server, like slang, to generate even more informative typing stubs.
      See more information here.
      Skill level: Beginner to Intermediate
      Duration: medium (175 hours)
      Language/Tools: Python, cocotb
      Mentor: Kaleb Barrett
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/free-and-open-source-silicon-foundation/
    idea_list_url: https://fossi-foundation.org/gsoc/gsoc25-ideas

  - organization_id: 45
    organization_name: FreeCAD
    no_of_ideas: 38
    ideas_content: |

      Improve FreeCAD Hidden Line Removal
      Outline
      FreeCAD's Technical Drawing module (TechDraw) relies heavily on the OpenCascade Hidden Line Removal algorithms. These algorithms can be very slow, do not provide progress reporting and do not provide any linkage between the input shape and the output.

      Details
      The TechDraw module provides projections, section views and detail views of 3D model components and assemblies developed in FreeCAD modules such as Part, PartDesign and Draft.

      Expected Outcome
      a) develop new code for projecting shapes and creating the geometry for technical drawings.
      -or-
      b) modify the existing OpenCascade code as an enhancement.

      Project Properties
      Both OpenCascade and TechDraw are written in C++.

      Skills
      The student should have a good knowledge of C++ and be familar with graphics topics such as the painters algorithm, face detection and hidden line removal.
      Knowledge of technical drawing standards and previous exposure to Qt will be helpful. Familiarity with OpenCascade is a definite plus.

      Difficulty
      Hard

      Size
      long

      Additional Information
      Potential mentor(s): wandererfan
      Organization website: https://freecadweb.org
      Communication channels: https://forum.freecadweb.org

      ~~~~~~~~~~
      Create visual programming nodes for generating BIM data with IfcSverchok

      Outline
      Blender allows visual node programming, similar to Grasshopper in Rhino. Grasshopper has a really neat extension called GeometryGym which allows users to use visual node programming to generate building geometry and data using the "IFC" international standard. It's super awesome, and something like that doesn't exist yet in the open source world with only free software. So, let's create it!

      Some of this is already started, so the basics are already coded, but now it needs to be tested, debugged, and a whole bunch more nodes written and tested out in experiments in generating buildings with visual nodes.

      https://github.com/IfcOpenShell/IfcOpenShell/tree/v0.7.0/src/ifcsverchok is the source code, take a look, install it, and play around!

      Expected Outcome
      A whole bunch more nodes, and little examples of generating buildings via nodes, and getting an IFC output.

      Future Possibilities
      If we code it right, in the future, these nodes can be made agnostic of Blender and also work in FreeCAD (e.g. through PyFlow). So this allows multiple authoring apps to benefit from visual programming.

      Project Properties
      Skills
      Python
      Knowledge of visual programming (knowledge with Grasshopper / Sverchok super useful!), if not, get ready to watch tutorials on them!
      Basic Blender knowledge
      Difficulty
      Medium

      Size
      Medium (175h)
      The IfcOpenShell API is exposed as visual nodes, and basic geometry creation nodes are related to IFC.

      Long (350h)
      Proof of concept of simple visual node programming tasks are recreated with Sverchok and IFC nodes.

      Additional Information
      Potential mentor(s): Dion Moult
      Organization website: https://ifcopenshell.org
      Communication channels: https://community.osarch.org , ##architect on Freenode , and https://github.com/IfcOpenShell/IfcOpenShell/issues
      
      ~~~~~~~~~~

      Scripts for generating simple animations (e.g. appear / disappear, bounce, appear left to right, fade in from above, etc)



      Outline
      Often, construction firms need to visualise animations of construction sequencing. A project timeline will be created, and related to individual model elements. For example, when a concrete slab is poured, it is linked to a 3D object called a slab. We need the ability to automatically generate animations from Blender where objects appear / disappear in various different ways when they start / end their task in the project timeline. The systems for describing project timelines is already in place, so now we need a little animation generator!

      Details
      Expected Outcome
      A series of small scripts that take objects and can automatically animate the visibility, locations, or staggered appearances of building elements, as well as sub elements, and basic scripts that correlate real world time to animation frames, and frames per second, and generate an animated timeline bar in various styles.

      Future Possibilities
      This animation system can be then used from BIM models either in Blender, FreeCAD, or via other software altogether, so it has quite a large impact on the ecosystem.

      Skills
      Basic knowledge of the principles of animation (keyframing)
      Basic Blender animation (you can do some tutorials and get up to speed pretty quick)
      Python
      Artistic sense! We should offer beautiful and elegant animations!
      Difficulty
      Easy

      Additional Information
      Potential mentor(s): Dion Moult
      Organization website: https://ifcopenshell.org
      Communication channels: https://community.osarch.org , ##architect on Freenode , and https://github.com/IfcOpenShell/IfcOpenShell/issues

      ~~~~~~~~~~

 
      Create a 2D nesting tool	C++/Python, CAM/BIM, OpenCasCade	350h	Medium/Hard
      Open
      Feature
      Open
      Create a 2D nesting tool
      #19576
      Feature
      @yorikvanhavre
      Description
      yorikvanhavre
      opened last month · edited by yorikvanhavre
      Problem description
      Nesting is the process of arranging different shapes inside one bigger container shape. This is often used in CNC or laser cutting operations, to try to figure out how to cut several shapes out of a piece of material, while wasting as little as possible of the material.

      FreeCAD currently has a nesting tool, but it is very inefficient and fails often.

      This project should:

      Explore and assess the current tool, where it works and where it fails
      Investigate existing, open-source nesting solutions
      Find out if any is usable in FreeCAD, both technically (code-wise) and legally (compatible license)
      Research possible algorithms, or ways to better the current algorithm
      Decide either to use an external solution, or build or refactor our own algorithm
      Adapt the current tool to use it
      Difficulty
      Medium/Hard

      Workbenches/Technologies
      CAM/BIM, OpenCasCade, C++/Python

      Project size
      350h

      ~~~~~~~~~~

      Create fillets between 2 arcs in Sketcher	C++, Sketcher	175h	Medium/Hard
      Open
      Feature
      @KrisCouvreur
      Description
      KrisCouvreur
      opened on Feb 8 · edited by yorikvanhavre
      Problem description
      Fillet between 2 arcs in Sketcher workbench : can someone write the Python code for this ?
      In attachment the math behind this.
      Pull request was not allowed.

      Fillet between 2 arcs.pdf

      Difficulty
      Medium/Hard

      Technology/workbenches
      Sketcher, OpenCasCade

      Project size
      175h

      ~~~~~~~~~~

      Allow to place windows and doors with different insertion points	Python, Qt, BIM, Coin3D, OpenCasCade	175h	Medium
      Open
      Feature
      Open
      [BIM] Add the "Window/Door Alignment" property
      #19552
      Feature
      @kaiwas
      Description
      kaiwas
      opened last month · edited by yorikvanhavre
      Gsoc idea summary
      See below

      Is there an existing issue for this?

      I have searched the existing issues
      Problem description
      Currently, all windows and doors are built relative to the lower left edge (origin).
      If you add the "Alignment" property, windows and doors can be placed in a more convenient way. For example, with the "Right" alignment, the origin is shifted by minus width and we can place the window relative to the end of the wall.
      If the alignment is "Center", the origin is shifted by minus half the width and we can snap to the center point of the wall.

      I have put together an approximate version using expressions, but this feature should be at the program level without using expressions.
      Video demonstration.

      vokoscreenNG-2025-02-12_09-14-56.mp4 
      Image

      The test file is attached. Remove the Zip extension.

      Win_align.FCStd.zip

      Full version info
      OS: Manjaro Linux (KDE/plasma/xcb)
      Architecture: x86_64
      Version: 1.1.0dev.40176 (Git) Conda AppImage
      Build type: Release
      Branch: main
      Hash: 2745f436026b6f1fb84dbaaf89ea22b5fb4c2295
      Python 3.11.9, Qt 5.15.13, Coin 4.0.3, Vtk 9.2.6, IfcOpenShell 0.7.0, OCC 7.7.2
      Locale: Russian/Russia (ru_RU)
      Stylesheet/Theme/QtStyle: OpenLight.qss/OpenLight/Fusion
      Logical/physical DPI: 96/91.7938
      Installed mods: 
        * FreeCAD_SketchArch
        * PitchedRoof
        * Road 2025.2.6
        * addFC 1.3.0
        * freecad.gears 1.3.0
        * sheetmetal 0.7.10
        * OpenTheme 2024.9.1
      Subproject(s) affected?
      BIM

      Anything else?
      No response

      Code of Conduct

      I agree to follow this project's Code of Conduct

      ~~~~~~~~~~

      Improve FreeCAD Hidden Line Removal	C++, OpenCasCade, Part, TechDraw	350h	Hard
      Open
      Feature
      Open
      [Part] Improve FreeCAD Hidden Line Removal
      #19442
      Feature
      @yorikvanhavre
      Description
      yorikvanhavre
      opened on Feb 6 · edited by yorikvanhavre
      Outline
      FreeCAD's Technical Drawing module (TechDraw) relies heavily on the OpenCascade Hidden Line Removal algorithms. These algorithms can be very slow, do not provide progress reporting and do not provide any linkage between the input shape and the output.

      Details
      The TechDraw module provides projections, section views and detail views of 3D model components and assemblies developed in FreeCAD modules such as Part, PartDesign and Draft.

      Expected Outcome
      a) develop new code for projecting shapes and creating the geometry for technical drawings.
      -or-
      b) modify the existing OpenCascade code as an enhancement.

      Project Properties
      Both OpenCascade and TechDraw are written in C++.

      Skills
      The student should have a good knowledge of C++ and be familar with graphics topics such as the painters algorithm, face detection and hidden line removal.
      Knowledge of technical drawing standards and previous exposure to Qt will be helpful. Familiarity with OpenCascade is a definite plus.

      Difficulty
      Hard

      Size
      long

      Additional Information
      Potential mentor(s): wandererfan
      Organization website: https://freecadweb.org
      Communication channels: https://forum.freecadweb.org
      Migrated from opencax/GSoC#69 (comment)

      ~~~~~~~~~~

      Improve API of the user preferences system	C++, Preferences, User Interface	175h	Medium
      Open
      Feature
      Open
      No way to reset individual preferences / display which setting was changed by the user or theme
      #19171
      Feature
      @maxwxyz
      Description
      maxwxyz
      opened on Jan 21 · edited by maxwxyz
      Is there an existing issue for this?

      I have searched the existing issues
      Problem description
      Currently, the user can only reset all preferences, the preferences from the tab or the group. There is no way to reset individual preferences.
      There is also no way to see, which preferences were changed in comparison to the default value.

      I propose a similar I as in existing apps, where any changed preference is displayed in bold with a reset button next to it. Hovering the reset button would show the default value, clicking it would only reset this preference field.

      UI Example from Prusa Slicer:

      Image

      Image

      Similar UI in Firefox:

      Image

      It would be great to have some sort of information on changes based on a different setting: For example, many TechDraw preferences changes when you switch from ASME to ISO. This relation, why a preference changed and because of which setting it has been changed (and the default when choosing the parent setting) would be great.

      Full version info
      OS: Windows 10 build 19045
      Architecture: x86_64
      Version: 1.1.0dev.39896 (Git) Conda
      Build type: Release
      Branch: main
      Hash: a977fade2de741c94c9efa59b1c2c26df18eb631
      Python 3.11.11, Qt 5.15.15, Coin 4.0.3, Vtk 9.3.0, OCC 7.8.1
      Locale: German/Germany (de_DE)
      Stylesheet/Theme/QtStyle: FreeCAD Light.qss/FreeCAD Light/Fusion
      Installed mods: 
        * Curves 0.6.51
        * fasteners 0.5.32
        * freecad.gears 1.2.0
        * Manipulator 1.5.7
      Subproject(s) affected?
      Core

      Anything else?
      No response

      Code of Conduct

      I agree to follow this project's Code of Conduct


      ~~~~~~~~~~

      Design a finer way to copy/paste object attributes	C++/Python, BIM, Part, Addons, User Interface	175h	Medium
      Open
      Feature
      Open
      Part: No way to copy / paste object properties or attributes
      #17749
      Feature
      @maxwxyz
      Description
      maxwxyz
      opened on Nov 8, 2024 · edited by maxwxyz
      Is there an existing issue for this?

      I have searched the existing issues
      Problem description
      There is currently no way to copy properties from one object to a different object, e.g. placement values.

      For example: Copying one object's placement properties and selecting a different object and pasting them so the placement property is transformed to the new object.
      The workflow could look like this:

      Right click an object --> copy placement
      Right click a different object --> paste placement
      In the case of placement there is a workaround: Open the placement editor while the old part is selected, select the new object and hit apply.

      This could be extended for other properties, e.g. material/appearance, display modes, ...
      Maybe the object can just be copied and then there is a Paste special command where the user can choose what to paste (everything = as today, or a selection of properties).

      Full version info
      OS: Windows 11 build 26100
      Architecture: x86_64
      Version: 1.1.0dev.39100 (Git)
      Build type: Release
      Branch: main
      Hash: 8865450a3e14220925e0e449c0f1f79056b4fb89
      Python 3.11.10, Qt 5.15.15, Coin 4.0.3, Vtk 9.3.0, OCC 7.8.1
      Locale: German/Germany (de_DE)
      Stylesheet/Theme/QtStyle: OpenDark.qss/OpenDark/Fusion
      Installed mods: 
        * CfdOF 1.27.13
        * Curves 0.6.51
        * dodo 1.0.1
        * fasteners 0.5.29
        * freecad.gears 1.3.0
        * Manipulator 1.5.7
        * OpenTheme 2024.9.1
        * OpticsWorkbench 1.0.25
        * Rocket 4.0.0
        * sheetmetal 0.5.3
        * Silk 0.1.5
      Subproject(s) affected?
      Part

      Anything else?
      No response

      Code of Conduct

      I agree to follow this project's Code of Conduct

      ~~~~~~~~~~

      Diagnose and explore solutions to performance issues with large files	C++, Core, Performance, User Interface	350h	Hard

      Performance issues with large files (hover/preselection/navigation) #17185
      Open
      Bug
      0 / 2
      0 of 2 issues completed
      Open
      Performance issues with large files (hover/preselection/navigation)
      #17185
      Bug
      0 / 2
      0 of 2 issues completed
      @maxwxyz
      Description
      maxwxyz
      opened on Oct 11, 2024 · edited by maxwxyz
      Is there an existing issue for this?

      I have searched the existing issues
      Problem description
      When working in large files selecting/preselection is super slow which leads to lagging when starting to orbit or move the camera.
      I guess that is also the case why moving around in the scene is so hard because it takes about 5 seconds where nothing happens, then I can rotate without performance issues

      It seems to be related that the app checks what is under the cursor. Just scrolling for zooming in and out takes 2 seconds until it starts. when it's started I can zoom in and out without issues when holding the mouse at the same position. Moving the mouse freezes again for 2 seconds then it works normally.

      The app behaves normally until the cursor is over geometry.
      When the mouse is moved without clicks over the geometry the preselection highlight of faces or edges lags behind significantly, it also takes a few seconds when clicking that the element gets selected.
      When the mouse cursor is not over geometry (just over the background) the navigation and orbiting starts instantly, so no issues.

      PC should be able to handle this without issues:
      11th Gen Intel i7-11850H @2,5GHz; 32 GB RAM; NVIDIA T1200.

      @Rexbas @kadet1090 FYI
      The file itself is around 190 mb and has a lot of nested bodies in parts in other part containers. I cannot provide the file.

      Full version info
      OS: Windows 10 build 19045
      Word size of FreeCAD: 64-bit
      Version: 1.1.0dev.38923 (Git)
      Build type: Release
      Branch: main
      Hash: d20cb9e6ee198beb2bfd7e72d3dec0a575e3f28c
      Python 3.11.9, Qt 5.15.13, Coin 4.0.3, Vtk 9.2.6, OCC 7.7.2
      Locale: German/Germany (de_DE)
      Stylesheet/Theme/QtStyle: unset/FreeCAD Classic/Qt default
      Installed mods: 
        * Curves 0.6.50
        * fasteners 0.5.29
        * freecad.gears 1.2.0
        * Manipulator 1.5.7
      Subproject(s) affected?
      Core

      Anything else?
      No response

      Code of Conduct

      I agree to follow this project's Code of Conduct


      ~~~~~~~~~~

      Implement Draft Analysis in Part Design	C++, Part Design	350h/175h	Medium
      Open
      Feature
      Open
      PartDesign: Draft Analysis not available
      #16099
      Feature
      @maxwxyz
      Description
      maxwxyz
      opened on Aug 28, 2024
      Is there an existing issue for this?

      I have searched the existing issues
      Problem description
      Currently there is no option to perform a draft analysis to inspect the model to be able to analyze whether the part model is manufacturable based on the draft condition applied.
      It is necessary that the part can be removed easily from the panel dies (in case of Sheet metal part) or Mold (in case of casting).

      Implementation in CATIA:
      https://skill-lync.com/blogs/all-about-draft-analysis-using-catia

      original

      grafik

      Full version info
      OS: Windows 10 build 19045
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.38553 (Git)
      Build type: Release
      Branch: main
      Hash: 59c1ccec3e6b70f56eeee8f94d361019b84bd850
      Python 3.11.9, Qt 5.15.13, Coin 4.0.2, Vtk 9.2.6, OCC 7.7.2
      Locale: German/Germany (de_DE)
      Installed mods: 
        * Curves 0.6.42
        * fasteners 0.5.25
        * freecad.gears 1.2.0
        * Manipulator 1.5.7
      Subproject(s) affected?
      PartDesign

      Anything else?
      Maybe related to the implementation of
      #15028

      @pierreporte FYI

      Code of Conduct

      I agree to follow this project's Code of Conduct


      ~~~~~~~~~~

      TechDraw: Export layered PDF File format	C++, PDF, TechDraw	175h	Medium

      Is there an existing issue for this?

      I have searched the existing issues
      Problem description
      All commercial CAD software usually export drawing in a layered PDF format. This allows the user to hide certain layers when viewing the PDF later or extract certain layers only.

      Usually they provide the following layers in this order:

      pixelated image rendering (colors/shades)
      hatching
      visible lines (of the model)
      symbols (balloons, tables, finishes,...)
      section view lines (cutting lines and name)
      Cosmetic geometry (incl. page drawing frame)
      title block template
      title block content (text/images)
      dimensions (values and lines/arrows)
      Demo:
      image

      With only one layer active:
      image

      Full version info
      OS: Windows 11 build 22631
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.37213 (Git)
      Build type: Release
      Branch: main
      Hash: 20e7deb86a8c6c2cd2378f09f8313760933f3a5c
      Python 3.11.9, Qt 5.15.13, Coin 4.0.2, Vtk 9.2.6, OCC 7.7.2
      Locale: German/Germany (de_DE)
      Installed mods: 
        * CfdOF 1.25.12
        * Curves 0.6.36
        * dodo 1.0.1
        * fasteners 0.5.20
        * freecad.gears 1.2.0
        * OpenTheme 2024.5.3
        * OpticsWorkbench 1.0.17
        * sheetmetal 0.4.13
      Subproject(s) affected?
      Techdraw

      Anything else?
      No response

      Code of Conduct

      I agree to follow this project's Code of Conduct

      ~~~~~~~~~~

      Support radius/diameter, also for cylindrical surfaces in measurement tools	C++, Measurement	175h	Medium

      Problem description
      Currently the unified measurement type cannot get results of the type radius or diameter when selecting a cylindrical surface. If a surface is selected, the area is chosen automatically. Switching manually to radius gives no result. There is no type to measure the diameter at all.
      The tool should support the measurement of the radius and diameter, when a cylindrical / arc surface and also curve is selected.

      Additionally, the annotation of radius/diameter should be attached and displayed at the center of the radius. Currently it is on a starting point of the selected curve.

      Full version info
      OS: Windows 10 build 19045
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.37063 (Git)
      Build type: Release
      Branch: main
      Hash: 680792030fd664c94829e2c1b78b21788e8d9879
      Python 3.11.9, Qt 5.15.13, Coin 4.0.2, Vtk 9.2.6, OCC 7.7.2
      Locale: German/Germany (de_DE)
      Installed mods: 
        * BIM 2021.12.0
        * CurvedShapes 1.0.9
        * Curves 0.6.35
        * fasteners 0.5.20
        * OpenTheme 2024.4.20
        * OpticsWorkbench 1.0.17
        * sheetmetal 0.4.13
      Subproject(s) affected?
      Core

      Anything else?
      No response

      Code of Conduct

      I agree to follow this project's Code of Conduct

      ~~~~~~~~~~  

      Measure inertia with material and coordinate system in measurement tools	C++, Measurement	175h	Medium

      Problem description
      With the material of the object the measurement tool should also support the measurement of inertia. The whole matrix should be displayed, plus the principal moments of inertia and its associated coordinate system, possibly different than the base one, with the origin at the center of gravity.

      Several implementations are possible and all are desirable:


      Most basic: use only the base coordinate system.

      Use a point as the origin. The coordinate system is then a translation of the base one.

      Use a local coordinate system.

      Use a single line to compute the inertia around it.
      Full version info
      0.22
      Subproject(s) affected?
      Core

      Anything else?
      Needs mass calculation, see #13715.

      Code of Conduct

      I agree to follow this project's Code of Conduct

      ~~~~~~~~~~

      Add attachment support to annotation labels	C++, Core	175h	Easy

      Problem description
      The AnnotationLabel when created has no attachment support for the origin of the annotation line(s).
      It is not possible to set the position and keep it updated when the annotation is placed at a selected geometry or object.

      Full version info
      OS: Windows 11 build 22631
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.36729 (Git)
      Build type: Release
      Branch: main
      Hash: 6ca35709ddc7f95fb84eef4c24973dc489e5acde
      Python 3.11.8, Qt 5.15.8, Coin 4.0.2, Vtk 9.2.6, OCC 7.7.2
      Locale: English/United States (en_US)
      Installed mods: 
        * BIM 2021.12.0
        * CfdOF 1.25.11
        * Curves 0.6.35
        * dodo 1.0.1
        * fasteners 0.5.20
        * fcVM-WB
        * freecad.gears 1.2.0
        * OpenTheme 2024.4.20
        * sheetmetal 0.4.13

      ~~~~~~~~~~
      
      Add snapping to measurements / picking points	C++, Measurement	175h/350h	Medium

      Currently when selecting two circles or cylinders, the measurement is displayed between the enveloped circle curve or between the mantle surfaces.
      It would be great if the unified measurement facility could support snapping like in the Draft WB to snap to circle midpoints, intersections, and so on.
      This would also allow to measure distances and angles of axes between shafts and holes.
      grafik

      Full version info
      OS: Windows 10 build 19045
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.37063 (Git)
      Build type: Release
      Branch: main
      Hash: 680792030fd664c94829e2c1b78b21788e8d9879
      Python 3.11.9, Qt 5.15.13, Coin 4.0.2, Vtk 9.2.6, OCC 7.7.2
      Locale: German/Germany (de_DE)
      Installed mods: 
        * BIM 2021.12.0
        * CurvedShapes 1.0.9
        * Curves 0.6.35
        * fasteners 0.5.20
        * OpenTheme 2024.4.20
        * OpticsWorkbench 1.0.17
        * sheetmetal 0.4.13

      ~~~~~~~~~~

      Unify DXF importers and exporters	C++/Python, DXF, Draft, Import	350h	Medium/Hard

      DXF import/export is a hot topic. There have been many issues with it and it seems that there are still some problems left. Apparently, the legacy importer/exporter should be used in most cases. But ideally, there should be only a single importer/exporter (with all the benefits and features of the current two implementations) or at least the better/recommended one should be the default to avoid the confusion. Are there any plans for that? I guess that it won't happen before the next release but it's something that should be resolved as soon as possible, in my opinion.

      Full version info
      OS: Windows 10 build 19045
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.36958 (Git)
      Build type: Release
      Branch: main
      Hash: a041129090b8dcbb8367636840d3c668ef30a933
      Python 3.11.9, Qt 5.15.13, Coin 4.0.2, Vtk 9.2.6, OCC 7.7.2
      Locale: Polish/Poland (pl_PL)

      ~~~~~~~~~~

      Allow adding text to the sketcher	C++, Sketcher, Qt	350h	Medium

      Currently the only way of adding text to FreeCAD is StringShape which doesn't play nicely with parametric design (e.g. font cannot be specified as function, neither can size as far as I can tell) and it's painful to use with Part Design.

      It would be good if user could just type string inside sketcher and extrude it if they use Part Design workflow.

      Full version info
      [code]
      OS: NixOS 24.05 (Uakari) (GNOME/gnome)
      Word size of FreeCAD: 64-bit
      Version: 0.21.2.Unknown
      Build type: Release
      Python 3.11.8, Qt 5.15.12, Coin 4.0.1, Vtk 9.2.6, OCC 7.6.2
      Locale: English/United States (en_US)
      Installed mods: 
        * kicadStepUpMod 10.22.9
        * Assembly4 0.50.6
        * fasteners 0.5.0
      [/code]

      ~~~~~~~~~~
      Export 3D PDF File format	C++, Core, PDF	350h	Hard

      There is no way to directly export into a 3D PDF and keep tree structure, materials and custom views.
      https://helpx.adobe.com/acrobat/using/adding-3d-models-pdfs-acrobat.html

      3D related file types to be used in 3D PDF are Universal 3D (.U3D) files (https://en.wikipedia.org/wiki/Universal_3D)

      Related issue for import of these files:

      import PRC file or 3D PDF into FreeCAD #6090

      OS: Windows 11 build 22631
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.36277 (Git)
      Build type: Release
      Branch: main
      Hash: 9e1903d46112b3660bf10c6a4537d728101d560b
      Python 3.10.13, Qt 5.15.8, Coin 4.0.2, Vtk 9.2.6, OCC 7.6.3
      Locale: German/Germany (de_DE)
      Installed mods: 
        * 3DfindIT 1.2.0
        * BIM 2021.12.0
        * CfdOF 1.25.2
        * CurvedShapes 1.0.5
        * Curves 0.6.23
        * Defeaturing 1.2.2
        * fasteners 0.5.12
        * FEMbyGEN 2.1.0
        * freecad.gears 1.2.0
        * freecad_metal_workbench 0.0.1
        * OpenDark 2023.12.17
        * sheetmetal 0.4.2

      ~~~~~~~~~~  

      Use only selected parts of a sketch / Features with different profiles of a master sketch	C++, Sketcher, Core	175h	Hard

      Currently it is not possible to create a master sketch with multiple, overlapping islands of wires and use the individual parts of the sketch in the 3D view for features. Always the entire sketch has to be used to create features. If there are open loops / wires or not one single closed profile, most PartDesign features fail.
      The idea is to create a sketch and use a a single loop / closed profile or combinations of the enclosed sketch for features in FreeCAD, for example PartDesign WB (Pad, Pocket, Revolve,...), Part WB (Extrude,...) or elsewhere.

      In other CAD software, when activating a sketch based feature (e.g. Pad) the user can select the parts of the sketch which should be included in the profile to be extruded. When hovering the sketch, the different - closed - profiles of overlapping sketch geometry are highlighted and can be selected individually to be added or removed from the final group of profiles which will be used for that feature.

      Example from Fusion360:
      extrude-shape

      Example from Onshape:

      onshape-profiles
      onshape-sketch-profiles

      This also lets the user create a single sketch (sometimes referred to as master sketch) and referencing different parts for different features, without the need to copy the sketch, redraw the sketch, recreate dimensions or create external geometry references and redrawing or constraining with regard to them.

      This was also mentioned as issue at the FreeCAD Day 2024 Complaint Session:
      Unable to easily apply operations to selected parts of a sketch

      Full version info
      OS: Windows 11 build 22631
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.36277 (Git)
      Build type: Release
      Branch: main
      Hash: 9e1903d46112b3660bf10c6a4537d728101d560b
      Python 3.10.13, Qt 5.15.8, Coin 4.0.2, Vtk 9.2.6, OCC 7.6.3
      Locale: German/Germany (de_DE)
      Installed mods: 
        * 3DfindIT 1.2.0
        * BIM 2021.12.0
        * CfdOF 1.25.2
        * CurvedShapes 1.0.5
        * Curves 0.6.23
        * Defeaturing 1.2.2
        * fasteners 0.5.12
        * FEMbyGEN 2.1.0
        * freecad.gears 1.2.0
        * freecad_metal_workbench 0.0.1
        * OpenDark 2023.12.17
        * sheetmetal 0.4.2

      ~~~~~~~~~~

      Improve the FreeCAD API documentation	C++/Python, Doxygen	175h	Easy

      Outline
      Work on the FreeCAD doxygen-generated documentation: Propose a better plan, document the modules better, make it clearer to read, etc.

      Details
      The API documentaiton of FreeCAD is generated with doxygen from the docstrings contained in the source code. It is hosted on https://github.com/FreeCAD/SourceDoc . It is currently not easily readable, the modules structure doesn't list classes and functions, python functionality is not well distinguishable from C++ functionality, and many other problems.

      Expected Outcome
      Identify problems and possible solutions, and propose changes to the docstrings and in-source doxygen instructions to build better docs, and possibly do some css work to produce a cleaner HTML result

      Project Properties
      Skills
      The student should have or build a good knowledge of doxygen, optionally be ready to do some css work too

      Difficulty
      Medium

      Additional Information
      Potential mentor(s): Yorik
      Organization website: https://freecad.org
      Communication channels: https://https://forum.freecad.org

      ~~~~~~~~~~
      
      Compare multiple parts / bodies (CAD versions and 3D Scan to Original CAD Model)	C++, OpenCasCade, Part	175h	Medium

      There is currently no feature to compare two parts or bodies. This would be helpful to analyze different parts or versions of the same body.
      Differences (more or less material/features) should be highlighted as an analysis report.
      The feature would also be helpful to inspect 3D scans (meshes) and compare them to the actual CAD model (quality inspection).

      In CATIA there are two option
      Example from CATIA:
      How-to-compare-2-Parts-in-CATIA-V5-2
      Demo Video: https://youtu.be/kb_iyLEO18Y?t=73&feature=shared

      In CATIA there are two options, to make a visual comparison (se image above) and a geometric comparison which shows results with added or removed material on both models in a linked view:
      6a0115711b8d26970b0240a4b4ac12200c-800wi

      Demo in Siemens NX: https://www.youtube.com/watch?app=desktop&v=DNx2AdKI7zg

      Demo with 3D scan comparison in SolidWorks: https://www.youtube.com/watch?v=06B6YcoNuoI

      I've tagged the PartDesign WB as this would be the most useful WB for such features but it would also be beneficial to compare meshes or assemblies and as mentioned above, scanned 3D meshes to actual CAD geometry.

      Full version info
      0.22



      ~~~~~~~~~~  

      Assembly: Possibility to Inspect the Assembly	C++, Assembly, Part	175h	Hard

      There should be some possibilities to inspect the assembly:

      display degrees of freedom (DoF) for the parts (maybe in the property view, maybe in an inspection dialog, maybe display them directly in the 3D view (e.g. arrows)
      alternatively an option to wiggle/animate the assembly in all open degrees of freedom, to see if the assembly is working correctly and all joints were made.
      Check for intersection of parts / collision (clash) detection. But also allow a maximum/minimum distance input and analyze if no parts have a closer or larger distance to each other
      Assembly Hierarchy and Structure: Displaying the organization of components within the assembly hierarchy is crucial for managing complex assemblies. The WB should provide tools for displaying the relation of all components, maybe like the dependency graph
      To add from the FreeCAD Day 2024 Complaint Session:
      No way to get the mass of a sub assembly. Material properties are not handled properly assemblies, you cant get aggregate properties

      Full version info
      OS: Windows 11 build 22631
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.35966 (Git)
      Build type: Release
      Branch: main
      Hash: 7f5d89fa1942fec79222e4d173655744037164dc
      Python 3.10.13, Qt 5.15.8, Coin 4.0.2, Vtk 9.2.6, OCC 7.6.3
      Locale: German/Germany (de_DE)
      Installed mods: 
        * 3DfindIT 1.2.0
        * BIM 2021.12.0
        * CfdOF 1.25.1
        * CurvedShapes 1.0.5
        * Curves 0.6.23
        * Defeaturing 1.2.2
        * fasteners 0.5.2
        * FEMbyGEN 2.1.0
        * freecad.gears 1.0.0
        * freecad_metal_workbench 0.0.1
        * OpenDark 2023.12.17
        * sheetmetal 0.4.0
        * woodworking 0.21.2.33771

      ~~~~~~~~~~

      Sketcher: Improve Dimension between Circle/Arc (Distance Constraints)	C++, Sketcher	175h	Hard

      Currently, it is only possible to constrain the minimum distance between two circles/arcs with the dimension tool:
      grafik

      The tool should be improved to behave like the distance tools on lines, depending on the cursor position of the mouse

      Minimum distance between circle/arcs, already implemented
      Maximum distance between circles/arcs
      Minimum horizontal distance between circles/arcs
      Maximum horizontal distance between circles/arcs
      Minimum vertical distance between circles/arcs
      Maximum vertical distance between circles/arcs
      What is meant:
      grafik
      grafik

      Building on top of @FlachyJoe #9166
      This FR is includes #11412 but includes additional cases to support all distances.
      Also includes #5864

      When implemented, the Dimension tool should be updated to include these different constraint cases and suggest the best case, depending on the cursor position.

      Full version info
      0.22

      ~~~~~~~~~~
      
      Edit multiple documents at a time (AKA make tabs independent editors)	C++, Core	350h	Hard

      freeCAD has been designed to edit one document at a time only. When two files are opened and an edition is occurring in one of them (for example a sketch is opened), the program stays in this edit mode when switching to the other document (the task panel is still the same). If this second document has a sketch that is also opened, it closes the one opened in the other document. In other words, tabs are not independent editor.

      This behavior is a limitation. It makes working on several documents in parallel difficult. A workaround is to open as much as FreeCAD sessions as needed, but it is impossible to detach a tab into its own FreeCAD session.

      This would be a big change because the architecture would be altered. Though it would make FreeCAD more predictable as basically all software with tabs make them independent editors.

      Full version info
      OS: Ubuntu 23.10 (KDE/plasma)
      Word size of FreeCAD: 64-bit
      Version: 0.22.0dev.35510 (Git) AppImage
      Build type: Release
      Branch: main
      Hash: da05f7c8e8b25ff783cc6c4eb3b73b640f134519
      Python 3.10.13, Qt 5.15.8, Coin 4.0.2, Vtk 9.2.6, OCC 7.6.3
      Locale: French/France (fr_FR)
      Installed mods: 
        * OpenDark 2023.12.1

      ~~~~~~~~~~  

      Improvement of Light Sources Preferences: Appearance, Multiple Lights in the Scene, Background Illumination	C++, Coin 3D, User Inteface	350h	Medium

      To extend the functionality of #11113 implemented by #11146 it would be great to add, adjust, and remove lights in the preference dialog of FreeCAD.
      The arrows could indicate a light each.
      grafik

      The direction of the lights should be editable as well as the intensity. If possible, even the color could be adjusted and all saved in the preferences. The current light which is edited could be highlighted in the view, maybe even represent color and intensity on the ball (like a real time preview). It should be possible to add new lights as well as to remove them again.
      Maybe themes could provide settings of the default lightning.

      There should be a setting to set the ambientColor and ambientIntensity with a default white ambient environment light in the scene, so no completely black areas on the model are visible.

      If possible default light settings e.g. three spot, default, ... could be provided and chosen via a dropdown menu and a custom entry could be saved.

      Full version info
      0.22





      ~~~~~~~~~~

      PartDesign: Design a good way to create walls / thin extrusions / ribs	C++, Part Design	350h	Hard

      Currently there is no good way to create "Thin" elements in the FreeCAD. Because of that creating wall-like elements in the Part Design is really hard and requires a lot of effort. Possible uses:

      Creating walls
      Creating ribs
      Creating reinforcements
      To illustrate this feature in OnShape:
      image

      It'd be nice to implement this in a way that would allow this feature to be easily used in most (all?) features without code duplication, so It probably should be implemented as separate "thicken" feature, that then can be: padded, pocketed, revolved, etc.

      This potential feature should also allow control on:

      Offset (One way, symmetric, Two Distances)
      Cap type (Round / Butt)
      Join type (Round / Tangent)
      If possible, there should be a way to create "Thicken" feature using for example "Pad" dialog, to simplify user workflow and make it more user friendly.

      Workarounds
      Using SheetMetal add base: https://wiki.freecad.org/SheetMetal_AddBase
      Creating SubShape binder to sketch with filled offset applied - it works, but it is not intended use of binder, and it has a lot of quirks
      Using Part workbench with 2d offset
      Sketch Offset tool will help a lot with many cases when (if) merged, but again it's not correct tool for the job
      Using Arch_Wall ?
      Full version info
      FreeCAD 0.21

      ~~~~~~~~~~
      
      Implement selection order priority	C++, Coin, User Interface	350h	Hard

      Recently we have a new tool which appeared called 'selection filter'. This also exist in Assembly4 as a toolbar. (introduced in core following #10243)

      This was in part introduced to fix an annoying issue that it is hard/impossible to select some points or lines.

      The technical reason for that issue (I think) is that the selection mechanism use pointOnRay function, but it uses the overload that returns only the 1st object found. So if you try to select a point but a face is closer to the camera, then the face is going to be selected.

      The selection mechanism should not behave like this. Instead it should use the pointOnRay that return ALL the objects found. Then these objects should be sorted by priority by the following order :

      Points
      Edges
      Faces
      Then the selection should take the item with the higher priority.
      @wwmayer Do you have any insight on the matter? Or can confirm if my analysis is correct?

      @Syres916 @FEA-eng you might be interested to follow this.

      Edited following @FEA-eng comments

      ~~~~~~~~~~  

      Sketcher: Implement automatic projection of external geometry for dimensions	C++, Sketcher	180h	Hard

      I would like to propose an easy improvement in the Sketcher module that can make it easier to use and faster.

      While using the following button commands: "Constrain horizontal distance" & "Constrain vertical distance"

      It would be great to run highlight edges from "Create external geometry" when the mouse hovers above external geometries and in case the user clicks, to create the external geometry automatically.

      I think all the functionality is existing already.

      This way the user can create constraints directly to the edges of the body without additional clicks

      ~~~~~~~~~~

      Design a compatibility system for different Assembly Workbenches	C++/Python, Assembly	350h	Hard

      ne of the key findings of the Ondsel Assembly workbench blog series was the need for a common data format for the interchange of assembly information.

      The creation of a data standard should be an early priority to allow the various addon assembly workbenches time to adapt and/or build migration scripts.

      This issue is for continued discussion about the requirements for a common data standard.

      ~~~~~~~~~~
      
      On-machine inspection for CAM	C++/Python, CAM	180h	Medium

      On-Machine Inspection
      Background
      In commercial manufacturing using CNC, the part is inspected to ensure that the resulting part matches the required tolerance. Tool wear, backlash, and other environmental factors can affect machining accuracy.

      Traditionally the part is removed from the machine after completion and placed and a Coordinate Measuring Machine (CMM) which probes the part and compares to the probe results to the required specifications. The problem with this approach is that the placement of the part is lost when it is removed from the machine. If re-work is necessary, the setup time to reestablish accurate placement can be very high.

      On-machine Inspection uses a touch probe in the CNC machine to replace the CMM. The part is left in place and a toolpath is executed.

      In manual mode, the machine probes the part and indicates to the operator if a probe point is out of tolerance.

      In automatic mode, the probe points are gathered and saved to an inspection report

      The CAM workbench in FreeCAD (Path) lacks any capability for generating an On Machine Inspection toolpath.

      Details
      Understand the basic workflow for creating a Path Job and generating tool paths for CNC machining operatoins. Understand the two main workflows for On-machine Inspection.
      Propose a Path operation and workflow for generating a toolpath, storing and displaying inspection results.
      Design the operation, task panels, and core logic.
      Implement unit tests for the core logic
      Implement the feature and demonstrate practical application
      Create a wiki page describing how on-machine inspection is used
      Expected Outcome
      Mergable code for an OMI feature
      Unit tests for the core logic
      A Wiki page describing the procedure for the user to create tests and the developer to create new comparators
      Future Possibilities
      There are numerous other places in the CAM workflow where Integration of touch probes and other sensing equipment would reduce errors and increase cycle time. These are valuable features to implement. They make FreeCAD more attractive to commercial use.

      Project Properties
      Skills
      Programming language mainly Python. Familiarity with or willingness to learn G-code.
      Familiarity or willingness to learn basic CNC / machining concepts
      Difficulty
      Medium

      Project size
      175h

      ~~~~~~~~~~  

      Advanced FreeCAD test system	C++/Python, Core	350h	Medium

      Advanced FreeCAD test system
      This page is dedicated to the Google Summer of Code project regarding the enhancement of FreeCAD's test system.

      Outline
      FreeCAD as a CAE application has a high level of complexity, both in its source code and also in its user interaction. To ensure a certain level of quality automatic testing is essential. However, as an open source application with spare time coders only this part of the project has not seen very much attention. One of the major reasons is the low-level handling required to write test cases. All actions to trigger, every result fetching and every single comparison needs to be hand coded. This makes it cumbersome to provide a test for every created functionality and possibly impossible to do so if deep document comparisons are needed. For example the Part and PartDesign workbench: An automated test for document objects require the resulting topology shape to be analysed. This is a tremendous part and cannot be handled on a per test basis.

      This project aims at reducing the work required to write meaningful tests. This should be accomplished by providing a infrastructure for result file storage and special "comparators" which compare the stored result files with the test result for equality.

      Details
      Create a result file infrastructure for the test system. It should allow to save an arbitrary number of files together with the test itself where the expected results are stored. It is intended to have one result file for each comparator used. The infrastructure should make the storage (file structure), loading and handling easy. It furthermore should define a specification for the generic file content, e.g. which comparator to use for it etc.
      Create a infrastructure for comparators and provide a few important ones. The comparators should be able to read in a result file and compare the available test output with it. As every workbench requires different types of comparisons the comparators need to be provided by the workbench itself, as well as possible top-level ones. The test infrastructure needs to be adopted to work with such workbench specific types. Furthermore there needs to be a way to generate result files for comparators. this can be done either by themselves or by a different class.
      a. Implement a global comparator for the document structure: It stores the Document object structure with all properties in a result file and compares the available document after a test run with it
      b. Implement a Part workbench comparator for shapes: It stores data about a certain TopoShape in a result file suitable for comparison, e.g. number of edges/vertices/faces, properties like area, mass, center of gravity.
      c. Advanced: Create a global comparator for the 3D output based on picture comparison. This is marked as advanced as this comparator needs to be tolerant to slight changes due to driver differences (see VTK for example) and also needs to somehow ensure the same display settings used for the comparators every time
      Create a wizard or GUI for test creation in the Test workbench. This would work like macro recording: the user starts the test recording, and everything plotted in the python console would be the test procedure. When hitting stop the user gets a dialog where he can choose which comparators to apply. The wizard than creates the appropriate test structure with the test itself, all needed result files etc.
      Create a Wiki page describing the working of the test system and how to create tests and new comparators
      Expected Outcome
      Mergable code for a result file based comparator system
      A GUI for simplified test generation based on macro recording
      A Wiki page describing the procedure for the user to create tests and the developer to create new comparators
      Tests which utilize the created comparators and show their use
      Future Possibilities
      Future contributions can include new comparators, e.g. for meshes. Also creating tests for existing functionality has a high priority and can be achieved with the new system. Futhermore a GUI based system can be created, where a test is defined by recorded UI events, see Record and replay events. This could also be a new GSoC project.

      Project Properties
      Skills
      Programming language mainly Python, some comparators may need C++ code.
      Understand and use APIs from FreeCAD and external libraries (OCC for Part comparator)
      Difficulty
      Medium

      Project size
      175h

      ~~~~~~~~~~

      FEM: Extend Z88 Solver	C++/Python, FEM, Z99	350h	Medium

      GSoC FEM Solver Z88
      This page is dedicated to the description of the Google Summer of Code project idea regarding extending FEM solver Z88OS.

      Outline
      FreeCAD is not only a traditional CAD platform but also aims at providing general engeneering functionality. One of the most valuable design tools for modern product development is the finite element method. It provides advanced means for design analysis, stress tests and optimisation. Over the last two years a FEM workbench in FreeCAD has been developed based on the CalculiX solver and already reached a usable state in the 0.16 release. However, since CalculiX has neither real Shell nor real Beam elements, CalculiX has limitations in the regard of these element types. This was the main reason to start an implementation of an additional solver for the FreeCAD FEM workbench. Z88OS was choosen, since it is OpenSource and thus runs on all major plattforms and has real Beam and Shell elements. The solver Z88OS has been integrated in FreeCAD FEM already. But only very limited parameter are supported at the moment. Only fixed constraints in main axis directions and simple node loads are supported on the pre processing side. On the contrary the post processing only the displacements are read into FreeCAD FEM. To really be able to use Z88 as an additional solver more of his capabilities need to be supported by FreeCAD.

      The GSoC project aims to exactly do this. On pre processing side of FreeCAD a lot of constraints and boundary conditions are supported by FEM and CalculiX solver. Most of them should be ported to Z88 too. On post processing side the FreeCAD FEM result object supports a wide range of result types as well as viewing them by the use of sophisticated VTK post processing tools. An implementation should be made to read more Z88 results into FreeCAD result object. Furthermore most Z88 solver adjustments are hard coded into FreeCAD FEM. They should be changed in a way they could be changed during run time of FreeCAD FEM.

      Details
      Get familiar with FreeCAD FEM workbench its capabilities and its architecture. Furthermore get familiar with Z88OS and its interface text files for pre- and post processing. It is important to have a good understanding of all involved components to be able to make the needed extensions.
      Post processing: Extend the importZ88result module to read stress and strains from Z88 result files and add them to the FreeCAD result object.
      Pre processing: Implement Z88 input file writing for all three element dimensions (beam, shell, volume) for the following constraints of FreeCAD FEM: fixed, force, pressure, self weight, displacement.
      Solver: extend the FreeCAD FEM solver object by FreeCAD properties to hold the the attributes which could be used to make the needed adjustments at Z88 solver binary.
      Advanced: add the free-ware solver Z88Aurora (not OpenSource, but free of license fee) as another possibility in FreeCAD FEM in addition to Z88OS. Z88Aurora supports much more constraints and analysis types than Z88OS
      Expected Outcome
      Fully functional advanced postprocessing in FreeCAD based on VTK
      Unit tests ensuring the functionality
      Documentation and tutorials for post processing
      Future Possibilities
      If this project is finished successfully futher work on the FEM workbench can be done. Advancing the preprocessing with better control over the meshing process come to mind, or integrating different solvers for other analysis types. Also calulix implementation can be advanced, for example allowing nonelinear calculations.

      Project Properties
      Skills
      Programming language Python
      Deep understanding and use of APIs from FreeCAD and Z88OS
      Knowledge of FEM pre- and postprocessing workflows and needs
      Difficulty
      Easy-Medium

      Project size
      175h



      ~~~~~~~~~~
      
      Upgrade the documentation system	C++/Python, Doxygen, Mediawiki, Markdown	350h	Easy  

      Upgrade the documentation system
      This page is dedicated to the description of the Google Summer of Code 2023 project idea of upgrading the documentation system of FreeCAD.

      Outline
      FreeCAD already possesses a vast documentation, written by its users and hosted on the FreeCAD wiki. On each FreeCAD release, the contents of the wiki get packed into a offline documentation package which is bundled with FreeCAD. When using the "what's this?" feature, FreeCAD users can quickly get documentation about a specific tool

      Additionally, this same documentation also has several translations, hosted on the same wiki and managed by a mediawiki plugin, and also counts on the source code structure and comments, automatically extracted by the doxygen tool, and hosted on https://www.freecadweb.org/api/

      However there are several problems:

      The mediawiki software is a dinosaur to maintain, and complicated to maintain up-to-date
      The mediawiki data is hard to back up. We are constantly at risk of loosing data
      The mediawiki search feature is notoriously weak
      The mediawiki is complicated to theme and make look good
      Our doc has become as important as FreeCAD itself. It would benefit from having the same level of decentralisation
      The current translation system is always at risk of becoming obsoleted, like many mediawiki plugins. It is not used anymore by the MediaWiki project
      A simpler, file-based system would allow much more automation, scripting and integrations. Python/C++ API documentation can be built on-the-fly and integrated
      A Git-based system would allow branching/tagging/versions of the documentation corresponding to FreeCAD versions and maintaining a more up-to-date documentation
      A markdown-based system would allow to produce many kinds of outputs such as online/HTML like the current wiki, but also better integrate into the FreeCAD Help system, or produce e-book formats or even printed books
      A markdown + Git based system would be easy to integrate into online translation platforms, and therefore free us from one more part of maintainance and unify with other translation systems of FreeCAD
      This project proposes to remedy to these problems by:

      switch the FreeCAD documentation, currently managed by a MediaWiki instance hosted on the FreeCAD website to a file-based, versioned system, preferably based on Git and markdown
      offer a nice web-based experience
      allowing the FreeCAD user to switch between online and offline documentation, and choose between different available languages
      extending and better integrating the autogenerated documentation, with special care for the python API
      enabling different e-book outputs (pdf, e-pub, etc)
      implement a good search system
      The above proposal also introduces a new problem: The ease-of-use of the Mediawiki platform would be lost. That ease-of-use is important because most of the edits done to the wiki are small edits, like corrrecting an info or fixing a typo. Many people who currently work on the wiki would probably do it less often if it required a complex Pull Request-based system. A wiki system, that allows easy and small edits, is therefore fundamental to keep.

      The solution to that problem could be found in using a wiki system that is based on files, markdown and git. As part of this project, available file-based wiki solutions should be researched.

      Details
      have a good knowledge of the markdown format, including how to work with yaml data
      be able to write scripts, preferably in Python, to automate some aspects of the migration or maintaining
      be able and ready to explore and work with the API of online platforms such as MediaWiki, GitHub or Crowdin
      be able to work with doxygen and autogenerated documentation systems
      be ready to document everything you do so others can take the work further
      Expected Outcome
      A better documentation system for FreeCAD, based on the proposed workflow below

      What's there to test already
      An automatic translation of the mediawiki content to markdown is already available on https://github.com/FreeCAD/FreeCAD-documentation . It is done automatically by the help of a python script at https://github.com/FreeCAD/FreeCAD-documentation/blob/main/migrate.py . The translated documentation can be read online, by browsing through the markdown pages, or from within FreeCAD's Help system. Both the Help addon and the markdown documentation form the core of what we want to develop.

      The goal of this project is to migrate for good to the markdown version, retire the migrate script, and shut down the wiki.

      Proposed workflow
      Research available file-based wiki solutions
      Write article explaining the migration to the community: why, what are the advantages, what are the issues
      Write a migration plan or adapt this one
      Define a directory / category structure that reflects the current documentation categories
      Define a tags / yaml system to allow further and finer classification of documentation pages
      Define a language switching system that allows user to use the documentation in their language
      Define a search system
      Define a sequence system so some pages can be assembled like a book
      Design an online HTML-based output
      Design a FreeCAD online output
      Design a FreeCAD offline output
      Design a multi-formats e-book output
      Design a printed book output
      Research and help choose a translation platform, investigate available plans (see below)
      Define what contributors should do while the wiki is in read-only mode
      Set the wiki in read-only mode
      Transfer all the contents from wiki to markdown files
      Verify that all the contents have been transferred
      Manually check each and fix each and every page for style errors
      Verify all the links
      Create a structure for translations and relocate all pages
      Setup the translation platform
      Tie the translation platform into the git repo
      Document the steps needed to setup the translation platform
      Document the process to adopt for translators
      Document the process to adopt for maintainers
      Define how dynamic contents such as FreeCAD API documentation can be extracted and added automatically to the documentation
      Write an article announcing the change
      Design a system to handle and redirect wiki.freecad.org links
      Remove the mediawiki installation
      Possible translation platforms, to be checked again
      Research which translation platform to use (transifex, crowdin?) based on:
      are they free for FOSS projects, or what are the costs
      how good they handle markdown files
      how already translated pages can be fed back into the translation platform
      automatic integration with github
      Crowdin - https://crowdin.com
      Free for FOSS projects
      Incomplete markdown support (looses images) (12/2020)
      Allows to upload a translated file as translation
      Integration with github
      Advantage: FreeCAD users know it
      Transifex - https://transifex.com
      Free for FOSS projects
      Incomplete markdown support (looses images) (12/2020)
      Allows to upload a translated page (git push)
      Integration with github
      Weblate - https://weblate.org
      Free for FOSS projects
      No markdown support (12/2020)
      Project Properties
      Skills
      Programming language: C++, but understanding some Python will be necessary
      Readiness to work with documentation, reasonably good english writing skills
      Difficulty
      Medium

      Project size
      175h or 350h

      ~~~~~~~~~~  

      FreeCAD ↔ BRLCAD integration	C++, BRL-CAD, OpenCasCade, Core	350h	Hard

      FreeCAD-BRLCAD integration
      This page is dedicated to the description of the Google Summer of Code 2023 project idea of integrating FreeCAD and BRL-CAD.

      Outline
      Is there an existing request for this?

      Details
      FreeCAD and BRL-CAD are very complementary applications: BRL-CAD is a powerful engine which could do with a better modelling UI, and FreeCAD has an increasingly vast modelling UI but could make great use of the support for large models that BRL-CAD can offer.

      FreeCAD being highly modular, and BRL-CAD having a C+ API, building a BRL-CAD module for FreeCAD is totally possible. This way, it would be possible to open BRL-CAD models (that are usually called databases, because they are often made of a collection of models) in FreeCAD, and it would also be possible to use FreeCAD as a modelling tool for BRL-CAD.

      This project idea will require a reasonable knowledge of C++, and, since it involves two different applications, a versatile mind able to learn quickly and navigate between many different concepts, as they are implemented differently in both applications.

      This project would be mentored commonly by both FreeCAD and BRL-CAD developers.
      https://wiki.freecad.org/FreeCAD-BRLCAD_integration

      Expected Outcome
      Documentation. Since this is a large task, that might not fit in a single GSOC project, other people (or yourself) will likely work on this project after the GSOC period ends. They must be able to take on the work where it has been stopped. Also, the first steps of this project will involve a lot of research, that should be made as available as possible to others.
      A basic prototype, that allows to open and visualize BRL-CAD databases in FreeCAD, and shows how modelling and saving BRL-CAD objects can work in FreeCAD
      Future Possibilities
      Such an integration could go a very long way, as both applications are very complex, and if the "wedding" works well, new possible fields of use could emerge. Also, we think this kind of inter-project integration could pave the way for more, so the possibilities are vast.
      Project Properties
      Skills
      Programming language: C++
      Good understanding and use of APIs from FreeCAD and BRL-CAD
      Knowledge of 3D modeling, topology and computational geometry is a plus
      Difficulty
      High, mostly because you have two different applications to learn and work with

      Project Size
      350h

      ~~~~~~~~~~

      Design a set of interactive controls in the 3D view for tools that have numeric values/inputs (drag to edit)	C++, Coin, Core, User Interface	350h	Hard

      Added from the FreeCAD Day 2024 Complaint Session:
      When you have done an operation, such as extrude, it’s impossible to visually edit that parameter via click and drag

      Currently all inputs for value/parameter based tools are handled. via the task dialog or the property view. It would be great to input data in the 3D view (widget/overlay) and also click and drag interactively in the 3d view to manipulate the feature. Also the direction of a feature could be indicated by arrows in the 3D view for an overall better UX and easier onboarding for new users.

      Applicable features would be:

      Pad feature: display direction with an arrow, click and drag arrow to define the length. (Double)click the arrow to reverse direction. Typing would insert a value in a widget right in the 3D view (like OVP in Sketcher WB).
      Revolve feature: display the direction and angle, dragging changes the angle
      Sheet metal flange: display direction, angle and length
      Pattern feature: define direction, offset, remove single copies
      and so on...
      Example of other software:

      fusion360-interactive-extrude

      solidworks-interactive-flange

      catia-interactive pattern

      fusion360-interactive-revolve

      Issue imported from https://tracker.freecad.org/view.php?id=4640

      Reporter: nukeRomancer
      Date submitted: 4/21/2021
      FreeCAD version: 0.2
      Category: Feature
      Status: new
      Tags:
      Original report text
      interactive controls in the viewport for all / most ( where applicable ) tools that have numeric values / inputs

      this would be a MASSIVE improvement to the general workflow

      https://forum.freecadweb.org/viewtopic.php?p=496292#p496292

      Other bug information
      Priority: immediate
      Severity: feature
      Category: Feature
      Updated: 4/22/2021
      Discussion from Mantis ticket
      Comment by Pauvres_honteux 2021-04-22 14:51
      Some good examples of how user interacting stuff can be made, begins at 28 minutes

      ~~~~~~~~~~
      
      Direct modeling tools	C++/Python, BIM, Core	350h	Medium

      Issue imported from https://tracker.freecad.org/view.php?id=3353

      Reporter: yorik
      Date submitted: 2/22/2018
      Original report text
      FreeCADs is a feature-based parametric modeling system, hence different modeling steps depend on one or multiple previous steps. Each step is at the same time a tool/operation, and a geometrical object, resulting from that operation. This mix of operation and object is called a feature. Direct modeling, often presented as the opposite of parametric modeling, allows to graphically move vertices, push or pull faces and edges to modify the geometry of an object.

      This issue is a GSOC idea https://www.freecadweb.org/wiki/Direct_modeling_tools

      and also as a test for bountysource...

      Other bug information
      Priority: normal
      Severity: minor
      Category: Feature
      OS: Debian Testing 64bit
      Platform: PC
      Updated: 2/6/2021
      Discussion from Mantis ticket
      Comment by Kunda1 2021-01-31 11:21
      Several attempts have already begun to tackle this issue:

      carlopav in https://forum.freecadweb.org/viewtopic.php?t=49837
      https://github.com/MariwanJ/Design456

      ~~~~~~~~~~
      Integrate a client for the buildingSMART Data Dictionary web service	Python, BIM	175h	Easy  

      The situation
      The BuildingSmarth Data Dictionary (BSDD) is an onlne service provided by BuildingSMART, the non-profit body that maintains the IFC file format, an universal and open file format for BIM.

      BSDD allows a user to query for terms and receive a series of records of where that term is used in different standards such as IFC itself, but also other classification systems used in the world. The final aim is to help BIM users, when they define something, for example a wall, to query the BSDD service to help them find what classes of what classification systems are applicable to that wall, and which one they should use. This can be used not only for objects, like a wall, but also materials (concrete, brick...) or even properties of an object (for ex the height of a wall).

      Classification systems are huge standards that define each and every item in a construction project. The aim is to have things defined as precisely as possible, so there is no ambiguity over what is what. Additionally, having a classification tag attached to an object also helps to overcome translation problems, as it's the same reference number across different languages.

      A BSDD client in FreeCAD
      Currently, assigning a class to an object works like this:

      A user designs a wall
      The user wishes to add a classification entry to that wall
      They can, in the BIM workbench, open the classification manager, choose a classification system, and search for the term "wall" in that system
      The user then picks the class they find most appropriate
      A BSDD workflow in FreeCAD could look like this:

      When opening the classification manager in the BIM workbench, a third panel could open
      That panel could already present a series of suggestions based on the current selected object
      The panel should also allow the user to see what have been search for automatically, and change that if that's not correct
      The user could click on one of the suggestions
      The appropriate classification would be used
      Expected Outcome
      Build a detailed plan of the workflow: What you imagine the user would need to do, and how that would happen
      Design a system to connect to the BSDD service. Beware, it requires authentication, one should carefully read the docs
      Extend the classification manager in the BIM workbench to add BSDD functionality
      Project Properties
      Skills
      The student should have reasonable coding skills in Python. The student should also get familiar with:

      All the details and requirements on https://wiki.freecad.org/Google_Summer_of_Code_2024
      Work with GIT, GitHub and pull requests
      The BuildingSMART Data Dictionary
      The BIM workbench
      The classification manager
      How BlenderBIM implements BSDD (see comments by Dion Moult below) and see how close we can match what they did
      Difficulty
      Medium

      Duration
      350h

      Additional Information
      Main FreeCAD GSoC page: https://wiki.freecad.org/Google_Summer_of_Code_2024
      Potential mentor(s): Yorik
      Organization website: https://freecad.org
      Communication channels: GSoC section on the FreeCAD forum and this issue
      
      
      
      

























      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/freecad/
    idea_list_url: https://wiki.freecad.org/Google_Summer_of_Code_2025


  - organization_id: 46
    organization_name: GNOME Foundation
    no_of_ideas: 5
    ideas_content: |
      
      Add eBPF profiling capabilities to Sysprof
      Papers: Proof of Concept for backend isolation
      Vala: Researching/Designing/Implementing xml/json/yaml/... integration
      Add printing support to GNOME Crosswords
      Add Wordlist Scoring to GNOME Crosswords Editor
      Project proposals will be listed here.
      Add eBPF profiling capabilities to Sysprof
      Currently, Sysprof works by recording stack traces from the Linux Perf subsystem using perf_event_open(). It also can record various system statistics using data from /proc such as CPU, memory, networking, and disk statistics.
      eBPF provides an existing new direction for tooling of this nature by uploading small programs into the kernel to extract the data you want without the parsing overhead. That data can be delivered to an application like Sysprof for recording into the capture files.
      This internship would involve creating the tooling within libsysprof to setup new eBPF programs by compiling, linking, and uploading them into the kernel along with necessary components to get data from the kernel back to Sysprof.
      This would then be used to port some collectors such as CPU or memory trackers to use eBPF instead of /proc files.
      Requirements
      Knowledge of C, preferably using GLib/GObject but that can be learned
      Minimal experience performance profiling software
      Minimal experience with the Linux kernel
      Learning how eBPF works and how to integrate that with the kernel can be learned on the job
      Communication
      Chat, email, video chat. Christian Hergert @chergert or hergertme on IRC/Matrix or @chergert at gnome.org
      Mentor(s): Christian Hergert
      Difficulty: Hard
      Mentor availability: ~350 hours
      More information
      https://gitlab.gnome.org/Teams/Engagement/internship-project-ideas/-/issues/51

      ~~~~~~~~~~
      Papers: Proof of Concept for backend isolation
      This project will mostly require work on Papers' libraries: ppsview and ppsdocument. The former contains an abstraction (PpsJob) to run (potentially slow) backend code in threads. The later is basically a common abstraction over different backends: PDF, DJVU, Tiff, etc. The idea is to create a component that will start a new process per-document (similar to web-browsers having one process per tab!). That side-car process will take care of all the calls to the backends (so embedded in ppsdocument), and be managed by PpsJobs. Further details are available in https://gitlab.gnome.org/GNOME/Incubator/papers/-/issues/104
      The idea for the GSoC will be for the Intern to prototype a solution to this problem, and investigate potential solutions and foot-guns. The intern will need quite a good knowledge on C, and have motivation to do some investigate work (e.g: look into solutions implemented by other projects like WebKit). I don't expect a full implementation or solution, even if that would be welcomed. A failed attempt at this might already gives us extremely valuable input.
      This will benefit Papers as the future Document Viewer in GNOME in two ways:
      By isolating documents from each other, we improve the overall security situation. Even CVEs that might allow somebody to gain access to execution code from rendering a PDF would not have access to the other documents.
      By isolating documents from the UI we improve the resilience of Papers. A document crashing during rendering (for which CVEs happen regularly (last one CVE-2024-6239) will not bring down with itself the complete application. This has been so far the main blocker to implement the Document Viewer tabbed view, which has been a feature request for Evince since 2005
      Requirements
      Good skill and experience in the C programming language. Both be able to write and read it
      The ability to investigate previous approaches to solve the same issue. We will guide the Intern on where to look
      Motivation to try different approaches. We know a big part of this project will be checking the feasibility of different solutions
      Communication
      Our preferred communication channel is Matrix (https://matrix.to/#/#papers:gnome.org), but we will also do video-calls to get onboarded and if deemed useful and necessary for the mentoring process
      Mentor(s): Pablo Correa Gomez, Qiu and Markus
      Difficulty: Hard
      Mentor availability: ~350 hours
      More information
      https://gitlab.gnome.org/Teams/Engagement/internship-project-ideas/-/issues/58

      ~~~~~~~~~~
      Vala: Researching/Designing/Implementing xml/json/yaml/... integration
      The goal of this project is to add xml, json and/or yaml format language integration to Vala. Other integrations already exist for DBus, GTK builder format, or GModule (https://gnome.pages.gitlab.gnome.org/vala/manual/attributes.html#dbus-attribute). Examples can be found here.
      Currently, parsing and emitting files in Vala with formats like xml, json, or yaml are relatively tedious, need a lot of boilerplate code, and are much more complicated than in other programming languages. But these file formats are very commonly used in modern software, and many internet protocols and existing standards depend on them. Improving their handling would allow more efficient development, as well as lower the barrier for newcomers to Vala.
      First, research is necessary, to find out how other programming languages have done the integrations. Also wanted features will need to be evaluated. For that also different example projects need to be looked into or created, to find the different use cases and related challenges and how to address them. For proposing designs of the new Syntax, "code mock-ups" are going to be written. These can later also serve as test cases for the vala test suite. Then the community will discuss and give feedback to iterate on the syntax design. As the last step (and probably the one taking the longest time), the proposed syntax('s) will be prototyped inside the Vala compiler. Also test cases for the new features, documentation and example code snippets should be developed at the end of the project. If time is left at the end, also other projects that benefit from the new features can be updated to use the new syntax, for example the Vala Language Server.
      Requirements
      Experience with programming in general, as well as a good understanding of object orientation
      Ready to learn the Vala language, and to understand and investigate the syntax of other programming languages for research purposes
      Being open to reach out to the Vala community, and to contributors of other projects written in Vala, to collect feedback about the current situation and the new syntax
      Ability to grow familiar with a relatively large codebase, to find solutions to problems you encounter (There will be a lot of guidance of course)
      Communication
      Main communication channel: Matrix: https://matrix.to/#/#vala:gnome.org Calls are possible for onboarding and mentoring whenever there is a need. (And when enough time)
      Mentor(s): Lorenz Wildberg
      Difficulty: Medium
      Mentor availability
      TBD
      More information
      https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/61

      ~~~~~~~~~~
      Add printing support to GNOME Crosswords
      GNOME Crosswords has some cursory svg code, but doesn't support printing. It is relatively straightforward to extend the svg code to produce printable puzzles. This project consists of multiple sequential stages, with some simple initial milestones and some stretch goals as well. In particular:
      Initial design and planning
      Refactor the svg code to make it handle the existing board and thumbnail usecases, as well as printable puzzles
      Add clues to the generated svg, and make it look good
      Bring the printing dialog to both the game and the editor
      Add crossword-specific options to the printing flow
      As stretch goals, it would be good to support additional puzzle types, as well as add an ipuz2pdf utility to the app.
      Requirements
      Knowledge of C, especially glib-style C programming. Ability to understand a complex codebase and issues.
      Familiarity with svg a plus
      A physical printer is not necessary
      Communication
      Primarily matrix. The main crosswords channel can be found at https://matrix.to/#/#crosswords:gnome.org
      We also will use gitlab issues and email as appropriate. Video conferencing occasionally when necessary.
      Mentor(s): Jonathan Blandford, Federico Mena Quintero, tanmayp@gnome.org
      Difficulty: Medium
      Mentor availability: ~350 hours (Could be ~175 hours if necessary, with fewer milestones reached
      More information
      https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/62

      ~~~~~~~~~~
      Add Wordlist Scoring to GNOME Crosswords Editor
      GNOME Crosswords Editor uses some lists of words in order to produce crosswords. These lists lack the metadata to make more interesting puzzles. We'd like to find, gather, and encode that metadata with the lists in order to choose appropriate words when working with the editor.
      For more information on the problem, please read this design doc.
      This project will involve finding ways to calculate, measure, and encode values for each of the five traits listed. We will then use it when creating a puzzle to try and create more interesting grids.
      Requirements
      The biggest requirement for this project is a love of words, and a certain amount of comfort with uncertainty. I will expect the intern to do some independent research and exploration
      This project will mostly be in python, and will involve a fair amount of data analysis as well as codings
      Some low-level C programming knowledge is a strong plus, as well as the ability to use a hex-editor. The current wordlist is stored in a custom data structure
      This project will involve working with some large data sets — possibly as big as 20 GB. A relatively fast machine with sufficient disk space will be required, as well as the ability to download large files.
      Communication
      Primarily matrix. The main crosswords channel can be found at https://matrix.to/#/#crosswords:gnome.org
      We also will use gitlab issues and email as appropriate. Video conferencing occasionally when necessary.
      Mentor(s): Jonathan Blandford, Federico Mena Quintero, tanmayp@gnome.org
      Difficulty: Medium
      Mentor availability: ~350 hours (Could be ~175 hours if necessary, with fewer milestones reached
      More information
      https://gitlab.gnome.org/Teams/internship/project-ideas/-/issues/63
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gnome-foundation/
    idea_list_url: https://gsoc.gnome.org/2025/


  - organization_id: 47
    organization_name: GNSS-SDR
    no_of_ideas: 4
    ideas_content: |
     
          Project Title: WAAS
      Description:
      Large-sized project (350 h)
      This Google Summer of Code (GSoC) project focuses on advancing the functionalities of GNSS-SDR receivers related to WAAS.
      The primary goal for the summer is to provide a working implementation of a GNSS-SDR receiver working with WAAS signals: Signal acquisition and tracking algorithms for their specific signals. The outcome should be a robust GNSS receiver capable of delivering RINEX-B files and real-time navigation solutions including SBAS information.
      Implement acquisition and tracking algorithms for WAAS signals, following the examples already implemented for other GNSS signals. This would facilitate research on precise positioning, safety positioning and drone-related activities working with real signals. Demodulation of the navigation message, opening the door to open innovation in multi-constellation receivers.
      Required skills:
      Basic knowledge of digital signal processing and proficiency in C++ programming are essential. Familiarity with the GNU Radio framework or GNSS-SDR is considered a valuable plus.
      Potential mentor(s):
      Miguel Ángel Gómez, Luis Esteve, Javier Arribas.


      ~~~~~~~~~~
          Project Title: Sensor Fusion
      Description:
      Large-sized project (350 h)
      This Google Summer of Code initiative aims to enhance sensor fusion capabilities between GNSS (Global Navigation Satellite System) and other sensors. The goal is to develop a functional GNSS receiver capable of integrating additional sensor data into its architecture, generating RINEX files, and enabling real-time navigation solutions—providing on-the-fly computation of position, velocity, and time. The fusion of GNSS signals with data from new sensors will leverage state-of-the-art AI techniques, such as Bayesian filters (e.g., Kalman filters and particle filters), graph neural networks (GNNs), and transformers for spatiotemporal data modeling. These methods will enhance research on sensor fusion, precise positioning, and urban canyon navigation using real-world signals.
      Integrating additional sensors into GNSS receivers is a key step in advancing next-generation multi-constellation systems. This innovation fosters open research and development while addressing critical challenges such as integrity, reliability, robustness, extended coverage, and high-accuracy positioning.
      Required skills:
      Applicants should possess a fundamental understanding of digital signal processing and demonstrate proficiency in C++ programming. Knowledge of GNSS principles and prior experience with sensor fusion, particularly between GNSS and INS, will be advantageous.
      Potential mentor(s):
      Miguel Ángel Gómez.

      ~~~~~~~~~~
          Project Title: Vector Tracking
      Description:
      Large-sized project (350 h)
      This Google Summer of Code initiative aims to enhance vector tracking capabilities between GNSS (Global Navigation Satellite System). The goal is to develop a functional GNSS-SDR receiver capable of performing Vector Tracking. It is well-known that the use of Vector Tracking Loops (VTL) in GNSS receivers can result in improved tracking performance and sensitivity, faster acquisition, and improved interference robustness. This project leads to a real-time SDR GNSS VTL receiver capable of working with different COTS front-ends. These methods will enhance research on sensor fusion, precise positioning, and urban canyon navigation using real-world signals.
      Required skills:
      Applicants should possess a fundamental understanding of digital signal processing and demonstrate proficiency in C++ programming. Knowledge of GNSS principles and prior experience with sensor fusion, particularly between GNSS and INS, will be advantageous.
      Potential mentor(s):
      Miguel Ángel Gómez.

      ~~~~~~~~~~
          Project Title: Improving the volk-gnsssdr library
      Description:
      Medium project (175 h)
      This project aims to improve volk-gnsssdr, the Vector-Optimized Library of Kernels for GNSS-SDR. This library provides SIMD-optimized implementations of essential signal processing functions (named kernels in this context) for efficient execution on modern processors.
      Objectives: During the summer, the focus will be on:
      Identifying performance-critical kernels that significantly impact GNSS-SDR execution speed.
      Implementing missing SIMD optimizations by adding NEON (for ARM architectures) and RISC-V vector extensions to existing kernels.
      Benchmarking and validating improvements to ensure enhanced performance and correctness across different hardware platforms. No physical access to those hardware platforms is required.
      Expected outcomes: By the end of the project, volk-gnsssdr will have broader SIMD coverage, improving the efficiency of GNSS-SDR on ARM and RISC-V architectures, making it more portable and performant for diverse GNSS applications.
      Required skills:
      Applicants should have a solid understanding of numerical computations and be proficient in C programming.
      Potential mentor(s):
      Carles Fernández-Prades.
         
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gnss-sdr/
    idea_list_url: https://gnss-sdr.org/google-summer-code-2025-ideas-list/

  - organization_id: 48
    organization_name: GNU Compiler Collection (GCC)
    no_of_ideas: 9
    ideas_content: |
      
      Rust Front-End. a new compiler front-end for Rust is in development please see: https://github.com/Rust-GCC/gccrs. A number of projects are available, you can choose one of the following. Required skills include C/C++ and finding a way through a large code-base, some knowledge of Rust would of course also be highly beneficial.
      Rewrite Rust lints to operate on our frontend's HIR instead of using GCC's existing infrastructure
      Our frontend has mutliple lint passes (mark-live, scanning for dead code, unused variables...) which are currently implemented by making use of existing GCC middle-end passes. However, this approach poses certain issues for our frontend, and we would like to instead implement these passes using our frontend's internal representation, and more specifically our HIR.
      To facilitate writing these lints, you will first need to introduce a new base HIR visitor class which will allow you to avoid repeating yourself with boilerplate visitor pattern code. Once this is done, you will need to reimplement existing lints to work using this new base visitor class. If time permits, it would be helpful to rewrite other HIR passes to make use of the new visitor framework you will introduce.
      This can be both a medium-sized or large project.
      Complete name resolution pass rewrite
      In order to handle complex imports and exports in the Rust programming language, we have started a rewrite of our name-resolution pass with a new data-structure and a new algorithm for resolving uses. We are planning to get the new algorithm to a working state by Spring 2025, but this rewrite will still be missing some of the features of the old name-resolver. Your goal will be to take care of these features and help us get the name-resolution rewrite to feature-parity with our old algorithm.
      This project should be medium-sized.
      Improving match expressions and pattern matching
      Our frontend is currently lacking support for important Rust patterns such as struct rebinding patterns (destructuring a structure instance's fields and binding them to new names) which prevents us from completing certain compiler milestones, as well as handle existing Rust code within the Rust standard library and Rust-for-Linux project. You will be tasked with improving multiple areas of the compiler in order to improve our handling of match expressions and pattern matching.
      This project can be medium-sized or large.
      
      ~~~~~~~~~~
      
      Fortran – DO CONCURRENT – see GFortranStandards for language links (Fortran standard and what's new documents for 2018 and 202x). Project would be mentored by Tobias Burnus. Required skills include C/C++; some knowledge of Fortran helps, but is not needed. Difficulty medium, size: 175 hours (medium)
      "DO CONCURRENT" is a special way to write loops such that each iteration is independent of another (except for reductions), permitting to run it concurrently.
      Goal is to execute the loops actually in parallel, namely:
      Handling do-concurrent loops in the generic OpenMP code, possibly starting without MASK support and only for those annotated by '!$omp loop'
      Extending it for MASK support / or optimizing the loop count for it.
      Handling parallelization without '!$omp loop' using the command line flag -fdo-concurrent= (like: no parallelization, OpenMP loop, etc.), "parallel" (pthread parallelization similar to (based on?) -ftree-parallelize-loops=n).
      For some experiments and results, see also https://arxiv.org/pdf/2110.10151.pdf or experiments by other compiler vendors (search the internet)
      As of Feb 2025, local/local_init for Fortran loops isn't fully implemented, PR101602, this does not affect the OpenMP implementation but just scalar code, but should eventually be fixed. (Hopefully, it will be fixed by the time this project starts. If not, it could be a first task.)
      
      ~~~~~~~~~~
      Fortran – 2018/202x – Several Fortran 2018 and all Fortran 202x features are unimplemented. See GFortranStandards for language links (Fortran standard and what's new documents for 2018 and 202x).
      Project would be mentored by Tobias Burnus. Required skills include C/C++; some knowledge of Fortran helps, but is not needed.
      The size and difficulty of the project depends on its agreed scope, i.e. it can be both a 175-hour (medium-sized) or a 350 hour (large) project, can be both medium difficulty or hard.
      Effort depends on which new feature(s) are implemented; requires some research about what's missing and about the effort. If interested, please ask via the fortran@ mailing list, https://gcc.gnu.org/lists.html
      For instance, the "Extracting tokens from string", "Interoperability with C", and "Trig functions changes" documented in "what's new in 202x" document would be a medium sized project.
      
      ~~~~~~~~~~

      Fortran – run-time argument checking. – In particular older Fortran code, which does not use modules, but also code which uses implicit-size or explicit-size arrays is prone to argument mismatches. The goal of this item is to add an optional run-time test which works by storing the argument-type/size data before the call in a global variable – and check against it in the callee. (A pointer to the called function is stored alongside to permit calls from uninstrumented code to instrumented code.) This project would/could be mentored by Tobias Burnus. Required skills include C/C++; some knowledge of Fortran helps, but is not needed. Difficulty medium, size: 175 hours (medium).
      
      ~~~~~~~~~~

      Fortran – improved argument compile-time checking – The compiler does check for the arguments in the same file – but it could do better in some cases, i.e. checking better the interface data or updating the expected input better from the use. This project would/could be mentored by Tobias Burnus. Required skills include C/C++; some knowledge of Fortran helps, but is not needed. Difficulty medium, size: 175 hours (medium).
      
      ~~~~~~~~~~

      Enhance OpenACC support. OpenACC is parallel programming model for heterogeneous HPC hardware. GCC currently supports most but not all of OpenACC 2.6. The project idea here is to fill some of the gaps, for example, implement:
      OpenACC acc_memcpy_device runtime API routine
      OpenACC init, shutdown, set directives
      These complement the corresponding acc_init etc. runtime API routines, which are already implemented.
      Make the OpenACC cache directive actually do something
      It's currently only parsed, but we're not actually using it for optimization purposes: prefetch data, move data to low-latency memory.
      OpenACC bind clause
      OpenACC device_type clause
      To work on these items, it's definitely very helpful to have available a GNU/Linux system with an AMD or Nvidia GPU supported by GCC Offloading, but it's not strictly necessary. Mentors: Thomas Schwinge, Tobias Burnus. The size and difficulty of the project depends on the agreed number of items to be implemented, i.e. it can be both a 175-hour (medium-sized) or a 350 hour (large) project, can be both medium difficulty or hard.
      
      Notes on OpenACC init, shutdown, set directives:
      Certain functionality in OpenACC exists both in a directive variant and a runtime API routine variant. For example, OpenACC 2.6 has 2.16.3. "Wait Directive" (directive variant) and 3.2.11. "acc_wait" etc. (runtime API routine variants). In GCC, the front ends map the directive variant to gcc/omp-builtins.def:BUILT_IN_GOACC_WAIT (see git grep --cached BUILT_IN_GOACC_WAIT\\\|c_finish_oacc_wait -- gcc/). This eventually gets translated to a regular function call to libgomp/oacc-async.c:GOACC_wait, which uses the same building blocks as do acc_wait etc., which are also implemented in libgomp/oacc-async.c. (libgomp is the GCC runtime library for OpenMP originally, but then also OpenACC, implementing both the user-level OpenACC "Runtime Library Routines" and the compiler-used GOACC_[...] etc. routines.) Similar for #pragma acc enter data create(var) vs. acc_create, and others. Some users like to use one of directive vs. runtime API routine variants over the other; generally some prefer using the directive variants instead of C/C++ #include <openacc.h> or Fortran use openacc module. Corresponding to the acc_init, acc_shutdown, acc_set_device_num/acc_set_device_type runtime API routine variants implemented in GCC, in OpenACC 2.5, "New init, shutdown, set directives were added", which are not yet implemented in GCC. Implementation of those is assumed to be very much similar as the OpenACC wait directive is via BUILT_IN_GOACC_WAIT, for example, so would enhance the GCC code along these lines, plus proper testsuite coverage.
      
      ~~~~~~~~~~
      Simple file system for use during Nvidia and AMD GPU code generation testing. GCC supports code offloading from a host system to a device: Nvidia and AMD GPUs, via the OpenACC and OpenMP target programming models for heterogeneous HPC hardware. In order to test Nvidia PTX and AMD GCN (etc.) code generation, bare of the OpenACC/OpenMP code offloading infrastructure, we run GCC's make check in configurations where the GPU is treated similar to an embedded device: generate (single-threaded) GPU code, use a run tool to load it to the device and execute it (Nvidia, AMD), and return success status. Other than simple malloc and printf implementations, these device kernels don't have any "access to the outside world". In particular, they have no way to read/write files -- which a number of GCC test cases like to do, which thus currently FAIL to execute. The idea of this GSoC project is either (a) to implement a simple "in-memory" file system (volatile), which is either (a.1) initially empty or (a.2) initially contains files as determined by the test harness (dg-additional-files directives used in test cases), and may grow additional files that the respective test case writes, and then is able to read back, or (b) to implement an RPC mechanism from the device to the host, so that device kernels may access host files. (The latter is implemented by LLVM, for example.) Either variant is to be implemented in the run tools mentioned above, and newlib, which provides a libc for the devices. In order to execute this project, you have to have a system with a GPU that is supported with GCC code offloading (a laptop with Nvidia GPU should work, for example), and some prior experience with low-level GPU or embedded programming is highly desirable, as well as understanding of low-level file access: how are open, write, etc. typically implemented. For variant (a), how to implement a simple "in-memory" file system; for variant (b), how to implement an RPC mechanism between device and host? Performance is not a big concern in this context. Mentor: Thomas Schwinge. The size and difficulty of the project depends on the agreed number of items to be implemented, i.e. it can be both a 175-hour (medium-sized) or a 350 hour (large) project, can be both medium difficulty or hard.
      
      ~~~~~~~~~~
      
      Extend the static analysis pass GCC has gained an experimental static analysis pass which performs some rudimentary checking of malloc/free and the stdio FILE stream API. There is plenty of scope for extending this pass in ways that may interest a contributor, such as
      Add format-string support to -fanalyzer. We currently have two different implementations of warnings for format strings (e.g. printf) in GCC; gcc/c-family/c-format.cc implements -Wformat in the C/C++ frontends, doing type-checking on format strings against their arguments, and gcc/gimple-ssa-sprintf.cc implements parts of -Wformat_overflow=, -Wformat_truncation=, and -Wrestrict in the middle-end). Now that the analyzer has -Wanalyzer-out-of-bounds, it might be good to refactor and generalize this format-string parsing to share more code, and so that the analyzer can reuse it, and do similar range analysis (but with the analyzer's more precise path-sensitive interprocedural approach; see https://gcc.gnu.org/bugzilla/show_bug.cgi?id=107017)
      Add a checker for some API or project of interest to the contributor (e.g. the Linux kernel, a POSIX API that we're not yet checking, or something else), either as a plugin, or as part of the analyzer core for e.g. POSIX.
      Extending the analyzer's support for C++. See https://gcc.gnu.org/bugzilla/showdependencytree.cgi?id=97110.
      Extend the plugin to add checking for usage of the CPython API (e.g. reference-counting); see https://gcc.gnu.org/bugzilla/show_bug.cgi?id=107646
      This project would be mentored by David Malcolm. Required skills include C/C++ and finding a way through a large code-base. The size of the project depends on its agreed scope, i.e. it can be both a 175-hour (medium-sized) or a 350 hour (large) project but it is probably easier to define a large one. Difficulty also depends on scope but is likely to be hard.
      One more project idea, co-mentored by Thomas Schwinge:
      e. add checks for programs using OpenACC (parallel programming model for heterogeneous HPC hardware), for example: extend the analyzer's existing malloc/free-like checks to understand OpenACC host vs. device memory, and OpenACC runtime API memory allocator and mapper routines (acc_malloc vs. acc_create vs. acc_map_data etc.; see also here). Depending on the number of checks to be implemented, this can also be both a 175-hour (medium-sized) or a 350 hour (large) project. As the suggested checks only concern host-side code, having an AMD or Nvidia GPU supported by GCC Offloading is not necessary for this project.
      
      ~~~~~~~~~~
      
      Tooling for running BPF GCC tests on a live kernel. eBPF is a technology for injecting code into, for example, a running Linux kernel, in a safe way. GCC contains a back end for eBPF code generation. There is a target specific testsuite with many compile-time tests, and a lot of the other compiler testsuites can also be tested. However, the BPF backend doesn't have any execution tests. Other backends rely on a simulator in order to run target GCC tests. However, BPF programs are not like userland programs. They have no main function. Instead every compiled object may feature several entry points, which are designed to be invoked by a kernel. These entry points are of different kinds, and the context provided via a pointer argument to each entry point is different depending on the kind of entry point. For example, a BPF entry point for a kprobe gets passed an argument that points to a description of the probed task. Due to this, it would be very difficult to have a simulator actually emulating a running kernel with all its complexities. We do have a simulator, but it is designed just to emulate simple instructions in combination with GDB. The goal of this project is to:
      Write a test tool (probably within the contrib/ directory in the GCC sources) to launch a suitable kernel in some sort of virtual environment (like qemu) and load and execute a given BPF program object. This is similar to what the kernel BPF sefltests infrastructure does. This also requires to write some glue infrastructure for the BPF tests, in order to communicate the result of execution of tests etc.
      Once we have the test tool, the next step will be to integrate it in the Dejagnu based testing infrastructure in GCC.
      Finally, using the integrated infrastructure, a new testsuite for the BPF target shall be added to the GCC testsuite, containing an initial set of well choosen tests.
      Note that the BPF, by its own nature, will really benefit from having execution tests in the compiler testsuite, because in practice every compiler change (not just in the BPF backend) has the potential of causing the compiler to generate programs that are not verifiable by the kernel BPF verifier. This is thus an important project. Prior knowledge of eBPF specifically is not necessary but useful; some prior knowledge of (virtual) instruction set architectures is desirable. Knowledge on building the kernel and virtualization environments would also be very useful. Mentors: David Faust, Jose E. Marchesi, Thomas Schwinge. The difficulty of this project is medium, and the size is large: 350 hours. However, if only the point 1 and 2 are implemented then it could be medium-sized: 175 hours.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gnu-compiler-collection-(gcc)/
    idea_list_url: https://gcc.gnu.org/wiki/SummerOfCode

  - organization_id: 49
    organization_name: GNU Image Manipulation Program
    no_of_ideas: 14
    ideas_content: |
      
      Implement In-Painting Tool
      Category
      User Interface, Core, Tools, GEGL
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, CmykStudent
      Difficulty
      Intermediate
      Outcome
      implementation of the tool in GIMP codebase
      GIMP has had support for in-painting (filling in an area based on the surrounding image) for many years with the third-party Resythesizer plug-in. There have been many requests to implement the feature as a tool directly in core GIMP. In addition to this algorithm, there is also the GEGL operation alpha-inpaint which works similarly.
      Relevant discussions that would assist with implementing this feature can be found here and here.
      Study the Resynthesizer plug-in, gegl:alpha-inpaint operation, and other implementations
      Design a potential implementation and UI
      Improve the implementation of the algorithms as needed
      Implement the tool

      ~~~~~~~~~~
      Image Segmentation Improvements
      Category
      Core, Tools
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, CmykStudent
      Difficulty
      Intermediate
      Outcome
      New and/or improved algorithms for selecting parts of images
      GIMP has many different tools and algorithms for selecting specific sections of an image - from the standard Rectangle and Ellipse Select tools to the more advanced Paint Select and Foreground Select tools. Yet there are always new algorithms and methods for segmenting images.
      Find an existing algorithm or propose a new one
      Implement, optimize and test for real image processing work on a variety of images
      Design how it should be used in GIMP
      An additional mode in an existing tool
      A new tool entirely

      ~~~~~~~~~~
      Improving unit testing
      Category
      Unit testing
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, Jacob
      Difficulty
      Intermediate
      Outcome
      Improved unit testing infrastructure and new unit tests
      Currently GIMP unit testing framework is really outdated, adding new tests is complex and therefore never happens. We should specify and code a proper framework for testing GIMP features.
      This implies automated tests we can run in our Continuous Integration in Gitlab and not interactive tools (though such tools can be interesting too, as additional process, if someone has something nice to propose).
      Port existing tests to the new framework;
      Testing all libgimp functions;
      Testing GEGL operations implemented within GIMP codebase;
      Testing plug-ins (in priority the file import/export ones, but not only);
      Testing core code;
      Testing GUI code if possible;
      Writing down the procedure to add unit tests to make it a mandatory process in future development.

      ~~~~~~~~~~
      Fuzz testing integration
      Category
      Unit testing, Security
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, Jacob
      Difficulty
      Intermediate
      In addition to unit testing, we would also like to build a robust automated fuzz testing suite. Integrating a fuzzer would help us better detect when new code could lead to a security vulnerability or incorrect behavior in GIMP. This project would cover many aspects of GIMP, from core code to plug-ins to public API.
      Study GIMP and determine what areas to cover in initial implementation
      Review fuzzing techniques and tools
      Design a test suite and process
      Implement fuzz testing suite

      ~~~~~~~~~~
      Implement sandboxing for plug-ins
      Category
      Security, Plug-ins
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, Jacob
      Difficulty
      Complicated
      Many features of GIMP such as image import and export are implemented with separate plug-ins. For this project, we would like to run them in a sandbox environment for safety and security.
      This is a complex project, and requires knowledge of both GIMP’s architecture as well as extensive research into security. Mentors would be learning alongside the student, so any interested individual would need to be able to work well independently. Please contact us to discuss your proposal for this project.

      ~~~~~~~~~~
      Improving the text tool
      Category
      GEGL, color science
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Liam Quin
      Difficulty
      Intermediate
      Outcome
      Improvement of the text tool
      This is a project following up a few previous GSoC projects, which deserves further work as this is a complicated topic.
      Our text tool is a bit of a UI and UX mess and deserves a proper rewrite/enhancement project:
      Re-specify text editing and formating as well as the tool option, for existing features, but also adding new features for modern text editing (see also this draft);
      Add OpenType support.
      Continue previous years experiments on a new text layout library.

      ~~~~~~~~~~
      Implement GEGL operations for GIMP
      Category
      GEGL, image processing
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, Øyvind
      Difficulty
      Intermediate
      Outcome
      implementation or improvements of GEGL operations in GIMP or GEGL codebase
      The migration of GIMP to use GEGL has accelerated - for some GIMP functionality the main hurdle to migrate is having GEGL ops that can act as drop in replacement for the core processing functionality (some ops would be desired directly in GIMP others could likely go directly into GEGL).
      For most code involved, porting to GEGL involves understanding what the current code does; and port or reimplement it as a floating point processing operation (floating point math often ends up shorter and more readable than the 8bit equivalents.
      There are also some filters which were ported to GEGL, but some people prefer the old one (e.g. the Sharpen filter). It would be worth investigating the difference and either implement the old one or improve the new one.
      Talk to us for specifics on which operations would be a good project`.

      ~~~~~~~~~~
      Implement OpenColorIO Color Management
      Category
      User Interface, Core, Tools, GEGL
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      drc, CmykStudent
      Difficulty
      Intermediate
      Outcome
      implementation of the OCIO color management system in GIMP codebase
      GIMP uses industry standard ICC Color profiles to allow users to match and maintain colors for image editing and printing. The film industry utilizes a separate standard, OpenColorIO, which focuses more on manipulating colors in a space rather than trying to keep them consistent across multiple devices.
      This project would involve adding support for OCIO color management in addition to the existing system. This addition would improve user workflows for motion picture and animation work, as well as improve compatibility with other OCIO-supporting software like Blender and Krita. The project would involve the following:
      Research OCIO and color management systems in general
      The Krita manual has an excellent overview of the subject
      Design and test a user interface
      Implement the code
      
      ~~~~~~~~~~
      Implement GEGL Filter Browser
      Category
      GEGL, User Interface
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan
      Difficulty
      Intermediate
      Outcome
      implementation of the feature in GIMP codebase
      During the 3.0 development process, a new filter API was created that allows script and plug-in developers to apply any valid GEGL filter they have installed. However, GIMP doesn’t not currently have a built-in browser to easily find the name, descriptions, and properties of these filters.
      For this project, you would design and develop a GEGL Browser, similar to the existing Plug-in and Procedure Browsers. This will involve both code development and UX/UI Design.
      
      ~~~~~~~~~~
      
      Improve Non-Destructive Editing
      Category
      GEGL, User Interface
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, CmykStudent
      Difficulty
      Intermediate
      Outcome
      implementation of the feature in GIMP codebase
      As of version 3.0, GIMP now has initial support for non-destructive editing with layer effects. Yet there is much more work to be done. Our roadmap provides some ideas for the next areas to improve, or you can propose your own:
      Studying the current implementation
      Design improvements to UI or functionality
      Implement the improvements
      
      ~~~~~~~~~~
      Improving off-canvas editing
      Category
      User Interface, Core
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan
      Difficulty
      Intermediate
      Outcome
      implementation of the feature in GIMP codebase
      GIMP recently got the ability to view the image out of the canvas. This is still incomplete. Among the many possible improvements:
      Being able to select off-canvas.
      Being able to see off-canvas but with an effect (e.g. dimming).
      Having various tools and features working differently when “Show All” is enabled.
      
      ~~~~~~~~~~
      Improve Metadata Editor and Viewer
      Category
      Metadata, Plug-in, User Interface
      Project size (GSoC)
      Large (350 hours)
      Skills
      C
      Possible mentors
      Jehan, Jacob
      Difficulty
      Intermediate
      Outcome
      Improved metadata UI and codebase
      Our image metadata viewer and editor could use some code review and improvements. It currently supports only a subset of all valid metadata, and the UI could be improved to allow easier editing and viewing of metadata.
      Additionally, some image formats such as HEIC, FITs, and DICOM have custom metadata. Another aspect of this project might be considering how to handle these in a way that is easily extensible and maintainable.
      For further inspiration, you can review open issues tagged with the Metadata label in our tracker.
      Review metadata related issues and develop a plan
      Design user interface and code structure
      Implement planned changes in the metadata plug-in
      
      ~~~~~~~~~~
      Extension website
      Category
      Web
      Project size (GSoC)
      Large (350 hours)
      Skills
      Python, HTML, Javascript and other web technologies
      Possible mentors
      Jehan
      Difficulty
      Intermediate
      Outcome
      New website and build scripts for continuous integration
      We would want a website for our future extension platform, with very specific criteria. Apart from some necessary dynamic parts, we want a website as static as possible, with generated pages when possible. GIMP is a software project, which relies on community. We don’t want to spend all our time having to maintain and manage a website with a lot of moving parts. So we need simplicity first, security first, with just the right amount of dynamicity. The static website framework which we seem to want to go with the most in our project right now is Hugo.
      Even though it has a “web” component, this project is also about building a proper backend, which includes processing XML metadata (AppStream) in a secure way (considering third-party received data as unsafe and possibly malicious), generic static web and repository data from these repositories, and more.
      See this document for an early overview of what we are looking for.
      
      ~~~~~~~~~~
      Convert gimp-help build system from autotools to meson
      Category
      gimp-help, build system
      Project size (GSoC)
      Large (350 hours)
      Skills
      Python, some understanding of autotools and Makefiles
      Possible mentors
      Jacob
      Difficulty
      Intermediate
      Outcome
      The gimp-help repository can be built using meson
      More and more projects move from autotools to meson for building. GIMP itself already uses meson as main build system. We would want all targets in our autotools build converted to meson. The main ones being able to build html for all languages, validate the xml files, create the distribution packages, making pdf quickreference guides, etc.
      Some guidelines for porting from autotools to meson can be found here, and more Gnome specific here.
      The build system needs to function on Linux, Windows and Mac. This would need to be integrated in our CI builds. There is an almost 2 year old repository where some work was done, but we ran into some problems due to the more strict directory and other requirements of meson. However, there have been improvements to meson which may make it easier now.
      It is possible that you may have to write a meson module like the gnome one, which has functions for handling yelp, gtkdoc, etc. Don’t forget to check out the i18n module, you may be able to use that too.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gnu-image-manipulation-program/
    idea_list_url: https://developer.gimp.org/core/internship/ideas/


  - organization_id: 50
    organization_name: GNU Octave
    no_of_ideas: 3
    ideas_content: |
      
      
      Adding clustering *Searcher classes in statistics package
      Although the statistics package already has knnsearch and rangesearch functions, it misses classdefs for extending their functionality. Furthermore, the KDTree method in the aforementioned functions is currently disabled, because it is very slow and poorly implemented (see GitHub issue #151). The goal of this project if to implement KDTreeSearcher, ExhaustiveSearcher, and hnswSearcher classes (including their knnsearch and rangesearch methods) along with the createns helper function. Beyond MATLAB compatibility, the KDTree implementation should ideally utilize a compiled oct library for faster construction and queries of points.
      Project size [?] and Difficulty
      ~350 hours (hard)
      Required skills
      Octave, classdef, C++, good knowledge of clustering methods
      Potential mentors
      Andreas Bertsatos

      ~~~~~~~~~~



      Custom re-implementation of the texi2html (v.1.82) command line tool
      Implement a compiled .oct function to relax the dependency of the pkg-octave-doc package on texi2html (v.1.82) command line tool, which is no longer maintained or further developed but also not readily available to all linux distributions. The idea is to have a `texi2html` function within the pkg-octave-doc package that will replace the functionality of the texi2html (v.1.82) command line tool. This will also help improve the speed of pkg-octave-doc processing large packages, which contain specific tags (such as @math) which are currently handled within Octave code.
      Project size [?] and Difficulty
      ~350 hours (hard)
      Required skills
      Perl, C++, Octave, Texinfo, HTML
      Potential mentors
      Andreas Bertsatos

      ~~~~~~~~~~
      
      Port Chebfun to Octave and improve classdef support
      Chebfun uses interpolation to approximate functions to very high accuracy, giving numerical computing that feels like symbolic computing. The software is implemented as collection of "classdef" classes and is Free and Open Source Software. However, Chebfun does not yet work with Octave, largely due to differences and issues with Octave's classdef implementation. This project has two aims: (1) make changes to the Chebfun code to make it work on Octave and (2) improve Octave's classdef functionality. Some initial steps toward to first goal can be found on this octave_dev branch. The second goal will likely involve a collaborative effort because classdef is a priority on | Octave's Development Roadmap and because other proposed projects also involve classdef.
      Project size [?] and Difficulty
      ~350 hours (hard)
      Required skills
      Octave, object-oriented programming, polynomial interpolation and approximation theory, C++.
      Potential mentors
      Colin B. Macdonald

    
      
      
      
      
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gnu-octave/
    idea_list_url: https://wiki.octave.org/Summer_of_Code_-_Getting_Started#Suggested_projects
  

  - organization_id: 51
    organization_name: GNU Radio
    no_of_ideas:
    ideas_content: |
      GSoCIdeas
      Jump to navigation
      Jump to search
      Note- also check out Grant Ideas for additional ideas that are more suited towards grant money than GSoC.
      
      Contents
      1 Summer of Code 2025: Project ideas list
      1.1 FM Broadcast Radio application
      1.2 5G Cell Scanner
      1.3 Expanding the GNU Radio 4.0 Block Set
      1.4 Graphical interoperability between CyberEther and GNU Radio
      1.5 GPU Accelerated Signal Processing Blocks
      1.6 GRC and GR 4.0
      1.7 Revitalize in-tree and out-of-tree (OOT) modules
      1.8 CI for maintenance branches and select OOT modules
      2 Old Ideas
      Summer of Code 2025: Project ideas list
      This is the list of project ideas for the summer of code 2025 within GNU Radio.
      Remember that these are ideas and are merely meant as an inspiration for you to write your own proposal.
      Students who do not find a fit among these projects are encouraged to engage with us and suggest new ones. The GNU Radio discussion mailing list is the best place to contact all of us. Please do not contact us off-list for the sake of discussing the summer of code, unless you're contacting a mentor listed here to get feedback on a proposal.
      Reviewing the Google GSoC FAQ page for a broader understanding of project, mentor, and student responsibilities is recommended.
      If you need a USRP or other radio hardware to complete the project, we will be able to arrange something.
      Please add ideas to this list (you may cannibalize old ideas, of course!).
      Guidelines for good projects (when suggesting projects, please consider these):
      Clearly defined scope, with a main target that can be done in 3 months
      Clear benefits for the GNU Radio project
      Not specific to a certain hardware. No specific embedded devices, either, please.
      Both OOTs and in-tree improvements are welcome
      FM Broadcast Radio application
      GNU Radio has built-in capabilities to receive, decode and play FM broadcast radio stations. With additional projects https://github.com/bastibl/gr-rds we are able to decode RDS data alongside. The project does not (yet) have a fully fledged demo application which would allow potential users and beginners to see how to build a production-grade application (almost). The goal for this project is to build an application which works plug&play with many SDRs and automatically scans (all) potential FM broadcast frequencies, gives a channel list and allows users to tune/select a radio station they would like to listen to.
      Therefore one part of the project is to focus on a polished user experience in the frontend application. Since this should be a good demo the other part of the project should focus on developing a well-functioning flowgraph with the existing signal processing blocks and potentially also porting gr-rds to a newer GNU Radio and/or integrating it in the GNU Radio source tree. This flowgraph should then be started/halted on demand of the frontend application. Potentially multiple streams could be recorded at the same time or decoded and some of the signal processing signals can be shown in a debug view so potential beginners and users can perform introspection on the application.
      
      Prerequisites
      Programming skills in Python
      Interest in designing a functional and polished graphical user interface
      Preferred: Familiarity with basic signal processing libraries in Python (e.g., SciPy).
      Interest working with real radio signals
      Expected Outcome
      Fully fledged FM broadcast receiver application with integrated RDS and spectrum scanning
      A clean example application which shows how the signal processing can be combined well with a GUI
      Project Length
      Small (100 hours) – Medium (200 hours)
      Difficulty'
      Easy
      Mentor(s)
      Andrej Rode
      5G Cell Scanner
      Cell scanning by passively observing the RF environment using an SDR and decoding received signals based on the waveforms defined in the 2G/3G/4G/5G standards is a well-established approach for assessing cellular connectivity in the surrounding environment. While multiple cell scanners are publicly available, they often employ opaque signal processing methods and frequently cease analysis prematurely, failing to provide detailed information about the cells. This includes not decoding the Master Information Block (MIB) and the System Information Block (SIB1) to extract cell properties and signal quality metrics. Our objective is to develop a high-quality cell scanner using GNU Radio in a transparent way that delivers the most information possible (depending on the cells’ signal levels) in a trustable manner. The general procedure will be based on the initial synchronization and cell identification process on the user-equipment side of 5G (see further reads). Depending on the student’s experience, we can also go a step further and parallelize the cell scanning process by observing multiple frequency bands simultaneously by applying channelization and parallel processing techniques to the signal.
      Prerequisites
      Proficiency with GNU Radio.
      Basic programming skills in Python.
      Preferred: Familiarity with basic signal processing libraries in Python (e.g., SciPy).
      Preferred: General understanding of the 5G waveform and experience with 5G processing libraries in Python.
      Expected Outcome
      Development of an Out-Of-Tree (OOT) module or flowgraphs capable of interacting with SDR input streams and automatically generating detailed visualizations of cell search results.
      Capability to export results as a function of time and SDR location to enable the creation of coverage maps.
      Further Reads
      https://de.mathworks.com/help/5g/ug/nr-cell-search-and-mib-and-sib1-recovery.html
      https://de.mathworks.com/help/5g/gs/synchronization-signal-blocks-and-bursts.html
      Project Length
      Small (100 hours) – Medium (200 hours)
      Difficulty'
      Medium
      Mentor(s)
      Michael Petry
      Andrej Rode
      
      Expanding the GNU Radio 4.0 Block Set
      GNU Radio 4.0 has reached a stage where real signal processing applications can achieve performance improvements over GNU Radio 3.x. To maximize its adoption, we aim to expand the set of available blocks, making it easier for the community to build applications with readily available components. The goal of this project is to migrate existing GR 3.x blocks (e.g. gr-digital, gr-analog, gr-audio ...) into GR 4.0. A good list of blocks in GR3 that should be ports has been maintained here: [1]
      Prerequisites
      Knowledge of modern C++
      Signal processing understanding
      Outcome
      GR4 OOT module with a substantial number of blocks
      Each block should have CI tests and an example flowgraph
      Document the process so that other block developers can be guided
      
      Project length
      Long (350 hours)
      Difficulty
      Medium
      Mentor(s)
      John Sallay, Josh Morman
      
      Graphical interoperability between CyberEther and GNU Radio
      The CyberEther project comes with some neat graphical sinks that would be great to have access to in GNU Radio. This project entails creating a new CyberEther GUI workflow much like the gr-bokehgui project, such that users can create flowgraphs with CyberEther sinks. This would allow the user to visualize GNU Radio data streams in one of the high-performance CyberEther plots (lineplot, waterfall, spectrogram, etc).
      Prerequisites
      Knowledge of C++ and some Python
      Familiarity with graphical APIs (OpenGL, Vulkan, Metal)
      Basic Qt understanding
      Outcome
      OOT module with CyberEther sinks
      Support for both GNU Radio main branch and 3.10?
      Project length
      Long (350 hours)
      Difficulty
      Medium
      Mentor(s)
      Luigi Cruz, Håkon Vågsether
      GPU Accelerated Signal Processing Blocks
      GPUs offer incredible capability for accelerating a number of signal processing routines when the calculations can be done in parallel. Also, GNU Radio 3.10 brought in a "custom buffers" feature which provides support generally for accelerator devices by allowing blocks to have direct access to device memory, finally making accelerator processing feasible through a flowgraph (see FOSDEM 2022 Presentation.
      One piece that is missing for GNU Radio is a library of blocks that accelerate common DSP routines. There are several interesting libraries of GPU accelerated signal processing - primarily using CUDA because of its accessible programming paradigm and the ubiquity of NVIDIA hardware:
      Matx
      cuSignal (Python signal processing)
      CUSP
      Integration of any of this functionality, along with additional kernels for signal processing would need to be predicated on using gr-cuda custom buffers, and expanding this module as needed
      This project can be broken into several subprojects:
      Create gr-matx OOT
      Add Matx Custom Buffer Type (after gr-cuda)
      Create blocks wrapping Matx operations
      Expand gr-cuda
      Additional custom buffer types - pinned, unified
      Create python custom buffers allowing zero copy into python blocks
      Create gr-cuSignal
      Wrap cuSignal functionality (dependent on python zero copy)
      Replicate existing GR blocks as CUDA accelerated (things not in cuSignal or Matx)
      Target for extensions to Matx, cuSignal, or CUSP (within our control)
      FIR Filters
      Polyphase Resampler
      Signal Source
      Moving Average
      Polyphase Clock Sync
      Stream Operators
      ...
      Prerequisites
      Knowledge of C++ and Python.
      Familiarity with CUDA programming
      
      Outcome
      Depends on chosen subprojects (see above).
      Project length
      350 hours
      Difficulty
      Medium
      Mentor(s)
      Josh Morman, Andrej Rode
      GRC and GR 4.0
      Development of GR 4.0 is progressing quickly. In the current runtime prototype a plugin architecture is used to properly register blocks with the runtime. This allows a more dynamic construction of flowgraphs and introspection into the blocks. But this means the current way of assembling a flowgraph by generating a Python or C++ file needs updates.
      The idea is to port and change necessary parts of GRC (Qt development version) to use the block registry in the new GNU Radio runtime https://github.com/gnuradio/gnuradio4/ and assemble some of the example flowgraphs defined in GRC files and make them run. The design for this is not finalized and therefore you will have freedom to propose your ideas.
      Prerequisites
      Good Knowledge of C++ and Python
      Experience with inter-language bindings (not necessarily C++ & Python) is useful
      Basic Qt understanding
      Outcome
      Prototype integration of GRC with the new plugin architecture of GR 4.0
      Project length
      Long (350 hours)
      Difficulty
      Challenging
      Mentor(s)
      Andrej Rode, Josh Morman
      
      
      
      Revitalize in-tree and out-of-tree (OOT) modules
      A lot has changed since version 3.7, and GNU Radio has made great technical strides the last few years. However, some OOT modules haven't been updated to support the latest versions of GNU Radio, and these modules currently require the user to install an older version of the framework. This is unfortunate, and lowers the useability of GNU Radio as a whole. Some of these modules have been superseded by others, but might still have some blocks or flowgraphs that are useful, and these could be updated and moved in-tree. Some in-tree modules are also in need of attention, like gr-wavelet, which does not have any examples.
      Prerequisites
      Knowledge of C++, Python and DSP.
      Outcome
      More example code, tests and flowgraphs for various in-tree modules
      Porting various OOT modules to support recent versions of GNU Radio
      Possibly blocks/flowgraphs from old OOT modules moved in-tree
      Project length
      Small (90 hours) - Medium (175 hours)
      Difficulty
      Easy - Medium
      Mentor(s)
      Andrej Rode, Håkon Vågsether
      
      CI for maintenance branches and select OOT modules
      It would be useful to have nightly builds for GNU Radio's maintenance branches (3.8, 3.9, 3.10) and some select OOTs.
      Prerequisites
      Experience with Docker?
      ?
      Outcome
      Automated PPAs, Snaps, Flatpak apps
      Project length
      175 hours
      Difficulty
      Easy
      Mentor(s)
      Håkon Vågsether, ?
      Old Ideas
      Feel free to browse old ideas from previous years for inspiration.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gnu-radio/
    idea_list_url: https://wiki.gnuradio.org/index.php?title=GSoCIdeas

  - organization_id: 52
    organization_name: GRAME
    no_of_ideas:
    ideas_content: |
      Google Summer of Code possible projects
      This page contains a list of possible GSoC projects, with a preliminary section explaining the prerequisites to follow before working on a real project.
      Discovering the Faust ecosystem
      The application process for GSoC consists of the next steps:
      become acquainted with the Faust language and ecosystem. In particular looking at the Powered By Faust page can help understanding the variety of projects that have been developed using Faust. Read also the technical documentation.
      join the Faust discord server and #gsoc channel.
      read the GSoC guide for students. Develop your understanding of the various stages of the program. Read this blog post.
      check the GSoC contribution timeline.
      read our Contributing guidelines.
      get invite to chosen project in Faust github organization.
      submit the application/proposal including all requirements at the Google Summer of Code Site.
      Information Candidates Should Supply
      The application process has several steps. First, verify that you meet the GSoC contributor eligibility requirements, i.e. you are at least 18 years old, eligible to work in your country of residence, etc. As of 2023, GSoC eligibility has been expanded to include "open source beginners" in addition to students. The next step is to contact the mentor(s) of the project you are interested in; the best place to do so is in the #gsoc channel of the Faust Discord server, where you can ask questions related to the project you're interested in working on, and submit draft proposals for feedback. Your goal is to convince prospective mentors that you are the right person to get the job done; you can do this by sharing your previous work, demonstrating relevant experience/intuition, asking pertinent questions, etc. Finally, submit a project proposal via your GSoC contributor dashboard. Your submission must include a PDF that should contain the following information:
      Project:
      A detailed description of the project that you wish to tackle. Either select a topic from the list below, or, if you wish to work on an idea of your own, we are pretty open as long as this serves the goal of consolidating Faust and its ecosystem as a whole.
      A proposal of a technical solution with your envisioned methodology. The more detailed the better.
      A realistic schedule with objectives (one every two weeks for example) and deadlines. Focus on mid-term objectives as well as on the final evaluation.
      Personal data:
      First name, last name, affiliation and geographical location.
      A brief list of the main studies and programming courses attended, with ranking.
      List of the most important software projects contributed and success.
      Which are your best skills in terms of programming ?
      In general what is your taste in terms of programming? language, methodology, team work, etc.
      Is there anything that prevents you from working full time on the project during the program period?
      How do you see your involvement after the program ends? Do you see yourself pushing the project further, or do you see yourself contributing to other Faust and its ecosystem projects?
      Are you more interested in the Faust language and its ecosystem, or do you feel more like a hacker?
      What are your long-term wishes in terms of job?
      Possible projects:
      Integrated Faust Language Server and Formatting Extension for VS Code
      Integration in the Heavy Compiler Collection
      Extending the Faust DSP Testbench
      Backend for MOJO
      Support for CLAP format
      Integration in Surge
      Integration in Bespoke
      Integration in Audiokinetic Wwise
      Integration in BELA
      Integration in openFramework
      PluginGuiMagic architecture
      Faust programming by examples
      Languages built on top of the signal API
      Developing modular synthesis using widget modulation
      Some more ideas could possibly be turned as GSoC projects.
      Integrated Faust Language Server and Formatting Extension for VS Code
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      Description: A language server, sometimes called an LSP, is a code analysis tool that allows programming environments to get information about projects. This lets them display information like code completions, inline errors, locations of function definitions, reference official documentation, and more. Many programming languages have their own language server (see https://langserver.org/ for a list), but Faust does not. If there was a Faust language server, it would make it easier to write Faust code using any IDE that supports LSP. This would make it easier for beginners to get started writing Faust using programming tools they're already familiar with, and it would make it easier for experts to navigate large codebases. The tree-sitter-faust project could be helpful in doing any parsing required for a language server.
      We propose to create a Visual Studio Code extension that integrates the Faust Language Server with a dedicated Faust code formatter. Leveraging the vscode-languageclient package, the extension will launch the Faust Language Server to provide robust features (code completion, diagnostics, navigation) while also offering context-aware formatting tailored to Faust DSP syntax.
      Integrate the Faust Language Server:
      Use vscode-languageclient to launch and manage the server, ensuring features like auto-completion and error checking are available for .dsp files.
      Develop a Faust Code Formatter:
      Implement a formatter that understands Faust’s constructs, providing commands and auto-format-on-save functionality to improve readability and enforce best practices.
      Expected outcomes:
      A fully functional VS Code extension that combines the Faust Language Server with a dedicated code formatter.
      Enhanced developer productivity through improved code intelligence and formatting.
      Comprehensive documentation and user-friendly configuration options, making it easier for the Faust community to adopt best practices.
      Skills required: Faust programming, TypeScript and Web programming.
      An easy, medium or hard difficulty rating of each project: medium
      Extending the Faust DSP Testbench
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      Description: The Faust DSP Testbench, a fork of the DSP-Testbench project, is designed to help developers using the JUCE framework to analyse their Faust DSP. This project will focus on extending the Testbench’s functionality to make it a more comprehensive and user-friendly tool for developers and researchers working with Faust.
      The proposed extensions aim to:
      Extend and improve the visualisation tools.
      Enable better visualization of DSP performance and behavior.
      Expected outcomes:
      A robust, user-friendly Faust DSP Testbench with automated testing, benchmarking, and visualization capabilities.
      Comprehensive documentation and tutorials for using the Testbench effectively.
      Skills required: Faust programming, DSP theory, C++, knowledge of the JUCE framework.
      An easy, medium or hard difficulty rating of each project: medium
      Backend for MOJO
      Mentors: Stéphane Letz and Yann Orlarey
      Expected size of project: 175 hours
      Mojo is a new programming language that bridges the gap between research and production by combining the best of Python syntax with systems programming and metaprogramming. Mojo combines the usability of Python with the performance of C, unlocking unparalleled programmability of AI hardware and extensibility of AI models. With Mojo, you can write portable code that’s faster than C and seamlessly inter-op with the Python ecosystem. Having autodifferentiation inside the language is not yet ready but is regularly discussed on Mojo Discord.
      The primary objective of the project is to develop a backend for this new language, add architecture files, and measure how the generated code behaves doing various benchmarks.
      Expected outcomes:
      a new backend to generate MOJO code
      development of MOJO architecture files to create benchmarks and measure the speed of the generated code
      Skills required/preferred: C++ and basic Python programming, Faust programming
      An easy, medium or hard difficulty rating of each project: medium
      Differentiable DSP in Faust [Taken in 2024]
      Mentors: Thomas Rushton, David Braun, Stéphane Letz, and Yann Orlarey
      Expected size of project: 175 hours
      Differentiable programming is a technique whereby a program can be differentiated with respect to its inputs, permitting the computation of the sensitivity of the program's outputs to changes in its inputs.
      Partial derivatives of a program can be found analytically via automatic differentiation and, coupled with an appropriate loss function, used to perform gradient descent. Differentiable programming has consequently become a key tool in solving machine learning problems.
      Differentiable digital signal processing (DDSP) is the specific application of differentiable programming to audio tasks. DDSP has emerged as a key component in machine learning approaches to problems such as source separation, timbre transfer, parameter estimation, etc. DDSP is reliant on a programming language with a supporting framework for automatic differentiation. In Python, this is provided by libraries such as TensorFlow and JAX; other languages, Swift for example, may feature native support.
      We would like to explore the possibility of implementing automatic differentiation in Faust; the successful implementation of a Faust library for differentiable programming would permit the application of Faust to DDSP problems. Exploratory work on such a library has begun; one aim is to turn this into a comprehensive package of support for differentiable Faust programs.
      Related work, concerned with adding automatic differentiation capabilities to the Faust compiler, was conducted for a previous edition of GSoC. Also consult David Braun's DawDreamer project, which uses Faust's JAX backend.
      Expected outcomes:
      creation of an automatic differentiation library describing derivatives for all of Faust's operators, helper functions for generalising the creation of differentiable Faust programs, a variety of time- and frequency-domain loss functions, etc.;
      development of a series of practical applications of the new library;
      a new autodiff (or machine learning) architecture file, to support the training of machine learning models and the generation of parameter weights;
      a means to use the generated weights for real-time inference.
      Skills required/preferred: Faust programming, machine learning
      An easy, medium or hard difficulty rating of each project: medium
      Support for CLAP format
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      CLAP is an Audio Plugin format (as pure C api), liberally licensed (MIT), entirely developers in the open (GitHub), with support from commercial developers (u-he, Bitwig, more). CLAP has many design goals, but a primary one was to allow developers to build their base plugin layer using a properly open clean C standard, to replace the VST2 API which most folks base their plugin model on, and then project into other systems. An extensive discussion can be accessed here.
      The project is to develop:
      a faust2clap tool (see faust2xx Tools and Developing a faust2xx Script) to statically compile Faust DSP code in a CLAP plugin.
      and a CLAP pluging embedding the libfaust based dynamic compilation chain, so that DSP programs can be written and recompiled on the fly
      new C++ architecture files will have to be developed.
      Look at additional CLAP projects.
      Expected outcomes: The result will be a faust2clap script to compile a DSP program in a CLAP plugin, and a CLAP pluging embedding libfaust.
      Skills required/preferred: C++ programming, audio and Faust programming.
      An easy, medium or hard difficulty rating of each project: medium
      Integration in Surge
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      The Surge Synth Team is a group of musicians, developers, testers, documenters, and general volunteer open source enthusiasts who randomly assembled to work on the Surge Synthesizer. Use the Discord channel to connect to their community.
      The project is to develop a faust2surge tool (see faust2xx Tools and Developing a faust2xx Script) to statically compile Faust DSP code in a Surge plugin. This is currently discussed here. You'll probably have to develop or adapt C++ architecture files.
      Expected outcomes: The result will be a faust2surge script to compile a DSP program in a Surge plugin.
      Skills required/preferred: C++ programming, audio and Faust programming, knowledge of the JUCE framework.
      An easy, medium or hard difficulty rating of each project: medium
      Integration in Bespoke
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      More detailed description of the project: Bespoke is a modular DAW for Mac, Windows, and Linux. It contains a bunch of modules, which you can connect together to create sounds. Use the Discord channel to connect to their community. The integration could follow the two steps:
      develop a faust2bespoke tool (see faust2xx Tools and Developing a faust2xx Script) to statically compile Faust DSP code in Bespoke modules
      a complementary approach is to directly embed the Faust compiler (using libfaust + LLVM JIT), allowing DSP programs to be edited, dynamically compiled, and run in the platform
      This is currently discussed here. You'll probably have to develop or adapt C++ architecture files. A recent Faust integration in TouchDesigner can be studied as an example.
      Expected outcomes: The result will be:
      afaust2bespoke tool to compile Faust DSP code in Bespoke modules
      a Bespoke plugin embedding the libfaust + LLVM library, and allowing DSP programs to be edited, dynamically compiled, and run in the platform
      Skills required/preferred: C++ programming, graphical programming, audio and Faust programming.
      An easy, medium or hard difficulty rating of each project: medium to hard
      References:
      Bespoke Anywhere
      Integration in Godot [Taken as an internship in 2025]
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      More detailed description of the project: Godot Engine is a feature-packed, cross-platform game engine to create 2D and 3D games from a unified interface. It provides a comprehensive set of common tools, so that users can focus on making games without having to reinvent the wheel. The integration could follow the two steps:
      develop a faust2godot tool (see faust2xx Tools and Developing a faust2xx Script) to statically compile Faust DSP code in Godot modules
      a complementatry approach is to directly embed the Faust compiler (using libfaust + LLVM JIT), allowing DSP programs to be edited, dynamically compiled, and run in the platform
      You'll probably have to develop or adapt C++ architecture files. A recent Faust integration in TouchDesigner can be studied as an example.
      Expected outcomes: The result will be:
      afaust2godot tool to compile Faust DSP code in Godot modules
      a Godot plugin embedding the libfaust + LLVM library, and allowing DSP programs to be edited, dynamically compiled, and run in the platform
      Skills required/preferred: C++ programming, audio and Faust programming.
      An easy, medium or hard difficulty rating of each project: medium to hard
      Integration in Cables.gl [Taken in 2024]
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      More detailed description of the project: Cables.gl is a tool for creating beautiful interactive content. With an easy to navigate interface and real time visuals, it allows for rapid prototyping and fast adjustments. You are provided with a set of operators, such as mathematical functions, shapes, materials and post processing effects. Connect these to each other with virtual cables to create the experience you have in mind. Easily export your piece of work at any time. Embed it into your website or use it for any kind of creative installation. Use the Discord channel to connect to their community.
      The project would be to integrate the Faust Web Audio Library to dynamically compile and run Faust DSP programs in Cables.gl.
      Expected outcomes: The result will be a Cable.gl plugin embedding the libfaust WASM library, and allowing DSP programs to be edited, dynamically compiled, and controlled with an adapted Graphical User Interface.
      Skills required/preferred: TypeScript/JavaScript programming, Web technologies, audio and Faust programming.
      An easy, medium or hard difficulty rating of each project: medium
      PluginGuiMagic architecture
      Mentor: Stéphane Letz and Daniel Walz
      Expected size of project: 175 hours
      More detailed description of the project: PluginGuiMagic is a WYSWYG runtime design system for JUCE plugins. The foleys_plugin_magic module allows to have a generated UI, that can be edited at runtime using advanced layout and styling options. It also adds visualisers to display signals, levels and spectral with no extra coding involved. The project is to develop new C++ architecture files to ease the use of PGM in the faust2juce tool. Another faust_juce_pgm_skeleton project to look at.
      Expected outcomes: The result will be set of C++ architecture files and an improved faust2juce tool.
      Skills required/preferred: C++ programming, knowledge of the JUCE framework, knowledge of the foleys_plugin_magic module, audio and Faust programming.
      An easy, medium or hard difficulty rating of each project: medium
      VST plugin embedding the dynamic compiler [Taken in 2024]
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      More detailed description of the project: A VST plugin using the libfaust + LLVM JIT to do DSP live coding in any VST aware host. FX and monophonic or polyphonic synthesizers can be written. The source code can be edited and recompiled on the fly. The GUI has to be automatically created. The pMix and Amati projects can be used as starting points. An integration with the PluginGuiMagic architecture could possibly be added.
      Expected outcomes: The result will be a VST plugin developed with the JUCE framework .
      Skills required/preferred: C++ programming, audio and Faust programming, knowledge of the JUCE framework.
      An easy, medium or hard difficulty rating of each project: medium
      Integration in Audiokinetic Wwise
      Mentor: Stéphane Letz
      Expected size of project: 350 hours
      More detailed description of the project: Audiokinetic is the leading global provider of the most advanced and scalable cross platform interactive audio solutions. A trusted technology partner to the world’s largest developers, OEMs, and audio production companies, its flagship product Wwise is the gold standard interactive audio engine on the market. Wwise features a complete suite of design and development tools, making it easy to prototype and bring to life your creative vision for audio, no matter the scale of your project. The integration could follow the two steps:
      develop a faust2wwise tool (see faust2xx Tools and Developing a faust2xx Script) to statically compile Faust DSP code in Wwise modules
      a complementatry approach is to directly embed the Faust compiler (using libfaust + LLVM JIT), allowing DSP programs to be edited, dynamically compiled, and run in the platform
      Look at the faust2wwise preliminary work. You'll probably have to develop or adapt C++ architecture files.
      Expected outcomes: The result will be:
      a new faust2wwise tool with the associated C++ architecture files to compile a DSP project in a ready to use Wwise plugin
      a plugin embedding the libfaust + LLVM JIT dynamic compiler technology to allow Faust DSP live-coding
      Skills required/preferred: C++ programming, audio and Faust programming, knowledge of the Audiokinetic Wwise architecture.
      An easy, medium or hard difficulty rating of each project: hard
      Integration in BELA
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      More detailed description of the project: BELA is a maker platform for creating beautiful interaction. Designed for artists, musicians, researchers and makers, Bela brings the power of ultra-low latency interactive audio and sensors to your digital projects. A Faust/BELA integration has already been done in a faust2bela tool and some preliminary work on the dynamic compilation chain have been done.
      Expected outcomes: The result will be:
      an improved faust2bela tool
      a fully integrated Faust/BELA IDE that would allow to design and experiment Faust code in the Web plaform (using the dynamic WebAssembly based compilation chain), then compile it in C++ and deploy it on the BELA board. Monophonic DSP and MIDI controllable polyphonic instruments should be supported.
      a finished dynamic compilation chain integration.
      Integration in openFramework
      Mentor: Stéphane Letz
      Expected size of project: 175 hours
      More detailed description of the project: openFrameworks is an open source C++ toolkit designed to assist the creative process by providing a simple and intuitive framework for experimentation. It allows to access a lot of additional extensions and libraries in the form of addons. The project is to explore how Faust can be integated in the framework as an ofxFaust addon, either statically (using the C++ generated code from a DSP program), or possibly embedding the libfaust compiler. Adapted architecture files will have to be developed.
      Expected outcomes: The result will be a new ofxFaust and openFrameworks demo examples explaining how to use it.
      Integration in the Heavy Compiler Collection
      Mentor: Alexander Chalikiopoulos
      Expected size of project: 175 hours
      More detailed description of the project: HVCC is a python-based dataflow audio programming language compiler that generates C/C++ code and a variety of specific framework wrappers. It's main focus is in parsing Pure Data DSP patch files, statically interprets them, and converts them to C/C++. The project is to explore how Faust can be integrated into the compiler toolchain. Likely starting from pd-faustgen external and then internally calling faustdoctor to wrap the resulting C into separate header and implementation files. A crude proof of concept integration between faust generated code and a heavy DSP graph was done to explore the feasibility of this integration.
      Expected outcomes: The result will be:
      extending hvcc compiler steps pd2hv, hv2ir and ir2c
      jinja2 templates that create Heavy compatible C header and implementation files, based on Faust code
      successfully create DSP prototypes using PD and Faust that can be compiled to C/C++ projects based on Heavy
      Skills required/preferred: Python, C, Pure Data, audio and Faust programming.
      An easy, medium or hard difficulty rating of each project: medium
      Packaging system for Faust libraries [Taken in 2024]
      Mentors: Yann Orlarey and Stéphane Letz
      Expected size of project: 350 hours
      More detailed description of the project: The idea is to develop a packaging system to facilitate the integration of Faust libraries in a DSP project. The inspiration comes from the Julia language with the JuliaHub project and/or the Rust language with the Cargo package manager.
      Requirements
      load packages containing Faust sources, either in .dsp or in .lib format
      be able to load sets of files (typically a library that is written as several .lib files)
      isolate packages in different environments, to avoid name conflicts
      notion of a centralized directory on GitHub, where contributions can be made in the form of Pull Requests. Publishing tool (with search by content) of this directory, general, like fausthub (inspired for example by Juliahub https://juliahub.com/lp/).
      at each PR, test of the syntax of the code with GitHub actions
      cache management: typically 1) the package is loaded the 1st time and kept in a cache, 2) then the compiler uses the version in the cache. Work on the question of new version management.
      automatic generation of the documentation from the lib files (starting from the existing tools and possibly adapting them), automatic deployment
      preservation semantic: we want to be able to keep a project as a DSP file with all its needed libraries with specific version numbers
      Syntax proposal
      Simple version
      package("foo") ⇒ syntactic sugar for library("https://faustpackages.grame.fr, "path/to/actual/library.lib")
      Version with constraint on version number
      package("foo", "3.4") ⇒ syntactic sugar for library("https://faustpackages.grame.fr, "path/to/actual/3.4/library.lib")
      package("foo").bar
      or else:
      foo = package("foo") and foo.bar in the DSP code
      Tools to describe packages
      look at the package format of Rust or Julia: .toml file, src folders, tests
      look at the TOML format (https://toml.io/en/), used by Rust and Julia
      Expected outcomes:
      a working insfrastructure with a server hosting the published packages
      an extended Faust compiler able to access the server
      Skills required/preferred: C++ programming, server/client technology.
      An easy, medium or hard difficulty rating of each project: hard
      Faust programming by examples
      Mentors: Yann Orlarey and Stéphane Letz
      Expected size of project: 350 hours
      More detailed description of the project: The objective is to develop a new approach to Faust programming, not textual or graphical, but based on DAW-like examples. This programming principle is analogue to the one described in the article Real time Composition in Elody. This approach is based on the idea of manipulating and editing virtual "audio files" which represent the real time audio inputs and outputs.
      To take a simple monophonic example, let's call these two virtual audio files INPUT and OUTPUT. Let's note t:file the fact of placing in the DAW a file fileat time t in seconds and t:file*0.75 the fact of placing in the DAW a file at time t but also controlling its sound level. So the DAW construction {0:INPUT, 1:OUTPUT*0.75} corresponds to a realtime echo whose Faust translation is process = + ~ (@(ma.SR):*(0.75));.
      Expected outcomes: The project consists in exploring this model and see how standard DAW editing actions can be translated in Faust DSP programs. A prototype coded in TypeScript, JavaScript or any other scripting languages will be developed.
      Skills required/preferred: C++ programming, possibly TypeScript + JavaScript or other scripting languages.
      An easy, medium or hard difficulty rating of each project: hard
      Languages built on top of the signal API
      Mentors: Yann Orlarey and Stéphane Letz
      Expected size of project: 350 hours
      More detailed description of the project: The signal API opens an intermediate access inside the Faust compilation chain. Generating complex expressions by directly using it can quickly become really tricky and unpracticable. So a language created on top of the signal API is usually needed. This is exactly what the Block Diagram Algebra is all about, and the entire Faust language itself.
      But some other approaches can possibly be tested. The Elementary audio language for instance is built over a similar signal language and uses JavaScript as the upper layer language to help create complex signal graphs programmatically.
      Expected outcomes: The project consits in exploring various approaches to build a language on top of the signal API. It could be a textual one (like JavaScript, Haskell or scripting languages...) or a purely graphical tool.
      Skills required/preferred: C++ programming, possibly TypeScript + JavaScript, Haskell or other functional languages.
      An easy, medium or hard difficulty rating of each project: hard
      Developing modular synthesis using widget modulation
      Mentors: Yann Orlarey and Stéphane Letz
      Widget modulation acts on the widgets of an existing Faust expression, but without requiring any manual modifications of the expression's code. This operation is done directly by the compiler, according to a list of target widgets and associated modulators. Target widgets are specified by their label, as used in the graphical user interface. Modulators are Faust expressions that describe how to transform the signal produced by widgets.
      The project would be to develop a set of modular synthesizers, typically by choosing and adapting existing functions in the Faust Libraries, each of them with a pretty GUI, to be combined in a patch like model. The widget modulation syntax will be used to prepare the widgets to be modulable. The implementation will be done using web technologies, and in particular FaustWasm, a high-level API that wraps around Faust compiler. Here is a list of possible steps:
      choose and adapt existing functions in the Faust Libraries and add a pretty GUI with User Interface Primitives to create modules including oscillators (which generate sound), filters (which modify sound by frequency), amplifiers (which control the volume), and modulators (like LFOs and envelopes, which affect other parameters over time)
      create sequencing modules, vital for composition in modular synthesis. It allows users to create a series of notes (a sequence) that can be sent to an oscillator to produce rhythmic patterns or melodies
      define a library of modulation circuits, using the lowest/highest primitives of the language, and define adapted signal mappings
      create a global GUI to rack all used modules as in VCV Rack, using Web technologies, and develop the connection logic needed between all considered modules, compiled and connected as separated Faust Web Audio nodes
      Expected size of project: 350 hours
      Expected outcomes: The project aims in developing new libraries for modular synthesis and a prototype Web application.
      Skills required/preferred: Faust programming, Web programming
      An easy, medium or hard difficulty rating of each project: medium
      Past GSoC editions
      2024: FaustNet - DDSP, Faust in Cables.gl, Amati++, a VST/CLAP Plugin embedding the dynamic compiler and Faust Package Manager
      FaustNet - DDSP aimed to continue the work done on adding automatic differentiation in Faust (started in a GSOC 2023 project), to leverage machine learning for audio processing tasks directly within the familiar Faust environment. It was worked on by Advik Raj Basani and contributed as a Pull Request on Thomas Rushton faust-ddsp library.
      Faust in Cables.gl aimed to develop a Cables.gl plugin that compiles Faust DSP code into a WASM AudioWorklet in real-time. It was worked on by Fay Carsons and contributed as a separated Faust Cables plugin project.
      Amati++, a VST/CLAP Plugin embedding the dynamic compiler, inspired by the pMix and Amati projects, this plugin has been built using the JUCE framework for the interface and libfaust with LLVM and interpreter backend API to compile Faust code. It was worked on by Tyler Li and is still a work-in-progress.
      Faust Package Manager aimed to add a packaging system to facilitate the integration of Faust libraries in a DSP project. It was worked on by Shehab Khaled Roshdy and a was contributed as a Pull Request that is still in test in a master-dev-pacman branch.
      2023: Automatic Differentiation in the Faust Compiler and Better Faust on the Web
      Automatic Differentiation in the Faust Compiler aimed at adding Automatic differentiation directly in the compiler, so that gradient calculation can be carried out natively in Faust, with applications in Machine Learning algorithms. The project was worked by Thomas Rushton and completed with this Pull Request, and finally integrated in the Faust master-branch.
      Better Faust on the Web aimed at enhancing Faust’s support for the web platform, and was worked on by Ian Clester. Transitioning the Faust web tools to a rewritten TypeScript version has been completed and deployed in updated versions of the Faust editor and Faust playground and soon in the Faust Web IDE with this Pull Request. A Faust web component embedding the libfaust JS/WebAssembly compiler has been developed and will be used soon in the Faust documentation. The development is fully detailed in this blog post.
      2022: Integration in HISE
      Faust Integration in HISE aimed at integrating support for the Faust audio programming language into HISE, an extensive framework for the creation of sample-based virtual musical instruments. The project has been completed by Roman Sommer with the help of Christoph Hart as mentor, and announced here.
      Faust ideas
      This repository hosts the "TODO/ideas list" for the Faust programming language.
      Conventions
      Items are placed at the bottom of the file and separated by ---.
      Items can have a person associated to them by declaring * Currently addressed by: xxx. If no-one is currently working on the item, replace xxx by nil.
      Items are ordered by priority and are also listed in the List section below.
      Items can be commented by adding subsections, pictures, etc.
      List
      Implement Jonathan Abel's Modal Reverb
      Improved UI Declarations
      Improved Linear Algebra Support
      Finish the DX7 Implementation
      Trigonometric simplifications
      WebAssembly specific optimisations
      Improve faust2audiokit
      Improve faust2vcvrack
      Testing tools on the Web
      Progressive Web applications for iOS and Android
      A tool to generate Faust web components as NPM packages
      PFFT like wrapper for Faust DSP code
      Hot reloadable soundfiles
      WebGPU audio architecture
      Invertible functions
      faust2nih tool
      Implement Jonathan Abel's Modal Reverb
      Currently addressed by: Romain and Yann
      This should be done as part of the Longyou grottoes project. The "final goal" would be to create an interactive website where users can process the sound of their microphone to apply the acoustics of this ancient space. Modal reverb would allow to interpolate between IRs and change some of the parameters of the space in real-time. It'd be nice if this could be reproducible so we need to think about a way to nicely generate these reverbs from an impulse response. This tool could be similar to mesh2faust or could come as part of a toolkit in matlab/octave/pyhton, etc.
      Improved UI Declarations
      Currently addressed by: Romain and Yann
      Essentially allow for specific UI elements to have metadatas associated to them outside of their declaration. As part of that, we want to implement a system to further customize UI elements.
      Potential Implementation
      Several approaches are being considered to further customize UI elements. The first one would consist of being able to declare a "CSS" allowing for the use of CSS code. Another approach (more generic and not limited to the web) would allow for the declaration of UI-specific metadata inspired by CSS.
      declare UI "
        synth{
          background-color: blue;
        }
        synth/freq{
          tooltip: Frequency parameter of the synth;
          width: 70%;
        }
        synth/gain{
          style: knob;
          tooltip: Gain parameter of the synth;
          width: 70%;
        }
      ";
      
      f = hslider("freq",400,50,1000,0.1);
      g = hslider("gain",0.5,0,1,0.01);
      process = hgroup("synth",os.sawtooth(f)*g);
      Of course, it would still be possible to declare metadatas within the UI declaration (this system would be fully backward compatible). Internally, we'd have to parse the metadata and create a corpus of supported CSS metadatas knowing that interfaces would be based on a specific kind of layout (e.g., grid layout). Once again, another option would be to allow to specify "pure CSS" giving access to all the CSS features without having to do some reformatting.
      Improved Linear Algebra Support
      Currently addressed by: nil
      Linear algebra operations are currently poorly supported in Faust. Having a way to conveniently express matrices would improvement. As part of that, linear algebra/matrix operations (e.g., inversion, multiplication, determinant, etc.) primitives could be added to the language.
      Potential Implementation
      Matrices could be expressed using the Faust-multirate vectorize primitives by creating vectors of vectors.
      It would be interesting to try to implement matrix operations from scratch in Faust. Although it might be hard and not so optimized, thus a more pragmatic solution would be to implement them as primitives. That would be a fair amount of work as this would imply that the corresponding code for each language supported by Faust would have to be supported.
      Finish the DX7 Implementation
      Currently addressed by: nil
      Essentially, finish dx7.lib. It might be worth looking at these elements to make this happen:
      https://webaudiomodules.org/demos/wasm/dx7.html
      https://github.com/everythingwillbetakenaway/DX7-Supercollider
      Trigonometric simplifications
      Currently addressed by: nil (suggested by Pierre Lecomte)
      For some applications, trigonometric functions (spherical harmonics) are used, and depending on the algorithm, the output formula could be very complicated. However, in a lot of cases, trigonometric identities could help to drastically simplify the expressions.
      WebAssembly specific optimisations
      Currently addressed by: Stéphane and Yann
      To run as fast as possible and approch native code performances as much as possible, WebAssembly code requires some specific optimisations, like: memory access (index precomputation as much as possible...), delay lines handling, struct/stack variables access...etc. We have started an informal collaboration with Mozilla engineers (Benjamin Bouvier) to work on this subject.
      Improve faust2audiokit
      Currently addressed by: nil
      The faust2audiokit tool transforms a Faust DSP program into a fully working AudioKit node. The result can be a monophonic DSP or a MIDI controllable polyphonic one (when the DSP describes an instrument, following the freq, gain, gate parameter naming convention).
      The project consists in improving and finishing the tool.
      Improve faust2vcvrack
      Currently addressed by: nil
      The faust2vcvrack The faust2vcvrack tool compiles a Faust DSP program in a folder containing the VCV Rack plugin C++ source code and a Makefile to compile it. By default the resulting C++ code is compiled and installed in the VCV Rack application:
      The project consists in improving the tool, particulary the automatically created graphical user interface which is ugly for now.
      Testing tools on the Web
      Currently addressed by: nil
      Faust distribution already contains some testing tools, like faust2plot or faust2octave.etc. It would be great to have them running in a Web page (or some extension of the same idea). For signal generators/processors, several output formats (oscilloscope, spectrogramme...), and for processors several calibrated input signals (dirac impulse, ramp, sinusoide..) would be available.
      Progressive Web applications for iOS and Android
      Faust code can easily be distributed as self-contained Web pages containing the Faust DSP code as a statically compiled Web Audio node. The project is to improve the current model to deploy the pages as Progressive Web applications. The faustwasm package will be improved to allow this new kind of deployment model. The use of movement sensors will be added in the architecture to keep the same capability currently found in the native applications. Deployment on iOS and Android machines will be tested.
      Done, see faustpwa.
      A tool to generate Faust web components as NPM packages
      Faust code can easily be distributed as self-contained Web pages containing the Faust DSP code as a statically compiled Web Audio node. The project is to improve the current model to deploy the pages as ready-to-use NPM packages. The faustwasm package will be improved to allow this new kind of deployment model. A faust2webnpm tool to compile a Faust DSP program will be developed, with polyphonic and polyphonic with global effect support.
      PFFT like wrapper for Faust DSP code
      The Max/MSP pfft~ object is designed to simplify spectral audio processing using the Fast Fourier Transform (FFT). In addition to performing the FFT and the Inverse Fast Fourier Transform (IFFT), pfft~ (with the help of its companion fftin~ and fftout~ objects) manages the necessary signal windowing, overlapping and adding needed to create a real-time Short Term Fourier Transform (STFT) analysis/resynthesis system.
      This model has been tested and implemented by Shihong Ren for Faust and can be tested on a customized version of the Faust IDE. The FFT input part process the temporal signal, delivers a tripplet of signals (real, imaginary, and current bin index), uses regular Faust DSP code working on this tripplet of signals, and finally do the iFFT process to produce temporal signals.
      Here is a noise reduction algorithm using this model written by Shihong.
      It is actually a simplified version of the commonly used spectral denoise (10.1109/TASSP.1979.1163209). When the user hits the button, the algorithm learns the current spectrum as a reference of the background noise. Then, subtract from every input spectrum, the power of this background noise spectrum (for each FFT bin).
      The Faust FFT DSP has 3 inputs: real part/imaginary part/current bin (as in pfft~ in Max). Each input gets sequentially a complex number as information about each FFT bin. The first part of the code gets the current FFT setup and defines necessary functions for calculating FFT info:
      import("stdfaust.lib");
      
      fftSize = hslider("fftSize", 1024, 2, 16384, 1);       // global variable set by the processor itself
      fftHopSize = hslider("fftHopSize", 1024, 2, 16384, 1); // global variable set by the processor itself
      bufferSize = fftSize / 2 + 1; // Bins from 0Hz to Nyquist freq
      freqPerBin = ma.SR / fftSize;
      binToFreq = *(freqPerBin);
      freqToBin = /(freqPerBin);
      
      cartopol(x, y) = x * x + y * y : sqrt, atan2(y, x);  // cartesian to polar
      poltocar(r, theta) = r * cos(theta), r * sin(theta); // polar to cartesian
      then UI components:
      freezeBtn = checkbox("Capture");
      reduceSld = hslider("Reduce", 0, 0, 2, 0.01);
      Here is a function to freeze the last spectrum, when the checkbox is on, instead of bypassing the input, it puts the last received full spectrum buffer into a feedback loop:
      freeze(rIn, iIn, bin) = out with { // 3 inputs for each audio channel: real, imaginary, current bin
          freezeSignal(sig, frz) = orig + freezed with {
              orig = sig * (1 - frz);
              freezed = orig : @(bufferSize) : + ~ (*(frz) : @(bufferSize - 1)) * frz;
          };
          out = freezeSignal(rIn, freezeBtn), freezeSignal(iIn, freezeBtn);
      };
      Finally the main processor, getting the current magnitude value and subtract the freezed spectrum's corresponding magnitude, then output the resulting spectrum for IFFT.
      fftproc(rIn, iIn, bin) = out, out with { // 3 inputs for each audio channel: real, imaginary, current bin
          pol = cartopol(rIn, iIn);
          mag = pol : _, !;
          phase = pol : !, _;
          pol_freezed = freeze(rIn, iIn, bin) : cartopol;
          mag_freezed = pol_freezed : _, !;
          phase_freezed = pol_freezed : !, _;
      
          out = poltocar(mag * (1 - freezeBtn) + (mag - mag_freezed * reduceSld) * freezeBtn : max(0), phase);
      };
      process = fftproc;
      The goal of the project is to use the same model for Faust code by writing a C++ wrapper that would add FFT and iFFT processing around the Faust DSP code. This can possibly be done by extending the ffunction primitive to a mode general version that would deliver a list of output values (instead of a single one), or if not possible, develop a dsp wrapper architecture file that would add the FFT/iFFT process around the Faust DSP code.
      Hot reloadable soundfiles
      The soundfile primitive currently provides access to a predefined list of external sound resources. These soundfiles are loaded once during the application's initialization and cannot be modified dynamically during runtime.
      The primary objective of the project is to enable hot reloadability for soundfiles, allowing users to change them on the fly while the DSP code is actively running. To achieve this, two key aspects need enhancement:
      code generation improvement: the code generation process should be refined to facilitate an atomic switch to the new soundfile while the DSP code is in execution. This ensures a seamless transition between different sound resources without interrupting the ongoing processing.
      soundfile loader architecture enhancement: the architecture of the soundfile loader, detailed in SoundUI.h, needs to be upgraded. This upgrade should introduce the capability for users to interactively change the loaded soundfile, potentially through a graphical user interface (GUI) element.
      For instance, integrating a GUI item within the application can empower users to select and switch soundfiles effortlessly during runtime.
      Additionally, a possible solution involves implementing a purely memory-based loader. This loader would emulate soundfiles as audio buffers in memory, allowing for dynamic changes to the loaded soundfiles without requiring a complete reload of resources. This approach enhances flexibility and responsiveness by enabling real-time alterations to the sound resource being processed.
      By addressing these aspects, the project aims to elevate the functionality of the soundfile primitive, providing users with the ability to seamlessly modify soundfiles while the DSP application is actively running.
      WebGPU audio architecture
      The WebGPU audio architecture represents an innovative model to use the WebGL language to compute and render audio on the Web platform: audio Synthesis uses rough streaming architecture to get chunks out of WebGPU and send control buffers to control a WebGPU compute shader.
      The primary objective of the project is to develop a WebGSL backend for Faust, and an customized architecture file to render the computed audio using the Web Audio API, as demonstrated in the current demonstration. To validate the efficacy of this model, benchmarks are planned. These will assess the performance of the WebGPU audio architecture, comparing it against the existing standards of AudioWorklet and WebAssembly solutions.
      Invertible functions
      Currently addressed by: nil
      There could be a new primitive to automatically compute the inverse of a function. If the function can't be inverted at compile-time, then an error should be raised. Having access to the inverse would be useful when a user writes a custom scale function and wants to know its inverse. For example, the user might have an hslider whose visible range is [0-1], but the effective value is scaled:
      scale = pow(_,5)*32*1000; // take [0-1] (unitless) and remap into [0-32000] milliseconds
      scaleInverse = inverse(scale);
      h = hslider("attack", scaleInverse(50), 0, 1, .01);
      process = h : scale;
      In the code above, we achieve three things:
      The attack parameter is "normalized" between 0 and 1, which is useful for modular synthesis.
      We have a custom scale function that remaps from [0-1] to a meaningful milliseconds unit.
      We set 50 milliseconds as the default attack.
      Note that scaleInverse will effectively be scaleInverse = _/(32*1000) : pow(_,1./5); However, some functions are not invertible, or require assumptions. For example, the inverse of pow(_,2) is plus or minus sqrt(_).
      Other use cases could involve automatically inverting custom scales that use ba.midikey2hz.
      In a more advanced example, it might be possible to invert a function that takes multiple arguments, while only inverting over the last argument.
      Example:
      func(a, b, c, x) = a+2*b+3*c+x;
      funcInverse = inverse(func);
      // funcInverse(a, b, c, y) now solves for x in y=func(a, b, c, x)
      process = _ : funcInverse(1, 1, 1) : _;
      This would be useful for numerical integration methods (see en.adsr_bias).
      faust2nihplug tool
      NIH-plug is an API-agnostic audio plugin framework written in Rust. The primary objective of the project is to develop a faust2nihplug tool to convert a Faust DSP program in a ready-to-compile NIH-plug project. Those lowpass-lr4-faust-nih-plug and lamb-rs projects can be used as starting points. Monophonic DSP and MIDI controllable polyphonic instruments should be supported.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/grame/
    idea_list_url: https://github.com/grame-cncm/faustideas

  - organization_id: 53
    organization_name: GeomScale
    no_of_ideas:
    ideas_content: |
      ⚠️ NOTE
      This year contributors will have to choose between a ~90 hours small-sized project, ~175 hours medium-sized project or ~350 hours large project. For more information please read the official gsoc website as well as GeomScale's introductory wiki for GSoC 2025.
      GeomScale hosts a few projects in different github repositories. The most mature one is volesti written in C++. Then there are two repositories that act as interfaces of volesti (i) Rvolesti in R that also contains utilities for financial applications and (ii) and dingo written in Python (uses C++ functions of volesti via Cython) and contains utilities for biological applications. Finally, there is PorQua a Python package for index replication in finance.
      Proposed projects are related to those repositories. There are two types of coding projects: research and development (marked as R&D in the table below) and pure development (marked as Dev in the table below). R&D projects needs a deep understanding of the mathematical background in addition to the implementation details that are needed by the Dev projects. Typically the former is more demanding than the later but this also depends on the background of the contributor.
      Mentors, please edit this wiki page, and add your ideas to the table below.
      Contributors, please look for a project that interests you in the table below. Before emailing project mentors, please do at least one project test and post a link to your solution on the proposal's wiki page.
      Proposal Type Languages Size Hours
      Randomized SDP solver R&D C++/R Large 350
      Non-convex sampling in dingo R&D C++ /Python Large 350
      Exclude Lpsolve from R and C++ interfaces of volesti Dev C++/R Medium 175
      Counting linear extensions with volume computation and applications in AI R&D C++ Large 350
      Expose sampling and volume on spectrahedra to R interface of volesti Dev R/Rcpp Medium 175
      Expose autodiff to R interface of volesti Dev R/Rcpp Medium 175
      Enhancing Rvolesti: Integration of Advanced Rounding Routines Dev R/Rcpp Small 90
      Supporting Sparse Matrix Representation for H‐Polytopes in Rvolesti Dev R/Rcpp Small 90
      Developing a Comprehensive Unit Test Framework for PorQua Dev Python Small 90
      General Sampling and Volume Computation in Dingo Dev Python Medium 175
      Interactive Web API for PorQua Dev Python Medium 175
      PorQua – A Framework for Constructing and Backtesting Investment Strategies Dev Python Large 350
      Shake and Bake ‐ Sampling from the boundary of convex polytopes R&D C++ Large 350
      All contributor applications will be discussed by the GeomScale mentor community, and proposals will be ranked considering factors such as quality, contributor's ability to successfully finish the project, and impact for the GeomScale project. A finite number of slots will be granted to GeomScale by Google, thus, only the best proposals will get chosen. This implies that it is possible that some ideas will not become GSoC projects even if they are supported by a good contributor application.
      Contributors, if you are interested in a coding project related to GeomScale that is not listed above, please try to find mentors by posting a description of your project idea on the gitter. If you find mentors, feel free to add your project idea to this wiki and write an application.
      Information Candidates Should Supply
      The application process has several steps. Before contacting anybody verifies that you are eligible. The next step is to contact the mentor of the project you are interested in. You have to convince them that you are the right person to get the job done. The next step is to work out more details and to contact the mentors or the GeomScale org by providing the following information by email or by gitter.
      Project:
      Select a project in the list and provide your personal and detailed description. If you wish to work on another idea of your own, we are pretty open as long as this serves the goal of consolidating GeomScale as a whole.
      Provide a proposal of a technical solution with your envisioned methodology. The more detailed the better.
      Explain how the solution will be available to the user, in which form. Do not forget the documentation, unitary tests, and cross-platform aspects.
      Provide a realistic schedule with objectives (one every two weeks for example) and deadlines. Focus on mid-term objectives as well as on the final evaluation.
      Personal data:
      First name, last name, affiliation, and geographical location.
      A brief list of the main studies and programming courses attended, with ranking.
      List of the most important software projects contributed and success.
      Which are your best skills in terms of programming and scientific computing?
      In general what is your taste in terms of programming? language, methodology, teamwork, etc.
      Is there anything that prevents you from working full time on the project during the program period?
      How do you see your involvement after the program ends? Do you see yourself pushing the project further, or do you see yourself contributing to other GeomScale projects?
      Are you more interested in the theory/scientific aspect of GeomScale, or do you feel more like a hacker?
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/geomscale/
    idea_list_url: https://github.com/GeomScale/gsoc25/wiki/table-of-proposed-coding-projects

  - organization_id: 54
    organization_name: Git
    no_of_ideas:
    ideas_content: |
      Home
      About Git Rev News
      Git Rev News Sources
      Git Rev News
      Git Rev News Archive
      SoC 2025 Applicant Microprojects
      SoC 2025 Ideas
      SoC 2022 Organization Application
      Mentoring Program Guide
      Historical Summer of Code and Outreachy Materials
      Hacking Git
      General Microproject Information
      General Application Information
      GSoC participants
      This is the idea page for Summer of Code 2025 for Git.
      Please completely read the general application information page before reading the idea list below.
      Summer of code main project ideas
      Students: Please consider these ideas as starting points for generating proposals. We are also more than happy to receive proposals for other ideas related to Git. Make sure you have read the “Note about refactoring projects versus projects that implement new features” in the general application information page though.
      Note about limit of project selection
      Kindly note that considering the bandwidth of available mentors, the Git project would only mentor up to 3 contributors this year.
      This is not a hard and fast rule. It may change if more community members are willing to mentor in the coming days. For instance, this may happen when a new project is proposed and some community member volunteers to mentor the same.
      Consolidate ref-related functionality into git-refs
      This project aims to streamline Git’s reference management into the existing git-refs command by consolidating functionality currently spread across multiple commands. The new command will provide subcommands for listing, getting, checking existence, writing, and optimizing references, replacing the functionality currently handled by git-update-ref(1), git-for-each-ref(1), git-show-ref(1), and git-pack-refs(1).
      The consolidation work should ensure backward compatibility with existing commands. The work involves C programming in Git’s codebase, creating comprehensive tests, and updating documentation.
      Required skills include C programming, familiarity with Git’s codebase, and experience with command-line tool development. The project is expected to take 12 weeks, with existing commands being maintained for backward compatibility while development focuses on the new unified interface.
      Getting started: Build Git from source, study the existing ref-related commands, and submit a micro-patch to demonstrate familiarity with the codebase.
      Expected Project Size: 175 hours or 350 hours
      Difficulty: Medium
      Languages: C, shell(bash)
      Possible mentors:
      Patrick Steinhardt < ps@pks.im >
      Jialuo She < shejialuo@gmail.com >
      Christian Couder < christian.couder@gmail.com >
      Ghanshyam Thakkar < shyamthakkar001@gmail.com >
      Refactoring in order to reduce Git’s global state
      This project focuses on modernizing Git’s environment handling by refactoring the environment.c code to reduce global state. The goal is to move environment variables and configuration from global scope into more appropriate local contexts, primarily into the struct repository / struct repository_settings structure. This architectural improvement will make the codebase more maintainable and potentially enable better multi-repository handling in the future. The project involves careful refactoring of Git’s core environment handling code, requiring strong C programming skills and attention to detail.
      The student will identify global variables that can be moved to local scope, implement the necessary structural changes, and ensure all affected code paths continue to work correctly. This includes updating tests, fixing any regressions, and documenting the architectural changes.
      Expected Project Size: 90 or 175 hours or 350 hours
      Difficulty: Medium
      Languages: C, shell(bash)
      Possible mentors:
      Patrick Steinhardt < ps@pks.im >
      Karthik Nayak < karthik.188@gmail.com >
      Jialuo She < shejialuo@gmail.com >
      Christian Couder < christian.couder@gmail.com >
      Ghanshyam Thakkar < shyamthakkar001@gmail.com >
      Machine-Readable Repository Information Query Tool
      This project aims to create a new Git command dedicated to querying repository metadata and configuration in a structured, machine-readable format. Currently, much of this functionality exists within git-rev-parse(1), which has evolved beyond its original purpose. The new command will provide a cleaner, more focused interface for programmatically accessing repository information using JSON output.
      The student will design and implement this new command, focusing on identifying what repository information should be exposed, designing a consistent JSON schema, and implementing the necessary interfaces to Git’s internal APIs. Key challenges include determining which subset of information from git-rev-parse to expose via this new command, ensuring backward compatibility, and creating a clean, well-documented command interface that’s useful for scripts and tools.
      While this is an exploratory project that hasn’t been extensively discussed in the Git community, it addresses a real need for better programmatic access to repository information.
      Expected Project Size: 175 hours or 350 hours
      Difficulty: Medium
      Languages: C, shell(bash)
      Possible mentors:
      Patrick Steinhardt < ps@pks.im >
      Karthik Nayak < karthik.188@gmail.com >
      Ghanshyam Thakkar < shyamthakkar001@gmail.com >
      Implement support for reftables in “dumb” HTTP transport
      Fetching Git repositories uses one of two major protocols:
      The “dumb” protocol works without requiring any kind of interactive negotiation like a CGI module. It can thus be served by a static web server.
      The “smart” protocol works by having the client and server exchange multiple messages with each other. It is more efficient, but requires support for Git in the server.
      While almost all servers nowadays use the “smart” protocol, there are still some that use the “dumb” protocol.
      The “dumb” protocol cannot serve repositories which use the “reftable” backend though. While there exists a “info/refs” file that is supposed to be backend-agnostic, this file does not contain information about the default branch. Instead, clients are expected to download the “HEAD” file and derive the default branch like that. This file is a mere stub in the “reftable” backend though, which breaks this protocol.
      The goal of this project is to implement “reftable” support for “dumb” fetches.
      See:
      https://git-scm.com/docs/reftable
      Note: While both ideas are valuable, we prioritize the ‘Consolidate ref-related functionality into git-refs’ proposal over support for reftables in “dumb” HTTP transport. If we receive applications for both projects, preference will be given to applications focusing on the git-refs consolidation work.
      Expected Project Size: 175 hours or 350 hours
      Difficulty: Medium
      Languages: C, shell(bash)
      Possible mentors:
      Patrick Steinhardt < ps@pks.im >
      Karthik Nayak < karthik.188@gmail.com >
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/git/
    idea_list_url: https://git.github.io/SoC-2025-Ideas/

  - organization_id: 55
    organization_name: GitLab
    no_of_ideas:
    ideas_content: |
      Open
      13
      Closed
      0
      All
      13
      New issue
      Actions
      Toggle history
      Created date
      Issue
      [Workspaces] Allow users to use Workspaces without having to build a custom image 1 of 6 checklist items completed
      #14 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      1
      updated 3 days ago
      Issue
      [Workspaces] Inject JetBrains Editors into a workspace 1 of 6 checklist items completed
      #13 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      3
      updated 5 days ago
      Issue
      [Web IDE] Add additional source control operations to the Web IDE 0 of 6 checklist items completed
      #12 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      1
      updated 1 week ago
      Issue
      [Vulnerability Management] Expand Vulnerability GraphQL Offering 1 of 6 checklist items completed
      #11 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      2
      updated 4 days ago
      Issue
      [Release Orchestration] Resource Groups 1 of 6 checklist items completed
      #10 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      2
      updated 1 week ago
      Issue
      [Portfolio Management] Epics can have Assignees 1 of 6 checklist items completed
      #9 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 2 days ago
      Issue
      [Package Registry] Simplify the packages list by consolidating versions of the package into the detail page 1 of 6 checklist items completed
      #8 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 1 week ago
      Issue
      [Navigation] Personalized Home Page 1 of 6 checklist items completed
      #7 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 23 hours ago
      Issue
      [Issue Tracking] Team Velocity and volatility 1 of 6 checklist items completed
      #6 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 1 week ago
      Issue
      [Infrastructure as Code] Protected Terraform States 1 of 6 checklist items completed
      #5 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 3 days ago
      Issue
      [Design System] Use improved hide heuristics when using GlDisclosureDropdown and GlCollapsibleListbox 1 of 6 checklist items completed
      #3 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 2 days ago
      Issue
      [Design System] Remove any CSS classes that are unused 1 of 6 checklist items completed
      #2 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      updated 2 days ago
      Issue
      [Deployment Management] Add Notification for expiring Deploy Tokens: E-mail and Webhook 1 of 6 checklist items completed
      #1 · created 4 weeks ago by Nick Veenhof
      GSoC
      Needs manager approval
      1
      updated 2 days ago
      Show 20 items
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gitlab/
    idea_list_url: https://gitlab.com/gitlab-org/developer-relations/contributor-success/google-summer-of-code-2025/-/issues


  - organization_id: 56
    organization_name: Google DeepMind
    no_of_ideas:
    ideas_content: |
      Instantly share code, notes, and snippets.
      dynamicwebpaige/gdm-gsoc-projects-2025.md Secret
      Last active 2 hours agoMarch 14, 2025 11:58
      Show Gist options
      Star
      134
      ()
      You must be signed in to star a gist
      Fork
      38
      ()
      You must be signed in to fork a gist
      Save dynamicwebpaige/92f7739ad69d2863ac7e2032fe52fbad to your computer and use it in GitHub Desktop.
      Code
      Revisions
      15
      Stars
      134
      Forks
      38
      Embed
      Clone this repository at &lt;script src=&quot;https://gist.github.com/dynamicwebpaige/92f7739ad69d2863ac7e2032fe52fbad.js&quot;&gt;&lt;/script&gt;
      Save dynamicwebpaige/92f7739ad69d2863ac7e2032fe52fbad to your computer and use it in GitHub Desktop.
      Download ZIP
      Google Summer of Code: 2025 Google DeepMind Project List
      Raw
      gdm-gsoc-projects-2025.md
      Shovel-Ready AI Developer Projects
      ☀️ Google Summer of Code
      Author: Google DeepMind GSoC Team
      Created: Aug 30, 2024
      Self Link: goo.gle/deepmind-gsoc-projects-2025
      TL;DR: This document outlines concise, open-source engineering projects to enhance the functionality and developer experience of AI Developer products (Gemini APIs, AI Studio, Colab, Gemma). Projects focus on addressing user pain points, unlocking new capabilities, and increasing developer adoption for Google DeepMind's tools. These are ideal for Google Summer of Code (GSoC) contributors! If you don't see a project on the list that you feel should be included, feel free to propose a new idea.
      Project List
      1. Develop a Gemini Workspace in Postman 📭
      Objective: Create a Postman Workspace for interacting with Google's Gemini APIs, providing a central hub for exploration, integration, and troubleshooting. This should streamline the process for developers to get started with Gemini and reduce the initial learning curve.
      Key Features:
      Pre-built Collections: Example API requests for various Gemini features (text generation, chat, image generation, code generation). These collections should cover all major API endpoints and include variations for different parameters (e.g., temperature, top_p, top_k). Each request should be well-documented with comments explaining its purpose and expected behavior. 🚀
      Environments: Pre-configured environments with API keys, authentication tokens, and project IDs. Include separate environments for testing and production, with clear instructions on how to obtain and configure the necessary credentials. ⚙️
      Documentation and Tutorials: Integrated documentation and guides for API endpoints, parameters, and use cases. This should be linked directly within the Postman Workspace, potentially using Postman's built-in documentation features. Tutorials should cover common tasks and scenarios, such as setting up a basic chatbot or generating images from text prompts. 📖
      Testing and Mocking: Example test scripts and mock servers for validating API responses and local development. Test scripts should cover success and error cases, checking for expected response formats and values. Mock servers (using Postman's mocking capabilities) allow developers to test their code without making actual API calls, saving on costs and avoiding rate limits. 🧪
      Note: Long-term maintenance via a GitHub Action is desirable. This action would automatically update the Postman Workspace with the latest Gemini API changes and documentation, ensuring it remains accurate and up-to-date. 🤖
      Complexity: Medium. Requires familiarity with Postman, REST APIs, and potentially GitHub Actions for automation. The project involves organizing existing information and creating helpful examples, rather than developing complex new features.
      Expected Size: 175-350 hours.
      Skills: REST API interaction, Postman, JSON, (optional) JavaScript for GitHub Actions.
      2. Improve Evals Documentation for the Gemini APIs 📝
      Objective: Expand and improve promptfoo, wandb, and other evals platforms' documentation for Gemini APIs, achieving parity with other open-source model providers' documentation. This will make it easier for researchers and developers to evaluate the performance of Gemini models and compare them to alternatives.
      Key Improvements:
      Model Format Documentation: Detailed explanations for each supported Gemini model (e.g., google:gemini-2.0-flash, google:gemini-2.0-flash-lite, etc.). This should include information on model capabilities, limitations, and intended use cases. Specify input/output formats for each model, including any special tokens or formatting requirements. 🤖
      Configuration Options: Documentation for all configuration options (e.g., safetySettings, stopSequences, temperature). Explain the purpose of each parameter and provide guidance on how to choose appropriate values. Include examples of how different parameter settings affect the model's output. ⚙️
      Environment Variables: Guidance on using environment variables (e.g., GOOGLE_API_KEY). Clearly explain how to set these variables in different environments (e.g., local development, cloud deployment) and emphasize the importance of keeping API keys secure. 🔑
      Advanced Features: Document advanced features like image and video handling, tools use/function calling, and error handling/rate limiting. Provide code examples and best practices for using these features effectively. Explain how to handle different error codes and how to implement retry mechanisms to mitigate rate limiting. ✨
      Code Examples: Comprehensive code examples for various use cases. These should be clear, concise, and well-documented. Include examples for different programming languages (e.g., Python, JavaScript) and different evaluation frameworks. Show how to integrate Gemini models into existing evaluation pipelines. 💻
      Complexity: Medium. This project primarily involves writing documentation and creating code examples. It requires a good understanding of the Gemini APIs and evaluation frameworks.
      Expected Size: 175-350 hours.
      Skills: Technical writing, Python, JavaScript, understanding of LLM evaluation methodologies.
      3. Enhance Gemini API Integrations in OSS Agents Tools 🤖🛠️
      Objective: Expand and improve Gemini API integration in agent/workflow tools (e.g., Composio, CrewAI, LangChain, LlamaIndex, etc.) and improve related documentation. Include code examples, make improvements to those libraries, etc. This will enable developers to seamlessly build AI agents and workflows that leverage the capabilities of Gemini models.
      Key Tasks:
      Identify Gaps: Analyze the existing integrations in each target tool and identify areas where Gemini support is lacking or could be improved.
      Implement Missing Features: Add support for missing Gemini features, such as multimodal inputs, function calling, and specific model configurations.
      Improve Existing Features: Optimize existing integrations for performance and reliability. Address any known bugs or limitations.
      Documentation Updates: Update the documentation for each tool to clearly explain how to use Gemini models. Include code examples and best practices.
      Community Engagement: Interact with the maintainers and users of the target tools to gather feedback and ensure the integrations meet their needs.
      Code Examples: Create multiple, distinct use-case examples of agent/workflow tools, making use of Gemini.
      Complexity: Medium to High. Requires familiarity with the Gemini APIs and the target agent/workflow tools. The complexity will depend on the specific gaps and improvements identified.
      Expected Size: 175-350 hours.
      Skills: Python, understanding of AI agents and workflows, experience with libraries like LangChain, LlamaIndex, etc.
      4. Batch Prediction with Long Context and Context Caching Code Sample 🚀🧠
      Objective: Develop a code sample demonstrating batch prediction with Gemini APIs, leveraging long context and context caching for efficiently answering questions about a single video. This addresses a common use case of extracting information from large content sources.
      Scenario: Extracting information from a video lecture/documentary by asking multiple, potentially interconnected, questions.
      Code Sample Features:
      Batch Prediction: Design and optimization for submitting a batch of questions. This should minimize API calls and improve efficiency. Consider using techniques like dividing the questions into smaller batches to avoid exceeding API limits. 📦
      Long Context Handling: Demonstrate use of Gemini's long context capabilities. Show how to provide the entire video transcript (or relevant segments) as context. Consider strategies for handling transcripts that exceed the maximum context length. 📏
      Context Caching: Implement context caching to store and reuse previous interactions. This can significantly reduce the amount of data sent to the API and improve response times, especially for interconnected questions. Use a suitable caching mechanism (e.g., in-memory cache, persistent storage). 💾
      Interconnected Questions: Handle questions that build upon previous answers. The code should maintain the conversation history and use it to provide more accurate and relevant responses. 🔗
      Output Formatting: Clear and user-friendly output. Present the answers in a structured format, possibly with links to the relevant timestamps in the video. ✨
      Code Documentation: Detailed comments, setup instructions, and usage guidelines. Explain the different components of the code and how they work together. Include instructions on how to obtain and configure an API key. Provide example questions and expected outputs. 📖
      Error Handling: Implement robust error handling to gracefully handle API errors, network issues, and invalid inputs.
      Complexity: Medium. Requires understanding of API interaction, data structures, and potentially asynchronous programming for batch processing.
      Expected Size: 175 hours.
      Skills: Python, API interaction, asynchronous programming, data structures.
      5. Enhance Gemini Support in Open-Source Extensions (Continue.dev/Aider-like) 💻✨
      Objective: Improve Gemini API integration within open-source coding extensions, similar to Continue.dev or Aider, addressing bugs, adding features (long context, context caching), and enhancing the user experience. This aims to provide developers with a seamless and powerful coding experience powered by Gemini.
      Key Focus Areas:
      API Key Authorization: Bug fixes, secure key management, and error handling. Ensure that API keys are stored securely and that the extension handles authentication failures gracefully. Provide clear error messages to the user. 🔑
      Long Context Support: Context window expansion and segmentation. Allow the extension to handle large codebases by dividing them into manageable chunks and sending them to the Gemini API. Implement strategies for maintaining context across multiple chunks. ↔️
      Context Caching: Caching mechanism and retrieval. Cache previous interactions with the Gemini API to improve performance and reduce costs. Implement a strategy for invalidating the cache when the code changes. 💾
      User Interface Enhancements: Model selection, parameter customization, and output formatting. Allow users to easily switch between different Gemini models and adjust parameters like temperature and top_p. Provide clear and concise output that is integrated into the coding environment. 🖥️
      Documentation & Examples: Gemini integration guide and code examples. Provide clear instructions on how to configure and use the Gemini integration. Include examples of common tasks, such as code completion, refactoring, and bug detection. 📖
      Code Summarization/Explanation: Add features to summarize or explain blocks of code using Gemini.
      Complexity: Medium to High. Requires understanding of IDE extensions, API integration, and potentially UI development.
      Expected Size: 175-350 hours.
      Skills: TypeScript/JavaScript, IDE extension development, API integration, UI/UX design.
      6. Open-source Gemini Example Apps
      Objective: Upgrade existing tutorials and content to support the new unified Gemini SDKs for JavaScript/TypeScript and Python. This could include migrating examples in the Gemini Cookbook from Python to JS/TS, building new end-to-end tutorials and examples, or upgrading examples for other open-source libraries that use dated versions of the Gemini APIs. This project increases adoption by providing up-to-date and diverse learning resources.
      Specific Tasks:
      Cookbook Migration: Migrate existing Python examples in the Gemini Cookbook to JavaScript/TypeScript. Ensure the code is idiomatic and well-documented.
      New Tutorials: Develop new end-to-end tutorials demonstrating various Gemini use cases, such as building a chatbot, creating a text summarization tool, or generating images from text prompts.
      Library Updates: Identify open-source libraries that use outdated versions of the Gemini APIs and update their examples to use the latest SDKs.
      Documentation: Ensure all examples are well-documented, with clear explanations of the code and the underlying Gemini concepts.
      Variety of Use Cases: Cover a wide range of Gemini capabilities, including text generation, code generation, image generation, and multimodal interactions.
      Complexity: Medium. Requires familiarity with Python and JavaScript/TypeScript, and the Gemini SDKs.
      Expected Size: 175-350 hours.
      Skills: Python, JavaScript/TypeScript, Gemini SDKs, technical writing.
      7. Evaluate Gemini on an Open-Source Benchmark
      Objective: Create a real-world multimodal benchmark or eval, and evaluate the Gemini models on it. If you don't want to create a benchmark yourself, you could also propose adding Gemini 2.0 to an existing external open-source benchmark. This contributes to the broader understanding of Gemini's capabilities and helps identify areas for improvement.
      Options:
      Create a New Benchmark: Design a new benchmark that focuses on a specific real-world task or scenario, incorporating multiple modalities (text, image, video, audio). This could involve:
      Defining a task and evaluation metrics.
      Collecting or generating a dataset.
      Developing evaluation scripts.
      Documenting the benchmark and making it publicly available.
      Extend an Existing Benchmark: Identify an existing open-source benchmark (e.g., on platforms like Hugging Face) and add support for Gemini 2.0. This involves:
      Understanding the benchmark's structure and evaluation methodology.
      Implementing the necessary code to run Gemini 2.0 on the benchmark.
      Reporting the results and comparing them to other models.
      Complexity: High. Requires strong understanding of evaluation methodologies, benchmarking, and potentially data collection/generation.
      Expected Size: 350 hours.
      Skills: Python, data analysis, machine learning evaluation, (optional) data collection/annotation.
      8. Self-Contained OSS-Fuzz Module for Researchers 🔬📦
      Objective: Develop a standalone Python module to provide researchers with APIs to query OSS-Fuzz project details, access historical fuzzing results, and experiment with custom fuzz targets.
      Expected Outcomes (Functionalities):
      Project Information Retrieval ℹ️:
      API to list all projects currently fuzzed by OSS-Fuzz.
      API to retrieve details for a specific project (e.g., language, build system, fuzzer engines used).
      Ability to filter projects based on criteria (e.g., language, library).
      Historical Fuzzing Results 📜:
      API to access historical coverage reports for a specific project and fuzzer.
      API to retrieve crash reports and statistics.
      Ability to specify a date range for the results.
      Data should be returned in a structured format (e.g., JSON).
      Custom Fuzzing Execution ⚙️:
      API to define and submit custom fuzz targets for a specific project.
      Ability to specify fuzzer engine, configuration options, and resources (e.g., CPU, memory).
      API to monitor the status of custom fuzzing runs.
      API to retrieve results from custom fuzzing runs (coverage, crashes).
      Modular Design 🧱:
      The module should be well-structured and easy to extend.
      It should be installable via pip.
      It should have clear documentation and usage examples.
      Required Skills: Python, Bash, understanding of fuzzing, familiarity with GCP.
      Mentor: Dongge Liu
      Expected Size: 350 hours
      Complexity: High. Requires significant programming experience and a deep understanding of fuzzing and the OSS-Fuzz infrastructure.
      9. Streamlined Experiment Execution and Improved Report UI (OSS-Fuzz-Gen) 🧪📈
      Objective: Enhance the experiment execution process and improve report readability in OSS-Fuzz-Gen.
      Expected Outcomes (Enhancements):
      Search Functionality 🔍: Implement a search feature to allow users to easily find specific experiments, projects, or fuzzers within the reports. This could include searching by name, date, or configuration parameters.
      Aggregated Metrics 📊: Provide aggregated metrics across multiple experiments, such as average coverage, number of crashes, and execution time. This will allow users to quickly compare the performance of different fuzzing strategies.
      Improved Navigation 🧭: Enhance the navigation within the reports to make it easier to find and access specific sections and data. This could include adding a table of contents, breadcrumbs, or interactive filters.
      Experiment Configuration ⚙️: Provide a clear and user-friendly interface for configuring experiments. This should include options for selecting the project, fuzzer, configuration parameters, and resources.
      Improved Readability & UI ✨: Improve the overall readability and visual appeal of the reports. This could include using charts and graphs to visualize data, improving the layout and formatting, and using a consistent color scheme.
      General UI/Feature Improvements 👍: Address any other UI or feature requests from users to improve the overall usability of OSS-Fuzz-Gen. This could include adding features like exporting reports in different formats, comparing results across different time periods, or customizing the display of data.
      Required Skills: Python, Bash, Web Development, understanding of fuzzing, familiarity with GCP.
      Mentor: Dongge Liu
      Expected Size: 350 hours
      Difficulty: Medium
      Complexity: Medium. Requires a mix of programming (Python, Bash) and web development skills. The focus is on improving usability and data presentation.
      10. Integrating Research Innovations into OSS-Fuzz-Gen 💡🔬
      Objective: Explore advancements from related research works and integrate them into OSS-Fuzz-Gen.
      Expected Outcomes:
      Identify at least 5 relevant research projects. 🤔: Research recent advancements in fuzzing, particularly those related to LLMs or improved fuzzing techniques. Select projects with potential for integration into OSS-Fuzz-Gen.
      Successfully integrate at least one research-driven technique. ✅: Choose one or more of the identified techniques and implement them within OSS-Fuzz-Gen. This will require adapting the research code and integrating it into the existing codebase.
      Demonstrate measurable improvements. 📈: Evaluate the impact of the integrated technique on fuzzing performance. This could involve measuring improvements in coverage, crash detection rate, or other relevant metrics. Provide clear evidence of the benefits of the integration.
      Required Skills: Python, Bash, C/C++, research experience in fuzzing, experience with LLM applications.
      Mentor: Dongge Liu
      Expected Size: 350 Hours
      Difficulty: Hard
      Complexity: High. Requires strong research skills, programming expertise, and a deep understanding of fuzzing.
      11. Gemma Model Projects 💎
      Objective: Contribute to the Gemma ecosystem by developing tools, tutorials, and integrations. Gemma is Google's family of open models.
      Project Ideas:
      Gemma Model Fine-tuning UI: Develop a user-friendly web interface (using Streamlit, Gradio, or similar) that allows users to fine-tune Gemma models on their own datasets. This should include:
      Dataset Uploading: Support various data formats (CSV, JSONL, text files) and handle data validation and preprocessing. Consider providing options for data augmentation.
      Hyperparameter Configuration: Allow users to easily adjust key hyperparameters (learning rate, batch size, epochs, etc.). Provide sensible defaults and tooltips explaining each parameter.
      Training Progress Visualization: Display real-time training progress, including loss curves, evaluation metrics (e.g., accuracy, F1-score), and potentially examples of generated text.
      Model Download/Export Options: Allow users to download the fine-tuned model in various formats (e.g., TensorFlow SavedModel, PyTorch, GGUF for local inference).
      Integration with Google Cloud Storage/Vertex AI: (Optional) Provide options for users to train at scale using Google Cloud resources. This would involve integrating with GCS for data storage and Vertex AI for training.
      Clear Documentation and Examples: Provide comprehensive documentation and step-by-step examples for using the UI.
      Complexity: Medium to High. Requires web development skills, familiarity with machine learning frameworks (TensorFlow/PyTorch), and potentially cloud integration.
      Expected Size: 175-350 hours.
      Skills: Python, Streamlit/Gradio, TensorFlow/PyTorch, (optional) Google Cloud Platform.
      Gemma <> Hugging Face Spaces Demo: Create an interactive demo for the Hugging Face Spaces platform using a Gemma model. This should showcase a specific capability of Gemma (e.g., text generation, question answering, code completion).
      Build a Gradio or Streamlit Application: Create a user-friendly web application that allows users to interact with the Gemma model.
      Integrate with the Hugging Face Hub: Load the Gemma model directly from the Hugging Face Hub.
      Provide Clear Instructions and Examples: Make it easy for users to understand how to use the demo and what to expect.
      Make the Demo Visually Appealing and Engaging: Use interactive elements, clear formatting, and potentially visualizations to make the demo engaging and informative.
      Complexity: Medium. Requires web development skills and familiarity with Hugging Face Spaces.
      Expected Size: 175 hours.
      Skills: Python, Streamlit/Gradio, Hugging Face Hub.
      Benchmark Gemma Models: Develop a comprehensive benchmark suite to test Gemma models on a range of tasks and datasets (academic benchmarks like MMLU, GSM8K, etc., and custom datasets).
      Create scripts for automation. Automate the benchmarking process for various tasks.
      Compare performance of various Gemma model families. Run the benchmarks on different Gemma model sizes and variants.
      Compare performance against other open models. Include other popular open models (e.g., Llama 2, Mistral) in the benchmark for comparison.
      Create informative summaries of benchmark results. Generate reports and visualizations summarizing the results. This should include tables, charts, and potentially a leaderboard.
      Regular Updates: Design the benchmark to be easily updated with new Gemma models and datasets.
      Reproducibility: Provide clear instructions and scripts to allow others to reproduce the benchmark results.
      Complexity: Medium to High. Requires understanding of benchmarking methodologies, machine learning evaluation, and scripting.
      Expected Size: 175-350 hours.
      Skills: Python, machine learning evaluation, scripting, data analysis.
      Gemma Model Function Calling Exploration:
      Investigate and document best practices for using Gemma with function calling, similar to other models' function calling capabilities. This capability allows the model to call external functions to retrieve information or perform actions.
      Create detailed tutorials, and comprehensive code examples. Provide step-by-step instructions and code examples demonstrating how to implement function calling with Gemma.
      Develop use case scenarios. Showcase various use cases where function calling can be beneficial, such as interacting with APIs, databases, or other external tools.
      Define clear specifications: Document how to define the functions that Gemma can call, including input/output formats and error handling.
      Explore Different Approaches: Investigate different approaches for implementing function calling, such as using existing libraries or developing custom solutions.
      Complexity: Medium. Requires understanding of LLM capabilities, API design, and potentially creating custom integrations.
      Expected Size: 175-350 hours
      Skills: Python, API design, LLM interaction.
      Comments are disabled for this gist.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/google-deepmind/
    idea_list_url: https://goo.gle/deepmind-gsoc-projects-2025


  - organization_id: 57
    organization_name: Graphite
    no_of_ideas:
    ideas_content: |
      Contributor guide
      » Project setup
      » Codebase overview
      » Debugging tips
      » Starting a task
      » Code quality guidelines
      » Submitting a contribution
      » Student projects
      » Graphene
      » Networks and nodes
      Student projects
      Graphite offers a number of opportunities for students to contribute by building a self-contained project as part of a structured format. These projects are designed to be completed over several months and are ideal for Google Summer of Code or similar internship programs, solo or group university capstone projects, and other arrangements. Each project has a distinct focus and is a great way to make a meaningful contribution to open source over the length of the program while receiving mentorship and guidance from the Graphite team.
      Student projects require adherence to a set schedule with regular check-ins, milestones, and evaluations. The structured setting is designed to provide a supportive environment for students to learn and grow as developers while gaining real-world industry experience from collaborating on a sizable software product and remaining accountable to stakeholders. It's our goal to make sure you succeed!
      Use this contributor guide to start out with the code. Then when you're ready, reach out through Discord and use the #🎓student-projects channel to discuss and work towards proposing a project with the Graphite core team.
      Google Summer of Code
      GSoC is a program offering students a stipend for successful completion of an internship-style experience with an open source organization. Read about how it works.
      Graphite is participating again in GSoC 2025. Getting involved early is a great way to have a head start and stand out in your application. The proposal formulation period is open now until the April 8 deadline (see the full timeline).
      Writing a proposal
      Writing a good proposal is an important first step that demonstrates your understanding of the project and your ability to plan and execute it. A well-defined proposal will set you up for success throughout the rest of the program.
      You are encouraged to reference the project idea list below to find several potential projects suited to your experience, interest, and choice of scope. Then, you must reach out to a core team member through Discord to discuss your plan in detail before writing a proposal. This will help you understand the project's scope and requirements and develop a detailed timeline for your expected summer-long work schedule. Importantly, it will also help us understand your background and capabilities to offer you feedback and suggestions for the best outcome in the competitive applicant selection process.
      When it comes to writing the proposal, which you will submit to the GSoC application website, we offer some guidelines below:
      Proposal structure: Please consult the Blender GSoC application template as reference for our desired format. For project ideas already listed below, omit the "Benefits" section. Remember: don't waste your—and our—time restating information that we already know, like background info about Graphite or our tech stack; we just want to hear your thoughts and plans about what you uniquely bring to the table and how you'll execute the project. Proposals should be utilitarian, not formal, while also demonstrating your professional communication skills. Using an LLM to write your proposal won't be to your advantage.
      Experience: We're especially interested in your background and work experience, so attaching a résumé or CV is an optional but recommended way to help us understand your capabilities. If able, please also include links to past open source contributions or personal projects in the bio section. Our goal is to provide an environment for you to learn and grow as a productive software engineer and team collaborator, not to help you learn the basics of coding, so any included work examples will help us understand your potential as a self-motivated contributor to the open source community.
      Work timeline: Your goal is to write a proposal that inspires confidence in your ability to successfully complete the project, which means understanding in detail what's involved at a technical level and how you plan to tackle it. A detailed work timeline is the most important written part of your proposal. It should be broken into weekly or bi-weekly milestones with a couple sentences of technical detail. The summary in the project idea list below doesn't give enough information to develop a timeline, so you'll need to discuss this with the core team on Discord.
      Prior PRs: The largest factor in our selection decision will be the quality and extent of your prior contributions to Graphite made during the proposal formulation period (or before, if applicable). Include a link to https://github.com/GraphiteEditor/Graphite/commits?author=YOUR_GITHUB_USERNAME in your proposal and feel free to write up a summary of what you've contributed and learned from the process. You may also keep contributing during the month after applications close, before we've finalized our selections, for those additional PRs to be considered.
      Project idea list
      Compilers, graphics, and theory
      These projects are more advanced but are highest priority for Graphite's development. We will be aiming to find standout candidates for at least one of these projects this year. If your background suits the projects listed in this section, you are likely to have better odds applying to these compared to the more general projects further below.
      Graphene language/compiler development
      Check back shortly for a full project description, or ask on Discord right now for more details.
      See the GitHub issue.
      Best for someone with an aptitude or focus on programming languages, compilers, and type system theory.
      GPU-accelerated rendering pipeline within the compiler/runtime/engine
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Build out infrastructure in the language/compiler/runtime/engine using rust-gpu and/or CubeCL.
      See the GitHub issue.
      Best for someone with both an aptitude for low-level graphics programming (experience in one of WGPU, Vulkan, OpenGL, etc.) and an interest in compilers and programming languages.
      Node equivalence rewriting
      Check back shortly for a full project description, or ask on Discord right now for more details.
      See the GitHub issue.
      Best for someone with an interest towards graph theory and compiler optimization topics like E-graphs.
      Machine learning architecture
      Generative AI and vision ML models will need to run in Graphite's node graph with a Rust-centric, modular, portable, deployable, scalable environment.
      Possible Mentors: Oliver
      Needed Skills: Machine learning (and potentially: Rust, Python, ONNX, Candle, Burn)
      Project Size: Large (GSoC: 350 hours)
      Difficulty: Hard
      Expected Outcomes: Specifics will vary by proposal. In general, a useful end-to-end integration of at least one GenAI or vision model into Graphite's node graph which can run both locally and deployed to a hosting provider server.
      AI/ML is filling a rapidly growing role as a tool in the creative process. Graphite's procedural node-based workflow is uniquely suited to leveraging the power and flexibility of AI nodes.
      Segment Anything 2 (object segmentation), Depth Anything (depth estimation), and Stable Diffusion (image generation, generative fill, style transfer, etc.) are currently the three models we are most interested in integrating. The challenge is settling on an architecture and tech stack which is well suited for Graphite's requirements.
      For additional technical details: click here
      Rendering and graphics
      Several of these require a good understanding of computer graphics rendering techniques and algorithms. Experience in game development and writing your own rendering engines is a plus.
      Mesh vector rendering
      Check back shortly for a full project description, or ask on Discord right now for more details.
      See the GitHub issues: fills and strokes.
      Support paints for strokes and fills
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Refactor and upgrade our renderer to cleanly handle paints for fills and strokes.
      This includes gradient rendering polyfills
      May include other rendering features like stroke alignment polyfills
      Advanced text layout and typography
      Check back shortly for a full project description, or ask on Discord right now for more details.
      See the GitHub issue.
      PDF and/or DXF import/export
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Scope and viability depends on the state of available libraries.
      Traditional brush engine
      Check back shortly for a full project description, or ask on Discord right now for more details.
      See the GitHub issue.
      Procedural brush engine
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Read this thesis for background, chapter 3 onwards.
      Advanced color management
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Add support for HDR/WCG and/or CMYK and alternate color spaces/models
      Requires an experienced understanding of color science
      Image processing algorithms for photography
      Check back shortly for a full project description, or ask on Discord right now for more details.
      New graphics nodes
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Research and implement image processing (raster) or geometry (vector) nodes that you propose or we suggest in our discussions with you.
      Example of one such node: Text on path.
      SVG with raster effects
      Check back shortly for a full project description, or ask on Discord right now for more details.
      The SVG spec supports a number of filters and other raster effects, and we currently only implement a small subset.
      Add support for the rest of the SVG spec, including filters, masks, and other raster effects.
      Allow roundtrip import and export of SVG files with these features.
      Editor tooling
      Snapping system overhaul
      Check back shortly for a full project description, or ask on Discord right now for more details.
      See the GitHub issue.
      Advanced vector editing tool modes
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Add modes for segment editing, mesh vector, and more. Discuss with us on Discord to decide on the scope of the project.
      Tooling polishing and gizmo additions
      Check back shortly for a full project description, or ask on Discord right now for more details.
      Marquee selection masking
      Graphite's raster editing features requires the implementation of Select mode, where users can draw a mask which becomes a marquee (marching ants) selection.
      Possible Mentors: Keavon, Hypercube
      Needed Skills: Rust, computer graphics
      Project Size: Large (GSoC: 350 hours)
      Difficulty: Medium
      Expected Outcomes: Complete implementation of Mask mode and its marquee selection. Marching ants visualization shader effect. Integration of selection mask with the node graph and raster editing tools. Useful raster editing workflow.
      A central part of the workflow in raster image editors is the selection of portions of the image to constrain manipulations just to the masked areas. Tools such as the circular and rectangular marquee, lasso, and magic wand are used to create masks. Instead of using dedicated tools, Graphite's design reuses the existing vector and raster drawing tools (like Rectangle, Ellipse, Pen, and Fill) to create masks in a dedicated Mask mode. Returning from Mask mode reveals the marching ants selection that constrains further editing operations.
      This is a key feature in Graphite's evolution to a fully-featured raster editor.
      Refactors and infrastructure
      Complex widget layout system
      Graphite's UI needs an upgraded layout system to support more complex and dynamic widget arrangements defined from the backend.
      Possible Mentors: Keavon
      Needed Skills: Rust, web (Svelte, CSS, TypeScript)
      Project Size: Small (GSoC: 90 hours) or Medium (GSoC: 175 hours)
      Difficulty: Medium
      Expected Outcomes: An improved system for defining widget layouts with better control and flexibility over arrangement and dynamic data binding. Reduction in boilerplate and plumbing required to define each new layout. Better control of styling between rows.
      The current system for defining the arrangement of widget layouts from the backend, created during a previous student project, has served us well thus far but has limitations. This project aims to extend the system to better model our evolved requirements.
      Students should have a good level of familiarity with Rust design patterns to envision, prototype, propose, and robustly implement a new system that can handle the complexity of Graphite's use cases. The size of this project can vary depending on the proposal's scope and extent of refactoring to these and adjacent systems.
      For additional technical details: click here
      Testing and performance instrumentation
      Graphite has many areas that could benefit from better automated testing for bugs and performance regressions.
      Possible Mentors: Dennis, Hypercube
      Needed Skills: Rust, unit testing
      Project Size: Small (GSoC: 90 hours) or larger if proposed
      Difficulty: Easy
      Expected Outcomes: Specific focus and scope may vary by the student's interests and proposal. In general, a significant increase in the coverage of tests in useful code areas (such as document loading, tool manipulation, and rendering) and attention towards systems which measure performance metrics and identify bottlenecks and regressions.
      Graphite could benefit from better testing coverage in a number of areas, especially end-to-end testing in the tool, document, and node graph systems. This project is about identifying and addressing areas that are lacking and most vulnerable to suffering from regressions. The student will be responsible for identifying areas that could benefit from better testing.
      Architecture visualization
      Infrastructure to generate visualizations of Graphite's system architecture would be a valuable addition to the project's documentation and debugging tools.
      Possible Mentors: Keavon, Dennis
      Needed Skills: Rust (especially proc macros)
      Project Size: Small (GSoC: 90 hours) or larger if proposed
      Difficulty: Medium
      Expected Outcomes: A system built from proc macros which can generate useful visualizations of Graphite's system architecture. Depending on proposal scope, this can include static visualizations added to the documentation, dynamic message flow visualizations for debugging, and tools to help identify redundant message traffic.
      Graphite's editor architecture, based around a message-passing processing queue, is structured as a hierarchical system of message handlers. Each handler stores its own state, and references to the state data may be passed along to its child handlers that need it.
      It is challenging to document the hierarchy of this system as a tree in the documentation because the code is often changing. Generating a visualization would ensure it remains up to date. Additional visualizations could also be generated with greater detail, such as message flow diagrams for each message.
      For additional technical details: click here
      Other
      Your own idea
      If you have an idea for a project that you think would be a good fit, we'd love to hear it!
      Possible Mentors: Varies
      Needed Skills: Varies
      Project Size: Varies
      Difficulty: Varies
      Expected Outcomes: Stated in your proposal.
      If none of the projects above suit your interests or experience, we are very open to discussing your own project ideas that could benefit Graphite. You may consult our task board and roadmap to get a feel for what our current priorities are.
      As is the case with all projects, please discuss this with us on Discord to flesh out your idea. Unsolicited proposals that have not been discussed with us will almost certainly be rejected.
      Successful past projects
      2024: Interactive node graph auto-layout
      Graphite's graph UI needs a system to automatically arrange layers and nodes given incremental changes to the graph contents.
      Affiliation: GSoC 2024
      Duration: 3 months
      Student: Adam Gerhant
      Program project listing
      Report and weekly updates
      Outcomes: A system that manages the placement of nodes based on a set of layout constraint rules and incremental updates to the graph topology. It should run efficiently, even with large graphs. It should be robust enough to handle a variety of graph topologies and user interactions, producing organized, useful, and stable layouts.
      Background: The Graphite concept is built around a node graph representation of layer stacks, while tools automatically generate and manipulate nodes. When a layer or node is inserted, deleted, moved, or referenced, the graph needs to be reorganized to maintain a clear and useful layout. Users can also interactively expand and collapse groups of nodes which occupies or frees up graph real estate.
      Unlike other node editors that are centered around manual graph editing, where users are fully in charge of node placements within one large node network, Graphite's node UI is more oriented towards automatic layout management and viewing just parts of the graph at one time. This means the shown graph topology is constantly changing and the layout system needs to cooperatively organize the graph in concert with user actions.
      While general graph layout algorithms are complex and struggle to produce good results in other node editors, Graphite's graph topology is more constrained and predictable, which makes it possible to design a layout system that can produce good results. Nodes tend to be organized into rows, and layers into columns. This turns the problem into more of a constraint-based, axis-aligned packing problem.
      2024: Rendering performance infrastructure improvements
      Graphite performance is bottlenecked by limitations in the new node graph rendering architecture that needs improvements.
      Affiliation: GSoC 2024
      Duration: 4 months
      Student: Dennis Kobert
      Program project listing
      Report and weekly updates
      Outcomes: A holistic, metrics-driven focus on fixing the many unoptimized areas of Graphite's node graph compilation, execution, and rendering systems. Integration of Vello as an integrated rendering backend. A significant improvement in the performance of the editor, especially in the node graph, and a more stable and predictable performance profile. Benchmarking and profiling tools to measure and visualize performance improvements and regressions.
      Background: Graphite's node graph system is the backbone of the editor, but it has many performance problems that need to be addressed because the system is relatively immature and performance-impacting shortcuts were taken during its initial development. This project is all about making the node graph system more robust and optimized, which will have a direct impact on the user experience and the editor's overall performance. By the end of the project, the editor should finally feel usable in the majority of user workflows. Vello should be enabled as an alternate render engine that will fully replace the existing SVG-based one in the future, once browser support arrives across major platforms.
      2024: Raw photograph decoding in Rust
      For Graphite to support editing photos from professional digital cameras, it needs a raw decoding/processing library.
      Affiliation: GSoC 2024
      Duration: 5 months
      Student: Elbert Ronnie
      Program project listing
      Report and weekly updates
      Rawkit library
      Outcomes: A Rust library that implements raw photo decoding functionality to native Rust. A clean, well-structured codebase and API. At a minimum, demonstrate the successful end-to-end decoding, debayering, and color space handling of Sony ARW format photos in Graphite. Publish the library to crates.io.
      Background: For Graphite to work as a photo editing app, it needs to import raw photos. These contain compressed sensor imagery and metadata in a variety of formats. Sony ARW is the first target and additional camera brands are stretch goals. Graphite needs a library written in pure Rust with a suitable (non-GPL) license, which does not currently exist in the ecosystem, so we need to create one ourselves.
      2023: Bezier-rs library
      Graphite's vector editing features require the implementation of Bezier curve and path manipulation computational geometry algorithms.
      Affiliation: University of Waterloo, Ontario, Canada
      Duration: 9 months
      Students: Hannah Li, Rob Nadal, Thomas Cheng, Linda Zheng, Jackie Chen
      Bezier-rs library
      Interactive web demo
      Outcomes: The student group designed an API for representing and manipulating Bezier curves and paths as a standalone Rust library which was published to crates.io. It now serves as the underlying vector data format used in Graphite, and acts as a testbed for new computational geometry algorithms. The team also built an interactive web demo catalog to showcase many of the algorithms, which are also handily embedded in the library's documentation.
      2022: Backend layout system
      Graphite's UI needs a system to define and manage layouts for widgets from the backend.
      Affiliation: California Polytechnic State University, San Luis Obispo, USA
      Duration: 3 months
      Student: Max Fisher
      Outcomes: The student designed and implemented a new system across the editor's frontend and backend which made it possible to define and manage layouts for widgets from the backend and receive input data from those widgets. Previously, all layouts were statically defined in the frontend and extensive plumbing was required to pass data back and forth.
      2022: Path boolean operations
      Graphite's vector editing features require the implementation of boolean operations on paths, such as union, intersection, and difference.
      Affiliation: California Polytechnic State University, San Luis Obispo, USA
      Duration: 3 months
      Student: Caleb Dennis
      Outcomes: The student devised and prototyped algorithms for performing boolean operations on paths, such as union, intersection, and difference. These were used as a stopgap during 2022 and 2023 to provide users with a rudimentary boolean operation feature set.
      Submitting a contribution
      Graphene
      Contents
      Google Summer of Code
      Writing a proposal
      Project idea list
      Compilers, graphics, and theory
      Graphene language/compiler development
      GPU-accelerated rendering pipeline within the compiler/runtime/engine
      Node equivalence rewriting
      Machine learning architecture
      Rendering and graphics
      Mesh vector rendering
      Support paints for strokes and fills
      Advanced text layout and typography
      PDF and/or DXF import/export
      Traditional brush engine
      Procedural brush engine
      Advanced color management
      Image processing algorithms for photography
      New graphics nodes
      SVG with raster effects
      Editor tooling
      Snapping system overhaul
      Advanced vector editing tool modes
      Tooling polishing and gizmo additions
      Marquee selection masking
      Refactors and infrastructure
      Complex widget layout system
      Testing and performance instrumentation
      Architecture visualization
      Other
      Your own idea
      Successful past projects
      2024: Interactive node graph auto-layout
      2024: Rendering performance infrastructure improvements
      2024: Raw photograph decoding in Rust
      2023: Bezier-rs library
      2022: Backend layout system
      2022: Path boolean operations
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/graphite/
    idea_list_url: https://graphite.rs/volunteer/guide/student-projects/

  - organization_id: 58
    organization_name: Haskell.org
    no_of_ideas:
    ideas_content: |
      GSoC 2025 Ideas
      This is a list of ideas for contributors who are considering to apply to Google Summer of Code 2025 for Haskell.org
      For project maintainers
      Are you working on a Haskell project and you could use the help of a contributor during the summer? Consider adding it as an idea here! You can contribute ideas by sending a pull request to our github repository (example from 2024). If you just want to discuss a possible idea, please contact us.
      What is a good idea? Anything that improves the Haskell ecosystem is valid. The GSoC rules state that it must involve writing code primarily (as opposed to docs).
      Projects should be concrete and small enough in scope such that they can be finished by the contributor. Past experience has shown that keeping projects “small” is almost always a good idea.
      Important changes since 2021/2022: In the past, GSoC projects were expected to take up the equivalent of full time employment for a student. In 2021, this was reduced to half time positions: students were expected to work around 175 hours in a 10 week period. Since 2022, contributors now have the choice between a larger (around 350 hours) or a smaller project. Ideas should indicate in which category they fall.
      Projects should benefit as many people as possible – e.g. an improvement to GHC will benefit more people than an update to a specific library or tool, but both are acceptable. New libraries and applications written in Haskell, rather than improvements to existing ones, are also welcome.
      For students/contributors
      We have added some tips on writing a proposal here. Please be aware that:
      This is not an all-inclusive list, so you can apply for projects not in this list and we will try our best to match you with a mentor.
      You can apply for up to two ideas (but only one can be accepted).
      Table of Contents
      CodeWorld GHC Update
      Language Server support for cabal.project files
      Qualified aliases in Liquid Haskell
      CodeWorld GHC Update
      CodeWorld is a web-based educational environment for learning computer science using Haskell. It is based on GHCJS, an old project to compile Haskell to JavaScript with a modified GHC compiler.
      GHCJS is no longer a good choice, as it is difficult to keep up to date with the latest GHC versions. However, modern versions of GHC have built-in backends for both JavaScript and WebAssembly, which are more reliable and easier to maintain, and kept up to date as part of the main line of GHC development. This project would involve updating CodeWorld to use one of the new GHC backends for JavaScript or WebAssembly.
      This would involve updating the build system, and making any necessary changes to the CodeWorld runtime to work with the new backends.
      The scope of the project can be adjusted based on the desired time frame and experience of the mentee. Some questions include:
      Is the goal to get a proof of concept, or a deployable replacement?
      Will the rule-based requirements checker also be updated to newer GHC versions?
      This requires updating the GHC API usage.
      This feature is, to my knowledge, not currently used by anyone.
      Will the educational dialect be updated?
      If so, how do we handle unconstrained universal equality? Note that this likely requires development of a non-trivial GHC plugin.
      If not, how do we deploy both versions simultaneously (if a deployable replacement is the goal)?
      What additional improvements are enabled by newer GHC versions and the new backends?
      Mentorship
      Chris Smith (cdsmith)
      Ideally, a second mentor with experience in one or both of GHC JS/WASM backends
      Difficulty and size
      The difficulty of this project is medium, as there are significant infrastructure and build system challenges to address. Depending on choices made, this may become hard.
      The minimum size of this project is 175 hours, but there is likely more work depending on the mentee’s desired scope and ideas.
      Language Server support for cabal.project files
      Goals
      Introduce a new Haskell Language Server plugin, which provides IDE-features for cabal.project files.
      Some possible features include: * Diagnostics * Completions of * keywords * filepaths * enum values * Syntax Highlighting
      The scope of the project can be adjusted based on the desired time frame and experience of the mentee. Some of these implementations can draw inspiration from the corresponding implementation in the hls-cabal-plugin.
      Background
      cabal.project files are often needed to configure how your project should be built. Haskell developers will often write and edit these files during their development process but as of yet, Haskell Language Server (HLS) provides no IDE support for them.
      Since HLS already provides IDE features for .cabal files it seems a natural next step to add a similar cabal.project plugin to HLS which provides IDE support for cabal.project files.
      Outcomes
      The main outcomes are pull requests with the implementation, tests, and code documentation of the implemented features.
      A secondary outcome is a blogpost describing the experience and the results of the project.
      Difficulty and Size
      The difficulty of this project is medium, as there are two rather big existing projects that developers need to understand in order to provide improvements.
      The minimum size of this project is 90 hours, but this can easily be extended to 175 as there is likely more work depending on the mentee’s desired scope and ideas.
      Required Skills
      Read and write technical English
      Haskell programming basics
      Project Mentor
      Jana Chadt (VeryMilkyJoe)
      Co-Mentor: Fendor
      Qualified aliases in Liquid Haskell
      Goals
      Update the implementation of Liquid Haskell to allow referring to type and predicate aliases in qualified form.
      Background
      Liquid Haskell is a verification tool for Haskell programs. The programmer writes specifications for these programs, and Liquid Haskell checks if the programs actually meet the specifications.
      Recently, the Liquid Haskell implementation went through a refactoring to improve name resolution. Much of the names in the specification language can be qualified now, in order to dissambiguate equal names that come from different modules. There is an exception though, when it comes to type and predicate aliases. For technical reasons, this constructs have been left behind in the refactoring.
      As the reference documentation explains, type aliases can be used to shorten specifications. Instead of writing a spec like:
      {-@ length :: [a] -> {v:Int | v >= 0} @-}
      one can write
      {-@ type INat = {v:Int | v >= 0} @-}
      {-@ length :: [a] -> INat @-}
      Unfortunately, if there are multiple INat aliases in scope, Liquid Haskell does not allow to qualify the name to disambiguate. For instance, the following specification is rejected with a message that says that SomeImport.INat is not in scope.
      {-@ length :: [a] -> SomeImport.INat @-}
      This project is to analyze the implementation and to design and implement a solution both for type and predicate aliases. There is a corresponding issue in the Liquid Haskell repo.
      Outcomes
      The main outcomes are a pull request with the implementation, tests, and code documentation, and a discussion of the analysis and the design in the corresponding issue.
      A secondary outcome is a blogpost describing the experience and the results of the project.
      Size
      Project size should be near 175 hours. The project will require a fair amount of reading of existing Haskell code, and building an understanding of how it works. Familiarity with the verification mechanisms is not necessary a priori, though some user-level understanding of Liquid Haskell is going to be needed to write tests.
      Required Skills
      Read and write technical English
      Haskell programming basics
      Project Mentor
      Facundo Domínguez, Tweag engineer and comaintainer of Liquid Haskell
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/haskell.org/
    idea_list_url: https://summer.haskell.org/ideas.html

  - organization_id: 59
    organization_name: HumanAI
    no_of_ideas:
    ideas_content: |
      HumanAI
      Activities
      
      HumanAI is dedicated to integrating Artificial Intelligence with various fields in the Arts and Humanities. Our mission is to enhance the analytical potential of Arts and Humanities by combining humanist interests with machine learning initiatives.
      HumanAI in GSoC 2025
      The HumanAI open source umbrella organization plans to participate in the 2025 Google Summer of Code. If you are a student interested in our projects please check our ideas page. HumanAI is an umbrella organization that welcomes other projects and organizations related to machine-learning in Arts and Humanities. Please contact the admins at human-ai@cern.ch if you are interested in participating as a project.
      Please take a look at our GSoC Page for more details.
      You can also find us on Gitter.
      Latest update: evaluation tests to be published on 2/27.
      Organization administrators:
      Prof. Sergei Gleyzer, AI
      Prof. Xabier Granja, Modern Languages
      Prof. Emanuele Usai, AI
      Prof. Despina Stavrinos, Social Sciences, Psychology
      
      
      Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/humanai/
    idea_list_url: https://humanai.foundation/


  - organization_id: 60
    organization_name: INCF
    no_of_ideas:
    ideas_content: |
      GSoC 2025 Project Descriptions
       Request edit access
      +6
       Share
      Sign in
      FileEditViewToolsHelp
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/incf/
    idea_list_url: https://docs.google.com/document/d/1T7U4nYFbVbZuIUw_2bB89YASj-ra26hRNtG2a20Gjlw/edit?tab=t.0
  

  - organization_id: 61
    organization_name: IOOS
    no_of_ideas:
    ideas_content: |
      Project Ideas for 2025
      IOOS DMAC community's project ideas list for Google Summer of Code 2025.
      Deadline for mentoring organization application: Feb 11, 2025.
      Project Title Project Idea Link Description Hours
      Build web UI versions using pyodide/pyscript for IOOS tools ioos/gsoc#64 The idea for this project is to build interfaces for ioos-qc and compliance-checker. A user should be able to load datasets, select data and the checks they want to apply. 350 hours
      Prometheus server- graphs and monitoring for ERDDAP™ ioos/gsoc#72 We recently started adding Prometheus metrics to ERDDAP™. The main goal of this project is to build an example Prometheus Server which can monitor one or more ERDDAP™ instances. 175 hours
      Update ERDDAP™ page rendering to use a template framework ioos/gsoc#73 The project is to migrate existing ERDDAP™ pages to use a templating framework. 175 hours
      IOOS Cloud Sandbox - model validation and verification tools ioos/gsoc#84 Add model validation and verification tools to https://github.com/ioos/Cloud-Sandbox. Model validation and verification can include comparing model results to observations, previously validated data, other model data, etc. 175 hours
      Code separation and build management for cloudflow ioos/gsoc#85 Move Cloudflow's code to a poetry or uv build, with well-established and externalized dependency, and allow deployment to pypi. 90 hours
      Increased logging for Cloudflow ioos/gsoc#86 Having AWS logging increased within the codebase of cloudflow would greatly increase our capacity to support multiple users on the coastal sandbox. 90 hours
      Combined DwCA/Croissant JSON-LD examples and tools ioos/gsoc#70 The project would primarily consist of python tools to convert existing DwC metadata (in XML format) into JSON-LD format, example metadata for datasets that employ both standards, and a proof-of-concept pipeline that uses a combined DwC/Croissant-described dataset to train an AI model that predicts DwC categories from images 175 hours
      NOAA trawl survey database ioos/gsoc#74 The primary objective of this project is to create an accessible international database of transboundary marine survey data across the Northeast Pacific Ocean. 175 hours
      Extend CrocoLake's available datasets ioos/gsoc#75 This project consists in taking an existing dataset that is not yet included in CrocoLake and developing or adapting existing modules to convert it to CrocoLake's format. 175 hours
      Autoval Improvement ioos/gsoc#76 This project aims to enhance the capabilities of the Autoval package, which was developed for STOFS auto validation. STOFS stands for the Surge and Tide Operational Forecast System. 175 hours
      OCSMesh Parallelization ioos/gsoc#77 OCSMesh is a Python package that automates the generation of unstructured continuous (creek-to-ocean) meshes using the jigsaw-python library and triangles. The goal of this project is to increase OCSMesh’s efficiency by parallelizing the most time consuming steps, including DEM processing and jigsaw mesh generation. 350 hours
      STOFS dashboard ioos/gsoc#78 This project aims to advance and improve our STOFS event dashboard (github repo). This tool allows a user to select events (e.g., tropical cyclones, winter storms, major incidents in coastal areas) and compare STOFS model results with observations for those events. 175 hours
      Probabilistic Surge Model Performance Assessment ioos/gsoc#79 The storm surge modeling team at the Office of Coast Survey (OCS) have developed a framework called (ondemand-storm-workflow) to develop probabilistic hurricane storm surge models. The goal of this project is to improve the post-prossessing and model evaluation capabilities of the workflow. 175 hours
      Land Cover Integration for Parametric Hurricane Model (PaHM) ioos/gsoc#80 This project aims to enhance the Generalized Asymmetric Holland Model (GAHM) within the Parametric Hurricane Modeling System (PaHM) framework by incorporating land cover effects on wind speeds during tropical cyclones. 350 hours
      Expand the Google Test suite for the Fisheries Integrated Modeling System ioos/gsoc#81 The Fisheries Integrated Modeling System (FIMS) is a framework to create statistical models, written in C++ and R, to assess the status of marine resources. This project will add tests for uncovered code and suggest places where the tests, especially the Google tests, can be enhanced. 175 hours
      Fix clang-tidy for the Fisheries Integrated Modeling System ioos/gsoc#82 The project follows a modified Google style guide for the The Fisheries Integrated Modeling System (FIMS) C++ standards and relies on GitHub action using clang-tidy to ensure that code pushed to the GitHub repository conforms to these standards. 90 hours
      Complete the integration of the logging system in the Fisheries Integrated Modeling System ioos/gsoc#83 This project would take examples already in the source code for the The Fisheries Integrated Modeling System (FIMS) and use pattern matching to insert new logging entries into the code where it seems that they are needed. 90 hours
      phytoclass for the masses ioos/gsoc#90 This project will improve usability and accuracy of phytoclass R library for conversion of HPLC pigment data to phytoplankton abundance estimations. 90 hours
      pyOBIS for stakeholders ioos/gsoc#91 This project will make use of the pyOBIS python library to create a series of jupyter notebooks to address research questions of natural resource managers. 90 hours
      Add MQTT support to ERDDAP™ #93 Add support for MQTT to ERDDAP™. MQTT is a message protocol which was in particular designed to be lightweight and used by remote/IoT devices. 350 hours
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/ioos/
    idea_list_url: https://github.com/ioos/gsoc/blob/main/2025/ideas-list.md

  - organization_id: 62
    organization_name: Inkscape
    no_of_ideas:
    ideas_content: |
      master
      inkscape
      doc
      gsoc
      summerofcode.md
      summerofcode.md
      Find file
      Blame
      Permalink
      Clean doc folder, add GSoC instructions
      Jonathan Neuhauser authored 4 months ago
      1d7e5d29
      History
      Code owners
      Assign users and groups as approvers for specific file changes. Learn more.
      summerofcode.md
      18.99 KiB
      Edit
      Welcome to Inkscape!
      For quite a few years Inkscape has been successfully participating in Google Summer of Code.
      Google has opened up the program to students AND beginners to Open Source who are 18 years are older. Projects can be small (~90 hours), medium size (~175 hours) or large size (~350 hours). Finish times are flexible, 12 to 22 weeks (with agreement of mentor).
      For more information, checkout Google's guide.
      GSoC is a program where Google funds the development of specific features in open source software by university students and others new to open source. Projects to be developed are picked by Inkscape administrators from the pool of proposals submitted by applicants.
      We've mentored about 4-6 students a year since GSoC started. Many students enjoyed their work and continue to be involved; perhaps your mentor will be a past GSoC student! A lot of exiting new features have been originally developed by GSoC students in the past several releases.
      You're interested in joining us for the next round as a student? Great! Scroll through the ideas list below to get inspired and when the time comes, talk to us and select a project of your choosing.
      You can select a proposal from the list below or come up with one of your own. In either either case, you must give us a detailed outline of what you plan to do. It is highly recommended that you discuss your idea as early as possible with Inkscape developers. They not only can give you guidance as you flesh out your proposal but ultimately you must convince them that you can do the work planned in the time allotted. If you have not discussed your proposal with Inkscape developers before you apply, your application will be rejected!
      Candidate Applications {#candidate_applications}
      Google program information:
      Home page.
      Summer of Code Application form. Applications open at 18:00 UTC on March 18th, 2024. https://developers.google.com/open-source/gsoc/timeline
      Inkscape-specific information:
      SOC Application Template.
      Candidate Applications for GSoC 2024 must be submitted to the GSoC site by 18:00 UTC on April 2nd 2024.
      The "two patches" rule
      We require two relevant previous contributions from each potential GSoC student at the time of the application deadline before accepting the student for GSoC participation.
      The reason for this requirement is that you can show us that you have
      succeeded in building Inkscape or set up the development environment for the subproject you intend to work on on your PC
      have understood a little piece of the code relevant for your project and are able to improve it.
      Inkscape is a large project, and you really should not try to understand all the code. Many (all?) developers know only parts of the program code! You can join our or chat and ask developers for help.
      Suggested "easy" bug fixes or improvements
      To get you started on Inkscape development, you can find (probably) easy-to-fix bugs or small improvements that require very little knowledge of the whole program by searching our bug-tracker for bugs tagged with 'easy-fix'.
      Note that for projects outside of the core repository (such as extensions, website, infrastructure or documentation / translation infrastructure) related projects, your two patches should be in the appropriate subprojects and programming language.
      Performance Evaluation
      See also the official guide.
      GSoC has two formal evaluation points, at the mid-term and at the end. These evaluations determine if you receive the stipend from Google. In order to receive a pass for the evaluations you will need to show adequate progress toward your project's goals.
      To help you meet your goals and so that your mentor can better evaluate your progress you should:
      Have frequent, public discussions of your progress. (Don't rely on just your mentor for advice)
      Have a public branch for your code to which you commit regularly. Ideally, an open merge request invites discussion from other experienced contributors.
      Give regular (typically weekly) status reports to the entire project.
      For the final pass, the code doesn't need to be merged yet, but as a general guideline, there should be a clear pathway to get it production-ready (in particular, remarks from core contributors should have been addressed).
      Remember: we want you to succeed!
      Suggested Project Ideas
      The following is a list of formal project suggestions, but do not feel limited to only these - some of our best contributions have been unique ideas that students had in mind from other sources! That's how most developers start contributing - an "itch to scratch" is the best motivation to stay on track!
      General inspiration may be taken from
      highly requested features
      UX bugtracker
      Older, possibly outdated project lists (definitely ask on chat before spending any time on investigating them):
      Development Project Ideas
      Projects
      Launchpad blueprints
      C++ projects
      UI-Free Inkscape
      Estimation of difficulty: Difficult - Long (350h)
      Potential mentors: Marc Jeanmougin
      Programming skills: C++, CMake
      Prerequisites: Minimal knowledge of build systems. Experience with GtkMM helpful.
      Detailed Description: Inkscape currently builds with X11 and gtk and a lot of graphical dependencies. But since it is allowed to run in commandline, and there are controlled environments (servers) that use it to convert svg to png and to perform actions, there should be no need to force it to build with those. The main goal of this project is to add a WITH_GUI compilation flag that when OFF, does not link Inkscape with any graphical dependency. While much work has been done towards this goal, much remains to be done. More work needs to be done to separate out hidden GUI dependencies that remain since the Verb to Action transition.
      Use cases: Server installs, scripts
      Rework Live (Path) Effect system
      Estimation of difficulty: Hard - Long (350h)
      Potential mentors: mikekov
      Programming skills: C++
      Prerequisites: experience with raster images
      Detailed Description: Live Path Effects (LPEs) are non-destructive effects applied to paths and shapes standalone or inside a group. This is done by keeping a reference to the original data to recompute when needed. Currently, they don't work on text and image elements, and the underlying code needs to be refactored to support this and make LPEs more robust.
      Use cases: Enable non-destructive editing for more object types, even groups with mixed element types.
      Path Library Improvements
      Estimation of difficulty: Hard - Long (350h)
      Potential mentors: Tavmjong Bah, KK
      Programming skills: C++
      Prerequisites: Strong math skills, specifically in (computational) geometry.
      Detailed Description: Inkscape relies on two geometry libraries for path manipulations: lib2geom and livarot. lib2geom is a generic modern library written specifically with Inkscape in mind. lib2geom is missing some functionality that Inkscape requires and that is found in livarot. This project is to move that functionality into lib2geom (or into separate files) using lib2geom path descriptions. A 2020 GSoC student did a significant amount of work understanding and documenting the issues involved. This project would be to build on his work.
      Specifically, the functionality needed is
      Path offset/inset functions.
      Path simplify.
      Stroke to path function.
      Line scanning (used for flowing text into a shape).
      Improvements to Paint Server Dialog
      Estimation of difficulty: Easy to Medium (175h)
      Potential mentors: Tavmjong
      Programming skills: C++
      Prerequisites: Some knowledge of GTK and CSS.
      Detailed Description: The Paint Server Dialog allows a user to visually select a pattern or hatch to use in painting the fill or stroke of an object. This project would be to expand the dialog to cover gradients, meshes, and solid colors as well as make other improvements to the dialog. Interaction with the Inkscape's UX team will be required.
      Improving UI of Live path effects
      Estimation of difficulty: Medium-Hard, Medium or Long depending on scope (175h or 350h)
      Potential mentors: Mike
      Programming skills: GTK 4, C++
      Prerequisites: Front end UI, familiarity with Live path effects
      Detailed Description: This project should implement the proposed UI clean up of controls. LPE controls should be more user friendly and predictive. Full Proposed designs
      Corners LPE Rotate copies LPE
      Recolor Artwork
      Estimation of difficulty: Variable - Short to Medium (90h or 175h)
      Potential mentors: Adam Belis ?
      Programming skills: C++
      Prerequisites:
      Detailed Description: An easy and convenient way how to change any color from the selection. Useful for experimenting and tweaking colors.
      Full proposal Here
      Use cases
      fast editing of color in whole project without the need for swatches
      easier way to make colors harmonize in a project
      Faster iteration and visioning of designs
      Python projects
      Import and Export extensions
      Estimation of difficulty: Flexible, usually easy to medium, Medium or Long depending on scope (175h or 350h)
      Potential mentors: Jonathan
      Programming skills: Python, Ability to read technical documents, depending on the format: some reverse engineering
      Prerequisites: minimal knowledge of test-driven development
      Detailed Description: Inkscape is alway looking to improve compatibility! Some ideas of relevant file formats - each of them more than enough for one GSoC:
      Refactor our DXF input and output extensions, and improve their test coverage / correctness
      Rewrite the XAML importer in Python (currenly XSLT) to match the capabilities of the new XAML exporter (i.e. support for different target frameworks, better text support...) - would have to select carefully what to support (drawing primitives) and what not (control elements) - the boundary is not as clear-cut as it seems.
      Update the Synfig export to support the latest Synfig developments
      Import or export of TikZ. There are a few abandoned extensions out there (from which we can borrow), but it's very widely used in science - both import and export could serve an important function in the scientific workflow. Related, import / export to Typst.
      Import of the proprietary fileformats of Vectornator (now Linearity Curve), Vectorstyler, Canva (users at some point will sit on a bunch of files that they can't open anymore because).
      Python based EMF / WMF importer - the current (core Inkscape) C extension is unmaintained and Python would probably be the right way to get more collaboration on it. A lot of public archives sit on mountains of EMF files. Note that the Document Foundation recently did a lot of work properly importing those files, so we can learn from them / maybe even join forces ...
      your favorite file format? - also have a look here: https://office.inkscape.org/nextcloud/index.php/s/Tq6cdDDGay6taCw
      Gcodetools refactoring and documentation
      Estimation of difficulty: Easy- Medium or Long depending on scope (175h or 350h)
      Potential mentors: Jonathan
      Programming skills: Python
      Prerequisites: Maker background / familiarity with the Maker community
      Detailed Description: Gcodetools is a set of Inkscape extensions that deal with reading and creating Gcode files, mostly for use in laser cutters or plotters. For this project, ideally someone with a Makerspace background will
      query maker spaces on their needs regarding gcodetools,
      implement those needs together with unit tests,
      improve the test coverage of Gcodetools,
      write proper documentation for it. (doesn't really exist at the moment).
      Packing / Nesting as an Inkscape extension
      Estimation of difficulty: Medium, Short or Long depending on scope (175h or 350h)
      Potential mentors: Jonathan
      Programming skills: Python
      Prerequisites: Computational geometry
      Detailed Description: In this project, a set of packing / nesting algorithms will be implemented:
      Linear nesting is not too useful in SVG, but might be a good place to get acquainted with the problem. 2D cutting stock problem would be very interesting to have and would work great with the new multipage functionality.
      For efficient packing of free form objects, we might just re-implement SVGNest in Python. There are probably some more recent research papers which would be interesting to implement as a comparison.
      Other
      Your project
      Estimation of difficulty: Variable - Variable (90h to 350h)
      Potential mentors: ask us!
      Programming skills: C++ or Python
      Prerequisites: good ideas
      Detailed Description: The most successful GSoC we had in the past were students coming with their own past, use cases and ideas for Inkscape. Many basic tools like 3d cubes or connectors you can see in Inkscape now have been brought by brilliant people (like you) with ideas. If we think that your project fits with Inkscape (ie: has its place with a vector graphic editor), we can help you refining your ideas and help bring shiny new stuff to life!
      Use cases
      Amaze us!
      Successful SOC Projects from Previous Years
      2005
      Connectors
      Inkboard
      Open Clip Art Library (OCAL) Interface
      DXF Import / Export
      2006
      Support for SVG Filters
      Filter Effects
      PDF export
      Inkboard Protocol Spec / Lib Conversion
      2007
      Text Style Improvements
      PDF import
      Live Path Effects
      3D Box Tool
      UI for SVG Filter Effects
      Raster Functionality
      Importing from, and Exporting to, a remote ccHost instance
      2008
      SVG Fonts support
      2Geom refactoring project - port most geometry code to 2Geom
      lib2geom: interactive applications showing off the power of lib2geom
      Tech drawing abilities
      A test suite
      2009
      Node tool rewrite
      D-Bus scripting API
      Connector tool improvements
      ICC/CMYK workflow
      2010
      Cairo-based rendering
      C++ification of SP Layer
      2011
      Rendering caching
      Javascript support improvements
      CSS support improvements
      2012
      Usibility Improvements for Guides
      On-canvas support for Tessellations
      Creating python bindings for lib2geom
      2013
      Recolor Tool
      Improved Units Support
      Electronics CAD Support
      New From Templates Dialog
      New Raster to Vector Algorithm
      2014
      Better Support for SVG Paints
      Robust Boolean and Stroking Operations for 2Geom
      2016
      Better data structure for selections, see also wiki page
      CSS Style Sheet Editor, see also wiki page
      2017
      SVG 2 Text Support
      Better CSS Style Sheet Support
      2019
      Mesh gradient and hatches polyfills
      2020
      New dialog system
      Command palette dialog
      Path operations documentation
      2021
      On-canvas marker editing
      Verbs to Gio::Actions conversion
      On canvas alignment snapping
      On-canvas interactive boolean operations - basis for the Shape builder Tool of Inkscape 1.2
      Website update to Django 2.x
      Rework of Export dialog, shipped in Inkscape 1.2
      2022
      Tab Structure
      Font Selections Improvement
      OCR Support
      2023
      GTK4 toolbar port preparation
      Customizable Appearance of Canvas Controls - shipped in Inkscape 1.4
      2024
      Support for .afdesign files, shipped in Inkscape 1.4
      Improving UX of Node and Bezier tools
      Node-based filter editing
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/inkscape/
    idea_list_url: https://gitlab.com/inkscape/inkscape/-/blob/master/doc/gsoc/summerofcode.md

  - organization_id: 63
    organization_name: International Catrobat Association
    no_of_ideas:
    ideas_content: |
      Ideas Page for Google Summer of Code 2025
      We are thrilled to share our carefully curated project ideas for this year’s Google Summer of Code.
      General Information
      These ideas are just some topics we came up with, where currently nobody is working on. However, Catrobat is a project with a wide range of possibilities and we’re aware of our blindspots: So let’s live the spirit of Open Source and come up with improvements (e.g., new features, extensions, …) that are related to the project and in which you’re interested in. We do have many senior contributors who would be happy to mentor such a project. Don’t be shy and check out the last point on the list: Your idea!
      General Knowledge Prerequisites for all Projects
      Knowledge in the usage of Git and GitHub
      Basic knowledge in the concepts of software testing (e.g., test doubles) and test-driven development
      Basic knowledge in app development (for Android and iOS projects)
      Java, JUnit, Mockito, Robotium and Espresso for Android development
      Swift and Objective C for iOS development
      Also please check that you have the proper hardware for the development (e.g., an Android/iOS smartphone for testing some of the projects, Mac for iOS development etc)
      Idea Overview
      Pocket Paint Flutter
      AI Mentor for PocketCode Students
      AI-Generated 3D Models from Marine Animals
      AR-Based Interactive Marine Ecosystem Simulation
      AI-Driven Adaptive Learning Module for Marine Biology
      Mobile Application for Marine Biology AR Learning
      Open-Source AR Toolkit for STEM Education
      Awesome Demo Game Project on Marine Biology
      Your own Project Ideas …
      Project Descriptions
      Pocket Paint Flutter
      350 HOURS
      Required Skills: Flutter, Dart, Android-Development, Agile Development
      Possible Mentors: Abdulbaki Celebi, Mario Kaurin, Julia Herold, Thorsten Bandel
      Expected Outcome: Features from Kotlin/Java version of Paintroid ported to new Flutter-based version
      Difficulty level: Medium to advanced
      The developer should have knowledge of Flutter. Develop and implement missing tools in Flutter that exist in our old Android app built with Android Native.
      AI Mentor for PocketCode Students
      350 HOURS
      Required Skills: Kotlin, Python, Android AI and ML Tools, Android-Development, Agile Development, Test Driven Development, Clean Code
      Possible Mentors: Paul Spiesberger, Patrick Ratschiller
      Expected Outcome: An integrated proof of concept AI mentor within PocketCode
      Difficulty level: Advanced
      AI is now capable of sophisticated programming and can automate many coding tasks. More importantly, it excels at explaining code to students, making learning more engaging and accessible. Our goal is to integrate an AI-powered mentor into PocketCode that understands a student’s programming context and offers real-time guidance to enhance learning and coding skills.
      The AI mentor could:
      Explain programming concepts, from variables and loops to software design patterns and testing strategies
      Suggest code from text prompts, help debug issues, and propose project ideas
      Assist in code architecture, naming conventions, and writing Catrobat language tests
      Explain and translate downloaded projects from other users
      You won’t need to implement everything—just focus on a part that excites you most! The Catrobat team will provide the initial prompt and necessary API access or local LLMs for support.
      AI-Generated 3D Models from Marine Animals
      350 HOURS
      Preferred Skills: Generative AI (Stable Diffusion, GANs, Autoencoders), 3D Modeling (Blender, Unreal Engine), Marine Biology Data Sources
      Possible Mentors: Krishan Mohan Patel, Himanshu Kumar
      Expected Outcome: Functionally coded 3D models
      Difficulty level: Medium
      This year’s focus of Catrobat includes topics around marine biology as an application area, and we have several projects around the general topic. This project will focus on developing AI-powered 3D models of marine species using generative AI techniques. By training machine learning models on marine biology datasets, realistic and interactive 3D assets of octopus, fish, corals, and other underwater species will be created for use in AR applications for teaching marine biology in high schools, where teachers and pupils will be able to “program” the simulated marine animals for learning purposes integrated into biology curricula. These models will adapt dynamically based on environmental conditions like depth, temperature, and biodiversity levels.
      AR-Based Interactive Marine Ecosystem Simulation
      350 HOURS
      Preferred Skills: AR Development (Unity, ARKit, ARCore), Physics-Based Ecosystem Simulations, AI-Powered Content Adaptation
      Possible Mentors: Himanshu Kumar, Aryavardhan Sharma
      Expected Outcome: AR simulation code
      Difficulty level: Advanced
      This year’s focus of Catrobat includes topics around marine biology as an application area, and we have several projects around the general topic. This project will develop an immersive AR simulation that allows users to explore marine ecosystems and understand ecological interactions. Students will be able to visualize food chains, coral reef dynamics, and the effects of pollution through real-time AR simulations. This project aims to provide an engaging, hands-on learning experience for STEM education.
      AI-Driven Adaptive Learning Module for Marine Biology
      350 HOURS
      Preferred Skills: AI for Adaptive Learning (Reinforcement Learning, NLP), Educational Gamification Techniques, Data Analytics for User Behavior Tracking
      Possible Mentors: Aryavardhan Sharma, Supreeth M Kumar
      Expected Outcome: AI-based machine learning module
      Difficulty level: Advanced
      This year’s focus of Catrobat includes topics around marine biology as an application area, and we have several projects around the general topic. This project will implement an AI-driven adaptive learning system that customizes educational content based on student engagement and progress. The system will analyze user interactions, quizzes, and exploration patterns to personalize the learning path, ensuring a more effective and engaging experience. We will provide remote access to hardware on which the learning algorithms can be executed.
      Mobile Application for Marine Biology AR Learning
      350 HOURS
      Preferred Skills: Mobile AR Development (Flutter, React Native), UI/UX Design for Interactive Learning, Voice & Gesture Recognition
      Possible Mentors: Supreeth M Kumar, Paul Spiesberger
      Expected Outcome: Mobile AR app
      Difficulty level: Advanced
      This year’s focus of Catrobat includes topics around marine biology as an application area, and we have several projects around the general topic. This project will focus on developing a mobile AR application that allows students to access interactive marine biology lessons anywhere. The app will support gesture-based interaction, voice commands, and real-time exploration of AI-generated underwater environments, making STEM education more accessible.
      Open-Source AR Toolkit for STEM Education
      350 HOURS
      Required Skills: Open-Source Development (GitHub, API Integrations), Modular AR Content Framework, Cross-STEM Applications (Physics, Chemistry, Earth Science).
      Possible Mentors: Wolfgang Slany, Krishan Mohan Patel
      Expected Outcome: AR toolkit / STEM
      Difficulty level: Medium
      This year’s focus of Catrobat includes topics around marine biology as an application area, and we have several projects around the general topic. This project will create a modular, open-source AR framework that educators and developers can use to extend AR-based learning into other STEM domains. The toolkit will include pre-built 3D models, AI-based interactive features, and an easy-to-use interface for educators to integrate AR content into their curriculum.
      Awesome Demo Game Project on Marine Biology
      350 HOURS
      Required Skills: Coding Basics
      Possible Mentors: Selina Ernst, Wolfgang Slany
      Expected Outcome: Catrobat Demo Game on Marine Biology
      Difficulty level: Beginner
      Spend the whole GSoC time developing and designing a demo game. This year’s focus of Catrobat includes topics around marine biology as an application area, and we have several projects around the general topic. The present project aims at inspiring young people to become aware of topics related to the protection of marine habits by creating related video games of their own. If you have your own original idea about a game around this topic, please feel free to suggest it. Please note that the demo game will be published under Catrobat’s free open source license, and that the game will thus become part of the Catrobat FLOSS project’s source code. Thus, all artwork, sounds, character names etc must be compatible with our licenses, i.e., freely publishable under our licenses, the AGPL version 3 and CC BY-SA 4.0, or under a compatible, possibly even freer license such as CC0.
      Your own Project Ideas …
      90, 175 OR 350 HOURS
      Required Skills: Kotlin, Java, Android-Development, iOS-Development, Agile Development
      Requirement: self-organized work
      Difficulty level: advanced
      In the last years we found that you have many great ideas and knowledge! We’re aware that there are many ways how to improve performance, reduce memory usage, make our services more stable and of course the code easier to maintain. We’re sure you do have ideas how to achieve this, although we may have never heard of this approach before -> that’s the great thing about Open Source! And well, that’s also the experience we made at last year’s GSoC - and we liked it!
      Also new features or extensions for iOS and Android are welcome to be introduced to us. Help us to spread coding and Open Source!
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/international-catrobat-association/
    idea_list_url: https://developer.catrobat.org/pages/development/google-summer-of-code/2025/

  - organization_id: 64
    organization_name: Internet Archive
    no_of_ideas:
    ideas_content: |
      Internet Archive - Google Summer of Code 2025 - Call For Proposals (CFP)
       Request edit access
       Share
      Sign in
      FileEditViewToolsHelp
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/internet-archive/
    idea_list_url: https://docs.google.com/document/d/1oHNwPNYmHV5q3puBfv6IQFs-4gTe9XLN2iz2Lgse-1k/edit?tab=t.0

  - organization_id: 65
    organization_name: Internet Health Report
    no_of_ideas:
    ideas_content: |
      List of ideas for projects
      Information for Students
      Make sure you have read the IHR contributor handbook
      The below ideas were contributed by current IHR contributors. They are sometimes vague or incomplete. Questions related to these ideas should be asked on the related GitHub discussion thread.
      Becoming accepted as a Google Summer of Code student is quite competitive. Accepted students typically have thoroughly researched the topic of their proposed project and have been active in the discussions. Simply copying and pasting an idea here will not work. On the other hand, creating a completely new idea without first consulting potential mentors also rarely works.
      Also keep in mind that these are just proposals, we are open to new ideas you might have! Do you have an awesome idea you want to work on for IHR, but that is not among the ideas below? That's cool. We love that! Please get in touch with a mentor early on and make sure your project is realistic and within the scope of IHR.
      If there is no specific contact given you can ask questions on github, slack, or at admin@ihr.live.
      List of ideas
      IHR Status Page
      Brief explanation: Things breaks easily, so we need a status page that tells us which services are running as usual and which one are not. This page could also provide a machine-readable JSON object so that we can automate email alerts when something is not running as usual. It would also be nice to keep historical availability data.
      We provide datasets in different formats (e.g., RUST API, files on an FTP server), which need to be monitored. Thus, there can be different liveness checks, e.g., that an API responds (and also gives results), that a file exists, etc.
      The project should use, or build on top of, an existing monitoring solution, should be maintainable, and extendable if we add new datasets in the future.
      Expected results:
      Find a suitable monitoring tool that can be used as a base for this project
      Implement a status page for all API endpoints and results, websites (ihr, ihr-archive, iyp), and the IYP database
      Add a machine-readable format of the page
      Automatic email notification when something is down
      Github discussion: https://github.com/orgs/InternetHealthReport/discussions/51
      Knowledge Prerequisite:
      Overview of the IHR ecosystem, see Resources below
      Docker
      Web development experience
      Resources:
      https://github.com/InternetHealthReport/
      IHR API
      IHR Archive
      IYP website
      IYP database
      Project size: 90 hours
      Difficulty: Easy
      Contact: Dimitrios Giakatos (dimitrios@iij.ad.jp), Malte Tashiro (malte@iij.ad.jp), Romain Fontugne (romain@iij.ad.jp)
      Migrate IHR API
      Brief explanation: All results displayed on the Internet Health Report website are accessible via the IHR REST API. The current codebase is developed on an outdated version of Django (2.2.27), which is no longer supported, and we are not utilizing all of Django's features. Therefore, instead of just upgrading the Django version, we plan to migrate the codebase from the complex Django framework to a simpler framework, such as FastAPI. Additionally, the current Django framework includes code for initializing/managing the database. This time, we want to implement Bash scripts for initializing/managing the database, which will result in better maintenance.
      Expected results:
      Migrate all Django endpoints to FastAPI
      Convert the database code from Django to Bash scripts
      Dockerize the application (excluding the Bash scripts, which will be run as is)
      Github discussion: https://github.com/orgs/InternetHealthReport/discussions/58
      Knowledge Prerequisite:
      Django (to understand the current codebase)
      FastAPI
      SQL
      Docker
      Resources:
      https://github.com/InternetHealthReport/ihr-django
      https://docs.djangoproject.com/en/2.2/
      https://fastapi.tiangolo.com/
      https://learnscripting.org/streamlining-database-operations-running-sql-queries-from-a-shell-script/
      Project size: 175 hours
      Difficulty: Medium
      Contact: Romain Fontugne (romain@iij.ad.jp), Dimitrios Giakatos (dimitrios@iij.ad.jp)
      Improve the IHR Website Codebase
      Brief explanation: The IHR website provides outputs from IHR research projects through a simple and user-friendly web interface. Its current codebase is large and contains many features. This time, instead of adding new features, we will focus on improving the existing ones. The goal of this project is to refactor certain components to enhance reusability.
      Expected results:
      Refactor the codebase
      Improve reusability
      Github discussion: https://github.com/orgs/InternetHealthReport/discussions/47
      Knowledge Prerequisite:
      VueJS
      JavaScript
      CSS
      HTML
      Resources:
      https://github.com/InternetHealthReport/ihr-website
      Project size: 175 hours
      Difficulty: Medium
      Contact: Dimitrios Giakatos (dimitrios@iij.ad.jp)
      IYP Browser
      Brief explanation: The Internet Yellow Pages (IYP) is a knowledge database that aggregates information about various Internet resources, such as ASNs, IP prefixes, and domain names. Currently, we use the Neo4J browser to query the graph, which returns results in four formats: an interactive graph, a table, a raw table, and a JSON object. To enhance the user experience, especially for those unfamiliar with Cypher, we have developed an LLM model and will provide an API to simplify the querying process. Our goal is to develop a new browser that allows users to input either a Cypher query (using the Neo4J API) or an English description (using our LLM API) of the results they wish to obtain from the database. Additionally, we aim to continue providing the default four output formats along with explanations generated by our LLM API.
      Expected results:
      Design a user-friendly, maintainable browser that connects to both the Neo4J API and our LLM API (frontend only, no backend)
      Implement a graph visualizer similar to that of the Neo4J browser
      Implement a data table viewer similar to that of the Neo4J browser
      Allow users to input either a Cypher query or a natural language description
      Provide the LLM-generated explanation text (from our LLM API) alongside the graph visualizer and/or data table viewer
      Github discussion: https://github.com/orgs/InternetHealthReport/discussions/50
      Knowledge Prerequisite:
      Neo4J
      Javascript
      VueJS
      NVL (Neo4j Visualization Library)
      Quasar
      Resources:
      https://github.com/InternetHealthReport/internet-yellow-pages
      http://iyp.iijlab.net/
      https://neo4j.com/docs/nvl/current/
      https://www.npmjs.com/package/@neo4j-nvl/base
      https://neo4j.com/docs/getting-started/graph-visualization/graph-visualization/
      Project size: 175 hours or 350 hours
      Difficulty: Medium
      Contact: Dimitrios Giakatos (dimitrios@iij.ad.jp), Malte Tashiro (malte@iij.ad.jp), Romain Fontugne (romain@iij.ad.jp)
      Traceroute visualization (continuation of GSoC'24)
      Brief explanation: Operators would like to have a better way to visualize latency increases in upstream networks. We have a lot of traceroute data from RIPE Atlas but we miss a good visualization to show traceroute details. The goal of this project is to design and implement a page on IHR to visualize traceroute results from RIPE Atlas. There is some good tools to get inspired from (tracemon and thousand eyes path visualization, having our own would be great so we can integrate it with other tools (e.g. IYP, AS Hegemony).
      Expected results:
      Create a VueJS component that fetch traceroute results from RIPE Atlas
      Display the results in intuitive graphs, showing the IP paths and corresponding RTT values
      Integrate with IYP data
      Github discussion: https://github.com/orgs/InternetHealthReport/discussions/59
      Knowledge Prerequisite:
      Be familiar with existing traceroute code
      Good understanding of traceroute
      Javascript
      VueJS
      Visualization library (i.e. Plotly or D3.js)
      Resources:
      https://www.ihr.live/en/traceroute-monitor
      https://github.com/InternetHealthReport/ihr-website/blob/master/src/views/TracerouteVisualizationTool.vue
      https://atlas.ripe.net/
      https://labs.ripe.net/author/massimo_candela/tracemon-network-debugging-made-easy/
      Project size: 350 hours
      Difficulty: Hard
      Contact: Romain Fontugne (romain@iij.ad.jp), Malte Tashiro (malte@iij.ad.jp), Dimitrios Giakatos (dimitrios@iij.ad.jp)
      Proposal template
      Project
      If appropriate, screenshot or another image
      Brief explanation:
      Expected results:
      Github discussion: https://github.com/orgs/InternetHealthReport/discussions/
      Knowledge Prerequisite:
      Resources:
      https://github.com/InternetHealthReport/
      Project size: 175 hours or 350 hours
      Difficulty: Easy / Medium / Hard
      Contact: (your name and email address for contact)
      Content based on https://community.kde.org/GSoC and available under Creative Commons License SA 4.0
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/internet-health-report/
    idea_list_url: https://github.com/InternetHealthReport/gsoc/blob/main/ideas.md


  - organization_id: 66
    organization_name: Invesalius
    no_of_ideas:
    ideas_content: |
      GSoC 2025 Ideas for InVesalius
      See also the instructions for applying here.
      All the current ideas for GSoC 2025 are listed bellow:
      Add unit tests to InVesalius to ease the process of adding new features
      Use tools like unittest or pytest to add tests to InVesalius code. That way, when adding new features or bug fixes, you can verify that no previous code has been affected. Also run this code when committing and sending pull requests on Github.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies.
      Deliverables:
      Unit tests in InVesalius code
      Github-CI action for running tests when committing or posting a pull-request
      Programming Languages: Python and YAML
      Duration: 175h
      Difficulty level: Intermediate
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com
      References: invesalius/invesalius3#496 and https://realpython.com/python-testing/
      Add type information to functions, methods and classes in InVesalius
      Since python 3.5 it is possible to add type information to the parameters of functions, methods and classes. With this information it is possible to use tools like Mypy to catch calls made with the wrong type. This way you can avoid errors and make your code easier to maintain and grow
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies.
      Deliverables:
      Type information added to InVesalius functions, methods and classes.
      Github-CI action for catching type errors using tools like Mypy
      Programming Languages: Python and YAML
      Duration: 175h
      Difficulty level: Intermediate
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com
      References: invesalius/invesalius3#497, https://docs.python.org/3/library/typing.html and https://mypy-lang.org/
      Add logging and error catching tool
      Tool that allows the user to activate the capture of logs and errors. It should be possible to save the sequence of events in a text file. It will be necessary to add logging capture to all functions and functionalities and their respective levels (debug, info, warn, error or critical).
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies.
      Deliverables:
      Graphic interface integrated to InVesalius that allows the user to activate the tool and save the logs.
      Log support to all InVesalius functions and functionalities.
      Programming Languages: Python
      Duration: 350h
      Difficulty level: Hard
      Mentor: Paulo Henrique Junqueira Amorim - paulojamorim@gmail.com
      References: invesalius/invesalius3#498, https://docs.python.org/3/library/logging.html and https://realpython.com/python-logging/
      Implement UX principles to improve InVesalius usability
      The neuronavigation feature of InVesalius currently does not follow user experience (UX) principles in the user interface and workflow design. The software usability can be significantly improved by applying the basic UX design principles.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies.
      Deliverables:
      Description and documentation of the neuronavigation workflow
      Refactored neuronavigation user controls and settings
      Programming Languages: Python
      Duration: 350h
      Difficulty level: Hard
      Mentor: Victor Hugo Souza - vhosouza@gmail.com
      References: invesalius/invesalius3#506
      Performance optimization of real-time neuronavigation
      The real-time neuronavigation feature of InVesalius currently works based on multi-threading using Queues, Events, and Jobs (look at #242). Optimization (utilizing the least memory, minimizing its CPU time, and offering high speed) is needed to improve neuronavigation performance.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of computer graphics.
      Deliverables:
      Characterize step-by-step code execution time for neuronavigation
      Improve threads’ sleep times
      Investigate: WX GUI becomes slower when navigation is on
      Optimize 3D rendering/updating scene
      Programming Languages: Python
      Duration: 350h
      Difficulty level: Hard
      Mentor: Victor Hugo Souza - vhosouza@gmail.com
      References: invesalius/invesalius3#529 and invesalius/invesalius3#242
      3D edition of masks
      User can edit a mask in InVesalius slice by slice. That is a very repetitive and error prone job. Since InVesalius has 3D visualizations, it's possible to draw over the rendering area and remove the voxels projected in the painted areas.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of computer graphics.
      Deliverables:
      Tool to edit masks using projections.
      Programming Languages: Python
      Duration: 350h
      Difficulty level: Hard
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com
      References: invesalius/invesalius3#91 and https://en.wikipedia.org/wiki/3D_projection
      Harmonize and revamp the cross-platform user interface over MacOS, Linux, and Windows
      Currently, the InVesalius interface is not properly designed for different modes (Light and Dark) mode, especially on MacOS, for example.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of computer graphics.
      Deliverables:
      Unify the color scheme to different modes (light and dark)
      Apply standard and default colors to UI components
      Adjust component sizing that are disrupted across platforms
      Introduce modern icons
      Programming Languages: Python
      Duration: 175h
      Difficulty level: Intermediate
      Mentor: Petrus Kirsten - petrus.kirsten@gmail.com / Victor Malheiro - victorhugomalheiro@gmail.com
      Surface texture
      Add texture to a surface based on the image tissue.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of computer graphics.
      Deliverables:
      Tool to set a texture to a surface.
      Programming Languages: Python
      Duration: 350h
      Difficulty level: Hard
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com
      References: https://en.wikipedia.org/wiki/Texture_mapping
      Extract surface using Dual contouring
      InVesalius uses Marching Cubes to extract surface from volumetric images. It's interesting to have other methods like Marching Tetrahedra and Dual Contouring.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of computer graphics.
      Deliverables:
      Tool to generate surfaces using other methods than Marching Cubes.
      Programming Languages: Python and Cython
      Duration: 350h
      Difficulty level: Hard
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com
      References: https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/ https://en.wikipedia.org/wiki/Marching_tetrahedra https://en.wikipedia.org/wiki/Isosurface
      Improvements in user response (loading and saving files)
      When saving or loading files (except DICOM), InVesalius does not provide any feedback to the user. The goal of this task is to implement a window that displays the progress when loading or saving the different types of files that InVesalius handles. This task also includes replacing the progress bar of the volume rendering functionality.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background in GUI.
      Deliverables:
      Windows with progress bar for the functionalities specified in the referenced issues (references).
      Programming Languages: Python
      Duration: 90h
      Difficulty level: Easy
      Mentor: Paulo Henrique Junqueira Amorim - paulojamorim@gmail.com
      Use Github Actions to create installers for macOS
      Github Actions is used for various softwares to run tests when a commit or pull request is submitted. Also, it can be used to compile software and create binaries ready to be used by the users. The idea in this task is to use Github Actions to create nightly and release InVesalius installers for macOS.
      Requirements: Computer with Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies.
      Deliverables:
      Github action to create nightly and release installers for InVesalius for macOS.
      Programming Languages: Python
      Duration: 175h
      Difficulty level: Intermediate
      Mentor: Paulo Henrique Junqueira Amorim - paulojamorim@gmail.com and Thiago Franco de Moraes - totonixsame@gmail.com
      References: https://docs.github.com/en/actions https://pyinstaller.org/en/stable/
      Convert from Pytorch to ONNX or Tinygrad
      InVesalius uses Pytorch framework to create machine learning based segmentation. The problem is Pytorch is a very large library which makes InVesalius installer and packages very large too. Also, Pytorch has some features not used by InVesalius. ONNX is a format to export machine learning models and a library too. Tinygrad is simple library alternative to Pytorch. Both ONNX and Tinygrad are smaller and enough to InVesalius use.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of Machine Learning and AI.
      Deliverables:
      Conversion of tool using Pytorch to ONNX or Tinygrad.
      Programming Languages: Python
      Duration: 175h
      Difficulty level: Intermediate
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com and Paulo Henrique Junqueira Amorim - paulojamorim@gmail.com
      References: https://github.com/tinygrad/tinygrad and https://onnx.ai/
      Convert from Pip and Conda to UV
      InVesalius uses Pip with requirements.txt. There is also a Conda environment. UV is a fast modern alternative that uses pyproject.toml and other modern Python standards and also can manage Python versions.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies.
      Deliverables:
      Conversion to UV and using documentation
      Conversion of Cython compilation to use pyproject.toml
      Programming Languages: Python
      Duration: 90h
      Difficulty level: Easy
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com and Paulo Henrique Junqueira Amorim - paulojamorim@gmail.com
      References: https://github.com/astral-sh/uv
      Segment brain in its subparts
      Use Machine Learning (like https://deep-mi.org/research/fastsurfer/) or an atlas (like https://yalebrainatlas.github.io/YaleBrainAtlas/) or both to segment brain subparts in MRI images. Segmentation of brain subparts in MRIs is crucial for precise targeting in Transcranial Magnetic Stimulation (TMS). It enables accurate identification of specific brain regions, ensuring stimulation is applied to the correct areas for optimal effectiveness. Proper placement of the TMS coil is essential, and with segmented MRI data, the coil’s position can be precisely aligned with the target brain regions.
      Requirements: Computer with Windows, Linux or Mac OS installed. A source code editor, Python language and InVesalius libraries dependencies. Good background of Machine Learning and AI.
      Deliverables:
      Tool to segment brain in its subparts.
      Model weights (if used AI).
      Programming Languages: Python
      Duration: 350h
      Difficulty level: hard
      Mentor: Thiago Franco de Moraes - totonixsame@gmail.com and Paulo Henrique Junqueira Amorim - paulojamorim@gmail.com and Renan Matsuda – renan_hiroshi@hotmail.com
      References: https://yalebrainatlas.github.io/YaleBrainAtlas/ and https://deep-mi.org/research/fastsurfer/
      Simultaneous visualization and control of Two Robots for Dual Transcranial Magnetic Stimulation
      Development and integration of the functionality for simultaneous control of two robots, aimed at applying dual-site Transcranial Magnetic Stimulation (TMS) in InVesalius (currently, support is provided for only one TMS coil attached to one robot). This feature is based on the existing implementation for the use of two or more coils, adapting it for multiple robots. The inclusion of this feature not only improves the speed, accuracy, and safety of the stimulatory process, but also enables the scientific exploration of interactive brain networks, by allowing concurrent, targeted TMS pulses to multiple brain areas.
      Requirements: Computer with Windows, Linux, or Mac OS installed. Python programming language and InVesalius library dependencies. A source code editor.
      Deliverables:
      Visualization interface showing the robots' movements integrated into the InVesalius neuronavigation system.
      Coordinate communication between the websocket data receiver, InVesalius brain targets, and GUI.
      Software module for control and synchronization of the two robots.
      Programming Languages: Python
      Duration: 350h
      Difficulty Level: Hard
      Mentor: Renan Matsuda - renan_hiroshi@hotmail.com and Thais Marchetti - thaismarchetti123@gmail.com and Lucas Betioli - lucasantoniobetioli@gmail.com and Victor Malheiro - victorhugomalheiro@gmail.com
      References:
      Neuronavigation: Track multiple coils simultaneously and show stylus/probe #827
      Robot control: https://github.com/biomaglab/tms-robot-control
      Implement neuronavigation capability for transcranial focused ultrasound (tFUS)
      Development and integration of the functionality for neuronavigation of transcranial focused ultrasound transducers (tFUS). InVesalius currently supports only neuronavigation for Transcranial Magnetic Stimulation (TMS) coils. We aim at extending the support to tFUS, which is becoming an important neuromodulation tool to study and and interact with brain function non-invasively. This new feature will significantly extend the user based on InVesalius to support accurate and reproducible neuroscience.
      Requirements: Computer with Windows, Linux, or Mac OS installed. Python programming language and InVesalius library dependencies. A source code editor.
      Deliverables:
      Visualization interface for coregistration of tFUS transducers.
      Targeting and guiding interface for tFUS.
      Minor adjustment to UI/UX considering the tFUS user requirements.
      Programming Languages: Python
      Duration: 350h
      Difficulty Level: Hard
      Mentor: Victor H. Souza - vhosouza@gmail.com and Renan Matsuda - renan_hiroshi@hotmail.com and Victor Malheiro - victorhugomalheiro@gmail.com
      References:
      Neuronavigation: Track multiple coils simultaneously and show stylus/probe #827
      tFUS: tFUS Basics
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/invesalius/
    idea_list_url: https://github.com/invesalius/gsoc/blob/main/gsoc_2025_ideas.md


  - organization_id: 67
    organization_name: JAX and Keras
    no_of_ideas:
    ideas_content: |
      Summer of Code 2025: JAX & Keras Project Ideas
       Request edit access
      +2
       Share
      Sign in
      FileEditViewToolsHelp
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/jax-and-keras/
    idea_list_url: https://docs.google.com/document/d/16uAZEldrXUBHjrszSO22Hr81OmVSjzVXza0szZl6Fxw/edit?usp=sharing

  - organization_id: 68
    organization_name: JSON Schema
    no_of_ideas:
    ideas_content: |
      Welcome to Google Summer of Code 2025 with JSON Schema!
      We are thrilled to announce that JSON Schema will be applying as a mentoring organization for the 2025 Google Summer of Code (GSoC). If accepted, we look forward to collaborating with talented contributors from around the world to advance the field of JSON Schema and open-source technology.
      Timeline and Project Ideas
      The official GSoC 2025 timeline is now live, and our project ideas are on the way! Stay tuned for updates and get ready to explore exciting opportunities to contribute to meaningful, real-world projects.
      Full timeline
      Important dates Deadline
      Organization Applications Open January 27, 2025
      Organization Application Deadline February 11, 2025
      Organizations Announced February 27, 2025
      Potential GSoC contributors discuss application ideas with mentoring organizations February 27 - March 24, 2025
      GSoC contributor application period March 24 - April 8, 2025
      Accepted GSoC Contributor projects announced May 8, 2025
      Contributors work on their Google Summer of Code projects June 2, 2025 - August 25, 2025
      Mentors submit final GSoC contributor evaluations (standard coding period) September 1, 2025 - September 8, 2025
      Initial results of Google Summer of Code 2024 announced September 3, 2025
      Project Ideas
      Here is the list of our 2025 project ideas:
      #874: GSOC 2025 : Build a Java wrapper library for sourcemeta/blaze
      #870: GSoC 2025: Better JSON Schema Errors
      #857: GSoC 2025: Investigating Schema Normalization
      #856: GSoC 2025: Comprehensive JSON Schema linting for encouraging best practices and catching anti-patterns early
      #872: GSOC 2025 : Automated Badge Issuance System For Tour
      #859: GSoC 2025: Adaption of component library in JSON Schema website
      Looking for mentors:
      #868: GSOC 2025 : JSON Schema Visualization Tool - Interactive Graphical Viewer
      Why Choose a JSON Schema Project?
      JSON Schema is a widely adopted and powerful tool in the developer ecosystem. Some of the most active members today joined because of their participation in past GSoC editions, which is a clear evidence of how positive the experience has been for them. Our mentors have extensive mentoring experience, you will have the best support before, during and after the program.
      Contributing to a JSON Schema project offers:
      Real-World Impact: Your work will influence the global developer community.
      Skill Development: Gain hands-on experience with cutting-edge technology and improve your software development skills.
      Collaborative Learning: Work closely with experienced mentors and a welcoming community.
      Professional Growth: Build your network, receive guidance, and showcase your contributions at community events.
      Financial Support: Participants receive a stipend from Google for their contributions.
      How to Apply
      Details about our projects, qualification tasks, and application guidelines will be shared soon. In the meantime, prepare by:
      Familiarizing yourself with JSON Schema.
      Engaging with the community via GitHub and Slack.
      Exploring past GSoC projects to understand the process.
      Getting in Contact
      GitHub: Please use Issues to comment on project ideas, ask questions and collaborate.
      Slack: Please join us in our slack workspace. All GSoC discussions are are hapenning in the #gsoc channel.
      Please see our Code of Conduct
      Getting Help
      Got a problem? Reach out to mentors or the community for assistance. Remember, mentors are listed, but other community members can also lend a hand. When talking to non-mentors:
      Introduce yourself.
      Discuss tasks based on personal interest, not just the contest.
      Explain technical decisions independently.
      Consult mentors for guidance on task evaluation.
      🫶 How to get involved before GSoC?
      If you join our organization before GSoC, we invite you to join us contributing to JSON Schema as a great way to start engaging with the Team, learn about the JSON Schema specification and get to know some of our projects.
      Please check out our Contribution guidelines to know more about how to contribute in each area.
      🏗 GSoC Contributor Guidance
      Please, check-out the GSoC Contributior Guidance
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/json-schema/
    idea_list_url: https://github.com/json-schema-org/community/blob/main/programs/mentoring/gsoc/gsoc-2025.md


  - organization_id: 69
    organization_name: JabRef e.V.
    no_of_ideas:
    ideas_content: |
      JabRef in Google Summer of Code 2025
      JabRef is a powerful, open-source, cross-platform citation and reference management tool designed to help researchers stay organized and efficient. With JabRef, you can effortlessly collect, organize, and manage your literature sources, giving you more time to focus on what truly matters: your research.
      By contributing to JabRef, you contribute to advancing global research. Trusted by over 10,000 researchers worldwide, JabRef plays a vital role in shaping the future of academic and scientific discovery. Your skills and creativity can help push the boundaries of what JabRef can achieve.
      Built in Java, JabRef is designed with a strong emphasis on high-quality, modern, and maintainable code. As a contributor, you’ll have the opportunity to enhance your technical skills, deepen your understanding of Java development, and learn best practices in open source collaboration. Whether you're a beginner or an experienced developer, working on JabRef will help you grow as a programmer while making a meaningful impact on a tool that supports researchers around the globe.
      We are passionate about open source and pride ourselves on fostering collaboration within a diverse and inclusive community. JabRef is dedicated to providing a welcoming environment for newcomers to open source, making it an ideal starting point for anyone eager to contribute. With four successful years of Google Summer of Code (GSoC) participation, we’ve achieved significant milestones in enhancing JabRef as a user-friendly research tool. Each project has been a meaningful step toward empowering researchers worldwide. As a GSoC participant with JabRef, you'll have the opportunity to grow your technical skills, coding expertise, and open source experience. Beyond the invaluable learning, participants receive a stipend from Google and gain access to a global professional network that can open doors for their future.
      Below, you’ll find some project ideas to inspire your contributions to JabRef through GSoC. We’ve also included links to provide more background information and context.
      Links
      What is Google Summer of Code?
      GSoC timeline
      latest proposal deadline: TBA
      coding until: TBA 18:00 UTC (can be extended under conditions)
      GSoC stipends: starting at 750 USD, depending on the country.
      Google's guide on making first contact
      Checklist for items contained in the proposal
      Google's guide on wrting a good proposal
      (All summarized information is tentative. The definitive information is on the linked pages.)
      Projects
      This page lists a number of ideas for potential projects to be carried out by the persons participating in Google Summer of Code 2025. This is by no means a closed list, so the possible contributors can feel free to propose alternative activities related to the project (the list of feature requests and the GitHub issue tracker might serve as an additional source of inspiration). Students are strongly encouraged to discuss their ideas with the developers and the community to improve their proposal until submission (e.g., using the Gitter Channel or the forum). It's also a good idea to start working on one of the smaller issues to make yourself familiar with the contribution process. Successful pull requests increase the chance of being accepted as a mentee.
      Improve handling of ancient documents by OCR and AI
      JabRef, a comprehensive literature management software, currently supports both handling metadata and text-based PDF documents. However, a significant limitation arises with scanned PDFs, particularly historical articles, which are not text-searchable due to their image-based format. This project aims to bridge this gap by integrating advanced OCR (Optical Character Recognition) technology, enabling full-text search in scanned PDFs.
      Useful links:
      A Document AI Package: https://github.com/deepdoctection/deepdoctection
      Hand-written text recognition in historical documents: https://github.com/githubharald/SimpleHTR#handwritten-text-recognition-with-tensorflow
      Java OCR with Tesseract: Baeldung Guide
      OCRmyPDF Installation and Usage: GitHub Repository
      ChatOCR and ChatGPT Integration: Blog Article
      AI-Powered OCR: Addepto Blog
      Tika OCR Integration: Apache Tika Wiki
      Tesseract OCR Library: Official Documentation
      Surya AI powered SOTA OCR, better than Tesseract but coded in python https://github.com/VikParuchuri/surya
      Some aspects:
      Add an option to call an OCR engine from JabRef, e.g., cloud based or local installs
      Define a common interface to support multiple OCR engines
      Provide a good default set of settings for the OCR engines
      Support expert configuration of the settings
      Add the extracted text as a layer to the pdf so that Apache Lucene can parse it
      Add an option to further process the text with Grobid for training and metadata extraction
      Expected outcome:
      A) Develop a common interface within JabRef to accommodate multiple OCR engines, ensuring flexibility and expandability. B) Enable expert users to fine-tune OCR settings, catering to specific needs or document formats.
      C) Incorporate the OCR-extracted text as a searchable layer in PDFs, allowing Apache Lucene to index and look for the content.
      Skills required:
      Proficiency in Java programming.
      A keen interest and curiosity in document processing and AI technologies.
      Possible mentors:
      @Siedlerchr, @InAnYan, @calixtus
      Project size:
      175h (medium)
      Integrating JabRef's Integrity Check with VS Code via Language Server Protocol (LSP)
      Synopsis
      JabRef is a widely used open-source reference manager supporting BibTeX and BibLaTeX. One of its features is the Integrity Check, which helps users identify potential issues in their bibliographic entries. This project aims to leverage JabRef's Integrity Check to provide real-time feedback in Visual Studio Code (VS Code) by implementing a Language Server Protocol (LSP)-based extension.
      Benefits to the Community
      Currently, users rely on JabRef’s graphical interface to run integrity checks manually. By integrating these checks into VS Code, users can receive immediate feedback while editing BibTeX/BibLaTeX files, improving the quality of bibliographic data and ensuring compliance with best practices. The integration will also make JabRef’s functionality more accessible to users who prefer VS Code for LaTeX editing.
      Deliverables
      A VS Code extension that communicates with an LSP server to analyze BibTeX/BibLaTeX files.
      An LSP server that integrates JabRef’s Integrity Check and returns structured diagnostics (e.g., warnings and errors).
      Real-time feedback in VS Code’s Problems panel, highlighting issues in bibliography files.
      Unit tests and documentation to ensure maintainability and ease of use.
      Technical Details
      The LSP server will be implemented in Java, leveraging JabRef’s existing Integrity Check logic.
      The VS Code extension will be written in TypeScript and communicate with the LSP server.
      Diagnostics will be provided in real-time as users edit .bib files.
      Optional: Quick fixes for common integrity issues.
      Related work: https://plugins.jetbrains.com/plugin/9473-texify-idea offers BibTeX error reporting in IntelliJ idea.
      Expected Outcomes
      By the end of GSoC, the VS Code extension should be functional and capable of detecting integrity issues in .bib files. The project will enhance the JabRef ecosystem by expanding its usability in modern LaTeX workflows.
      First steps
      Get to know to Check Integrity
      Try to convert the result of the check integrity to errorformat: file:col:line: message
      Serve the error format file using efm-langserver
      Then, you have an initial skilset on the JabRef API and language servers. then, you can include an LSP into JabRef.
      Skills Required
      Java (for LSP server and integration with JabRef)
      TypeScript (for VS Code extension development)
      Experience with Language Server Protocol (LSP) is a plus
      Familiarity with LaTeX/BibTeX/BibLaTeX is beneficial
      Possible mentors:
      @koppor, @calixtus
      Project size:
      175h (medium)
      Welcome Walkthrough
      This project aims to create an engaging and informative first start screen for JabRef, enhancing the initial user experience and showcasing the best features of the software. This screen will differ from the standard interface displayed when no database is open, providing a tailored introduction for new users.
      Moreover, this project aims for adding various walkthrouhgs through JabRef's features: Users should be guided to the interesting features of JabRef (instead of having to read the the documentation)
      For walkthroughts, read on at https://www.appcues.com/blog/the-5-best-walkthrough-examples.
      Hints on the welcome tab
      Configuration of Paper Directory:
      Implement a feature allowing users to easily set up and manage their paper directory.
      This should include a dialog asking for a directory if none is set.
      Integration of Online Services:
      Include options for update checks, connecting with online services like Grobid, fetchers, and full-text search capabilities.
      Incorporate telemetry features with a clear and concise privacy statement.
      Creation of Example Library:
      Develop a feature to create an example library, helping new users quickly understand JabRef's functionality.
      Community Engagement Tools -> https://github.com/JabRef/jabref/pull/12461#issuecomment-2708900164
      Add links to the JabRef forum for support and Mastodon for community interaction.
      Donation Prompt:
      Encourage support for JabRef through a tastefully integrated donation option.
      User Group-Specific Defaults:
      Offer pre-configured default preferences catering to different user groups, such as "relaxed users" wanting all features, and "pro-users" who prefer managing BibTeX files without additional features
      (These are just ideas, during the pro, this needs to be refined )
      Expected Outcome:
      A welcome dialog with nice and welcoming UX.
      Multiple walkthroughs through JabRef's features.
      Examples:
      The welcome dialog should ask for: Configuration of Paper Direction, Integration of Online Services (Grobid, Telemetry), Creation of Example Library, Community Engagement Tool, Link to Donation page
      The welcome dialog should offer some sensitive User Group-Specific Defaults: Offer pre-configured default preferences catering to different user groups, such as "relaxed users" wanting all features, and "pro-users" who prefer managing BibTeX files without additional features (as per Issue #9491).
      Walk through: Guide through collecting papers and refining the bibliography data - until the publication of data on an HTML page
      Skills required:
      Java, JavaFX
      Understanding of (potential) JabRef users
      Possible Mentors:
      @koppor, @tobiasdiez
      Project size:
      90h (small) - if only welcome tab is improved (and some more minor JabRef fixes are made)
      175h (medium) - if walkthroughs are made
      The GSoC proposal should include one initial idea of a walk through
      Issue: https://github.com/JabRef/jabref/issues/12664
      Using PostgreSQL as full backend for JabRef
      Currently, JabRef holds all entries in memory. It even converts LaTeX to Unicode and vice versa to support better search. While this is a great UX, this leads to a huge memory consumption. The more "proper" way is to use a database (such as PostgreSQL) to store the entries. Then, not all entries need to be loaded in memory. The first step is to introduce a data-access layer: The maintable should read from SQL database, not from all in-memory. Possible future work may be: https://www.zotero.org/support/dev/client_coding/direct_sqlite_database_access and https://github.com/zotero/zotero/blob/main/resource/schema/userdata.sql.
      There can be an initial phase to evluate whether PostgreSQL is the right DBMS as backend for JabRef. For instance, DuckDB and SQLite were also discussed. Currently, PostgeSQL turned out best (especially for handling regular expression search on the database itself), but things may have changed in 2025.
      This is issue https://github.com/JabRef/jabref/issues/12708
      Skills required:
      PostgreSQL, Java, JavaFX
      Possible Mentors:
      @koppor, @InAnYan, @calixtus
      Project size:
      175h (medium)
      Improved LibreOffice-JabRef integration
      Description:
      JabRef can connect to LibreOffice to offer premier reference management by allowing users to cite library entries directly into the document, and then generate bibliographies based on the cited entries. See JabRef LibreOffice Integration.
      We have a collection of independent projects available for the LibreOffice/OpenOffice integration feature of JabRef.
      BST style support: Currently, custom styles (JStyles) and CSL styles are supported. In the LaTeX-world, BST styles (specified via .bst files) are still popular. JabRef already has BST support, but it is currently not accessible via the UI.
      Expected deliverable: It should be possible to select a .bst file, which is then used for rendering into the LibreOffice document. [Details: #624]
      Improved support for CSL styles: Support for CSL styles in the LibreOffice integration has been a popular new feature in JabRef that users look forward to. This project aims to enhance the integration further by introducing:
      a) Footnote-based citation support for CSL styles: Currently, using CSL styles in footnotes of the LibreOffice document causes unexpected behavior, especially for numeric styles. There should be a proper definition of the "global order" of the citations so that they can be used in footnotes. This problem is already solved for JStyles (see a high-level overview here), so the solution needs to be extended/adapted for CSL styles (and BST styles, if project 1 is also undertaken).
      Expected deliverable: It is possible to use CSL styles in the footnotes of the documents, without any unexpected/broken ordering in the bibliography or numeric citations. [Tracking issue: #12484]
      b) Support for custom CSL styles: Sometimes, users wish to use external (or their own custom designed) CSL style files with JabRef that have not been (or not yet been) officially accepted by the Zotero-CSL community. There are plenty of websites/tools available that enable users to create custom CSL styles, enabling full flexibility in terms of how they want to style their citations. Adding support for using external CSL style files would thus be beneficial for such users.
      Expected deliverable: It is possible to load an external CSL style file in JabRef and use it for citing. [Tracking issue: #12337]
      Cross-compatibility with other reference management software: In case of CSL styles, reference management software like Zotero and Mendeley can read each other's citations in LibreOffice. This is made possible by following a specific format of document annotations, embedding information in CSL JSON. In JabRef, the internal format of references is currently a JabRef-custom format. It should be changed to a format used by Zotero, so that cross-compatibility can be ensured. See the discussion at https://github.com/JabRef/jabref/issues/2146#issuecomment-891432507 for details. This includes: i) Implementation of that format, ii) Implementation of a converter from the "old" JabRef-Format to the new one. The converter could be implemented within OpenOffice (similar to JabRef_LibreOffice_Converter).
      Expected deliverable: One can seamlessly switch working with LibreOffice documents having citations from Zotero and JabRef.
      Seamless citation style type switching: JabRef in LibreOffice should support auto-updation of references when switching from CSL-based formats to JStyle (or BST)-based formats and back. Currently, if the user messes up and realizes that they had to use another style family, the workaround is to re-cite all entries again with the new style, then refresh the bibliography. This may not be very user-friendly when citation styles need to be updated when submitting papers to different journals (one use-case), or simply because of last-minute change in decisions. For this project, the starting step will be unifying the "reference mark" (document annotation) format for all these style types, so that the entry information can be parsed across styles. This project thus goes very well coupled with Project 1.
      Expected deliverable: On changing style type (CSL/BST/JStyle), all references in the documents should seamlessly adapt to the new style.
      Skills required:
      Java, JavaFX
      Possible Mentors:
      @Siedlerchr, @subhramit
      Project size:
      350h (large): If (Project 1 + Project 2 + Project 3 + Project 4)
      175h (medium): If (Project 1 + Project 2) OR (Project 2 + Project 3) OR (Project 1 + Project 3)
      90h (small): If Project 1 OR Project 2 OR Project 3
      Improved SLR Support
      Description:
      With the ever-growing number of publications in computer science and other fields of research, conducting secondary studies becomes necessary to summarize the current state of the art. For software engineering research, Kitchenham popularized the systematic literature review (SLR) method to address this issue. The main idea is to systematically identify and analyze the majority of relevant publications on a specific topic. This is usually an activity that takes extensive manual effort. Some tool support does exist, but the full potential of tools has not been exploited yet. JabRef also offers basic functionality for systematic literature reviews that is used by a number of researchers to systematically "harvest" related work based on the fetching capabilities of JabRef. While using the feature, various additional feature requests came up. For instance, created search queries are currently transformed internally by JabRef to the query format of the publisher. It should also be possible to directly input a query at the publisher site, e.g., for IEEE or ACM.
      More background information: Paper: Systematic Literature Tools: Are we there yet?; Presentation.
      One key aspect would be the improvement of the fetcher infrastructure in JabRef to better adapt to new and changing Publisher/Journal websites and to offer a more direct integration. As an inspiration, see BibDesk.
      Expected outcome:
      An advanced SLR functionality, where a researcher is supported to execute a systematic-literature-review.
      We did an initial project organization at https://github.com/users/koppor/projects/2.
      Skills required:
      Java, JavaFX
      Possible mentors:
      @koppor, @calixtus
      Project size:
      175h (medium)
      Improved Journal Abbreviations
      Currently, JabRef has a single list of journal abbreviations. This list is a combined list of the .csv files at https://github.com/JabRef/abbrv.jabref.org/tree/main/journals. Instead of the dropdown of JabRef should not show a single "JabRef built in list", but should show the various lists we offer: built-in lists, external lists, custom lists. Then, one can enable and disable with a click. This eases the users to find issues in abbreviation lists and allows users to customize the lists according to their field (e.g., physics, information science, ...).
      Fore more context, see: https://github.com/JabRef/jabref/issues/12364
      Skills required:
      Java, JavaFX
      Possible Mentors:
      @calixtus, @koppor
      Project size:
      90h (small)
      Expected Outcome:
      A UI view which allows selecting/including journal abbreviations by category.
      {Your own project}
      You can propose another projects. JabRef offers various places where it can be improved. Think as a user or talk to other users. The following places are a good start:
      Switch to Apache Velocity: https://github.com/JabRef/jabref/issues/12418
      Big projects: https://github.com/JabRef/jabref/issues?q=sort%3Aupdated-desc+state%3Aopen+label%3A%22size%3A+big%22
      Feature requests prioritized: https://github.com/orgs/JabRef/projects/6
      General list of feature requests: http://discourse.jabref.org/c/features
      Candidates of university projects, the large ones: https://github.com/orgs/JabRef/projects/3/views/3?filterQuery=status%3A%22free+to+take%22+size-of-project%3Alarge&sortedBy%5Bdirection%5D=desc&sortedBy%5BcolumnId%5D=8246261
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/jabref-e.v./
    idea_list_url: https://github.com/JabRef/jabref/wiki/GSoC-2025-ideas-list


  - organization_id: 70
    organization_name: JdeRobot
    no_of_ideas:
    ideas_content: |
      GSoC 2025
      TOC GSoC-2025
      Ideas list
      Project #1: Robotics-Academy: support for solutions directly using ROS2 topics
      Project #2: Robotics-Academy: CI & Testing
      Project #3: Robotics-Academy: improve Computer Vision exercises, including with real cameras
      Project #4: Robotics-Academy: new exercise on End-to-End Visual Control of an Autonomous Vehicle using DeepLearning
      Project #5: VisualCircuit: Improving Functionality & Expanding the Block Library
      Project #6: Robotics Academy: using the Open3DEngine as robotics simulator
      Project #7: Robotics Academy: improvement of Gazebo scenarios and robot models
      Project #8: Robotics Academy: improvement of industrial robotics exercises with MoveIt2 and ROS2
      Project #9: BT-Studio: a tool for programming robots with Behavior Trees
      Project #10: Extend DetectionMetrics: GUI, CI Workflow, and Object Detection
      Application instructions for GSoC-2025
      Requirements
      Programming tests
      Send us your information
      Previous GSoC students
      How to increase your chances of being selected in GSoC-2025
      RTFM
      Robotics applications are typically distributed, made up of a collection of concurrent asynchronous components which communicate using some middleware (ROS messages, DDS…). Building robotics applications is a complex task. Integrating existing nodes or libraries that provide already solved functionality, and using several tools may increase the software robustness and shorten the development time. JdeRobot provides several tools, libraries and reusable nodes. They have been written in C++, Python or JavaScript. They are ROS-friendly and full compatible with ROS2-Humble (and Gazebo Harmonic).
      Our community mainly works on three development areas:
      Education in Robotics. RoboticsAcademy is our main project. It is a ROS-based framework to learn robotics and computer vision with drones, autonomous cars…. It is a collection of Python programmed exercises and challenges for engineering students.
      Robot Programming Tools. For instance, BT-Studio, for robot programming with Behavior Trees; VisualCircuit for robot programming with connected blocks, as in electronic circuits, in a visual way.
      Machine Learning in Robotics. For instance, the BehaviorMetrics tool for assessment of neural networks in end-to-end autonomous driving. Another example is DetectionMetrics tool for evaluation of visual detection neural networks and algorithms.
      Ideas list
      This open source organization welcomes contributors in these topics:
      Project #1: Robotics-Academy: support for solutions directly using ROS2 topics
      Brief explanation: Robotics-Academy is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS 2 or OpenCV.
      Nowadays, Robotics Academy offers the student up to 26 exercises, and another 11 prototype exercises. All of them come ready to use in the RoboticsAcademy docker image (RADI). The only requirement for the students its to download the docker image, all the dependencies are installed inside the RADI.
      Currently, exercises can be solved using Python without any knowledge of ROS 2 thank to our Hardware Abstraction Layer (HAL). However, some students asked for the possibility to use (and learn) ROS 2 interfaces (topics and services) while coding the solution. Project #2 will explore new ways of coding the exercise solution, where a few changes like ROS 2 spin control or editor autocompletions are required.
      Skills required/preferred: React, Python, ROS2.
      Difficulty rating: medium
      Expected results: New way of coding your solutions in RoboticsAcademy using ROS 2 topics
      Expected size: 90h
      Mentors: Pedro Arias (pedro.ariasp AT upm.es) and Apoorv Garg (apoorvgarg.ms AT gmail.com)
      Project #2: Robotics-Academy: CI & Testing
      Brief explanation: Robotics-Academy is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision.
      Project #2 seeks to identify and address potential issues early on, fostering the maintainability and reliability of its software. This commitment to improving the quality of the software will be achieved through the implementation of automated testing and continuous integration (CI) processes. The project will also include the development of a testing strategy and the implementation of a CI pipeline.
      Skills required/preferred: Docker, GitHub actions, Python, JavaScript, pytest, Selenium
      Difficulty rating: medium
      Expected results: Tests on RAM, RI and RA
      Expected size: 350h
      Mentors: Pedro Arias (pedro.ariasp AT upm.es), Pawan Wadhwani (pawanw17 AT gmail.com) and Miguel Fernandez (miguel.fernandez.cortizas AT upm.es)
      Project #3: Robotics-Academy: improve Computer Vision exercises, including with real cameras
      Brief explanation: As of now, Robotics-Academy includes two deprecated Computer Vision exercises: ColorFilter and OpticalFlow Teleoperator. These exercises allow users to learn de foundations of image processing using OpenCV library. A Work-In-Progress from the JdeRobot Computer Vision Working Group is the multiplatform support of real cameras in RoboticsAcademy exercises (it works on Linux, Windows and MacOS machines), using WebRTC.
      The main objective of this project is to prepare several exercises in RoboticsAcademy about Computer Vision (including the update of the previous two) which can be performed with real camera from the browser.
      Skills required/preferred: ComputerVision, OpenCV, React, Python
      Difficulty rating: easy
      Expected results: new exercises on ComputerVision in Robotics-Academy, including with real cameras.
      Expected size: 90h
      Mentors: David Pascual (d.pascualhe AT gmail.com) and David Pérez (david.perez.saura AT upm.es)
      Project #4: Robotics-Academy: new exercise on End-to-End Visual Control of an Autonomous Vehicle using DeepLearning
      Brief explanation: The goal of this project is to develop a new deep learning exercise focused on visual robotic control in the context of Robotics-Academy. We will create a web-based interface that allows users to upload a trained model, which will take camera input from a drone or car and output the linear speed and angular velocity of the vehicle. The controlled robot and its environment will be simulated using Gazebo. The objectives of this project include:
      Updating the web interface to accept models trained with PyTorch/TensorFlow.
      Building new widgets to monitor exercise results.
      Preparing a simulated environment.
      Coding the core application that feeds input data to the trained model and returns the results.
      Training a naive model to demonstrate how the exercise can be solved.
      This new exercise may utilize the infrastructure developed for the “Human detection” Deep Learning exercise. The following videos showcase one of our current web-based exercises and a visual control task solved using deep learning:
      Skills required/preferred: Python, Deep Learning, Gazebo, React, ROS2
      Difficulty rating: medium
      Expected results: a web-based exercise for robotic visual control using deep learning
      Expected size: 350h
      Mentors: David Pascual ( d.pascualhe AT gmail.com ) and Pankhuri Vanjani (pankhurivanjani AT gmail.com)
      Project #5: VisualCircuit: Improving Functionality & Expanding the Block Library
      Brief explanation: VisualCircuit allows users to program robotic intelligence using a visual language similar to electronic circuits, simplifying the creation of code for robotics applications such as Deep Learning, ROS, and more.
      Over the past few years, we have focused on making VisualCircuit more robust by resolving Nested Blocks (multi-level blocks) with the Block Composition feature, developing a working prototype for dockerized execution of robotics applications directly from the browser, migrating the old POSIX IPC implementation to a cross-platform compatible Python Shared Memory implementation, and more.
      Now, for GSoC 2025, the goal of the project is to further refine VisualCircuit by improving Shared Memory, Block Composition, and other features, developing more real-world robotics applications utilizing the latest functionalities of VC, expanding the block library to cater to a larger audience, and enhancing automated testing. Additionally, we aim to address other issues such as implementing Undo and Redo functionality, adding more keyboard shortcuts for faster circuit creation, and making various other improvements. You can read further about the tool on the website.
      Skills required/preferred: ROS2, Gazebo, Python, TypeScript
      Difficulty rating: medium
      Expected results: Expanding Block library for VisualCircuit, improving automated testing using GitHub Actions and creating real world robotics applications developed with latest functionalities of VC and resolving other major issues.
      Expected size: 175h
      Mentors: Toshan Luktuke (toshan1603 AT gmail.com), Pankaj Borade (borade.pankaj825 AT gmail.com) and Suhas Gopal.
      Project #6: Robotics Academy: using the Open3DEngine as robotics simulator
      Brief explanation: Open 3D Engine (O3DE) is an Apache 2.0-licensed multi-platform 3D engine that enables developers and content creators to build AAA games, cinema-quality 3D worlds, and high-fidelity simulations. It supports also simulation of most common robot sensors and actuators. The idea of this project is to integrate Open3DEngine into the RoboticsAcademy framework, with at least one exercise using it instead of Gazebo.
      Skills required/preferred: C++ programming, ROS
      Difficulty rating: Medium
      Expected results: A new robotics exercise in RoboticsAcademy using the Open3DEngine
      Expected size: 175h
      Repository Link - Open 3D Engine, RoboticsAcademy, RoboticsInfrastructure
      Mentors: José M. Cañas (josemaria.plaza AT gmail.com) and Jan Hanca ( jan.hanca AT googlemail.com )
      Project #7: Robotics Academy: improvement of Gazebo scenarios and robot models
      Brief Explanation: Currently Robotics Academy offers the student up to 26 exercises, and another 11 prototype exercises. The main goal of this project is to improve the current Gazebo scenarios and robot models for many the exercises making them more appealing and realistic without increasing too much the required computing power for rendering. For instance the world model of the FollowLine exercise will be enhanced in order to have a 3D race circuit and several models will be reviewed to be low poly (= faster to simulate).
      Skills required/preferred: experience with Gazebo, SDF, URDF, ROS2 and Python
      Difficulty rating: easy
      Expected results: New Gazebo scenarios
      Expected size: small (~90h)
      Mentors: Pedro Arias (pedro.ariasp AT upm.es) and Shashwat Dalakoti (shash.dal623 AT gmail.com)
      Project #8: Robotics Academy: improvement of industrial robotics exercises with MoveIt2 and ROS2
      Brief explanation: A few years ago we developed some exercises on industrial robots using MoveIt1 and ROS1-Noetic. A Work-In-Progress from the JdeRobot Industrial Robotics Working Group is the support in RoboticsAcademy to MoveIt2 and ROS2. A proof of concept has already been developed and it opens the door to new applications with manipulators (pick-and-place, palletizing…). Developing an easy API for the programming of industrial robots, similar to other solutions such as RAPID from ABB is an open topic. The main goal of this project is to integrate, refine this support and develop a new exercise regarding manipulation.
      Skills required/preferred: Gazebo, URDF, ROS2, MoveIt2
      Difficulty rating: medium
      Expected results: updated and operating new exercise on industrial robot manipulation
      Expected size: medium (~175h)
      Mentors: Diego Martín (diego.martin.martin AT gmail.com) and Pankhuri Vanjani (pankhurivanjani AT gmail.com)
      Project #9: BT-Studio: a tool for programming robots with Behavior Trees
      Brief explanation: Behavior Trees is a recent paradigm for organizing robot deliberation. There are brilliant open source projects such as BehaviorTrees.CPP and PyTrees. Our BT-Studio has been created to provide a web based graphical editor of Behavior Trees. It also includes a conversor to Python language, the dockerized execution of the generated robotics application from the browser and supports subtrees (a feature created along a previous GSoC-2024 project).
      The goal of this GSoC proposed project is to develop a Behavior Tree library, a collection of example robotics applications and further refine the tool.
      Skills required/preferred: Python, ROS, Gazebo
      Difficulty rating: medium
      Expected results: Behavior Trees library for BT-Studio and several example robotics applications developed with them.
      Expected size: 175h
      Mentors: José M. Cañas (josemaria.plaza AT gmail.com) and Oscar Martínez (oscar.robotics AT tutanota.com)
      Project #10: Extend DetectionMetrics: GUI, CI Workflow, and Object Detection
      Brief explanation: DetectionMetrics is a toolkit for evaluating perception models across frameworks and datasets. Past GSoC projects (Vinay Sharma, Jeevan Kumar) contributed to its first stable release, published in Sensors (Paniego et al., 2022). Recently, we revamped the tool to improve usability and installation—check it out here! Currently, DetectionMetrics functions as both a Python library and CLI, focusing on the quantitative evaluation of image and LiDAR segmentation models, with plans to expand into object detection. It supports PyTorch and TensorFlow models, along with multiple public datasets. Its modular design allows easy integration of new models and datasets. While redesigning the core functionality, some useful features were lost. This project aims to bring them back and enhance DetectionMetrics by:
      Recovering object detection evaluation support, including metrics like mAP and IoU. This involves restoring compatibility with COCO-style and Pascal VOC-style datasets and implementing necessary pipeline adjustments.
      Building a GUI for visualizing dataset samples (images, point clouds) and evaluation results (IoU, confusion matrices, etc.). Ideally, it will also provide an interactive interface for launching batched evaluation jobs. Possible tools: Streamlit, Gradio.
      Setting up a Continuous Integration (CI) workflow to automate testing, documentation generation, and versioning using Sphinx, pytest, and GitHub Actions.
      Since this new version of DetectionMetrics is still in its early stages, your contributions will have a lasting impact on a tool already featured in a scientific journal!
      Skills required/preferred: Python, GitHub Actions, PyTorch, Deep Learning
      Difficulty rating: Medium
      Expected results: A brand-new GUI and CI workflow for DetectionMetrics
      Expected size: Long (~350h)
      Mentors: David Pascual Hernández (d.pascualhe AT gmail.com), Sergio Paniego (sergiopaniegoblanco AT gmail.com), Santiago Montiel Marín (santiago.montiel AT uah.es)
      Application instructions for GSoC-2025
      We welcome students to contact relevant mentors before submitting their application into GSoC official website. If in doubt for which project(s) to contact, send a message to jderobot AT gmail.com We recommend browsing previous GSoC student pages to look for ready-to-use projects, and to get an idea of the expected amount of work for a valid GSoC proposal.
      Requirements
      Git experience
      C++ and Python programming experience (depending on the project)
      Programming tests
      Project #1 #2 #3 #4 #5 #6 #7 #8 #9 #10
      Academy (A) X X X X X X X X X X
      Python (B) X X X X X X X X X X
      ROS2 (C) X X O X X X X X X X
      React (D) X O X X O O * * O O
      
      Where:  
      * Not applicable
      X Mandatory
      O Optative
      Before accepting any proposal all candidates have to do these programming challenges:
      Note: Python Programming test for GSoC 25 will be updated soon.
      (A) RoboticsAcademy challenge
      (B) Python challenge (To be updated soon)
      (C) ROS2 challenge
      (D) React challenge
      Send us your information
      AFTER doing the programming tests, fill this web form with your information and challenge results. Then you are invited to ask the project mentors about the project details. Maybe we will require more information from you like this:
      Contact details
      Name and surname:
      Country:
      Email:
      Public repository/ies:
      Personal blog (optional):
      Twitter/Identica/LinkedIn/others:
      Timeline
      Now split your project idea in smaller tasks. Quantify the time you think each task needs. Finally, draw a tentative project plan (timeline) including the dates covering all period of GSoC. Don’t forget to include also the days in which you don’t plan to code, because of exams, holidays etc.
      Do you understand this is a serious commitment, equivalent to a full-time paid summer internship or summer job?
      Do you have any known time conflicts during the official coding period?
      Studies
      What is your School and degree?
      Would your application contribute to your ongoing studies/degree? If so, how?
      Programming background
      Computing experience: operating systems you use on a daily basis, known programming languages, hardware, etc.
      Robot or Computer Vision programming experience:
      Other software programming:
      GSoC participation
      Have you participated to GSoC before?
      How many times, which year, which project?
      Have you applied but were not selected? When?
      Have you submitted/will you submit another proposal for GSoC 2025 to a different org?
      Previous GSoC students
      Prajyot Jadhav (GSoC-2024) Robotics-Academy: migration to Gazebo Fortress
      Mihir Gore (GSoC-2024) Robotics-Academy: improve Deep Learning based exercises
      Pankaj Borade (GSoC-2024) VisualCircuit: block library
      Óscar Martínez (GSoC-2024) BT-Studio: a tool for programming robots with Behavior Trees
      Zebin Huang (GSoC-2024) End-to-end autonomous vehicle driving based on text-based instructions: research project regarding Autonomous Driving + LLMs
      Pawan Wadhwani (GSoC-2023) Robotics Academy: migration to ROS2 Humble
      Meiqi Zhao (GSoC 2023) Obstacle Avoidance for Autonomous Driving in CARLA Using Segmentation Deep Learning Models
      Siddheshsingh Tanwar (GSoC 2023) Dockerization of Visual Circuit
      Prakhar Bansal (GSoC 2023) RoboticsAcademy: Cross-Platform Desktop Application using ElectronJS
      Apoorv Garg (GSoC-2022) Improvement of Web Templates of Robotics Academy exercises
      Toshan Luktuke (GSoC-2022) Improvement of VisualCircuit web service
      Nikhil Paliwal(GSoC-2022) Optimization of Deep Learning models for autonomous driving
      Akshay Narisetti(GSoC-2022) Robotics Academy: improvement of autonomous driving exercises
      Prakarsh Kaushik(GSoC-2022) Robotics Academy: consolidation of drone based exercises
      Bhavesh Misra (GSoC-2022) Robotics Academy: improve Deep Learning based Human Detection exercise
      Suhas Gopal (GSoC-2021) Shifting VisualCircuit to a web server
      Utkarsh Mishra (GSoC-2021) Autonomous Driving drone with Gazebo using Deep Learning techniques
      Siddharth Saha (GSoC-2021) Robotics Academy: multirobot version of the Amazon warehouse exercise in ROS2
      Shashwat Dalakoti (GSoC-2021) Robotics-Academy: exercise using Deep Learning for Visual Detection
      Arkajyoti Basak (GSoC-2021) Robotics Academy: new drone based exercises
      Chandan Kumar (GSoC-2021) Robotics Academy: Migrating industrial robot manipulation exercises to web server
      Muhammad Taha (GSoC-2020) VisualCircuit tool, digital electronics language for robot behaviors.
      Sakshay Mahna (GSoC-2020) Robotics-Academy exercises on Evolutionary Robotics.
      Shreyas Gokhale (GSoC-2020) Multi-Robot exercises for Robotics Academy In ROS2.
      Yijia Wu (GSoC-2020) Vision-based Industrial Robot Manipulation with MoveIt.
      Diego Charrez (GSoC-2020) Reinforcement Learning for Autonomous Driving with Gazebo and OpenAI gym.
      Nikhil Khedekar (GSoC-2019) Migration to ROS of drones exercises on JdeRobot Academy
      Shyngyskhan Abilkassov (GSoC-2019) Amazon warehouse exercise on JdeRobot Academy
      Jeevan Kumar (GSoC-2019) Improving DetectionSuite DeepLearning tool
      Baidyanath Kundu (GSoC-2019) A parameterized automata Library for VisualStates tool
      Srinivasan Vijayraghavan (GSoC-2019) Running Python code on the web browser
      Pankhuri Vanjani (GSoC-2019) Migration of JdeRobot tools to ROS 2
      Pushkal Katara (GSoC-2018) VisualStates tool
      Arsalan Akhter (GSoC-2018) Robotics-Academy
      Hanqing Xie (GSoC-2018) Robotics-Academy
      Sergio Paniego (GSoC-2018) PyOnArduino tool
      Jianxiong Cai (GSoC-2018) Creating realistic 3D map from online SLAM result
      Vinay Sharma (GSoC-2018) DeepLearning, DetectionSuite tool
      Nigel Fernandez GSoC-2017
      Okan Asik GSoC-2017, VisualStates tool
      S.Mehdi Mohaimanian GSoC-2017
      Raúl Pérula GSoC-2017, Scratch2JdeRobot tool
      Lihang Li: GSoC-2015, Visual SLAM, RGBD, 3D Reconstruction
      Andrei Militaru GSoC-2015, interoperation of ROS and JdeRobot
      Satyaki Chakraborty GSoC-2015, Interconnection with Android Wear
      How to increase your chances of being selected in GSoC-2025
      If you put yourself in the shoes of the mentor that should select the student, you’ll immediately realize that there are some behaviors that are usually rewarded. Here’s some examples.
      Be proactive: Mentors are more likely to select students that openly discuss the existing ideas and / or propose their own. It is a bad idea to just submit your idea only in the Google web site without discussing it, because it won’t be noticed.
      Demonstrate your skills: Consider that mentors are being contacted by several students that apply for the same project. A way to show that you are the best candidate, is to demonstrate that you are familiar with the software and you can code. How? Browse the bug tracker (issues in github of JdeRobot project), fix some bugs and propose your patch submitting your PullRequest, and/or ask mentors to challenge you! Moreover, bug fixes are a great way to get familiar with the code.
      Demonstrate your intention to stay: Students that are likely to disappear after GSoC are less likely to be selected. This is because there is no point in developing something that won’t be maintained. And moreover, one scope of GSoC is to bring new developers to the community.
      RTFM
      Read the relevant information about GSoC in the wiki / web pages before asking. Most FAQs have been answered already!
      Full documentation about GSoC on official website.
      FAQ from GSoC web site.
      If you are new to JdeRobot, take the time to familiarize with the JdeRobot.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/jderobot/
    idea_list_url: https://jderobot.github.io/activities/gsoc/2025#ideas-list
  

  - organization_id: 71
    organization_name: Jenkins
    no_of_ideas:
    ideas_content: |
      CDF
      Blog
      Success Stories
      Contributor Spotlight
      Documentation
      User Guide
      Solution Pages
      Tutorials
      Developer Guide
      Contributor Guide
      Books
      Plugins
      Community
      Special Interest Groups
      Subprojects
      Security
      About
      Download
      Search
      K
      GSoC 2025 Project Ideas
      This page aggregates project ideas for Google Summer of Code 2025. Refer to the Jenkins Google Summer of Code page for more information about this project and applications..
      Below you can find project ideas that have been proposed for this year. New ideas may be proposed by interested mentors or GSoC contributors, such as new features in the core or "write a plugin for MY_TOOL_OR_SERVICE". Project ideas without potential mentors will be considered, though applicants may need to work with the community and GSoC org admins to find mentors. To add a new project idea, see: proposing project ideas .
      Accepted ideas
      The following list contains the project ideas that fully match the Jenkins project idea standard. The scope of these ideas is understood and we don't normally expect deep changes. All ideas have quick-start guidelines and newbie-friendly issues referenced. We welcome contributors to join the mentor teams and invite GSoC contributors to submit project proposal applications related to these ideas.
      Project Category Skills to study/improve
      AI-Powered Chatbot for Quick Access to Jenkins Resources
      Develop an AI-based chatbot to provide users with quick and intuitive access to Jenkins documentation, plugins, and community resources..
      Potential Mentor(s):
      Vutukuri Sreenivas
      Kris Stern
      Ashutosh Singh
      Plugins Natural Language Processing (NLP), Python, JavaScript/TypeScript, Jenkins Plugin Development, Machine Learning
      Backend code refactoring for Infra Statistics
      To significantly refactor backend code for the Infra Statistics.
      Potential Mentor(s):
      Kris Stern
      Bervianto Leo Pratama
      Phillipp Glanz
      Infra Groovy, Backend-frontend Integration, Code Refactoring, Infra / DevOps Processes
      Complete build retooling of jenkins.io
      Using alternative tooling with Gatsby and Antora to build the Jenkins static site and provide versioned Jenkins documentation.
      Potential Mentor(s):
      Kris Stern
      Bruno Verachten
      Kevin Martens
      Rajiv Ranjan Singh
      Tools Web development, AsciiDoc, Static website tooling, Documentation, Website retooling
      Domain-specific LLM based on actual Jenkins usage using ci.jenkins.io data
      To develop a web app using an existing open-source LLM model with Jenkins usage data collected for domain-specific Jenkins knowledge to be fine-tuned.
      Potential Mentor(s):
      Kris Stern
      Harsh Pratap Singh
      Shivay Lamba
      Vutukuri Sreenivas
      Infra Python, JavaScript/TypeScript, React.js, LLM, AI/ML, Jenkins, Ollama, LangChain, UI, Infra statistics, Data Analytics
      Improving Tekton Client Plugin for Jenkins
      Enhance the Jenkins Tekton Client Plugin to improve cloud-native CI/CD interoperability and user experience.
      Potential Mentor(s):
      Vibhav Bobade
      Kris Stern
      Plugins Java, Kubernetes, Tekton, Jenkins
      Improving Plugin Modernizer
      Improving the Jenkins Plugin Modernizer tool and provide integrations with Jenkins ecosystem.
      Potential Mentor(s):
      Bruno Verachten
      Valentin Delaye
      Sridhar Sivakumar
      Phillipp Glanz
      Tools OpenRewrite, Data structure (Trees) and visitor pattern, Java, Plugin hygiene and migration
      Revamping jenkins.io website Success Stories feature
      To revamp jenkins.io website's Success Stories feature to update both tooling and UI/UX experience with new design.
      Potential Mentor(s):
      Kris Stern
      Bervianto Leo Pratama
      UI/UX Website development, UI/UX design, Geospatial data visualization, Gatsby.js and React.js
      Swagger / OpenAPI standardization for Jenkins REST API
      Standardizing Jenkins REST API documentation using Swagger or the OpenAPI specifications.
      Potential Mentor(s):
      Kris Stern
      Bruno Verachten
      Rajiv Ranjan Singh
      Bervianto Leo Pratama
      Phillipp Glanz
      Tools Swagger / OpenAPI standardization, REST API, Documentation, Automation, Java
      Draft project ideas
      In the following list, you can refer to draft project ideas, which are currently under review. The scope of such ideas may change during the discussions, but the idea is accepted in principle. You are welcome to comment on the draft and join the project as a mentor. If you are a GSoC contributor, it is also fine to explore and apply to the draft project ideas.
      Project Category Skills to study/improve
      Android and/or iOS tutorials in official documentation
      Adding Android and/or iOS tutorials for Jenkins in the official documentation.
      Potential Mentor(s):
      Bruno Verachten
      Kris Stern
      Documentation Documentation, Java, YAML, Android / iOS development, Command line tools
      Pipeline documentation improvements - Phase 2 and Phase 3
      Improving the navigation and implementation of the Pipeline Steps Reference.
      Potential Mentor(s):
      Kris Stern
      Bervianto Leo Pratama
      Documentation Documentation, Web development, Jenkins plugins
      Improving Jenkinsfile Runner abilities and GitHub Actions
      To investigate the current state of the Jenkinsfile Runner project and to improve its abilities as well as those of GitHub Actions when used in conjunction.
      Potential Mentor(s):
      Valentin Delaye
      Kris Stern
      Bervianto Leo Pratama
      Tools Java, Jenkinsfile Runner, Docker, GitHub Actions
      Ongoing discussion
      These proposals are suggestions from the mailing list, which have not been published as project ideas yet. The feasibility is yet to be defined, and the idea may be dismissed depending on the feedback. Everyone is welcome to participate in the discussion and join as a potential mentor.
      Project Category
      Improve this page
      Report page issue
      The content driving this site is licensed under the Creative Commons Attribution-ShareAlike 4.0 license.
      Resources
      Downloads
      Blog
      Documentation
      Plugins
      Security
      Contributing
      Project
      Structure and governance
      Issue tracker
      Roadmap
      GitHub
      Jenkins on Jenkins
      Statistics
      Community
      Forum
      Events
      Mailing lists
      Chats
      Special Interest Groups
      𝕏 (formerly Twitter)
      Reddit
      Other
      Code of Conduct
      Press information
      Merchandise
      Artwork
      Awards
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/jenkins/
    idea_list_url: https://www.jenkins.io/projects/gsoc/2025/project-ideas/

  - organization_id: 72
    organization_name: Jitsi
    no_of_ideas:
    ideas_content: |
      Projects for GSoC 2025
      Jitsi has decided to apply for Google Summer of Code 2025!
      Here's the list of project ideas for GSoC 2025! Click on the title for a more detailed description.
      Chat Moderation & Editing
      Whiteboard Improvements
      Advanced Audio Settings
      Picture-in-Picture for iOS
      Jitsi Videobridge JavaScript client
      lib-jitsi-meet in TypeScript
      Virtual Backgrounds, take 2
      Integrated AI services with Skynet
      Meeting stats with rtcstats
      Audio Switchboard API
      Removing "ghost" participants on reconnections
      Interested in applying for a project?
      Make sure to read the GSoC advice pages to see how to get started, and check out the Jitsi handbook to get yourself more familiarized with Jitsi.
      Think about preparing a draft proposal, but note that:
      The participating organizations have not been announced yet, so we don't know whether Jitsi will participate this year.
      Proposals or drafts shouldn't be shared publically to avoid being plagiarized. Stay tuned on details on how to share drafts with the Jitsi team privately.
      Do you have a suggestion for a new project?
      If you have a suggestion for a project that's not on our list, feel free to create an issue in this repository.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/jitsi/
    idea_list_url: https://github.com/jitsi/gsoc-ideas/blob/master/2025/README.md

  - organization_id: 73
    organization_name: Joomla!
    no_of_ideas:
    ideas_content: |
      GSoC 2025 Project Ideas
      From Joomla! Documentation
      Build your website for just $3.88/mth. More value and performance with Namecheap.
      ADS VIA CARBON
      Welcome to Joomla GSoC 2025 Projects Page
      
      Welcome to the Joomla Google Summer of Code (GSoC) 2025 projects page.
      If you are interested in participating as a student please review the materials on applying that are available at Google. We strongly encourage you to ask questions about process and projects on our Mattermost chat tool.
      Note: The GSoC 2025 projects are displayed in no particular order
      Contents
      1 Project I: API Improvements
      1.1 Project Description
      1.2 Knowledge Prerequisite
      1.3 Expected Outcome
      1.4 Difficulty
      1.5 Project Hours
      1.6 Mentors
      2 Project II: Workflow enhancements
      2.1 Project Description
      2.2 Knowledge Prerequisite
      2.3 Expected Outcome
      2.4 Difficulty
      2.5 Project Hours
      2.6 Mentors
      3 Project III: Weblinks enhancements
      3.1 Project Description
      3.2 Knowledge Prerequisite
      3.3 Expected Outcome
      3.4 Difficulty
      3.5 Project Hours
      3.6 Mentors
      4 Project IV: Joomla! AI framework
      4.1 Project Description
      4.2 Knowledge Prerequisite
      4.3 Expected Outcome
      4.4 Difficulty
      4.5 Project Hours
      4.6 Mentors
      Project I: API Improvements[edit]
      #SECURITY
      Project Description[edit]
      To exchange information between different Content Management Systems, for integration or migration purposes, many ad hoc solutions have been created. A more universally applicable approach would be establishing a common, shared model for content. This would enable the creation of specific models tailored to individual CMSs, facilitating model-to-model transformations. A standardized content model would provide a more versatile and efficient solution for handling information exchange across diverse CMS platforms.
      There was a standard for content integration, CMIS [1], but it is hardly used nowadays, mainly because it is not up to date with modern web content management.
      
      Knowledge Prerequisite[edit]
      Language Requisitions: PHP, JavaScript
      Besides that, a must have: REST API
      Nice to have: API Protocols
      Expected Outcome[edit]
      Work towards a gradually more general (formal) content model, usable in multiple CMSs.
      Gradually adding more CMSs. Adjusting the general model and defining the specificities per CMS. Start with Joomla and 1 other.
      Export content from those CMSs to the general model using the API.
      Import content from the general model using the API.
      Increase the coverage for API
      Go through the components to add missing calls
      Auth & Error
      Enhancement to authentication (OAuth 2.0)
      Improve Error handling
      Difficulty[edit]
      Hard
      Project Hours[edit]
      [350 Hrs]
      Mentors[edit]
      Project II: Workflow enhancements[edit]
      Project Description[edit]
      With Joomla! 4.0 a workflow extension was implemented. It supports a powerful workflow mechanism to manage articles in Joomla! This project should help to improve the user experience of the workflow by checking other solutions, what is “the state of the arts” today and implement a proper UI solution for Joomla!
      
      Knowledge Prerequisite[edit]
      Language Requisitions: PHP, JavaScript
      Expected Outcome[edit]
      A graphical workflow interface (drag & drop + graphs)
      Different default workflows which are shipped with the system
      Improved documentation & help page
      Difficulty[edit]
      Hard
      Project Hours[edit]
      [350 Hrs]
      Mentors[edit]
      Project III: Weblinks enhancements[edit]
      Project Description[edit]
      A few years ago the weblink extension was extracted from the core and maintained in an extra repository. Over time the code was not kept up-to-date and does not cover all the standards.
      Knowledge Prerequisite[edit]
      Language Requisitions: PHP, JavaScript
      Nice to have: Joomla! 5 template creation
      Expected Outcome[edit]
      Bring the code to the latest standard of Joomla! Programming
      Implement the workflow into weblinks
      Suggest and implement new features which improve the extension itself
      
      Difficulty[edit]
      Medium
      Project Hours[edit]
      [175 Hrs]
      Mentors[edit]
      Project IV: Joomla! AI framework[edit]
      Project Description[edit]
      AI is here, so Joomla! should start offering a framework to get AI support into Joomla! The task of this project is to check out best practice examples on the internet and come up with a proposal for a basic AI framework.
      
      Knowledge Prerequisite[edit]
      Language Requisitions: AI knowledge, API, PHP
      
      Expected Outcome[edit]
      Basic best practices framework which can be extended in the future
      An Example implementation of one or more state-of-the-art AI providers
      
      Difficulty[edit]
      Medium
      Project Hours[edit]
      [175 Hrs]
      Mentors[edit]
      Categories: Google Summer of Code 2025Google Summer of Code
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/joomla!/
    idea_list_url: https://docs.joomla.org/GSoC_2025_Project_Ideas

  - organization_id: 74
    organization_name: KDE Community
    no_of_ideas:
    ideas_content: |
      GSoC/2025/Ideas
      Page
      Discussion
      Read
      View source
      View history
      Tools
      Appearance hide
      Text
      Small
      Standard
      Large
      Width
      Standard
      Wide
      < GSoC | 2025
      Konqi is giving a lesson!
      See also: GSoC Instructions, Last year ideas
      Guidelines
      Information for Students
      These ideas were contributed by our developers and users. They are sometimes vague or incomplete. If you wish to submit a proposal based on these ideas, you are urged to contact the developers and find out more about the particular suggestion you're looking at.
      Becoming accepted as a Google Summer of Code student is quite competitive. Accepted students typically have thoroughly researched the technologies of their proposed project and have been in frequent contact with potential mentors. Simply copying and pasting an idea here will not work. Neither generating a proposal with ChatGPT or equivalent! On the other hand, creating a completely new idea without first consulting potential mentors rarely works.
      When writing your proposal or asking for help from the general KDE community don't assume people are familiar with the ideas here. KDE is really big!
      If there is no specific contact given you can ask questions on the general KDE development list kde-devel@kde.org. See the KDE mailing lists page for information on available mailing lists and how to subscribe.
      Note
      These are all proposals! We are open to new ideas you might have!! Do you have an awesome idea you want to work on with KDE but that is not among the ideas below? That's cool. We love that! But please do us a favor: Get in touch with a mentor early on and make sure your project is realistic and within the scope of KDE.
      
      Adding a Proposal
      When adding an idea to this section, please include the following data:
      if the application is not widely known, a description of what it does and where its code lives
      a brief explanation (2-5 sentences, do not just put a link to a bug)
      the expected size of the project (small-90 hours, medium-175 hours or large-350 hours)
      the expected results
      pre-requisites for working on your project (skills required/preferred)
      if applicable, links to more information or discussions
      mailing list or IRC channel for your application/library/module
      your name and email address for contact (if you're willing to be a mentor)
      if possible, an easy, medium or hard rating of the project
      If you are not a developer but have a good idea for a proposal, get in contact with relevant developers first.
      Note
      Follow this template!
      
      Project: Something that you're totally excited about
      Brief explanation: Do you have an awesome idea you want to work on with KDE but that is not among the ideas below? That's cool. We love that! But please do us a favor: Get in touch with a mentor early on and make sure your project is realistic and within the scope of KDE. That will spare you and us a lot of frustration.
      Expected results: Something you and KDE loves
      Knowledge Prerequisite: Probably C++ and Qt but depends on your project
      Duration: Mention one of ~90, ~175 or ~350 hours of effort necessary to finish the project. Use only one of these three project classes and don't come up with other numbers here.
      Difficulty: Easy, medium or difficult project
      Mentor: Try to see who in KDE is interested in what you want to work on and approach them. If you are unsure you can always ask in #kde-soc:kde.org on matrix.
      
      Ideas
      Note
      Only projects as part of KDE can be mentored.
      
      Cantor
      Project: Python virtual environments in Cantor
      Brief explanation: Cantor is a graphical frontend for different computer algebra systems and programming languages (https://cantor.kde.org/). For the Python backend, it lacks the support for Python virtual environments. The purpose of this project is to implement this missing functionality.
      Expected results: Cantor can work with multiple Python virtual environment similarly to how it's possible in other IDEs like Spider-IDE, PyCharm, etc.
      Knowledge Prerequisite: C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentors: Alexander Semke, Israel Galadima, https://matrix.to/#/#cantor:kde.org
      Merkuro
      Project: Port account management to QML
      Brief explanation: Currently Merkuro makes use of QtWidgets dialog for managing the type of resources (accounts), the goal is to port all (or at least a some) of the dialogs to QML
      Expected results: Making Merkuro a step closer to be fully usable on mobile
      Knowledge Prerequisite: QML and C++
      Duration: ~350 hours, but we can discuss to reduce the scopes
      Difficulty: Difficult
      Mentors: Carl Schwan and Aakarsh MJ. Please contact us on #merkuro:kde.org (Matrix) and not via DM
      
      KArchive
      Project: Rewrite Zip backend to use libzip
      Brief explanation: Currently karchive uses home grown code to handle zip files. The code is not very good since it gets confused when it finds token markers in what it is actual compressed data. See https://bugs.kde.org/show_bug.cgi?id=450597
      Expected results: KArchive uses libzip for handling zip files (and there's no regressions)
      Knowledge Prerequisite: C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Albert Astals Cid <aacid@kde.org>
      
      Internationalization
      Project: Move translation files to git
      Brief explanation: Translation files currently live in SVN, they are one of the last things in SVN, and the sysadmin team would welcome if we stop using it so they can shut down the server (also some folks have trouble using SVN since it's now starting to become old). The plan is to move files to GIT but we need to make sure the history is preserved and the associated scripts are adapted. See more at https://invent.kde.org/teams/localization/issues/-/issues/1
      Expected results: Most/All of what is described above is done.
      Knowledge Prerequisite: git/bash/python
      Duration: ~350 hours
      Difficulty: Medium
      Mentor: Albert Astals Cid/Luigi Toscano, talk to us at https://matrix.to/#/#kde-i18n:kde.org
      
      Plasma
      Project: Make KWin aware of game controllers
      Brief explanation: Plasma could do a lot to improve support for game controllers: gamepads, fight sticks, flight sticks, and more. But before we can work on advanced features like button mapping or mouse emulation, Plasma's Wayland compositor KWin first needs to take control of controller input. The task is to modify KWin so it reads game controller input events and provides it back to games/applications unmodified. Once that's in place, the sky's the limit.
      Expected results: KWin has access to game controller input events, games still work, and Plasma does not suspend the system as long as you use the controller (one of our oldest bugs)
      Knowledge Prerequisite: C++, a little Qt, patience to dive into KWin and Wayland protocols
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Xaver Hugl. Introduce yourself on #kde-input:kde.org (Matrix) and tag user @zamundaaa
      Project: Make Plasma Virtual Keyboard production-ready
      Brief explanation: Evolve the current proof of concept into a solution that can be shipped with Plasma by default. Currently it's based on the Qt Virtual Keyboard API [1] [2]. It still needs lots of work and polish first though. That's where you come in!
      Expected results: A virtual keyboard that works well for different languages and can be shipped with Plasma. It should be usable on phones, tablets and the likes.
      Knowledge Prerequisite: C++, a little Qt, understanding of how Wayland works.
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Aleix Pol. Introduce yourself on #kde-input:kde.org (Matrix) and tag user @apol:kde.org
      Project: Select & use more than one input method
      Brief explanation: Different users require different ways to input text. Some will need an on-screen keyboard for their tablet, phone, or laptop touchscreen. Some use fcitx5 or IBus to enter complex characters with their keyboard. Some would like to dictate or generate text with the help of an AI model. Some would like all of the above depending on the situation. Plasma on Wayland currently lets you select one input method as "Virtual Keyboard" in System Settings, but ideally we want many input methods to co-exist peacefully.
      Expected results: On the less ambitious end, Plasma and KWin will let you switch between input methods / virtual keyboard on the fly. On the more ambitious end, multiple input methods can be active at the same time so you can e.g. use fcitx5 for physical keyboard input and Maliit or plasma-keyboard as on-screen keyboard.
      Knowledge Prerequisite: C++, a little Qt, understanding of how Wayland works
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Eike Hein. Introduce yourself on #kde-input:kde.org (Matrix) and tag user @hein:kde.org
      Project: Improve input handling in ways that you're totally excited about
      Brief explanation: Input handling is one of the elected KDE Goals and we're looking for all the help we can get. If you have an itch that needs scratching, and none of the other ideas on this page look quite right to you, we're still interested in your contributions. Drop by on our Matrix channel (see below) and let's discuss what your project could look like.
      Expected results: An input-related GSoC application drafted with community input but including many of your own ideas, opinions and planned milestones. Once selected, actually delivering on those plans.
      Knowledge Prerequisite: Depends on the project, but probably C++, Qt, and a basic understanding of Wayland
      Duration: 90, 175 or 350 hours, depending on what you sign up for
      Difficulty: also depends on the project
      Mentor: Jakob Petsovits (@jpetso:kde.org) and/or other interested KDE people in the #kde-input:kde.org (Matrix) chatroom. Say hi and let's chat!
      Plasma Mobile
      Make network related KCMs feature complete with desktop equivalent
      Brief explanation: Currently, Plasma Mobile has its own Wi-Fi, cellular networking and hotspot settings modules. They are very basic, and lack some features compared to their desktop equivalents (ex. enterprise Wi-Fi security). The desktop has a very functional networking settings module, but it has a large codebase and complex UI that is not easy to adapt to mobile usage.
      The aim of the project is to improve the mobile networking settings so that it is functionally equivalent to the desktop experience. This includes support for enterprise Wi-Fi networks, VPN configuration, and etc. The tasks involves exposing configuration values from C++ to QML and writing some UI code around it (working heavily with NetworkManager and ModemManager). Developing a shared base with the desktop implementation and consolidating code is also a key goal.
      Expected results: Mobile network KCMs can share more code with the desktop one and are more featureful
      Knowledge Prerequisite: QML and C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Carl Schwan and rest of Plasma mobile team. https://matrix.to/#/#plasmamobile:kde.org
      KDE Linux
      Kirigami ISO Image Writer
      Brief explanation: Create a GUI in Kirigami for ISO Image Writer: https://invent.kde.org/kde-linux/kde-linux/-/issues/132
      Expected results: ISO Image Writer GUI rewrite using Kirigami.
      Knowledge Prerequisite: QML and C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org
      Backup Prototype
      Brief explanation: Backuping its data is important to not lose them. Whether it's duplicating locally, on the same network or on an external server to be able to retrieve them in case of bad manipulation or incident. The tool should also be robust and trustable (when it says it copied, it really copied). The projects aims to create a prototype which satisfies these conditions: https://invent.kde.org/kde-linux/kde-linux/-/issues/131
      Expected results: A prototype for a local backup solution that is robust
      Knowledge Prerequisite: QML and C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org
      CVE/Security Tracker
      Brief explanation: Security is one of the core values that matters to people. When we install software, we should know if the version has known vulnerabilities and if we can update it to a version that have it fixed. This project aims to create a solution that will allow to track them: https://invent.kde.org/kde-linux/kde-linux/-/issues/134
      Expected results: A system that can track security advisories. Ideally a web based solution.
      Knowledge Prerequisite: Any programming language
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org
      Recovery Infrastructure
      Brief explanation: When your computer crash or do not start, you'd like to recover as much as you can. The aim of the task is to create a tool that would allow to recover this data: https://invent.kde.org/kde-linux/kde-linux/-/issues/135
      Expected results: A prototype of a system/application to help users and OEMs recover a broken system, or at least its data.
      Knowledge Prerequisite: QML and C++, possibly others
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org
      Replication Infrastructure
      Brief explanation: When you change computer, you may want to keep some data: installed applications, configuration files, personal data... The aim of the project is to create a tool that will allow to synchronise data between two machines: https://invent.kde.org/kde-linux/kde-linux/-/issues/136
      Expected results: A prototype of a system/application to help users replicate (or move) from one system to another.
      Knowledge Prerequisite: QML and C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org
      Karton
      Brief explanation: KDE has developed its own virtual machine application. The aim of the project is to create a Kirigami graphical interface to the tool: https://invent.kde.org/kde-linux/kde-linux/-/issues/133
      Expected results: A polished Kirigami-based virtual machine application that can replace virt-manager and virtualbox for most users.
      Knowledge Prerequisite: QML and C++
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org
      Automatic Testing
      Brief explanation: The goal of this project is to develop automated tests which will allow to detect regressions before pushing new features/tools to the user: https://invent.kde.org/kde-linux/kde-linux/-/issues/79.
      Expected results: Fully automated tests to detect regressions in KDE Linux
      Knowledge Prerequisite: Bash, Python, Perl
      Duration: ~350 hours
      Difficulty: Medium
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org
      Website
      Brief explanation: KDE Linux needs to have a website. There are already some websites in KDE done with Hugo. The aim of the task is to create a website for KDE Linux, including multiple infos such as Downloads links, Community links... More details can be found at https://invent.kde.org/kde-linux/kde-linux/-/issues/92
      Expected results: A swanky website for KDE Linux using Hugo
      Knowledge Prerequisite: Web development, ideally using Hugo
      Duration: ~90 hours
      Difficulty: Easy
      Mentor: Harald Sitter et al. https://matrix.to/#/#kde-linux:kde.org
      KDE Games
      Mankala: Bao La Kiswahili
      Brief explanation: Add Bao La Kiswahili and create a computerized opponent with various levels of difficulty for it. Explore the use of machine learning algorithms in creating a computerized opponent. Code can be found at https://invent.kde.org/joaotgouveia/mankala.
      Expected results: An additional game in Mankala
      Knowledge Prerequisite: C++, Qt, QML
      Duration: ~175 hours
      Difficulty: Medium
      Mentor: Benson Muite, João Gouveia contact through https://matrix.to/#/#mancala:kde.org
      Misc
      Project: Add more fuzzed libraries to oss-fuzz
      Brief explanation: oss-fuzz is a SAS for fuzzying code. We have a few libraries there (karchive, kimagefomats, kcodecs), but we should add more since we have quite some code that processes file formats.
      Expected results: As many projects/libraries as possible have been added to oss-fuzz
      Knowledge Prerequisite: docker/compiling
      Duration: ~350 hours
      Difficulty: Medium
      Mentor: Albert Astals Cid <aacid@kde.org>
      GCompris
      Project: Enhancing GCompris Server with GUI Sub-Programs for Dataset Creation
      Project Overview: This project aims to enhance the GCompris server by integrating a set of GUI-based sub-programs specifically designed for teachers. These tools will facilitate the creation of new datasets for various educational applications.The applications targeted for dataset expansion include:
         Grammar Analyses
         Graduated Lines
         Decimal Numbers
         Share
         Fractions Create
      By implementing these sub-programs, educators will be able to customize learning materials more effectively to fit their pupils needs.
      Resources Required:
         Developers with experience in Qt/QML, Gitlab.
         Being able to compile GCompris on QT6 and use it.
      Development resources:
      The server source code is available here : https://invent.kde.org/education/gcompris/-/tree/work/server_qt6?ref_type=heads The development guide is here: https://invent.kde.org/education/gcompris/-/wikis/Developers-corner/Development-process
      Duration: ~175 hours
      Difficulty: Middle
      Mentor: Emmanuel Charruau, Johnny Jazeix (contact on Matrix KDE Webchat)
      Kdenlive
      Project: Improving Kdenlive timeline markers
      Brief explanation: Kdenlive already allows the user to add markers to the timeline and inside clips. The idea is to update the current code to add a duration attribute to the markers. With this change, markers will be able to represent a time range with a start and an end time, which will unlock some nice new features. See this issue for more technical details.
      Expected results: An nice display of the time range markers in the timeline and monitors. The marker's time range should also be connected to existing features and extend them, like render a marker's range, or improved searching.
      Knowledge Prerequisite: C++, Qt, will also involve some Qml
      Duration: ~175 hours
      Difficulty: Medium
      Mentor: Jean-Baptiste Mardelle (https://matrix.to/#/@j-b-m:matrix.org)
      Marknote
      Project: Implement block editor
      Brief explanation: Implement a basic block editor where each elements from markdown is transformed into a block which can be drag-and-dropped.
      Inspiration can be taken from https://rubymamistvalove.com/block-editor
      Expected results: A nice rich text editor which can then be also reused in other apps like Merkuro Mail.
      Knowledge Prerequisite: C++, Qt, will also involve some Qml
      Duration: ~350 hours
      Difficulty: Medium
      Mentor: Carl Schwan (https://matrix.to/#/#marknote:kde.org)
      digiKam
      Project: Interface the database search engine to an AI based LLM
      Brief explanation: The digiKam photo management program already allows the user to search items over the collections using a database. Many powerful search tools can find items by many criteria such as metadata, aesthetic contents, face, place, date, hierarchical keywords, etc. The idea is to add a new top-level interface where users can enter a human phrase which describes the contents to search. With this change, the searches can be user-friendly to use without having to pass plenty of settings used to tune the engine. The LLM must be included in the application, without using an external web-service, as it's not permitted to share data over the Internet. All the new implementations must be written in C++, not Python.
      Relevant entries in bugzilla: - wish 497938 - wish 367700
      Expected results: A nice and simple view where users type a human comprehensive phrase to search items over the photo collections.
      Knowledge Prerequisite: C++, Qt, OpenCV, AI modeling, Large Language Model
      Duration: ~350 hours
      Difficulty: Difficult
      Mentor: Michael Miller (michael_miller@msn.com), Maik Qualmann (metzpinguin@gmail.com), and Gilles Caulier (caulier.gilles@gmail.com)
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kde-community/
    idea_list_url: https://community.kde.org/GSoC/2025/Ideas

  - organization_id: 75
    organization_name: Keploy
    no_of_ideas:
    ideas_content: |
      Google Summer of Code'25 Participant Guide
      Communication
      Welcome to the Keploy GSoC'25 projects page. We encourage candidates to come up with their own project idea. Join our Slack Channel and stay tuned for updates.
      Use our Template for the proposal. We recommend the use of google docs for the proposal.
      General suggestions and warnings
      Project ideas describe the goals we want to achieve but may miss details that have to be defined during the project: we expect students to do their own research, propose solutions and be ready to deal with uncertainty and solve challenges that will come up during the project
      Code and prototypes are preferred over detailed documents and unreliable estimates: rather than using your time to write a very long application document, we suggest to invest in writing a prototype (which means the code may be thrown out entirely) which will help you understand the challenges of the project you want to work on; your application should refer to the prototype or other Github contributions you made to Keploy that show you have the capability to succeed in the project idea you are applying for.
      Students who have either shown to have or have shown to be fast learners for the required hard and soft skills by contributing to Keploy have a lot more chances of being accepted: in order to get started contributing refer to the :doc:Keploy Contributing Guidelines <keploy/keploy/contributing.md>
      Get trained in the projects you want to apply for: once applicants have completed some basic training by :doc:contributing to Keploy <keploy/keploy/contributing.md> we highly suggest to start working on some aspects of the project they are interested in applying: all projects listed this year are improvements of existing modules so these modules already have a list of open issues which can be solved as part of your advanced training. It will also be possible to complete some of the tasks listed in the project idea right now before GSoC starts. We will list some easy tasks in the project idea for this purpose.
      Projects List
      1. AI-Powered Open-Source Code Review Agent (Using any CI/CD workflow)
      Mentors: Hermione, Gourav, Yash, Shubham
      Develop an AI-driven, open-source code review agent that integrates with version control platforms and CI/CD pipelines to provide automated feedback on coding style, security vulnerabilities, and best practices. Use any CI/CD runners and open-source static analysis tools to improve the developer experience in open-source projects.
      Description: The objective of this project is to enhance the Keploy Playground by introducing new functionalities, improving user experience, and expanding its capabilities. This includes:
      Expanding Language Support: Adding robust support for multiple programming languages such as Java and Python.
      Integrating Test & Mock Support: Providing comprehensive functionalities to generate tests and simulate mocks seamlessly.
      Improving User Onboarding: Redesigning the user experience, especially the onboarding process, to ensure a smooth introduction to Keploy’s capabilities.
      Tasks:
      Explore the architecture and workflows of various open-source code review systems to understand their impact and areas for improvement and build a matrix comparing them based on features such as accuracy, language support, ease of integration, and performance
      Build a modular webhook-based system to allow easy integration with various platforms.
      Integrate OWASP Dependency-Check or Google’s Open Source Insights (deps.dev API) to detect vulnerable dependencies.
      Export review results in JSON, Markdown, or PDF formats for offline analysis.
      Skills Required:
      CI/CD workflows & automation
      REST APIs & Webhooks
      Golang
      JavaScript/TypeScript, Node.js
      Static Code Analysis Tools (ESLint, GolangCI-Lint)
      AI/ML for automated code review - Vertex AI (Optional but beneficial)
      Refs
      ESLint: Pluggable JavaScript Linter
      GolangCI-Lint
      Time Estimate : 350 hours
      Difficulty : Hard
      2. OSS Code Indexer for Efficient Retrieval
      Mentors: Shivam, Charan, Sarthak, Shubham Jain
      Goals & Ideas Develop an efficient code indexing system that enables fast and scalable code search and retrieval. The system will integrate open source unit test geneartion with a Retrieval-Augmented Generation (RAG) indexer, utilizing vector and graph databases to improve query efficiency and relevance. The goal is to create a robust and scalable solution that can handle large open-source codebases and enable better code discovery, navigation, and reuse.
      Integrate the existing RAG bot with a vector database.
      Explore dynamic indexing techniques to improve efficiency.
      Research methodologies for leveraging GRAGs to enhance retrieval.
      Test OSS UTG with OSS Repos.
      Integrate Gemini with UTG.
      Skills Required
      Experience with RAG (Retrieval Augmented Generation) architectures.
      Knowledge of vector databases (e.g., Pinecone, FAISS, Weaviate, etc.).
      Understanding of graph databases and their integration with AI systems.
      Familiarity with indexing strategies for efficient code retrieval.
      Proficiency in Python/Golang for backend development.
      Refs
      Research papers on RAG and GRAG models.
      Documentation for vector and graph databases.
      Tasks
      Integrate the existing RAG bot with a Milvus.
      Modify the existing RAG bot to store code snippets as vector embeddings in Milvus.
      Explore dynamic indexing techniques to improve efficiency.
      Research and compare different indexing techniques (HNSW, IVF, PQ, Flat Index) for faster retrieval.
      Research methodologies for leveraging GRAGs to enhance retrieval.
      Implement a prototype that combines vector search with graph-based retrieval to improve accuracy.
      Test Open-Source UTG (Unit Test Generation) with OSS Repositories.
      Run Keploy’s OSS Unit Test Generator (UTG) on real-world repositories and suggest optimizations for the UTG model based on results.
      Use Gemini AI (Google’s LLM) to generate better test cases from indexed OSS codebases.
      Time Estimate : 350 hours
      Difficulty : Medium
      3. TestSuite Idempotency Checker
      Mentors: Animesh, Sarthak Shyngle, Neha Gupta
      Description: Ensuring idempotency in test suites is crucial for reliable and repeatable testing. This project focuses on analyzing test cases to identify operations that should be idempotent, it will help in detecting noisy parameters and inconsistencies which may lead to flaky tests.
      Goals & Ideas
      Identify Noisy Parameters – Automatically detect parameters in test cases that cause unnecessary variations, leading to non-idempotent behavior.
      Validate CRUD Operations – Ensure that CRUD requests in test cases conform to idempotency rules by verifying their consistency across multiple executions.
      HTML-based Test Verification – Check test cases that interact with HTML responses to ensure stable outputs and prevent unintended failures.
      Automated Idempotency Reporting – Develop a reporting mechanism that flags test cases violating idempotency, with insights into potential fixes.
      Tasks
      Implement Idempotency Check for GET Requests in Postman
      Denoise the un-expected Parameters (timestamp, headers, token's, change in body response) from Keploy Testcases
      Create a basic report template using Allure or Extent Reports.
      Handling noisy parameters of big payloads(10k or more lines) in the cli-diff viewer.
      Skills Required
      Scripting Languages such as Python, Bash.
      Golang
      Logical Reasoning + DSA
      Ref
      idempotency and safety in REST APIs
      How Idempotent REST APIs Boost Reliability and Error Handling
      Idempotent Message Validator
      Time Estimate : 350 hours
      Difficulty : Medium
      4. Improve Keploy Open-Source Playground console
      Mentors: Aditya Sharma, Shivam Jha, Tvisha Raji, Manas, Neha Gupta
      Description
      The goal of this project is to elevate the open-source Keploy Playground for the contributors to understand record-replay. Few of the features requests b community includes:
      Expanding Language Support: Adding support for more languages such as Java, Python, Node.
      Integrating Test & Mock Support: Adding support to fetch generated tests from the keploy server and simulated mocks which can be editable on the playground.
      Improving User Onboarding: Currently the playground lags if the payload is big, or in case of AI/ML genrated tests, the idea is to improve performance of the react console so that other community members can experience it well.
      Goals & Ideas
      Currently Loading Structure Loading is Fragile: Improve the user experience by fixing the performance issues and handling edge cases.
      Interactive Demo Environment: Build a dynamic playground console where users can interact with live demos, generate tests, and see real-time results.
      Automated Test Generation from URL Input: Allow users to provide a URL, then automatically scrape the frontend to generate a sitemap, identify API calls, and create tests based on the discovered endpoints using ATG
      Multi-Language Testing Support: Implement a flexible backend architecture that supports testing across multiple languages, making Keploy a versatile tool for a diverse range of applications.
      Skills Required
      Next.js, React, typescript
      API call handling
      Golang, Java, Python
      [optional] AI/ML
      Refs
      [source code] - https://github.com/keploy/website/tree/main/app/(default)
      Meshery Playground
      Time Estimate : 350 hours
      Difficulty : Medium
      5. API contract matching - Adding Features and Platform support
      Mentors: Gourav Kumar, Charan Kamarapu, Ahmed Lotfy, Shubham Jain
      Description: The goal of this project is to enhance the functionality of contract testing by adding new features and improving existing capabilities. This includes better schema storage, consolidation, and validation, along with exploring a provider-driven approach as a future enhancement.
      Goals & Ideas
      Schema Storage Enhancement: Implement local storage support for schemas, functioning as a mock public registry (e.g., S3).
      Unified Schema Management: Merge individual test/mock schemas into a comprehensive single schema for each service, consolidating all APIs
      Advanced Schema Comparison: Design and improve schema validation between interconnected services to ensure consistency.
      Provider-Driven Architecture: Develop and integrate a provider-driven contract testing model into Keploy, allowing service providers to define and manage contracts efficiently.
      Skills Required
      Golang
      REST APIs
      Refs
      What is Contract Testing?
      Keploy Documentation
      What is a REST API? - IBM
      A Tour of Go
      Tasks
      Implement Microservices Architecture with HTTP APIs & Validate Keploy Contract Testing
      Identify and Resolve Issues in Keploy Contract Testing Implementation
      Time Estimate : 350 hours
      Difficulty : medium
      6. App Dashboard with Metrics and Chart
      Mentors: Manas Manohar, Tvisha Raji, Hermione Dadheech, Neha Gupta
      Description
      The objective of this project is to create a console that provides interactive visualizations, metrics, and insights for code merges and test activities.
      The console should support dynamic updates and be powered by a Go web server that processes and serves data.
      It should be structured for easy extensibility, making it straightforward to add new metrics or charts in the future.
      Goals & Ideas
      Dynamic Dashboard: Develop a frontend that aggregates and displays real-time test reports using visual elements such as graphs and charts
      Template-Based PR Insights: Allow users to create and utilize templates for code analysis, offering customizable views for different teams and workflows.
      Scalable & Modular Design: Ensure the system’s architecture is modular and can accommodate new metrics, charts, or data sources with minimal effort.
      Tasks:
      Build a web app that tracks multiple repositories and user activities, offering a customizable feed of test outcomes and analytics.
      Research techniques for building modular dashboards, data processing, and integration with various version control or repository hosting services.
      Skills Required
      Next.js, Charting Libraries(e.g., Chart.js, Recharts, D3.js)
      Golang
      MongoDB
      Refs
      Grafana – For inspiration on dashboard design and real-time data visualization.
      Golang Documentation – For best practices in building scalable Go services.
      Time Estimate : 350 Hours
      Difficulty : Medium
      Task List : Good First Issue for GSoC aspirants
      Projects Good First Issue
      update website themes keploy/keploy#2536
      keploy/keploy#2535
      keploy/keploy#2534
      Improve keploy console keploy/keploy#2551
      keploy/keploy#2552
      Integrate RAG Bot with a Vector Database keploy/keploy#2533
      PR Analysis with Linting & Static Analysis in testGPT keploy/keploy#2532
      Checking of HTML-Based Test Validation keploy/keploy#2528
      a GitHub App to Trigger GitHub Actions keploy/keploy#2531
      Denoise Unexpected Parameters in Keploy Testcases keploy/keploy#2527
      Implement Idempotency Check for GET Requests keploy/keploy#2526
      SON Diff viewer re-alignment to top keploy/keploy#2524
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/keploy/
    idea_list_url: https://github.com/keploy/gsoc/tree/main/2025


  - organization_id: 76
    organization_name: Kiwix
    no_of_ideas:
    ideas_content: |
      Google Summer Of Code
      For the full list of issues you can work on, see our GitHub repositories /openZIM, /offspot and /kiwix
      GSoC has three sets of projects, lasting ~90, ~175 and ~350 hours approximately so that people who can not work full-time (because of exams or whatnot) can still participate.
      WP1
      What it is: WP1 is the bot and website that provides tables like this one on English Wikipedia. The tables help editors determine which articles they should focus on in their WikiProjects. The website also provides tools for creating a Wikipedia “selection”, ie a list of articles, so that they can create a ZIM file and have a subsetted offline version of Wikipedia.
      Project A, Combinator Builder: There are currently multiple ways to build a selection, from simple article lists to SPARQL queries. We wish to create a “combinator” builder, which allows a user to combine existing or future builders to create a final selection.
      Deliverables:
      Provide a data model for a combinator builder that integrates with the rest of the WP1 site
      Provide a UI frontend for users to create combinator builders
      Sufficient backend and frontend tests
      Skills required:
      Good understanding of Python
      Understanding of Javascript
      Understanding of Vue.js or willingness to learn
      Difficulty: Medium
      Scope: Small (about 90 hours of work)
      Project B, Scheduled selections/ZIMs: Currently, users create their selections and then manually request/create their ZIM files. However, for certain classes of selections, such as those based on WikiProjects or SPARQL queries, it is possible that the results are stale and there are more recent results available.
      We should provide a way for a user to schedule their selection being processed into a ZIM file (1 month, 3 months, 6 months, 1 year). As part of this process, the user should provide us with an email where we can notify them that their ZIM has been created. We should also remove ZIMs from the schedule if the user doesn’t “claim” them, ie come to the website and download them.
      Deliverables:
      Scheduling system for running ZIM creation tasks on set intervals
      Method for collecting email addresses, and publication of privacy policy for handling of PII
      Frontend UI for scheduling ZIM files, including handling required input and error cases
      Sufficient backend and frontend tests
      Skills required:
      Good understanding of Python
      Understanding of Javascript
      Understanding of Vue.js or willingness to learn
      Difficulty: Medium-Easy
      Scope: medium (about 120-150 hours of work)
      Interested? Check out the repo.
      Kolibri UI Revamp
      Some of the content we offer is actually harvested by our friends at Learning Equality. Kolibri2zim is the tool that allows us to package it to the ZIM format. The UI rendition isn’t great and we’d like to fix that.
      Objective: Redo the menu UIs based on a new design. Foundations have already been laid in a Git branch, but some features have not yet been implemented or are missing.
      Technologies: Vue.js + a bit of Python
      Key Deliverables:
      Finalised code changes for creating beautiful Vue.js UIs inside Kolibri ZIMs
      Skills required:
      Good understanding of JavaScript, HTML, and CSS
      Familiarity with at least one modern JS Framework (React, Vue.JS, Angular, …)
      Knowledge of web development and user interface design.
      Difficulty: Medium, but short (90 hours) project
      Interested? Check out the repo!
      Gutenberg Library UI Revamp
      We provide a ZIM copy of the Gutenberg library but saying that its layout and design is not optimal would be an understatement.
      Objective and deliverable:
      suggest and implement a new UI for this zim
      Difficulty:
      Medium (mostly because good developers suck at design, and good designers suck at coding), probably 175 hours.
      Skills required: vue.js
      Look around the gutenberg repository here.
      TED Talks UI Revamp
      We also provide a ZIM copy of the TED talks, and although it’s not as bad as Gutenberg, it could do better.
      Objective and deliverable:
      Suggest and implement a new UI for this zim
      Difficulty:
      Medium, probably 175 hours.
      Skills required: vue.js
      Check out the TED repository here.
      Hotspot Companion
      The Kiwix-hotspot is a neat adaption of the Raspberry pi microserver into a local hotspot that entire classrooms can connect to without having to download anything onto their devices. The hotpost owner downloads content from our library onto a microSD card running the Raspbian OS, and off they go, the hotspot is fully autonomous with Kiwix-server working as a regular http daemon. The problem arises when users want to update the available content, or download usage metrics collected by the hotspot.
      Objective and deliverable: Develop a mobile application prototype serving as a bridge between internet connectivity and the offline mode of a Raspberry Pi-based hotspot. The primary goal is to facilitate efficient data synchronization, allowing users to leverage internet benefits when available while ensuring a seamless offline experience. The application will have a very simple interface enabling users to manage the transfer of data between the remote server and the Raspberry Pi.
      Difficulty: Hard (it touches on many different techs but the good news is we don’t expect more than a working prototype), 350 hours.
      Skills required: mobile, flutter
      Look around the Offspot repository and meta issue here.
      Want To Join?
      Think hard about what you want to do, and go to the Google Summer of Code website between March 24 to April 8, 2025, to register and submit your project idea(s).
      After reviewing all proposals, students projects will be announced on May 8, 2025. (full timeline)
      Help & Tips
      We want to be clear upfront that we will not select candidates who have never made at least one PR to our codebase: we make our choice based on how candidates handle themselves (is the code clear, are there comments, how do they explain their choices when asked, etc.). PRs do not need to be related to the project submitted – we just need to know that you can work in a team. If we don’t know you, we can’t choose you! And if your project has “UI” in it, then it probably is a good idea to submit a mockup of what you plan to implement.
      (We also wrote a helpgul guide to Writing your Google Summer of Code application)
      Last but not least: over the years about half the students who did GSoC with Kiwix came up with their own project rather than one from our list – be bold!
      Do You Have Questions?
      Then come and join us on our Slack channel!
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kiwix/
    idea_list_url: https://kiwix.org/en/google-summer-of-code/


  - organization_id: 77
    organization_name: Kornia
    no_of_ideas:
    ideas_content: |
      ⚠️ ⚠️ [ READ APPLICATION PROTOCOL] ⚠️ ⚠️
      Projects Index
      Implement efficient SmolVLM
      Apriltag and calibration detectors
      Pointcloud registration algorithms
      Camera Pose Estimation algorithms
      Implement GPU image transforms
      Depth Estimation on Android Using Rust
      Implement modular VO Slam API
      ** projects ideas are ordered by soft priority
      Projects
      Implement efficient Smol VLM
      Description: The aim of this project is to bring State of the Art methods for lightweight Visual Language models into Kornia in Rust. Recently, Hugging Face released a family of small visual language models (SmolVLM) which can be a game changer for the industry to build applications in embedded devices using such AI models.
      Expected Outcomes: The expectation is to implement an API in Rust to integrate the latest SmolVLM model. Evaluate which NN engine suits better for this task, either onnxruntime (via ORT-Pyke) or Candle. It’s expected also to evaluate a native Rust implementation of the model and its feasibility. Tests and benchmarks in both desktop and nvidia jetson are also mandatory as part of the final delivery.
      Resources:
      Rust Book: https://doc.rust-lang.org/book/
      ORT: https://ort.pyke.io/
      Candle: https://github.com/huggingface/candle
      SmolVLM: https://huggingface.co/HuggingFaceTB/SmolLM-1.7B-Instruct
      Possible Mentors: Miquel Farre
      Difficulty: Medium
      Duration: 350 hours
      Apriltag and calibration detectors
      Description: This project aims to implement in Kornia Rust curated detection algorithms useful for localization and calibration purposes. It’s very common to use April tags for camera calibration applications; or corners detectors for more advanced machine vision applications. In the area of visual localization, common algorithms are FAST (because it is really fast), or ORB. With such methods kornia-rs could be used in many robotics applications together with existing foundational libraries such sophus-rs.
      Expected Outcomes: Implement efficient CPU versions of the above detectors with proper testing and benchmarking against common libraries such OpenCV or VPI. It’s expected also as part of the delivery to work together with the author of sophus-rs to show an integration of a calibration system using e.g the april tag detector and/or using FAST features for a Visual SLAM implementation.
      Resources:
      Rust Book: https://doc.rust-lang.org/book/
      Nvidia VPI: https://docs.nvidia.com/vpi/index.html
      Opencv-rs: https://docs.rs/opencv/latest/opencv/
      Aprilgrid-rs: https://github.com/powei-lin/aprilgrid-rs
      Sophus-rs: https://github.com/sophus-vision/sophus-rs
      Possible Mentors: Edgar Riba
      Difficulty: Hard
      Duration: 350 hours
      Pointcloud registration algorithms
      Description: This project aims to provide 3D registration capabilities to kornia-rs through pointcloud processing via implement local or global methods such as expanding the family of ICP algorithms with newer state of the art KISS family.
      Improve existing Iterative Closest Point (ICP) for point cloud alignment by adding Point to Normal loss, or evaluate again KISS-ICP.
      Optional, implement Truncated Signed Distance Function (TSDF).
      The implementations should be optimised to use for near real-time systems
      Resources:
      Rust Book: https://doc.rust-lang.org/book/
      ICP: https://manipulation.csail.mit.edu/Fall2020/pset2/pset2_ICP.html
      KISS-ICP: https://arxiv.org/abs/2209.15397
      TSDF: https://www.open3d.org/docs/0.14.1/tutorial/t_reconstruction_system/integration.html
      Possible Mentors: Sergey
      Difficulty: Hard
      Duration: 350 hours
      Camera Pose Estimation algorithms
      Description: This project aims to enhance kornia-rs's capabilities in 3D registration and pose estimation by implementing and optimizing key algorithms, including:
      Perspective-n-Point (PnP) and Efficient PnP (EPnP) for camera pose estimation
      Affine and similarity transformations (e.g., cv2.AffineTransform3D) for rigid and non-rigid transformations
      Potential optimizations for near real-time performance and robustness
      Expected Outcomes:
      A set of efficient, well-tested Rust implementations of the above algorithms
      Integration with kornia-rs for seamless use in robotics, AR, and SLAM applications
      Benchmarking and comparison with existing implementations for accuracy and performance such as Open3D
      Comprehensive documentation and examples
      Expected Outcomes:
      A set of efficient, well-tested Rust implementations of the above algorithms
      Integration with kornia-rs for seamless use in robotics, AR, and SLAM applications
      Benchmarking and comparison with existing implementations for accuracy and performance such as OpenCV
      Comprehensive documentation and examples
      Resources:
      Rust Book: https://doc.rust-lang.org/book/
      PNP : https://medium.com/@rashik.shrestha/perspective-n-point-pnp-f2c7dd4ef1ed
      KISS-ICP: https://arxiv.org/abs/2209.15397
      TSDF: https://www.open3d.org/docs/0.14.1/tutorial/t_reconstruction_system/integration.html
      Possible Mentors: Dmytro Mishkin, Daniel Barath
      Difficulty: Hard
      Duration: 350 hours
      Implement GPU image transforms
      Description: This project has the main objective to improve the existing image transformations in the kornia-imgproc crate which are currently implemented in native CPU to be upgraded to GPU. Ideally, propose a plan to upgrade the functionality in this crate into efficient GPU implementations via CubeCL or similar that can support WGP in native Rust. An example would be geometric sampling transformations like resize, or warp_affine/warp_perspective. Additionally, color transformations and Distance Transform would be very welcomed.
      Expected Outcomes: Finished implementations of the functions with proper documentation, testing and benchmarking against existing libraries such OpenCV or Nvidia VPI. Examples and tutorials are expected as part of the end of the project delivery as testing in Nvidia Jetsons.
      Resources:
      Rust Book: https://doc.rust-lang.org/book/
      Kornia Imgproc Crate: https://github.com/kornia/kornia-rs/tree/main/crates/kornia-imgproc
      CubeCL: https://github.com/tracel-ai/cubecl
      Nvidia VPI: https://docs.nvidia.com/vpi/index.html
      Opencv-rs: https://docs.rs/opencv/latest/opencv/
      Possible Mentors: Edgar Riba; Guillaume (tracel-ai)
      Difficulty: Hard
      Duration: 350 hours
      Depth Estimation on Android Using Rust
      Description: This project aims to develop an Android application using Rust to perform real-time depth estimation with ONNX Runtime via Rust bindings for ONNX Runtime. By leveraging Rust’s performance efficiency and memory safety, the application will enable on-device AI processing for applications in robotics, augmented reality (AR), SLAM, and 3D scene reconstruction.
      Expected Outcomes:
      A fully functional Rust-based Android application capable of real-time depth estimation.
      Integration of ONNX Runtime via Pyke’s Rust bindings for optimized AI inference.
      Utilization of Android’s official Rust build system for compatibility and performance.
      A lightweight, user-friendly UI for depth visualization.
      Performance benchmarking to compare execution efficiency.
      Comprehensive documentation and a demo video showcasing real-world applications.
      Resources:
      Android’s Official Build System for Rust Modules: Overview
      ONNX Runtime with Rust Bindings: ORT
      Depth Estimation Models: [Depth-Anything, MiDaS, etc.]
      Possible Mentors: Christie Jacob
      Difficulty: Medium
      Duration: 350 hours
      Implementation of VO Slam API
      Description: This project aims to build a Visual Odometry (VO) SLAM API in Rust for the Kornia-rs ecosystem, focusing first on an RGB-D pipeline (e.g., iPhone LiDAR data + Prompt DepthAnything for high-resolution, accurate depth) and subsequently extending it to monocular-only VO. The implementation should be efficient, dependency-light, and well-suited for real-time or near–real-time robotics and AR/VR use cases.
      Expected Outcomes: A VO SLAM crate in Rust that is straightforward to integrate with Kornia-rs, starting first with the simpler RGB-D visual odometry pipeline and making progress towards robust monocular visual odometry pipeline in rust.
      Resources:
      RGB-D Odometry Open3D
      Monocular Visual Odometry
      Visual Odometry From Scratch
      Global Registration Open3D
      MadPose - Relative Pose Estimation through Affine Corrections of Monocular Depth Priors
      PromptDA - Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation
      Possible Mentors: Pablo Vela
      Difficulty: Hard
      Duration: 350 hours
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kornia/
    idea_list_url: https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025

  - organization_id: 78
    organization_name: Kotlin Foundation
    no_of_ideas:
    ideas_content: |
      Home
      Get started
      Take Kotlin tour
      Kotlin overview
      What's new in Kotlin
      Kotlin evolution and roadmap
      Basics
      Concepts
      Multiplatform development
      Data analysis
      Platforms
      Standard library
      Official libraries
      API reference
      Language reference
      Tools
      Compiler and plugins
      Learning materials
      Early access preview (EAP)
      Other resources
      FAQ
      Kotlin compatibility guides
      Kotlin Foundation
      Google Summer of Code
      Overview
      GSoC 2025
      GSoC 2024
      GSoC 2023
      Security
      Kotlin documentation as PDF
      Community
      Kotlin brand assets
      Press kit
      Other resources
      Google Summer of Code
      GSoC 2025
      Google Summer of Code with Kotlin 2025
      Edit pageLast modified: 27 February 2025
      This article contains the list of project ideas for Google Summer of Code with Kotlin 2025, and contributor guidelines
      Kotlin resources:
      Kotlin GitHub repository
      Kotlin Slack and the #gsoc Slack channel
      If you got any questions, contact us via gsoc@kotlinfoundation.org
      Kotlin contributor guidelines for Google Summer of Code (GSoC)
      Getting started
      Check out the GSoC FAQ and the program announcement.
      Familiarize yourself with the Kotlin language:
      The official Kotlin website is a great place to start.
      Read the official documentation to get a better understanding of the language.
      Take a look at the Kotlin courses on JetBrains Academy or the Android team's Training options.
      Follow the Kotlin X or Kotlin Bluesky accounts to stay up to date on the latest news and developments.
      Check out the Kotlin YouTube channel for tutorials, tips, and the latest updates.
      Get to know the Kotlin open source community:
      Explore the general Kotlin contribution guidelines.
      Join the Kotlin Slack channel to connect with other developers and get help with any questions you may have.
      Join the #gsoc channel to ask questions and get support from the GSoC team.
      How to apply
      Check out the project ideas and select the one you would like to work on.
      If you are not familiar with Kotlin, read the introductory info on the Kotlin website.
      Refer to the GSoC contributor guidelines.
      Apply via the GSoC website.
      We suggest that you write a working code sample relevant to the proposed project. You can also show us any code sample that you are particularly proud of.
      Describe why you are interested in Kotlin and your experience with it.
      If you participate in open source projects, please reference your contribution history.
      If you have a GitHub, Twitter account, blog, or portfolio of technical or scientific publications, please reference them as well.
      Disclose any conflicts with the GSoC timeline due to other commitments, such as exams and vacations.
      Thank you! We look forward to reading your applications!
      Project ideas
      Build Server Protocol: add Kotlin support [Hard, 350 hrs]
      The Kotlin team wants to expand official Kotlin support not only for Gradle and Maven build systems, but any other build system as well and support them natively in JetBrains IDE with minimal effort. On the other hand, we also want to provide basic Kotlin support in non-JetBrains IDE – one part of such support is to be able to get Kotlin specific information from any build system supporting Kotlin.
      The solution to these requirements could be a Build Server Protocol (BSP) that provides an abstraction layer between build system and IDE.
      The goal of this project would be implementing a prototype which uses the BSP protocol to get all required for IDEA information from a user project to be able to work with Kotlin code in the project. To limit the scope of this prototype – user project will be using Gradle to build itself.
      Skills required (preferred)
      Kotlin
      Understanding how to write Gradle plugins
      Bonus: understanding how to write IntelliJ IDEA plugins
      Possible mentors
      Yahor Berdnikau, Bálint Hegyi, and Reinhold Degenfellner
      Tasks for applicants
      Task #1. Why are you interested in this project?
      Task #2. Practice assignment: create a Gradle plugin which exposes a specific task. This task should on the presence of Kotlin Gradle Plugin get all the Kotlin sources structure and output to the file. Having tests is a bonus
      Support Android and iOS targets in Kotlin Multiplatform for an existing Google service [Medium, 175 hrs]
      This project aims to create an open-source Kotlin Multiplatform (KMP) library that supports an existing Google service on at least Android and iOS. This project will showcase best practices in creating KMP libraries for existing services, with a focus on appropriate production implementation (for example, proper API key management, allowing user-managed API keys, client throttling).
      Expected outcomes
      A new Kotlin Multiplatform library with support for an existing Google service
      Sample code and documentation
      Skills required (preferred)
      Kotlin
      Kotlin Multiplatform
      Mobile development (Android and iOS)
      Possible mentor
      Matt Dyor, and the Google team
      Add Kotlin Multiplatform support in Bazel [Hard, 350 hrs]
      Bazel's support for Kotlin is evolving, but proper Kotlin Multiplatform (KMP) integration remains a challenge. This project aims to improve Bazel's KMP support by addressing dependency resolution issues, enhancing rules_kotlin and rules_jvm_external compatibility, and enabling cross-platform builds.
      Key improvements will focus on handling platform-specific dependencies (expect/actual mechanisms), improving Gradle metadata support, and ensuring a smoother developer experience for KMP in Bazel.
      Expected outcomes
      Enhanced dependency resolution for Kotlin Multiplatform in Bazel
      Improved integration with rules_kotlin and rules_jvm_external
      A working KMP build setup in Bazel for seamless multiplatform development
      Skills required (preferred)
      Kotlin Multiplatform and Gradle
      Bazel build system
      Dependency resolution strategies
      Possible mentor
      Shauvik Roy Choudhary, and the Uber team
      Kotlin Language Server (LSP) [Hard, 350 hrs]
      The Language Server Protocol (LSP) is a widely adopted standard that enables code intelligence features such as autocompletion, go-to definition, and refactoring across different editors and IDEs. There is currently no official Kotlin LSP server. Uber has developed an internal Kotlin LSP, but a publicly maintained, community-driven implementation can support broader use cases, including code migration, AI-powered code assistance, and seamless integration into various development environments.
      This project aims to develop a Kotlin LSP implementation, ensuring compatibility with key LSP features and broadening Kotlin's accessibility across development environments.
      Expected outcomes
      Develop a Kotlin LSP implementation
      Skills required (preferred)
      Kotlin
      Language Server Protocol (LSP)
      Plugin or extension development for IDEs
      Possible mentor
      Shauvik Roy Choudhary, and the Uber team
      Maven Central publishing plugin for Gradle with new APIs [Medium, 175 hrs]
      Maven Central is one of the most popular Maven repositories for publishing JVM-focused libraries and projects. It is actively used by Apache Maven or Gradle-based open-source projects, and based on Sonatype Nexus v2, pending migration to a newer version. There is ongoing migration of open source projects to a new Maven Central Instance, which has a very different API implementation and needs special support in the build tool plugins. Developing a Gradle plugin that is compatible with the new Maven Central publication APIs would help the library authors building with Gradle to have a smooth experience with the new process.
      Currently, there are multiple implementations of Maven Central publishing plugins in Gradle, for example, the Maven Publish Plugin or the New Maven Central Publishing, which already tries to adopt the new APIs. A potential contributor, during the application or the community bonding phase, would need to review the implementations and suggest a plugin to be updated, or decide to build a new plugin or fork. The deliverables would include either a new version of an existing plugin for Maven Central publishing or a new plugin for Gradle. We anticipate the implementation to be in Kotlin or Java and to have proper test coverage and documentation. Additional deliverables may include Kotlin DSL extensions to simplify the use of the plugins and Declarative Gradle extensions.
      Expected outcomes
      Updated Maven Central publishing plugin or a new plugin
      Skills required (preferred)
      Kotlin
      Gradle
      Maven Repositories
      Possible mentor
      Oleg Nenashev, and the Gradle team
      Improving Configuration Cache and lock contention in key Gradle plugins [Easy to Hard, 90 hrs to 350 hrs]
      Gradle is working on Isolated Projects – a new feature that greatly extends the configuration cache to further improve performance, particularly the performance of Android Studio and IntelliJ IDEA sync. From the developer experience standpoint, it is one of the most expected features in Gradle.
      One of the problems for Isolated projects is the lock contention in the Gradle core and plugins sometimes getting in the way of parallel execution. We would like to reduce the lock contention, especially in the key Gradle Build Tool plugins for Java, Kotlin, Android, and Kotlin Multiplatform ecosystems. Contributors are welcome to choose the deliverables, based on their interest and the desired project size.
      Potential deliverables include but not limited to:
      Embed the Configuration Cache Report tool into the Gradle Profiler (or implement a GitHub Action for it)
      Profile Gradle and a few popular Gradle plugins in various projects, with automation of the test suite on GHA
      Determine potential areas and plugins where lock contention can be reduced, with or without Configuration Cache
      While around, contribute to other areas of Configuration Cache compatibility in the target plugins
      Implement some of the discovered improvements
      Expected outcomes
      Implementing extensibility features in the Kotlin DSL for Gradle and improving support for common project integrations
      Skills required (preferred)
      Kotlin
      Gradle
      Java
      Performance analysis
      Profiling
      Possible mentor
      Oleg Nenashev, Laura Kassovic
      Gradle convention plugin for developing Jenkins plugins [Easy to Hard, 90 hrs to 350 hrs]
      There are more than 50 Jenkins plugins that are implemented with Gradle. There is a Gradle JPI plugin, but it is not fully compliant with Jenkins hosting requirements, and needs an update. In this project idea, the aim would be to recover the Gradle developer flow for Jenkins, reach feature parity with the Apache Maven flow (Parent POM, Plugin Compatibility Tester, Jenkins Bill of Materials, and others), and to improve the developer experience for those who develop Jenkins plugins with Gradle.
      Contributors are welcome to choose the deliverables, based on their interest and the desired project size.
      Potential deliverables include but not limited to:
      Refreshing the Gradle JPI plugin and making it compliant with hosting best practices
      Migrating the Gradle JPI plugin codebase from Groovy to Kotlin
      Implementing a new convention plugin for Jenkins Plugins that would cover the main features of Jenkins plugin Parent POM, with Kotlin and Kotlin DSL. This would include not just building the plugin, but also testing and static analysis according to Jenkins' best practices
      Adopting the refreshed plugin and/or the convention plugin in the most popular Gradle plugin, including the Gradle Plugin itself
      Integrating Gradle Plugins into Plugin Compatibility Tester and Bill of Materials
      Documenting the updated Gradle development flow for Jenkins plugins
      Expected outcomes
      Updated Gradle JPI Plugin AND/OR new convention plugin for Jenkins, published on Jenkins Update Center and Gradle Plugin Portal
      Skills required (preferred)
      Kotlin DSL
      Kotlin
      Gradle
      Jenkins
      Java
      Possible mentor
      Oleg Nenashev, Stefan Wolf
      Kotlin DSL and Declarative Gradle documentation samples test framework [Easy to Medium, 90 hrs to 175 hrs]
      Many projects, including Gradle, have a lot of Kotlin DSL samples and code snippets (see the Gradle Docs for examples). Testing them against multiple versions poses certain challenges because the snippets often represent incomplete code for the sake of brevity. We would like to build a test framework that simplifies the verification of those samples within a unit test framework (Kotest or JUnit 5) on GitHub Actions or Teamcity. Later we would be interested in doing the same for Declarative Gradle samples.
      Expected outcomes
      Implementing extensibility features in the Kotlin DSL for Gradle and improving support for common project integrations
      Skills required (preferred)
      Kotlin
      Gradle
      Java
      Static analysis
      Possible mentor
      Oleg Nenashev, Laura Kassovic
      IntelliJ Platform Gradle Plugin – Gradle Reporting and Parallel Verifications [Medium, 175 hrs]
      The IntelliJ Platform Gradle Plugin, a plugin for the Gradle build system, simplifies configuring your environment for building, testing, verifying, and publishing plugins for IntelliJ-based IDEs. The plugin manages the build, test, and verification steps while keeping up with the constant changes introduced in the IntelliJ Platform. The IntelliJ Platform Gradle Plugin is used by JetBrains, third-party developers, and external companies to integrate their workflows with JetBrains tools.
      Expected outcomes
      Introduce Gradle Reporting to provide detailed, configurable verification task reports.
      Utilize Gradle Worker API to enable parallel execution of the verifyPlugin task against multiple IntelliJ Platform versions, reducing the task execution time.
      Explore additional Gradle enhancements to further improve plugin development workflows.
      Skills required (preferred)
      Kotlin
      Gradle
      IntelliJ Platform
      Possible mentor
      Jakub Chrzanowski, JetBrains
      Add More Kotlin OpenRewrite Recipes [Medium, 175 hrs]
      OpenRewrite is a powerful framework for automating code migrations and refactorings in a structured manner. While OpenRewrite has strong support for Java, the Kotlin ecosystem would benefit from a more comprehensive set of OpenRewrite recipes to help developers seamlessly migrate their codebases.
      Expected outcomes
      Development of new OpenRewrite recipes for Kotlin code migrations
      Skills required (preferred)
      Kotlin
      OpenRewrite framework
      Java-to-Kotlin migration strategies
      Possible mentor
      Shauvik Roy Choudhary, and the Uber team
      Add BOM Support to Bazel rules_jvm_external [Hard, 350 hrs]
      Bazel's rules_jvm_external provides a structured way to declare external Java dependencies, but it currently lacks proper support for Bill of Materials (BOM) files. BOM files are widely used in Maven and Gradle to manage dependencies in a consistent manner without requiring developers to specify individual versions. This project aims to enhance rules_jvm_external by adding BOM support, allowing developers to use BOM-based dependency resolution within Bazel. The project may involve contributing to an existing open-source effort or implementing BOM support directly in rules_jvm_external, ensuring compatibility with widely used dependency management approaches.
      Expected outcomes
      Implementation of BOM support in Bazel rules_jvm_external
      Improved dependency resolution and usability for Bazel users
      Documentation and examples for using BOM support in Bazel
      Skills required (preferred)
      Starlark (Bazel's scripting language)
      Bazel build system
      Dependency resolution strategies
      Possible mentor
      Shauvik Roy Choudhary, and the Uber team
      Clean and actionable reporting for Gradle code quality plugins for Kotlin [Easy to Medium, 90 hrs to 175 hrs]
      Gradle recently introduced a new Problems API that allows Gradle and third-party plugins to propagate issues and warnings in a unified way. This API provides clean and actionable error reporting and more insights into the console output, dedicated HTML reports, and connected observability tools. IDEs, such as IntelliJ IDEA or Android Studio, also have access to the details via Gradle's tool integration API, and can show warnings right in the code editorI. Several core features and plugins have already adopted the Problems API: Java compilation, dependency resolution errors, deprecation warnings, etc. We want the code quality plugins for Kotlin to adopt this API, too; it would greatly improve the developer experience for 100,000+ Kotlin developers using Gradle.
      In this project, we invite contributors to choose a number of Kotlin code quality plugins, such as Ktlint, Detekt, Diktat, ArchUnit, or Checkstyle for Kotlin, and integrate them with Problems API. You can also work on integrating a similar analysis for Gradle builds defined with KotlinDSL.
      Expected outcomes
      Implement Problems API integration in the mentioned plugins
      Skills required (preferred)
      Kotlin
      Gradle
      Possible mentors
      Oleg Nenashev, Balint Hegyi, Reinhold Degenfellner
      Was this page helpful?
      YesNo
      Google Summer of Code with Kotlin 2025
      Kotlin contributor guidelines for Google Summer of Code (GSoC)
      Getting started
      How to apply
      Project ideas
      Build Server Protocol: add Kotlin support [Hard, 350 hrs]
      Support Android and iOS targets in Kotlin Multiplatform for an existing Google service [Medium, 175 hrs]
      Add Kotlin Multiplatform support in Bazel [Hard, 350 hrs]
      Kotlin Language Server (LSP) [Hard, 350 hrs]
      Maven Central publishing plugin for Gradle with new APIs [Medium, 175 hrs]
      Improving Configuration Cache and lock contention in key Gradle plugins [Easy to Hard, 90 hrs to 350 hrs]
      Gradle convention plugin for developing Jenkins plugins [Easy to Hard, 90 hrs to 350 hrs]
      Kotlin DSL and Declarative Gradle documentation samples test framework [Easy to Medium, 90 hrs to 175 hrs]
      IntelliJ Platform Gradle Plugin – Gradle Reporting and Parallel Verifications [Medium, 175 hrs]
      Add More Kotlin OpenRewrite Recipes [Medium, 175 hrs]
      Add BOM Support to Bazel rules_jvm_external [Hard, 350 hrs]
      Clean and actionable reporting for Gradle code quality plugins for Kotlin [Easy to Medium, 90 hrs to 175 hrs]
      Google Summer of Code with Kotlin
      Google Summer of Code with Kotlin 2024
      Contributing to KotlinReleasesPress KitSecurityBlogIssue TrackerCareersKotlin MerchOpt-Out
      Kotlin™ is protected under the Kotlin Foundation and licensed under the Apache 2 license.
      Supported and developed by JetBrains
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kotlin-foundation/
    idea_list_url: https://kotlinlang.org/docs/gsoc-2025.html


  - organization_id: 79
    organization_name: KubeVirt
    no_of_ideas:
    ideas_content: |
      Google Summer of Code 2025
      "Google Summer of Code (GSoC) is a global, online program that brings new contributors into open source software organizations." - Google Summer of Code Contributor Guide
      The KubeVirt community is applying to be a Google Summer of Code organization, to provide mentorship opportunity to applicants interested in learning about open source software development in the cloud native ecosystem.
      See the Google Summer of Code website for more information about the program.
      Key Dates
      Feb 27: List of accepted organizations announced
      Feb 27 - Mar 24: Potential contributors discuss project application ideas with organizations
      Apr 8: Contributor application deadline
      May 8 - June 1: Community Bonding Period
      June 2 - Sep 1: The Summer of Code!
      See the Google Summer of Code timeline for more detailed timeline information.
      Project Ideas
      KubeVirt is proposing the following project ideas as starting points for GSoC contributors to develop their own project applications.
      1. Dynamic attachment and removal of filesystem volumes
      GitHub issue: https://github.com/kubevirt/community/issues/384
      Description
      Direct directory sharing between a virtual machine and the host is made possible by filesystem devices. Pods and virtual machines can share the same Persistent Volume Claim thanks to this virtiofs. For instance, the capability to hotplugging an extra directory might be utilized to obtain diagnostic information from the VM and thereafter examine it.
      While attaching a disk to a running virtual machine dynamically is standard for VMs, it is an uncommon operation for pods. KubeVirt has already implemented the capability for hotplugging disks and LUNs, but it does not yet have the functionality to add or remove filesystems from a virtual machine. The volume hotplug/unplug feature isn’t supported natively by Kubernetes. KubeVirt mechanism relies on an additional pod known as the attachment pod to schedule and attach storage to the specific node where the VM is operating. Then, the storage is hotplug through Libvirt api.
      In addition, virtiofs is deployed in a separate container which is usually started together with the pod. However, in the case of hotplug, the pod cannot be dynamically modified with extra containers. This is a further challenge which needs to be taken into account during the design proposal.
      Expected outcomes
      The project goal is to propose and develop a solution based on the current approach of the attachment pod which supports filesystem volume types.
      Project requirements
      Project size: 350 hours
      Difficult: Hard
      Required skills: Kubernetes knowledge and GoLang programming skills
      Mentors: Alice Frosi: afrosi@redhat.com, German Maglione: gmaglion@redhat.com, Javier Cano Cano jcanocan@redhat.com
      See the GitHub issue for more information on the project, how to get started, and to ask questions.
      2. Adding emulated BMC support to KubeVirt (KubeVirtBMC)
      GitHub issue: https://github.com/kubevirt/community/issues/386
      Description
      KubeVirt is a virtualization API for Kubernetes, that allows to run virtual machine-based workloads on Kubernetes. [1]
      Often times, developers require the ability to deploy applications or systems in local virtual environments like bare-metal ones. Existing solutions involve libvirt domains or QEMU VMs with Basedband Management Controller (BMC) emulators, which are not directly compatible with KubeVirt, necessitating a Kubernetes-native solution. The original RFE [2] was followed up by an implementation of a BMC emulator for KubeVirt named KubeVirtBMC [3].
      KubeVirtBMC facilitates the deployment of software/applications/platforms such as OpenShift and OpenStack - whose installers typically require communication with bare-metal out-of-band management protocols like IPMI and Redfish - in KubeVirt VMs for development, testing, and debugging purposes, similar to the functionality provided by VirtualBMC [4] and sushy-emulator [5] but within a Kubernetes context.
      As a result, a KubeVirt feature proposal was created and accepted [6], which now needs to be implemented. The proposal is divided into four phases, with work on phase one having already begun.
      Expected outcomes
      The project goal is to transfer KubeVirtBMC into the KubeVirt organization and to continue the development of a native BMC emulator for KubeVirt as laid out in the accepted proposal. Phases one to three of the proposal should be completed, while phase four is optional.
      Project requirements
      Project size: 350 hours
      Difficult: Hard
      Required skills: Kubernetes knowledge, GoLang programming skills, possibly experience with BMCs and the IPMI/Redfish protocols
      Mentors: Felix Matouschek fmatouschek@redhat.com, Zespre Chang starbops@zespre.com
      See the GitHub issue for more information on the project, how to get started, and to ask questions.
      3. Self-sufficient virt-handler
      GitHub issue: https://github.com/kubevirt/community/issues/388
      Description
      Kubevirt is a Kubernetes extension to run vVirtual machines on Kubernetes clusters leveraging Libvirt + Qemu & KVM stack. It does this by exposing a custom resource called VirtualMachine which is then translated into a Pod. This Pod is treated as any other application Pods, and includes a monitoring process, virt-launcher, that manages the Libvirt+Qemu processes. The virt-launcher exposes a command grpc server for managing the virtual machine and has a notify client (see below notify server) through which it sends domain (virtual machine state) events and Kubernetes events.
      Each node in the cluster is running a node agent, called virt-handler. The virt-handler is using the command servers of virt-launchers to manage virtual machines. It is also providing a notify server that collects domain and Kubernetes events from launchers in order to obtain internal state of virtual machines.
      The hard dependencies on OS, file system, presence of virt-launcher Pod and GRPC servers make it hard to run virt-handler independently inside unprivileged Pod without the presence of virt-launcher. The goal of this project is to run virt-handler inside an unprivileged Pod and simulate a virt-launcher so that no Pod for virt-launcher needs to exist.
      Expected outcomes
      The main goal of this project is to create a proof of concept to run virt-handler in an unprivileged Pod without virt-launcher Pods to be running on the same host. This will enable scalability testing with significantly less resources required.
      Project requirements
      Project size: 350 hours
      Difficulty: Hard
      Required skills: Golang
      Desirable skills: Kubernetes, GRPC, Unix
      Mentor: Ľuboslav Pivarč lpivarc@redhat.com, Co-mentor: Victor Toso victortoso@redhat.com
      See the GitHub issue for more information on the project, how to get started, and to ask questions.
      4. Early enablement of CBOR
      GitHub issue: https://github.com/kubevirt/community/issues/389
      Description
      Kubevirt is a Kubernetes extension to run Virtual machines on Kubernetes clusters leveraging Libvirt + Qemu & KVM stack. It does this by exposing custom resources (defined by Custom Resource Definition, also known as CRD) called VirtualMachine, VirtualMachineInstance, as well as resources for backpups and other features.
      From the beginning, Kubernetes supported only json or yaml format for custom resources, in fact that was a default for core API types as well. Support for Protocol Buffers (protobuf) was introduced for core API types while CRDs were left with json/yaml because they required a schema. The protobuf helped to scale Kubernetes beyond limitations presented in the past. Kubernetes 1.32 introduced Alpha support of CBOR (Concise Binary Object Representation) for CRDs, promising a more compact format and further aiding scalability of Kubernetes and related projects.
      The goal of this project is to build a proof of concept, integrating CBOR for our client-go, as well as enabling SIG-scale testing, paving the way for adoption once the feature graduates in Kubernetes.
      Expected outcomes
      The main goal of this project is to create a proof of concept, integrating CBOR into Kubevirt in a way that can be used to run our scalability jobs. This integration will need to be guarded as the feature is not widely available, and should include a comparison of CBOR and json, visual aids and a presentation for the community about the work and findings.
      For the future, we expect guidance for enabling the feature as well summarizing the benefits from this adoption.
      Project requirements
      Project size: 350 hours
      Difficulty: Medium
      Required skills: Golang
      Desirable skills: Kubernetes
      Mentor: Ľuboslav Pivarč lpivarc@redhat.com, Co-mentor: Pending
      See the GitHub issue for more information on the project, how to get started, and to ask questions.
      Custom project proposals
      You can submit your own project idea by emailing the kubevirt-dev Google Group and CC'ing Andrew Burden aburden@redhat.com and Petr Horáček phoracek@redhat.com.
      If a mentor from the KubeVirt community supports the proposed project idea, we can add it to the KubeVirt project ideas list.
      How and where to find help
      First, try to check KubeVirt documentation, we cover many topics and you might already find some of the answers. If there is something unclear, feel free to open an issue and a PR. This is already a great start to getting in touch with the process.
      For questions related to KubeVirt and not strictly to the GSoc program, try to use the #kubevirt-dev Slack channel in the Kubernetes workspace and GitHub issues as much as possible. Your question can be useful for other people, and the mentors might have a limited amount of time. It is also important to interact with the community as much as possible.
      You can also search the Slack channel archive to see if others have previously encountered the same issue.
      If something doesn't work, try to document the steps and how to reproduce the issue as clearly as possible. The more information you provide, the easiest is for us to help you. If you open an issue in KubeVirt, this already guides you with a template with the kind of information we generally need.
      Tips on how to begin
      Install KubeVirt and deploy KubeVirt VMs following the getting started guide
      Look for good-first issues and try to solve one to get familiar with the project (if there isn’t a PR linked to it, feel free to pick it)
      Read through our General contributing guide and our Developer contributing guide for understanding of community expectations and further tips on how to get started with the project.
      How to submit the proposal
      The preferred way is to create a google doc and share it with the mentors (slack or email work). If for any reason, google doc doesn't work for you, please share your proposal by email. Early submissions have higher chances as they will be reviewed on multiple iterations and can be further improved.
      What the proposal should contain
      The design and your strategy for solving the challenge should be concisely explained in the proposal. Which components you anticipate touching and an example of an API are good starting points. The updates or APIs are merely a draft of what the candidate hopes to expand and change rather than being final. The details and possible issues can be discussed during the project with the mentors that can help to refine the proposal.
      It is not necessary to provide an introduction to Kubernetes or KubeVirt; instead, candidates should demonstrate their familiarity with KubeVirt by describing in detail how they intend to approach the task.
      Mentors may find it helpful to have a schematic drawing of the flows and examples to better grasp the solution. They will select a couple of good proposals at the end of the selection period and this will be followed by an interview with the candidate.
      The proposal can have a free form or you can get inspired by the KubeVirt design proposals and template. However, it should contain a draft schedule of the project phases with some planned extra time to overcome eventual difficulties.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kubevirt/
    idea_list_url: https://github.com/kubevirt/community/wiki/Google-Summer-of-Code-2025


  - organization_id: 80
    organization_name: Kubeflow
    no_of_ideas:
    ideas_content: |
      Kubeflow Events
      Future Events
      Google Summer of Code 2025
      Google Summer of Code 2025
      Google Summer of Code 2025
      The Kubeflow Community plans to participate in Google Summer of Code 2025. This page aims to help you participate in GSoC 2025 with Kubeflow.
      Note
      While Kubeflow participated in GSoC 2024, we are currently awaiting final confirmation of our participation in GSoC 2025. Google will announce the final list of accepted organizations on February 27, 2025.
      What is GSoC?
      Google Summer of Code (GSoC) is a global program that offers students stipends for working on open-source projects during the summer.
      For more information, see the GSoC FAQ and watch the video below:
      How can I participate?
      Thank you for your interest in participating in GSoC with Kubeflow!
      Please carefully read the following information to learn how to participate in GSoC with Kubeflow.
      Key Dates
      Here are the key dates for GSoC 2025, the full timeline is available on the GSoC website:
      Event Date
      Applications Open March 24 @ 18:00 UTC
      Applications Deadline April 8 @ 18:00 UTC
      Accepted Proposals Announced May 8
      Community Bonding May 8 - June 1
      Coding Begins June 2
      Midterm Evaluations July 14 - 18
      Coding Ends September 1
      Final Evaluations September 1 - 8
      Eligibility
      To participate in GSoC with Kubeflow, you must meet the GSoC eligibility requirements:
      Be at least 18 years old at time of registration.
      Be a student or an open source beginner.
      Be eligible to work in their country of residence during duration of program.
      Be a resident of a country not currently embargoed by the United States.
      Steps
      Sign up as a student on the GSoC website.
      Join the Kubeflow Slack:
      NOTE: please do not reach out privately to mentors, instead, start a thread in the #kubeflow-contributors channel so others can see the response.
      Learn about Kubeflow:
      Read the Introduction to Kubeflow
      Review the Architecture Overview
      Consider trying out Kubeflow (not required, can be challenging)
      Review the project ideas to decide which ones you are interested in:
      You may wish to attend the next community meeting for the group that is leading your chosen project.
      NOTE: while we recommend you submit a proposal based on the project ideas, you can also submit a proposal with your own idea.
      Submit a proposal through the GSoC website between March 24th and April 8th.
      Wait for the results to be announced on May 8th.
      Project Ideas
      Project 1: Kubeflow Platform Enhancements
      Components: Kubeflow Manifests, Kubeflow Dashboard, Kubeflow Notebooks, Kubeflow Pipelines
      Possible Mentors: @juliusvonkohout, @thesuperzapper
      Difficulty: Hard
      Size: 350 hours
      Possible Projects:
      Pipelines: productionize the SeaweedFS PoC as secure minio replacement
      Pipelines: isolate artifacts per namespace/profile/user using only one bucket (kubeflow/pipelines#4649)
      Notebooks/Dashboard: migrate code to kubeflow/dashboard and kubeflow/notebooks (kubeflow/kubeflow#7549)
      Dashboard: work on the Central Dashboard angular rewrite (kubeflow/dashboard#38)
      Dashboard: support using groups for auth (kubeflow/manifests#2910)
      Manifests: improve scripts and CI/CD in kubeflow/manifests, including matrix calls to test multiple Kubernetes versions simultaneously
      Skills Required/Preferred:
      GitHub and GitHub Actions
      containers and Kubernetes knowledge
      Experience with Python, Go and JavaScript frameworks
      Project 2: Kserve Models Web App
      Components: KServe
      Possible Mentors: @juliusvonkohout, @varodrig, @Griffin-Sullivan
      Difficulty: Medium
      Size: 175 hours
      Goals:
      Reviving and updating the kserve/kserve-models-web application.
      Clean up and merge the open issues and PRs
      Implement a better CI/CD pipeline.
      Potentially migrate the application to kubeflow/kserve-model-ui
      Add features for editing, regression testing, and monitoring/metrics support.
      Synchronize with kserve 0.14+ changes.
      Skills Required/Preferred:
      GitHub Actions
      containers and Kubernetes knowledge
      JavaScript frameworks
      Project 3: Istio CNI and Ambient Mesh
      Components: Kubeflow Manifests
      Possible Mentors: @juliusvonkohout, @kimwnasptd
      Difficulty: Medium
      Size: 175 hours
      Goals:
      Secure our service mesh with istio-cni by default (kubeflow/manifests#2907)
      Provide an out-of-box option for istio-ambient mesh (kubeflow/manifests#2676)
      Controllers to create HTTPRoute and AuthorizationPolicies, that align with way-point proxies
      Manifests to also have a flavour of HTTPRoute and updated AuthorizationPolicies
      Secure Kserve by default (kubeflow/manifests#2811)
      Rootless Kubeflow (kubeflow/manifests#2528)
      Skills Required/Preferred:
      GitHub and GitHub Actions
      Kubernetes and networking
      Istio, Kustomize
      Project 4: Deploying Kubeflow with Helm
      Components: Kubeflow Manifests, Kubeflow Pipelines, Kubeflow Trainer, Kubeflow Katib, Kubeflow Spark Operator, Kubeflow Model Registry
      Possible Mentors: @chasecadet, @varodrig, @juliusvonkohout
      Difficulty: Medium
      Size: 350 hours
      Goals:
      To extend our userbase and satisfy the requirement for a helm chart that many users and companies have voiced, a community-driven Helm chart is being developed for Kubeflow v1.10.x.
      Work with Kubeflow components maintainers and kubeflow/manifests to support the creation of Helm charts for a full Kubeflow deployment with similar functionality as the current kustomize manifests for the Kubeflow 1.10.x release.
      Investigate possible systems to automatically generate or maintain charts based on the existing kustomize manifests, such that we have a single source of truth.
      Skills Required/Preferred:
      Container and Kubernetes knowledge
      Helm (especially templating and chart creation)
      Kustomize (not strictly required, but a plus)
      Project 5: JupyterLab Plugin for Kubeflow
      Components: Kubeflow Notebooks, Kubeflow Pipelines
      Possible Mentors: @ederign, @StefanoFioravanzo
      Difficulty: Medium
      Size: 350 hours
      Goals:
      Work with the new IDE Working Group (name pending - kubeflow/community#808) to create a JupyterLab plugin for Kubeflow
      Modernizing and/or consolidating Elyra, Kale, and Jupyter Scheduler into a single plugin for Kubeflow
      Eventually, the plugin will likely integrate with:
      Kubeflow Pipelines (priority)
      Kubeflow Notebooks
      Kubeflow Model Registry
      Kubeflow Training Operator
      and more
      Skills Required/Preferred:
      Python for backend development and API integration
      JavaScript/TypeScript for frontend development
      Modern UI frameworks (e.g., React, Jupyter widgets) is a plus
      Familiarity with Jupyter Notebook, JupyterLab
      Jupyter extension development experience is a plus
      Project 6: Batch Processing Gateway Integration
      Components: Kubeflow Spark Operator
      Possible Mentors: @Shekharrajak, @lresende, @yuchaoran2011, @andreyvelich
      Difficulty: Hard
      Size: 350 hours
      Goals:
      Integrating the Batch Processing Gateway (BPG) with Kubeflow for submitting, monitoring, and managing Spark applications across multiple clusters (kubeflow/spark-operator#2422)
      Analyse, Design, Plan, and Execute Spark Job Execution Strategies:
      Evaluate the trade-offs between running a Spark kernel directly within a Kubeflow Notebook versus leveraging the Batch Processing Gateway for job submission.
      Assess the cloud-native design of Kubeflow SDK and Notebook environments to determine the optimal approach for Spark integration that maximizes efficiency, scalability, and usability.
      Make a well-informed decision on whether to support Spark kernels within notebooks, use BPG, or implement a hybrid approach for an enhanced user experience.
      Automated Job Routing and Scalable Execution:
      Implement dynamic workload routing using BPG to automatically distribute Spark jobs based on cluster load, resource availability, and workload priority.
      Integrate with the Spark Operator to optimize resource allocation, minimize execution delays, and ensure efficient scaling for petabyte-scale machine learning and data processing workloads.
      Enhanced User API and Notebook Integration:
      Develop a Python SDK for Kubeflow notebooks, enabling users to submit, manage, and monitor Spark jobs via BPG REST APIs for a lightweight, scalable solution.
      Ensure a seamless user experience by providing intuitive APIs that abstract complex job management operations, making it easier for data scientists and ML engineers to experiment and iterate on workflows within
      Comprehensive Debugging and Performance Monitoring:
      Enable full debugging capabilities by integrating Spark UI, logging, and monitoring tools into Kubeflow, allowing users to visualize Spark DAGs, tasks, and execution stages.
      Implement centralized logging and Prometheus-based monitoring to provide real-time insights into Spark job performance across clusters.
      Ensure users can efficiently analyze job execution, detect bottlenecks, and optimize data processing and ML workflows within Kubeflow.
      Note: Most of the logging APIs must be leveraged out of the box from either BPG or Spark - but we need to document, showcase examples to user.
      Comprehensive documentation and user guides to assist users in leveraging the new features effectively.
      Skills Required/Preferred:
      Proficiency in Python, Java and familiarity with developing SDKs.
      Experience with Kubernetes and managing containerized applications.
      Understanding of Apache Spark and its deployment on Kubernetes clusters.
      Familiarity with RESTful API development and integration.
      Experience with monitoring tools and logging frameworks is a plus.
      Project 7: GPU Testing for LLM Blueprints
      Components: Kubeflow Trainer (Training Operator)
      Possible Mentors: @andreyvelich, @varodrig
      Difficulty: Medium
      Size: 350 hours
      Goals:
      Explore using Self-Hosted Runners for GPU testing in Kubeflow Trainer (kubeflow/trainer#2432)
      Skills Required/Preferred:
      GitHub Actions
      Kubernetes
      PyTorch
      Python
      Project 8: Support JAX and TensorFlow Training Runtimes
      Components: Kubeflow Trainer (Training Operator)
      Possible Mentors: @Electronic-Waste, @XshubhamX, @andreyvelich
      Difficulty: Hard
      Size: 350 hours
      Goals:
      Add support TensorFlow as a training runtime in Kubeflow Trainer (kubeflow/trainer#2443)
      Add support JAX as a training runtime in Kubeflow Trainer (kubeflow/trainer#2442)
      Skills Required/Preferred:
      Go
      Kubernetes
      JAX
      TensorFlow
      Project 9: Export Kubeflow Trainer Models to Kubeflow Model Registry
      Components: Kubeflow Trainer (Training Operator), Kubeflow Model Registry
      Possible Mentors: @tarilabs, @franciscojavierarceo
      Difficulty: Hard
      Size: 350 hours
      Goals:
      Integrate Kubeflow Trainer with Kubeflow Model Registry (kubeflow/trainer#2438)
      Trainer has implemented initializers for model and dataset, and will support model exporter in the future.
      By supporting the model registry as one of the destinations of the exporter, Trainer will integrate with Kubeflow ecosystem more deeply.
      Skills Required/Preferred:
      Kubernetes
      Go
      YAML
      Python
      Project 10: Support Volcano Scheduler in Kubeflow Trainer
      Components: Kubeflow Trainer (Training Operator)
      Possible Mentors: @Electronic-Waste, @rudeigerc
      Difficulty: Hard
      Size: 350 hours
      Goals:
      Integrate Volcano Scheduler with Kubeflow Trainer (kubeflow/trainer#2437)
      Currently, Trainer does not support Volcano for scheduling.
      Since Volcano is a widely adopted scheduler for AI workloads, it could provide Trainer with more AI-specific scheduling capabilities if we integrate Volcano into Trainer
      Skills Required/Preferred:
      Kubernetes
      Go
      Volcano
      Project 11: Support Postgres for Kubeflow Pipelines backend
      Components: Kubeflow Pipelines
      Possible Mentors: @rimolive, @shivaylamba
      Difficulty: Medium
      Size: 175 hours
      Goals:
      Implement support for PostgreSQL as an alternative to MySQL/MariaDB in Kubeflow Pipelines (kubeflow/pipelines#9813)
      Kubeflow Pipelines must store information about pipelines, experiments, runs, and artifacts in a database. Currently, the only database it supports is MySQL/MariaDB.
      We plan to support PostgreSQL as an alternative to MySQL/MariaDB so users will be able to reuse existing databases, and PostgreSQL will be a good use case for supporting multiple databases.
      Skills Required/Preferred:
      Kubernetes
      Python
      Go
      YAML
      Project 12: Empowering Kubeflow Documentation with LLMs
      Components: Kubeflow Website
      Possible Mentors: @franciscojavierarceo, @chasecadet, @shravan-achar, @Shekharrajak, @varodrig
      Difficulty: Hard
      Size: 350 hours
      Goals:
      Leverage LLMs to improve Kubeflow documentation: (kubeflow/website#4025).
      Explore how other OSS communities leverage LLMs with the user documentation.
      Explore possibilities to use LLMs to improve existing Kubeflow documentation or use LLMs to help with user questions.
      Skills Required/Preferred:
      JavaScript
      Python
      HTML
      Netlify
      Hugo
      Feedback
      Was this page helpful?
      Yes No
      
      Last modified March 5, 2025: fix: SeaweedFS PoC link in GSoC project (#4031) (56f27bf)
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kubeflow/
    idea_list_url: https://www.kubeflow.org/events/gsoc-2025/
  

  - organization_id: 81
    organization_name: LLVM Compiler Infrastructure
    no_of_ideas:
    ideas_content: |
      The LLVM Compiler Infrastructure
      Site Map:
      Overview
      Features
      Documentation
      Command Guide
      FAQ
      Publications
      LLVM Projects
      Open Projects
      LLVM Users
      Bug tracker
      LLVM Logo
      Blog
      Meetings
      LLVM Foundation
      
      Download!
      Download now: LLVM 20.1.0
      All Releases
      APT Packages
      RPM Snapshots
      Pre-releases
      
      View the open-source
      license
      
      Search this Site
      
      
      Useful Links
      Forums
      LLVM Discourse
      
      Mailing Lists:
      Commits List
      
      Discord (Real-time Chat):
      Discord
      
      IRC Channel:
      irc.oftc.net #llvm
      
      Calendar:
      LLVM Community Calendar
      
      Dev. Resources:
      doxygen
      Sources (GitHub)
      Code Review
      Blog
      Bug tracker
      Buildbot
      Green Dragon
      LNT
      Scan-build
      llvm-cov
      Compile-time tracker
      
      Release Emails
      20.1.0: Mar 2025
      19.1.7: Jan 2025
      19.1.6: Dec 2024
      19.1.5: Dec 2024
      19.1.4: Nov 2024
      19.1.3: Oct 2024
      19.1.2: Oct 2024
      19.1.1: Oct 2024
      19.1.0: Sep 2024
      18.1.8: Jun 2024
      18.1.7: Jun 2024
      18.1.6: May 2024
      18.1.5: May 2024
      18.1.4: Apr 2024
      18.1.3: Apr 2024
      18.1.2: Mar 2024
      18.1.1: Mar 2024
      18.1.0: Mar 2024
      All Announcements
      
      Maintained by the
      llvm-admin team
      Open LLVM Projects
      Google Summer of Code Ideas & Projects
      Google Summer of Code 2025
      LLVM Core
      Introduce an ABI lowering library
      Byte type
      Clang
      Simple C++20 modules without a build system
      Usability Improvements for trapping Undefined Behavior Sanitizer (UBSan)
      Improve documentation parsing in Clang
      Advanced symbol resolution and reoptimization for clang-repl
      LLDB
      Rich disassembler for LLDB
      LLVM libc
      Bfloat16 in LLVM libc
      Direct I/O from the GPU with io_uring
      Profiling and testing the LLVM libc GPU math
      ClangIR
      Validate existing Clang CodeGen test coverage with ClangIR
      Participate in ClangIR upstreaming
      Clang Static Analyzer
      Teach the Clang Static Analyzer to understand lifetime annotations
      Enzyme
      Improve Enzyme reliability and compile times for Rust
      Offload (Former OpenMP Offloading)
      LLVM Compiler Remarks Visualization Tool for Offload Proposal
      Google Summer of Code 2024
      LLVM Core
      Remove undefined behavior from tests
      Automatically generate TableGen file for SPIR-V instruction set
      LLVM bitstream integration with CAS (content-addressable storage)
      Add 3-way comparison intrinsics
      Improve the LLVM.org Website Look and Feel
      The 1001 thresholds in LLVM
      Clang
      Out-of-process execution for clang-repl
      Support clang plugins on Windows
      On Demand Parsing in Clang
      Improve Clang-Doc Usability
      LLDB
      Rich disassembler for LLDB
      (OpenMP) Offload
      GPU Delta Debugging
      Offloading libcxx
      Performance tuning the GPU libc
      Improve GPU First Framework
      ClangIR
      Compile GPU kernels using ClangIR
      LLVM libc
      Half precision in LLVM libc
      Google Summer of Code 2023
      LLVM Core
      Re-optimization using JITLink
      JITLink new backends
      Improving compile times
      Addressing Rust optimization failures
      Better performance models for MLGO training
      Machine Learning Guided Ordering of Compiler Optimization Passes
      Map LLVM values to corresponding source-level expressions
      Clang
      Out-of-process execution for clang-repl
      Improve and Stabilize the Clang Static Analyzer's "Taint Analysis" Checks
      Implement autocompletion in clang-repl
      Modules build daemon: build system agnostic support for explicitly built modules
      ExtractAPI Objective-C categories
      ExtractAPI C++ Support
      ExtractAPI while building
      Improve Clang diagnostics
      Tutorial development with clang-repl
      Add WebAssembly Support in clang-repl
      LLD
      LLD Linker Improvements for Embedded Targets
      MLIR
      Optimizing MLIR’s Presburger library
      Interactively query MLIR IR
      Code Coverage
      Support a hierarchical directory structure in generated coverage html reports
      Patch based test coverage for quick test feedback
      ClangIR
      Build and run SingleSource benchmarks using ClangIR
      Enzyme
      Move additional Enzyme Rules to Tablegen
      Google Summer of Code 2022
      LLVM Core
      Implement a shared-memory based JITLinkMemoryManager for out-of-process JITting
      Modernize the LLVM "Building A JIT" tutorial series
      Write JITLink support for a new format/architecture
      Instrumentation of Clang/LLVM for Compile Time
      Richer symbol dependency information for LTO
      Machine Learning Guided Ordering of Compiler Optimization Passes
      Learning Loop Transformation Heuristics
      Evaluate and Expand the Module-Level Inliner
      Remove undef: move uninitialized memory to poison
      Add ABI/API export annotations to the LLVM build
      Clang
      Extend clang AST to provide information for the type as written in template instantiations
      Implement support for C++17 structured bindings in the Clang Static Analyzer
      Improve Clang Diagnostics
      Polly
      Completely switch to new pass manager
      Enzyme
      Move Enzyme Instruction Transformation Rules to Tablegen
      Vector Reverse-Mode Automatic Differentiation
      Enable The New Pass Manager
      Google Summer of Code 2021
      LLVM Core
      Distributed lit testing
      Learning Loop Transformation Heuristics
      Fuzzing LLVM-IR Passes
      llvm.assume the missing pieces
      Implement a shared-memory based JITLinkMemoryManager for out-of-process JITting
      Modernize the LLVM "Building A JIT" tutorial series
      Write JITLink support for a new format/architecture
      Fix fundamental issues in LLVM's IR
      Utilize LoopNest Pass
      Clang
      Extend clang AST to provide information for the type as written in template instantiations
      OpenMP
      JIT-ing OpenMP GPU kernels transparently
      OpenACC
      OpenACC Diagnostics from the OpenMP Runtime
      Polly
      Use official isl C++ bindings
      Enzyme
      Integrate custom derivatives of BLAS, Eigen, and similar routines into Enzyme
      Integrate Enzyme into Swift to provide high-performance differentiation in Swift
      Differentiation of Fixed-Point Arithmetic
      Integrate Enzyme into Rust to provide high-performance differentiation in Rust
      Clang Static Analyzer
      Clang Static Analyzer performance profiling
      Clang Static Analyzer constraint solver improvements
      LLDB
      A structured approach to diagnostics in LLDB
      Google Summer of Code 2020
      LLVM Core
      Improve debugging of optimized code
      Improve inter-procedural analyses and optimizations
      Improve parallelism-aware analyses and optimizations
      Make LLVM passes debug info invariant
      Improve MergeFunctions to incorporate MergeSimilarFunction patches and ThinLTO Support
      Add DWARF support to yaml2obj
      Improve hot cold splitting to aggressively outline small blocks
      Advanced Heuristics for Ordering Compiler Optimization Passes
      Machine learning and compiler optimizations: using inter-procedural analysis to select optimizations
      Add PostDominatorTree in LoopStandardAnalysisResults
      Create loop nest pass
      Instruction properties dumper and checker
      Unify ways to move code or check if code is safe to be moved
      Clang
      Extend clang AST to provide information for the type as written in template instantiations
      Find null smart pointer dereferences with the Static Analyzer
      LLDB
      Support autosuggestions in LLDB's command line
      Implement the missing tab completions for LLDB's command line
      Reimplement LLDB's command-line commands using the public SB API.
      Add support for batch-testing to the LLDB testsuite.
      MLIR
      See the MLIR open project list
      Google Summer of Code 2019
      LLVM Core
      Debug Info should have no effect on codegen
      Improve (function) attribute inference
      Improve LLVM binary utilities
      Clang
      Implement an ASTImporter fuzzer
      Improve shell autocompletion for Clang
      Apply the Clang Static Analyzer to LLVM-based Projects
      Generate annotated sources based on LLVM-IR analyses
      Google Summer of Code 2018
      Google Summer of Code 2017
      What is this?
      LLVM Subprojects: Clang and more
      Improving the current system
      Factor out target descriptions
      Implementing Code Cleanup bugs
      Compile programs with the LLVM Compiler
      Add programs to the llvm-test suite
      Benchmark the LLVM compiler
      Benchmark Statistics and Warning System
      Improving Coverage Reports
      Miscellaneous Improvements
      Adding new capabilities to LLVM
      Extend the LLVM intermediate representation
      Pointer and Alias Analysis
      Profile-Guided Optimization
      Code Compaction
      New Transformations and Analyses
      Code Generator Improvements
      Miscellaneous Additions
      Project using LLVM
      Add a MachineModulePass
      Encode Analysis Results in MachineInstr IR
      Code Layout in the LLVM JIT
      Improved Structure Splitting and Field Reordering
      Finish the Slimmer Project
      Written by the LLVM Team
      Google Summer of Code 2025
      Welcome prospective Google Summer of Code 2025 Students! This document is your starting point to finding interesting and important projects for LLVM, Clang, and other related sub-projects. This list of projects is not only developed for Google Summer of Code, but open projects that really need developers to work on and are very beneficial for the LLVM community.
      We encourage you to look through this list and see which projects excite you and match well with your skill set. We also invite proposals not on this list. More information and discussion about GSoC can be found in discourse . If you have questions about a particular project please find the relevant entry in discourse, check previous discussion and ask. If there is no such entry or you would like to propose an idea please create a new entry. Feedback from the community is a requirement for your proposal to be considered and hopefully accepted.
      The LLVM project has participated in Google Summer of Code for many years and has had some very successful projects. We hope that this year is no different and look forward to hearing your proposals. For information on how to submit a proposal, please visit the Google Summer of Code main website.
      Rich Disassembler for LLDB
      Description
      Use the variable location information from the debug info to annotate LLDB’s disassembler (and `register read`) output with the location and lifetime of source variables. The rich disassembler output should be exposed as structured data and made available through LLDB’s scripting API so more tooling could be built on top of this. In a terminal, LLDB should render the annotations as text.
      Expected outcomes
      For example, we could augment the disassembly for the following function
      frame #0: 0x0000000100000f80 a.out`main(argc=1, argv=0x00007ff7bfeff1d8) at demo.c:4:10 [opt]
        1   void puts(const char*);
        2   int main(int argc, char **argv) {
        3    for (int i = 0; i < argc; ++i)
      → 4      puts(argv[i]);
        5    return 0;
        6   }
      (lldb) disassemble
      a.out`main:
      ...
        0x100000f71 <+17>: movl  %edi, %r14d
        0x100000f74 <+20>: xorl  %r15d, %r15d
        0x100000f77 <+23>: nopw  (%rax,%rax)
      →  0x100000f80 <+32>: movq  (%rbx,%r15,8), %rdi
        0x100000f84 <+36>: callq 0x100000f9e ; symbol stub for: puts
        0x100000f89 <+41>: incq  %r15
        0x100000f8c <+44>: cmpq  %r15, %r14
        0x100000f8f <+47>: jne 0x100000f80 ; <+32> at demo.c:4:10
        0x100000f91 <+49>: addq  $0x8, %rsp
        0x100000f95 <+53>: popq  %rbx
      ...
      using the debug information that LLDB also has access to (observe how the source variable i is in r15 from [0x100000f77+slide))
      $ dwarfdump demo.dSYM --name  i
      demo.dSYM/Contents/Resources/DWARF/demo: file format Mach-O 64-bit x86-64
      0x00000076: DW_TAG_variable
       DW_AT_location (0x00000098:
       [0x0000000100000f60, 0x0000000100000f77): DW_OP_consts +0, DW_OP_stack_value
       [0x0000000100000f77, 0x0000000100000f91): DW_OP_reg15 R15)
       DW_AT_name ("i")
       DW_AT_decl_file ("/tmp/t.c")
       DW_AT_decl_line (3)
       DW_AT_type (0x000000b2 "int")
      to produce output like this, where we annotate when a variable is live and what its location is:
      (lldb) disassemble
      a.out`main:
      ...                                                               ; i=0
        0x100000f74 <+20>: xorl  %r15d, %r15d                           ; i=r15
        0x100000f77 <+23>: nopw  (%rax,%rax)                            ; |
      →  0x100000f80 <+32>: movq  (%rbx,%r15,8), %rdi                   ; |
        0x100000f84 <+36>: callq 0x100000f9e ; symbol stub for: puts    ; |
        0x100000f89 <+41>: incq  %r15                                   ; |
        0x100000f8c <+44>: cmpq  %r15, %r14                             ; |
        0x100000f8f <+47>: jne 0x100000f80 ; <+32> at t.c:4:10          ; |
        0x100000f91 <+49>: addq  $0x8, %rsp                             ; i=undef
        0x100000f95 <+53>: popq  %rbx
      The goal would be to produce output like this for a subset of unambiguous cases, for example, variables that are constant or fully in registers.
      Confirmed mentors and their contacts
      Adrian Prantl aprantl@apple.com (primary contact)
      Jonas Devlieghere jdevlieghere@apple.com
      Required / desired skills
      Required:
      Good understanding of C++
      Familiarity with using a debugger on the terminal
      Need to be familiar with all the concepts mentioned in the example above
      Need to have a good understanding of at least one assembler dialect for machine code (x86_64 or AArch64).
      Desired:
      Compiler knowledge including data flow and control flow analysis is a plus.
      Being able to navigate debug information (DWARF) is a plus.
      Size of the project:
      medium (~175h)
      Project difficulty:
      hard
      Discourse: URL
      Bfloat16 in LLVM libc
      Description:
      Bfloat16 is a recently developed floating point format tailored to machine learning and AI, and in the latest C++23 standard, it is officially standardized as std::bfloat16_t. Its support could be found in many modern hardware, ranging from CPUs of all the major vendors including Intel, AMD, Apple, and Amazon, to GPUs (nVidia and AMD GPUs) and Google TPUs. On the software side, it is supported in all major accelerator libraries, such as CUDA, ROCm, oneAPI, PyTorch, and Tensorflow. The goal for this project is to implement bfloat16 math functions in the LLVM libc library.
      Expected result:
      Setup the generated headers properly so that the type and the functions can be used with various compilers (+versions) and architectures.
      Implement generic basic math operations supporting bfloat16 data types that work on supported architectures: x86_64, arm (32 + 64), risc-v (32 + 64), and GPUs.
      Implement specializations using compiler builtins or special hardware instructions to improve their performance whenever possible.
      If time permits, we can start investigating higher math functions for bfloat16.
      Skills:
      Basic C & C++ skills + Interest in knowing / learning more about the delicacy of floating point formats.
      Project size: Large
      Difficulty: Easy/Medium
      Confirmed Mentors: Tue Ly, Nicolas Celik,
      Discourse: URL
      Direct I/O from the GPU with io_uring
      Description:
      Modern GPUs are capable of unified addressing with the host. We currently use this to provide I/O support using the RPC interface. However, this requires a dedicated user thread on the CPU to handle the server code. We want to explore alternatives to providing I/O from the GPU using the Linux io_uring interface.
      This interface is a ring buffer designed to accelerate syscalls. However, it provides a polling mode that allows the kernel to flush the ring buffer without the user initiating a system call. We should be able to register mmap() memory with the GPU using AMD and NVIDIA API calls. This interface should allow us to implement a rudimentary read/write interface which can be thought of as the same as the syscall on the CPU. That can then be used to implement a whole file interface.
      Expected result:
      An implementation of pwrite and pread that runs on the GPU.
      Support for printf by forwarding snprintf into pwrite.
      If time permits, exploring GPU file APIs.
      Skills:
      Basic C & C++ skills + access to a GPU, Linux kernel knowledge, GPU knowledge.
      Project size: Small
      Difficulty: Hard
      Confirmed Mentors: Joseph Huber, Tian Shilei
      Discourse: URL
      Profiling and testing the LLVM libc GPU math
      Description:
      The LLVM C library provides implementations of math functions. We want to profile these against existing implementations, such as CUDA's libdevice, ROCm's device libs, and OpenCL's libclc. Last year we worked on some interfaces to support these tests, now they need to be refined and filled out for the interesting functions.
      Additionally, we want to verify the accuracy of these functions when run on the GPU via brute force testing. The goal is to verify that the implementations are correct and at least conformant to the error ranges in the OpenCL standard. This will require a set of unit tests written in the offload/ project, ideally using the new API that @callumfare is working on.
      Expected result:
      Final performance results similar to Old results but with the more optimized functions and higher accuracy.
      A test suite that can do brute force testing to confirm that the implementations are conformant.
      Skills:
      Basic C & C++ skills + access to a GPU, some math knowledge
      Project size: Small
      Difficulty: Easy / Medium
      Confirmed Mentors: Joseph Huber, Tue Ly
      Discourse: URL
      Validate existing Clang CodeGen test coverage with ClangIR
      Description: The ClangIR (CIR) project aims to establish a new intermediate representation (IR) for Clang. Built on top of MLIR, it provides a dialect for C/C++ based languages in Clang, and the necessary infrastructure to emit it from the Clang AST, as well as a lowering path to the LLVM-IR dialect. ClangIR upstreaming is currently in progress.
      In order to give community more frequent updates it'd be great if we can report ClangIR progress by measuring the coverage of existing Clang's CodeGen tests in face of a ClangIR enabled pipeline. By collecting information on crashing, passing or failing tests we can come up with a metric that is easier to report and understand, provide entry points for newcomers looking for tasks and help the project by classifying existing issues. Existing Clang CodeGen tests live in clang/test/CodeGen* and can be found in different states regarding ClangIR support:
      FileCheck fails. LLVM IR builds but FileCheck fails to match output
      LLVM IR differs because ClangIR pipeline is emitting different IR (e.g. different instructions are used, missing attributes). Issues need to be created and ClangIR needs to be fixed.
      LLVM IR differs because CHECK lines need be made more flexible (LLVM-IR dialect output is different, SSA value names, order of attributes, etc). It's possible a tool like llvm-canon might be of good use here.
      Test crash / error. ClangIR doesn't support some C/C++ construct or LLVM lowering hasn't been implemented.
      Test pass. Yay!
      In order to retrieve the information above, the student needs to make changes to Clang's testing infra (LIT configs, scripts, tests, ???) such that it's easier to replay the same invocations with ClangIR enabled, compare against traditional pipeline result or retrieve special directives from tests.
      It's not clear what is the best methodology just yet, but it's expected that submitted proposals that want to be taken seriously should present few possible ideas on how to achieve this, prior discussion with other members of the community is encouraged. The student is also expected to interact with the ClangIR community, file github issues, investigate and/or make changes to failing codegen tests.
      Expected result:
      Build the infrastructure to run tests and collect results.
      Present the results in a way that can be placed on a webpage.
      File issues or change check lines for 50% of the "FileCheck fails" category above. The only subdirectories that need consideration for the moment are:
          clang/test/CodeGen
          clang/test/CodeGenCXX
          clang/test/CodeGenOpenCL
          clang/test/CodeGenCUDA
          
      Bonus point: find ways to automate/facilitate changes to tests, put PRs to fix problems in ClangIR.
      Skills: Python, intermediate C++ programming skills and familiarity with basic compiler design concepts are required. Prior experience with LLVM IR, MLIR, Clang or ClangIR programming is a big plus, but willingness to learn is also a possibility.
      Project size: Large
      Difficulty:Medium
      Potential Mentors: Bruno Cardoso Lopes Andy Kaylor
      Discourse: URL
      Participate in ClangIR Upstreaming
      Description: ClangIR is a new, MLIR_based intermediate representation of C and C++ code. It has been developed in an LLVM incubator project, but work is now underway to migrate the code from the incubator to the main LLVM repository. As the code is moved, it must be updated to align with LLVM coding standards and quality expectations. The goal for this project is to participate in the ClangIR upstreaming process and help improve both the code and the upstreaming process.
      The ClangIR project intends to unlock the possibility of better optimization, analysis, and diagnostics for C and C++ code by adding new abstractions that more closely model the source constructs, preserving more details than are available in standard LLVM IR. The ClangIR dialect is already being used to solve real-world problems using the implementation available in the ClangIR incubator, but we need to move this into the main LLVM repository in order to make this functionality available to a larger audience.
      This project will be an opportunity to gain hands-on experience with MLIR development with a focus on day-to-day software engineering discipline. Participants will work side-by-side with other LLVM contributors to achieve a common goal, and in the process will gain a deep understanding of the ClangIR dialect.
      Expected result:
      Migrate ClangIR support for C and C++ language features into the main LLVM repository
      Improve the quality of code as it is being migrated
      Suggest ways to improve the migration process
      Skills: Proficiency with modern C++ programming and familiarity with basic compiler design concepts are required. Prior experience with LLVM IR, MLIR, Clang or ClangIR programming is a big plus, but since the goal of this project is to gain such experience, it is not a prerequisite.
      Project size: Medium to Large
      Difficulty:Medium
      Potential Mentors: Andy Kaylor Bruno Cardoso Lopes
      Discourse: URL
      Teach the Clang Static Analyzer to understand lifetime annotations
      Description: The Clang Static Analyzer (CSA) can already find a wide range of temporal memory errors. These checks often have hardcoded knowledge about the behavior of some APIs. For example, the cplusplus.InnerPointer checker knows the semantics of std::string::data. The Clang community introduced some lifetime annotations including [[clang::lifetimebound]] and [[clang::lifetime_capture_by(X)]] and made many improvements to Clang's default warnings. Unfortunately, the compiler's warnings only do statement local analysis. The CSA is capable of advanced inter-procedural analysis. Generalizing the existing checks like cplusplus.InnerPointer could enable the analyzer to find even more errors in annotated code. This can become even more impactful once the standard library gets annotated.
      Expected result:
      Identify the checks that can benefit from the [[clang::lifetimebound]] and [[clang::lifetime_capture_by(X)]] annotations.
      Extend those checks to support these annotations.
      Make sure the generated bug reports are high quality, the diagnostics properly explain how the analyzer took these annotations into account.
      Validate the results on real world projects.
      Potentially warn about faulty annotations (stretch goal).
      Skills: Intermediate C++ programming skills and familiarity with basic compiler design concepts are required. Prior experience with Clang or CSA programming is a big plus, but willingness to learn is also a possibility.
      Project size: Large
      Difficulty:Hard
      Potential Mentors: Gabor Horvath Balazs Benics Daniel Domjan
      Discourse: URL
      Simple C++20 modules without a build system
      Description
      Currently there is no easy way to take a collection of source files using C++20 modules and build an executable from them. This makes it hard to create simple tests or tiny programs using C++20 modules without first setting up a build system. This project's goal is to extend the extremely simple build system in Clang's driver to handle these cases.
      This can be done by using Clang's existing support for scanning for C++20 modules to discover the dependencies between the source files that have been passed in, and then build them in that order, passing in the right PCM files where needed. This may also be extended to support explicitly building Clang modules discovered via module map files too.
      Expected outcomes
      Invoking clang similarly to
      clang -o program -std=c++20 main.cpp A.cppm B.cppm
      should compile successfully where each translation-unit only imports modules defined in other source files on the command line, or the standard library. This should add no overhead to cases where modules are not used.
      Confirmed mentors and their contacts
      Michael Spencer
      Required skills
      Intermediate knowledge of C++; familiarity with how C++ code is built. Familiarity with C++20 modules is an asset, but not required.
      Size of the project:
      medium (~175h)
      Project difficulty:
      medium
      Discourse: URL
      Usability Improvements for trapping Undefined Behavior Sanitizer (UBSan)
      Description
      Undefined Behavior Sanitizer (UBSan) is a useful compilation mode in Clang for finding uses of undefined behavior (e.g. signed integer overflow) and problematic C/C++ code (e.g. unsigned integer overflow). The default version of UBSan uses a compiler runtime that only works in userspace (e.g. it won’t work in the kernel or for embedded applications) and is not considered secure enough for use in production environments. To handle these other environments UBSan provides a trapping mode that emits trap instructions that immediately halts the application rather than calling into the UBSan runtime which normally diagnoses the problem and then carries on execution.
      Unfortunately trapping UBSan has some deficiencies which make it hard to use. In particular:
      Clang silently ignores the -fsanitize-trap=undefined flag when it's passed without -fsanitize=undefined. This project would fix this as a “warm up task” to get familiar with the Clang codebase.
      When a UBSan trap is hit with the debugger attached it is not convenient to figure out the reason UBSan trapped. For x86_64 and arm64 some information is encoded in the instruction but decoding this is very inconvenient. While LLDB could be taught to look at the instruction and decode the meaning this is brittle because it depends on undocumented compiler ABI. Instead we can build upon the __builtin_verbose_trap work to encode the reason for trapping ("trap reasons") inside the debug information. If time permits we can also investigate emitting more precise trap reasons
      Expected outcomes
      When the -fsanitize-trap=undefined flag is passed on its own the compiler silently ignores it. Currently Clang requires that the -fsanitize-trap= flag is also passed. Clang should be taught to warn about this.
      Teach Clang to emit the UBSan trap reasons in debug information on UBSan trap instructions similar to how __builtin_verbose_trap works.
      Confirm LLDB is able to recognize the UBSan trap reasons and add tests for this.
      If time permits we should investigate emitting more precise trap reasons by using information available in the compiler. We may want to implement a "Sema Diagnostic" like approach where trap reason strings can easily be constructed inside the compiler. This task is more open-ended and has potentially uses outside of UBSan (e.g. -fbounds-safety).
      Confirmed mentors and their contacts
      Dan Liew
      Michael Buch
      Required skills
      Good understanding of C++
      Desirable skills
      Familiarity with UBSan
      Familiarity with LLDB
      Size of the project:
      small (~90h). but can be extended if time allows
      Project difficulty:
      Easy. This project would be good for a beginner to LLVM. Note the "emitting more precise trap reasons" portion is more open ended and so the difficulty of this is entirely down to direction the applicant chooses.
      Discourse: URL
      Improve documentation parsing in Clang
      Description of the project: Clang-Doc is a C/C++ documentation generation tool created as an alternative for Doxygen and built on top of LibTooling. This effort started in 2018 and critical mass has landed in 2019, but the development has been largely stagnant mostly due to a lack of resources until last year when the development restarted as a successful Google Summer of Code project.
      
      The tool is built on top of LibTooling and leverages Clang parsers which supports parsing of Doxygen commands in documentation comments (this support is also used in the implementation of Clang’s
      -Wdocumentation
      which can be used to validate the content of documentation comments during compilation).
      
      Unfortunately, Clang’s documentation parser is incomplete and has several issues:
      Not all Doxygen commands are supported, limiting the Clang-Doc’s usability.
      Not all C/C++ constructs are currently handled, most notably C++20 features such as concepts.
      Markdown support in documentation comments introduced in Doxygen version 1.8.0 is missing.
      Expected result: The goal of this project is to implement the missing features in Clang’s documentation parser as well as their handling in Clang-Doc to improve the quality of the generated documentation. The eventual goal is for the LLVM project to start using Clang-Doc for generating its reference documentation, but before we can do that we need to ensure that all required features are implemented.
      
      Successful proposals should focus not only on addressing the existing limitations, but also draw inspiration for other potential improvements from other documentation tools such as hdoc, standardese, subdoc or cppdocgen.
      
      Over the course of the project, the candidate will have an opportunity to gain significant experience with LLVM and Clang internals (including lexer and parser) and C/C++ language.
      Skills: Intermediate knowledge of C++; interest in compilers and parsers. Previous experience with Clang/LibTooling is a bonus but not required.
      Project size: Either medium or large.
      Difficulty: Medium
      Confirmed Mentor: Petr Hosek, Paul Kirth
      Discourse: URL
      Advanced symbol resolution and reoptimization for clang-repl
      Description of the project: The Clang compiler is part of the LLVM compiler infrastructure and supports various languages such as C, C++, ObjC and ObjC++. The design of LLVM and Clang enables them to be used as libraries, and has led to the creation of an entire compiler-assisted ecosystem of tools. The relatively friendly codebase of Clang and advancements in the JIT infrastructure in LLVM further enable research into different methods for processing C++ by blurring the boundary between compile time and runtime. Challenges include incremental compilation and fitting compile/link time optimizations into a more dynamic environment. Incremental compilation pipelines process code chunk-by-chunk by building an ever-growing translation unit. Code is then lowered into the LLVM IR and subsequently run by the LLVM JIT. Such a pipeline allows creation of efficient interpreters. The interpreter enables interactive exploration and makes the C++ language more user friendly. Clang-Repl is one example.
      Expected result: The project aims to develop a robust mechanism for resolving missing symbols by dynamically identifying and loading the appropriate shared objects or static archives. Additionally, it will explore use cases where adapting symbols based on execution profiles leads to measurable performance improvements, optimizing the efficiency of just-in-time compilation and dynamic execution environments.
      Skills: Intermediate knowledge of C++, Understanding of LLVM and the LLVM JIT in particular
      Project size:Either medium or large.
      Difficulty: Medium
      Confirmed Mentor: Vassil Vassilev
      Discourse: URL
      Improve Enzyme reliability and compile times for Rust
      Description
      Enzyme requires good information about the memory layout of types. LLVM-IR is intentionally opaque, e.g. `&f32` and `&f64` both have the LLVM-IR type `ptr`. Enzyme is generally able to infer the underlying type (e.g. f32 vs f64) through usage analysis, but that process is slow and can in some cases fail. To make autodiff more robust, we should lower either MIR or THIR type information into LLVM-IR metadata. This analysis is recursive, for example `&[T]` is a fat pointer and therefore will be represented as a (ptr, int) pair in LLVM-IR. In this case the algorithm should recursively also analyze `T` and generate metadata for it.
      The function here can be extended to generate metadata from rusts Mid-level IR (MIR). A prototype of the parser was implemented here and can be used for inspiration. Various LLVM-IR examples for the metadata which we want to generate can be found in this test folder. Look for annotations in the style of ` {[-1]:Pointer, [-1,0]:Float@float}`.
      The online compiler Explorer fork can be used to trigger related bugs, starting with "can not deduce type of X".
      Expected outcomes
      The participant should find and select some interesting testcases, in which Enzyme either fails to differentiate an example due to inssuficient Type Information, or takes unreasonable long times (e.g. > 20x slower than compiling the code without autodiff). In the second case, a profiler should be used to verify that Enzyme causes a long compile time due to type analysis. The participant should then write (or later extend) the Type parser to generate the correct metadata, such that Enzyme can handle the new testcases. The LIT testcases should be added to the rust compiler, to avoid further regressions.
      Examples for code that currently is not handled correctly can be discussed in the project proposal phase.
      Confirmed mentors and their contacts
      Manuel Drehwald
      Oli Scherer
      Johannes Doerfert
      Required skills
      Intermediate knowledge of Rust and C++; Familiarity with profilers or LLVM metadata is an asset, but not required.
      Size of the project:
      medium (~175h)
      Project difficulty:
      medium
      Discourse: URL
      Introduce an ABI lowering library
      Description: Currently, every LLVM-based frontend that wants to support calling into C code (FFI) needs to re-implement a substantial amount of complex call ABI handling. The goal of this project is to introduce an LLVM ABI library, which can be reused across different frontends, including Clang. More details on the motivation and a broad outline of the design are available in the corresponding RFC.
      The initial phase of the project will be to implement a prototype that can handle at least the x86_64 System V ABI. This will involve implementing the ABI type system, mapping of Clang types to ABI types and moving at least part of the X86 ABIInfo implementation from Clang to the new ABI library. This is to demonstrate general feasibility, figure out design questions and analyze compilation-time impact.
      Assuming the results from the prototype are positive, the next step would be to upstream the implementation by splitting it into smaller PRs. Finally, the implementation can be expanded to cover additional targets, ultimately removing Clang's ABI handling code entirely.
      Expected result: The minimum result is a prototype for the x86_64 ABI. The maximum result is fully upstreamed support for all targets. The expected result is somewhere in the middle between those two.
      Skills: Intermediate C++. Some familiarity with LLVM is a plus, but not required.
      Project size: Large
      Difficulty: Hard
      Confirmed mentors: Nikita Popov
      Discourse: URL
      Byte type
      Description: LLVM IR can't represent implementations of memcpy, memcmp, etc correctly due to the lack of a way to represent raw memory. This project aims to add a new 'byte' type to the LLVM IR to represent raw memory.
      In addition to adding the new type, the project involves changing clang to lower chars to the new b8 type instead of i8, fixing incorrect lowerings of memory intrinsics, and tracking down the performance regressions.
      There is already a prototype implementation of the byte type for an older version of LLVM. More information here.
      Expected result: The minimum result is a port of the existing prototype to the current LLVM, fixing all known incorrect optimizations, add support for the byte type to Alive2, and a performance analysis.
      Skills: Intermediate C++, familiarity with LLVM, profiling.
      Project size: Large
      Difficulty: Hard
      Confirmed mentors: Nuno Lopes
      Discourse: URL
      LLVM Compiler Remarks Visualization Tool for Offload Proposal
      Description: LLVM offers different information via remarks, profiling, or runtime debug annotations (e.g., LIBOMPTARGET_INFO=-1). However, as projects increase, dissecting this information becomes difficult for users. For example, it is difficult to collect all this data, visualize it, and learn from it when building large projects.
      Currently, some of this information—for example, compilation remarks—can be exported in JSON format. We want to create a tool to visualize, aggregate, and summarize the information. To aid accelerator development, we will start with the offload project as the primary candidate.
      Similar tools, such as opt-viewer, can be used as references and starting points.
      Expected outcomes: The expected outcome is a tool (e.g., in the form of a compiler wrapper such as ccache) that will allow the dump of all the compiler-generated information in JSON format and organize it in a project structure.
      The tool should generate an HTML-based report to help visualize the remarks. We envision a small client-server application using Python to spawn a local server as the visualization's front end. The server will expose the different reports and perform early analysis and aggregation.
      Additionally, the tool should be designed so that, in the future, the analysis of the remarks can provide generalized guidelines for the developer (e.g., show the most common remark, use LLM models to explain actions, etc.). The client (HTML viewer) will display the aggregated data, in-line remarks, profile information, etc. We do not expect the project to have all the features at the end of the GSoC but to serve as a placeholder for growth in the future.
      In particular, the outcomes of this project should be:
      Together with the mentors, help the design of the compiler wrapper, data storage layer, and client/server infrastructure. This includes the server API. The outcome of this task is a design document (similar to an RFC).
      Create a compiler wrapper that will dump different information in JSON format into the data storage layer (e.g., folders).
      Create a simple server layer that exposes the backend API to the front end. Python is the right way to do this, but we welcome other suggestions that align with the LLVM project. We would like to avoid relying on external projects (e.g., Flask) to avoid adding more dependencies to the LLVM project.
      Create a simple client-side visualization tool that can be extended in the future to show more reports.
      Mentors: @shiltian, @jdoerfert, @josemonsalve2
      Required/desired skills:
      Basic understanding of the LLVM Compiler to be able to generate compiler remarks, profiling data, and other information from the compiler.
      Proficiency in Python and C++.
      Full-stack web development.
      Project size: Large
      Difficulty: Easy
      Discourse Link: [GSoC][Offload]LLVM Compiler Remarks Visualization Tool for Offload Proposal
      Google Summer of Code 2024
      Google Summer of Code 2024 was yet another successful one for LLVM project. For the list of accepted and completed projects, please take a look into Google Summer of Code website.
      Welcome prospective Google Summer of Code 2024 Students! This document is your starting point to finding interesting and important projects for LLVM, Clang, and other related sub-projects. This list of projects is not only developed for Google Summer of Code, but open projects that really need developers to work on and are very beneficial for the LLVM community.
      We encourage you to look through this list and see which projects excite you and match well with your skill set. We also invite proposals not on this list. More information and discussion about GSoC can be found in discourse . If you have questions about a particular project please find the relevant entry in discourse, check previous discussion and ask. If there is no such entry or you would like to propose an idea please create a new entry. Feedback from the community is a requirement for your proposal to be considered and hopefully accepted.
      The LLVM project has participated in Google Summer of Code for several years and has had some very successful projects. We hope that this year is no different and look forward to hearing your proposals. For information on how to submit a proposal, please visit the Google Summer of Code main website.
      Remove undefined behavior from tests
      Description of the project: Many of LLVM's unit tests have been reduced automatically from larger tests. Previous-generation reduction tools used undef and poison as placeholders everywhere, as well as introduced undefined behavior (UB). Tests with UB are not desirable because 1) they are fragile since in the future the compiler may start optimizing more aggressively and break the test, and 2) it breaks translation validation tools such as Alive2 (since it's correct to translate a fuction that is always UB into anything).
      The major steps include:
      Replace known patterns such as branch on undef/poison, memory accesses with invalid pointers, etc with non-UB patterns.
      Use Alive2 to detect further patterns (by searching for tests that are always UB).
      Report any LLVM bug found by Alive2 that is exposed when removing UB.
      Expected result: The majority of LLVM's unit tests will be free of UB.
      Skills: Experience with scripting (Python or PHP) is required. Experience with regular expressions is encouraged.
      Project size: Either medium or large.
      Difficulty: Medium
      Confirmed Mentor: Nuno Lopes
      Discourse: URL
      Automatically generate TableGen file for SPIR-V instruction set
      Description of the project: The existing file that describes the SPIR-V instruction set in LLVM was manually created and is not always complete or up to date. Whenever new instructions need to be added to the SPIR-V backend, the file must be amended. In addition, since it is not created in a systematic way, there are often slight discrepancies between how an instruction is described in the SPIR-V spec and how it is declared in the TableGen file. Since SPIR-V backend developers often use the spec as a reference when developing new features, having a consistent mapping between the specification and TableGen records will ease development. This project proposes creating a script capable of generating a complete TableGen file that describes the SPIR-V instruction set given the JSON grammar available in the KhronosGroup/SPIRV-Headers repository, and updating SPIR-V backend code to use the new definitions. The specific method used for translating the JSON grammar to TableGen is left up to the discretion of the applicant, however, it should be checked into the LLVM repository with well-documented instructions to replicate the translation process so that future maintainers will be able to regenerate the file when the grammar changes. Note that the grammar itself should remain out-of-tree in its existing separate repository.
      Expected result:
      The SPIR-V instruction set's definition in TableGen is replaced with one that is autogenerated.
      A script and documentation are written that support regenerating the definitions as needed given the JSON grammar of the SPIR-V instruction set.
      Usage of the SPIR-V instruction set in the SPIR-V backend updated to use the new autogenerated definitions.
      Skills: Experience with scripting and an intermediate knowledge of C++. Previous experience with LLVM/TableGen is a bonus but not required.
      Project size: Medium (175 hour)
      Confirmed Mentors: Natalie Chouinard, Nathan Gauër
      Discourse: URL
      LLVM bitstream integration with CAS (content-addressable storage)
      Description of the project: The LLVM bitstream file format is used for serialization of intermediate compiler artifacts, such as LLVM IR or Clang modules. There are situations where multiple bitstream files store identical information, and this duplication leads to increased storage requirements.
      
      This project aims to integrate the LLVM CAS library into the LLVM bitstream file format. If we factor out the frequently duplicated part of a bitstream file into a separate CAS object, we can replace all copies with a small reference to the canonical CAS object, saving storage.
      
      The primary motivating use-case for this project is the dependency scanner that's powering "implicitly-discovered, explicitly-built" Clang modules. There are real-world situations where even coarse de-duplication on the block level could halve the size of the scanning module cache.
      Expected result: There's a way to configure the LLVM bitstream writer/reader to use CAS as the backing storage.
      Skills: Intermediate knowledge of C++, some familiarity with data serialization, self-motivation.
      Project size: Medium or large
      Confirmed Mentors: Jan Svoboda, Steven Wu
      Discourse: URL
      Add 3-way comparison intrinsics
      Description of the project: 3-way comparisons return the values -1, 0 or 1 depending on whether the values compare lower, equal or greater. They are exposed in C++ via the spaceship operator (operator<=>) and in Rust via the PartialOrd and Ord traits. Currently, such comparisons produce sub-optimal codegen and optimization results in some cases.
      
      The goal of this project is to resolve these optimization issues by implementing new 3-way comparison intrinsics, as described in [RFC] Add 3-way comparison intrinsics. The implementation steps are broadly:
      Add the intrinsics to LLVM IR.
      Implement legalization/expansion support in SelectionDAG and GlobalISel.
      Implement optimization support in ConstantFolding, InstSimplify, InstCombine, CorrelatedValuePropagation, IndVarSimplify, ConstraintElimination, IPSCCP, and other relevant transforms.
      Make use of the intrinsics via InstCombine canonicalization or direct emission in clang/rustc.
      Adding new target-independent intrinsics is a good way of becoming familiar with a broad slice of LLVM!
      Expected result: Support for the intrinsics in the backend and the most important optimization passes. Ideally full integration starting at the frontend.
      Skills: Intermediate knowledge of C++
      Project size: Medium or large
      Difficulty: Medium
      Confirmed Mentors: Nikita Popov, Dhruv Chawla
      Discourse: URL
      Improve the LLVM.org Website Look and Feel
      Description of the project: The llvm.org website serves as the central hub for information about the LLVM project, encompassing project details, current events, and relevant resources. Over time, the website has evolved organically, prompting the need for a redesign to enhance its modernity, structure, and ease of maintenance.
      
      The goal of this project is to create a contemporary and coherent static website that reflects the essence of LLVM.org. This redesign aims to improve navigation, taxonomy, content discoverability, mobile device support, accessibility, and overall usability. Given the critical role of the website in the community, efforts will be made to engage with community members, seeking consensus on the proposed changes.
      Expected result: A modern, coherent-looking website that attracts new prospect users and empowers the existing community with better navigation, taxonomy, content discoverability, and overall usability. Since the website is a critical infrastructure and most of the community will have an opinion this project should try to engage with the community building community consensus on the steps being taken. Suggested approach:
      Conduct a comprehensive content audit of the existing website.
      Select appropriate technologies, preferably static site generators like Hugo or Jekyll.
      Advocate for a separation of data and visualization, utilizing formats such as YAML and Markdown to facilitate content management without direct HTML coding.
      Present three design mockups for the new website, fostering open discussions and allowing time for alternative proposals from interested parties.
      Implement the chosen design, incorporating valuable feedback from the community.
      Collaborate with content creators to integrate or update content as needed.
      The successful candidate should commit to regular participation in weekly meetings, deliver presentations, and contribute blog posts as requested. Additionally, they should demonstrate the ability to navigate the community process with patience and understanding.
      Skills: Knowledge in the area of web development with static site generators. Knowledge in html, css, bootstrap, and markdown. Patience and self-motivation.
      Difficulty: Hard
      Project size: Large
      Confirmed Mentors: Tanya Lattner, Vassil Vassilev
      Discourse: URL
      Out-of-process execution for clang-repl
      Description of the project: The Clang compiler is part of the LLVM compiler infrastructure and supports various languages such as C, C++, ObjC and ObjC++. The design of LLVM and Clang enables them to be used as libraries, and has led to the creation of an entire compiler-assisted ecosystem of tools. The relatively friendly codebase of Clang and advancements in the JIT infrastructure in LLVM further enable research into different methods for processing C++ by blurring the boundary between compile time and runtime. Challenges include incremental compilation and fitting compile/link time optimizations into a more dynamic environment.
      
      Incremental compilation pipelines process code chunk-by-chunk by building an ever-growing translation unit. Code is then lowered into the LLVM IR and subsequently run by the LLVM JIT. Such a pipeline allows creation of efficient interpreters. The interpreter enables interactive exploration and makes the C++ language more user friendly. Clang-Repl is one example.
      
      Clang-Repl uses the Orcv2 JIT infrastructure within the same process. That design is efficient and easy to implement however it suffers from two significant drawbacks. First, it cannot be used in devices which do not have sufficient resources to host the entire infrastructure, such as the arduino due (see this talk for more details). Second, crashes in user codes mean that the entire process crashes, hindering overall reliability and ease of use.
      
      This project aims to move Clang-Repl to an out-of-process execution model in order to address both of these issues.
      Expected result: Implement an out-of-process execution of statements with Clang-Repl; Demonstrate that Clang-Repl can support some of the ez-clang use-cases; Research into approaches to restart/continue the session upon crash; As a stretch goal design a versatile reliability approach for crash recovery;
      Skills: Intermediate knowledge of C++, Understanding of LLVM and the LLVM JIT in particular
      Project size:Either medium or large.
      Difficulty: Medium
      Confirmed Mentor: Vassil Vassilev,
      Discourse: URL
      Support clang plugins on Windows
      Description of the project: The Clang compiler is part of the LLVM compiler infrastructure and supports various languages such as C, C++, ObjC and ObjC++. The design of LLVM and Clang allows the compiler to be extended with plugins[1]. A plugin makes it possible to run extra user defined actions during a compilation. Plugins are supported on unix and darwin but not on windows due to some specifics of the windows platform.
      
      This project would expose the participant to a broad cross section of the LLVM codebase. It involves exploring the API surface, classifying the interfaces as being public or private, and annotating that information to the API declarations. It would also expose the participant to details and differences of different platforms as this work is cross-platform (Windows, Linux, Darwin, BSD, etc). The resulting changes would improve LLVM on Linux and Windows while enabling new functionality on Windows.
      Expected result: This project aims to allow make clang -fplugin=windows/plugin.dll work. The implementation approach should extend the working prototype [3] and extend the annotation tool [4]. The successful candidate should be prepared to attend a weekly meeting, make presentations and prepare blog posts upon request.
      Further reading
      [1] https://clang.llvm.org/docs/ClangPlugins.html
      [2] https://discourse.llvm.org/t/clang-plugins-on-windows
      [3] https://github.com/llvm/llvm-project/pull/67502
      [4] https://github.com/compnerd/ids
      Skills: Intermediate knowledge of C++, Experience with Windows and its compilation and linking model.
      Project size:Either medium or large.
      Difficulty: Medium
      Confirmed Mentor: Vassil Vassilev, Saleem Abdulrasool
      Discourse: URL
      On Demand Parsing in Clang
      Description of the project: Clang, like any C++ compiler, parses a sequence of characters as they appear, linearly. The linear character sequence is then turned into tokens and AST before lowering to machine code. In many cases the end-user code uses a small portion of the C++ entities from the entire translation unit but the user still pays the price for compiling all of the redundancies.
      
      This project proposes to process the heavy compiling C++ entities upon using them rather than eagerly. This approach is already adopted in Clang’s CodeGen where it allows Clang to produce code only for what is being used. On demand compilation is expected to significantly reduce the compilation peak memory and improve the compile time for translation units which sparsely use their contents. In addition, that would have a significant impact on interactive C++ where header inclusion essentially becomes a no-op and entities will be only parsed on demand.
      
      The Cling interpreter implements a very naive but efficient cross-translation unit lazy compilation optimization which scales across hundreds of libraries in the field of high-energy physics.
      
      // A.h
      #include <string>
      #include <vector>
      template <class T, class U = int> struct AStruct {
        void doIt() { /*...*/ }
        const char* data;
        // ...
      };
      
      template<class T, class U = AStruct<T>>
      inline void freeFunction() { /* ... */ }
      inline void doit(unsigned N = 1) { /* ... */ }
      
      // Main.cpp
      #include "A.h"
      int main() {
        doit();
        return 0;
      }
          
      
      
      This pathological example expands to 37253 lines of code to process. Cling builds an index (it calls it an autoloading map) where it contains only forward declarations of these C++ entities. Their size is 3000 lines of code. The index looks like:
      // A.h.index
      namespace std{inline namespace __1{template <class _Tp, class _Allocator> class __attribute__((annotate("$clingAutoload$vector")))  __attribute__((annotate("$clingAutoload$A.h")))  __vector_base;
        }}
      ...
      template <class T, class U = int> struct __attribute__((annotate("$clingAutoload$A.h"))) AStruct;
          
      
      
      Upon requiring the complete type of an entity, Cling includes the relevant header file to get it. There are several trivial workarounds to deal with default arguments and default template arguments as they now appear on the forward declaration and then the definition. You can read more in [1].
      
      Although the implementation could not be called a reference implementation, it shows that the Parser and the Preprocessor of Clang are relatively stateless and can be used to process character sequences which are not linear in their nature. In particular namespace-scope definitions are relatively easy to handle and it is not very difficult to return to namespace-scope when we lazily parse something. For other contexts such as local classes we will have lost some essential information such as name lookup tables for local entities. However, these cases are probably not very interesting as the lazy parsing granularity is probably worth doing only for top-level entities.
      
      Such implementation can help with already existing issues in the standard such as CWG2335, under which the delayed portions of classes get parsed immediately when they're first needed, if that first usage precedes the end of the class. That should give good motivation to upstream all the operations needed to return to an enclosing scope and parse something.
      
      Implementation approach: Upon seeing a tag definition during parsing we could create a forward declaration, record the token sequence and mark it as a lazy definition. Later upon complete type request, we could re-position the parser to parse the definition body. We already skip some of the template specializations in a similar way [2, 3].
      
      Another approach is every lazy parsed entity to record its token stream and change the Toks stored on LateParsedDeclarations to optionally refer to a subsequence of the externally-stored token sequence instead of storing its own sequence (or maybe change CachedTokens so it can do that transparently). One of the challenges would be that we currently modify the cached tokens list to append an "eof" token, but it should be possible to handle that in a different way.
      
      In some cases, a class definition can affect its surrounding context in a few ways you'll need to be careful about here:
      
      1) `struct X` appearing inside the class can introduce the name `X` into the enclosing context.
      
      2) `static inline` declarations can introduce global variables with non-constant initializers that may have arbitrary side-effects.
      
      For point (2), there's a more general problem: parsing any expression can trigger a template instantiation of a class template that has a static data member with an initializer that has side-effects. Unlike the above two cases, I don't think there's any way we can correctly detect and handle such cases by some simple analysis of the token stream; actual semantic analysis is required to detect such cases. But perhaps if they happen only in code that is itself unused, it wouldn't be terrible for Clang to have a language mode that doesn't guarantee that such instantiations actually happen.
      
      Alternative and more efficient implementation could be to make the lookup tables range based but we do not have even a prototype proving this could be a feasible approach.
      Expected result:
      Design and implementation of on-demand compilation for non-templated functions
      Support non-templated structs and classes
      Run performance benchmarks on relevant codebases and prepare report
      Prepare a community RFC document
      [Stretch goal] Support templates
      The successful candidate should commit to regular participation in weekly meetings, deliver presentations, and contribute blog posts as requested. Additionally, they should demonstrate the ability to navigate the community process with patience and understanding.
      Further reading
      [1] https://github.com/root-project/root/blob/master/README/README.CXXMODULES.md#header-parsing-in-root
      [2] https://github.com/llvm/llvm-project/commit/b9fa99649bc99
      [3] https://github.com/llvm/llvm-project/commit/0f192e89405ce
      Skills: Knowledge of C++, Deeper understanding of how Clang works, knowledge of Clang AST and Preprocessor.
      Project size:Large
      Difficulty: Hard
      Confirmed Mentor: Vassil Vassilev, Matheus Izvekov
      Discourse: URL
      Improve Clang-Doc Usability
      Description of the project: Clang-Doc is a C/C++ documentation generation tool created as an alternative for Doxygen and built on top of LibTooling. This effort started in 2018 and critical mass has landed in 2019, but the development has been largely dormant since then, mostly due to a lack of resources.
      
      The tool can currently generate documentation in Markdown and HTML formats, but the tool has some structural issues, is difficult to use, the generated documentation has usability issues and is missing several key features:
      Not all C/C++ constructs are currently handled by the Markdown and HTML emitter limiting the tool’s usability.
      The generated HTML output does not scale with the size of the codebase making it unusable for larger C/C++ projects.
      The implementation does not always use the most efficient or appropriate data structures which leads to correctness and performance issues.
      There is a lot of duplicated boiler plate code which could be improved with templates and helpers.
      Expected result: The goal of this project is to address the existing shortcomings and improve the usability of Clang-Doc to the point where it can be used to generate documentation for large scale projects such as LLVM. The ideal outcome is that the LLVM project will use Clang-Doc for generating its reference documentation.
      
      Successful proposals should focus not only on addressing the existing limitations, but also draw inspiration for other potential improvements from other similar tools such as hdoc, standardese, subdoc or cppdocgen.
      Skills: Experience with web technologies (HTML, CSS, JS) and an intermediate knowledge of C++. Previous experience with Clang/LibTooling is a bonus but not required.
      Project size: Either medium or large.
      Difficulty: Medium
      Confirmed Mentor: Petr Hosek, Paul Kirth
      Discourse: URL
      Rich Disassembler for LLDB
      Description
      Use the variable location information from the debug info to annotate LLDB’s disassembler (and `register read`) output with the location and lifetime of source variables. The rich disassembler output should be exposed as structured data and made available through LLDB’s scripting API so more tooling could be built on top of this. In a terminal, LLDB should render the annotations as text.
      Expected outcomes
      For example, we could augment the disassembly for the following function
      frame #0: 0x0000000100000f80 a.out`main(argc=1, argv=0x00007ff7bfeff1d8) at demo.c:4:10 [opt]
        1   void puts(const char*);
        2   int main(int argc, char **argv) {
        3    for (int i = 0; i < argc; ++i)
      → 4      puts(argv[i]);
        5    return 0;
        6   }
      (lldb) disassemble
      a.out`main:
      ...
        0x100000f71 <+17>: movl  %edi, %r14d
        0x100000f74 <+20>: xorl  %r15d, %r15d
        0x100000f77 <+23>: nopw  (%rax,%rax)
      →  0x100000f80 <+32>: movq  (%rbx,%r15,8), %rdi
        0x100000f84 <+36>: callq 0x100000f9e ; symbol stub for: puts
        0x100000f89 <+41>: incq  %r15
        0x100000f8c <+44>: cmpq  %r15, %r14
        0x100000f8f <+47>: jne 0x100000f80 ; <+32> at demo.c:4:10
        0x100000f91 <+49>: addq  $0x8, %rsp
        0x100000f95 <+53>: popq  %rbx
      ...
      using the debug information that LLDB also has access to (observe how the source variable i is in r15 from [0x100000f77+slide))
      $ dwarfdump demo.dSYM --name  i
      demo.dSYM/Contents/Resources/DWARF/demo: file format Mach-O 64-bit x86-64
      0x00000076: DW_TAG_variable
       DW_AT_location (0x00000098:
       [0x0000000100000f60, 0x0000000100000f77): DW_OP_consts +0, DW_OP_stack_value
       [0x0000000100000f77, 0x0000000100000f91): DW_OP_reg15 R15)
       DW_AT_name ("i")
       DW_AT_decl_file ("/tmp/t.c")
       DW_AT_decl_line (3)
       DW_AT_type (0x000000b2 "int")
      to produce output like this, where we annotate when a variable is live and what its location is:
      (lldb) disassemble
      a.out`main:
      ...                                                               ; i=0
        0x100000f74 <+20>: xorl  %r15d, %r15d                           ; i=r15
        0x100000f77 <+23>: nopw  (%rax,%rax)                            ; |
      →  0x100000f80 <+32>: movq  (%rbx,%r15,8), %rdi                   ; |
        0x100000f84 <+36>: callq 0x100000f9e ; symbol stub for: puts    ; |
        0x100000f89 <+41>: incq  %r15                                   ; |
        0x100000f8c <+44>: cmpq  %r15, %r14                             ; |
        0x100000f8f <+47>: jne 0x100000f80 ; <+32> at t.c:4:10          ; |
        0x100000f91 <+49>: addq  $0x8, %rsp                             ; i=undef
        0x100000f95 <+53>: popq  %rbx
      The goal would be to produce output like this for a subset of unambiguous cases, for example, variables that are constant or fully in registers.
      Confirmed mentors and their contacts
      Adrian Prantl aprantl@apple.com (primary contact)
      Jonas Devlieghere jdevlieghere@apple.com
      Required / desired skills
      Required:
      Good understanding of C++
      Familiarity with using a debugger on the terminal
      Need to be familiar with all the concepts mentioned in the example above
      Need to have a good understanding of at least one assembler dialect for machine code (x86_64 or AArch64).
      Desired:
      Compiler knowledge including data flow and control flow analysis is a plus.
      Being able to navigate debug information (DWARF) is a plus.
      Size of the project.
      medium (~175h)
      An easy, medium or hard rating if possible
      hard
      Discourse: URL
      GPU Delta Debugging
      Description
      LLVM-reduce, and similar tools perform delta debugging but are less useful if many implicit constraints exist and violation could easily lead to errors similar to the cause that is to be isolated. This project is about developing a GPU-aware version, especially for execution time bugs, that can be used in conjunction with LLVM/OpenMP GPU-record-and-replay, or simply a GPU loader script, to minimize GPU test cases more efficiently and effectively.
      Expected outcomes
      A tool to reduce GPU errors without loosing the original error. Optionally, other properties could be the focus of the reduction, not only errors.
      Confirmed mentors and their contacts
      Parasyris, Konstantinos parasyris1@llnl.gov
      Johannes Doerfert jdoerfert@llnl.gov
      Required / desired skills
      Required:
      Good understanding of C++
      Familiarity with GPUs and LLVM-IR
      Desired:
      Compiler knowledge including data flow and control flow analysis is a plus.
      Experience with debugging and bug reduction techniques (llvm-reduce) is helpful
      Size of the project.
      medium
      An easy, medium or hard rating if possible
      medium
      Discourse: URL
      Offloading libcxx
      Description
      Modern C++ defines parallel algorithms as part of the standard library, like `std::transform_reduce(std::execution::par_unseq, vec.begin(), vec.end(), 0, std::plus, …)`. In this project we want to extend an implementation of those that is using OpenMP, including GPU offload, where reasonable. While some algorithms might be amenable to GPU offload via a pure (wrapper) runtime solution, we know others, especially those featuring user provided functors, will also require static program analysis and potentially transformation for additional data management. The goal of the project is to explore different algorithms and the options we have to execute them on the host as well as on accelerator devices, esp. GPUs, automatically via OpenMP.
      Expected outcomes
      Improvements to the prototype support of offloading in libcxx. Evaluations against other offloading approaches and documentation on the missing parts and shortcommings.
      Confirmed mentors and their contacts
      Johannes Doerfert jdoerfert@llnl.gov
      Tom Scogland scogland1@llnl.gov
      Tom Deakin tom.deakin@bristol.ac.uk
      Required / desired skills
      Required:
      Good understanding of C++ and C++ standard algorithms
      Familiarity with GPUs and (OpenMP) offloading
      Desired:
      Experience with libcxx (development).
      Experience debugging and profiling GPU code.
      Size of the project.
      large
      An easy, medium or hard rating if possible
      medium
      Discourse: URL
      The 1001 thresholds in LLVM
      Description
      LLVM has lots of thresholds and flags to avoid "costly cases". However, it is unclear if these thresholds are useful, their value is reasonable, and what impact they really have. Since there are a lot, we cannot do a simple exhaustive search. In some prototype work we introduced a C++ class that can replace hardcoded values and offers control over the threshold, e.g., you can increase the recursion limit via a command line flag from the hardcoded "6" to a different number. In this project we want to explore the thresholds, when they are hit, what it means if they are hit, how we should select their values, and if we need different "profiles".
      Expected outcomes
      Statistical evidence on the impact of various thresholds inside of LLVM's code base, including compile time changes, impact on transformations, and performance measurements.
      Confirmed mentors and their contacts
      Jan Hueckelheim jhueckelheim@anl.gov
      Johannes Doerfert jdoerfert@llnl.gov
      William Moses wmoses@mit.edu
      Required / desired skills
      Required:
      Profiling skills and knowledge of statistical reasoning
      Desired:
      Good understanding of the LLVM code base and optimization flow
      Size of the project.
      medium
      An easy, medium or hard rating if possible
      easy
      Discourse: URL
      Performance tuning the GPU libc
      Description
      We have begun work on a libc library targeting GPUs. This will allow users to call functions such as malloc or memcpy while executing on the GPU. However, it is important that these implementations be functional and performant. The goal of this project is to benchmark the implementations of certain libc functions on the GPU. Work would include writing benchmarks to test the current implementations as well as writing more optimal implementations.
      Expected outcomes
      In-depth performance for libc functions. Overhead of GPU-to-CPU remote procedure calls. More optimal implementations of 'libc' functions.
      Confirmed mentors and their contacts
      Joseph Huber joseph.huber@amd.com
      Johannes Doerfert jdoerfert@llnl.gov
      Required / desired skills
      Required:
      Profiling skills and understanding of GPU architecture
      Desired:
      Experience with libc utilities
      Size of the project.
      small
      An easy, medium or hard rating if possible
      easy
      Discourse: URL
      Improve GPU First Framework
      Description
      GPU First is a methodology and framework that can enable any existing host code to execute the entire program on a GPU without any modification from users. The goal of this project is two folded: 1) Port host code to handle RPC to the new plugin and rewrite it with the host RPC framework introduced in the GPU LibC project. 2) Explore the support for MPI among multiple thread blocks on a single GPU, or even multiple GPUs.
      Expected outcomes
      More efficient GPU First framework that can support both NVIDIA and AMD GPUs. Optionally, upstream the framework.
      Confirmed mentors and their contacts
      Shilei Tian i@tianshilei.me
      Johannes Doerfert jdoerfert@llnl.gov
      Joseph Huber joseph.huber@amd.com
      Required / desired skills
      Required:
      Good understanding of C++ and GPU architecture
      Familiarity with GPUs and LLVM IR
      Desired:
      Good understanding of the LLVM code base and OpenMP target offloading
      Size of the project.
      medium
      An easy, medium or hard rating if possible
      medium
      Discourse: URL
      Compile GPU kernels using ClangIR
      Description: Heterogeneous programming models such as SYCL, OpenMP and OpenACC help developers to offload computationally intensive kernels to GPUs and other accelerators. MLIR is expected to unlock new high-level optimisations and better code generation for the next generation of compilers for heterogeneous programming models. However, the availability of a robust MLIR-emitting C/C++ frontend is a prerequisite for these efforts.
      The ClangIR (CIR) project aims to establish a new intermediate representation (IR) for Clang. Built on top of MLIR, it provides a dialect for C/C++ based languages in Clang, and the necessary infrastructure to emit it from the Clang AST, as well as a lowering path to the LLVM-IR dialect. Over the last year, ClangIR has evolved into a mature incubator project, and a recent RFC on upstreaming it into the LLVM monorepo has seen positive comments and community support.
      The overall goal of this GSoC project is to identify and implement missing features in ClangIR to make it possible to compile GPU kernels in the OpenCL C language to LLVM-IR for the SPIR-V target. The OpenCL to SPIR-V flow is a great environment for this project because a) it is already supported in Clang and b) OpenCL's work-item- and work-group-based programming model still captures modern GPU architectures well. The contributor will extend the AST visitors, the dialect and the LLVM-IR lowering, to add support e.g. for multiple address spaces, vector and custom floating point types, and the spir_kernel and spir_func calling conventions.
      A good starting point for this work is the Polybench-GPU benchmark suite. It contains self-contained small- to medium sized OpenCL implementations of common algorithms. We expect only the device code (*.cl files) to be compiled via ClangIR. The existing OpenCL support in Clang can be used to create lit tests with reference LLVM-IR output to guide the development. Optionally, the built-in result verification and time measurements in Polybench could also be used to assess the correctness and quality of the generated code.
      Expected result: Polybench-GPU's 2DCONV, GEMM and CORR OpenCL kernels can be compiled with ClangIR to LLVM-IR for SPIR-V.
      Skills: Intermediate C++ programming skills and familiarity with basic compiler design concepts are required. Prior experience with LLVM IR, MLIR, Clang or GPU programming is a big plus, but willingness to learn is also a possibility.
      Project size: Large
      Difficulty: Medium
      Confirmed Mentors: Julian Oppermann, Victor Lomüller, Bruno Cardoso Lopes
      Discourse: URL
      Half precision in LLVM libc
      Description:
      Half precision is an IEEE 754 floating point format that has been widely used recently, especially in machine learning and AI. It has been standardized as _Float16 in the latest C23 standard, bringing its support to the same level as float or double data types. The goal for this project is to implement C23 half precision math functions in the LLVM libc library.
      Expected result:
      Setup the generated headers properly so that the type and the functions can be used with various compilers (+versions) and architectures.
      Implement generic basic math operations supporting half precision data types that work on supported architectures: x86_64, arm (32 + 64), risc-v (32 + 64), and GPUs.
      Implement specializations using compiler builtins or special hardware instructions to improve their performance whenever possible.
      If time permits, we can start investigating higher math functions for half precision.
      Skills:
      Intermediate C++ programming skills and familiarity with basic compiler design concepts are required. Prior experience with LLVM IR, MLIR, Clang or GPU programming is a big plus, but willingness to learn is also a possibility.
      Project size: Large
      Difficulty: Easy/Medium
      Confirmed Mentors: Tue Ly, Joseph Huber,
      Discourse: URL
      Google Summer of Code 2023
      Google Summer of Code 2023 was very successful for LLVM project. For the list of accepted and completed projects, please take a look into Google Summer of Code website.
      LLVM
      Re-optimization using JITLink
      Description of the project: In Just-In-Time compilers we often choose a low optimization level to minimize compile time and improve launch times and latencies, however some functions (which we call hot functions) are used very frequently and for these functions it is worth optimizing more heavily. In general hot functions can only be identified at runtime (different inputs will cause different functions to become hot), so the aim of the reoptimization project is to build infrastructure to (1) detect hot functions at runtime and (2) compile them a second time at a higher optimization level, hence the name "re-optimization".
      
      There are many possible approaches to both parts of this problem. E.g. hot functions could be identified by sampling, or using existing profiling infrastructure, or by implementing custom instrumentation. Reoptimization could be applied to whole functions, or outlining could be used to enable optimization of portions of functions. Re-entry into the JIT infrastructure from JIT’d code might be implemented on top of existing lazy compilation, or via a custom path.
      
      Whatever design is adopted, the goal is that the infrastructure should be generic so that it can be used by other LLVM API clients, and should support out-of-process JIT-compilation (so some of the solution will be implemented in the ORC runtime).
      Expected result:
      Improve ergonomics of indirection – ideally all forms of indirection (for re-optimization, lazy compilation, and procedure-linkage-tables) should be able to share a single stub (and/or binary rewriting metadata) at runtime.
      Implement basic re-optimization on top of the tidied up indirection.
      (Stretch goal) Garbage-collect unoptimized code that is no longer needed once the optimized version is available.
      Desirable skills: Intermediate C++; Understanding of LLVM and the LLVM JIT in particular.
      Project size: Large.
      Difficulty: Medium
      Confirmed Mentor: Vassil Vassilev, Lang Hames
      Discourse: URL
      JITLink new backends
      Description of the project: JITLink is LLVM's new JIT linker API -- the low-level API that transforms compiler output (relocatable object files) into ready-to-execute bytes in memory. To do this JITLink’s generic linker algorithm needs to be specialized to support the target object format (COFF, ELF, MachO), and architecture (arm, arm64, i386, x86-64). LLVM already has mature implementations of JITLink for MachO/arm64, MachO/x86-64, ELF/x86-64, ELF/aarch64 and COFF/x86-64, while the implementations for ELF/riscv, ELF/aarch32 and COFF/i386 are still relatively new.
      You can either work on an entirely new architecture like PowerPC or eBPF, or complete one of the recently added JITLink implementations. In both cases you will likely reuse the existing generic code for one of the target object formats. You will also work on relocation resolution, populate PLTs and GOTs and wire up the ORC runtime for your chosen target.
      Expected result: Write a JITLink specialization for a not-yet-supported or incomplete format/architecture such as PowerPC, AArch32 or eBPF.
      Desirable skills: Intermediate C++; Understanding of LLVM and the LLVM JIT in particular; familiarity with your chosen format/architecture, and basic linker concepts (e.g. sections, symbols, and relocations).
      Project size: Large.
      Difficulty:Medium
      Confirmed Mentor: Vassil Vassilev, Lang Hames
      Stefan Gränitz
      Discourse: URL
      Improving compile times
      Description of the project: While the primary job of a compiler is to produce fast code (good run-time performance), it is also important that optimization doesn’t take too much time (good compile-time performance). The goal of this project is to improve compile-time without hurting optimization quality.
      The general approach to this project is:
      Pick a workload to optimize. For example, this could be a file from CTMark compiled in a certain build configuration (e.g. -O0 -g or -O3 -flto=thin).
      Collect profiling information. This could involve compiler options like -ftime-report or -ftime-trace for a high-level overview, as well as perf record or valgrind --tool=callgrind for a detailed profile.
      Identify places that are unexpectedly slow. This is heavily workload dependent.
      Try to optimize an identified hotspot, ideally without impacting generated code. The compile-time tracker can be used to quickly evaluate impact on CTMark.
      As a disclaimer, it should be noted that outside of pathological cases, compilation doesn’t tend to have a convenient hotspot where 90% of the time is spent, instead it is spread out across many passes. As such, individual improvements also tend to have only small impact on overall compile-time. Expect to do 10 improvements of 0.2% each, rather than one improvement of 2%.
      Expected result: Substantial improvements on some individual files (multiple percent), and a small improvement on overall geomean compile-time.
      Desirable skills: Intermediate C++. Familiarity with profiling tools (especially if you are not on Linux, in which case I won’t be able to help).
      Project size: Either medium or large.
      Difficulty: Medium
      Confirmed Mentor: Nikita Popov
      Discourse: URL
      Addressing Rust optimization failures
      Description of the project: The Rust programming language uses LLVM for code generation, and heavily relies on LLVM’s optimization capabilities. However, there are many cases where LLVM fails to optimize typical code patterns that are emitted by rustc. Such issues are reported using the I-slow and/or A-LLVM labels.
      The usual approach to fixing these issues is:
      Inspect the --emit=llvm-ir output on Godbolt.
      Create an LLVM IR test case that is not optimized when run through opt -O3.
      Identify a minimal missing transform and prove its correctness using alive2.
      Identify which LLVM pass or passes could perform the transform.
      Add necessary test coverage and implement the transform.
      (Much later: Check that the issue is really resolved after the next major LLVM version upgrade in Rust.)
      The goal of this project is to address some of the less hard optimization failures. This means that in some cases, the process would stop after step 3 or 4 without proceeding to implementation, because it’s unclear how the issue could be addressed, or it would take a large amount of effort. Having an analysis of the problem is still valuable in that case.
      Expected result: Fixes for a number of easy to medium Rust optimization failures. Preliminary analysis for some failures even if no fix was implemented.
      Desirable skills: Intermediate C++ for implementation. Some familiarity with LLVM (at least ability to understand LLVM IR) for analysis. Basic Rust knowledge (enough to read, but not write Rust).
      Project size: Either medium or large.
      Difficulty: Medium
      Confirmed Mentor: Nikita Popov
      Discourse: URL
      Implement autocompletion in clang-repl
      Description of the project: The Clang compiler is part of the LLVM compiler infrastructure and supports various languages such as C, C++, ObjC and ObjC++. The design of LLVM and Clang enables them to be used as libraries, and has led to the creation of an entire compiler-assisted ecosystem of tools. The relatively friendly codebase of Clang and advancements in the JIT infrastructure in LLVM further enable research into different methods for processing C++ by blurring the boundary between compile time and runtime. Challenges include incremental compilation and fitting compile/link time optimizations into a more dynamic environment.
      
      Incremental compilation pipelines process code chunk-by-chunk by building an ever-growing translation unit. Code is then lowered into the LLVM IR and subsequently run by the LLVM JIT. Such a pipeline allows creation of efficient interpreters. The interpreter enables interactive exploration and makes the C++ language more user friendly. The incremental compilation mode is used by the interactive C++ interpreter, Cling, initially developed to enable interactive high-energy physics analysis in a C++ environment.
      
      Our group puts efforts to incorporate and possibly redesign parts of Cling in Clang mainline through a new tool, clang-repl. The project aims at the design and implementation of robust autocompletion when users type C++ at the prompt of clang-repl. For example:
            [clang-repl] class MyLongClassName {};
            [clang-repl] My<tab>
            // list of suggestions.
          
      Expected result: There are several foreseen tasks:
      Research the current approaches for autocompletion in clang such as clang -code-completion-at=file:col1:col2.
      Implement a version of the autocompletion support using the partial translation unit infrastructure in clang’s libInterpreter.
      Investigate the requirements for semantic autocompletion which takes into account the exact grammar position and semantics of the code. Eg:
                [clang-repl] struct S {S* operator+(S&) { return nullptr;}};
                [clang-repl] S a, b;
                [clang-repl] v = a + <tab> // shows b as the only acceptable choice here.
              
      Present the work at the relevant meetings and conferences.
      Project size:Large.
      Difficulty: Medium
      Confirmed Mentor: Vassil Vassilev
      Discourse: URL
      Modules build daemon: build system agnostic support for explicitly built modules
      Description of the project: Clang currently handles modules independently in each clang instance using the filesystem for synchronization of which instance builds a given module. This has many issues with soundness and performance due to tradeoffs made for module reuse and filesystem contention.
      Clang has another way of building modules, explicitly built modules, that currently requires build system changes to adopt. Here the build system determines which modules are needed, for example by using clang-scan-deps, and ensures those modules are built before running the clang compile task that needs them.
      In order to allow adoption of this new way of building modules without major build system work we need a module build daemon. With a small change to the command line, clang will connect to this daemon and ask for the modules it needs. The module build daemon then either returns an existing valid module, or builds and then returns it.
      There is an existing open source dependency scanning daemon that is in a llvm-project fork. This only handles file dependencies, but has an IPC mechanism. This IPC system could be used as a base for the modules build daemon, but does need to be extended to work on Windows.
      Expected result: A normal project using Clang modules with an existing build system (like Make or CMake) can be built using only explicitly built modules via a modules build daemon.
      Desirable skills: Intermediate C++ programming skills; familiarity with compilers; familiarity with Clang is an asset, but not required.
      Project size: 175h or 350h depending on reuse of IPC
      Difficulty: medium
      Confirmed Mentors: Michael Spencer, Jan Svoboda
      Discourse: URL
      ExtractAPI Objective-C categories
      Description of the project: Swift-DocC is the canonical documentation compiler for the Swift OSS project. However Swift-DocC is not Swift specific and uses SymbolKit's languaguage agnostic JSON-based symbol graph format to understand which symbols are available in the code, this way any language can be supported by Swift-DocC as long as there is a symbol graph generator.
      Clang supports symbol graph generation for C and Objective-C as described in [RFC] clang support for API information generation in JSON. Today, support for Objective-C categories is not complete, on one hand if the category extends a type in the current module, the category members are assumed to belong to the extended type itself. On the other hand, if the extended type belongs to another module the category is ignored. Nonetheless, it is common to extend types belonging to other modules in Objective-C as part of the public API of the module. The goal of this project is to extend the symbol graph format to accommodate Objective-C categories and to implement support for generating this information both through clang and through libclang.
      Expected result: Adding the necessary support to clang's symbol graph generator and in libclang for describing categories of symbols defined in other modules. This might involve additions to SymbolKit that would need to be discussed with that community.
      Desirable skills: Intermediate C++ programming skills; familiarity with clang and Objective-C are assets but not required.
      Project size: Medium
      Difficulty: Medium
      Confirmed Mentors: Daniel Grumberg, Zixu Wang, Juergen Ributzka
      Discourse: URL
      ExtractAPI C++ Support
      Description of the project: Swift-DocC is the canonical documentation compiler for the Swift OSS project. However Swift-DocC is not Swift specific and uses SymbolKit's languaguage agnostic JSON-based symbol graph format to understand which symbols are available in the code, this way any language can be supported by Swift-DocC as long as there is a symbol graph generator.
      Clang supports symbol graph generation for C and Objective-C as described in [RFC] clang support for API information generation in JSON.
      Currently the emitted symbol graph format does not support various C++ constructs such as templates and exceptions and the symbol graph generator does not fully understand C++. This project aims to introduce support for various C++ constructs in the symbol graph format and to implement support for generating this data in clang.
      Expected result: Adding the necessary support to clang's symbol graph generator and in libclang for describing categories of symbols defined in other modules. This will involve additions to SymbolKit that would need to be discussed with that community.
      Desirable skills: Intermediate C++ programming skills; familiarity with clang and Objective-C are assets but not required.
      Project size: Large
      Difficulty: Medium/Hard
      Confirmed Mentors: Daniel Grumberg, Zixu Wang, Juergen Ributzka
      Discourse: URL
      ExtractAPI while building
      Description of the project: Swift-DocC is the canonical documentation compiler for the Swift OSS project. However Swift-DocC is not Swift specific and uses SymbolKit's languaguage agnostic JSON-based symbol graph format to understand which symbols are available in the code, this way any language can be supported by Swift-DocC as long as there is a symbol graph generator.
      Clang supports symbol graph generation for C and Objective-C as described in [RFC] clang support for API information generation in JSON.
      Currently users can use clang to generate symbol graph files using the clang -extract-api command line interface or generating symbol graphs for a specific symbol using the libclang interface. This project would entail adding a third mode that would generate the symbol graph output as a side-effect of a regular compilation job. This can enable using the symbol graph format as a light weight alternative to clang Index or clangd for code intelligence services.
      Expected result: Enable generating symbol graph files during a regular compilation (or module build); provide a tool to merge symbol graph files in the same way a static linker links individual object files; Extend clang Index to support all the information contained by symbol graph files.
      Desirable skills: Intermediate C++ programming skills; familiarity with clang and Objective-C are assets but not required.
      Project size: Medium
      Difficulty: Medium/Hard
      Confirmed Mentors: Daniel Grumberg, Zixu Wang, Juergen Ributzka
      Discourse: URL
      Improve Clang diagnostics
      Description: The diagnostics clang emits are ultimately its interface to the developer. While the diagnostics are generally good, there are some rough edges that need to be ironed out. Some cases can be improved by special-casing them in the compiler as well.
      As one can see from Clang’s issue tracker, there are lots of issues open against clang’s diagnostics.
      This project does not aim to implement one big feature but instead focuses on smaller, incremental improvements to Clang’s diagnostics.
      Possible example issues to resolve:
      Calling nullptr function pointer in a constexpr function results in poor diagnostic
      Print name of uninitialized subobject (instead of type)
      https://github.com/llvm/llvm-project/issues/57906
      clang(++) unhelpful frame-larger-than warning, very small stack frame exceeding very large limit
      Any other diagnostics issue you find interesting or ran into personally.
      Expected outcomes: At least three fixed smaller diagnostics issues, or one larger implemented diagnostics improvement.
      Confirmed Mentor:Timm Bäder
      Desirable skills:
      Intermediate C++ knowledge.
      Preferably experience in the Clang code base, since the issues mentioned can have their root cause in various parts of it.
      Preferably an already working local LLVM build
      Project type: Medium/200 hr
      Discourse URL
      Tutorial development with clang-repl
      Description: The Clang compiler is part of the LLVM compiler infrastructure and supports various languages such as C, C++, ObjC and ObjC++. The design of LLVM and Clang enables them to be used as libraries, and has led to the creation of an entire compiler-assisted ecosystem of tools. The relatively friendly codebase of Clang and advancements in the JIT infrastructure in LLVM further enable research into different methods for processing C++ by blurring the boundary between compile time and runtime. Challenges include incremental compilation and fitting compile/link time optimizations into a more dynamic environment.
      Incremental compilation pipelines process code chunk-by-chunk by building an ever-growing translation unit. Code is then lowered into the LLVM IR and subsequently run by the LLVM JIT. Such a pipeline allows creation of efficient interpreters. The interpreter enables interactive exploration and makes the C++ language more user friendly. The incremental compilation mode is used by the interactive C++ interpreter, Cling, initially developed to enable interactive high-energy physics analysis in a C++ environment.
      We invest efforts to incorporate and possibly redesign parts of Cling in Clang mainline through a new tool, clang-repl. The project aims implementing tutorials demonstrating the capabilities of the project and investigating adoption of clang-repl in xeus-clang-repl prototype allowing to write C++ in Jupyter.
      Expected result: There are several foreseen tasks:
      Write several tutorials demostrating the current capabilities of clang-repl.
      Investigate the requirements for adding clang-repl as a backend to xeus-cling.
      Improve the xeus kernel protocol for clang-repl.
      Prepare a blog post about clang-repl and possibly Jupyter. Present the work at the relevant meetings and conferences.
      Confirmed Mentor: Vassil Vassilev David Lange
      Desirable skills: Intermediate C++; Understanding of Clang and the Clang API in particular
      Project type: Medium
      Discourse URL
      Add WebAssembly Support in clang-repl
      Description: The Clang compiler is part of the LLVM compiler infrastructure and supports various languages such as C, C++, ObjC and ObjC++. The design of LLVM and Clang enables them to be used as libraries, and has led to the creation of an entire compiler-assisted ecosystem of tools. The relatively friendly codebase of Clang and advancements in the JIT infrastructure in LLVM further enable research into different methods for processing C++ by blurring the boundary between compile time and runtime. Challenges include incremental compilation and fitting compile/link time optimizations into a more dynamic environment.
      Incremental compilation pipelines process code chunk-by-chunk by building an ever-growing translation unit. Code is then lowered into the LLVM IR and subsequently run by the LLVM JIT. Such a pipeline allows creation of efficient interpreters. The interpreter enables interactive exploration and makes the C++ language more user friendly. The incremental compilation mode is used by the interactive C++ in Jupyter via the xeus kernel protocol. Newer versions of the protocol allow possible in-browser execution allowing further possibilities for clang-repl and Jupyter.
      We invest efforts to incorporate and possibly redesign parts of Cling in Clang mainline through a new tool, clang-repl. The project aims to add WebAssembly support in clang-repl and adopt it in xeus-clang-repl to aid Jupyter-based C++.
      Expected result: There are several foreseen tasks:
      Investigate feasibility of generating WebAssembly in a similar way to the new interactive CUDA support.
      Enable generating WebAssembly in clang-repl.
      Adopt the feature in xeus-clang-repl.
      Prepare a blog post about clang-repl and possibly Jupyter. Present the work at the relevant meetings and conferences.
      Confirmed Mentor: Vassil Vassilev Alexander Penev
      Desirable skills: Good C++; Understanding of Clang and the Clang API and the LLVM JIT in particular
      Project type: Large
      Discourse URL
      LLD Linker Improvements for Embedded Targets
      Description of the project GNU toolchain is used widely for building embedded targets. There's a certain momentum in the Clang/LLVM community towards improving the Clang toolchain to support embedded targets. Using the Clang toolchain as an alternative can help us improve code quality, find and fix security bugs, improve developer experience and take advantage of the new ideas and the momentum surrounding the Clang/LLVM community in supporting embedded devices.
      A non-comprehensive list of improvements that can be made to LLD:
      --print-memory-usage support
      "--print-memory-usage" in GCC provides a breakdown of the memory used in each memory region defined in the linker file. Embedded developers use this flag to understand the impact on memory. Often embedded systems define multiple memory regions with different space constraints. Supporting this in Clang toolchain will help projects that wish to use Clang toolchain for their projects.
      Linkmap
      Currently, the LLD linker's linkmap output is not as rich as the BFD linker output. Achieving feature parity on linkmap output will be highly useful in analyzing the binaries created by the LLD linker. Further, outputting linkmap in different formats (current LLD output, BFD, and JSON) can help build automation tools for investigating the artifacts produced by the linker.
      --print-gc-sections improvement
      When the "--print-gc-sections" flag is enabled, LLD prints the sections that were discarded during the linking process. This information currently does not include the mapping between the symbol and the section groups, which is useful for debugging. Preserving this information during the linking process will require modifications to internal linker data structures.
      Project size: Medium or Large
      Difficulty: Medium/Hard
      Skills: C++
      Expected result:
      Implementation of "--print-memory-usage" flag.
      Support for new linkmap output formats 1. BFD and 2. JSON.
      Improved "--print-gc-sections" output to include information about the surviving symbols.
      Confirmed Mentors: Prabhu Rajasekaran Petr Hosek
      Discourse: URL
      Optimizing MLIR’s Presburger library
      Description: MLIR’s Presburger Library, FPL (https://grosser.science/FPL), provides mathematical abstractions for polyhedral compilation and analysis. The main abstraction that the library provides is a set of integer tuples defined by a system of affine inequality constraints. The library supports standard set operations over such sets. The result will be a set defined by another constraint system, possibly having more constraints. When many set operations are performed in sequence, the constraint system may become very large, negatively impacting performance. There are several potential ways to simplify the constraint system; however, this involves performing additional computations. Thus, spending more time on more aggressive simplifications may make each individual operation slower, but at the same time, insufficient simplifications can make sequences of operations slow due to an explosion in constraint system size. The aim of this project is to find the right balance between the two.
      The goals of this project:
      Understand the library's performance in terms of runtime and output size.
      Optimize the library by finding the best output size and performance tradeoff.
      Expected outcomes:
      Benchmarking the performance and output constraint complexity of the primary operations of the library.
      Implementing simplification heuristics.
      A better understanding of which simplification heuristics improve overall performance enough to be worth the additional computational cost.
      Desirable skills: Intermediate C++, Experience in benchmarking
      Project size: Large
      Difficulty: Medium
      Confirmed mentors: Kunwar Grover
      Discourse: URL
      Interactively query MLIR IR
      Description: The project aims to develop an interactive query language for MLIR that enables developers to query the MLIR IR dynamically. The tool will provide a REPL (or command-line) interface to enable users to query various properties of MLIR code, such as "isConstant" and "resultOf". The proposed tool is intended to be similar to clang-query, which allows developers to match AST expressions in C++ code using a TUI with autocomplete and other features.
      The goals of this project:
      Understand the MLIR IR representation and common explorations user do.
      Implement a REPL to execute queries over MLIR IR.
      Expected outcomes:
      Standalone that can be used to interactively explore IR.
      Implement common matchers that are usable by the tool.
      (stretch) Enable extracting parts of the IR matched by query into self-contained IR snippets.
      Desirable skills: Intermediate C++, Experience in writing/debugging peephole optimizations
      Project size: Either medium or large.
      Difficulty: Medium
      Confirmed mentors: Jacques Pienaar
      Discourse: URL
      Better performance models for MLGO training
      Description of the project We are using machine-guided compiler optimizations ("MLGO") for register allocation eviction and inlining for size, in real-life deployments. The ML models have been trained with reinforcement learning algorithms. Expanding to more performance areas is currently impeded by the poor prediction quality of our performance estimation models. Improving those is critical to the effectiveness of reinforcement learning training algorithms, and therefore to enabling applying MLGO systematically to more optimizations.
      Project size: either 175 or 350 hr.
      Difficulty: Medium
      Skills: C/C++, some compiler experience, some Python. ML experience is a bonus.
      Expected outcomes: Better modeling of the execution environment by including additional runtime/profiling information, such as additional PMU data, LLC miss probabilities or branch mispredictions. This involves (1) building a data collection pipeline that covers additional runtime information, (2) modifying the ML models to allow processing this data, and (3) modifying the training and inference process for the models to make use this data.
      Today, the models are almost pure static analysis; they see the instructions, but they make one-size-fits-all assumptions about the execution environment and the runtime behavior of the code. The goal of this project is to move from static analysis towards more dynamic models that better represent code the way it actually executes.
      Mentors Ondrej Sykora, Mircea Trofin, Aiden Grossman
      Discourse URL
      Improve and Stabilize the Clang Static Analyzer's "Taint Analysis" Checks
      Description of the project: The Clang static analyzer comes with an experimental implementation of taint analysis, a security-oriented analysis technique built to warn the user about flow of attacker-controlled ("tainted") data into sensitive functions that may behave in unexpected and dangerous ways if the attacker is able to forge the right input. The programmer can address such warnings by properly "sanitizing" the tainted data in order to eliminate these dangerous inputs. A common example of a problem that can be caught this way is SQL injections. A much simpler example, which is arguably much more relevant to users of Clang, is buffer overflow vulnerabilities caused by attacker-controlled numbers used as loop bounds while iterating over stack or heap arrays, or passed as arguments to low-level buffer manipulating functions such as memcpy().
      Being a static symbolic execution engine, the static analyzer implements taint analysis by simply maintaining a list of "symbols" (named unknown numeric values) that were obtained from known taint sources during the symbolic simulation. Such symbols are then treated as potentially taking arbitrary concrete values, as opposed to the general case of taking an unknown subset of possible values. For example, division by a unchecked unknown value doesn't necessarily warrant a division by zero warning, because it's typically not known whether the value can be zero or not. However, division by an unchecked tainted value does immediately warrant a division by zero warning, because the attacker is free to pass zero as an input. Therefore the static analyzer's taint infrastructure consists of several parts: there is a mechanism for keeping track of tainted symbols in the symbolic program state, there is a way to define new sources of taint, and a few path-sensitive checks were taught to consume taint information to emit additional warnings (like the division by zero checker), acting as taint "sinks" and defining checker-specific "sanitization" conditions.
      The entire facility is flagged as experimental: it's basically a proof-of-concept implementation. It's likely that it can be made to work really well, but it needs to go through some quality control by running it on real-world source code, and a number of bugs need to be addressed, especially in individual checks, before we can declare it stable. Additionally, the tastiest check of them all – buffer overflow detection based on tainted loop bounds or size parameters – was never implemented. There is also a related check for array access with tainted index – which is, again, experimental; let's see if we can declare this one stable as well!
      Expected result: A number of taint-related checks either enabled by default for all users of the static analyzer, or available as opt-in for users who care about security. They're confirmed to have low false positive rate on real-world code. Hopefully, the buffer overflow check is one of them.
      Desirable skills: Intermediate C++ to be able to understand LLVM code. We'll run our analysis on some plain C code as well. Some background in compilers or security is welcome but not strictly necessary.
      Project size: Either medium or large.
      Difficulty: Medium
      Confirmed Mentors: Artem Dergachev, Gábor Horváth, Ziqing Luo
      Discourse: URL
      Machine Learning Guided Ordering of Compiler Optimization Passes
      Description of the project This continues the work of GSoC 2020 and 2021. Developers generally use standard optimization pipelines like -O2 and -O3 to optimize their code. Manually crafted heuristics are used to determine which optimization passes to select and how to order the execution of those passes. However, this process is not tailored for a particular program, or kind of program, as it is designed to perform “reasonably well” for any input. We want to improve the existing heuristics or replace the heuristics with machine learning-based models so that the LLVM compiler can provide a superior order of the passes customized per program. The last milestone enabled feature extraction, and started investigating training a policy for selecting a more appropriate pass pipeline.
      Project size: either 175 or 350 hr.
      Difficulty: Medium
      Skills: C/C++, some compiler experience. ML experience is a bonus.
      Expected outcomes: Pre-trained model selecting the most economical optimization pipeline, with no loss in performance; hook-up of model in LLVM; (re-)training tool; come up with new optimization sequences through search or learning.
      Mentors Tarindu Jayatilaka, Mircea Trofin, Johannes Doerfert
      Discourse URL
      Support a hierarchical directory structure in generated coverage html reports
      Description of the project:
      Clang supports source-based coverage that shows which lines of code are covered by the executed tests [1]. It uses llvm-profdata [2] and llvm-cov [3] tools to generate coverage reports. llvm-cov currently generates a single top-level index HTML file. For example, a single top-level directory code coverage report [4] for LLVM repo is published on a coverage bot. Top-level indexing causes rendering scalability issues in large projects, such as Fuchsia [5]. The goal of this project is to generate a hierarchical directory structure in generated coverage html reports to match the directory structure and solve scalability issues. Chromium uses its own post-processing tools to show a per-directory hierarchical structure for coverage results [6]. Similarly, Lcov, which is a graphical front-end Gcov[7], provides a one-level directory structure to display coverage results [8].
      [1] Source-based code coverage
      [2] llvm-profdata
      [3] llvm-cov
      [4] LLVM coverage reports
      [5] Fuchsia
      [6] Coverage summary for Chromium
      [7] Gcov
      [8] Lcov coverage reports
      [9] Issue #54711: Support per-directory index files for HTML coverage report
      Expected result: Implement a support in hierarchical directory structure in generated coverage html reports and show the usage of this feature in LLVM repo code coverage reports.
      Project size: Medium or Large
      Difficulty: Medium
      Confirmed Mentors: Gulfem Savrun Yeniceri Petr Hosek
      Discourse: URL
      Map LLVM values to corresponding source-level expressions
      Description of the project Developers often use compiler generated remarks and analysis reports to optimize their code. While compilers in general are good at including source code positions (i.e line and column numbers) in the generated messages, it is useful if these generated messages also include the corresponding source-level expressions. The approach used by the LLVM implementation is to use a small set of intrinsic functions to define a mapping between LLVM program objects and the source-level expressions. The goal of this project is to use the information included within these intrinsic functions to either generate the source expression corresponding to LLVM values or to propose and implement solutions to get the same if the existing information is insufficient. Optimizing memory accesses in a program is important for application performance. We specifically intend to use compiler analysis messages that report source-level memory accesses corresponding to the LLVM load/store instructions that inhibit compiler optimizations. As an example, we can use this information to report memory access dependences that inhibit vectorization.
      Project size: Medium
      Difficulty: Medium
      Skills: Intermediate C++, familiarity with LLVM core or willingness to learn the same.
      Expected result: Provide an interface which takes an LLVM value and returns a string corresponding to the equivalent source-level expression. We are especially interested in using this interface to map addresses used in load/store instructions to equivalent source-level memory references.
      Confirmed Mentors: Satish Guggilla (satish.guggilla@intel.com) Karthik Senthil (karthik.senthil@intel.com)
      Discourse: URL
      Build and run SingleSource benchmarks using ClangIR
      Description of the project:
      Clang codegen works by emitting LLVM IR using AST visitors. In the ClangIR project, we emit ClangIR (CIR) from AST visitors too (CIRGen), and then lower to (a) LLVM IR directly or, alternatively, (b) MLIR in-tree dialects. Lowering to LLVM is still quite immature and lacks many instructions, attributes and metadata support. ClangIR would greatly benefit from some level of parity with Clang AST → LLVM IR codegen quality, in both performance and build time. This is key for incrementally bridging correctness and performance testing, providing a baseline for future higher level optimizations on top of C/C++. A good starting point is to build and run simple benchmarks, measuring both generated code and build time performance. LLVM's llvm-test-suite contains scripts and machinery that easily allows checking correctness and collecting perf related data and its SingleSource collection provide a set of simpler programs to build. In a nutshell, while working on this project the student will brigde the gap of CIR → LLVM lowering, and at times fix any lacking Clang AST → CIR support. The work is going to be done incrementally on top of SingleSource benchmarks, while measuring compiler build time and the performance of compiled programs.
      Skills: Intermediate C++ programming skills; familiarity with compilers, LLVM IR, MLIR or Clang are a big plus, but willingness to learn is also a possibility.
      Expected result:Build and run programs from the SingleSource subdirectory from the lvm-test-suite, collect and present results (perf and build time) against regular (upstream) clang codegen.
      Project size: Large
      Difficulty: Medium
      Confirmed Mentors: Bruno Cardoso Lopes Nathan Lanza
      Discourse: URL
      Move additional Enzyme Rules to Tablegen
      Description of the project: Enzyme performs automatic differentiation (in the calculus sense) of LLVM programs. This enables users to use Enzyme to perform various algorithms such as back-propagation in ML or scientific simulation on existing code for any language that lowers to LLVM. The support for an increasing number of LLVM Versions (7-main), AD modes (Reverse, Forward, Forward-Vector, Reverse-Vector, Jacobian), and libraries (BLAS, OpenMP, MPI, CUDA, ROCm, ...) leads to a steadily increasing code base. In order to limit complexity and help new contributors we would like to express more parts of our core logic using LLVM Tablegen. The applicant is free to decide how to best map the program transformation abstractions within Enzyme to Tablegen.
      Expected results: 1. Extend the tablegen rule generation system within Enzyme to cover a new component beside of the AdjointGenerator
      2. Moving several existing rules to the new autogenerated system (e.g. LLVM instructions, LLVM intrinsics, MPI calls, ...
      Confirmed mentor: Manuel Drehwald William Moses
      Desirable skills: Good knowledge of C++, calculus, and LLVM and/or Clang, and/or MLIR internals. Experience with Tablegen, Enzyme or automatic differentiation would be nice, but can also be learned in the project.
      Project size: Large
      Difficulty: Medium
      Discourse URL
      Patch based test coverage for quick test feedback
      Description of the project Most of the day to day tests in LLVM are regression tests executed by Lit, structured as source code or IR to be passed to some binary, rather than test code directly calling the code to be tested. This has many advantages but can make it difficult to predict which code path is executed when the compiler is invoked with a certain test input, especially for edge cases where error handling is involved. The goal of this project is to help developers create good test coverage for their patch and enable reviewers to verify that they have done so. To accomplish this we would like to introduce a tool that can be fed a patch as input, add coverage instrumentation for the affected source files, runs Lit tests, and records which test cases cause each counter to be executed. For each counter we can then report the number of test cases executing the counter, but perhaps more importantly we can also report the number of test cases executing the counter that are also changed in some way by the patch, since a modified line that results in the same test results isn’t properly tested, unless it’s intended to be a non-functional change. This can be implemented in three separate parts:
      Adding an option to llvm-lit to emit the necessary test coverage data, divided per test case (involves setting a unique value to LLVM_PROFILE_FILE for each RUN)
      New tool to process the generated coverage data and the relevant git patch, and present the results in a user friendly manner
      Adding a way to non-intrusively (without changing build configurations) enable coverage instrumentation to a build. By building the project normally, touching the files changed by the patch, and rebuilding with CCC_OVERRIDE_OPTIONS set to add coverage we can lower the overhead of generating and processing coverage of lines not relevant to the patch.
      The tooling in step 2 and 3 can be made completely agnostic of the actual test-runner, lowering the threshold for other test harnesses than Lit to implement the same functionality. If time permits adding this as a step in CI would also be helpful for reviewers.
      Project size: Small or medium
      Difficulty: Simple
      Skills: Python for Lit, data processing and diff processing. No compiler experience necessary.
      Expected result: Implement a new tool for use by the community. Developers get help finding uncovered edge cases during development, while also avoiding paranoid sprinkling of asserts or logs just to check that the code is actually executed. Reviewers can more easily check which parts of the patch are tested by each test.
      Confirmed Mentors: Henrik Olsson
      Discourse: URL
      Google Summer of Code 2022
      Google Summer of Code 2022 was very successful for LLVM project. For the list of accepted and completed projects, please take a look into Google Summer of Code website.
      LLVM
      Implement a shared-memory based JITLinkMemoryManager for out-of-process JITting
      Description of the project: Write a shared-memory based JITLinkMemoryManager.
      LLVM’s JIT uses the JITLinkMemoryManager interface to allocate both working memory (where the JIT fixes up the relocatable objects produced by the compiler) and target memory (where the JIT’d code will reside in the target). JITLinkMemoryManager instances are also responsible for transporting fixed-up code from working memory to target memory. LLVM has an existing cross-process allocator that uses remote procedure calls (RPC) to allocate and copy bytes to the target process, however a more attractive solution (when the JIT and target process share the same physical memory) would be to use shared memory pages to avoid copies between processes.
      Expected results:
      Implement a shared-memory based JITLinkMemoryManager:
      Write generic LLVM APIs for shared memory allocation.
      Write a JITLinkMemoryManager that uses these generic APIs to allocate shared working-and-target memory.
      Make an extensive performance study of the approach.
      Confirmed Mentor: Vassil Vassilev, Lang Hames
      Desirable skills: Intermediate C++; Understanding of LLVM and the LLVM JIT in particular; Understanding of virtual memory management APIs.
      Project type: Large
      Discourse URL
      Modernize the LLVM "Building A JIT" tutorial series
      Description of the project: The LLVM BuildingAJIT tutorial series teaches readers to build their own JIT class from scratch using LLVM’s ORC APIs, however the tutorial chapters have not kept pace with recent API improvements. Bring the existing tutorial chapters up to speed, write up a new chapter on lazy compilation (chapter code already available) or write a new chapter from scratch.
      Expected results:
      Update chapter text for Chapters 1-3 -- Easy, but offers a chance to get up-to-speed on the APIs.
      Write chapter text for Chapter 4 -- Chapter code is already available, but no chapter text exists yet.
      Write a new chapter from scratch -- E.g. How to write an out-of-process JIT, or how to directly manipulate the JIT'd instruction stream using the ObjectLinkingLayer::Plugin API.
      Confirmed Mentor: Vassil Vassilev, Lang Hames
      Desirable skills: Intermediate C++; Understanding of LLVM and the LLVM JIT in particular; Familiarity with RST (reStructed Text); Technical writing skills.
      Project type: Medium
      Discourse URL
      Write JITLink support for a new format/architecture
      Description of the project: JITLink is LLVM’s new JIT linker API -- the low-level API that transforms compiler output (relocatable object files) into ready-to-execute bytes in memory. To do this JITLink’s generic linker algorithm needs to be specialized to support the target object format (COFF, ELF, MachO), and architecture (arm, arm64, i386, x86-64). LLVM already has mature implementations of JITLink for MachO/arm64 and MachO/x86-64, and a relatively new implementation for ELF/x86-64. Write a JITLink implementation for a missing target that interests you. If you choose to implement support for a new architecture using the ELF or MachO formats then you will be able to re-use the existing generic code for these formats. If you want to implement support for a new target using the COFF format then you will need to write both the generic COFF support code and the architecture support code for your chosen architecture.
      Expected results: Write a JITLink specialization for a not-yet-supported format/architecture.
      Confirmed Mentor: Vassil Vassilev, Stefan Gränitz, Lang Hames
      Desirable skills: Intermediate C++; Understanding of LLVM and the LLVM JIT in particular; familiarity with your chosen format/architecture, and basic linker concepts (e.g. sections, symbols, and relocations).
      Project type: Large
      Discourse URL
      Instrumentation of Clang/LLVM for Compile Time
      Description of the project: Every developer, at some point (usually while waiting for their program to compile), has asked "Why is it taking so long?" This project is to seek an answer to this question. There exists within LLVM, and by extension CLANG, a timing infrastructure that records events within the compiler. However, its utilization is inconsistent and insufficient. This can be improved by adding more instrumentation throughout LLVM and CLANG but one must be careful. Too much instrumentation, or instrumenting the wrong things, can be confusing and overwhelming, thus making it no more useful than not enough information. The trick is to find the right places to instrument and controlling the instrumentation. Seeking out these key spots will take you through the entire compilation process, from preprocessing through to final code generation, and all phases between. As you instrument the code, you will look at the data as you evolve it, which will further direct your search. You will develop new ways to control and filter the information to allow a better understanding of where the compiler is spending its time. You will seek out and develop example test inputs that illustrate where the compiler can be improved, which will in turn, help direct your instrumenting and search. You will consider and develop ways of controlling the instrumentation to allow better understanding and detailed examination of phases of compilation. Through all of this, you will gain an understanding of how a compiler works, from front end processing, through the LLVM optimization pipeline, through to code generation. You will see, and understand, the big picture of what is required to compile and optimize a C/C++ program, and in particular, how CLANG, LLVM and LLC accomplish these tasks. Your mentors have a combined experience of approximately 25 years of compiler development and around 8 years of experience with LLVM itself to help you on your quest.
      Expected results:
      Targetted expansion of the use of the existing timing infrastructure
      Identification of appropriate test inputs for improving compile time
      Identification of compile time hotspots
      New and improved methods of controlling the timing infrastructure
      Confirmed Mentor: Jamie Schmeiser, Whitney Tsang
      Desirable skills: C++ programming skills; CLANG/LLVM knowledge an asset but not necessary; self motivated; curiosity; desire to learn
      Project type:175 or 350 hour
      Difficulty Rating:Easy - Medium
      Discourse URL
      Machine Learning Guided Ordering of Compiler Optimization Passes
      Description of the project This continues the work of GSoC 2020 and 2021. Developers generally use standard optimization pipelines like -O2 and -O3 to optimize their code. Manually crafted heuristics are used to determine which optimization passes to select and how to order the execution of those passes. However, this process is not tailored for a particular application, or kind of application, as it is designed to perform “reasonably well” for any input. We want to improve the existing heuristics or replace the heuristics with machine learning-based models so that the LLVM compiler can provide a superior order of the passes customized per application. The last milestone enabled feature extraction, and started investigating training a policy for selecting a more appropriate pass pipeline.
      Project size: either 175 or 350 hr.
      Difficulty: Medium
      Skills: C/C++, some compiler experience. ML experience is a bonus.
      Expected outcomes: Pre-trained model selecting the most economical optimization pipeline, with no loss in performance; hook-up of model in LLVM; (re-)training tool.
      Mentors Tarindu Jayatilaka, Mircea Trofin, Johannes Doerfert
      Discourse URL
      Learning Loop Transformation Policies
      Description of the project This project is a continuation of last year’s. In 2021, the project achieved its first milestone - separating correctness decisions from policy decisions. This opens up the possibility of replacing the latter with machine-learned ones. Rough milestones: 1) select an initial set of features and use the existing ML Guided Optimizations (MLGO) infra to generate training logs; 2) define a reward signal, computable at compile time, to guide a reinforcement learning training loop; 3) iterate through training and refine reward/feature set
      Project size: either 175 or 350 hr, ideally 350 hr
      Difficulty: Medium/Hard
      Skills: C/C++, some compiler experience. ML experience is a bonus.
      Expected outcomes: policy ('advisor') interface for loop unrolling, with current heuristic as default implementation; set up feature extraction for reinforcement learning training; set up a reward metric; set up training algorithm, and iterate over policy training
      Mentors Johannes Doerfert, Mircea Trofin
      Discourse URL
      Evaluate and Expand the Module-Level Inliner
      Description of the project LLVM's inliner is a bottom-up, strongly-connected component-level pass. This places limits on the order in which call sites are evaluated, which impacts the effectiveness of inlining. We now have a functional Module Inliner, as result of GSoC2021 work. We want to call site priority schemes, effectiveness/frequency of running function passes after successful inlinings, interplay with the ML inline advisor, to name a few areas of exploration.
      Project size: either 175 or 350 hr, ideally 350 hr, milestones allow for 175hr scoping
      Difficulty: Medium/Hard
      Skills: C/C++, some compiler experience.
      Expected outcomes: Proposal and Evaluation of alternative traversal orders; evaluation of 'clustering' inlining decisions (inline more than one call site at a time); evaluation of effectiveness/frequency of function optimization passes after inlining
      Mentors Kazu Hirata, Liqiang Tao, Mircea Trofin
      Discourse URL
      Richer symbol dependency information for LTO
      Description of the project: C and C++ programs are often composed of various object files produced from separately-compiled source files that are then linked together. When compiling one source file, knowledge that can be derived from the logic contained within the other source files would normally not be available. Link-time optimization, also known as LTO, is a way for optimization to be done using information from more than one source file.
      In LLVM, LTO is achieved by using LLVM bitcode objects as the output from the "compile" step and feeding those objects into the link step. LLVM's LTO operates in conjunction with the linker. The linker is invoked by the user and the linker in turn drives LLVM's LTO when it encounters LLVM bitcode files, getting information from LTO about what symbols a bitcode object defines or references. Information about what symbols are defined in or referenced from an object is necessary for the linker to perform symbol resolution, and a linker is normally able to extract such information from regular (non-bitcode) object files.
      The implied consequences of LLVM's LTO implementation with respect to linker GC (linker garbage collection) can be improved, especially for aggressive forms of linker GC with lazy inclusion of objects and sections. In particular, the symbols referenced but undefined by an LTO module are, to the linker, monolithic at the module level. At the same time, the symbols referenced but undefined by regular (non-LTO) objects are monolithic to LTO. Together, this means that the inclusion of an LTO module into the overall process potentially leads, in the linker's initial symbol resolution, to all the undefined symbols in that module being considered as referenced; in turn, additional artifacts (e.g., archive members) may be added into the resolution, which further leads to references that may resolve to symbols defined in LTO modules and a premature conclusion that the definition of these symbols are needed. This at least means potentially unnecessary codegen is being done for functions that will be garbage-collected in the end (waste of electricity and time).
      We acknowledge that an ideal implementation probably involves a "coroutine" like interaction between the linker and LTO codegen where information flows back and forth; however, such an endeavour is invasive to both linkers and to LLVM.
      We believe that by
      having the linker register, via an API to LTO, symbol reference "nodes" modelling the relationship between a symbol and the symbols that are referenced in turn from (the object file section containing) its linker-selected definition, and
      using that information in LTO processing,
      the LTO processing will be able to effectively identify a more accurate set of LTO symbols that are visible outside of the LTO unit. The linker merely needs to identify only exported symbols and entry points (such as the entry point for an executable and functions involved in initialization and finalization).
      Having the LLVM opt/codegen understand the dependency implications from the "outside world" is strictly better than the other direction: the symbols referred to by relocations in non-LTO code are pretty much fixed as compiled (whereas some references in LTO code may disappear with optimization).
      Expected results:
      Modification of the C++ LTO interface used by LLD to implement an interface to record the symbol reference dependency data (incorporating awareness of sections and comdats). This may additionally include a method to add LTO objects provisionally, simulating behaviours where linkers only add objects as needed.
      Modification of LTO to use new symbol reference information for definitions in regular objects when visiting definitions in the IR prior to the internalization pass to discover (transitive) symbol references and record the so-referenced symbols as being visible to regular objects. This may additionally include the "late" incorporation of LTO objects added provisionally into the merged LTO module.
      Modification of LLD (for ELF) to modify initial resolution to use the new interface as a replacement for setting VisibleToRegularObj except for entry point functions (including C++ dynamic initialization and finalization).
      Confirmed Mentors: Sean Fertile, Hubert Tong, Wael Yehia
      Desirable skills: Intermediate C++; basic linker concepts (e.g., symbols, sections, and relocations)
      Project size: 350 hours
      Difficultly: Medium/Hard
      Discourse URL
      Remove undef: move uninitialized memory to poison
      Description of the project The existence of the undef value in LLVM prevents several optimizations, even in programs where it is not used. Therefore, we have been trying to move all uses of undef to poison so we can eventually remove undef from LLVM.
      This project focuses on uninitialized memory: right now the semantics of LLVM is that loading a value from uninitilized memory yields an undef value. This prevents, for example, SROA/mem2reg from optimizing conditional loads as phi(undef, %x) cannot be replaced with x, as %x might be poison.
      This project consists in devising a consistent semantics for uninitialized (based on existing proposals), an upgrade plan for LLVM, and implementing the changes in LLVM and clang. In clang the changes should be specific to bit-fields.
      For more information see the following discussion and/or contact the mentor.
      Further reading: introduction to LLVM's memory model.
      Project size: 350 hr
      Difficulty: Medium/Hard
      Skills: Intermediate C++
      Expected outcomes:
      Semantics for memory operations that removes the need for undef values
      Upgrade plan for LLVM and frontends
      Implementation of the proposed semantics in LLVM
      Implementation of auto-upgrade path for old LLVM IR files
      Implementation of fixes in clang to use the new IR features
      Benchmarking to check for regressions and/or perf improvements
      Mentors: Nuno Lopes
      Add API/ABI export annotations to the LLVM build
      Description of the project
      Currently, all libraries inside LLVM export all their symbols publicly. When linking statically against them, the linker will remove unused symbols and this is not a problem.
      When the libraries are built as shared libraries however, the number of exported symbols is very large and symbols that are meant to be internal spill into the public ABI of the shared libLLVM.so.
      In this project, we’d like to change the default visibility of library symbols to “hidden”, add an annotation macro to LLVM and use the macro to gradually move the entire library in this direction. This will eventually enable building the shared libLLVM.so on Windows as well.
      In practice, this means adding -fvisibility=hidden to individual libraries and annotating exported symbols with the LLVM export annotation.
      We would like this work to be as unintrusive into other developer’s workflow as possible, so starting with a small internal library would be beneficial, e.g. one of the LLVM targets or IR passes.
      For further reading, there is a Discourse thread avaiable that discusses the idea behind this proposal: Supporting LLVM_BUILD_LLVM_DYLIB on Windows as well as the linked Phabricator review with a patch implementing the functionality: ⚙ D109192 [WIP/DNM] Support: introduce public API annotation support None of this work has been committed yet but can be used as a starting point for this proposal.
      Project size: Medium
      Difficulty: Easy
      Skills: Build systems, CMake, LLVM
      Expected outcomes:
      Export macro implemented and commited to LLVM
      At least one internal target ported to the new export scheme
      Mentors: Timm Bäder, Tom Stellard
      Clang
      Extend clang AST to provide information for the type as written in template instantiations.
      Description of the project: When instantiating a template, the template arguments are canonicalized before being substituted into the template pattern. Clang does not preserve type sugar when subsequently accessing members of the instantiation.
          std::vector<std::string> vs;
          int n = vs.front(); // bad diagnostic: [...] aka 'std::basic_string<char>' [...]
      
          template<typename T> struct Id { typedef T type; };
          Id<size_t>::type // just 'unsigned long', 'size_t' sugar has been lost
          
      Clang should "re-sugar" the type when performing member access on a class template specialization, based on the type sugar of the accessed specialization. The type of vs.front() should be std::string, not std::basic_string<char, [...]>.
      
      Suggested design approach: add a new type node to represent template argument sugar, and implicitly create an instance of this node whenever a member of a class template specialization is accessed. When performing a single-step desugar of this node, lazily create the desugared representation by propagating the sugared template arguments onto inner type nodes (and in particular, replacing Subst*Parm nodes with the corresponding sugar). When printing the type for diagnostic purposes, use the annotated type sugar to print the type as originally written.
      
      For good results, template argument deduction will also need to be able to deduce type sugar (and reconcile cases where the same type is deduced twice with different sugar).
      Expected results: Diagnostics preserve type sugar even when accessing members of a template specialization. T<unsigned long> and T<size_t> are still the same type and the same template instantiation, but T<unsigned long>::type single-step desugars to 'unsigned long' and T<size_t>::type single-step desugars to 'size_t'.
      Confirmed Mentor: Vassil Vassilev, Richard Smith
      Desirable skills: Good knowledge of clang API, clang's AST, intermediate knowledge of C++.
      Project type: Large
      Discourse URL
      Implement support for C++17 structured bindings in the Clang Static Analyzer
      Description of the project: Even though a lot of new C++ features are supported by the static analyzer automatically by the virtue of clang AST doing all the work under the hood, the C++17 "structured binding" syntax
          auto [x, y] = ...;
      requires some extra work on the Static Analyzer side. The analyzer's transfer functions need to be taught about the new AST nodes, BindingDecl and DecompositionDecl, to work correctly in all three interpretations described by the Standard.
      
      Incomplete support for structured bindings is a common source of false positives in the uninitialized variable checker on modern C++ code, such as #42387.
      
      It is likely that the Clang CFG also needs to be updated. Such changes in the CFG may improve quality of clang warnings outside of the Static Analyzer.
      Expected results: The Static Analyzer correctly models structured binding and decomposition declarations. In particular, binding variables no longer appear uninitialized to the Static Analyzer's uninitialized variable checker.
      Confirmed Mentor: Artem Dergachev, Rashmi Mudduluru, Gábor Horváth, Kristóf Umann
      Desirable skills: Intermediate knowledge of C++. Some familiarity with Clang AST and/or some static analysis background.
      Project size: 350 hr
      Difficulty: Medium/Hard
      Discourse URL
      Improve Clang Diagnostics.
      Description: Clang Diagnostics, which issues Warnings and Errors to the programmer, are a critical feature of the compiler. Great diagnostics can have a significant impact on the user experience of the compiler and increase their productivity.
      Recent improvements in GCC [1] [2] shows that there is significant headroom to improve diagnostics (and user interactions in general). It would be a very impactful project to survey and identify all the possible improvements to clang on this topic and start redesigning the next generation of our diagnostics.
      In addition, we will also make conclusions on issues reported on the LLVM Github Issue page labeled with clang-diagnostics and if they need fixing, we will prepare patches otherwise simply close them.
      Expected outcomes: Diagnostics will be improved:
      Improve diagnostic aesthetics
      Cover missing diagnostics
      Reduce false positive rate
      Reword diagnostics
      Confirmed Mentor: Aaron Ballman, Erich Keane, Shivam Gupta
      Desirable skills: C++ coding experience
      Project type: Large/350 hr
      Discourse URL
      Polly
      Complete switch to new pass manager
      Description of the Project: While the standard Polly-enabled -O1/-O2/-O3 optimization pass pipelines work fine with the New Pass Manager (NPM), some parts of Polly still only works with the legacy pass manager. This includes some passes such as -polly-export-jscop/-polly-export-jscop, regression testing, Polly-ACC, command line options such as -polly-show, the PassInstrumentation mechanism used by e.g. -print-after-all. LLVM (and Clang) have moved to NPM being the default and support for the legacy pass manager is deprecated, slowly degenerates and features getting removed. That is, all of Polly's functionality should eventually work with the NPM as well, and be prepared for the complete removal of the legacy pass manager. More details about the two pass managers found here.
      Expected results: The goal is to make Polly more usable with using only the NPM. Milestones, not necessarily all to be reached in this GSoC, are:
      1. Make all of Polly's functionality available in the NPM (or decide to deprecate/remove it)
      2. Better integration into the NPM (such as supporting PassInstrumentation); If the NPM turns out to be inadequate, use only a monolothic function pass.
      3. Replace the legacy pass manager in regression tests.
      4. Be ready for complete removal of the legacy pass manager in LLVM.
      Confirmed mentor: Michael Kruse
      Desirable skills: Understanding of the C++ template pattern used by the new pass manager (CRTP, Mixins, etc). Familarity with how LLVM can be linked (static, BUILD_SHARED_LIBS, and SHLIB/DYLIB) and its plugin loading machanisms (static, -load and -load-pass-plugin). Ideally, already worked with LLVM's new pass manager.
      Project size: Medium
      Difficulty: Medium/Hard
      Discourse URL
      Enzyme
      Move Enzyme Instruction Transformation Rules to Tablegen
      Description of the project: Enzyme performs automatic differentiation (in the calculus sense) of LLVM programs. This enables users to use Enzyme to perform various algorithms such as back-propagation in ML or scientific simulation on existing code for any language that lowers to LLVM. The support for an increasing number of LLVM Versions (7-main), AD modes (Reverse, Forward, Forward-Vector, Reverse-Vector, Jacobian), and libraries (BLAS, OpenMP, MPI, CUDA, ROCm, ...) leads to a steadily increasing code base. In order to limit complexity and help new contributors we would like to express our core logic using LLVM Tablegen. The applicant is free to decide how to best map the program transformation abstractions within Enzyme to Tablegen.
      Expected results: 1. A working tablegen rule generation system within Enzyme
      2. Moving several existing rules to the new autogenerated system (e.g. LLVM instructions, LLVM intrinsics, BLAS calls, MPI calls, ...
      Confirmed mentor: William Moses, Valentin Churavy
      Desirable skills: Good knowledge of C++, calculus, and LLVM and/or Clang, and/or MLIR internals. Experience with Tablegen, Enzyme or automatic differentiation would be nice, but can also be learned in the project.
      Project size: Large
      Difficulty: Medium
      Discourse URL
      Vector Reverse-Mode Automatic Differentiation
      Description of the project: Enzyme performs automatic differentiation (in the calculus sense) of LLVM programs. This enables users to use Enzyme to perform various algorithms such as back-propagation in ML or scientific simulation on existing code for any language that lowers to LLVM. Enzyme already implements forward and reverse mode automatic differentiation. Enzyme also implements vector forward mode automatic differentiation, which allows Enzyme to batch the derivative computation of several objects in a single call. The goal of this project is too extend this capability in order to perform vector reverse mode. In doing so, multiple sweeps of reverse mode automatic differentiation can be performed at the same time, reducing memory, time, and otherwise generally enabling further optimization.
      Expected results: Vectorized version of reverse mode automatic differentiation
      Confirmed mentor: William Moses, Tim Gymnich
      Desirable skills: Good knowledge of C++ and some experience with LLVM API's. Experience with Enzyme or automatic differentiation would be nice, but can also be learned in the project.
      Project size: Medium
      Difficulty: Medium
      Discourse URL
      Enable The New Pass Manager
      Description of the project: Enzyme is a compiler plugin for LLVM that performs automatic differentiation (in the calculus sense) of LLVM programs. This enables users to use Enzyme to perform various algorithms such as back-propagation in ML or scientific simulation on existing code for any language that lowers to LLVM.
      Enzyme integrates into frontends through the use of an LLVM plugin that can be loaded into Clang, LLVM (opt), the linker (lld), libraries (HIPRtc), directly loaded (Julia), among others (Flang, Rust, etc).
      While using various pieces of machinery from the new pass manager internally, Enzyme does not currently automatically register its transformation passes when using the new pass manager. This creates problems for users on LLVM 13 or above, where the new pass manager is run by default and may not understand why they get linker errors from their code not being differentiated (currently they must add a flag to specify the old pass manager).
      The goal of this project is to enable Enzyme to be called by the new pass manager in LLVM and generally create a coherent user experience.
      Expected results: 1. Enzyme can be called by the new pass manager
      2. [Optional] Additional syntactic sugar that makes it easier to use Enzyme.
      Confirmed mentor: William Moses, Valentin Churavy
      Desirable skills: Good knowledge of C++, and LLVM. Experience with Enzyme would be nice, but can also be learned in the project.
      Project size: Small
      Difficulty: Medium
      Discourse URL
      Google Summer of Code 2021
      Welcome prospective Google Summer of Code 2021 Students! This document is your starting point to finding interesting and important projects for LLVM, Clang, and other related sub-projects. This list of projects is not only developed for Google Summer of Code, but open projects that really need developers to work on and are very beneficial for the LLVM community.
      We encourage you to look through this list and see which projects excite you and match well with your skill set. We also invite proposals not on this list. You must propose your idea to the LLVM community through our developers' mailing list (llvm-dev@lists.llvm.org or specific subproject mailing list). Feedback from the community is a requirement for your proposal to be considered and hopefully accepted.
      The LLVM project has participated in Google Summer of Code for several years and has had some very successful projects. We hope that this year is no different and look forward to hearing your proposals. For information on how to submit a proposal, please visit the Google Summer of Code main website.
      LLVM
      Distributed lit testing
      Description of the project: The LLVM lit test suites consist of thousands of small independent tests. Due to the number of tests, it can take a long time to run the full suite, even on a high-spec computer. Builds are already distributable across multiple computers available on the same network, using software such as distcc or icecream, so running tests on a single machine becomes a potential bottleneck. One way to speed up running of the tests could be to distribute test execution across many computers too. Lit provides a test sharding mechanism, which allows multiple computers to run parts of the same testsuite in tandem, but this currently assumes access to a single common filesystem, which may not be possible in all cases and a knowledge of which machines the suite can currently be run on. This project’s goal is to update the existing lit harness (or write a wrapper around it) to allow distribution of the tests in this way, with the idea that developers can write their own interface between the harness and the distribution system of their choice. This harness may need to be able to identify test dependencies such as input files and executables, send the tests to the distribution system (possibly in batches), and receive, collate and report the results to the user, in a similar manner to how lit already does.
      Expected results: An easy to use harness as described above. Some evidence that given a distributed system, a user can expect to see test suite execution to speed up if they are using that harness.
      Confirmed mentor: James Henderson
      Desirable skills: Good knowledge of Python. Familiarity with LLVM lit testing. Some knowledge of distribution systems would also be beneficial.
      Learning Loop Transformation Heuristics
      Description of the project: This is a short description, please reach out to Johannes (jdoerfert on IRC) and Mircea Trofin if it sounds interesting. We successfully introduced an ML framework for inliner decisions, now we want to expand the scope. In this project we will look at loop transformation heuristics, such as the unroll factor. As a motivational example we can look at a small trip count dgemm which we optimize pretty poorly. With the nounroll pragmas we do a better job but still not close to gcc. The project is open-ended and we could look at various passes/heuristics concurrently.
      Preparation resources: The ML inliner framework in the LLVM code base as well as the paper. LLVM transform passes (that are based on heuristics), e.g., loop unroll.
      Expected results: Measurable better performance with a learned predictor, potentially a set of "classical" heuristics derived from the ML model.
      Confirmed Mentor: Johannes Doerfert, Mircea Trofin
      Desirable skills: Intermediate knowledge of ML, C++, self motivation.
      Fuzzing LLVM-IR Passes
      Description of the project: This is a short description, please reach out to Johannes (jdoerfert on IRC) if it sounds interesting. Fuzzing often reveals a myriad of bugs. CSmith (and others) showed how to do this with C-like languages and we have used LLVM-IR fuzzing in the past successfully. In this project we will apply fuzzing to new passes that are in development, e.g., the Attributor pass. We want to find and fix crashes but also other bugs, including compile time performance problems.
      Preparation resources: The LLVM fuzzer infrastructure. LLVM passes that we might want to fuzz, e.g. the Attributor pass. Prior IR-Fuzzing work (https://www.youtube.com/watch?v=UBbQ_s6hNgg)
      Expected results: Crashes, maybe also a way to catch non-crash bugs, including performance problems.
      Confirmed Mentor: Johannes Doerfert
      Desirable skills: Intermediate knowledge C++, self motivation.
      llvm.assume the missing pieces
      Description of the project: This is a short description, please reach out to Johannes (jdoerfert on IRC) if it sounds interesting. llvm.assume is a powerful mechanism to retain knowledge. Since it inception it was improved already multiple times but there are major extensions still outstanding which we want to tackled in this project. An incomplete list of topics includes:
      range-based assumptions, design idea 3) in the RFC.
      outline arbitrary assumption/assertion code, design idea 2) in the RFC.
      side-effect free assumptions, see this review.
      more knowledge retention usages
      less interference with optimizations
      Preparation resources: The llvm.assumption usage, the assumption cache, the "enable-knowledge-retention" option, the RFC and this review.
      Expected results: New llvm.assume use cases, improved performance through knowledge retention, optimization based on assertions.
      Confirmed Mentor: Johannes Doerfert
      Desirable skills: Intermediate knowledge C++, self motivation.
      Fix fundamental issues in LLVM's IR
      Description of the project: LLVM's IR has fundamental, long-standing issues. Many are related with undefined behaviors. Others are simply a fallout from underspecification and different interpretations by diffferent people. Alive2 is a tool that detects bugs in LLVM's optimizations automatically. Using Alive2, we track bugs exposed by the unit tests on a dashboard.
      Expected results: 1) Report and fix bugs detected by Alive2. 2) Pick one fundamental IR issue and make progress towards fixing it, including proposing fixes for the semantics, testing fixes to the semantics by running Alive2 over the LLVM unit tests and medium-sized programs, test performance of semantic fixes and fix performance regressions.
      Confirmed Mentor: Nuno Lopes, Juneyoung Lee
      Desirable skills: Intermediate C++; willingness to learn about LLVM IR semantics; experience reading papers (preferred).
      Utilize LoopNest Pass
      Description of the project: The idea of LoopNest pass is recently added, and there are no existing passes utilizing it. Before having LoopNest pass, if you want to write a pass that works on a loop nest, you have to pick from either a function pass or a loop pass. If you chose to write it as a function pass, then you lose the ability to add loops dynamically back to the pipeline. If you decide to write it as a loop pass, then you are wasting compile time to traverse to your pass and return right away when the given loop is not the outermost loop. In this project, we want to utilize the recently introduced LoopNest pass for passes intended for loop nest and have the same ability as the LoopPass to dynamically add loops to the pipeline. In addition, improve the current implementation of LoopNestPass when necessary.
      Expected results (possibilities): Utilize LoopNest Pass for some existing transformations/analyses.
      Confirmed Mentors: Whitney Tsang, Ettore Tiotto
      Desirable skills: Intermediate knowledge of C++, self-motivation.
      JIT-ing OpenMP GPU kernels transparently
      Description of the project: This is a short description, please reach out to Johannes (jdoerfert on IRC) if it sounds interesting. OpenMP GPU kernels are usually lowered to native binaries, e.g., cubin, and embedded into the host object. At runtime, OpenMP "plugins" will connect with the device driver, e.g., CUDA, to load and run such embedded binary images. In this project we want to develop a new plugin that takes LLVM-IR code, optimizes the IR with kernel parameters known only at runtime, and then generates the GPU binary for consumption by other plugins. Similar to the remote offload plugin we can do this transparently to the user. In addition to the JIT infrastructure setup in the plugin we will need to embed the IR into the host object.
      Preparation resources:OpenMP target offloading infrastructure, LLVM JIT infrastructure.
      Expected results: A JIT-capable offload plugin which can achieve superior performance when kernel specialization is enabling optimizations.
      Confirmed Mentor: Johannes Doerfert
      Desirable skills: Intermediate knowledge C++, JIT compilation, self motivation.
      OpenACC
      OpenACC Diagnostics from the OpenMP Runtime
      Description of the project: Clacc and Flacc are projects to introduce OpenACC support to Clang and Flang. For that purpose, OpenACC runtime support is being developed on top of LLVM's OpenMP runtime. However, diagnostics emitted by LLVM's OpenMP runtime are expressed in terms of OpenMP concepts, and so those diagnostics are not always meaningful to OpenACC users. This project should address this issue in two steps:
      Develop a mechanism that selects OpenACC versions of diagnostics that are emitted as a result of OpenACC-related calls into the runtime. This mechanism should be general enough that it could be used for programming languages besides OpenMP and OpenACC. One possible approach is to extend internationalization mechanisms already present in some components of the OpenMP runtime.
      Provide OpenACC translations for existing OpenMP diagnostics. This step requires an understanding of the relationship between OpenACC and OpenMP as implemented in Clacc and Flacc.
      Many components of OpenACC support that will depend upon this project have not yet been upstreamed and are under development. A high-level understanding of those efforts is helpful for this project and can be provided by the mentors. Nevertheless, this project can be completed in upstream LLVM's OpenMP runtime now independently of those efforts.
      Expected results: A version of upstream LLVM's OpenMP runtime that can emit OpenACC diagnostics as needed.
      Confirmed Mentors: Valentin Clement, Joel E. Denny
      Desirable skills: Intermediate C++; Experience with OpenACC or OpenMP
      Polly
      Use official isl C++ bindings
      Description of the project: Polly use algorithms from the Integer Set Library (isl), which is a library written in C. It uses reference-counting for memory management. Getting reference counting correct is much easier in C++ using RAII, therefore we created a C++ binding for isl: isl-noexceptions.h. Since then, isl also gained two official C++ bindings, cpp.h and cpp-checked.h. We would like to replace the Polly-maintained C++ bindings with the upstream bindings. Unfortunately, this is not an in-place replacement. Differences include how errors are checked, method names, which functions are considered as operator/constructor overloads and the set of exported functions. This will require changing Polly's uses of the C++ bindings and submitting patches to isl to export additional functionality needed by Polly.
      Expected results: Reduce the differences between the Polly-maintained isl-noexceptions.h bindings and one of the two C++ bindings that isl supports. Due to isl-noexceptions.h exporting more functions and classes than the upstream bindings do, a complete replacement will probably be out of reach, but even reducing the differences will reduce the maintenance cost of Polly's isl-noexceptions.h.
      Confirmed mentor: Michael Kruse
      Desirable skills: Deep knowledge of C++, in particular RAII and move-semantics. Interest in API design. Ideally, you already wrote some library's header file. Experience with the isl library would be nice, but can also be learned in the project.
      Enzyme
      Integrate custom derivatives of BLAS, Eigen, and similar routines into Enzyme
      Description of the project: Enzyme performs automatic differentiation (in the calculus sense) of LLVM programs. This enables users to use Enzyme to perform various algorithms such as back-propagation in ML or scientific simulation on existing code for any language that lowers to LLVM. Enzyme does so by applying the chain rule to every instruction in every function called by the original function to be differentiated. While functional, this is not necessarily optimal for high-level matrix operations which may have algebraic properties for faster derivative computation. Enzyme also has a mechanism for specifying a custom gradient for a given function. If a custom derivative is available, Enzyme will use that rather than fallback to implementing its own. Many programs use BLAS libraries to efficiently compute matrix and tensor operations. This project would enable high-performance automatic differentiation of BLAS and similar libraries (such as Eigen) by specifying custom derivative rules for their operations.
      Expected results: Efficient differentiation of BLAS and Eigen codes by writing custom derivative rules for matrix and tensor operations.
      Confirmed mentor: William Moses, Johannes Doerfert
      Desirable skills: Good knowledge of C++, calculus, and linear algebra. Experience with BLAS, Eigen, or Enzyme would be nice, but can also be learned in the project.
      Integrate Enzyme into Swift to provide high-performance differentiation in Swift
      Description of the project: Enzyme performs automatic differentiation (in the calculus sense) of LLVM programs. This enables users to use Enzyme to perform various algorithms such as back-propagation in ML or scientific simulation on existing code for any language that lowers to LLVM. While this functions for any frontend that emits LLVM IR, it may be desirable to have closer integration between Enzyme and the frontend for the sake of passing additional information and creating a better user experience. Swift provides automatic differentiation through the use of specifying custom derivative rules in the front-end. Enzyme could be integrated directly with Swift, differentiating the eventual LLVM, but it would lose out on all this additional information about custom derivatives. Moreover, calling into Enzyme naiively would be without Type checking, fine AD-specific debug information, or various other nice tools that Swift provides users of AD. This project would seek to integrate Enzyme and the Swift front end to provide both a nice user-experience for swift programmers who want to use Enzyme to enable high-performance automatic differentiation, and also to allow Enzyme to take advantage of derivative-specific metadata already available in swift.
      Expected results: Creation of a custom type-checked linguistic construct in Swift for calling Enzyme. Mechanisms for passing Swift's differentiation-specific metadata for use by Enzyme.
      Confirmed mentor: William Moses, Vassil Vassilev
      Desirable skills: Good knowledge of C++ and Swift. Experience with Enzyme or automatic differentiation would be nice, but can also be learned in the project.
      Differentiation of Fixed-Point Arithmetic
      Description of the project: Enzyme performs automatic differentiation (in the calculus sense) of LLVM programs. This enables users to use Enzyme to perform various algorithms such as back-propagation in ML or scientific simulation on existing code for any language that lowers to LLVM. In a variety of fields, it is desirable to compute on fixed-point values (e.g. integers) rather than floating point values. This avoid certain truncation errors that may be critical to a given application. Moreover, particular pieces of hardware may simply be more efficient on fixed point rather than floating point values. This project would seek to extend Enzyme to support differentiation of not only floating point base values, but also fixed point base values..
      Expected results: Implementation of adjoints for LLVM fixed point intrinsics, requisite type analysis rules, and integration into a front-end for an end-to-end test.
      Confirmed mentor: William Moses
      Desirable skills: Good knowledge of C++, caclulus, and LLVM internals. Experience with Enzyme or automatic differentiation would be nice, but can also be learned in the project.
      Integrate Enzyme into Rust to provide high-performance differentiation in Rust
      Description of the project: Enzyme performs automatic differentiation (in the calculus sense) of LLVM programs. This enables users to use Enzyme to perform various algorithms such as back-propagation in ML or scientific simulation on existing code for any language that lowers to LLVM. While this functions for any frontend that emits LLVM IR, it may be desirable to have closer integration between Enzyme and the frontend for the sake of passing additional information and creating a better user experience. This project would seek to integrate Enzyme and the Rust front end to provide a nice user-experience for Rust programmers who want to use Enzyme to enable high-performance automatic differentiation. This also potentially involves integration of LLVM plugin support/custom codegen into rustc.
      Expected results: Creation of a custom type-checked linguistic construct in Rust for calling Enzyme. Mechanisms for parsing Rust's Type information (represented as debug LLVM debug info) directly into type analysis.
      Confirmed mentor: William Moses
      Desirable skills: Good knowledge of C++ and Rust. Experience with Enzyme or automatic differentiation would be nice, but can also be learned in the project.
      Clang Static Analyzer performance profiling
      Description of the project:
      Chart how much time is spent in transfer functions – including (but not limited to!) checker callbacks.
      Add llvm Statistics and Timers for quickly obtaining precise and concise dumps without external profilers. Statistics on state splits might be particularly interesting!
      Measure time spent analyzing specific stack frames. Say, how much time do we spend inlining std::string methods? This time could be saved if we add custom models for these methods instead.
      Confirmed mentor: Artem Dergachev
      Clang Static Analyzer constraint solver improvements
      Description of the project: CSA has a small in-house constraint solver, it is pretty trivial, but super fast. The goal is to support range-based logic for some of the symbolic operators, while keeping it linear. Additionally, a unit-test framework can be designed specifically for testing constraint solvers (right now it’s tested rather awkwardly). This project has a couple of interesting properties. It can be segmented into small chunks, and each of these chunks has a non-trivial solution. It might introduce you to a world of solvers (it is a good idea to check your ideas with some heavy-weight solver such as z3). And because the existing solver is simple, there is a myriad of possible extensions to try.
      Confirmed mentor: Valeriy Savchenko
      A structured approach to diagnostics in LLDB
      Description of the project:
      Design and integrate a new diagnostic abstraction (similar to clang::Diagnostic) to report errors, warnings and notes in a structured way.
      Allow us to differentiate between bugs (unexpected errors) and things the debugger simply doesn’t know (expected errors). Be smart about printing global errors only once. Have the ability of being verbose and have additional metadata (source location, DWARF unit, object file, etc, depending on the type of error and where it originated).
      Should be compatible and tightly integrated with the existing classes, such as the Status and CommandReturnObject.
      Confirmed mentor: Jonas Devlieghere and Raphael Isemann
      Google Summer of Code 2020
      LLVM participation in Google Summer of Code 2020 was very successful and resulted in many interesting projects contributed to LLVM. For the list of accepted and completed projects, please take a look into Google Summer of Code website.
      LLVM
      Improve inter-procedural analyses and optimizations
      Description of the project: This is a short description, please reach out to Johannes (jdoerfert on IRC) if it sounds interesting. During the GSoC'19 we build the Attributor framework to improve the inter-procedural capabilities of LLVM. This is useful on its own but especially in situations where inlining is impossible or undesirable. In this GSoC project we will look at capabilities not yet available in the Attributor and for the potential to connect the Attributor with existing intra- and inter-procedural optimizations. In this project there is a lot of freedom to determine the actual tasks but we will provide a pool of smaller and medium sized tasks that can be chosen from as well.
      Preparation resources: The Attributor YouTube videos from the LLVM Developers Meeting 2019 and the recording of the IPO panel from the same meeting. The Attributor framework as well as other existing inter-procedural analyses and optimizations in LLVM.
      Expected results: Measurable better IPO, especially visible in cases where inlining is not an option or undesirable.
      Confirmed Mentor: Johannes Doerfert
      Desirable skills: Intermediate knowledge of C++, self motivation.
      Improve parallelism-aware analyses and optimizations
      Description of the project: This is a short description, please reach out to Johannes (jdoerfert on IRC) if it sounds interesting. With the OpenMPOpt pass (under review) we started to teach the LLVM optimization pipeline about OpenMP parallelism encoded as OpenMP runtime calls. In this GSoC project we will look at capabilities not yet available in the OpenMPOpt pass and for the potential to connect existing intra- and inter-procedural optimizations, e.g. the Attributor. In this project there is a lot of freedom to determine the actual tasks but we will provide a pool of smaller and medium sized tasks that can be chosen from as well.
      Preparation resources: The "Optimizing Indirections, using abstractions without remorse" video on YouTube from the LLVM Developers Meeting 2018. The paper "Compiler Optimizations for OpenMP" and "Compiler Optimizations For Parallel Programs" both by J. Doerfert and H. Finkel (the slides for these are potentially even more useful).
      Expected results: Measurable better performance or program analysis results for parallel programs with a focus on OpenMP.
      Confirmed Mentor: Johannes Doerfert
      Desirable skills: Intermediate knowledge of C++, self motivation.
      Make LLVM passes debug info invariant
      Description of the project: Generating debug information is one of the fundamental tasks a compiler typically fulfills. It is clear that executable generated code should not depend on the presence of debug information.
      
      Unfortunately there are known cases in LLVM were code generation differs depending on whether debug information is enabled (`-g`) or not. These kind of bugs can lead to bad debug experience ranging from unexpected execution behaviour to the point of programs running fine in debug mode while crashing without debug information.
      
      The issue has likely not a single cause but is triggered during different passes on different architectures. One such reason is the insertion of Call Frame Information (CFI) in the compiler backend during frame lowering and other later passes. The presence of CFI instructions seems to change instruction scheduling which therefore leads to different generated code.
      Preparation resources:
      PR37728 is a meta-bug that collects several related issues of differing codegen.
      PR37240 is a bug discussing the CFI issue mentioned above.
      The following RFC discusses some possible mitigation strategies and gives some background information on the CFI issue.
      Expected results:
      Write some tooling based on existing scripts to automatically generate examples of differing codegen. This is intended as a starting task to get to know the existing LLVM tools, learn to read LLVM's internal outputs etc.
      Choose one or more (depending on the difficulty) bugs that cause codegen differences and try to provide patches to fix them. We would be particularly interested in the mentioned CFI issue but working on some of the other related bugs is also absolutely fine.
      Confirmed Mentors: Paul Robinson and David Tellenbach
      Desirable skills: Intermediate knowledge of C++, some familarity with general computer architecture, some familarity with the x86 or Arm/AArch64 instruction set.
      Improve MergeFunctions to incorporate MergeSimilarFunction patches and ThinLTO Support
      Description of the project: MergeSimilarFunctions pass is able to merge not just identical functions, but also functions with small differences in their instructions to reduce code size. It does this by inserting control flow and an additional argument in the merged function to account for the differences. This work was presented at the LLVM Dev Meeting in 2013 A more detailed description was published in a paper at LCTES 2014. The code was released to the community at the time. Meanwhile, the pass has been in production use at QuIC for the past few years and has been actively maintained internally. In order to magnify the impact of MergeSimilarFunctions, it has been ported to ThinLTO and the patches have been upstreamed (see stack of 5 patches mentioned below). But instead of replacing the existing MergeFunctions pass in LLVM-upstream the community suggested we improve the existing one with the ideas from MergeSimilarFunctions. And then leverage the ThinLTO on top of that. The MergeSimilarFunction used in ThinLTO gives impressive code size reduction across a wide range of workloads and the work was presented at LLVM-dev 2018. The LLVM project would greatly benefit from this code size optimization as most embedded systems (think SmartPhones) applications are constrained on code-size.
      Preparation resources:
      Stack of patches:
      MergeSimilarFunctions 1/n: a code size pass to merge functions with small differences
      [Porting MergeSimilarFunctions 2/n] Changes to DataLayout
      [Merge SImilar Function ThinLTO 3/n] Add hash code to function summary
      [Merge SImilar Function ThinLTO 4/n] Make merge function decisions before the thin-lto stage
      [Merge SImilar Function ThinLTO 5/n] Set up similar function to be imported
      The paches can be easily applied to LLVM-trunk and would give a developer a decent head start ;).
      List of llvm-dev mailing list posts on previous discussions around Merge Functions
      Link1
      Link2
      Link3
      Link4
      The original paper: LCTES 2014
      Video and slides of the presentation
      Expected results:
      Improve MergeFunctions to have feature parity with MergeSimilarFunctions.
      Enable MergeFunctions to ThinLTO.
      Confirmed Mentors:Aditya Kumar (hiraditya on IRC and phabricator), JF Bastien (jfb on phabricator)
      Desirable skills: Course on compiler design, SSA Representation, Intermediate knowledge of C++, Familiarity with LLVM Core.
      Add DWARF support to yaml2obj
      Description of the project: LLVM provides a tool called yaml2obj which coverts a YAML document into an object file, for various different file formats such as ELF, COFF and Mach-O, along with obj2yaml which does the inverse. The tool is commonly used to test parts of LLVM, as YAML is often easier to use to describe an object file than raw assembly and more maintainable than a pre-built binary. DWARF is a debugging file format commonly used by LLVM. Many of the tests for LLVM’s DWARF emission are written in assembly, but it would be nicer to write them in YAML. However, yaml2obj does not properly support emission of DWARF sections. This project is to add functionality to yaml2obj to make writing test inputs for DWARF tests simpler, particularly for ELF objects.
      Preparation resources: Reading up on the DWARF file format will be useful, in particular the standards available at http://dwarfstd.org/Download.php. Also, familiarising yourself with the basics of the ELF file format, as described here https://www.sco.com/developers/gabi/latest/contents.html, may be beneficial.
      Expected results: The ability to use yaml2obj to generate DWARF sections for object files. Particularly important is ensuring the input YAML can be more easily understood than the equivalent assembly.
      Confirmed Mentors: James Henderson
      Desirable skills: Intermediate knowledge of C++.
      Improve hot cold splitting to aggressively outline small blocks
      Description of the project: Hot Cold Splitting in LLVM is an IR level function splitting transformation. The goal of hot/cold splitting is to improve the memory locality of code and helps reduce startup working set. The splitting pass does this by identifying cold blocks and moving them into separate functions. Because it is implemented at the IR level all the back end target benefit from it. It is a relatively new optimization and it was recently presented at the LLVM Dev Meeting in 2019 and the slides are here Because most of the benefit comes from outlining small blocks e.g., __assert_rtn. The goal of this project is to identify potential blocks via static analysis e.g., exception handling code, optimizing personality functions. Use cost-model to ensure outlining reduces the code size of the caller, use tail call whenever appropriate to save instructions.
      Preparation resources:
      Update on hot cold splitting
      The following two papers provide earlier work on hot cold splitting. While these papers are a good start, LLVM's HCS has completely different implementation in two aspects a) It is implemented at IR level and outlines basic blocks as function rather than naked branches. b) It is based on regions and outlines a set of basic blocks.
      Original paper on hot cold splitting by Pettis and Hansen.Section 5 on procedure splitting is interesting one. It has nice examples ;) to help understand why HCS works.
      Paper on hot cold splitting The paper provides some details on one approach to split functions. This is helpful to get a different perspective and may help get new ideas.
      Video and slides of the presentation
      Expected results:
      Improve Hot Cold Splitting to detect and outline cold blocks from program via static analysis or profile information. Use appropriate cost model to weigh benefit of HCS. In case compile time overhead becomes quadratic, come up with a cost model to detect when quadratic behavior gets triggered and bail out based on a compiler flag.
      Confirmed Mentors:Aditya Kumar (hiraditya on IRC and phabricator)
      Desirable skills: Course on compiler design, SSA Representation, Intermediate knowledge of C++, Familiarity with LLVM Core.
      Advanced Heuristics for Ordering Compiler Optimization Passes
      Description of the project: Selecting optimization passes for given application is very important but non-trivial problem because of the huge size of the compiler transformation space (incl. pass ordering). While the existing heuristics can provide high performance code for certain applications, they cannot easily benefit a wide range of application codes. The goal of the project is to learn the interplay between LLVM transformation passes and code structures, then improve the existing heuristics (or replace the heuristics with machine learning-based models) so that the LLVM compiler can provide a superior order of the passes customized per application.
      Expected results (possibilities):
      Insights about (implicit) dependences between existing passes.
      New pass pipelines (think -O3a, -O3b, ...) selectable by the user that tend to perform substantially better on certain kinds of programs.
      An improved LLVM pass heuristic or new machine learning-based models that can select the best order for LLVM transformation passes based on code structures.
      Preparation resources:
      HERCULES: Strong Patterns towards More Intelligent Predictive Modeling, Eunjung Park; Christos Kartsaklis; John Cavazos, IEEE ICPP’14 https://ieeexplore.ieee.org/abstract/document/6957226
      Predictive Modeling in a Polyhedral Optimization Space, Eunjung Park, John Cavazos, Louis-Noël Pouchet, Cédric Bastoul, Albert Cohen & P. Sadayappan, IJPP’13 https://link.springer.com/article/10.1007/s10766-013-0241-1
      Machine Learning in Compiler Optimization, Zheng Wang and Michael O’Boyle, IEEE Magazine 2018. https://ieeexplore.ieee.org/document/8357388
      Confirmed Mentors:EJ Park, Giorgis Georgakoudis, Johannes Doerfert
      Desirable skills: C++, Python, experience with LLVM and learning-based prediction preferable.
      Machine learning and compiler optimizations: using inter-procedural analysis to select optimizations
      Description of the project: Current machine learning models for compiler optimization select the best optimization strategies for functions based on isolated per function analysis. In this approach, the constructed models are not aware of any relationships with other functions around it (callers or callees) which can be helpful to decide the best optimization strategies for each function. In this project, we want to explore the SCC (Strongly Connected Components) call graph to add inter-procedural features in constructing machine learning-based models to find the best optimization strategies per function. Moreover, we want to explore the case that it is helpful to group strongly related functions together and optimize them as a group, instead of per function.
      Expected results (possibilities):
      Improved heuristics for existing (inter-procedural) passes, e.g. to weight inlining versus function cloning based on code features.
      Machine learning models to select the best optimizations using code features and inter-procedural analysis. This model can be used for functions in isolation or groups of functions, e.g., CGSCCs.
      Preparation resources:
      HERCULES: Strong Patterns towards More Intelligent Predictive Modeling, Eunjung Park; Christos Kartsaklis; John Cavazos, IEEE ICPP’14 https://ieeexplore.ieee.org/abstract/document/6957226
      Predictive Modeling in a Polyhedral Optimization Space, Eunjung Park, John Cavazos, Louis-Noël Pouchet, Cédric Bastoul, Albert Cohen & P. Sadayappan, IJPP’13 https://link.springer.com/article/10.1007/s10766-013-0241-1
      Machine Learning in Compiler Optimization, Zheng Wang and Michael O’Boyle, IEEE Magazine 2018. https://ieeexplore.ieee.org/document/8357388
      Confirmed Mentors:EJ Park, Giorgis Georgakoudis, Johannes Doerfert
      Desirable skills: C++, Python, experience with LLVM and learning-based prediction preferable.
      Description of the project: There is currently no easy way to use the result of PostDominatorTreeAnalysis in a loop pass, as PostDominatorTreeAnalysis is a function analysis, and it is not included in LoopStandardAnalysisResults. If one adds PostDominatorTreeAnalysis in LoopStandardAnalysisResults, then all loop passes need to preserve it, meaning that all loop passes need to make sure the result is up to date. In this project, we want to modify some commonly used utilities to generate a list of updates, which can be consume by different updaters, e.g. DomTreeUpdater to update DominatorTree and PostDominatorTree, and MSSAU to update MemorySSA, etc, instead of only updating the DominatorTree. In additional, we want to change existing loop passes to preserve the PostDominatorTree. Finally, adding PostDominatorTree in LoopStandardAnalysisResults.
      Expected results (possibilities): PostDominatorTree added in LoopStandardAnalysisResults, and can be used by loop passes. More common utilities change to generate list of updates to be easily obtained by different updaters.
      Confirmed Mentors: Whitney Tsang, Ettore Tiotto, Bardia Mahjour
      Desirable skills: Intermediate knowledge of C++, self-motivation.
      Preparation resources:
      Create LoopNest Pass
      Description of the project: Currently if you want to write a pass that works on a loop nest, you have to pick from either a function pass or a loop pass. If you chose to write it as a function pass, then you lose the ability to add loops dynamically back to the pipeline. If you decide to write it as a loop pass, then you are wasting compile time to traverse to your pass and return right away when the given loop is not the outermost loop. In this project, we want to create a LoopNestPass, where transformations intended for loop nest can inherit from it, and have the same ability as the LoopPass to dynamically add loops to the pipeline. In addition, create all the adaptors requires to add loop nest passes at different points of the pass builder.
      Expected results (possibilities): Transformations/Analyses can be written as LoopNestPass, without compromising compile time or usability.
      Confirmed Mentors: Whitney Tsang, Ettore Tiotto
      Desirable skills: Intermediate knowledge of C++, self-motivation.
      Preparation resources:
      Instruction properties dumper and checker
      Description of the project: TableGen is flexible and allow the end-user to define and set common properties of records (instructions). Every target has dozens or hundreds of such instruction properties. As target code evolve, the td files become more and more complicated, it become harder to see whether the setting of some properties is necessary, even correct or not. eg: whether hasSideEffects property is correctly set on all instructions? One can manually search through the TableGen-generated files; or write some script to run TableGen and matching the output for some specific properties, but a standalone utility that can dump and check instruction properties systematically (eg: also allow target to define some verification rules) might be better from a build-process-management standpoint. This can help to find quite some hidden bugs and hence improve the overall codegen code quality. In addition, the utility can be used to write regression tests for instruction properties, which will increase the quality and precision of LLVM's regression tests.
      Expected results (possibilities): A standalone llvm tool or utility that can dump and check instruction properties systematically
      Confirmed Mentors: Hal Finkel, Jinsong Ji , Qingshan Zhang
      Desirable skills: Intermediate knowledge of C++, self-motivation.
      Unify ways to move code or check if code is safe to be moved
      Description of the project: Determining whether it is safe to move code around is implemented in several transformations in LLVM (e.g. canSinkOrHoistInst in LICM, or makeLoopInvariant in Loop). Each of these implementations may return different results for a given query, making code motion safety checks inconsistent and duplicated. On the other hand, the mechanism for doing the actual code motion is also different in each transformation. Code duplication causes maintenance problems and increases the time taken to write new transformation. In this project, we want to first identify all the existing ways in loop transformations (could be function or loop pass) to check if code is safe to move, and to move code, and create a standardize way to do so.
      Expected results (possibilities): A standardize/superset of all the existing ways in loop transformations of checking if code is safe to be moved and to move
      Confirmed Mentors: Whitney Tsang, Ettore Tiotto, Bardia Mahjour
      Desirable skills: Intermediate knowledge of C++, self-motivation.
      Preparation resources:
      MLIR
      All the items in the list of open projects are opened to GSOC. Feel free to propose your own ideas as well on Discourse.
      Find null smart pointer dereferences with the Static Analyzer
      Description of the project: The Clang Static Analyzer already knows how to prevent crashes caused by null pointer dereference in arbitrary code, however it often "gives up" when the code is too complicated. In particular, implementation details of C++ standard classes, even simple ones such as smart pointers or optionals, may be too convoluted for the Analyzer to fully understand. Moreover, the exact behavior depends on which implementation of the Standard Library is used (e.g., GNU libstdc++ or LLVM's own libc++).
      We can enable the Analyzer to find more bugs in modern C++ code by teaching it explicitly about the behavior of C++ standard classes, and therefore skipping the whole process in which the Analyzer tries to understand all the implementation details on its own. For example, we could teach it that a default-constructed smart pointer is null, and any attempt to dereference it would result in a crash. The project would therefore consist in manually providing implementations for various methods of standard classes.
      Expected results: We want the Static Analyzer to emit warnings when a null smart pointer dereference would occur in the code. For example:
          #include <memory>
      
          int foo(bool flag) {
            std::unique_ptr<int> x;  // note: Default constructor produces a null unique pointer;
      
            if (flag)                // note: Assuming 'flag' is false;
              return 0;              // note: Taking false branch
      
            return *x;               // warning: Dereferenced smart pointer 'x' is null.
          }
          
      We should be able to cover at least one class fully, for example, std::unique_ptr, and then see if we can generalize our results to other classes, such as std::shared_ptr or the C++17 std::optional.
      Confirmed Mentor: Artem Dergachev, Gábor Horváth
      Desirable skills: Intermediate knowledge of C++.
      LLDB
      Support autosuggestions in LLDB's command line
      Description of the project: LLDB's command line offers several convenience features that are inspired by features of UNIX shells such as tab completions or a command history. One feature that is not implemented yet are 'autosuggestions'. These are suggestions for possible commands that the user might want to type, but unlike tab completions they are displayed directly behind the cursor while the user is typing a command. A good demonstration how this could look like are the autosuggestions implemented in fish shell.
      This project is about implementing autosuggestions in LLDB's editline-based command shell.
      Confirmed Mentor: Jonas Devlieghere and Raphael Isemann
      Desirable skills: Intermediate knowledge of C++.
      Implement the missing tab completions for LLDB's command line
      Description of the project: LLDB's command line offers several convenience features that are inspired by features of UNIX shells such as tab completions for commands. These tab completions are implemented by a completion engine that is not only used by the command line interface of LLDB, but also by graphical interfaces for LLDB such as IDEs. While the tab completions in LLDB are really useful, they are currently not implemented for all commands and their respective arguments. This project is about implementing the remaining completions for the commands in LLDB which will greatly improve the user experience of LLDB. Improving existing completions is also part of the project. Note that the completions are not static list of strings but often require inspecting and understanding the internal state of LLDB. As LLDB commands and their tab completions cover all aspects of LLDB, this project offers a great way to get an overview of all the functionality in LLDB.
      Confirmed Mentor:Raphael Isemann
      Desirable skills: Intermediate knowledge of C++.
      Reimplement LLDB's command-line commands using the public SB API.
      Description of the project: Just as LLVM is a library to build compilers, LLDB is a library to build debuggers. LLDB vends a stable, public SB API. Due to historic reasons the LLDB command line interface is currently implemented on top of LLDB's private API and it duplicates a lot of functionality that is already implemented in the public API. Rewriting LLDB's command line interface on top of the public API would simplify the implementation, eliminate duplicate code, and most importantly reduce the testing surface.
      This work will also provide an opportunity to clean up the SB API of commands that have accrued too many overloads over time and convert them to make use of option classes to both gather up all the variants and also future-proof the APIs.
      Confirmed Mentor:Adrian Prantl and Jim Ingham
      Desirable skills: Intermediate knowledge of C++.
      Add support for batch-testing to the LLDB testsuite.
      Description of the project: One of the tensions in the testsuite is that spinning up a process and getting it to some point is not a cheap operation, so you'd like to do a bunch of tests when you get there. But the current testsuite bails at the first failure, so you don't want to do many tests since the failure of one fails all the others. On the other hand, there are some individual test assertions where the failure of the assertion should cause the whole test to fail. For example, if you fail to stop at a breakpoint where you want to check some variable values, then the whole test should fail. But if your test then wants to check the value of five independent locals, it should be able to do all five, and then report how many of the five variable assertions failed. We could do this by adding Start and End markers for a batch of tests, do all the tests in the batch without failing the whole test, and then report the error and fail the whole test if appropriate. There might also be a nice way to do this in Python using scoped objects for the test sections.
      Confirmed Mentor: Jim Ingham
      Desirable skills: Intermediate knowledge of Python.
      Google Summer of Code 2019
      Google Summer of Code 2019 contributed a lot to the LLVM project. For the list of accepted and completed projects, please take a look into Google Summer of Code website.
      LLVM
      Debug Info should have no effect on codegen
      Description of the project: Adding Debug Info (compiling with `clang -g`) shouldn't change the generated code at all. Unfortunately we have bugs. These are usually not too hard to fix and a good way to discover new part of the codebase! We suggest building object files both ways and disassembling the text sections, which will give cleaner diffs than comparing .s files.
      Expected results: Reduced test cases, bug reports with analysis (e.g., which pass is responsible), possibly patches.
      Confirmed Mentor: Paul Robinson
      Desirable skills: Intermediate knowledge of C++, some familiarity with x86 or ARM instruction set.
      Clang
      Implement an ASTImporter fuzzer
      Description of the project: Clang contains an ASTImporter which allows moving declarations and statements from one Clang AST to another. This is for example used for static analysis across translation units and in LLDB's expression evaluator.
      The current ASTImporter works as intended when moving simple C code from one AST to another. However, more complicated declarations such as C++'s OOP features and templates are not fully implemented and can cause crashes or invalid AST nodes. The bug reports related to these crashes are often filed against LLDB's expression evaluator and are rarely submited with a minimal reproducer. This makes improving ASTImporter a time-consuming and tedious task.
      This project is about writing a fuzzer to proactively discover these ASTImporter bugs and provide minimal reproducers which make understanding and fixing the underlying bug easier.
      A possible implementation of such a fuzzer and driver could look like this:
      Generate some source code that can be imported (either fully randomly or based on existing source code from a user-given code corpus).
      Import randomly a few declarations from this AST. The AST in which they are imported to can already be populated with declarations.
      Run Clang's code generator over our imported AST.
      If we hit an assert during the import or CodeGen steps we probably found an ASTImporter bug.
      The fuzzer driver should now reduce the size of the source code until it is as small as possible and still reproduces the crash (e.g. by running Creduce with an automatically generated test script).
      The reproducer should now be stored in a format so that it can just be copied into Clang's regression test suite for the ASTImporter (see the clang/test/Import/ directory). The reproducer must still reproduce the found bug when run as part of the test suite.
      This is just one possible approach and students are welcome to submit their own ideas on how the fuzzer should operate. Approaches that allow to automatically verify more aspects of the imported AST (e.g. the source locations of AST nodes, size of RecordDecls) are encouraged. The fuzzer and driver should be implemented in C++ and/or Python.
      Confirmed Mentor: Raphael Isemann, Shafik Yaghmour
      Desirable skills: Intermediate knowledge of C++.
      Improve shell autocompletion for Clang
      Description of the project: Clang has a newly implemented autocompletion feature which details can be found at LLVM blog. We would like to improve this by adding more flags to autocompletion, supporting more shells (currently it supports only bash) and exporting this feature to other projects such as llvm-opt. Accepted student will be working on Clang Driver, LLVM Options and shell scripts.
      Expected Results: Autocompletion working on bash and zsh, support llvm-opt options.
      Confirmed Mentor: Yuka Takahashi and Vassil Vassilev
      Desirable skills: Intermediate knowledge of C++ and shell scripting
      Google Summer of Code 2018
      Google Summer of Code 2018 contributed a lot to the LLVM project. For the list of accepted and completed projects, please take a look into Google Summer of Code website.
      Google Summer of Code 2017
      Google Summer of Code 2017 contributed a lot to the LLVM project. For the list of accepted and completed projects, please take a look into Google Summer of Code website.
      What is this?
      This document is meant to be a sort of "big TODO list" for LLVM. Each project in this document is something that would be useful for LLVM to have, and would also be a great way to get familiar with the system. Some of these projects are small and self-contained, which may be implemented in a couple of days, others are larger. Several of these projects may lead to interesting research projects in their own right. In any case, we welcome all contributions.
      If you are thinking about tackling one of these projects, please send a mail to the LLVM Developer's mailing list, so that we know the project is being worked on. Additionally this is a good way to get more information about a specific project or to suggest other projects to add to this page.
      The projects in this page are open-ended. More specific projects are filed as unassigned enhancements in the LLVM bug tracker. See the list of currently outstanding issues if you wish to help improve LLVM.
      LLVM Subprojects: Clang and More
      In addition to hacking on the main LLVM project, LLVM has several subprojects, including Clang and others. If you are interested in working on these, please see their "Open projects" page:
      The Clang Open Projects list.
      The Polly Open Projects list.
      The SAFECode Open Projects list.
      Improving the current system
      Improvements to the current infrastructure are always very welcome and tend to be fairly straight-forward to implement. Here are some of the key areas that can use improvement...
      Factor out target descriptions
      Currently, both Clang and LLVM have a separate target description infrastructure, with some features duplicated, others "shared" (in the sense that Clang has to create a full LLVM target description to query specific information).
      This separation has grown in parallel, since in the beginning they were quite different and served disparate purposes. But as the compiler evolved, more and more features had to be shared between the two so that the compiler would behave properly. An example is when targets have default features on speficic configurations that don't have flags for. If the back-end has a different "default" behaviour than the front-end and the latter has no way of enforcing behaviour, it won't work.
      An alternative would be to create flags for all little quirks, but first, Clang is not the only front-end or tool that uses LLVM's middle/back ends, and second, that's what "default behaviour" is there for, so we'd be missing the point.
      Several ideas have been floating around to fix the Clang driver WRT recognizing architectures, features and so on (table-gen it, user-specific configuration files, etc) but none of them touch the critical issue: sharing that information with the back-end.
      Recently, the idea to factor out the target description infrastructure from both Clang and LLVM into its own library that both use, has been floating around. This would make sure that all defaults, flags and behaviour are shared, but would also reduce the complexity (and thus the cost of maintenance) a lot. That would also allow all tools (lli, llc, lld, lldb, etc) to have the same behaviour across the board.
      The main challenges are:
      To make sure the transition doesn't destroy the delicate balance on any target, as some defaults are implicit and, some times, unknown.
      To be able to migrate one target at a time, one tool at a time and still keep the old infrastructure intact.
      To make it easy for detecting target's features for both front-end and back-end features, and to merge both into a coherent set of properties.
      To provide a bridge to the new system for tools that haven't migrated, especially the off-the-tree ones, that will need some time (one release, at least) to migrate..
      Implementing Code Cleanup bugs
      The LLVM bug tracker occasionally has "code-cleanup" bugs filed in it. Taking one of these and fixing it is a good way to get your feet wet in the LLVM code and discover how some of its components work. Some of these include some major IR redesign work, which is high-impact because it can simplify a lot of things in the optimizer.
      Some specific ones that would be great to have:
      Fix the design of GlobalAlias to not require dest type to match source type
      Redesign ConstantExpr's
      Static constructors should be purged from LLVM
      Additionally, there are performance improvements in LLVM that need to get fixed. These are marked with the slow-compile keyword. Use this LLVM bug tracker query to find them.
      Add programs to the llvm-test testsuite
      The llvm-test testsuite is a large collection of programs we use for nightly testing of generated code performance, compile times, correctness, etc. Having a large testsuite gives us a lot of coverage of programs and enables us to spot and improve any problem areas in the compiler.
      One extremely useful task, which does not require in-depth knowledge of compilers, would be to extend our testsuite to include new programs and benchmarks. In particular, we are interested in cpu-intensive programs that have few library dependencies, produce some output that can be used for correctness testing, and that are redistributable in source form. Many different programs are suitable, for example, see this list for some potential candidates.
      Compile programs with the LLVM Compiler
      We are always looking for new testcases and benchmarks for use with LLVM. In particular, it is useful to try compiling your favorite C source code with LLVM. If it doesn't compile, try to figure out why or report it to the llvm-bugs list. If you get the program to compile, it would be extremely useful to convert the build system to be compatible with the LLVM Programs testsuite so that we can check it into SVN and the automated tester can use it to track progress of the compiler.
      When testing a code, try running it with a variety of optimizations, and with all the back-ends: CBE, llc, and lli.
      Benchmark the LLVM compiler
      Find benchmarks either using our test results or on your own, where LLVM code generators do not produce optimal code or where another compiler produces better code. Try to minimize the test case that demonstrates the issue. Then, either submit a bug with your testcase and the code that LLVM produces vs. the code that it should produce, or even better, see if you can improve the code generator and submit a patch. The basic idea is that it's generally quite easy for us to fix performance problems if we know about them, but we generally don't have the resources to go finding out why performance is bad.
      Benchmark Statistics and Warning System
      The LNT perf database has some nice features like detect moving average, standard deviations, variations, etc. But the report page give too much emphasis on the individual variation (where noise can be higher than signal), eg. this case.
      The first part of the project would be to create an analysis tool that would track moving averages and report:
      If the current result is higher/lower than the previous moving average by more than (configurable) S standard deviations
      If the current moving average is more than S standard deviations of the Base run
      If the last A moving averages are in constant increase/decrease of more than P percent
      The second part would be to create a web page which would show all related benchmarks (possibly configurable, like a dashboard) and show the basic statistics with red/yellow/green colour codes to show status and links to more detailed analysis of each benchmark.
      A possible third part would be to be able to automatically cross reference different builds, so that if you group them by architecture/compiler/number of CPUs, this automated tool would understand that the changes are more common to one particular group.
      Improving Coverage Reports
      The LLVM Coverage Report has a nice interface to show what source lines are covered by the tests, but it doesn't mentions which tests, which revision and what architecture is covered.
      A project to renovate LCOV would involve:
      Making it run on a buildbot, so that we know what commits / architectures are covered
      Update the web page to show that information
      Develop a system that would report every buildbot build into the web page in a searchable database, like LNT
      Another idea is to enable the test suite to run all built backends, not only the host architecture, so that coverage report can be built in a fast machine and have one report per commit without needing to update the buildbots.
      Miscellaneous Improvements
      Completely rewrite bugpoint. In addition to being a mess, bugpoint suffers from a number of problems where it will "lose" a bug when reducing. It should be rewritten from scratch to solve these and other problems.
      Add support for transactions to the PassManager for improved bugpoint.
      Improve bugpoint to support running tests in parallel on MP machines.
      Add MC assembler/disassembler and JIT support to the SPARC port.
      Move more optimizations out of the -instcombine pass and into InstructionSimplify. The optimizations that should be moved are those that do not create new instructions, for example turning sub i32 %x, 0 into %x. Many passes use InstructionSimplify to clean up code as they go, so making it smarter can result in improvements all over the place.
      Adding new capabilities to LLVM
      Sometimes creating new things is more fun than improving existing things. These projects tend to be more involved and perhaps require more work, but can also be very rewarding.
      Extend the LLVM intermediate representation
      Many proposed extensions and improvements to LLVM core are awaiting design and implementation.
      Improvements for Debug Information Generation
      EH support for non-call exceptions
      Many ideas for feature requests are stored in LLVM bugzilla. Search for bugs with a "new-feature" keyword.
      Pointer and Alias Analysis
      We have a strong base for development of both pointer analysis based optimizations as well as pointer analyses themselves. We want to take advantage of this:
      The globals mod/ref pass does an inexpensive bottom-up context sensitive alias analysis. There are some inexpensive things that we could do to better capture the effects of functions that access pointer arguments. This can be really important for C++ methods, which spend lots of time accessing pointers off 'this'.
      The alias analysis API supports the getModRefBehavior method, which allows the implementation to give details analysis of the functions. For example, we could implement full knowledge of printf/scanf side effects, which would be useful. This feature is in place but not being used for anything right now.
      We need some way to reason about errno. Consider a loop like this:
          for ()
            x += sqrt(loopinvariant);
      We'd like to transform this into:
          t = sqrt(loopinvariant);
          for ()
            x += t;
      This transformation is safe, because the value of errno isn't otherwise changed in the loop and the exit value of errno from the loop is the same. We currently can't do this, because sqrt clobbers errno, so it isn't "readonly" or "readnone" and we don't have a good way to model this.
      The important part of this project is figuring out how to describe errno in the optimizer: each libc #defines errno to something different it seems. Maybe the solution is to have a __builtin_errno_addr() or something and change sys headers to use it.
      There are lots of ways to optimize out and improve handling of memcpy/memset.
      Profile-Guided Optimization
      We now have a unified infrastructure for writing profile-guided transformations, which will work either at offline-compile-time or in the JIT, but we don't have many transformations. We would welcome new profile-guided transformations as well as improvements to the current profiling system.
      Ideas for profile-guided transformations:
      Superblock formation (with many optimizations)
      Loop unrolling/peeling
      Profile directed inlining
      Code layout
      ...
      Improvements to the existing support:
      The current block and edge profiling code that gets inserted is very simple and inefficient. Through the use of control-dependence information, many fewer counters could be inserted into the code. Also, if the execution count of a loop is known to be a compile-time or runtime constant, all of the counters in the loop could be avoided.
      You could implement one of the "static profiling" algorithms which analyze a piece of code an make educated guesses about the relative execution frequencies of various parts of the code.
      You could add path profiling support, or adapt the existing LLVM path profiling code to work with the generic profiling interfaces.
      Code Compaction
      LLVM aggressively optimizes for performance, but does not yet optimize for code size. With a new ARM backend, there is increasing interest in using LLVM for embedded systems where code size is more of an issue.
      Someone interested in working on implementing code compaction in LLVM might want to read this article, describing using link-time optimizations for code size optimization.
      New Transformations and Analyses
      Implement a Loop Dependence Analysis Infrastructure
      - Design some way to represent and query dep analysis
      Value range propagation pass
      More fun with loops: Predictive Commoning
      Type inference (aka. devirtualization)
      Value assertions (also PR810).
      Code Generator Improvements
      Generalize target-specific backend passes that could be target-independent, by adding necessary target hooks and making sure all IR/MI features (such as register masks and predicated instructions) are properly handled. Enable these for other targets where doing so is demonstrably beneficial. For example:
      lib/Target/Hexagon/RDF*
      lib/Target/AArch64/AArch64AddressTypePromotion.cpp
      Merge the delay slot filling logic that is duplicated into (at least) the Sparc and Mips backends into a single target independent pass. Likewise, the branch shortening logic in several targets should be merged together into one pass.
      Implement 'stack slot coloring' to allocate two frame indexes to the same stack offset if their live ranges don't overlap. This can reuse a bunch of analysis machinery from LiveIntervals. Making the stack smaller is good for cache use and very important on targets where loads have limited displacement like ppc, thumb, mips, sparc, etc. This should be done as a pass before prolog epilog insertion. This is now done for register allocator temporaries, but not for allocas.
      Implement 'shrink wrapping', which is the intelligent placement of callee saved register save/restores. Right now PrologEpilogInsertion always saves every (modified) callee save reg in the prolog and restores it in the epilog, however, some paths through a function (e.g. an early exit) may not use all regs. Sinking the save down the CFG avoids useless work on these paths. Work has started on this, please inquire on llvm-dev.
      Implement interprocedural register allocation. The CallGraphSCCPass can be used to implement a bottom-up analysis that will determine the *actual* registers clobbered by a function. Use the pass to fine tune register usage in callers based on *actual* registers used by the callee.
      Add support for 16-bit x86 assembly and real mode to the assembler and disassembler, for use by BIOS code. This includes both 16-bit instruction encodings as well as privileged instructions (lgdt, lldt, ltr, lmsw, clts, invd, invlpg, wbinvd, hlt, rdmsr, wrmsr, rdpmc, rdtsc) and the control and debug registers.
      Miscellaneous Additions
      Port the Bigloo Scheme compiler, from Manuel Serrano at INRIA Sophia-Antipolis, to output LLVM bytecode. It seems that it can already output .NET bytecode, JVM bytecode, and C, so LLVM would ostensibly be another good candidate.
      Write a new frontend for some other language (Java? OCaml? Forth?)
      Random test vector generator: Use a C grammar to generate random C code, e.g., quest; run it through llvm-gcc, then run a random set of passes on it using opt. Try to crash opt. When opt crashes, use bugpoint to reduce the test case and post it to a website or mailing list. Repeat ad infinitum.
      Add sandbox features to the Interpreter: catch invalid memory accesses, potentially unsafe operations (access via arbitrary memory pointer) etc.
      Port Valgrind to use LLVM code generation and optimization passes instead of its own.
      Write LLVM IR level debugger (extend Interpreter?)
      Write an LLVM Superoptimizer. It would be interesting to take ideas from this superoptimizer for x86: paper #1 and paper #2 and adapt them to run on LLVM code.
      It would seem that operating on LLVM code would save a lot of time because its semantics are much simpler than x86. The cost of operating on LLVM is that target-specific tricks would be missed.
      The outcome would be a new LLVM pass that subsumes at least the instruction combiner, and probably a few other passes as well. Benefits would include not missing cases missed by the current combiner and also more easily adapting to changes in the LLVM IR.
      All previous superoptimizers have worked on linear sequences of code. It would seem much better to operate on small subgraphs of the program dependency graph.
      Projects using LLVM
      In addition to projects that enhance the existing LLVM infrastructure, there are projects that improve software that uses, but is not included with, the LLVM compiler infrastructure. These projects include open-source software projects and research projects that use LLVM. Like projects that enhance the core LLVM infrastructure, these projects are often challenging and rewarding.
      Encode Analysis Results in MachineInstr IR
      At least one project (and probably more) needs to use analysis information (such as call graph analysis) from within a MachineFunctionPass, however, most analysis passes operate at the LLVM IR level. In some cases, a value (e.g., a function pointer) cannot be mapped from the MachineInstr level back to the LLVM IR level reliably, making the use of existing LLVM analysis passes from within a MachineFunctionPass impossible (or at least brittle).
      This project is to encode analysis information from the LLVM IR level into the MachineInstr IR when it is generated so that it is available to a MachineFunctionPass. The exemplar is call graph analysis (useful for control-flow integrity instrumentation, analysis of code reuse defenses, and gadget compilers); however, other LLVM analyses may be useful.
      Code Layout in the LLVM JIT
      Implement an on-demand function relocator in the LLVM JIT. This can help improve code locality using runtime profiling information. The idea is to use a relocation table for every function. The relocation entries need to be updated upon every function relocation (take a look at this article). A (per-function) basic block reordering would be a useful extension.
      Improved Structure Splitting and Field Reordering
      The goal of this project is to implement better data layout optimizations using the model of reference affinity. This paper provides some background information.
      Finish the Slimmer Project
      Slimmer is a prototype tool, built using LLVM, that uses dynamic analysis to find potential performance bugs in programs. Development on Slimmer started during Google Summer of Code in 2015 and resulted in an initial prototype, but evaluation of the prototype and improvements to make it portable and robust are still needed. This project would have a student pick up and finish the Slimmer work. The source code of Slimmer and its current documentation can be found at its Github web page.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/llvm-compiler-infrastructure/
    idea_list_url: https://llvm.org/OpenProjects.html

  - organization_id: 82
    organization_name: LabLua
    no_of_ideas:
    ideas_content: |
      LabLua - Programming Language Research
      Ideas List - Google Summer of Code 2025
      In this page we introduce some of the projects that are are working with us this year under the LabLua umbrella and list some potential ideas for GSoC 2025 projects.
      If you are a contributor candidate, feel free to get in touch with us via our Matrix, mailing list or by sending an email to one of our mentors. You can apply using one of the ideas in the list or you can bring your own idea. Either way, don't leave it to the last minute =).
      Please use our application template to prepare your proposal and take a look at our successful projects from last year.
      Documentation generator tool for the Teal language
      Port Lua Test Suite to Lunatik
      Lunatik binding for Human Interface Devices (HID) drivers
      Lunatik package for Linux distros
      Terminal UI library for Lua
      Conntrack and NAT support for Lunatik
      Prepared Statements for LuaSQL
      Lunatik Binding for Linux Traffic Control (TC) and eBPF Maps
      Documentation generator tool for the Teal language
      The goal of this project is to create a "tealdoc" tool that generates documentation from comments embedded in Teal source code. Teal is a statically typed language that compiles to Lua (Teal is to Lua somewhat like TypeScript is to JavaScript). Since Teal is essentially a superset of Lua, this tool should be useful for Lua as well. There is prior art for Lua (LuaDoc, LDoc), but the community would benefit from a Teal-specific tool that is able to make use of its type annotations as possibly integrate better with language servers in modern editors.
      Expected results
      a CLI tool that generates Markdown from Teal or Lua comments and Teal type annotations
      support for generating HTML, possibly using templating systems (possibly reusing LDoc code)
      stretch goal: integration with other existing tooling such as the vscode-teal plugin and LuaRocks
      stretch goal: extensibility for supporting more languages in the Lua ecosystem
      Tools
      Teal
      any Lua libraries needed
      LuaRocks
      Skill level
      Intermediate
      Project size
      Large (350 hours)
      Mentor
      Hisham Muhammad
      Lunatik binding for Human Interface Devices (HID) drivers
      Lunatik is a framework for scripting the Linux kernel with Lua. For example, Lunatik can be used for scripting the Linux networking subsystem (as presented at Netdev 0x14 and 0x17) among other examples.
      The purpose of this project is to create a Lunatik library for binding the Linux HID APIs to allow developers to write new HID drivers using Lua. This project might leverage the Lunatik device library, which allows the creation of character device drivers using Lua. Moreover, this project should also port at least one HID driver to Lua.
      Expected results
      Lunatik HID library
      HID driver examples in Lua
      Benchmark comparison between the original HID drivers and their Lua implementation
      Prerequisites
      Lua and C programming languages
      Experience with the Lua-C API (highly desirable)
      Experience with Linux kernel (highly desirable)
      Skill level
      Intermediate
      Project size
      Medium (175 hours) or Large (350 hours)
      Mentors
      Lourival Vieira Neto
      Matrix room
      #lunatik
      Port Lua Test Suite to Lunatik
      Lunatik is a framework for scripting the Linux kernel with Lua. For example, Lunatik can be used for scripting the Linux networking subsystem (as presented at Netdev 0x14 and 0x17) among other examples.
      The purpose of this project is to port the Lua Test Suite to Lunatik. That is, to adapt scripts from the Lua Test Suite and develop a Linux loadable kernel module containing its C portion. This project might leverage the GSoC 2015 project developed by Guilherme Salazar, which ported the Lua Test Suite to the NetBSD kernel.
      The main difference between the kernel Lua and regular user-level Lua is that kernel Lua doesn't have support for standard libraries that depend on operating system (e.g., io and os) and for floating-point numbers.
      Expected results
      Adapted test scripts for Lunatik
      Lunatik library for testing the Lua C API
      Test Report at least for x86_64 and ARM64
      Prerequisites
      Lua and C programming languages
      Experience with the Lua-C API (nice to have)
      Experience with Linux kernel (nice to have)
      Skill level
      Intermediate
      Project size
      Medium (175 hours)
      Mentors
      Guilherme Salazar
      Lourival Vieira Neto
      Matrix room
      #lunatik
      Lunatik package for Linux distros
      Lunatik is a framework for scripting the Linux kernel with Lua. For example, Lunatik can be used for scripting the Linux networking subsystem (as presented at Netdev 0x14 and 0x17) among other examples.
      The purpose of this project is to create Lunatik packages for some Linux distributions including, at least, Ubuntu, OpenWRT and VyOS. This project should also provide the documentation and templates for creating packages for new Lunatik libraries.
      Expected results
      Lunatik packages for Linux distros (at least, Ubuntu, OpenWRT, VyOS)
      Submit packages to upstream repositories
      Documentation and templates
      Prerequisites
      Lua and C programming languages
      Experience with build tools and package managers (highly desirable)
      Experience with the Lua-C API (nice to have)
      Experience with Linux kernel (nice to have)
      Skill level
      Intermediate
      Project size
      Small (90 hours)
      Mentors
      Marcel Moura
      Lourival Vieira Neto
      Matrix room
      #lunatik
      Terminal UI library for Lua
      Lua has several core libraries that work across platforms; luasocket (networking), luafilesystem (file system), and luasystem (time, random, terminal). The latter library, luasystem, provides the primitives to handle terminal operations, albeit they are fundamentally different on Posix and Windows based systems.
      The purpose of this project is to shape the new terminal.lua library that builds on luasystems terminal primitives to build basic UI elements for user interaction in a cross-platform way. This should not be anything like curses, but the simpler user interactions like;
      progress indicators/bars
      prompts; yes/no, ok/cancel
      reading line inputs; reading a filename or other strings
      hidden inputs; for secrets
      headers and footers (basics for full-screen apps)
      More complex full screen app support (panels, drawing/re-drawing)
      etc.
      Things to consider
      The library should be general purpose, adhering the the Lua principle of 'mechanisms over policies'. This means for example that it should be possible to use it sync as well as async (coroutines), and it shouldn't force control over the main application loop, etc. A developer using the library should be able to make his/her own choice.
      Besides that terminals are challenging to work with. There are many control codes to control the terminal, however querying the terminal is very limited. There is no way to request current color status or cursor visibility for example.
      Some explorations to get started:
      what are terminals to begin with? a great explanation part 1, and part 2
      read up on terminals and streams; stdin, stdout, and stder; especially the latter two, when to use what?
      what does LuaSystem offer for platform compatibility, see LuaSystem terminal docs
      check the existing code base
      Expected results
      API that makes it easy to work around terminal limitations
      API design with consistency across platforms
      updated terminal.lua build on top of LuaSystem, ready for a first release
      works on Windows and Posix
      including tests, documentation and examples
      Prerequisites
      Lua programming language
      Experience with terminals (nice to have)
      Skill level
      Beginner
      Project size
      Medium (175 hours)
      Mentors
      Thijs Schreijer
      Matrix room
      #lunarmodules
      Conntrack and NAT support for Lunatik
      Connection tracking (conntrack) is a fundamental component of the Linux kernel's networking stack. It is part of the Netfilter framework and is responsible for monitoring active network connections passing through the system. Conntrack maintains a state table, allowing the kernel to track packets as part of a flow and apply connection-oriented filtering, NAT (Network Address Translation), and stateful firewalling.
      NAT is used to modify IP addresses and ports in packet headers to facilitate address translation, load balancing, and security enforcement. The Linux kernel provides APIs to manipulate NAT and connection tracking through the Netfilter framework.
      The purpose of this project is to port conntrack and NAT data structures and kernel APIs to lunatik. These are present under:
      net/netfilter/conntrack.h
      net/netfilter/nf_conntrack_common.h
      net/netfilter/conntrack_tuple.h
      net/netfilter/nf_conntrack_core.h
      net/netfilter/nf_nat.h
      This projects builds upon the GSoC 2024 Project 'Lunatik binding for Netfilter'. For complete reference on the relevant kernel headers and data structures, refer to the following gist.
      Expected results
      Allow fetching the conntrack entries and connection information
      Ability to conntrack add entries from lua programs that need to perform NAT. Example use case - L7 load balancing using netfilter in lua
      Ability to perform NAT for atleast inet protocols
      Prerequisites
      Lua and C programming languages
      Linux Networking
      Experience with Linux Kernel (highly desirable)
      Experience with Netfilter subsystem (good to have)
      Skill level
      Challenging
      Project size
      Medium (175 hours) or Large (350 hours)
      Mentors
      Lourival Vieira Neto
      Mohammad Shehar Yaar Tausif
      Matrix room
      #lunatik
      Add support for prepared statements for LuaSQL
      'LuaSQL' is a generic interface from Lua to a DBMS. It aims at portability over performance, but it allows extensions to suit the particularities of each DBMS.
      The inclusion of support for prepared statements in LuaSQL has been discussed thoroughly some time ago, but since each DBMS offers very different APIs there is no standard that could be defined to assure portability between them. Anyway the demand persists.
      This project proposes the addition of a minimal API that would allow each driver to offer prepared statements according to its DBMS restrictions and mechanisms.
      Expected results
      Propose a new API that would be flexibly enough to cover the main features of each database respecting each different mechanisms of defining prepared statements
      Implement the new API into one or more drivers
      Test and document everything
      Prerequisites
      C programming languages
      Experience with any database C API (highly desirable)
      Experience with Lua-C API (highly desirable)
      Experience with Lua (good to have)
      Skill level
      Challenging
      Project size
      Large (350 hours)
      Mentors
      Tomás Guisasola
      Matrix room
      #lunarmodules
      Lunatik Binding for Linux Traffic Control (TC) and eBPF Maps
      This project aims to create Lunatik bindings for the Linux Traffic Control (TC) subsystem and eBPF maps to enable efficient and programmable network traffic control. These bindings will allow Lua scripts to manipulate TC and interact with eBPF maps, providing a flexible interface for traffic shaping, filtering, and monitoring.
      This work is heavily inspired by the luaxdp binding, which integrates Lua with XDP (eXpress Data Path) using eBPF. Given that TC and XDP both utilize eBPF, this new binding (luatc) will reuse and adapt parts of the luaxdp codebase, ensuring consistency and maintainability.
      Linux Traffic Control (TC) is a subsystem of the Linux kernel that allows administrators to manage network packet transmission, enabling features like traffic shaping, queuing, scheduling, and policing. It is widely used for bandwidth control, Quality of Service (QoS), and network performance optimization.
      Configuring TC using traditional tools can be complex and static, making it difficult to implement custom traffic processing logic. Lunatik, a Lua-based kernel scripting interface, can simplify this process by allowing users to write Lua scripts that dynamically interact with TC queuing disciplines (qdiscs), classes, and filters.
      Additionally, this project will introduce support for eBPF maps within Lunatik. eBPF maps are a key component of eBPF, providing efficient storage and retrieval of structured data between user space and kernel space. This functionality will not be restricted to the TC binding (luatc), but will be implemented as a general feature in Lunatik, enabling other kernel extensions to leverage eBPF maps.
      Expected results
      A fully functional Lunatik binding for the TC subsystem, allowing Lua scripts to configure and manipulate network traffic.
      Support for eBPF maps in Lunatik, enabling efficient data sharing between Lua scripts and eBPF programs.
      Integration with the existing luaxdp codebase, reusing and adapting components where possible.
      Clear documentation and examples, demonstrating how to use luatc for network traffic control and eBPF maps for data storage.
      Prerequisites
      Lua and C programming languages
      Linux Networking
      Experience with Linux Kernel (highly desirable)
      Experience with Traffic Control (TC) subsystem (good to have)
      Experience with eBPF maps (good to have)
      Skill level
      Challenging
      Project size
      Large (350 hours)
      Mentors
      Lourival Vieira Neto
      Savio Sena
      Matrix room
      #lunatik
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/lablua/
    idea_list_url: https://github.com/labluapucrio/gsoc

  - organization_id: 83
    organization_name: Learning Equality
    no_of_ideas:
    ideas_content: |
      Published using Google Docs
      Report abuseLearn more
      Learning Equality: Google Summer of Code 2025 Ideas List
      Updated automatically every 5 minutes
      
      Learning Equality: Google Summer of Code 2025 Ideas List
      
      
      
      
      
      
      Learning Equality is an education technology nonprofit that develops and maintains Kolibri, an adaptable set of open solutions specially designed to support teaching and learning with technology but without the Internet for the half of the world that still lacks access to connectivity.
      
      Kolibri is centered around an offline-first learning platform that runs on a variety of low-cost and legacy devices. It is complemented by a curricular tool, a library of open educational materials, and a toolkit of resources to support training and implementation. These tools are open and available in a variety of languages, to better support learners and educators globally.
      
      As a community-driven nonprofit, Learning Equality works closely to co-design Kolibri with a core network of collaborators, including national NGOs, UN agencies, government, and corporate partners. We also adopt a needs-based approach, constantly gathering insights from our community to inform the development of our tools.
      
      Through its do-it-yourself adoption model and strategic collaborations, Kolibri has reached learners and educators in more than 220 countries and territories since its launch in 2017.
      
      If you are interested in knowing more about our GSoC project ideas, Kolibri or Learning Equality, send us an email to gsoc@learningequality.org, and we will invite you to join our #﻿gsoc-2025 Slack channel! We hope to see you soon!
      
      
      Project Ideas for GSoC 2025
      
      Create Robust Windows App
      
      Implement a prototype of a Rich Text Editor
      
      Create a new user onboarding experience for Kolibri
      
      HTML5 Article Renderer
      
      Implement a feature to publicly share curriculum-aligned content
      
      
      Create Robust Windows App
      Background
      The current deployment of Kolibri involves platform-specific applications for Windows, macOS, and Linux (Gnome), each requiring a separate Python environment setup on the host system. This approach presents significant challenges in terms of maintainability, user experience, and cross-platform compatibility.
      
      Needs
      Change our installer to use https://pyinstaller.org/ so we can use the same app we have in MacOs  and make it independent of the status of Python in the system where Kolibri is installed.
      Adapt current Kolibri app, https://github.com/learningequality/kolibri-app to be fully compatible with Windows, integrating native features such as taskbar icon functionality and system-specific menus.
      Outcome
      The primary goal of this project is to streamline the deployment and operation of Kolibri by developing a unified application framework that is independent of the host system's Python environment.
      
      Mentors
      Richard Tibbles and Prathamesh Desai
      
      Skills
      WxPython
      Windows taskbar API
      Windows installation, configuration and services
      Duration
      175 hours in 12 weeks
      
      Difficulty level
      Medium
      
      
      Implement a prototype of a Rich Text Editor
      Background
      Kolibri Studio currently uses a very old version of Toast UI’s text editor. It is desirable to have an up to date Rich Text editor for use in both the Kolibri Learning Platform and Kolibri Studio, to generate Rich Text content in a way that can be scoped for the specific use case, and also extended to allow insertion of specific toolbar elements under specific circumstances.
      
      Needs
      Create a prototype Vue.js based text editor component using a well maintained and robust text editing library
      Have feature parity for the existing text editor in Kolibri Studio
      Add underline and list formatting options to the text editor
      Outcome
      A prototype Rich Text Editor, implemented within Kolibri Studio, that allows inlining of a range of rich text elements. Taking an HTML document as a reactive input/output for the Vue component.
      
      Mentors
      Marcella Maki and Jacob Pierce
      
      Skills
      Javascript
      Vue.js
      HTML/CSS
      Duration
      175 hours in 12 weeks
      
      Difficulty level
      Medium
      
      
      Create a new user onboarding experience for Kolibri
      Background
      Although Kolibri has user documentation, within Kolibri there is not yet an in-app onboarding experience. This project would be to create that onboarding experience that introduces users to Kolibri's user interface Key features within the Learn plugin will be highlighted through informative pop-up elements containing tips after the user has completed the device setup process. It's designed to enhance user understanding and engagement with Kolibri UI.
      
      With inclusivity at the heart of Learning Equality’s mission, building accessible products is an essential part of our day-to-day work. Approaching this frontend work with accessibility at the center will be critical for success.
      
      Needs
      Research and evaluate the pros and cons of existing  libraries like popper.js or tippy.js  and how those can be used as reference for a custom approach that we could maintain ourselves
      Create an accessible, flexible popover component that can be associated with a variety of interactive elements on the page, such as links, buttons, or menu items
      Integrate the component into an onboarding workflow for new users
      Outcome
      Implement a guided introduction to Kolibri for new users that helps orient users to features and navigation, and understand the product's value through experience.
      
      Mentors
      Liana Harris and Marcella Maki
      
      Skills
      HTML, Javascript, Vue.js
      Inclusive design principles, familiarity with WCAG specification
      Duration
      175 hours in 12 weeks
      
      Difficulty level
      Medium
      
      HTML5 Article Renderer
      Background
      Currently Kolibri allows for sandboxed HTML5 applications that are able to implement arbitrary styling, Javascript, HTML etc, all presented inside a sandboxed iframe. However, this puts a large burden on the content creator to have knowledge of HTML and CSS if all they want is to produce rich text content. In order to allow this, we wish to be able to render HTML5 documents outside of an iframe, and with carefully crafted styling to create a responsive article experience.
      
      This will be building on previous technical work that handles taking an HTML5 document and applying sanitization to it to remove disallowed HTML tags.
      
      Needs
      To create consistent styling to this Figma spec
      Ensure responsive behaviours
      Ensure accessibility conformance as close as possible to WCAG 2.1 level AA.
      Outcome
      A Kolibri content renderer that can take an ‘article’ format that consists either of an HTML5 document with all assets inlined, or an HTML5 article zip file, and render to spec. Stretch goals would include integration of existing renderers to handle audio, video, and other multimedia content for better rendering experiences than simple HTML5 elements.
      
      Mentors
      Samson Akol, Allan Otodi Opeto, and Radina Matic
      
      Skills
      Javascript
      Vue.js
      HTML/CSS
      Mobile responsiveness testing
      Accessibility testing
      Duration
      175 hours in 12 weeks
      
      Difficulty level
      Medium
      
      Easy sharing of community channels
      Background
      In many places, Kolibri is used to support the teaching of  local, regional, or national curricula. Aligning of open educational resources (OERs) to curricular standards can be done through Kolibri Studio, but is time consuming and requires expertise. Many organizations using Kolibri in their projects have already done the work to create sets of aligned channels.
      
      While it is currently possible to share channels and collections of channels within the Kolibri ecosystem, it is not user friendly. This project would update and add to that experience to improve the ease of sharing community curated libraries of resources for use within their projects and also for easier sharing with others.
      
      Needs
      Implement a new “Community Library” feature (name is provisional) within Kolibri Studio, using the existing “Collections” backend functionality.
      Allow a way to make these “Community Libraries” publicly discoverable on Kolibri Studio so that users can choose to make their Community Libraries publicly discoverable for use by others.
      Implement a license audit feature, so that prior to making a community library publicly discoverable, the owner can assert and correct licensing to ensure that it is accurate and appropriate to be publicly shared.
      Implement the new add community library workflow in Kolibri, which will permanently record the token for the library so any time new resources are imported from Studio, the community libraries that have been added are displayed.
      Outcome
      An updated feature implemented within both Kolibri Studio and Kolibri that allows users to more easily share collections with aligned channels.
      
      Mentors
      Alex Velez and Richard Tibbles
      
      Skills
      Javascript
      Vue.js
      HTML/CSS
      Python
      Fullstack development
      Duration
      175 hours in 12 weeks
      
      Difficulty level
      Medium
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/learning-equality/
    idea_list_url: https://docs.google.com/document/d/e/2PACX-1vT49WKgbsAIUoJ0jJS8LTWWm7UTByM0Pw3qt0KgyU_BShB1oGtZBkrEWuannFsRMVvGd0QBytZt8blh/pub

  - organization_id: 84
    organization_name: LibreOffice
    no_of_ideas:
    ideas_content: |
      Add languages
      GSoC Ideas
      Page
      Discussion
      Read
      View source
      View history
      < Development | GSoC
      TDF LibreOffice Document Liberation Project Community Blogs Weblate Nextcloud Redmine Ask LibreOffice Donate
      Wiki Home Development Design QA Events Documentation Website Localization Accessibility Marketing Diversity Wiki Help
      Overview Reporting Bugs How to build Code Overview Git Commands Debugging EasyHacks Release Plan FAQ Developers Extensions → Open Issues
      
      This page lists the project ideas for Google Summer of Code, see the general info about LibreOffice and GSoC. All applicants are required to complete at least one easy hack.
      All tasks on this page already indicate mentors for the task. New tasks on this page should be added only by those with the experience and time to invest in mentoring new developers.
      Note that the LibreOffice project selects GSOC projects that are well researched and show a good understanding of the scope of the problem. It is also possible to create a project proposal not based on the ideas given below, if the application of the contributor shows good understanding of the problem. In fact, if you apply with one of the prepared ideas below, we expect you to show you did research beyond the abstracts given below even more.
      When doing that please use this template:
      === Title of the task ===
      
      Some detailed description of the things to accomplish.
      Don't hesitate to provide details if you have some like code pointers, links to specifications, etc.
      
      Goal(s) - the expected outcome of the project.
      
      ;Required skills / knowledge: C++, Reading other's code, and any other useful skill required go here.
      
      ;Size: 90, 175 or 350 hours
      
      ;Difficulty: Range among easy, medium, hard
      
      ;Potential mentors
      :''Joe Devel'', IRC: jdevel, mail: {{nospam|joe|devel.org}}
      Please move successfully completed projects to Development/GSoC/Successfully Implemented Ideas.
      User Experience
      The design team collected a number of ideas in in the pad http://pad.documentfoundation.org/p/UX-GSoC_Ideas. Not for all ideas mentors have committed so far. If you are interested in a task that has no mentor you would need to find someone. If the topic needs further refinement feel free to contact the UX team in order to prioritize the usability engineering. Some examples for full-featured topics:
      Variable units on numerical input
      LibreOffice allows to change the unit from cm to inch or point, etc. but only globally. Some workflows make it necessary to deal with different units at the same time. For instance the page size in inch, positioning of objects in centimeter, and size in points. The proposal is to allow switching the unit on the control.
      Mockup: https://bug-attachments.documentfoundation.org/attachment.cgi?id=130628
      Enhancement request on Bugzilla (and the various See Also tickets)
      Goals:
      derive a new control from spin edit that allows switching the unit
      ideally but optionally remember the unit per control
      consider solutions to change the precision per adding decimal places
      replace the existing numerical spin edit controls
      Required skills / knowledge
      (C++, Reading other's code)?
      Size
      350 hours
      Difficulty
      (Medium)?
      Potential mentors
      Andreas Heinisch, mail: andreas.heinischyahoo.de
      Heiko Tietze, IRC: htietze, Mail: heiko.tietzedocumentfoundation.org
      Remember window size per document
      LibreOffice remembers the window size per module and it's possible to have, for example, a Writer document in landscape next to a portrait sized Calc sheet. However, closing the modules brings you back to the start center which overwrites the module size. And the size/position is not stored per document, which is a major problem for many users.
      Ticket on Bugzilla.
      Goal:
      Restore the window size per module from the document
      Required skills / knowledge
      (C++, Reading other's code)?
      Size
      175 hours
      Difficulty
      (Medium)?
      Potential mentors
      Andreas Heinisch, mail: andreas.heinischyahoo.de
      Heiko Tietze, IRC: htietze, Mail: heiko.tietzedocumentfoundation.org
      Improve snapping and object selection
      Snapping in LibreOffice is a bit awkward, and doesn't work as expected in some cases. There is also no advanced snapping supported (taking into account multiple object positions and distances), which would make object position and sizing much easier for the user. This idea involves investigating the existing implementation for snapping in the svx module and work on it.
      Goal:
      Make snapping and object selection pleasant to use.
      Extended goal for this idea is to look into object selection and handles rendering, consistency and UX. In some cases the selection and selection handles aren't properly rotated with the object, sometimes an outline of the selection isn't rendered or rendering could be improved.
      Required skills / knowledge
      (C++, Reading other's code)?
      Size
      350 hours
      Difficulty
      Hard
      Potential mentors
      Tomaž Vajngerl, IRC: quikee, mail: quikeegmail.com
      
      Re-design Notebookbar using Native Toolkit Widgets
      The task here is to redesign the Notebookbar to use vcl weld mechanism instead of custom widgets. The issue is filed as tdf#163988 in Bugzilla.
      Currently, although Notebookbar uses Glade UI files, it uses custom widgets, and most of the logic is done in C++ code.
      Although the result looks nice with GTK3 and some other UI plugins, it has some drawbacks as described in tdf#163988. Specially in GTK4, the result is not interesting. Also, changing the Notebookbar in the Glade interface designer is not easy/possible with this approach.
      The task here is to re-design the Notebookbar, using native toolkit widgets and make sure that is usable with VCL weld mechanism. Doing modifications in the C++ code to make it usable in LibreOffice UI is not part of this task, so that people who only know how to design, but are not familiar with C++ can also do the task. To make the result usable with LibreOffice, additional coding/refactoring is needed which does not fit into this project.
      One can start by creating a dialog box with GtkNotebook, and then add appropriate icons and other GTK widgets to reach to a reasonable UI, comparable to what is available with the custom widgets.
      Please note that not each and every GTK widget is supported by VCL weld, so you have to go step by step to make sure that the result works well with VCL weld mechanism.
      A preview can be generated by both glade-previewer -f notebook.ui and also by using the ui file with minweld example. One may test the result, after putting the UI file in instdir/share/config/soffice.cfg/ and changing the minweld example to reflect the name of the UI and the ID of the dialog.
      ./bin/run minweld
      Goal:
      Re-design Notebookbar using native widgets.
      Required skills / knowledge
      UI Design, Glade UI designer, Reading other's code
      Size
      175 hours
      Difficulty
      Medium
      Potential mentors
      Hossein Nourikhah, IRC: hossein, mail: hosseinlibreoffice.org
      New dialog to edit Table Styles
      LibreOffice Writer and Calc have a set of built-in table styles. For instance, in Writer, when the user inserts a new table, they can go to Table - AutoFormat Styles to select which style to apply to the table.
      To create a new style, the user can first insert a table to the document, format it manually and then go to Table ▸ AutoFormat Styles and click Add. This will extract the table formatting properties and create the new style.
      However, LibreOffice does not offer a dialog to Edit existing table styles.
      The objective of this project is to create a new dialog to edit all the properties of existing table styles.
      The UX team has already devised a proposal for the new Edit Table Styles dialog.
      As a stretch goal, it would be nice to have this dialog be used in Impress as well. See the Table Design entry in Impress's Properties sidebar when a table is selected.
      Required skills / knowledge
      UI Design, C++, Reading other's code, Debugging
      Size
      350 hours
      Difficulty
      Medium
      Potential mentors
      Rafael Lima, mail: rafael.palma.limagmail.com
      Base
      Implement report builder in C++
      Designing and generating reports in LibreOffice is an important feature of LibreOffice BASE. The current report builder implementation uses Java and Pentaho Reporting Flow Engine of Pentaho BI for creating the output, which is an ODT file. Dependence on Java and Pentaho creates issues for packaging LibreOffice in different distributions, and also makes development harder.
      The file format used for storing the reports is in itself and XML file, and the resulting ODT file is also an XML document conforming to ODF standard. In order to implement report builder in C++, one should look into the import/export filters in LibreOffice, like the FODF which use XSLT. The resulting code should be able to do the export to ODT without the help of Pentaho library and/or Java.
      LibreOffice uses libxslt as an external library that provides the required tool to XSL tranfromations in C++ code. One can find some of the existing XSL transformation files used in import/export filters with:
      $ git ls-files "filter/*.xsl"
      Defining appropriate XSL transformation file alongside writing C++ code is needed to implement the reportgenerator.
      The other parts of the reporting workflow are already in C++. The reportdesign is in C++, and also other parts of the LibreOffice BASE that the report designer relies on are written in C++. This project can also improve report generating performance of LibreOffice.
      Help page for the current implementation.
      Base guide chapter for the current implementation.
      Goal
      Implementing report builder in C++, and removing the Java / Pentaho dependency
      Required skills / knowledge
      C++, XML, XSLT, Reading other's code
      Size
      350 hours
      Difficulty
      Hard
      Potential mentors
      Hossein Nourikhah, IRC: hossein, mail: hosseinlibreoffice.org
      Basic
      Draw
      Impress
      Attach animations to styles
      Currently, Impress styles control most of the visual shape appearance, but not the slideshow animation effect. Which is a pity, as the styles concept is pretty powerful inside LibreOffice, and provides a nice way to change animation settings and type for a great number of objects simultaneously. For a slightly different view onto the same problem, see this bug report, and this one from the LibreOffice side.
      Original patch from GSoC 2010: https://cgit.freedesktop.org/libreoffice/build/tree/patches/dev300/sd_effects_styles.diff?h=master-backup
      Goal:
      Make styles animatable.
      Required skills / knowledge
      C++, Reading other's code
      Size
      350 hours
      Difficulty
      Hard
      Potential mentors
      Thorsten Behrens, IRC: thorsten, mail: thorsten.behrensallotropia.de
      Katarina Behrens, IRC: bubli, mail: bublibubli.org
      Rework Impress slideshow to use DrawingLayer primitives
      The Impress slideshow, while being designed to only interact with Impress via interfaces, had to resort to an ugly hack to be able to render all Impress content. That was ok back in the day, but is becoming a liability these days. Nowadays, what one want to use is the DrawingLayer Primitives (https://wiki.openoffice.org/wiki/DrawingPrimitives), which means porting over slideshow/source/engine/shapes/* to use this kind of abstraction, instead of the StarView Metafile previously in use.
      Goal:
      Get rid of ugly hack for rendering Impress content in slideshows by porting code to use DrawingLayer primitives.
      Required skills / knowledge
      C++, Reading other's code.
      Size
      350 hours
      Difficulty
      Hard
      Potential mentors
      Thorsten Behrens, IRC: thorsten, mail: thorsten.behrensallotropia.de
      Calc
      Common
      Accessibility checker for Impress and Calc
      We have an accessibility checker sidebar in Writer, but not in Impress and Calc. The accessibility checker triggers a check of the document for accessibility issues and displays those in the sidebar, with helpful hints how to resolve those issues. Accessibility issues include checks of the document metadata (name, description), document structure, objects in the document, as well as check of contrast (font color vs. background color). A lot of issues apply for Impress and Calc too, but some are Writer specific and there as some that are unique to Impress and Calc.
      Goal:
      Add accessibility sidebar to impress (move code from writer to common code into svx or sfx2), implement a trigger to re-run a check when an object changes, go through the accessibility checks for writer and investigate which check also applies to Impress, add the accessibility check to common code and adapt if necessary (for example to work in editeng and not writer model). If there is still time, repeat the same for Calc.
      Required skills / knowledge
      C++, Reading other's code, Debugging,
      Size
      350 hours
      Difficulty
      Medium to Hard
      Potential mentors
      Tomaž Vajngerl, IRC: quikee, mail: quikeegmail.com
      Extend support for document theme colors
      Support for theme colors is already implemented for Writer, Impress/Draw and Calc, however some colors weren't extended to support theme colors properly. Also when we define gradients we don't support theme colors there so support for theme color gradients would need to be added.
      Goal:
      Search for properties or parts of properties where we use colors, but we don't support to set a ComplexColor (used for theme colors). Implement a property that works with a ComplexColor for that property, add support to change the color in ThemeColorChanger, write a round-trip test and adapt the import/export filters (for ODF and OOXML) to support saving the theme color for the property. Repeat.
      Required skills / knowledge
      C++, Reading other's code, Debugging
      Size
      350 hours
      Difficulty
      Hard
      Potential mentors
      Tomaž Vajngerl, IRC: quikee, mail: quikeegmail.com
      Filters
      Import Markdown files into LibreOffice Writer
      This project is meant to deliver a first working version of Markdown import into LibreOffice Writer, optionally using a document template (OTT) to provide decorative content, and custom styles. Participants are encouraged to research available import libraries, as well as means to get content inserted programmatically into a Writer document (e.g. via UNO, or via DLP's librevenge).
      Related report: tdf#162153.
      Goal:
      Make it possible to import Markdown files compliant to the CommonMark specification into Writer.
      As a stretch goal, adding experimental support for Paste-special-as-Markdown can be implemented for Writer.
      Required skills / knowledge
      C++, working with libraries
      Size
      350 hours
      Difficulty
      Medium
      Potential mentors
      Thorsten Behrens, IRC: thorsten, mail: thorsten.behrensallotropia.de
      UNO
      UNO is the LibreOffice component model, cross-language and intra- as well as inter-process. It is somewhat similar to Corba and COM. It is used to extend LibreOffice via document-related scripts and more general extension packages, as well as to use LibreOffice functionality remotely from another process.
      UNO's cross-language abilities are implemented by bridging between various language-specific environments and a binary runtime representation (with a C API). Next to C++, Java, and Python, it would be great to have such a bridge also for a great language like Rust and a lightweight scripting language like LUA and latest version of .NET, which is cross-platform.
      Rust UNO Language Binding
      One aspect is to use Rust FFI to interface with the binary UNO C API. Another is to design the Rust representations of the various UNO constructs (its data types; objects with their multiple interfaces and methods; services and singletons), so that this language binding can not only be used to interact with existing LibreOffice services written in other languages, but also to create new services in Rust. A third aspect could be to create a pure Rust implementation of the UNO remote bridge protocol.
      Some documentation pointers are:
      UNO Type System
      UNO Object Life Cycle Model
      Uno Remote Protocol
      Some code pointers are:
      bridges/source/jni_uno as an example of an in-process UNO bridge (for Java, via JNI)
      binaryurp as an example of a remote UNO bridge (in C++)
      Goal:
      Make it possible to use LibreOffice's UNO API with Rust.
      Required skills/knowledge
      Rust, interfacing to low-level C/C++, working against formal specifications
      Size
      350 hours
      Difficulty
      Medium to hard
      Potential mentors
      Stephan Bergmann, IRC: sberg, mail: stephan.bergmannallotropia.de
      Michael Stahl, IRC: mst___, mail: mstlibreoffice.org
      Bjoern Michaelsen, IRC: Sweetshark, mail: bjoern.michaelsenlibreoffice.org
      Python code auto-completion
      While it has been years since LibreOffice (and before that, OpenOffice) support Python binding, there were difficulties for the Python script developers to use it efficiently. One of the obstacles is the lack of Python auto-completion. The reason why this was not possible was that the Python objects are created at runtime, and therefore an IDE can not know about the structure of the classes when a developer writes the code.
      The solution for that is to generate Python stubs from IDL specifications. This is done in many other languages in the module codemaker. The task here is to create a similar tool for Python, which can be named pythonmaker.
      To get an idea of the needed code, you may look into codemaker/source/, and there you will see:
      cppumaker: stub generator for C++
      javamaker: stub generator for Java
      netmaker: stub generator for Python
      Goal:
      Make it possible to do Python code auto-completion by generating Python stubs from IDL specifications.
      Required skills/knowledge
      C++, Python, reading other people's code
      Size
      350 hours
      Difficulty
      Medium to hard
      Potential mentors
      Hossein Nourikhah, IRC: hossein, mail: hosseinlibreoffice.org
      Ideas without a mentor
      A number of ideas from previous years can be found at the Development/GSoC/Ideas without a mentor page. Please note that you need to find a mentor willing to mentor the task. There is no guarantee that anyone in the community is going to mentor one of these tasks this year.
      Category: GSoC
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/libreoffice/
    idea_list_url: https://wiki.documentfoundation.org/Development/GSoC/Ideas

  - organization_id: 85
    organization_name: Liquid Galaxy project
    no_of_ideas:
    ideas_content: |
      Google Summer of Code 2025
      21st edition
      
      
      
      We are happy to announce that the Liquid Galaxy project has been accepted for GSoC 2025.
      
      Searching for our project ideas? look no further and click:
      
      
      
      MENU
       Basic Items
      
       Project Ideas
      
       Master proposal document
        GSoC 2025 pre-requirements
        Official Announcement and Calendar
        Community Streamings
       
       Mentor Team
       
       News
       
      ALL ABOUT THE PROPOSAL (from latest general Meet)
      
      
      
      
      
      
      
      
      
      Looking for some guidance to start writing your proposal ???
      Follow rules in the Master proposal document  and watch senior mentor Yash Raj talking about it:
      
      
      
      
      You can rewatch here our latest MEET with GSoC wanna-be contributors, where we answered your questions and made some announcements:
      
      
      
      
      
      
      
      
      - Goal: to create small open-sourced applications in Flutter or our web tech stack for the Liquid Galaxy. The applications must run in smartphones, vertical, 6.3”, if developed in Flutter API level of last year.
      
      - The working application should demo a simple AI use case accessing an open-source model, preferably Google’s Gemma 2, in an external API. Cost of the API will be up on the user of the tool, as they have to put their own key in a setting of the app.
      
      - The LLM results must be shown on the Liquid Galaxy screens, sending the coordinates, text or whatever is the return of your query. Also you can use voice synthesis to speak out aloud.
      
      - Participants: The contest is open to all Liquid Galaxy contributors and anyone interested
      
      - Dates: The last day to send us all the materials is April 20, 2025, no excuses there.
      
      - App: You have to send us a Google Drive folder with the following contents:
      
      . Documentation in Google Docs
      
      . A link to your GitHub project.
      
      . Video: recorded in HD, horizontally, with you introducing yourself, presenting the app functionalities, showing the app, and showing the virtual liquid galaxy accepting commands from your app. It should be a minimum of 10 minutes, and a maximum of 20.
      
      . If Apk compiled targeting minimum Android 14 (API 34).
      
      - Jury: will have Google Developer Experts in Flutter and Liquid Galaxy project mentors.
      
      - Awards:
      
      1st: 100 $ in cash (through Paypal), Xtorm mobile accessory (50$)
      
      2nd: Xtorm mobile accessory (50$)
      
      1 and 2: Big swag pack, with shirts and stickers of Flutter, Flutter Lleida, Liquid Galaxy and more.
      
      Everybody that sent an app that works and follows rules will receive a certificate of participation.
      
      
      And, of course, awareness for final selection on GSoC !!! That will be days away.
      
      
      - Mentions: All participants releasing a functional application will receive a certificate of participation, will be mentioned on our site and social networks, and have another opportunity to present their project in a special Liquid Galaxy streaming that will be held on April 26, 2025, 16:00 CET.
      
      - Promotional events: the projects will be shown at several Google Developers events across Spain and maybe Europe. Google will also be informed.
      
      - Disclaimer: We reserve the right to modify, improve, or make final decisions on the winner selection.
      
      Remember, this contest is to motivate you to code, learn, help others, and be near the selection to the GSoC 2025.
      We train you: tons and tons of new training are available in Youtube for the community by the community
      
      
      
      
      
      February 27
      The Liquid Galaxy project has been selected for the Google Summer of Code program 2025.
      
      Next steps:
      - Read carefully the GSoC agenda
      - Work or continue working with our pre-requirements.
      - Read our Project Ideas List , with all the projects we propose for this GSoC.
      - Start to write the Master Proposal document with included instructions.
      - Reach us by email liquidgalaxylab@gmail.com for any question.
      
      Be ready for our next Liquid Galaxy streamings A.M.A., to be held on March 6, 16:30 CET. RSVP at Google Developers Event platform to get your seat, and send us a screenshot of your reservation to be added to a private MEET. Here, the senior mentor team will explain the next steps and will answer your questions.
      
      BASIC ITEMS 
      - Always review all those things for a good start with us:
      . Watch our 1st Liquid Galaxy project Community video streaming for very important news, including many new changes in our tech stack.
      . Explore our web site and join our GitHub
      . Join our Discord for announcements,
      . Join GDG Lleida for events announcements at Google Developers platform, and be familiar with our technology and way of doing things.
      . Join Flutter Lleida for events announcements of Dart/Flutter related topics at Flutter Lleida Meetup
      Nov 23, 2024
      Here's the news most of you were waiting for, the new changes in community activities and
      GSoC 2025 pre-requirements
      All wanna be selected contributors will have to deliver pre-required tasks if they want to be considered, as we have to be sure you're familiar with your tech stack and about your coding capabilities, very next to your soft skill abilities.
      Please read these instructions carefully, watch the 1st community meeting for season 2024-2025 and if you have any questions contact us the only way to communicate with us, our lovely Gmail account;
      liquidgalaxylab@gmail.com
      Note: you can create the tasks in the order you want, but for us to approve every task we need them in order. Send every task as noted, and wait for approval to send the next one. We'll not consider contributors not following the rules.
      For every task, we need a video and the GitHub code link, if any, as proof, so first create in your own Google Drive a folder with read permissions for everyone, with your name and GSoC 2025, and create subfolders for every task. Do not delete this till Sept 2025. Send us your first task sending the drive main GSoC folder with read permissions to anyone. (edited for clarity)
      The videos for this use have to be a 3-minute max video, recorded horizontally in full HD, showing up your face talking and the screen recorded from the camera, not screen captured.
      
      Please always name all files with task name, your name and GSOC year (2025).
      Drop too a line in our Discord saying the video is ready, and possibly it will be published here.
      
      
      DATELINES clarification (as Jan 31)
      Contributors have to try to give us the task on time, due that we need time to evaluate your abilities, both technical and soft skills.
      Contributors that arrive late to the party, nothing bad there, just simply have to hurry up.
      All pre-required tasks are needed for our evaluation of contributors and have to be presented maximum April 17, but as you can imagine dates will be so tight that we can not guarantee your work to be reviewed.
      
      
       - Task 1:             Install a virtual LG        Due January 10
      Build your own Liquid Galaxy with 3 virtual machines, be careful with the RAM requirements to run such a system. The rig has to be 3 machines, and the control has to be a smartphone ran on the emulator (edited for clarity), following our tech stack changes.
      To test your rig only use the nice SatNOGS Visualization tool, developed by student Michel Algarra, that works great on a smartphone 6.x inches vertically. You must use a pixel phone emulator such as 6a, 7a or any available models. Please don't resize the screen to mimic smartphones as that isn't right. Remember the video cannot be longer than 3 minutes.  (edited for clarity)
      
      Documentation is available on the GSoC 2024 updated LG installation manuals
      Older versions as this English and Spanish, the nice tutorial on setup a LG virtual by contributor Soham Jaiswal https://www.youtube.com/watch?v=CLdUuDHo6lU, and the one from Yash Raj, actual senior mentor of the project, at https://youtu.be/wzv-CiN6VeA?si=swVIiwIU3R3RR4sA  are also OK.
      
      To see how we want the video take a look too at the many GSoC 2024 contributors' task 1 videos,
      https://youtu.be/gdYbBEdzGLc?si=lJcVKP9sd9eSnPxM
      https://youtu.be/Ns3sKSfDWE4?si=F-vwoJ1FPY1Ej3VN
      https://youtu.be/SeZ-Jy64SEU?si=FLr1iNKYatZO9OKv
      https://youtu.be/6FDVE9MULlI?si=ABD4BPEfJ1vJ6aer
      https://youtu.be/si3tT1g3ty0?si=EHr0OSG7WnoOHUuq
      
      to the 2023 with 50 !!! installations
      https://www.youtube.com/watch?v=Q_p6Z-yk2Wo
      
      
      
      
      - T2:     Create a basic Flutter app  or web app*        Due January 20
      
      You have to create a basic LG app, where the user can select on a simple window:
      - To put the lg logo on the LG (left screen of a 3 screens rig)
      - To send 2 different kmls, selectable one by one.
      - An option to clean the logos
      - And option to clean the kmls
      
      * As as Nov 23, 2024, the new web tech stack is not fully defined, our counsel if you're starting early is go Dart/Flutter.
      
      Send proof of task following rules, including a video explaining your code (5 mins max) (edited for clarity) , and the kml that you have created. If the kml is not created by you, please mention the source where you took it from.
      Also do make a released build of your apk when showcasing the functionality of the app.
      Send us the videos, the kml files and the released build apk.
      
      
      - T3: Creating and delivering technical presentations
      
      For our Liquid Galaxy streaming series, and to train the community and show up both your technical and soft skills, we require you to record a minimum of three 20’’ minimum, and a max of 45, - edited for clarity- technical presentations.
      Those can be about any of our tech stack topics, technologies we use, or related questions.
      Before recording, send an email to liquidgalaxylab@gmail.com with your 3 proposals for presentations, next to a schedule when you plan to have those ready, as we're starting to populate the events platform.
      Also when ready, share a Google Slides deck with your presentation OPEN FOR COMMENTS  - edited for clarity- before recording, just to take a look.
      All the files you send us, have to have the same naming structure: and for presentations add in the front the exact name of presentation  :   
      presentationname-task name-yourname-GSOC2025   , - edited for clarity-
      
      Make a copy, rename, and use this template for your slides https://docs.google.com/presentation/d/1jE5hgubsCGg3TnaBUngxh8gh84nijDClnwXXth8tN-w/edit?usp=sharing
      Remember that the creator contributor must attend live questions on the day we stream the video, q&a will be handled on our Discord, in channel #community-chat, as the videos will be pre recorded and the chat will close after the stream. ---edited for Discord chat---
      For the other contributors, remember that attending presentations and interacting will help your LG Score, giving you more opportunities to be selected for GSoC 2025.
      
                                                 --Added template and edited for clarity as 7.1.25--
      
      Due date is since today, 23.11.2024, and is due before GSoC contributors announcement.
      
      As samples, and to get train you can watch the great presentations contributors did in the past, such as:
      
      
      
      
      Integrating Google Maps in Flutter for Liquid Galaxy apps, by Saumya Bhattacharya
      https://www.youtube.com/live/d1ScO1SrIV0?si=V1ljMb7ReHUgpVoy
      
      Solving frequently asked doubts by Liquid Galaxy Contributors, by Shaunak Nagrecha
      https://www.youtube.com/live/Rkt1TtyrD54?si=drN96E7UdqHw-Ktg
      
      and tons more you can find in out Youtube channel and old GSoC posts, 2024 , 2023 
      
      Send proof of task following guidelines.
      
      
      - T4: Creating at least 3 entries for our Liquid Galaxy WIKI 
      
      Created in 2024 by contributor Dev Gadani with the help of Sidharth and mentor Vedant, our WIKI
      is a searchable repository of LG knowledge.
      
      As proof of your knowledge of our tech stach we require every to be considered contributor create 
      3 new entries for the wiki, all related to the new tech stack situations.
      All good entries will be published and credited in our lg.eu Wiki.
      
      You should send us a previous email with what 3 contents you want to create for the wiki, as many other contributors may have chosen the same.
      
      Each entry has to have the clearest definition of what the entry is, and what part of the Liquid Galaxy handles, it can be UX side (functions on the apps in Flutter or JAVA) or the rig side (all the things related to the Liquid Galaxy cluster and his network, including the AI server and the Dockers we use).
      
      Please write with clarity for others to understand, and quote code in the right way.
      
      Add graphics if needed, and remember to store the images in the same folder independently.
      
      All the entries have to be on the same Google Doc, we’ll not accept pdfs or .docx, and please name the doc with your name and GSoC2024. 
      
      Each entry has to be a minimum of half a page, as you have to explain the aforementioned parts and the code or instructions involved.
      
      You’ll be credited if the entry is published, and also you can be invited to write other ones if the ones you choose have been already written many times.
      
      Send proof of task following guidelines.
      
      You can take a look at the WIKI presentation video with instructions and technical explanations.
      
      Due date before GSoC contributors announcement. 
      (edited for clarity) 
      
      
      - T5:  UI creation challenges   ---added 31.12.2024--
      
      For task 5 you will have to showcase your knowledge of UI and UX by creating some of the best designs in code. Each of them has to be a separate file or page coded in HTML, CSS, js (any frameworks), and using GSAP (optional), or dart (flutter). 
      The choice to code it on the web tech stack or as an app is yours.
      Some of the challenges have it written specifically that it must be done in KML.
      Your judgement will be on whether you can create such pixel perfect micro interactions, animations and interfaces, as for 2025 we want the best looking UI.
      
      Submission link will always be a Github repo, containing all the code, the web pages can be deployed while the app pages can be built and you can send us the apk.
      The kml files can be kept in the assets folder.
      
      Don't use AI such as chatGPT and show us your original work.
      
      Check the docs link for more details: https://docs.google.com/document/d/1LaIoYUdlyr5Cywrytnuuw4DXt2mvH2MvDcbyUIpljcg/edit?usp=sharing
      
      Care about semantics, UX, accessibility, cross-browser compatibility and performance is much needed.
      
      
      Due date is since today, 31.12.2024, and due January 25, 2025
      
      
      Official announcement and official calendar
      
      On Jan 15, Google announced the 2025 edition, at their main page at: https://summerofcode.withgoogle.com/
      
      Important dates to remember:
      January 27 - 18:00 UTC Mentoring organizations can begin submitting applications to Google
      February 11 - 18:00 UTC Mentoring organization application deadline
      February 11 - 26 Google program administrators review organization applications
      February 27 - 18:00 UTC List of accepted mentoring organizations published
      February 27 - March 24 Potential GSoC contributors discuss application ideas with mentoring organizations
      March 24 - 18:00 UTC GSoC contributor application period begins
      April 8 - 18:00 UTCG SoC contributor application deadline
      April 29 - 18:00 UTC GSoC contributor proposal rankings due from Org Admins
      May 8 - 18:00 UTC Accepted GSoC contributor projects announced
      May 8 - June 1 Community Bonding Period | GSoC contributors get to know mentors, read documentation, get up to speed to begin working on their projects
      June 2Coding officially begins!
      July 14 - 18:00 UTC Mentors and GSoC contributors can begin submitting midterm evaluations (for standard 12-week coding projects)
      July 18 - 18:00 UTC Midterm evaluation deadline (standard coding period)
      July 14 - August 25 Work Period | GSoC contributors work on their project with guidance from Mentors
      August 25 - September 1 - 18:00 UTC Final week: GSoC contributors submit their final work product and their final mentor evaluation (standard coding period)
      September 1 - 8 - 18:00 UTC Mentors submit final GSoC contributor evaluations (standard coding period)
      September 1 - November 9 GSoC contributors with extended timelines continue coding
      November 10 - 18:00 UTC Final date for all GSoC contributors to submit their final work product and final evaluation
      November 17 - 18:00 UTC Final date for mentors to submit evaluations for GSoC contributor projects with extended deadlines
      
      A total team of 22 mentors of various levels, including trainee, junior, seniors, and Google Developer Experts mentors, are ready for this GSoC 2025 at the Liquid Galaxy project.
      
      
      NEWS
      
      1st dateline: JAN 10 2025, Task 1 statistics 
      From a total of 78 interested new contributors, 48 different virtual liquid galaxy installations have been presented to us successful and on time, with 15 more not rightly delivered. Congratulations to all of you, and remember, continue your effort with the rest of pre-required tasks, reading carefully this unique GSoC post, and contacting us at liquidgalaxylab gmail com, or asking the community in our Discord if you have any doubts.
      
       
      
      Your video installations are starting to be public on Youtube, with a special gamification: to animate you all to see your colleague's videos, and how they did, we're going to have a little contest:
      - in between every video will appear a Dash flying or statics, added when editing. --edited for clarity--
       Don't know what's a Dash ? The Flutter mascott !!!
      
      - always first of all, RSVP for the opening of the video at Google Developers event platform, see all the videos, take note of the minute and second where the dash appears, and send us email to  liquidgalaxylab gmail com with the times of all the videos (or some, as you wish)
      - we'll take note of the contributors that have watched up more dashes, checking they have RSVP's for the event platform, and make a raffle among them of a unique swag pack of Flutter goodies as: a set of pins, a t-shirt, and a hat. This kit will be sent to your home address, as we'll pick up the winner at a public event in a few weeks and ask for their address by email.
      
      - Raffle will be after Google GSoC official orgs announcement --edited for clarity-- around Feb 28
      
      
      
      January 27: Calling all 3D designers in our community 
      
      
      Announcing the winners, that's right, two!, for the Mr WW 3d animation contest. To be true there are two prizes, as only two of you have contributed, and both have done a nice work that will be used in the future in our streamings. Winners are, in no order: Jaivardhan Shukla and Vedang Lokhande. @everyone The two winners can send me their postal address (to the lg gmail) where we'll send a swag pack. CONGRATULATIONS and thank you for your animations.
      
      
      
      
      Hello designers, after a popular request in our Discord we are going to have a new contest, this time based in our lovely Mr. Worlwide, a mascot created by student Kahy back in 2019, under the GCI competition.
      
      The contest:
      - Create 3D animations with the Mr WW, in video horizontal full HD, to be used as wipes between sections in our future videos. Mr. WW has to do polite actions as you want. See the samples below and be creative.
      - dates: last day to deliver video Feb 23.
      - delivery way: send shared drive folder within the video, open for anyone to view --edited for clarity--
      - entries per person: maximum 3, each will count individually
      - public raffle on: Feb 25, 16:00 CET
      - what to win: a swag pack of Liquid Galaxy and Google merchandising, to be sent to your home address.
      
      You can download here the 3d model.
      
      Actual animations samples:
      salute
      thank you
      
      The project keeps the possibility of changing anything and our deliveries are final.
      
      Any questions send email to us.
      
      
      Activities in Madrid Spain to promote GSoC
      
      The Liquid Galaxy project has been an active part of several events that happened in Madrid, Spain, the last week of January 2025.
      Stephanie Taylor and Mary Radomile, world managers of GSoC, came to Spain to promote GSoC and we helped organize the following events:
      
      - GSoC presentation at URJC, home of JDE Robot organization, where the team led by his admin JM Cañas held a 90 university student event.
      
      - GSoC presentation at university UFV, where our beloved AI mentor Moisés Martínez, who's a lecturer there, organized the assistance of 50+ students. 
      
      
      
      6 mentors from our community attended: Victor (Flutter), Mario (Cloud), Irene (WTM), Moisés (AI), Oscar (code) and Andreu (admin and mentor), here with admins Stephanie and Mary:
      
      
      
      Also, we have a fantastic community dinner with current and old people from GSoC, including alumni, mentors, admin, and managers.
      
      
      Our Mr. Worldwide mascot had a presence too there, here with mentor Moisés:
      
      
      
      
      
      
      Community streamings
      
      If you're interested in developing applications based on our new web tech stack, take a look at our GitHub and this presentation :
      
      Our pre-requirements AMA streaming:
      
      
      GSoC presentation at Devfest Santander (Spanish)
      by Andreu Ibanez, admin Liquid Galaxy project
      
      
      Nov 28, 2024
      
      
      
      
      GSoC presentation in Arabic
      "Empowering Through Open Source: Google Summer of Code Stories [Arabic]" by our long-term contributor Mahinour Ala, now also WomenTechmakers Ambassador, who will become a mentor hopefully this GSoC 2025 for our project
      
      
      
      
      
      
      Mentor Vedant gave a talk about GSoC and our project at Pune's university, India
      
      
      
      
      
      
      Liquid Galaxy streamings Community news for season 2024-2025 and GSoC 2025
      
      
      
      Technical presentations :
      
      - Jan 14, 16:00 CET
      
      GSAP
      (GreenSock Animation Platform)
      Presented and Q&A by Dev Gadani
      
      
      - Jan 16, 16:00 CET
      Port forwarding on LG virtual installations
      Presented and Q&A by Rohit Kumar
      
      
      
      - Jan 24, 17:00 CET
      Introducing the Liquid Galaxy Web App
      Presented and Q&A by mentors Yash and Vedant, and contributor Rohit Kumar
      
      
      
      - Feb 3, 16:00 CET
      Building interactive tours with KML for LG
      Presented by contributor Jaivardhan Shukla
      
      
      
      
      Liquid Galaxy streamings Dealing with a good UI, an HTML, CSS and JS for GSoC 2025
      by senior mentor Yash Raj
      
      
      
      
      Task 1 video packs :
      
      2nd:
      
      3rd
      
      
      
      
      4th
      
      
      
      
      
      Image Recognition in Flutter Apps using TensorFlow Lite 
      Presented by Shuvam Swapnil
      February 17, 16:00
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/liquid-galaxy-project/
    idea_list_url: https://www.liquidgalaxy.eu/2024/11/unique-post-for-gsoc-2025-at-liquid.html


  - organization_id: 86
    organization_name: MBDyn
    no_of_ideas:
    ideas_content: |
      GSoC Project Ideas
      Last edited by Andrea Zanoni 4 weeks ago
      Ideas for Google Summer of Code projects
      In this page you'll find some ideas for projects to be developed in the context of the Google Summer of Code. If you are a student looking forward to apply, please remember that these are just suggestions and general ideas, you are free, and actually strongly encouraged, to propose you own project. You are also strongly encouraged to discuss with the regular developers your ideas before submitting an application.
      2021 GSoC Edition Update We updated some of the projects that you see in this list to the 2021, shortened, version of the Google Summer of Code program. Other project ideas remained pretty much unaltered, mainly because we see them mostly as general improvement frameworks, inside of which many individual projects are possible. If you are interested in working on any on them, get in contact with us in the Issues section: we will work out together a project.
      2022 GSoC Edition Update In the 2022 GSoC Edition, contributors will have the choice to submit proposals for short (175 hours) or long (350 hours). From most of the ideas you see in this list, projects of both types can be carved out. Contact us in the Issues section and we will discuss together how to structure your MBDyn GSoC project!.
      2024 GSoC Edition Update In the 2024 GSoC Edition, contributors will have even more flexibility in submitting proposals. Projects can be carried out in short (90 hours), intermediate (175 hours) and long (350 hours) versions. As you can see from the ideas in this list, projects of all sized can be carved out, so the important thing is that you get in contact with us as soon as possible, in the Issues to discuss together how to best structure your proposal.
      Furthermore, from the 2024 GSoC edition we completely re-structured the project proposals, learning from past experience.
      GSoC Project Ideas
      Pre-process
      Python Preprocessor Development
      Modeling Capabilities
      Genetic Optimization Module
      Post-process
      Blendyn Development
      Complete NetCDF output implementation
      IPC/RT
      Introduce MAVLink support
      MBDyn-DUST module
      Utility
      Packaging MBDyn
      Pre-Process
      Python Preprocessor development
      The MBDyn Python Preprocessor is a tool that is intended to support and speed up the generation of input files, integrating the standard MBDyn input syntax with Python code.
      The preprocessor can parse an input file searching for Python code wrapped by #beginpreprocess and #endpreprocess tags, and processes it generating portions of the final input file. See the examples in contrib/PythonPreprocessor/examples.
      After the 2024 GSoC project of Shimul Baidya, pre Preprocessor is now able to generate an entire MBDyn model using only Python code. This makes it suitable for integration in other software providing a Python API, to define a GUI-based method for MBDyn model generation. It also makes it easy to define higher-order preprocessing methods, like meshing flexible elements and automatically generating models for complex systems (for example, aeroelastic models of rotary-wing aircraft).
      In this context, many possibilities for GSoC projects can be devised. A non-comprehensive list of ideas that can be taken alone or combined to form a GSoC project:
      Integration of the Preprocessor in Blendyn, so that Blender can become a pre- and post-processor for MBDyn.
      Integration of the Preprocessor in FreeCAD
      Addition of classes that handle the generation of rotary-wing aircraft components (like HingelessRotor, FullyArticulatedRotor, Wing, etc...)
      Addition of classes to handle flexible element meshing
      This project can be scoped at 175 or 350 hours.
      Category: User Interface
      Programming Languages: Python
      Difficulty: Low/Intermediate
      Mentors: Andrea Zanoni, Marek Lukasiewicz
      ENTRY TEST: Complete step 1 of standard MBDyn GSoC entry test, compiling MBDyn from the preprocess branch, then write a simple parametric input file leveraging the Python Preprocessor. If you can, try to add support for a new MBDyn entity (e.g. a Drive Caller, see Section 2.6 of the Input Manual).
      Modeling Capabilities
      Genetic Optimization Module
      The purpose of this project is to develop and MBDyn module which implements a genetic algorithm (GA) which will solve optimization problems inside an MBDyn simulation run.
      The module will implement a super-element, i.e. an element that will take inputs from a series of drives (which, in turn, can expose other entities private data) and output one or more optimized variables to another set of drives. The main structure will be similar to the one of the hfelem module.
      In their basic form, GAs are extremely simple to implement, therefore the preferred way in this GSoC project will be to develop one from scratch and keep external dependencies to a minimum. Linking of external GA optimization libraries will be considered only after a satisfactory level of functionality is reached with the in-house code.
      Implementing the baseline GA solver, with the minimum required flexibility to be usable, is a 175 hours project.
      Developing a fully-featured GA solver, plus structuring the module so that also external GA optimization libraries can be linked is a 350 hours project.
      Category: Modeling Capabilities
      Programming Languages: C++
      Keywords: Optimization, Genetic Algorithms
      Difficulty: Intermediate/Advanced
      Mentors: Andrea Zanoni
      Post-Process
      Blendyn development
      MBDyn is a multibody dynamics solver which comes without any default graphical user interface for pre- and post-processing. There exist a few standalone post-processing tools based on EasyAnim, OpenDx and Blender.
      However, Blendyn, based on Blender, is the most up-to-date.
      See some example videos of its output and the tutorials to understand better what Blendyn is about.
      It is simple to use and generates 3D animations that represent the exact model movement and joints. Blendyn has got a great push in the development in the 2017 edition of the GSoC by the work of Reddy Janga and the 2022 edition by Do Tieng Dung, but some desirable features are still missing and several other need completion of fixing. For example:
      only fixed timestep simulation output is currently supported, variable timestep should be allowed also
      support the live plotting of MBDyn signals, for example leveraging the NetCDF output sync feature
      support the plotting of signals derived from arbitrary compositions of MBDyn signals (e.g. the sum of two signals) (up to here, this is a 90 hours project)
      support for the visualization of specific models, like for example aeroelastic models of rotary wing aircraft, biomechanical models of the human body, ecc... (getting here will require 175 or 350 hours, depending on how many possibilities for specific models are introduced)
      Category: User Interface
      Programming Languages: Python
      Keywords: Blender, UI, post-process
      Difficulty: Low/Intermediate
      Mentors: Andrea Zanoni
      ENTRY TEST: Complete step 1 of standard MBDyn GSoC entry test, then use the Blender Python API (or console) to create a simple Blender model
      Complete NetCDF output implementation
      MBDyn can output simulation results in NetCDF format, speeding up significantly the manipulation of output data for visualization and processing. Currently, the support for binary output is still not complete among all the MBDyn entities. For example, drives are currently not supported, nor are numerous user-defined elements contained in modules.
      The aim of this project is to add the support for binary output to all the missing entities. A vast library of examples can be obtained simply looking at the current implementation for the supported entities.
      The roadmap can be the following one:
      complete the binary output of 'standard' elements (e.g. plates are currently missing)
      add the binary output of reference frames
      add the binary output of drives (up to here, this is a 90 hours project)
      complete the binary output of elements defined in modules
      enable the user to output to NetCDF also solver diagnostics (e.g. residuals, iterations, jacobians) (up to here, this is a 175 hours project)
      Category: Post-process
      Programming Languages: C++
      Keywords: post-process, NetCDF
      Difficulty: Low
      Mentors: Andrea Zanoni
      IPC/RT
      Introduce MAVLink support
      MBDyn offers several possibilities to communicate with external processes: UNIX sockets, RTAI mailboxes or standard TCP/UDP sockets can be used to exchange data.
      The purpose of this project is to add the support to the MAVLink, a lightweight messaging protocol born for communicating with drones.
      The desired output is a module similar to module-flightgear, in which a new mode of operation of the file drivers of type stream and of the output elements of type stream is defined, allowing the user to select which MBDyn signal put into which MAVLink fields.
      Depending on the amount of flexibility/implemented features, this project can be scoped at 90 hours or 175 hours.
      Category: Modeling Capabilities
      Programming Languages: C/C++
      Keywords: Inter-Process Communication, Sockets
      Difficulty: Low
      Mentors: Andrea Zanoni, Marek Lukasiewicz
      MBDyn-DUST Module
      MBDyn can be coupled with external software, allowing it to be inserted into co-simulation pipelines. The most common application is Fluid-Structure Interaction (FSI), which is the field for which MBDyn was initially developed.
      DUST is a mid-fidelity aerodynamic solver, designed to provide fast estimated good enough for aircraft conceptual design. It is based on an integral boundary element formulation of the aerodynamic problem and vortex-particle modelling of the wakes.
      MBDyn is currently typically coupled with DUST using preCICE. However, for most applications, this is a rather unnecessary complication, since all is requested from preCICE is to make the two software exchange data at each timestep and give each other the OK to go to to the next step at convergence.
      This project aims at developing an in-house solution for the coupling, in the form of a MBDyn module. It will follow a similar pattern as the one from the 2020 GSoC edition from Runsen Zhang, who created a template module for the co-simulation of MBDyn and Chrono.
      This is a 350 hours project.
      Category: Modeling Capabilities
      Programming Languages: C/C++
      Keywords: Inter-Process Communication, Co-Simulation
      Difficulty: Intermediate/Advanced
      Mentors: Andrea Zanoni, Alberto Savino, Alessandro Cocco
      Utility
      Packaging MBDyn
      MBDyn is currently distributed only through publicly available source code, that the user is then expected to compile themselves. This has been identified as a barrier to entry for new users, especially ones not used to Linux environment. Even the latest documentation needs to be compiled by the end user.
      The purpose of this project is to simplify the installation process for a new user of MBDyn coming from a mechanical or aerospace engineering background. The resulting process should be portable to many Linux distributions, independent of the end user's local setup, include MBDyn's documentation and be well-documented itself.
      The first part of the contribution should be a review of available formats. Then the contributor should package MBDyn using the best solution(s) identified, and test it on a variety of systems.
      Additional goals, dependent on the scope and progress, would be to incorporate the packaging process into Continuous Integration (CI) and setup infrastructure to allow easy downloading of the premade binary.
      This work can have a positive impact on many fellow students, as the software is regularly used in teaching. Additionally, the skills developed by the contributor will be applicable not just to MBDyn, but to many open source projects with an involved build step.
      Depending on the amount of flexibility/implemented features, this project can be scoped at 90 hours or 175 hours.
      Category: Utility
      Programming Languages: C/C++ (mostly build systems)
      Keywords: Packaging, Maintenance
      Difficulty: Intermediate
      Mentors: Andrea Zanoni, Marek Lukasiewicz
      Comments
      Please register or sign in to add a comment.
      On this page
      Ideas for Google Summer of Code projects
      GSoC Project Ideas
      Pre-Process
      Python Preprocessor development
      Modeling Capabilities
      Genetic Optimization Module
      Post-Process
      Blendyn development
      Complete NetCDF output implementation
      IPC/RT
      Introduce MAVLink support
      MBDyn-DUST Module
      Utility
      Packaging MBDyn
      Pages
      15
      Home
      Development
      Development Guidelines
      CI
      to do list
      Google Summer of Code (GSoC)
      GSoC and MBDyn
      Entry Test
      Frequently Asked Questions
      Project Ideas
      Students Blogs
      Applications
      preCICE MBDyn adapter
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/mbdyn/
    idea_list_url: https://public.gitlab.polimi.it/DAER/mbdyn/-/wikis/GSoc-Project-Ideas


  - organization_id: 87
    organization_name: MDAnalysis
    no_of_ideas:
    ideas_content: |
      Hello, and welcome to MDAnalysis!
      Please see our Google Summer of Code wiki page for general information, including advice on application writing, and our GSoC FAQ for commonly asked questions.
      If you just found out about the MDAnalysis Python package from the GSoC website, you can watch the MDAnalysis 2021 Trailer [YouTube] to get an overview of the scope of the MDAnalysis package.
      Prerequisites
      MDAnalysis is a Python library for the analysis of computer simulations of many-body systems at the molecular scale, spanning use cases from interactions of drugs with proteins to novel materials. For Google Summer of Code, we are also collaborating with other organizations and software projects that use MDAnalysis. Our GSoC projects generally require a basic knowledge and hands-on experience in specific areas, so for our suggested projects, please check carefully the project descriptions to see the associated desirable skills. Broadly speaking, we found that applicants with experience in molecular dynamics (MD) simulations and the associated analyses -- or equivalent experience in simulations and modeling of molecular systems (physics, biophysics, chemistry, or materials) -- are very successful.
      To Prospective Applicants
      If you are interested in taking part, please get in touch on the GSoC with MDAnalysis Discussion Forum. Given the GSoC program structure (small, medium, and large projects), letting us know of your intentions to apply and getting acquainted with the project early will be very helpful.
      To Prospective Mentors
      MDAnalysis welcomes new mentors; please get in touch on the developer forum if you are interested in taking part. We typically expect mentors to be familiar with our development process, as evidenced by contributions to the code base and interactions on the developer forum.
      Overview
      See below for a list of projects ideas for Google Summer of Code 2025.
      The currently proposed projects are:
      Integrating MDAnalysis streaming analysis within WESTPA propagators
      Dashboard for tracking WESTPA simulation progress
      Lazy trajectory analysis with Dask and a Lazy Timeseries API
      Better interfacing of Blender and MDAnalysis
      HBond interactions from implicit hydrogens
      Continuous (i.e., non-binary) Interaction Fingerprints (IFPs)
      Improving ProLIF's 2D interaction visualizations
      Benchmarking and performance optimization
      Integrating OpenFolds’ structural prediction confidence metrics into the topology system
      Or work on your own idea! Get in contact with us to propose an idea and we will work with you to flesh it out into a full project. Contact us via the GSoC with MDAnalysis Discussion Forum (or if your project is a specific feature you'd want to add, raise an issue in the Issue Tracker.)
      Look at the list of all available mentors for MDAnalysis for potential mentors for your project. Please send all communications to the discussion forum (and don't contact mentors privately). You can certainly ask for the opinion of a specific mentor if you know that their expertise is particularly suitable for your project.
      Collaborations
      WESTPA
      WESTPA (The Weighted Ensemble Simulation Toolkit with Parallelization and Analysis) is a high-performance Python framework for applying the weighted ensemble (WE) path sampling strategy, which enables simulations of processes that are orders of magnitude longer than the simulations themselves. A WE simulation involves an iterative process: many MD simulations are executed in parallel and periodically evaluated to be replicated or terminated based on a set WE resampling criteria. To rigorously apply WE resampling, the MD simulations are analyzed during run time with tools such as MDAnalysis to determine the state of the simulated system.
      Read the WE Overview; install the WESTPA package; and work through tutorials 7.1 and 7.5 of our tutorials suite to start learning more about WESTPA.
      Molecular Nodes
      Built as an add-on for the popular and industry-leading 3D software Blender, Molecular Nodes(MN) enables import and visualization of complex molecular datasets inside of Blender. Many formats are supported such as static structures, electron density maps, EM (electromagnetic) tomography data and importantly, molecular dynamics simulation trajectories, powered by MDAnalysis. Blender is primarily intended for use via a GUI by artists, but scripting via the python API is also possible, with many potential avenues for automated animation and rendering.
      A great overview of the project is the talk given at the Blender Conference in 2022. The MN documentation includes a lot of information about how to get started, including written and video tutorials, with one specific to MD trajectory import. Workshop materials are also publicly available for an online Introduction to MDAnalysis and Molecular Nodes workshop held in February 2024, which includes an interactive tutorial for visualizing imported MDAnalysis data in Molecular Nodes.
      It’s important to first familiarize yourself with using Blender and Molecular Nodes via a GUI and some of the quirks that go along with it, before trying to write code for it.
      ProLIF
      ProLIF was one of the first packages to be part of the MDAKit ecosystem. It’s a Python library designed to generate interaction fingerprints for any kind of molecular complex in MD trajectories, docking simulations, or experimental structures.
      An interaction fingerprint encodes interactions between molecules as a bitvector. The interactions are detected by looking up atoms that match predefined molecular patterns (using SMARTS queries) and satisfy geometrical constraints (distance, angle, dihedral…).
      You can find more details about the package in the original publication (note that some details have changed since then), in the MDAnalysis UGM 2023 presentation slides, or in the tutorials.
      Project summary
      The table summarizes the project ideas; long descriptions come after the table (or click on the links under each project name). The difficulty is a somewhat subjective ranking, where easy means that we know pretty much what needs to be done, medium requires some additional research into best solutions as part of the project, and hard is high risk/high reward where we think a solution exists but we will have to work with the student to find it and implement it. The project size is either 90 h (small), 175 h (medium) or 350 h (large) projects.
      project name difficulty project size description skills mentors
      1 Integrating MDAnalysis streaming analysis within WESTPA propagators medium 175 hours Integrate MDAnalysis with WESTPA to analyze streamed trajectory data Python (multiprocessing), Networking (TCP/IP), MD Engines @jeremyleung521, @ltchong, @fiona-naughton, @orbeckst
      2 Dashboard for tracking WESTPA simulation progress easy 90 hours Create a graphical user interface to report MD trajectory progress Python (frontend UI, multiprocessing), Networking (TCP/IP) @jeremyleung521, @ltchong, @fiona-naughton, @talagayev
      3 Lazy trajectory analysis with Dask and a Lazy Timeseries API medium 175 hours Build out a lazy reader and timestep interface Dask or lazy computation paradigm, Object-oriented programming, Writing analysis code classes/scripts, Experience with a numpy-like-interface @ljwoods2, @orbeckst, @yuxuanzhuang
      4 Better interfacing of Blender and MDAnalysis medium 350 hours Improve how Blender and Molecular Nodes interface with MDAnalysis to import and animate MD trajectories Python, MDAnalysis, Blender (and programming via its Python API) @yuxuanzhuang, @bradyajohnston
      5 HBond interactions from implicit hydrogens medium 175/350 hours Make interaction fingerprints analysis with ProLIF (an MDAKit) more accessible and faster to run Python, RDKit, SMARTS, compchem @cbouy, @talagayev
      6 Continuous (i.e., non-binary) interaction fingerprints (IFPs) hard 350 hours Define thresholds for interactions and implement continuous encoding for interactions Python, RDKit, compchem @cbouy, @talagayev
      7 Improving ProLIF's 2D interaction visualizations medium 90/175 hours Improve ProLIF's "LigNetwork" plot and add 2D visualizations to summarize information in IFPs Python, JavaScript @cbouy, @talagayev
      8 Benchmarking and performance optimization easy/medium 175/350 hours Write benchmarks for automated performance analysis and address performance bottlenecks Python/ASV, Cython @orbeckst, @ljwoods2
      9 Integrating OpenFolds’ structural prediction confidence metrics into the topology system easy/medium 90 hours Expose the predicted local distance difference test metric (pLDDT) via the MDAnalysis topology system OpenFold or structural prediction tools more generally, Python, Solving parsing problems @ljwoods2, @orbeckst
      Project 1: Integrating MDAnalysis streaming analysis within WESTPA propagators
      Summary
      This project aims to integrate MDAnalysis with WESTPA to exploit MDAnalysis’s ability to analyze streamed trajectory data generated by WESTPA. This integration will reduce I/O bottlenecks and minimize the runtime needed to analyze a WESTPA simulation before intermittent restarting of the short, completed MD simulations.
      Detailed Description
      MDAnalysis is currently an option for extracting and analyzing simulation data for WESTPA simulations. This project aims to expand those capabilities by integrating streaming directly into WESTPA’s propagator executables and work managers for analysis, reducing the need for users to configure the networking. This will include stress testing MDAnalysis’s streaming capabilities, as analysis might involve using networking configurations such as streaming data from many-nodes-to-many-nodes and many-nodes-to-one-nodes.
      Expected Outcomes
      Stress-testing MDAnalysis streaming
      Additional propagator executables for integrating MDAnalysis streaming within WESTPA
      Relevant Skills
      Python (multiprocessing)
      Networking (TCP/IP)
      MD Engines
      Related issues/PRs/etc.:
      https://github.com/jeremyleung521/westpa/pull/28
      Possible Mentors
      @jeremyleung521
      @ltchong
      @fiona-naughton
      @orbeckst
      Expected Size of Project
      Large (175 hours)
      Difficulty Rating
      Medium
      Project 2: Dashboard for tracking WESTPA simulation progress
      Summary
      WESTPA simulations involve running multiple MD trajectories in parallel, which makes it hard to track progress. This project aims to create a graphical user interface that exploits MDAnalysis’s streaming ability and WESTPA’s work managers to monitor the progress of a WESTPA simulation.
      Detailed Description
      While WESTPA simulations report status at regular intervals, these iterations could last minutes to hours, leaving users unsure of the intermediate progress or time estimate. The task here will involve creating a graphical user interface reporting trajectory progress and completion time estimates through MDAnalysis’s streaming abilities and extracting relevant information from WESTPA’s work managers (ZMQ, python multiprocessing) and data managers.
      Expected Outcomes
      New CLI tool for WESTPA tracking simulation progress
      MDAnalysis module for aggregating/tracking multiple simulations
      Relevant Skills
      Python (frontend UI, multiprocessing)
      Networking (TCP/IP)
      Related issues/PRs/etc.:
      Not applicable
      Possible Mentors
      @jeremyleung521
      @ltchong
      @fiona-naughton
      @talagayev
      Expected Size of Project
      Small (90 hours)
      Difficulty Rating
      Easy
      Project 3: Lazy trajectory analysis with Dask and a Lazy Timeseries API
      Summary
      This project aims to improve MDAnalysis’s viability in high-performance clusters and high-throughput environments by building out a lazy (rather than eager) reader and timestep interface along with a sample H5MD implementation and basic analysis classes.
      Detailed Description
      MDAnalysis’s core data structure for holding trajectory data, the timestep, is extremely useful for providing a highly uniform interface for various readers, however, its eager approach to memory management, where trajectory frames are loaded into the object one step at a time, constrains analysis speed compared to the increasingly popular lazily-loaded paradigm used in recent packages like Dask and Polars. In HPC or cloud computing environments where minimizing analysis time is a necessity for making MDAnalysis viable at scale, having a lazy interface for new readers to target and existing ones to adapt to along with a sample implementation with H5MD and basic analysis classes that build on it would provide immediate benefits for HPC MDAnalysis users and a future platform for ensuring MDAnalysis is a tool that can scale with its users’ projects.
      MDAnalysis already has a timeseries API for readers which provides a natural starting place for a similar lazy_timeseries interface which would include an additional argument to select between coordinates, velocities, and forces. Existing readers can implement lazy_timeseries by first simply passing the numpy.ndarray result of calling timeseries into a Dask array, but certain readers like the H5MDReader or ZarrH5MDReader can receive a proper lazy implementation.
      Expected Outcomes
      MDAKit with lazy reader and timeseries interface code
      A working H5MD implementation of the interface
      A lazy timeseries analysis base
      Implementation of at least one basic analysis algorithm using the interface (like RMSD)
      Relevant Skills
      Experience with dask or lazy computation paradigm
      Knowledge of object-oriented programming
      Experience writing analysis code classes/scripts
      Any experience with a numpy-like-interface is useful
      Related issues/PRs/etc.:
      https://github.com/MDAnalysis/mdanalysis/issues/4713
      https://github.com/MDAnalysis/mdanalysis/issues/4598
      https://github.com/MDAnalysis/mdanalysis/issues/4561
      https://github.com/MDAnalysis/mdanalysis/issues/2865
      Possible Mentors
      @ljwoods2
      @orbeckst
      @yuxuanzhuang
      Expected Size of Project
      Medium (175 hours)
      Difficulty Rating
      Medium
      Project 4: Better interfacing of Blender and MDAnalysis
      Summary
      Improvements to how Blender and Molecular Nodes interface with MDAnalysis which powers the import and animation of MD trajectories inside of Blender. Simple import is currently available when using the GUI in Blender, but there is still a lot of potential for improvements in scriptability, automated rendering, and using Blender as an analysis tool for MD trajectories.
      Detailed Description
      Blender is industry-leading 3D modeling and animation software. Through the add-on Molecular Nodes, MDAnalysis universes are able to be imported into the 3D scene, enabling advanced rendering of molecular dynamics trajectories that is not possible inside of any other molecule viewer. The ability to script and automate this rendering is possible but limited with lots of room for improvement for visualizing many common MD datasets. Blender also provides a great platform for implementing a potential GUI, to enable interactive analysis of MD trajectories with stunning visuals, all powered by MDAnalysis under the hood.
      Expected Outcomes
      Prototype improved API for scripting and working with Molecular Nodes from Jupyter Notebooks or other similar environments
      Prototyping common analysis and visualization tasks that could be performed from within Blender via the GUI
      Relevant Skills
      Proficiency with Python
      Working knowledge of MDAnalysis
      Familiarity with Blender and programming via its Python API
      Related issues/PRs/etc.:
      https://github.com/MDAnalysis/mdanalysis/discussions/4862
      https://github.com/yuxuanzhuang/ggmolvis
      https://github.com/yuxuanzhuang/ggmolvis/issues/11
      https://www.mdanalysis.org/2024/12/12/sdg_molecularnodes/
      https://github.com/BradyAJohnston/MolecularNodes/pull/719
      Possible Mentors
      @yuxuanzhuang
      @bradyajohnston
      Expected Size of Project
      Large (350 hours)
      Difficulty Rating
      Medium
      Project 5: HBond interactions from implicit hydrogens
      Summary
      This project makes interaction fingerprints analysis with ProLIF (an MDAKit) more accessible and faster to run from PDB files for machine-learning (ML) practitioner.
      Detailed Description
      Interaction fingerprints (IFPs) are a common strategy to filter docking poses that aren't able to recapitulate known interactions in molecular complexes, but their use require explicit hydrogens to model hydrogen bonds. While ML-based docking and cofolding tools have seen increased usage other the recent years, the files that these methods generate only contain heavy atoms. While it's possible to add hydrogens to a complex and optimize its hydrogen-bond network, this significantly slows down and ultimately hampers the use of IFPs to evaluate the quality of ML-based molecular complexes. By adding to ProLIF the ability to evaluate hydrogen bond interactions solely based on heavy atom positions (and with the assumptions that hydrogens are positioned ideally for such interactions), it would be possible to directly compare co-crystallized complexes (e.g., from the PDB) with ML-based poses without requiring the intermediate use of protonation tools (PDB2PQR, reduce...etc.).
      Expected Outcomes
      New set of hydrogen-bond interaction classes available using implicit hydrogens
      Helper function to load PDBs with heavy atoms only and common non-standard residues (HSD, HSE, HID…etc.) appropriately
      Relevant Skills
      Python
      RDKit
      SMARTS
      Computational Chemistry
      Related issues/PRs/etc.:
      Not applicable
      Possible Mentors
      @cbouy
      @talagayev
      Expected Size of Project
      Medium/Large (175/350 hours)
      Difficulty Rating
      Medium
      Project 6: Continuous (i.e., non-binary) interaction fingerprints (IFPs)
      Summary
      IFPs use cutoff values for defining the different expected distances and angles that interactions must follow, leading to cases slightly outside of these thresholds to not be detected at all. This project aims to bring an alternative (continuous) encoding for interactions in ProLIF (an MDAKit) so that such cases may still be accounted for in subsequent analysis.
      Detailed Description
      IFPs are inherently binary and based on distance and angles thresholds that can be hard to define robustly across the wide diversity of use cases. The idea here would be to define "ideal" and "suboptimal" thresholds for distances and angles, and for interacting atoms that satisfy the ideal thresholds encode them as 1 (as would be with a "traditional" IFPs), for those that don't satisfy the suboptimal thresholds encode them as 0, and for anything in between encode them through a sigmoid function that outputs a real value between 0 and 1. This would allow to deal more gracefully with cases that follow non-ideal geometries for interacting atoms. Note that the sigmoid function that transforms the input distances and angles into a real value will have to be determined during the project.
      Expected Outcomes
      The interaction classes have the ability to specify multiple thresholds for distances and angles, and additional metadata is returned when these classes are used to detect interactions
      The conversion of the resulting IFPs to a pandas DataFrame outputs continuous values between 0 and 1 instead of being binary
      From a user perspective, they should only have to toggle on a new parameter in the Fingerprint object initialization to enable this analysis
      Relevant Skills
      Python
      RDKit
      Computational Chemistry
      Related issues/PRs/etc.:
      Not applicable
      Possible Mentors
      @cbouy
      @talagayev
      Expected Size of Project
      Large (350 hours)
      Difficulty Rating
      Hard
      Project 7: Improving ProLIF's 2D interaction visualizations
      Summary
      This project involves improvements to the current “LigNetwork” plot produced by ProLIF to make it easier to use and more publication-ready, and leaves some room to add other 2D visualizations that can help summarize the information contained in interaction fingerprints.
      Detailed Description
      When creating a "LigNetwork" plot with ProLIF, the protein residues are placed randomly and left for the user to drag and drop to make the figure readable. It would be beneficial to automate the placement of residues on the plot in a way that minimizes the overlap between residues and the ligand, and minimizes crossing between interaction edges.
      Depending on the size of the project, additional visualizations could be added, such as: a "heatmap" of ligand atoms involved in different interactions by highlighting such atoms with a bivariate Gaussian distribution based on an atomic interaction-aware weighting (see doi.org/10.1186/1758-2946-5-43 for reference). Another one could be to generate a figure similar to the LigNetwork with InteractionDrawer, converting the ProLIF metadata to follow their JSON schema. For protein-protein systems and residue network analysis, Flareplot would be very beneficial.
      Expected Outcomes
      The placement of residues on the LigNetwork plot is made to be readable out of the box
      If time allows, additional kinds of plots are added to further improve ProLIF’s visualization capabilities
      Relevant Skills
      Python
      JavaScript
      Related issues/PRs/etc.:
      Not applicable
      Possible Mentors
      @cbouy
      @talagayev
      Expected Size of Project
      Small/Medium (90/175 hours)
      Difficulty Rating
      Medium
      Project 8: Benchmarking and performance optimization
      Summary
      The goal of this project is to increase the performance assessment coverage (using the existing ASV framework), identify code that should be improved, and optimize code.
      Detailed Description
      The MDAnalysis Roadmap emphasizes performance improvement. The performance of the MDAnalysis library is assessed by automated nightly benchmarks with ASV (see https://github.com/MDAnalysis/benchmarks/wiki) but coverage of the code base is low. The goal of this project is to substantially increase the performance assessment coverage, identify code that should be improved, and possibly implement performance optimizations.
      Expected Outcomes
      Write ASV benchmark cases for all major functionality in the core library
      Write ASV benchmark cases for often-used analysis tools
      Analyze performance history and generate a priority list of code that should be improved
      Document writing benchmarks with a short tutorial
      Optional: Optimize performance for at least one discovered performance bottleneck
      Relevant Skills
      Python/ASV
      Cython
      Related issues/PRs/etc.:
      https://github.com/MDAnalysis/mdanalysis/issues/1023
      https://github.com/MDAnalysis/mdanalysis/issues/1721
      https://github.com/MDAnalysis/mdanalysis/issues/4577
      Possible Mentors
      @orbeckst
      @ljwoods2
      Expected Size of Project
      Medium/Large (175/350 hours)
      Difficulty Rating
      Easy/Medium
      Project 9: Integrating OpenFolds’ structural prediction confidence metrics into the topology system
      Summary
      The goal of this project is to expose per-molecule and inter-molecular structural prediction confidence metrics to users via the MDAnalysis topology system.
      Detailed Description
      Structural prediction tools like OpenFold are increasingly important for in-silico estimations of protein structure and of binding probability between molecules. However, working with the raw output of prediction tools is challenging and often requires bespoke tools made by researchers prone to inefficiency and errors. MDAnalysis’s topology system provides a robust, natural interface for working with per-residue (like pLDDT) and between-residue/chain metrics (like a contact probabilities matrix). This project seeks to build the foundation for working with structural prediction confidence metrics in MDAnalysis.
      After this project is complete, users will be able to access confidence metrics via Numpy arrays associated with (or between) each AtomGroup in a way that is consistent with current MDA atom selection
      Expected Outcomes
      Modifications of the PDBParser to associate confidence metrics with and between each AtomGroup
      Relevant Skills
      OpenFold experience or structural prediction tools more generally
      Python
      Experience solving parsing problems
      Related issues/PRs/etc.:
      https://github.com/MDAnalysis/mdanalysis/issues/4134
      Possible Mentors
      @ljwoods2
      @orbeckst
      Expected Size of Project
      Small (90 hours)
      Difficulty Rating
      Easy/Medium
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/mdanalysis/
    idea_list_url: https://github.com/MDAnalysis/mdanalysis/wiki/GSoC-2025-Project-Ideas

  - organization_id: 88
    organization_name: MIT App Inventor
    no_of_ideas:
    ideas_content: |
      Introduction
      Welcome to Google Summer of Code with MIT App Inventor.
      We have an application process in addition to Google's application process. You must do both. Please apply to Google for GSoC through Google’s Website. All applications have to go through Google.
      We will be receiving applications within the timeframe allocated by GSoC. Please consult the GSoC website for details. For bite-sized issues to work on as part of the community introduction phase, please see the help wanted issue list.
      Below is the list of projects we are proposing for the summer; you can choose one or more projects from the list, or come up with your own project. Also note that these projects could be worked on outside GSoC if you would like to volunteer during the summer.
      Information for students
      How to apply
      Our application form for GSoC 2025 is here. Additional instructions are linked from the application form.
      Potential Projects
      This is what you might expect from projects in the list below:
      Brief explanation: An explanation of what the project is about. Please note that this might be just an idea, and as part of your work in the project you will be defining and scoping the project.
      Technical Difficulty: A rough idea of how difficult the project is given knowledge of the language but not necessarily the knowledge of the frameworks involved.
      Estimated Time Commitment: An estimate for the total number of hours required to be spent on the project to produce a working solution with testing.
      Knowledge Prerequisite: A brief list of the technologies needed in order to work on this project.
      Potential Mentor: The currently active team member you will probably be working with during the summer (this can also change depending on which projects are chosen).
      Projects list
      Artificial Intelligence Projects
      Trainable ChatBot interface and AI component
      Brief Explanation: App Inventor has a growing offering of artificial intelligence features and is looking to add more cutting-edge AI learning experiences. We are looking to build a tool to create a trainable and customizable ChatBot that can be imported into an App Inventor app. This would be a similar experience to our Personal Image Classifer (PIC) and Personal Audio Classifer (PAC) extensions wherein there are external websites to build and train models, and these models are then exported and imported into App Inventor.
      PIC: https://classifier.appinventor.mit.edu/
      PAC: https://c1.appinventor.mit.edu/
      Familiarity with RAG implementations and SLMs will be helpful.
      Technical Difficulty: Hard
      Estimated Time Commitment: 350 hours
      Knowledge Prerequisites: Java, GWT, Javascript.
      Potential Mentors: Natalie Lao
      Property editor for creating transfer-learning ML models
      Brief Explanation: Our Personal Image Classifer (PIC) and Personal Audio Classifer (PAC) components use external websites to build and train models. Those models then have to be exported and imported into App Inventor. It's a cumbersome process.
      PIC: https://classifier.appinventor.mit.edu/
      PAC: https://c1.appinventor.mit.edu/
      Build these sites as property editors in core App Inventor.
      Technical Difficulty: Hard
      Estimated Time Commitment: 350 hours
      Knowledge Prerequisites: Java, GWT, Javascript.
      Potential Mentors: Jeff Schiller
      Component Projects
      ListView Component Update
      Brief Explanation: The ListView component offers a sophisticated set of behavior options. It supports both the addition of simple list elements by comma-delimited string and complex items by an interactive editor in the web designer. It supports several different layouts of list elements that include strings and images. Lists elements can display in a scrolling list style or a "swipe left" single element card style. Several parts of this need to be enhanced or refactored.
      Expected Results: Add features: New layout matching a swipe-left browser with a large central image with text below as captions; refactor of web designer list item editor to use UIBinder layout template, be more user-friendly, and be keyboard navigable; multi-select support. Update some iOS features that do not work properly.
      Knowledge Prerequisites: Java, GWT, swift
      Technical Difficulty: Medium
      Estimated Time: 175 hours
      Potential Mentors: Susan Rati Lane
      iOS Implementation of Menu Component
      Brief Explanation: A previous GSoC project created a set of menu components for Android apps. We were never able to release it because by the time PR review was complete, we were fully supporting iOS, and these components were not implemented in iOS.
      Expected Results: Implement Menu, Sidebar, and Floating Action components in iOS to match the functionality in this PR: https://github.com/mit-cml/appinventor-sources/pull/2299. It is not up-to-date with master, but it should compile and run in a development environment.
      Knowledge Prerequisites: swift
      Technical Difficulty: Hard
      Estimated Time: 350
      Potential Mentors: Susan Rati Lane
      Designer Projects
      Improvements for the Designer view. This part of the system is built mainly with Java using the Google Web Toolkit.
      Responsive (Mobile phone) layout
      Brief Explanation: In 2023, App Inventor rolled out an extensive refactor of our user interface to support GWT's UiBinder framework. This allows us to provide multiple user interface layouts based on device or user preferences. We see a growing number of users accessing App Inventor with mobile phones, and handheld devices are globally more accessible than desktops or laptops. We would like to provide a user interface option that makes App Inventor a more practical option for small screens.
      Technical Difficulty: Medium
      Estimated Time Commitment: 350 hours
      Knowledge Prerequisites: Java, GWT, UiBinder.
      Potential Mentors: Susan Lane
      Better behavior for unimplemented components
      Currently, when an Android-only component is added to a project and loaded into the iOS Companion, the app just crashes. We would like our iOS Companion to be able to detect that it is trying to load an unimplemented component and present the user with useful information about it. We would also like the app to run if it is possible without the unimplemented component.
      Technical Difficulty: Medium
      Estimated Time: 175
      Knowledge Prerequisite: Swift
      Potential Mentors: Evan Patton, Susan Lane
      Assets Library
      Brief Explanation: Allow users to upload sets of assets to be imported easily into different projects.
      Expected Results: An interface that allows for uploading and organizing assets (images and sounds) to be used within App Inventor apps through the Designer.
      Knowledge Prerequisites: JavaScript and Java
      Technical Difficulty: Medium
      Estimated Time: 175 hours
      Potential Mentors: Evan Patton, Jose Dominguez or Jeff Schiller
      Learning Management System (LMS) Integrations
      Brief Explanation: Integrate App Inventor with one or more LMS systems such as Google Classroom and Canvas.
      Expected Results: An interface that allows course organisers to assign course work and manage submissions and grading of App Inventor projects through an existing LMS.
      Knowledge Prerequisites: JavaScript and Java
      Technical Difficulty: Medium
      Estimated Time: 175 hours
      Potential Mentors: Jose Dominguez or Jeff Schiller
      User defined components/extensions
      Brief Explanation: Add the ability to create user-defined components (or extensions). By which we mean an App Inventor user could take a set of App Inventor components (and blocks using those components) and wrap them up together in a single reusable unit which exposed a set of properties, methods and events. In the initial implementation, perhaps, those units could only be used in the project in which they are defined, but ultimately you'd like for them to be exportable/importable, so that they could be used by other users (or that same user in other projects).
      Expected Results: App Inventor users can create reusable components.
      Knowledge Prerequisites: App Inventor, Java, GWT, UIBinder
      Technical Difficulty: Hard
      Estimated Time: 350 hours
      Potential Mentors: Mark Friedman
      Additional Projects
      Github workflow hooks
      Brief Explanation: The appinventor-sources repository behaves differently from the Github workflow expectations. In particular, we have two branches that function as master: master and ucr (Upcoming Component Release). Changes that must be installed on devices (Android or iOS Companion) need to be released at specific times of the year, so that work is branched from and merged into ucr. Changes that affect the web designer can be released at any time and are branched into/merged into master. Github does not recognize ucr for the purpose of updating linked issues and other features. We also would like to manage other issue labels, like updating when PRs need additional review, etc.
      Expected Results: Write Github hooks to match our dual-master workflow.
      Knowledge Prerequisites: Python, Git, Github
      Technical Difficulty: Medium
      Estimated Time: 175 hours
      Potential Mentors: Evan Patton, Jeff Schiller, or Susan Rati Lane
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/mit-app-inventor/
    idea_list_url: https://github.com/mit-cml/appinventor-sources/wiki/Google-Summer-of-Code-2025

  - organization_id: 89
    organization_name: Machine Learning for Science (ML4SCI)
    no_of_ideas:
    ideas_content: |
      Machine Learning for Science
      Activities
      
      Machine Learning for Science (ML4Sci) is an open-source organization that brings together modern machine learning techniques and applies them to cutting edge problems in Science, Technology, Engineering, and Math (STEM).
      ML4SCI in GSoC 2025
      The ML4Sci open source organization plans to participate in the 2025 Google Summer of Code. If you are a student interested in our projects please check our ideas page. ML4Sci is an umbrella organization that welcomes other projects and organizations related to machine-learning for science. Please contact the admins at ml4-sci@cern.ch if you are interested in participating as a project. Our contributors publish scientific articles in peer-reviewed journals.
      Please take a look at our GSoC Page for more details.
      If you are interested in AI in Humanities and Arts please visit our sister GSoC Organization HumanAI planning to take part in GSoC 2025.
      If you are interested in our activities please join our announcements mailing list. To join, you will need to create a CERN lightweight account.
      You can also find us on Gitter.
      Latest update: evaluation test release date: 02/27.
      Organization administrators:
      Prof. Sergei Gleyzer (University of Alabama)
      Prof. Emanuele Usai (University of Alabama)
      Dr. Patrick Peplowski (JHUAPL)
      
      
      Improve this page. Thanks to GitHub Pages, Jekyll and Bootstrap.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/machine-learning-for-science-(ml4sci)/
    idea_list_url: https://ml4sci.org/


  - organization_id: 90
    organization_name: MariaDB
    no_of_ideas:
    ideas_content: |
      Google Summer of Code 2025
      This year we are again participating in the Google Summer of Code. We, joined with the MariaDB Foundation, believe we are making a better database that remains application compatible with MySQL. We also work on making LGPL connectors (currently C, C++, ODBC, Java, Node.js) and on MariaDB Galera Cluster, which allows you to scale your reads & writes. And we have MariaDB ColumnStore, which is a columnar storage engine, designed to process petabytes of data with real-time response to analytical queries.
      Contents
      Where to Start
      List of Tasks
      MariaDB Server
      MDEV-28395 LOAD DATA plugins
      MDEV-36100 Generate vector embeddings automatically on INSERT
      MDEV-36107 expressions in mysqltest
      MDEV-36108 variable substitutions in mysqltest
      MDEV-18827 Create utility to parse frm files and print their DDL
      MDEV-9345 Replication to enable filtering on master
      Buildbot build statistics dashboard
      Suggest a Task
      Where to Start
      Please join us on Zulip to mingle with the community. You should also subscribe to the developers mailing list (this is the main list where we discuss development - there are also other mailing lists).
      To improve your chances of being accepted, it is a good idea to submit a pull request with a bug fix to the server.
      Also see the List of beginner friendly issues from the MariaDB Issue Tracker.
      List of Tasks
      MariaDB Server
      MDEV-28395 LOAD DATA plugins
      Full-time project 350h
      LOAD DATA INFILE can flexibly load data into a table from CSV-like files accessible by the mariadbdb process. LOAD XML INFILE can do it for XML files. LOAD DATA LOCAL INFILE and LOAD XML LOCAL INFILE can do it with files accessible by the client, but not by the server. But there are requests to suport loading more file formats and from other locations, for example, from S3.
      This project is to implement support for LOAD plugins and refactor the current LOAD code accordingly. There are two kind of plugins — data parser plugin (CSV-like and XML) and transfer plugin (file and LOCAL). Implementing new plugins is not in the scope of this task, this task is mainly about moving existing code around, creating a possibility for new plugins (like JSON or S3).
      Skills needed: C++, bison
      Mentors: Sergei Golubchik
      MDEV-36100 Generate vector embeddings automatically on INSERT
      Full-time project 350h
      Implement a syntax and a plugin API that the server will use to generate embeddings for documents that the user stores in the database. This should allow to simplify significantly the vector pipeline. mariadbd will not generate embeddings internally, it will invoke a plugin to do that.
      Skills needed: C++
      Mentors: Sergei Golubchik
      MDEV-36107 expressions in mysqltest
      Part-time project 175h
      extend mysqltest language to support
      standard arithmetic +, -, *, /, %
      comparisons ==, !=, <, <=, >, >=
      boolean &&, ||, may be ? :
      if possible: string repetition, perl-style x (to replace SELECT REPEAT() in test files)
      This should work in commands let, if, while
      Skills needed: C++
      Mentors: Sergei Golubchik
      MDEV-36108 variable substitutions in mysqltest
      Part-time project 175h
      extend mysqltest language to support bash-like substitutions:
      ${var}
      ${parameter:offset:length}
      ${#parameter}
      ${parameter/pattern/string/flags}
      may be ${parameterˆ}, ${parameterˆˆ}, ${parameter,}, ${parameter}
      may be ${parameter@function} with functions like u, U, Q, etc
      recursive expansion:
      ${${var}}
      Skills needed: C++
      Mentors: Sergei Golubchik
      MDEV-18827 Create utility to parse frm files and print their DDL
      Full-time project - potential part-time (175 - 350h, depending on scope)
      FRM files are what MariaDB uses to store metadata about tables. These files can be used to generate DDL statements (CREATE TABLE ...). We are lacking a utility to parse these files which could in turn make DBAs lives easier. The task of this project is to have this utility implemented, making use of MariaDB's FRM parsing logic. You may have to carry out some refactoring to extract the parsing code into a reusable library, once for MariaDB Server, once for the FRM parsing tool.
      Skills needed: C/C++, understanding libraries and APIs.
      Mentors: Vicențiu Ciorbaru / Sergei Golubchik
      MDEV-9345 Replication to enable filtering on master
      Part-time project 175h
      The current methods of filtering replication events are limited to either 1) at binlog-write time, which can break point-in-time recovery because some committed transactions will be missing from the binary log, or 2) on the replica, which forces all events on the primary server to always be sent to the replica, which can be a security concern and is also not efficient. This task aims to eliminate these limitations by adding in another point at which replication filtering occurs: on the binlog dump threads. This would allow users to both maintain a consistent binary log, and minimize network traffic by guarding events which are never intended for replication.
      Skills needed: C++
      Mentors: Brandon Nesterenko
      Buildbot build statistics dashboard
      Part-time project 175h TODO - A more ample description will be created.
      Skills needed:
      Mentors: Vlad Radu
      Suggest a Task
      Do you have an idea of your own, not listed above? Do let us know in the comments below (Click 'Login' on the top of the page first)!
      ← Google Summer of Code 2013
      ↑ Google Summers of Code ↑
      Comments
        Include Archived
      No comments
      Content reproduced on this site is the property of its respective owners, and this content is not reviewed in advance by MariaDB. The views, information and opinions expressed by this content do not necessarily represent those of MariaDB or any other party.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/mariadb/
    idea_list_url: https://mariadb.com/kb/en/google-summer-of-code-2025/
  

  - organization_id: 91
    organization_name: Meshery
    no_of_ideas:
    ideas_content: |
      Docs
      Catalog
      Playground
      Community
      Resources
      Getting Started
      Google Summer of Code and Meshery
      Google Summer of Code Participation?
      The key component of these projects is our Community. This community, which you will join as an participant in Google Summer of Code, is improving the world of diverse cloud native systems. Your contributions will affect people you've never met. The Meshery community includes software engineers, researchers, students, artists, system administrators, operators and web designers -- all of whom will be happy to help you get started.
      We believe that all contributors should expect and be part of a safe and friendly environment for constructive contribution. We can more effectively and successfully compare and challenge different ideas to find the best solutions for advancement, while building the size, diversity, and strength of our community.
      2025 Program Timeline
      - January 27 - Organization applications open
      - February 27 - Accepted GSoC Organizations announced
      - March 24 - Students submit their proposals
      - May 7 - Accepted students are announced
      - November 19th - Successful student projects are announced
      Statistics
      Since year 2005, 16,000+ students and 13000 mentors from over 118 countries has came together to participate in GSoC
      Approximately 38+ million lines of code have been produced
      GSOC 2025 Project Ideas
      1. Multi-player Collaboration: Resilient Websockets and GraphQL Subscriptions
      Description:
      Meshery's current implementation of websockets and GraphQL subscriptions is in need of refactoring for increased reliability and resiliency. This client and server-side refactoring includes use of webworkers and separation of concerns for the client-side, and the use of a message broker for the server-side. The project has implications on Meshery's implementation of multi-player collaboration functionality.
      Expected outcomes:
      Resilient websockets and GraphQL subscriptions for Meshery, enabling multi-player collaboration functionality.
      Recommended Skills: Golang, Kubernetes, Azure, well-written and well-spoken English
      Expected project size: large (~175 hour projects)
      Mentors: Lee Calcote, Aabid Sofi
      Issue: https://github.com/meshery/meshery/issues/13554
      2. Support for Azure in Meshery
      Description:
      Enhance Meshery's existing orchestration capabilities to include support for Azure. The Azure Service Operator(ASO) provides a wide variety of Azure Resources via Kubernetes custom resources as first-class Meshery Models. This involves enabling Meshery to manage and orchestrate Azure services and their resources, similar to how it handles other Kubernetes resources. The project will also include generating support for Azure services and their resources in Meshery's Model generator.
      Expected outcomes:
      Meshery will be able to orchestrate and manage all Azure services supported by ASO. This includes the ability to discover, configure, deploy, and operate the lifecycle of Azure services through Meshery. The Meshery Model generator will be updated to automatically generate models for Azure services, simplifying their integration and management within Meshery. This will be an officially supported feature of Meshery.
      Recommended Skills: Golang, Kubernetes, Azure, well-written and well-spoken English
      Expected project size: large (~175 hour projects)
      Mentors: Lee Calcote, Mia Grenell
      Issue: https://github.com/meshery/meshery/issues/11244
      3. Kubectl Plugin for MeshSync Snapshot
      Description:
      Develop a kubectl plugin via krew that allows users to temporarily deploy MeshSync, capture the state of their cluster, and then import the snapshot into Meshery for offline infrastructure management. The plugin will serve as a lightweight alternative to a full Meshery deployment while still enabling Meshery Server to understand the state and configuration of Kubernetes cluster, simplyfying common networking challenges between the cluster and Meshery Server.
      Expected outcomes:
      - A functional kubectl plugin that facilitates capturing a MeshSync snapshot of Kubernetes cluster resources.
      - Improved networking efficiency, reducing the complexity of connecting Kubernetes clusters with Meshery Server.
      - Support for selective snapshot capture, including single resources, namespaces, or entire cluster visualizations.
      - Read-only access mode to generate snapshots without requiring full Meshery deployment.
      Recommended Skills: Golang, Krew, Kubernetes, well-written and well-spoken English.
      Expected project size: large (~175 hour projects)
      Mentors: Lee Calcote, James Horton
      Issue: https://github.com/meshery/meshery/issues/11869
      4. Distributed client-side inference (policy evaluation) with WebAssembly (WASM) and OPA in Meshery
      Description:
      Meshery's highly dynamic infrastructure configuration capabilities require real-time evaluation of complex policies. Policies of various types and with a high number of parameters need to be evaluted client-side. With policies expressed in Rego, the goal of this project is to incorporate use of the https://github.com/open-policy-agent/golang-opa-wasm project into Meshery UI, so that a powerful, real-time user experience is possible.
      Expected outcomes:
      The goal of this project is to enhance Meshery's infrastructure configuration capabilities by incorporating real-time policy evaluation using the golang-opa-wasm project. This project will integrate the capabilities of golang-opa-wasm into the Meshery UI, enabling users to experience the existing, powerful, server-side policy evaluation client-side.
      Recommended Skills: WebAssembly, Golang, Open Policy Agent, well-written and well-spoken English.
      Expected project size: large (~175 hour projects)
      Mentors: Lee Calcote, James Horton
      Issue: https://github.com/meshery/meshery/issues/13555
      5. Meshery Model Support for kro ResourceGraphDefinitions (RGDs)
      Description:
      Enhance Meshery's existing orchestration capabilities to include support for kro ResourceGraphDefinitions (RGDs) as first-class Meshery Models. This involves enabling Meshery to manage and orchestrate RGDs, similar to how it handles other Kubernetes resources. The project will also include generating support for ResourceGraphDefinition in Meshery's Model generator.
      Expected outcomes:
      Meshery will be able to orchestrate and manage kro RGDs. This includes the ability to deploy, configure, and manage the lifecycle of RGDs through Meshery. The Meshery Model generator will be updated to automatically generate models for kro RGDs, simplifying their integration and management within Meshery. This will be an officially supported feature of Meshery.
      Recommended Skills: Golang, Cuelang, Well-written and well-spoken English, Kubernetes, DevOps
      Expected project size: large (~350 hour projects)
      Mentors: Lee Calcote, Mia Grenell
      Issue: https://github.com/meshery/meshery/issues/13520
      6. Hands-on tutorials using Meshery Playground
      Description:
      Learning paths with hands-on labs are a crucial resource for DevOps engineers and cloud-native practitioners. The Meshery Playground provides a live cluster environment, making it an ideal platform for learning every kind of cloud and cloud native technology. Meshery Docs is in need of comprehensive tutorials and scenarios covering common infrastructure management use cases. Mission is to create and publish a series of hands-on tutorials using Meshery Playground. Each tutorial will include step-by-step guides, live demonstrations, and interactive labs using the Playground allowing learners to apply their knowledge directly without the hassle of any configuration.These tutorials will be reviewed by various project maintainers and then published in guides/tutorials.
      Expected outcomes:
      - 10+ new tutorials published in Meshery Docs.
      - Each tutorial should be interactive, guiding users through infrastructure.
      - Tutorials should vary in complexity, catering to beginners and advanced learners.
      Recommended Skills: written English, Markdown, Kubernetes, DevOps, and hands-on experience with cloud-native tools.
      Expected project size: large (~350 hour projects)
      Mentors: Lee Calcote, James Horton
      Issue: https://github.com/meshery/meshery/issues/13521
      7. Kanvas Snapshot Kubectl Plugin
      Description:
      Kubernetes manifests, especially collections of them, can be complex. This plugin will bridge the gap between Kubernetes cluster and workflow configurations and their visual representation in Kanvas Snapshots. The plugin will allow users to generate a visual snapshot of the combination of multiple Kubernetes manifest files, each containing one or more Kubernetes resources. Users will be able to receive these snapshots either via email or as a URL displayed directly in the terminal.
      Expected outcomes:
      - A functional kubectl plugin that integrates with Meshery to generate Kanvas Snapshots from Kubernetes manifests.
      - Support for both synchronous and asynchronous delivery, allowing users to receive snapshots via email or directly in the terminal.
      Recommended Skills: Golang, Krew, Kubernetes, well-written and well-spoken English.
      Expected project size: large (~175 hour projects)
      Mentors: Lee Calcote, James Horton
      Issue: https://github.com/meshery/meshery/issues/12036
      8. Expanding end-to-end test coverage in Meshery using Playwright
      Description:
      Meshery integrates with many other CNCF projects and technologies. Sustaining those integrations is only possible through automation. To automate functional integration and end-to-end testing, Meshery now uses Playwright as one of the tools for browser testing. End-to-end tests run with each pull request to ensure that changes do not break existing functionality. Expanding the coverage of E2E tests is crucial to improving the reliability of Meshery’s UI and workflows. This project focuses on writing Playwright-based tests for more Meshery components, ensuring robust test coverage across the platform.
      Expected outcomes:
      Development of comprehensive E2E test cases for additional Meshery components using Playwright.
      Recommended Skills: JavaScript, Playwright, GitHub Workflows, familiarity with React or Nextjs would be helpful, CI/CD.
      Expected project size: medium (~175 hour projects)
      Mentors: Lee Calcote, Aabid Sofi
      Issue: https://github.com/meshery/meshery/issues/13514
      
      COMMUNITY NEWSLETTER
      Subscribe
      Community
      Blog
      Mailing Lists
      Calendar
      Internships
      Discussion Forums
      Getting Started
      Features
      Run Meshery
      Integrations
      Cloud Native Playground
      Resources
      Docs
      Meshery Catalog
      Tutorials
      Cloud Native Performance
      Socials
      Twitter
      YouTube
      Docker Hub
      Slack
      GitHub
      LinkedIn
      © 2025 The Meshery Authors
      Confidently wrangling cloud native infrastructure
      Code of Conduct
      The Linux Foundation. Meshery has registered trademarks and uses trademarks
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/meshery/
    idea_list_url: https://meshery.io/programs/gsoc/2025

  - organization_id: 92
    organization_name: MetaBrainz Foundation Inc
    no_of_ideas:
    ideas_content: |
      Development/Summer of Code/2025
      < Development | Summer of Code
      Jump to navigation
      Jump to search
      Are you interested in working with MetaBrainz in Google Summer of Code 2025? You're in the right place!
      Contents
      1 Important Schedule Note
      2 Where to start
      3 Application template
      4 Projects
      4.1 BookBrainz
      4.2 ListenBrainz
      4.3 MusicBrainz
      4.4 MetaBrainz
      Important Schedule Note
      If you're arriving here after 31 March 2025, you've missed your chance to apply with us. We will not consider applications from applicants who have not discussed their idea during the application discussion phase which ends March 31st. We will make no exceptions.
      Where to start
      New to MetaBrainz?
      The MetaBrainz Foundation has been set up to build community maintained databases and make them available in the public domain or under Creative Commons licenses.
      New to MetaBrainz development and/or GSoC?
      Getting started with GSoC
      Application template
      When you're ready to write your application, please use this Application Template as the basis of your application.
      Projects
      BookBrainz
      BookBrainz is a database of book metadata.
      We're interested in projects that help us reach our roadmap, and that add major functionalities to the website.
      Please see our ideas page for more details and information on getting started.
      Top 3 Desired Skills: Node.js, React, PostgreSQL
      Ideas page | Main page | Forums
      ListenBrainz
      An open source music website that allows users to import their listen history. One of the goals is for this data to be used for building open music recommendation systems.
      Languages/skills: Python, Flask, PostgreSQL, Spark, React, Android
      Ideas page | Main page | Forums
      MusicBrainz
      A community-maintained open source music encyclopedia that collects music metadata and makes it available to the public.
      Languages/skills: JavaScript (React), PostgreSQL, Rust
      Ideas page | Main page | Forums
      MetaBrainz
      A non-profit that believes in free, open access to data. It is the parent organization responsible for maintaining all other projects listed on this page.
      Languages/skills: TBD language, Docker, Postgres
      Ideas page | Main page | Forums
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/metabrainz-foundation-inc/
    idea_list_url: https://wiki.musicbrainz.org/Development/Summer_of_Code/2025

  - organization_id: 93
    organization_name: Micro Electronics Research Lab - UITU
    no_of_ideas:
    ideas_content: |
      Welcome to the project ideas list for GSoC'25. You are allowed to choose any given project to work on with us or you can suggest your own idea as well.
      We encourage you to join our Discord Server (gsoc-2025) to discuss ideas. Please use the recommended Proposal Format for all projects and you can see the detailed timeline here.
      Project 01: Integrating TCAM IP into Chipyard via MMIO and RoCC Interfaces
      Difficulty: Hard
      Designation: 350 hours (large)
      Required Skills & Tools: CHISEL, Verilog, C/C++.
      Mentors: Shahzaib Kashif, Dr. Ali Ahmed, Sajjad Ahmed
      Chat Channel: Discord Channel
      Overview:
      This project aims to integrate a Ternary Content Addressable Memory (TCAM) IP with our forked version of Chipyard as both a Memory-Mapped I/O (MMIO) peripheral and a RoCC (Rocket Custom Coprocessor) accelerator. The TCAM is a high-speed search memory that enables efficient lookup operations, making it useful for applications such as networking, security, and database acceleration.
      The key objectives of this project are:
      MMIO Integration: Attach the TCAM IP as an MMIO device within the Chipyard SoC. This will allow the core to communicate with the TCAM using standard memory operations.
      RoCC Integration: Implement the TCAM as a RoCC accelerator, leveraging the Rocket Core’s RoCC interface for direct communication with the processor.
      Software Interface: Develop a user-space software library or API that enables applications to interact with the TCAM seamlessly. This should include functions for writing, reading, and searching within the TCAM.
      Testing & Verification: Validate the correctness and performance of the integration by writing test programs that run on the generated SoC containing (Core + TCAM as MMIO) and (Core + TCAM as RoCC).
      Expected Outcomes:
      A fully integrated TCAM IP with Chipyard, accessible via both MMIO and RoCC.
      A software library that provides an easy-to-use interface for interacting with TCAM.
      Test programs that demonstrate TCAM functionality on the generated SoC.
      Documentation to help future contributors extend or modify the TCAM integration.
      Skills Required:
      Familiarity with RISC-V and Chipyard framework.
      Experience with Chisel/Verilog for hardware design.
      Knowledge of SoC integration, MMIO, and RoCC interfaces.
      Proficiency in C/C++ for writing the software interface.
      Project 02: A.U.T.O.V.A.R. - Automated UVM Tuning Orchestrated Via AI Reasoning
      Difficulty: Hard
      Designation: 350 hours (large)
      Required Skills & Tools: UVM, SystemVerilog, Python, Machine Learning, NLP, Transformers, Reinforcement Learning, Regression Testing, Hardware Verification.
      Mentors: Dr. Farhan Ahmed Karim
      Chat Channel: Discord Channel
      Overview:
      A.U.T.O.V.A.R. is an AI-powered framework designed to automate the modification of UVM components (drivers, monitors, scoreboards, sequences) based on evolving DUT specifications. By leveraging NLP and ML, the system extracts key parameters from DUT documentation and updates verification environments accordingly. Reinforcement learning ensures that the generated UVM components are validated against regression tests and optimized for coverage. This project aims to minimize manual effort, reduce human error, and accelerate the verification cycle in hardware design.
      Methodology
      DUT Specification Analysis
      Use natural language processing (NLP) and machine learning (ML) to parse DUT specifications (e.g. interface documents, or protocol standards).
      Extract key parameters: signal names, timing requirements, protocol rules, and transaction formats.
      UVM Component Modification
      Train an A.I. model (e.g., a transformer-based architecture) to map DUT changes to UVM component updates:
      Drivers/Monitors: Adjust transaction generation/collection logic based on new signal timing or protocol rules.
      Scoreboards: Update reference models and error-checking algorithms to reflect DUT functionality.
      Sequences: Regenerate test sequences to cover new scenarios or constraints.
      Use reinforcement learning (RL) to validate modified components against regression tests and optimize for coverage.
      Enable real-time feedback loops: Test failures trigger iterative AI refinement of UVM components.
      Expected Outcomes:
      AI-powered parser for DUT specifications using NLP
      Automated UVM component adaptation based on DUT changes
      Integration of reinforcement learning for optimizing verification environments
      Real-time feedback loops for iterative UVM refinement
      Improved verification efficiency and reduced manual workload
      Project 03: AEGIS - AI-Enhanced Generation of Intelligent Scenarios
      Difficulty: Hard
      Designation: 350 hours (large)
      Required Skills & Tools: UVM, SystemVerilog, Python, Machine Learning, NLP, Reinforcement Learning, Hardware Verification, ASIC/FPGA Design, AXI/PCIe/USB Protocols.
      Mentors: Dr. Farhan Ahmed Karim, Shahzaib Kashif
      Chat Channel: Discord Channel
      Overview
      AEGIS is an AI-driven framework designed to automate the generation of optimized test cases for hardware verification. Using NLP, the system extracts key features from DUT specifications and synthesizes test scenarios targeting corner cases, protocol compliance, and functional coverage. Reinforcement learning helps prioritize high-impact tests to maximize verification efficiency. The generated test cases are integrated into UVM environments with automated sequences, scoreboard checks, and assertions.
      Methodology
      DUT Specification Parsing
      Use NLP to analyze DUT specifications (e.g. protocol standards, or natural-language requirements).
      Extract critical features: interfaces, timing diagrams, protocol rules, and functional modes.
      Test Case Synthesis
      Train an A.I. model to map DUT specifications to test scenarios, including:
      Corner Cases: Stress tests for boundary conditions (e.g., FIFO overflow, clock domain crossings).
      Protocol Compliance: Tests for adherence to standards like AXI, PCIe, or USB.
      Functional Coverage: Scenarios targeting untested logic in the DUT.
      Use reinforcement learning (RL) to prioritize high-impact tests that maximize coverage metrics.
      Integration with Verification Environment
      Generate UVM-compatible test sequences, scoreboard checks, and assertions.
      Expected Outcomes
      AI-powered DUT specification parser using NLP
      Automated test scenario generation covering corner cases, protocol compliance, and functional coverage
      Reinforcement learning-based test prioritization for enhanced coverage
      UVM-compatible test sequences, assertions, and scoreboard integration
      Improved verification speed and reduced manual test generation effort
      Project 04: AURUM - Automated UVM Reference of Userspec Model
      Difficulty: Hard
      Designation: 350 hours (large)
      Required Skills & Tools: UVM, SystemVerilog, Python, NLP, Machine Learning, Formal Verification, SMT Solvers, Hardware Verification, Behavioral Modeling.
      Mentors: Talha Ahmed
      Chat Channel: Discord Channel
      Overview
      AURUM is an AI-driven framework that automates the generation of high-accuracy golden/reference models from DUT specifications. Using NLP, the system extracts functional requirements, protocols, and constraints to generate executable golden models. AI-based behavioral cloning ensures high-fidelity mapping from specifications to code, while self-validation techniques, including formal verification and adaptive learning, ensure correctness. This approach reduces manual model development efforts, minimizes human error, and accelerates verification cycles.
      Methodology
      Specification Analysis
      NLP Parsing: Extract functional requirements, protocols, and timing constraints from DUT specifications (text documents, or UML diagrams).
      Contextual Understanding: Use A.I. model to infer implicit requirements (e.g., "FIFO depth = 16" implies overflow/underflow conditions).
      Model Generation
      Code Synthesis: Convert parsed specifications into executable golden models.
      Example: Translate "32-bit CRC32 calculator" into a Python function using the IEEE 802.3 polynomial.
      Behavioral Cloning: Train A.I. models on existing golden model-DUT pairs to learn specification-to-code mappings.
      Self-Validation
      Consistency Checks: Use formal methods (e.g., SMT solvers) to verify AI-generated models against specifications.
      Adaptive Learning: Refine models using test failures and coverage feedback from verification environments.
      Expected Outcomes
      AI-powered specification parser to extract DUT functionalities
      Automated synthesis of golden/reference models from specifications
      Behavioral cloning for learning specification-to-code mappings
      Formal verification and self-validation using SMT solvers
      Integration with UVM-based verification environments
      Project 05: General Test Bench for RISC-V CPUs Using PYUVM
      Difficulty: Medium
      Designation: 350 hours (large)
      Required Skills & Tools: UVM, SystemVerilog, Python, Functional Verification, Hardware Verification, Behavioral Modeling.
      Mentors: Zeeshan Rafique
      Chat Channel: Discord Channel
      Overview
      With the increasing adoption of RISC-V as an open-source Instruction Set Architecture (ISA), there is a growing need for effective and reusable verification methodologies. This project aims to develop a general test bench for RISC-V CPUs using pyuvm, a Python-based Universal Verification Methodology (UVM) framework. The goal is to create a structured, reusable, and automated verification environment that facilitates CPU validation, functional correctness, and compliance testing.
      Benefits to the Community
      Unified Verification Framework : Provides a consistent and reusable test environment across different RISC-V CPU implementations.
      Accessibility: Uses Python and pyuvm, making UVM-based verification more accessible to a broader audience.
      Automation: Supports automated test execution and result analysis, reducing the manual effort in CPU verification.
      Compliance and Debugging: Ensures conformance with the RISC-V specification and aids in debugging CPU designs.
      Methodology
      Test Bench Architecture:
      Modular design with transaction-level modeling.
      Sequence generation for instruction execution.
      Coverage collection and analysis.
      Integration with RISC-V Simulators:
      Support for Verilator and Spike.
      Automated simulation result analysis.
      Test Suite Development:
      Basic functional tests (ALU, control flow, memory access, etc.).
      Compliance tests for RISC-V ISA validation.
      Directed and random instruction sequences for robustness.
      Automation and Reporting:
      Python-based scripting for test execution.
      Logging and result visualization.
      Expected Outcomes
      A generic test bench framework for RISC-V CPUs using pyuvm.
      A set of reusable test cases covering core CPU functionalities.
      Integration with open-source RISC-V simulators (e.g., Verilator, Spike).
      Scripts for automated testing and reporting.
      Documentation on usage and extension.
      Skills Required to standout:
      Familiarity with RISC-V architecture and CPU design.
      Experience with Python-based verification frameworks.
      Knowledge of UVM and hardware simulation tools.
      Basic understanding of Formal verification.
      Understanding of Verilator, Spike, or other RISC-V simulators (preferred).
      Future Enhancements:
      Extend coverage to advanced RISC-V features (e.g., vector extensions, privileged mode testing).
      Integrate with formal verification tools.
      Support multi-core RISC-V CPU verification.
      References:
      PYUVM Documentation
      Cocotb
      RISC-V Specifications
      RISC-V Spike Simulator
      Verilator
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/micro-electronics-research-lab-uitu/
    idea_list_url: https://github.com/merledu/Google-Summer-of-Code/wiki/GSoC'25-Project-Ideas-List

  - organization_id: 94
    organization_name: Mixxx
    no_of_ideas:
    ideas_content: |
      Student Project Ideas for Google Summer of Code 2025
      This page lists the suggested tasks to build a 90 hour (small sized) a 175 hour (medium sized) or 350 hour (large) project for Google Summer of Code 2025. The ideas are already assigned to example projects, but you are encouraged to use them for building your own project adding your own ideas and make it suit perfectly to you, your skills and your time line.
      If you are interested in applying to GSoC, read GSoC Advice before applying or getting involved. Only beginner contributors that are active members of the Mixxx community are accepted. If this is not the case yet, just say hello at https://mixxx.zulipchat.com and discuss your Ideas and discus cases with us.
      Adding an AI infrastructure with cross-platform hardware acceleration
      Typical AI applications in the DJ environment (STEM separation, music analysis) require very high computing power. However, as the commercial DJ software DJay Pro demonstrates, it is possible to perform these on modern laptop hardware in real time with high audio quality. This is made possible by the use of the dedicated Neural Processing Unit (NPU) or powerful Graphical Processing Units (GPU). As cross-platform software, Mixxx must be able to do this on:
      macOS (ARM M1/2 with Neural Engine NPU)
      macOS (x64 with GPU only)
      Linux with various NPU and GPU solutions from different manufacturers
      Windows with various NPU and GPU solutions from different manufacturers
      Today, there is only one AI framework that supports full hardware acceleration across all these platforms, which is ONNX Runtime (onnxruntime.ai). This project is about the integration of ONNX Runtime with ExecutionProviders for CPU (all operating systems), as well as at least one NPU or GPU acceleration solution into Mixxx. This project explicitly includes contributions to third-party projects, in particular to the package managers VCPKG and the Linux distribution Debian/Ubuntu, which Mixxx uses to integrate dependencies. A further aspect to handle is, that these libraries, as well as, the AI models itself are significiantly larger than the current dependencies that come with Mixxx. This requires the development of suitable solutions for the continuous code integration (CI) and for the distribution to the end users.
      Expected Outcome: ONNX Runtime with ExecutionProviders for CPU (all operating systems), as well as at least one NPU or GPU acceleration solution builds within the Mixxx environment. All changes on third-party code is contributed upstream to the particuar projects.
      Skills: Knowledge of CMake, C++. Basic experience with contributing packages to package managers/Linux distributions.
      Possible Mentor: Jörg
      Difficulty: Medium
      Size: 350 h
      Converting Demucs v4 (Hybrid Transformer) AI model to ONNX format
      With Demucs v4 https://github.com/adefossez/demucs, there is a high quality stem separation model available as OpenSource. But, this is a PyTorch model that cannot be used in a C++ project with support for any kind of acceleration hardware. To allow this, the model needs to be converted to the ONNX format to run in ONNX Runtime. This conversion is not trivial, as the DSP functions required for most audio applications are not equivalent in PyTorch and ONNX. In particular, the short-time Fourier transformations STFT/ISTFT must be remodeled in ONNX to enable the automatic ONNX export of PyTorch. It must be demonstrated that the exported ONNX model produces equivalent results as the original PyTorch model. Therefore a minimal C/C++ command line program supporting MP3 files and embedding ONNX Runtime and the exported model should be created.
      Expected Outcome: The model runs in ONNX Runtime and generates similar results as the original
      Skills: Basic knowledge of C/C++. Sound experience with the creation of AI models - preferably in ONNX.
      Possible Mentor: Jörg
      Difficulty: Difficult
      Size: 175 h
      AI music analyzer to detect Beats, Downbeats, Phrases
      While Mixxx has a solid analyzer for beat/tempo detection, it is traditionally DSP-based, while the state of the art has moved to a hybrid approach of AI models that include some DSP routines for data pre-processing. Commercial DJ software with such AI music analyzers (DJay Pro, DJ Studio) demonstrates virtually always perfect beat recognition in DJ Medien's tests, even on challenging tracks with a variety of tempo changes. There are OpenSource music analyzer models available, nanmely https://github.com/JoergAtGithub/all-in-one (https://huggingface.co/spaces/taejunkim/all-in-one / https://taejun.kim/music-dissector/0427_justthewayyouare). While a science project with impressive results, this is a PyTorch model that cannot be used in a C++ project with support for any kind of acceleration hardware (it's based on the Demucs HT model above), also here an ONNX model is needed. This project is about building an infrastructure that allows Mixxx developers to optimize the analyzer, check the correctness of the results and generate production-ready ONNX models for the Mixxx DJ software in an automated workflow. In particular, the process when a user reports a track with incorrectly detected beats/downbeats/phrase-length/phrase-type and we need to optimize the model needs to be implemented. The main focus of this process is to ensure that the optimization for one track does not lead to worse recognition for other tracks.
      Skills: Knowledge of C/C++. Sound experience with the creation of AI models - preferably in ONNX.
      Possible Mentor: Daniel Schürmann
      Difficulty: Difficult
      Size: 175 h
      AI driven STEMS seperator
      Currently creation of stem files files is a manual process in preparation of a DJ set. Many DJs can't effort the time and the storage space for extracting stem files. In this project a temporary stem file shall be created on demand from the Mixxx GUI. Part of the project shall be evaluation of already published algorithms. Integration of one of them into the Mixxx analyzer and handling of the caching an the required GUI for this feature.
      Expected Outcome: Playing and remixing of stem files
      Skills: Good understanding of sound processing, C++
      Possible Mentor: ?
      Difficulty: Medium
      Size: 175 h
      Using The Harmonix Set to automatically evalute the output of our music analyzers
      The Harmonix Set https://github.com/urinieto/harmonixset repository contains human annotated labels for 912 Western Pop music tracks. This is a great base to benchmark current and future music analyzers in Mixxx. This project is about the automatic execution of the Mixxx Analyzer in a local development environment using all tracks of the Harmonix Set, that are available on the developer's local hard disk and generate a report that visualizes the deviations.
      Expected Outcome: A lightweight tool or script that can be executed out-of-the-box on Windows, macOS and Linux.
      Skills: Experience C++ and a common scripting environment like Python
      Music files: The Mixxx project cannot provide the music files, so the students must have a larger number of the music files listed in The Harmonix Set available themselves.
      Possible Mentor: Jörg
      Difficulty: Easy
      Size: 175 h
      Streamline Search-possibilities.
      To give users to use their track collection optimal, they need all kinds of search possibilities. At the moment Mixxx has a lineEdit (with memory to recall previous searches) which converts the input to a sql-query. In the library and in the players users can find 'related' tracks, based on similar artist, bpm, key. We have some on-going projects (like SearchCrates and a popup FastSearch) to extend the search-engine and we started a survey to get a picture of our users concrete wishes. This project consists in:
      streamlining all search-possibilities,
      making combinations between the different possibilities concrete
      creating features to help users without database background to create a complex search
      fine tuning and optimizing searches in speed and result
      possibility to create a keywords-table to speedup searches
      Expected Outcome: An integrated search engine that combines all possibilities to search and store the results in a user-friendly way, according to the results of the user survey.
      Skills: Logic in SQL, affinity with music, notions of DJ-ing, C++, lots of enthusiasm.
      Possible Mentor: Evelynne
      Difficulty: Medium
      Size: 175 h (or more depending on the project proposal)
      Sharp Scratching
      Currently crossfader changes are stretched on audio buffer time to avoid pop sounds. This is too long for some scratching styles. During this project you need to dive into the audio engine code find the code that is responsible for crossfading and make it independent from the audio buffer size.
      https://github.com/mixxxdj/mixxx/issues/8899 https://github.com/mixxxdj/mixxx/issues/11253
      Expected Outcome: Cut type crossfader curve, suitable for scratching.
      Skills: Good understanding of sound processing, C++
      Possible Mentor: Daniel Schürmann
      Difficulty: Medium
      Size: 175 h
      Auto completion for the Genre track metadata
      Mixxx allows to assign a Genre to a track. This is currently a free text field that allows different spellings for the same Genre like Hiphop, Hip-Hop or Hip Hop. If you use all of these, you will not see all tracks when filtering. This project shall fix it, by auto-complete the Genre when entering, to genres that are already used for other tracks in the library. It shall be also allowed to add additional Genres to a track. This project can be extended by implementing a Tree of Genres for lookup and by auto suggesting a Genre from Discogs or MusicBrainz. https://musicbrainz.org/genres
      Expected Outcome: A new auto completer for the Genre edit box
      Skills: Basic SQLite, Basic C++
      Possible Mentor: Daniel Schürmann
      Difficulty: Easy
      Size: 90 h
      Resample options
      Mixxx uses a linear resample when scratching. This is blazing fast, but the sound can be improved. Here Mixxx should provide more resample options. This project involves to review the already used resample libraries RubberBand and Soundtouch and compare them with other candidates. The one with the best Sound/CPU load trade of shall be selected. Make sure that it supports on the fly changing of the sample rate without artefacts. This project may also involve to contribute a missing feature to such library.
      https://github.com/mixxxdj/mixxx/issues/9328
      Expected Outcome: Optional replacement of the linear resampler.
      Skills: Good understanding of sound processing, C++
      Possible Mentor: Daniel Schürmann
      Difficulty: Easy
      Size: 175 h
      Something Else!
      As always with Summer of Code, you aren't limited to the suggestions we've made here. If you've got a great idea for a project involving Mixxx then we're looking forward to hearing about it. We recommend spending more than a few days using Mixxx and participating in the community to develop a better understanding of areas where Mixxx could use improvement. Our issue tracker is full of feature requests and other ideas scattered throughout, so if you browse through it, you may find many more ideas for GSoC projects.
      IMPORTANT: You should contact us first to get feedback if you're going to submit a proposal for your own project idea! We very rarely approve ideas students propose. If you're not already experienced with DJ equipment, we recommend sticking with one of the ideas above.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/mixxx/
    idea_list_url: https://github.com/mixxxdj/mixxx/wiki/GSOC-2025-Ideas

  - organization_id: 95
    organization_name: National Resource for Network Biology (NRNB)
    no_of_ideas:
    ideas_content: |
      Skip to content
      Navigation Menu
      Product
      Solutions
      Resources
      Open Source
      Enterprise
      Pricing
      Search or jump to...
      Sign in
      Sign up
      Dismiss alert
      nrnb
      /
      GoogleSummerOfCode
      Public
      Notifications You must be signed in to change notification settings
      Fork 46
      Star 134
      Code
      Issues
      23
      Pull requests
      Discussions
      Actions
      Projects
      Security
      Insights
      Additional navigation options
      Preview
      Issues
      Search Issues
      is:issue
       state:open
       Labels
      Milestones
      New issue
      Search results
      Open
      23
       (23)
      Closed
      234
       (234)
      Author
      Labels
      Projects
      Milestones
      Assignees
      Types
      Newest
      Chatbot to query VCell modeling resources
      Difficulty: Medium
      GUI
      LLM
      Machine learning
      Modeling
      Python
      RDF
      REST
      SBML
      Scheme
      Size: 175h
      VCell
      Status: Open.
      #263 
      In nrnb/GoogleSummerOfCode;
      · vcellmike opened 2 days agoon Mar 12, 2025
      2
      comments
      Curation Support Tools for the Creation of a Lung Cancer Disease Map
      Difficulty: Medium
      LLM
      Python
      Size: 175h
      Status: Open.
      #262 
      In nrnb/GoogleSummerOfCode;
      · cannin opened 2 weeks agoon Feb 28, 2025
      7
      comments
      Optimization of SBOannotator for Dynamic Term Integration and AI Enhancement
      Difficulty: Medium
      GUI
      LLM
      Python
      REST
      SBML
      Size: 175h
      Status: Open.
      Feature
      #261 
      In nrnb/GoogleSummerOfCode;
      · NantiaL opened 2 weeks agoon Feb 28, 2025
      8
      comments
      Using GraphRAG for Automated Data Analysis with LLMs to Explore Cancer Pharmacogenomics Data
      Difficulty: Medium
      LLM
      Python
      R
      Shiny
      Size: 175h
      Status: Open.
      #260 
      In nrnb/GoogleSummerOfCode;
      · cannin opened last monthon Feb 15, 2025
      12
      comments
      Enhancing the Systems Biology Simulation Core Library (SBSCL) with a Solver-Agnostic Framework for Constraint-Based Simulation and Analysis
      Difficulty: Medium
      Java
      SBML
      Size: 175h
      Status: Open.
      Feature
      #259 
      In nrnb/GoogleSummerOfCode;
      · draeger opened on Feb 9on Feb 9, 2025
      4
      comments
      A highly efficient numerical ordinary differential equation solver in the Systems Biology Simulation Core Library
      C++
      Difficulty: Medium
      High-performance computing
      Java
      SBML
      SED-ML
      Size: 175h
      Status: Open.
      Feature
      #258 
      In nrnb/GoogleSummerOfCode;
      · draeger opened on Feb 9on Feb 9, 2025
      8
      comments
      Development of a converter between SBOL2 and SBOL3 in Python
      Difficulty: Hard
      Python
      SBOL
      Size: 350h
      Status: Open.
      #257 
      In nrnb/GoogleSummerOfCode;
      · Gonza10V opened on Feb 6on Feb 6, 2025
      6
      comments
      cy3sbml update: major fixes, library upgrades, and new features
      Cytoscape
      Difficulty: Medium
      Java
      SBML
      Size: 175h
      Status: Open.
      #256 
      In nrnb/GoogleSummerOfCode;
      · matthiaskoenig opened on Feb 4on Feb 4, 2025
      7
      comments
      BioSeqJournal: Julia Journaled Sequences Library
      C++
      Difficulty: Hard
      Julia
      Size: 175h
      Status: Open.
      #255 
      In nrnb/GoogleSummerOfCode;
      · marcoxa opened on Jan 28on Jan 28, 2025
      7
      comments
      Refactor Cytosnap to use Playwright
      Canvas
      Cytoscape.js
      Difficulty: Easy
      JavaScript
      Size: 175h
      Status: Open.
      #254 
      In nrnb/GoogleSummerOfCode;
      · maxkfranz opened on Jan 27on Jan 27, 2025
      11
      comments
      Web-Based Interactive Visualization to integrate Geneset Analysis with DBRetina
      CSS
      Cytoscape.js
      Difficulty: Medium
      HTML
      JavaScript
      Size: 175h
      Status: Open.
      #251 
      In nrnb/GoogleSummerOfCode;
      · MoHelmy opened on Jan 25on Jan 25, 2025
      25
      comments
      Integrating DBRetina with an LLM-Powered Chatbot for Genomic Data Exploration
      C++
      CSS
      Difficulty: Hard
      HTML
      LLM
      Machine learning
      Size: 175h
      Status: Open.
      #250 
      In nrnb/GoogleSummerOfCode;
      · MoHelmy opened on Jan 25on Jan 25, 2025
      12
      comments
      Website for VCellDB.org
      CSS
      Difficulty: Medium
      HTML
      Java
      JavaScript
      JSON
      REST
      Size: 175h
      VCell
      web services
      XML
      Status: Open.
      #249 
      In nrnb/GoogleSummerOfCode;
      · vcellmike opened on Jan 24on Jan 24, 2025
      20
      comments
      COBRAxy: spatial and single-cell metabolic modelling
      Difficulty: Medium
      Galaxy
      Python
      Size: 175h
      Status: Open.
      #248 
      In nrnb/GoogleSummerOfCode;
      · kiaradamiani opened on Jan 22on Jan 22, 2025
      14
      comments
      Improving Cytoscape.js layout utilities
      Cytoscape.js
      Difficulty: Hard
      JavaScript
      Size: 175h
      Status: Open.
      #247 
      In nrnb/GoogleSummerOfCode;
      · ugurdogrusoz opened on Jan 22on Jan 22, 2025
      5
      comments
      Automating the constructions of datasets from SynBioHub to streamline the trainning of ML models on standardized data in SBOL
      Difficulty: Medium
      Machine learning
      Python
      SBOL
      Size: 175h
      Status: Open.
      #246 
      In nrnb/GoogleSummerOfCode;
      · Gonza10V opened on Jan 17on Jan 17, 2025
      9
      comments
      Assisting the creation of SBGN diagrams using large language models (LLMs)
      CSS
      Difficulty: Medium
      HTML
      JavaScript
      LLM
      SBGN
      Size: 175h
      Status: Open.
      #245 
      In nrnb/GoogleSummerOfCode;
      · hasanbalci opened on Jan 10on Jan 10, 2025
      10
      comments
      Getting the complexity score from SBOL files to streamline DNA synthesis using standards
      Difficulty: Medium
      Python
      SBOL
      Size: 175h
      Status: Open.
      #241 
      In nrnb/GoogleSummerOfCode;
      · Gonza10V opened on Mar 26, 2024on Mar 26, 2024
      8
      comments
      Cytoscape Automated Testing Suite for Biomedical Visualization
      Cytoscape
      Difficulty: Medium
      JavaScript
      Python
      REST
      Size: 175h
      Status: Open.
      #233 
      In nrnb/GoogleSummerOfCode;
      · jingjingbic opened on Jan 15, 2024on Jan 15, 2024
      10
      comments
      Large Network Renderer
      Cytoscape
      Difficulty: Medium
      Hierarchical network
      HiView
      JavaScript
      JSON
      NDEx
      OpenGL
      Size: 175h
      Status: Open.
      #229 
      In nrnb/GoogleSummerOfCode;
      · jingjingbic opened on Jan 12, 2024on Jan 12, 2024
      13
      comments
      Cytoscape.js extension template using ESM
      Cytoscape.js
      Difficulty: Easy
      JavaScript
      Size: 175h
      Status: Open.
      #223 
      In nrnb/GoogleSummerOfCode;
      · maxkfranz opened on Mar 2, 2023on Mar 2, 2023
      29
      comments
      Prototype COSE Network Layout Algorithm to Support Biological Context for Layouts More Intuitive to Humans
      Cytoscape.js
      Difficulty: Medium
      JavaScript
      JSON
      Size: 175h
      Status: Open.
      #219 
      In nrnb/GoogleSummerOfCode;
      · cannin opened on Jan 21, 2023on Jan 21, 2023
      15
      comments
      Making biological network knowledge discoverable and accessible on search engines
      CSS
      Difficulty: Easy
      HTML
      JavaScript
      Python
      Size: 175h
      XML
      Status: Open.
      #218 
      In nrnb/GoogleSummerOfCode;
      · cannin opened on Jan 21, 2023on Jan 21, 2023
      48
      comments
      Footer
      © 2025 GitHub, Inc.
      Footer navigation
      Terms
      Privacy
      Security
      Status
      Docs
      Contact
      Manage cookies
      Do not share my personal information
      0 suggestions
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/national-resource-for-network-biology-(nrnb)/
    idea_list_url: https://github.com/nrnb/GoogleSummerOfCode/issues


  - organization_id: 96
    organization_name: Neovim
    no_of_ideas:
    ideas_content: |
      Introduction
      Neovim is a text editor based on Vim. One of the main project goals is to encourage hacking and collaboration.
      Project ideas for Google Summer of Code are tracked as issues with the "gsoc" label.
      These projects may require familiarity with C, Lua, and Vimscript.
      Documentation for Neovim developers is here: https://neovim.io/doc/user/develop.html
      The Neovim source has roots going back to 1987 which means libraries such as libuv were not around at that time. The codebase can be made easier to maintain and understand by using these libraries. Project ideas that involve working heavily with internals will in general be more difficult than project ideas that "simply" add new features. However working with older/complex parts of the code base can also provide valuable learning feedback for writing simpler and more maintainable code.
      Getting started
      Proposals are tracked as issues with the "gsoc" label. We are happy to hear other ideas you may have, just create a new issue and mention that it's for GSoC. Because communication is a big part of open source development you are expected to get in touch with us before making your application. See Where to ask questions.
      To get familiar with the project,
      read CONTRIBUTING.md
      try a small coding task (choose from complexity:low issues)
      Note: this year we will likely accept 1-2 students. We expect to get more strong proposals than available slots, so we will need to turn some good proposals down.
      Where to ask questions
      Ask questions here:
      https://github.com/neovim/neovim/discussions
      https://matrix.to/#/#neovim:matrix.org
      Do not ask general GSoC questions on the issue tracker. Do use the issue tracker to ask specific technical questions about your proposal. Do not ask "where do I start?" on the issue tracker.
      Making a proposal
      The application period for GSOC is March 24 - April 8 (Timeline). Send your proposal through the GSOC page. We encourage students to send a first draft early in this period, this allows us to give feedback and and ask for more information if need.
      "Writing a proposal" guidelines
      Proposal evaluation criteria
      Below are some suggested issues. These are starting points. Your proposal should start with (1) a "Problem" section that describes the problem being solved, followed by (2) your proposed solution to the problem, including implementation details and constraints.
      Tips
      Anywhere a Vim concept (such as "textlock") is mentioned, you can find what it means by using the :help command from within neovim (:help textlock).
      Ask questions and post your partial work frequently (every 1-2 days, if possible). It's OK if work is messy; just mark the pull request (PR) as "Draft".
      Take advantage of the continuous integration (CI) systems which automatically run against your pull requests. When you send work to a PR, the full test-suite runs on the PR while you continue to work locally.
      Only a text editor, cmake, and a compiler are needed to develop Neovim. LSP is very helpful also.
      See :help dev-tools and CONTRIBUTING.md for documentation on building, debugging, and development tips.
      GSoC Ideas 2025
      Proposals are tracked as issues
      Choose an existing issue, or create a new issue.
      Below are some suggested issues. These are starting points. Your proposal should start with (1) a "Problem" section that describes the problem being solved, followed by (2) your proposed solution to the problem, including implementation details and constraints.
      AI primitives
      Size: 175 hours
      Difficulty: Medium
      Desirable Skills:
      Lua
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Tracking issue: https://github.com/neovim/neovim/issues/32084
      Description:
      Although Nvim doesn't plan to include AI features by default, it should provide basic features that make it easy to build AI plugins (chat, completion, etc.)
      Expected Result:
      Identify and implement Nvim features that make it easy for users to build high-quality AI "chat" and "completion" plugins. For example:
      Support textDocument/inlineCompletion from the LSP 3.18 spec.
      Add a way to mark a buffer or window as "busy" or "in progress", that works with the default statusline (and custom statuslines).
      Add a "progress meter" interface to the Nvim standard library.
      Improvements to the "prompt buffer" concept
      multiline input
      paste into the prompt
      a builtin "filetype" with standard highlighting
      standard headers with distinctive highlighting
      standard mappings
      ...?
      ":restart" command
      Size: 175 hours
      Difficulty: Medium
      Desirable Skills:
      C
      Lua
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Tracking issue: https://github.com/neovim/neovim/issues/32484
      Description:
      Developing/troubleshooting plugins has friction because "restarting" Nvim requires quitting, then manually starting again, in some fashion.
      Expected Result:
      Implement a :restart command which allows Nvim to restart itself. This will involve some knowledge of inter-process communication / RPC.
      Restore :terminal buffers after restart
      Size: 175 hours
      Difficulty: Easy
      Desirable Skills:
      Lua
      C (minimal)
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Tracking issue: https://github.com/neovim/neovim/issues/28297
      Description:
      Currently, the contents of :terminal buffers isn't preserved after Nvim restarts. Or when a :terminal buffer is closed, its contents can't be reloaded.
      Expected Result:
      :terminal buffer contents can be saved to the filesystem.
      User has a way to view saved terminal buffers and reload them.
      Visiting a "mark" in a terminal buffer reloads the terminal buffer if it's not loaded.
      :terminal buffers optionally are included in Nvim "session" files and restored when the session is reloaded.
      "Remote SSH" features
      Size: 350 hours
      Difficulty: Medium
      Desirable Skills:
      Lua
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Tracking issue: https://github.com/neovim/neovim/issues/21635
      Description:
      Working with remote systems could be more "ergonomic". VSCode's "remote ssh" plugin demonstrates how ergonomics can greatly improve usability.
      Expected Result:
      Introduce a command or some sort of interface that Allows the user to:
      input a ssh URI (hostname + port)
      or select from a list of hosts discovered from your local ~/.ssh/config
      nvim connects to the remote ssh endpoint using your local ~/.ssh credentials
      or prompts for password as needed
      nvim starts a new local UI that attaches to a remote nvim server running on the remote machine.
      if necessary, nvim auto-installs itself on the remote machine.
      it also installs your plugins, on the remote!
      the local nvim UI controls the remote nvim server, and you can use it to work on the remote machine very much like a local nvim.
      Visual-first editing
      Size: 350 hours
      Difficulty: Medium-Hard
      Desirable Skills:
      C and Lua
      Familiar with event-loop programming model
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Tracking issue: https://github.com/neovim/neovim/issues/16296
      Description:
      Vim tradtionally has a "verb-object" editing model, whereas editors like kakoune and helix have "object-verb". The existing visual-mode in Nvim could be enhanced to support this in Nvim.
      Expected Result:
      Visual-mode in Nvim becomes more intuitive and useful:
      it can be repeated with dot (.)
      introduce a modifier similar to v, except normal-mode commands work in this mode, after the "selection" is chosen.
      GUI Features
      Size: 175 hours
      Difficulty: Medium-Hard
      Desirable Skills:
      C and related tools
      Familiar with event-loop programming model
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Description:
      Nvim GUIs are implemented as processes communicating with Nvim. Originally the UI protocol exposed most functionality as a single, terminal-like screen grid. Work has been done to allow UIs (including embeddings in GUI editors, like VSCode) to render the screen layout themselves, based on semantic updates from Nvim. Some screen elements like the cmdline, popupmenu and message area has been externalized. As a result of a 2018 GSOC project, windows can be drawn on separate grids.
      Expected Result:
      Further improvements to the GUI protocol.
      Some UIs want to render the buffer contents themselves. A solution would be a UI protocol mode, where the rendered grid is not used, rather all decorations, such as syntax highlighting, conceals, virtual text are transmitted for the current viewport. Such an UI would be able to render text without the restrictions of the builtin monospace grid. Then the UI should be able to inform nvim about usage of virtual columns and wrapping, so that vim commands such as gj are consistent with how text is presented to the user.
      Another path is to improve the core Nvim grid model. We could allow the width and height of cells be different for each row. This would allow for heading text with different font size, and pictures rendered inside windows.
      Putting forward your own ideas of UI improvements is encouraged. Read the docs for the implemented extensions as well as the tracking issue for ongoing/planned work, as a starting point.
      IDE "Vim mode"
      Size: 175 hours
      Difficulty: Medium
      Desirable Skills:
      Familiar with RPC
      Code license: Apache 2.0
      Mentor: Justin M. Keyes (@justinmk)
      Description:
      Implement "Vim mode" in an editor/IDE (such as IntelliJ) by embedding a nvim instance.
      Expected Result:
      Full Nvim editing should be available in the editor/IDE, while also allowing the user to use the native editor/IDE features.
      Examples:
      VSCode integration
      Sublime Text integration
      GSoC Ideas 2019
      (DONE) "Multiprocessing" feature
      Description:
      p2p architecture for data sharing between multiple Nvim instances. Similar to Python's multiprocessing module, the idea is to to offload Nvim tasks (VimL and/or Lua) to child Nvim processes.
      Here's a picture of the potential workflow:
      parent calls invoke_async(Foo)
      parent spawns new child nvim process
      parent sends command name Foo + state to child
      parent does other, unrelated work
      child completes its Foo work
      child sends notification (method name + state) to parent
      Difficulty: Hard
      Code license: Apache 2.0
      Mentor: Justin M Keyes (@justinmk)
      (DONE) TUI (Terminal UI) remote attachment
      Description:
      The built-in UI is called the TUI. It looks like Vim, but internally it is decoupled from the UI and "screen" layout subsystem. It was designed to be able to connect to other (remote) instances of Nvim, but this hasn't been implemented yet. #7438
      Nvim is both a server and a client. Nvim (client) can connect to any other Nvim (server). And Nvim GUIs can show the screen of a remote Nvim server.
      But the built-in Nvim TUI cannot show the screen of a remote Nvim server. That's the goal of this project.
      It is not "live share". It's just showing the remote UI in a client TUI.
      Networking question are out of scope. It is assumed the client has an SSH tunnel or named pipe to connect to.
      The Nvim API model is:
      :help api: general API functions
      :help ui: UI events
      Any client can call any API function.
      If a client calls nvim_ui_attach, then it is a "UI client". This simply means that Nvim will send UI events as msgpack-rpc notifications on the channel.
      That's how every Nvim UI works. And that's how the TUI client (this project proposal) will work.
      Python "demo UI" may be helpful: https://github.com/neovim/python-gui
      The simplest UI is the "fake UI" implemented in test/functional/ui/screen.lua from the Nvim test suite. It creates a text UI from real Nvim UI events. This allows us to write Lua tests that check the state of the UI, by simply writing the text UI in the test. In the Neoivm repo, "git grep 'screen:expect'" shows all of the places where this is used.
      The example_spec.lua test shows a simple example. You can try it by running this shell command:
      TEST_FILE=test/functional/example_spec.lua make functionaltest
      Overview of the screen.lua "fake UI" implementation:
      Screen._wait() / Screen:sleep() runs the event loop to consume UI events
      Screen:_redraw() dispatches UI events to the appropriate handlers
      For example Screen:_handle_grid_line() consumes a line event, and updates some tables (self._grids and self._attr_table).
      And those tables are literally the contents of the fake UI that Screen:expect() tests against.
      Use cases:
      Connect to any Nvim. Unlike tmux, Nvim UI client can connect to any other running Nvim, including GUIs.
      Potential for using libnvim as the RPC core of any Nvim API client, to eliminate the need for clients to implement their own msgpack-RPC handling.
      Expected Result:
      Implement a TUI "remote UI" client. Modify the TUI subsystem so that it can display a remote Nvim instance. The C codebase already has msgpack support, an event-loop, and the ability to connect to sockets/named pipes/etc.
      Extend tui/tui.c to:
      connect to a channel
      get UI events from the channel
      unpack the events and call the appropriate handlers
      Extend tui/input.c to:
      send user input to the channel (i.e. call the nvim_input() API function)
      Example:
      nvim --servername foo
      will connect to the Nvim server at address foo. The nvim client instance sends input to the remote Nvim server, and reflects the UI of the remote Nvim server. So the nvim client acts like any other external (G)UI.
      Difficulty: Medium
      Code license: Apache 2.0
      Mentor: Justin M Keyes (@justinmk), Björn Linse (@bfredl)
      GSoC Ideas 2018
      (DONE) UI protocol improvements
      Description:
      Nvim GUI:s are implemented as processes communicating with Nvim over a protocol. Currently this protocol exposes most functionality as a terminal-like screen grid. A long term goal is enabling richer UIs (including embeddings in GUI editors, like VSCode) by refactoring the protocol towards semantic updates and letting the GUI actually draw buffer contents and other screen elements. Currently this has been implemented for a few specific elements, like the completion popup menu and the command line.
      Expected Result:
      The UI protocol has gained new capabilities. This could involve substantial changes such as the GUI receiving redraw updates for each window separately, so that the GUI could be responsible for managing the overall layout of windows and statuslines.
      Alternatively, improvements could be done within the current global screen grid, such as the ability to display grid-aligned images in signs, buffers and statuslines. It could also involve adding semantic information to the grid, so that GUI:s can identify screen elements reliably rather than guessing it from highlights.
      Code license: Apache 2.0
      Difficulty:
      Medium to Hard
      Student: (@UtkarshMe)
      Mentor: Björn Linse (@bfredl)
      Java client
      Desirable Skills:
      Familiar with Vim/Nvim and Vim script (VimL)
      Moderate/High experience in Java
      Familiar with event-loop programming model
      Description:
      Implement a Nvim API client using Java.
      Implement a client, written in Java, which allows Java applications to control Nvim using the Nvim RPC API. If you are familiar with AWS or any other SaaS, note that a Nvim API client is just like a SDK for a REST web service, except that Nvim uses msgpack, not HTTP/JSON.
      The Nvmi RPC API is documented at :help api and :help rpc.
      To correctly implement the client one needs to understand the msgpack-rpc protocol. Some sort of event-loop mechanism will be needed to handle notifications.
      For reference, you can find clients in other languages at the related projects wiki page.
      The ultimate goal is to have a library that can be used to create plugins for IntelliJ and Eclipse. Minimizing third-party dependencies may help there.
      Expected Result:
      Java library that can be used to build Neovim extensions (UIs and other applications).
      Method signatures generated from nvim --api-info.
      Since nvim is already required (for --api-info), the Java code-generation script could be written in Lua (which is built-in to nvim).
      Passes the test suite used by the Nvim python-client.
      Using the python-client tests as a guide, create equivalent tests using a Java testing framework.
      Test suite should be runnable from the command-line (should not require an IDE) via maven/gradle (or some other industry-standard build-tool).
      Builds (and passes tests) on Linux (Travis CI) and Windows (AppVeyor)
      End-user deliverable should be compatible Java 6 (this is negotiable)
      Source-code can be latest version of Java (no backwards-compatibility requirement)
      Code license: Apache 2.0
      Difficulty:
      Medium
      Mentor: Justin M Keyes (@justinmk)
      (DONE) C# client
      Description:
      Implement a Nvim API client using C#.
      Implement a client, written in C#, which allows C# applications to control Nvim using the Nvim RPC API. If you are familiar with AWS or any other SaaS, note that a Nvim API client is just like a SDK for a REST web service, except that Nvim uses msgpack, not HTTP/JSON.
      The Nvmi RPC API is documented at :help api and :help rpc.
      To correctly implement the client one needs to understand the msgpack-rpc protocol. Some sort of event-loop mechanism will be needed to handle notifications (hint1, hint2).
      For reference, you can find clients in other languages at the related projects wiki page.
      The ultimate goal is to have a library that can be used to create plugins for Visual Studio. Minimizing third-party dependencies may help there.
      Expected Result:
      C# library that can be used to create C#-based Neovim extensions (UIs and other applications).
      Method signatures generated from nvim --api-info.
      Since nvim is already required (for --api-info), the C# code-generation build script could be written in Lua (which is built-in to nvim).
      Passes the test suite used by the Nvim python-client.
      Using the python-client tests as a guide, create equivalent tests using a C# testing framework.
      Test suite should be runnable from the command-line (should not require an IDE) via MSBuild or some other industry-standard build-tool.
      Builds (and passes tests) on Linux (Travis CI) and Windows (AppVeyor)
      Builds against .NET Standard 2.0
      Deliverable should be easy to install as a NuGet (or other) package.
      Source-code can be latest version of C# (no backwards-compatibility requirement)
      Code license: Apache 2.0
      Difficulty:
      Medium
      Student: (@b-r-o-c-k)
      Mentor: Justin M Keyes (@justinmk)
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/neovim/
    idea_list_url: https://github.com/neovim/neovim/wiki/Google-Summer-of-Code#gsoc-ideas-2025


  - organization_id: 97
    organization_name: Neuroinformatics Unit
    no_of_ideas:
    ideas_content: |
      Get involved
      Google Summer of Code
      Google Summer of Code
      Google Summer of Code (GSoC) is a global fully online program whose aim is to bring new developers into open source software. It is a great opportunity to gain experience in real-world software development while helping the open source community. Additionally, GSoC contributors receive a stipend from Google.
      Initially focused on university students, since 2022 the program has expanded to welcome students and all beginner contributors to open source who are 18 years and older to participate.
      In 2025, NIU is participating as a mentoring organization with GSoC for the first time, pairing candidates with NIU developers to work on ~12-week programming projects. So if you are interested in contributing to open source software, this is a great opportunity to get involved!
      How does GSoC work?
      Through the GSoC application process, interested applicants submit project proposals to the various organizations participating in GSoC - in our case, the NIU. Then, the organizations select which proposals they would like to see funded by Google. Successful applicants will spend their summer contributing code to our open source organization under the guidance of our mentoring team.
      Below you can find some more information on the projects that we are putting forward for GSoC 2025, and some guidelines to help you with your application.
      To learn more about the program, we recommend reading the GSoC FAQs and the GSoC Contributor Guide, and having a look at the 2025 Timeline. For general information, see also the GSoC website.
      GSoC NIU Projects 2025
      NIU is offering a variety of projects for GSoC 2025, organized under four of our software tools. Click on a card below to learn more about the project ideas for each tool.
      A project can be one of three sizes: small (90 h), medium (175 h) or large large (350 h). The standard coding period is 12 weeks for medium and large projects, and 8 weeks for small projects.
      However, GSoC contributors can request in their proposal up to a 22-week coding period, if they know they may have other commitments or certain weeks when they will not be able to work full time on their GSoC project. During the project preparation period (called “community bonding period”), both the GSoC contributor and the mentors will agree on a schedule and sign off on it.
      movement
      Markerless pose estimation tools based on deep learning, such as DeepLabCut and SLEAP, have revolutionised the study of animal behaviour. However, there is currently no user-friendly, general-purpose approach for processing and analysing the trajectories generated by these popular tools. To fill this gap, we’re developing movement, an open-source Python package that provides a unified data analysis interface across pose estimation frameworks.
      GSoC NIU Projects 2025: movement
      ethology
      ethology is a Python package in early-development stage, whose aim is to facilitate the application of a wide range of computer vision tasks to animal behaviour research, by providing a unified data analysis interface across these tasks. We plan to support both classic computer vision tasks and deep learning based ones, such as background subtraction, object detection, ID tracking, segmentation, any-point tracking, and any useful combinations between them.
      GSoC NIU Projects 2025: ethology
      BrainGlobe
      BrainGlobe is a community-driven suite of open-source Python tools. The BrainGlobe tools are widely used to process, analyse and visualise images of brains (and other related data) in neuroscientific research.
      GSoC NIU Projects 2025: BrainGlobe
      datashuttle
      datashuttle is a tool to automate neuroscience project folder creation, validation and transfer. It creates and validates projects standardised to the NeuroBlueprint specification. It also allows these folders to be easily synchronised between computers.
      GSoC NIU Projects 2025: datashuttle
      spikewrap
      spikewrap is a package for managing extracellular electrophysiology analysis.
      GSoC NIU Projects 2025: spikewrap
      Apply to GSoC with NIU
      As part of your application to GSoC, you will need to submit a project proposal. To help you with this, we provide some NIU guidelines on how to write a successful proposal to work with us.
      You may also want to checkout other useful application guides, such as:
      the GSoC Contributor Guide: writing a proposal,
      the Python Software Foundation guide,
      the OpenAstronomy one, or
      the INCF one,
      all of which we are closely following. Applicants are given about 2 weeks to complete their applications. For further details see the GSoC Contributor Guide.
      If you are interested in any of the NIU projects on offer, feel free to get in touch on our GSoc Zulip channel with any questions. Please reach out in public channels, rather than via DMs or personal conversations - communicating in the open is a big part of open source! However, if you have any concerns you wish to discuss privately (such as accessibility), please contact one of the organisation admins.
      For clarity, please always use your full name when getting a Zulip account, when registering for the program, and when submitting your project plan.
      Team
      The NIU GSoC team for 2025 is composed of the following members. To read more about the different roles involved in GSoC, see GSoC Participant Roles.
      Our working languages are Python and English ;) - but we also speak other languages! We listed any additional languages spoken by the mentors in each of the projects’ descriptions.
      Adam Tyson
      @adamltyson
      Organisation administrator
      https://github.com/adamltyson
      Sofía Miñano
      @sfmig
      Organisation administrator & mentor
      https://github.com/sfmig
      Alessandro Felder
      @alessandrofelder
      Mentor
      https://github.com/alessandrofelder
      Niko Sirmpilatze
      @niksirbi
      Mentor
      https://github.com/niksirbi
      Igor Tatarnikov
      @IgorTatarnikov
      Mentor
      https://github.com/IgorTatarnikov
      Joe Ziminski
      @JoeZiminski
      Mentor
      https://github.com/JoeZiminski
      Further details
      GSoC NIU Projects 2025
      GSoC NIU Contributor Application Guidelines
      Previous
      Mentored open-source contributions
      Next
      GSoC NIU Projects 2025
      On this page
      How does GSoC work?
      GSoC NIU Projects 2025
      Apply to GSoC with NIU
      Team
      Further details
      This Page
      Show Source
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/neuroinformatics-unit/
    idea_list_url: https://neuroinformatics.dev/get-involved/gsoc

  - organization_id: 98
    organization_name: NumFOCUS
    no_of_ideas:
    ideas_content: |
      Ideas Pages
      This is the home page of projects ideas of NumFOCUS for Google Summer of Code 2025. Since NumFOCUS is an umbrella organization you will only find links to the ideas page of each organization under the NumFOCUS umbrella at this page.
      aeon
      AiiDA
      ArviZ
      conda / rattler
      Data Retriever
      DISCOVER Cookbook
      igraph
      NetworkX
      Open2C
      optimagic
      pvlib
      PyBaMM
      PyMC
      PySAL
      Qutip
      sbi
      SciML
      Stan
      TNL
      toqito
      Zarr
      See the README for contact information of each org.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/numfocus/
    idea_list_url: https://github.com/numfocus/gsoc/blob/master/2025/ideas-list.md


  - organization_id: 99
    organization_name: OSGeo (Open Source Geospatial Foundation)
    no_of_ideas:
    ideas_content: |
      Google Summer of Code 2025 Ideas
      Jump to navigation
      Jump to search
      @
      Back to the main OSGeo Google Summer of Code 2025 wiki page.
      See also ideas from 2024, 2023, 2022, 2021,2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007.
      
      Contents
      1 OSGeo Google Summer of Code 2025
      2 Recent Modifications in GSoC (Must Read)
      3 The ideas pages
      3.1 OSGeo Foundation graduated project
      4 I want to apply as a student
      4.1 Which project do I choose?
      4.2 Important dates
      OSGeo Google Summer of Code 2025
      The Open Source Geospatial Foundation would like to extend a welcome to the interested SoC contributors. On this page, you will find links to a host of ideas organized by project. You will find ideas ranging from the depths of computer science graph theory to the heights of visualization. One thing all these ideas have in common is lots and lots of spatial data.
      These ideas are *only* to motivate you and serve as an example of the kind of hills we want to charge up. Your own ideas are more than welcome - they are encouraged. We view you as the next wave of open-source leaders and the future of the geospatial industry; show us what you've got!
      Contributors: check out the Google Summer of Code Recommendations for Students page.
      If you need more information on how to apply you can contact us on OSGeo's discourse
      Read the GSoC Roles and Responsibilities to understand successful teamwork and interplay of project, mentors, and students.
      There is a Google SoC flyer to look at and post in appropriate places.
      OSGeo is involved in working with maps and things, but what kind of projects does it really do? Have a look at the live blog feed to see what people are working on right now.
      Mentors, there's an additional link providing some tips and specifying your responsibilities on the main OSGeo Google Summer of Code Administrative wiki page.
      Recent Modifications in GSoC (Must Read)
      The program is open to all the students who are 18 years and older AND to the beginners in open source development, who might not be university students but are 18 years and older. With folks around the world changing careers, returning to the workforce, and learning on their own (outside of academic programs) we see an opportunity to reach a plethora of excited individuals who want to learn more about open source and be a part of our amazing GSoC communities. Check Eligibility here.
      GSoC Contributors will be able to choose from multiple-size projects: medium at ~175 hours, large at ~350 hours and small at ~90 hours. This is to remove the barrier of available time that many potential contributors have and open the program to people who want to learn about open source development but can’t dedicate all or even half of their summer to the program.
      We are building increased flexibility around the timing of projects - there is an option to extend the standard 12-week coding time frame to a maximum of 22 weeks. This is to allow folks who may realize that spreading the work over say, 16 weeks, is a more realistic goal with their current life situation. Or for contributors who have life happen in the middle of the program and they can’t work on their projects for a few weeks, but they can come back to it after a month to finish it. This would make it easier for GSoC Contributors and mentors to be able to navigate together when obstacles occur and the GSoC Contributor can successfully complete their project.
      The ideas pages
      To add your page, please contact the GSoC admin team to let them know of your ideas page, by sending an email to gsoc-admin@osgeo.org
      OSGeo Foundation graduated project
      GRASS GIS SoC Ideas: GRASS GIS is an open source GIS focusing on analysis, modeling and visualization. It is a collection of modules written in C and Python and has a GUI written in wxPython. If you know Python, or want to implement algorithms in C, take a look!
      pgRouting Ideas: pgRouting extends the PostGIS / PostgreSQL geospatial database to provide geospatial routing functionality and more.
      ZOO-Project Ideas: The ZOO-Project is a WPS open source project released under a MIT/X-11 style license. It provides support for WPS 1.0.0 and 2.0.0 versions and is able to handle services implemented in various programming languages.
      istSOS Ideas: The istSOS project is sensor data management tool that allows collection, maintenance and publishing of monitoring observations using the Open Geospatial Consortium (OGC) SensorThingsAPI standard.
      
      I want to apply as a student
      Before applying as a student, check out the Google Summer of Code Recommendations for Students page.
      Which project do I choose?
      Most of the software projects are available pre-built on our OSGeoLive { DVD | USB stick | VirtualMachine } with project overviews and short tutorials where you can try everything out.
      View the documents and download the ISO from https://live.osgeo.org
      Important dates
      The official timeline
      [Back to Google Summer of Code 2024 @ OSGeo]
      Category: Google Summer of Code
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/osgeo-(open-source-geospatial-foundation)/
    idea_list_url: https://wiki.osgeo.org/wiki/Google_Summer_of_Code_2025_Ideas


  - organization_id: 100
    organization_name: OWASP Foundation
    no_of_ideas:
    ideas_content: |
      GSoC 2025 Ideas
      Bug Logging Tool (BLT) • OWASP DevSecOps Maturity Model • OWASP Nettacker • OWASP Nest • OWASP Juice Shop • Pygoat • OpenCRE
      Tips to get you started in no particular order:
      Read the Student Guidelines.
      Check our GitHub organization.
      Contact one of the project mentors below.
      List of Project Ideas
      Bug Logging Tool (BLT)
      OWASP BLT is a bug-hunting & logging platform that enables users to hunt for vulnerabilities, participate in bug bounties, and contribute to open-source security. Organizations can leverage BLT to manage vulnerability reports, track security issues, and engage with ethical hackers.
      BLT is a large-scale project with a growing ecosystem, offering full-stack development, security automation, AI-powered analysis, and blockchain-based incentives. This year’s GSoC projects focus on UI/UX improvements, API development, automation, and gamification to enhance the platform’s usability and impact.
      Preference will be given to students who have at least 5 merged PRs before GSoC selection.
      🔹 2025 GSoC Ideas / Large Projects
      🔸 Modern UI/UX Overhaul & Lightweight Front-End in React (~350h)
      A complete redesign of BLT’s interface, improving accessibility, usability, and aesthetics. The new front-end will be built with React and Tailwind CSS, ensuring high performance while maintaining a lightweight architecture under 100MB. Dark mode will be the default, with full responsiveness and an enhanced user experience.
      🔸 Organization Dashboard – Enhanced Vulnerability & Bug Management (~350h)
      Redesign and expand the organization dashboard to provide seamless management of bug bounties, security reports, and contributor metrics. Features will include advanced filtering, real-time analytics, and improved collaboration tools for security teams.
      🔸 Secure API Development & Migration to Django Ninja (~350h)
      Migrate our existing and develop a secure, well-documented API with automated security tests to support the new front-end. This may involve migrating from Django Rest Framework to Django Ninja for improved performance, maintainability, and API efficiency.
      🔸 Gamification & Blockchain Rewards System (Ordinals & Solana) (~350h)
      Introduce GitHub-integrated contribution tracking that rewards security researchers with Bitcoin Ordinals and Solana-based incentives. This will integrate with other parts of the website as well such as daily check-ins and code quality. Gamification elements such as badges, leaderboards, and contribution tiers will encourage engagement and collaboration in open-source security.
      🔸 Decentralized Bidding System for Issues (Bitcoin Cash Integration) (~350h)
      Create a decentralized system where developers can bid on GitHub issues using Bitcoin Cash, ensuring direct transactions between contributors and project owners without BLT handling funds.
      🔸 AI-Powered Code Review & Smart Prioritization System for Maintainers (~350h)
      Develop an AI-driven GitHub assistant that analyzes pull requests, detects security vulnerabilities, and provides real-time suggestions for improving code quality. A smart prioritization system will help maintainers rank issues based on urgency, community impact, and dependencies.
      🔸 Enhanced Slack Bot for Real-Time Security Alerts & Automation (~175h)
      Expand the BLT Slack bot to automate vulnerability tracking, send real-time alerts for new issues, and integrate GitHub notifications and contributor activity updates for teams.
      🔗 More projects & discussions: BLT Milestones
      ✅ Expected Results
      Successfully implementing a fully functional, production-ready feature.
      Contributions must align with BLT’s core security and performance goals.
      Code should adhere to best practices, including security testing, CI/CD integration, and documentation.
      📌 Knowledge Prerequisites
      To contribute effectively, familiarity with at least one or more of the following is recommended:
      Back-End: Python, Django, Django Ninja, SQL
      Front-End: React, Next.js, Tailwind CSS, HTML/CSS
      Blockchain: Bitcoin Ordinals, Solana, Smart Contracts
      AI/ML: NLP, Machine Learning for security analytics
      DevOps & Security: GitHub API, REST API, OAuth, Authentication
      👥 Mentors
      We are actively looking for more mentors! If you have experience in Django, React, Blockchain, or AI, we’d love to have you onboard.
      📌 Confirmed Mentors:
      Donnie (@DonnieBLT on Slack)
      Yash Pandey
      Bishal Das
      Ahmed ElSheikh
      Patricia Waiyego
      Sudhir
      Looking for 4 more mentors!
      🎥 To get up to speed, check out our BLT videos.
      OWASP DevSecOps Maturity Model
      Join us in enhancing the DSOMM, a pivotal tool designed to improve the security and operational efficiency of software development processes. We are looking for passionate students to contribute to two major areas: our main application development in JavaScript and our metric analyzer and collector in Java. Whether you are looking to tackle medium-sized challenges or are ready to embark on a larger project, we have exciting opportunities for you.
      To receive early feedback please:
      put your proposal on Google Docs and submit it to the OWASP Organization on Google’s GSoC page in “Draft Shared” mode.
      Please pick “dsomm” as Proposal Tag to make them easier to find for us. Thank you!
      Medium Feature Pack for the DSOMM Main Application (JS)
      This pack includes tasks that are crucial for enhancing the user experience and functionality of the DSOMM main application. Contributors will address existing issues and add new features:
      Implement a State or Tag for “Not yet assessed”, addressing Issue #241
      Enhance the Excel download feature in “Mapping” by adding assessment information, as discussed in Issue #244
      Refine the handling of subcategories to streamline the organization and presentation of maturity model elements, making the tool more intuitive. See Issue #194
      Introduce the Adding of Diagrams feature to enhance the visualization of DevSecOps processes and maturity levels, as outlined in Issue #183
      Your Idea: Proposals that innovate or enhance the metric collection and analysis process are highly encouraged.
      Large Feature Pack for the metric Analyzer and Collector (Java)
      This pack challenges students to develop the entire workflow from data collection to visualization for DSOMM metrics, including the implementation of a Kafka queue. Projects include:
      Design and implement a collector for OWASP DefectDojo, fetching Mean Time to Resolve (MTTR) and Mean Time to Patch (MTTP) via the defectdjo-client which fetches MTTR/MTTP)
      Develop a collector for Jira, to retrieve information about security tasks.
      Create a collector for Jenkins and Kubernetes, aimed at measuring deployment frequency by team, a key metric in DevOps performance.
      Engineer a collector for GitHub and Bitbucket, to calculate MTTP by tracking pull request opening and merge dates. In addition, check that branch protection is enabled and a .gitignore exists in the root file system.
      Engineer a collector for gitleaks, fetching Mean Time to Resolve (MTTR) and Mean Time to Patch (MTTP)
      Your Idea: Proposals that innovate or enhance the metric collection and analysis process are highly encouraged.
      Please take a look at the architecture digram of DSOMM metricCA. The whole way from the collector to grafana needs to be implemented. Please note that a queue Kafka and Prometheus is currently not implemented and needs to be implemented in the collector and in the metricAnalyzer.
      For Backstage, Jira and Confluence a defined format and tags might be used to identify the corresponding team and type of document (e.g. threat modeling/pentest).
      Prerequisites
      Proficiency in the corresponding programming language (JavaScript for the main application, Java for the metric analyzer and collector)
      Previous contributions to open-source projects are highly desirable, demonstrating your commitment and collaborative skills
      Mentors
      Reach out to us on Slack to discuss these and other ideas!
      Timo Pagel
      Aryan Prasad
      OWASP Nettacker
      OWASP Nettacker is a Modular Automated Penetration Testing/ Information gathering Framework and Vulnerability Scanner fully written in Python. Nettacker can run a variety of scans discovering subdomains, open ports, services, vulnerabilities, misconfigurations, default credentials.
      Explanation of Ideas
      fix scan engine multi-threading/queuing issues
      improve WebUI / add dashboard
      add DefectDojo integration / output report format
      add SARIF output report format
      implement testing framework, get 70% code coverage level
      Getting Started
      Repositories:
      OWASP Nettacker on OWASP GitHub
      Join OWASP Slack and contact us on channel #project-nettacker
      Knowldege Requirements
      Python
      Flask
      HTML/CSS/JavaScript
      previous vulnerability scanning/bug bounty hunting experience
      Mentors
      Sam Stepanyan
      Ali Razmjoo
      Arkadii Yakovets
      OWASP Nest
      OWASP Nest is a comprehensive platform designed to enhance collaboration and contribution within the OWASP community. The application serves as a central hub for exploring OWASP projects and ways to contribute to them, empowering contributors to find opportunities that align with their interests and expertise. Our mission is to drive real-world collaboration and elevate the OWASP organization by addressing key challenges and streamlining processes.
      Repository
      backend
      frontend
      schema
      Technical Stack
      Python, Django, Pytest
      TypeScript, React, Jest
      Chakra UI, Tailwind CSS
      PostgreSQL, Algolia
      Docker, k8s, AWS
      Projects / Ideas
      OWASP Contribution Hub: Aiming to streamline the onboarding process and connect contributors with mentors and impactful projects. This milestone focuses on improving collaboration within the OWASP community.
      OWASP Nest API: The development of REST and GraphQL API endpoints for OWASP Projects, Chapters, Events, and Committees. This milestone will standardize data access across OWASP’s resources.
      OWASP Nest Kubernetes Adoption: This milestone focuses on migrating the OWASP Nest application to Kubernetes, ensuring scalability, reliability, and ease of deployment.
      OWASP NestBot AI agent/assistant: Develop an AI-powered OWASP NestBot Slack assistant that acts as an auto-responder for frequently asked questions, guides users to the appropriate OWASP channels, and handles typical OWASP community queries.
      OWASP Project Health Dashboard: A dashboard for monitoring the health of OWASP projects. This includes tracking vital metrics such as release frequency, issue resolution, and contributor growth.
      OWASP Schema: Developing and extending a standardized schema for OWASP Projects and Chapters. This milestone aims to ensure consistency and ease of integration across OWASP resources.
      OWASP Snapshots: Creating a summary of activities within OWASP projects, chapters, and events, including new blog posts and news, to keep the community informed about recent developments.
      Please visit our planned milestones page or gsoc2025 labeled issues page.
      Your own ideas
      Do you have an idea to improve OWASP Nest? We’d love to hear it, please reach out in Slack to ensure that the idea fits OWASP Nest goals.
      Expected Results
      Your proposal projects/ideas are fully completed.
      Your code follows our existing style guides and passes quality checks, test coverage, etc.
      Getting Started
      Check out our contributing guidelines
      Join OWASP Nest channel #project-nest
      Consider good first issue (if there are any) from OWASP Nest issues page
      Mentors
      Arkadii Yakovets (arkid15r on Slack)
      Kateryna Golovanova (Kate on Slack)
      Tamara Lazerka (Tamara on Slack)
      OWASP Juice Shop
      OWASP Juice Shop is probably the most modern and sophisticated insecure web application! It can be used in security trainings, awareness demos, CTFs and as a guinea pig for security tools! Juice Shop encompasses vulnerabilities from the entire OWASP Top Ten along with many other security flaws found in real-world applications!
      To receive early feedback please:
      put your proposal on Google Docs and submit it to the OWASP Organization on Google’s GSoC page in “Draft Shared” mode.
      Please pick “juice shop” as Proposal Tag to make them easier to find for us. Thank you!
      Explanation of Ideas
      MultiJuicer as a CTF Platform
      MultiJuicer saw some enhancements of its Team Score Board last year. It now is not that far away from being a full-fledged CTF platform of its own. This project should focus on the remaining features needed to make MultiJuicer a fully functional CTF platform. This should include making the Team Score Board visually attractive, flavorfully unique and more competition-oriented. The existing Solution Webhook integration already marks solved challenges automatically, but other information like team cheat score, progress over time etc. are not tracked or displayed today. The MultiJuicer CTF should offer the same features as the Juice Shop CTF tool in order to configure the availability of hints. This should include a way to allow teams to pay for hints with some of their collected points. To avoid issues with bigger teams hacking on the same instance of Juice Shop, a team grouping mechanism could be considered as well. The progress on the CTF Score Board could then be aggregated on group level for different teams/instances.
      Test suite harmonization
      Juice Shop had a full replacement of its end-to-end test suite - from Protractor to Cypress - in its GSoC 2022 project. Now it is time to take on the remainin test suites, especially the Integration/API tests currently running on Frisby.js. That library as not seen updates in 2+ years and it became more and more flaky over the years, causing occasional CI/CD failures and time-consuming retry-mechanisms to keep those in check. A new foundation for these tests is needed. In scope is also to look at the frontend and backend unit test suites, and find a way to reduce the number of test frameworks being used in order to achieve higher consistency and less complexity for maintenance of the project. This project should include the test suites in the Juice Shop CTF tool as well. Proposals that also have the augmentation of MultiJuicer with end-to-end tests in scope, are specially welcome.
      Juice Shop side-project rennovation
      The Juice Shop CTF Tool is currently implemented in vanilla JavaScript. It should be migrated to TypeScript for consistency of maintenance with the main project. Furthermore, the code linting should be adapted to the main Juice Shop ESLint standards. Test coverage and relevance should be reviewed and strengthened where necessary.
      Similarly, the following other sub-projects should be rennovated and brought onto an identical tech stack: Juicy Statistics, Juicy Coupon Bot, Juicy Chat Bot, and Juicy Coupon Lambda.
      Your own idea
      You have an awesome idea to improve OWASP Juice Shop that is not on this list? Great, please submit it!
      Expected Results
      A new feature or improvement of an existing one that makes OWASP Juice Shop even better
      Your code follows our existing styleguides and passes all existing quality gates regarding code smells, test coverage etc.
      Code that you write comes with automated tests that fit into our available test suites.
      Getting started
      Make sure your JavaScript/TypeScript is sufficient to work on the Juice Shop codebase. Check our Codebase 101 here. Students with some experience with (or willingness to learn) Angular and Node.js/Express are usually prefered.
      Read our Contribution Guidelines very carefully. Best make some small contributions before GSoC, so we can see how you work and help you dive into the code even better.
      Get in touch via Slack or email (see below) to discuss any of the listed or your own idea for GSoC!
      Mentors
      Bjoern Kimminich - OWASP Juice Shop Project Leader (bkimminich on Slack)
      Jannik Hollenbach - OWASP Juice Shop Project Leader (Jannik on Slack)
      PyGoat
      PyGoat is an open-source, intentionally vulnerable Python web application designed to help developers and security enthusiasts learn about web application security. It provides hands-on experience in identifying and mitigating common security vulnerabilities, making it a valuable resource for practicing secure coding and penetration testing techniques.
      Repository
      PyGoat
      Skills Required
      HTML/CSS/JavaScript
      Python
      Django
      Docker
      Basic knowledge of application security
      Getting started
      CheckGitHub project and Website.
      Join OWASP Slack and contact us on channel #project-pygoat
      Projects / Ideas
      Refactor the webapp, move away vulnarable labs from the main website.
      Deploy a microservice architecture based approch for the labs.
      Add new labs to the project.
      Improvment of interactive playgrounds.
      Extend labs to other languages as well.
      Prepare for OWASP Top 10:2025 section
      Mentors
      ardiansyah
      Rupak Biswas(Rupak on slack)
      OpenCRE
      OpenCRE is the world’s largest Cybersecurity knowledge graph. It semantically links information between standards, knowledge bases and security tools. Also, it allows users to extend the graph themselves and contains a RAG chatbot implementation. OpenCRE is a great GSOC project if you’re looking to add “Data science/engineering”, “Knowledge Graph and AI” with a focus on Legal Tech and cybersecurity in your CV.
      Repository
      OpenCRE
      Skills Required
      HTML/CSS/React-Typescript
      Python
      Flask
      Docker
      Getting started
      Check the GitHub project and the issues marked as either good first issue , help wanted or GSOC
      Join OWASP Slack and contact us on channel #project-opencre
      Projects / Ideas
      There are many small, medium and large project in the Issues Page tagged with GSOC that we are interested in, depending on your background and interests they are split in the following categories: AI, Frontend, Backend, FullStack. They all contain a bit of frontend and data analysis and graph operations. Priorities for us are:
      Make the gap analysis functionality faster
      MyOpenCRE
      Releasing the Explorer page
      Mentors
      Spyros Gasteratos
      Rob Van Der Veer
      Paola Gardenas
      Edit on GitHub
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/owasp-foundation/
    idea_list_url: https://owasp.org/www-community/initiatives/gsoc/gsoc2025ideas
  

  - organization_id: 101
    organization_name: Open Climate Fix
    no_of_ideas:
    ideas_content: |
      Open Climate Fix: GSoC 2025 Project Ideas #Shared
       Request edit access
       Share
      Sign in
      FileEditViewToolsHelp
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-climate-fix/
    idea_list_url: https://docs.google.com/document/d/1nh6pdIjCTSLWwgFhgIV1gpG8CbIqGyoCFDHOfWmKdwA/edit?usp=sharing

  - organization_id: 102
    organization_name: Open Food Facts
    no_of_ideas:
    ideas_content: |
      GSOC/2025 ideas list
      Jump to navigation
      Jump to search
      Here are ideas for GSOC There are just ideas, and are non limitative.
      IMPORTANT:
      for an introduction on how to candidate, read https://world.openfoodfacts.org/google-summer-of-code
      take also the time to visit our website to understand the project more in depth.
      Contents
      1 Open Food Facts proposals
      1.1 Folksonomy Engine: a one size fit all for any product data
      1.1.1 Description
      1.1.2 Expected outcomes
      1.1.3 Project information
      1.2 Add a way to easily extend the features of the Open Food Facts website, mobile app and reusing apps
      1.2.1 Description
      1.2.2 Expected outcomes
      1.2.3 Project information
      1.3 Moodle Integration Plugin
      1.3.1 Description
      1.3.2 Expected outcomes
      1.3.3 Project information
      1.4 H5P Content Generator
      1.4.1 Description
      1.4.2 Expected outcomes
      1.4.3 Project information
      1.5 Open Food Facts Explorer - a new generation frontend
      1.5.1 Description
      1.5.2 Expected outcomes
      1.5.3 Project information
      1.6 Add Mini Games to the Open Food Facts Mobile App
      1.6.1 Description
      1.6.2 Expected Outcomes
      1.6.3 Project Information
      1.7 Porting Open Prices Features to the Open Food Facts Mobile App
      1.7.1 Description
      1.7.2 Expected outcomes
      1.7.3 Project Information
      1.8 Enhancing Developer Experience Through Automation and Workflow Optimization
      1.8.1 Description
      1.8.2 Expected outcomes
      1.8.3 Project information
      2 Your idea
      3 Project template
      3.1 <DESCRIPTIVE TITLE>
      3.1.1 Description
      3.1.2 Expected outcomes
      3.1.3 Project information
      Open Food Facts proposals
      Folksonomy Engine: a one size fit all for any product data
      Description
      At Open Food Facts we are on a mission to collect any factual data about food products, but also cosmetics, and any products. Modelling every possible products is a challenging task but also topics can be very different based on usage. For example some researchers are interested in knowing the correlation between sugar in cereals and the presence of a cartoon on the front package.
      Faithful to our crowded sourced approach to open data collection, we devised Folksonomy Engine, akin to the way Open Street Map works.
      The basics are there, but we need to make it more easy and efficient to use in order to reach a large public. We must introduce better properties suggestion, reusable widgets and
      Expected outcomes
      The project, should deliver new API features, like suggestion based on popularity and categories, a better handling of nested properties values, tools for exploring and merging values.
      It should also deliver an improved reusable javascript based web interface for display and edition, with maybe some formalization of properties definition.
      The roadmap can be changed while iterating over features, to better achieve the goal of usability by a large variety of contributors.
      Project information
      repository: https://github.com/openfoodfacts/folksonomy_api (and https://github.com/openfoodfacts/folksonomy_frontend)
      Slack channels: #folksonomy_engine
      Potential mentors: Alex G. (slack: Alex G., alex -at- openfoodfacts.org, github: alexgarel), Charles Nepote
      Project duration: 175 hours or 350 hours
      Skills required: Python, Javascript
      Difficulty rating: Medium
      Add a way to easily extend the features of the Open Food Facts website, mobile app and reusing apps
      Description
      Open Food Facts gathers raw product data and computes attributes (e.g. nutritional and environmental scores, allergens) that users can filter and rank products on, and knowledge panels to provide useful and actionable information (e.g. information about ingredients). We already have an internal API for sending attributes and knowledge panels to the Open Food Facts website and mobile app. We now want to make it much easier to our community to create new attributes and knowledge panels to create extensions for our website, app and all the apps that reuse Open Food Facts data.
      Expected outcomes
      The task is to create a standalone system in Python to compute attribute and knowledge panels from the raw JSON product data (we already have a standalone sytem to compute panels for categories that can be reused as a model). The system should make it easy for community developers to create and test new attributes and knowledge panels. As a first use case, the system will provide attributes and panels to let users declare that they do not eat specific ingredients of their choosing.
      Project information
      repository: https://github.com/openfoodfacts/facets-knowledge-panels
      Slack channels: #productopener
      Potential mentors: Stéphane Gigandet, Pierre Slamich, Alex Garel
      Project duration: ~350 hours
      Skills required: Python, JSON REST API
      Difficulty rating: Medium
      Moodle Integration Plugin
      Description
      This project aims to create a bridge between Moodle, a popular learning platform (stats), and Open Food Facts (OFF), the open database of food products. The goal is to facilitate the creation of high-quality educational resources on healthy and sustainable food choices. It will make OFF data easily accessible to course creators. It could also lead teachers and students to contribute data into OFF through educational activities like hunger games, scan parties, etc.
      Expected outcomes
      A Moodle integration plugin for Open Food Facts. This plugin should allow the automatic import of OFF data into:
      Moodle Blocks, to display food information in the side dock (column on the right)
      Moodle Database activitiy and Glossary activity, to make food information accessible in the main course sections
      Moodle Question bank and Quizz activity, for the creation of quizzes
      Ultimately, the project also plans for an OFF Moodle theme and a resource sharing hub like MoodleNet. We may swap one of these items into the project backlog, if a contributor prefers to.
      Project information
      Repo: to be created on May 8
      Slack channels: #summerofcode #education
      Potential mentors: Louis Bastarache
      Project duration: 350 hours
      Skills required: PHP, HTML, MySQL and a data source here
      Difficulty rating: Medium
      Moodle: https://moodle.mieuxchoisir.org/
      H5P Content Generator
      Description
      This project aims to create a bridge between H5P and the Open Food Facts database. It's related to the Moodle project, but it's shorter and the skills are different. It would make food content available on Moodle, but also on CMS, wiki and web pages. Consider it as an ETL project: you have to extract data from the OFF DB, transform it, and load it in an HTML5 package. We will need a UI/API to use it. It's an ongoing project, so should be easier to complete something in less than 350 hours.
      Expected outcomes
      A standalone H5P generator that will create H5P content types based on OFF data. We've begun to work on automatic content generation from the OFF database. The next step would be to improve our work and generate some H5P content types. Since we have a generation recipe for them, the content types that we target first are Drag the words, Fill in the blanks, Mark the words, Quiz, Single choise set and Summary.
      Project information
      Repo: to be created on May 8
      Slack channels: #summerofcode #education
      Potential mentors: Louis Bastarache
      Project duration: 175-350 hours
      Skills required: PHP, Java, Spring, Firebase and a data source here
      Difficulty rating: Medium
      Open Food Facts Explorer - a new generation frontend
      Description
      The Open Food Facts Explorer is a modern frontend for Open Food Facts, developed using SvelteKit. It offers functionalities such as basic editing, product page displays with Knowledge Panels support, search capabilities, and user authentication. Additionally, it incorporates the new folksonomy engine and a taxonomy explorer, enhancing data organization and accessibility.
      Expected outcomes
      The main objective of the project is to refine and expand its features to align with the standard Open Food Facts website.
      Decoupling the backend from the frontend will improve the long-term maintainability of the codebase, while leveraging a modern JavaScript framework will facilitate the development of new features.
      It also has the potential to make the website far more easy to use on a mobile, which constitute more than 70% of visits
      SvelteKit's support for server-side rendering (SSR) and emphasis on accessibility enhance the responsiveness of the web application, broadening its potential reach.
      The development roadmap remains flexible, allowing adjustments during iterations to improve usability and ensure feature completeness.
      Project information
      Repository: https://github.com/openfoodfacts/openfoodfacts-explorer
      Slack channels: #off-explorer
      Potential mentors: VaiTon
      Project duration: ~175 hours
      Skills required: TypeScript, Svelte and SvelteKit (really easy to learn), a basic understanding of HTTP APIs
      Difficulty rating: Medium (for its length)
      
      Add Mini Games to the Open Food Facts Mobile App
      Description
      Open Food Facts empowers users with information about food products. This project aims to enhance user engagement and education by introducing fun, informative mini-games within the Open Food Facts mobile app. These games will leverage the existing Open Food Facts data. The games will focus on contributions, and increasing user understanding of food .
      Potential mini-games are:
      Hunger Games (AI Prediction Validation): This game will present users with questions about products, one after the other, on a given topic (category, nutrition facts, ingredients…). Users will then be asked to validate the prediction, and will move to a similar prediction for another product.
      How Much Sugar? (Sugar Cube Guessing): This game will display a product image and name. Users will guess the number of sugar cubes equivalent to the product's sugar content per serving (or per 100g). The actual number of sugar cubes will drop in a playful animation.
      Caloprix (Nutri-Score Guessing): This game challenges users to guess the Nutri-Score (A, B, C, D, or E) of a product based on its image, name, and potentially a limited set of other data points (e.g., category). The game will reveal the correct Nutri-Score and provide a brief explanation of what factors contribute to that score. The game ends when the user gets it wrong. The goal is to get as many good answers as possible in a row.
      The Price is Right (Price Guessing): This game challenges you to guess the price of an item of a product, and answers you by saying “More” or “Less”. The goal is to guess the right prices in as little guesses as possible.
      
      Expected Outcomes
      Working Mini-Games: Several mini-games integrated into the Open Food Facts mobile app (iOS and Android) and our website.
      User Interface: A clean, intuitive, and engaging user interface for each mini-game, consistent with the Open Food Facts app's design.
      Testing: Thorough testing of the mini-games on various devices and screen sizes.
      Project Information
      Main Repository: https://github.com/openfoodfacts/smooth-app
      Web version of Hunger Games for reference: https://hunger.openfoodfacts.org
      Slack Channels: #mobile-app-dev, #dev
      Potential Mentors: Edouard M, Primael Q and Pierre S
      Project Duration: ~350 hours
      Skills Required:
      Mobile App Development with Flutter
      JSON REST API interaction
      Design integration
      An experience with web development would be a great plus
      Difficulty Rating: Medium
      
      Porting Open Prices Features to the Open Food Facts Mobile App
      Description
      This project aims to integrate the core features of Open Prices into the Open Food Facts mobile application. Open Prices allows users to contribute and view price information for products, creating a valuable resource for consumers. Currently, this functionality is primarily available on the Open Prices website. Bringing Open Prices to the mobile app will significantly increase accessibility and user engagement, leveraging the app's existing user base. This will empower users to easily compare prices while shopping, contribute new price data on-the-go. The project will focus on seamlessly integrating these features into the existing app structure, ensuring a consistent and user-friendly experience.
      Expected outcomes
      Beautify the current user Interface and review the current user Experience (UI/UX) for existing flows: Prioritize a user-friendly and intuitive interface for both viewing and contributing price data, adhering to mobile design best practices.
      Price Viewing: Implement the ability to browse and search for product prices within the Open Food Facts mobile app. This should include clear display of current and historical prices, potentially with visualizations (e.g., price trends).
      Bulk Price Contribution using Artificial Intelligence: Enable users to easily add new bulk price information for products directly through the app. This should include mechanisms for data validation and image uploads for price verification.
      Offline Functionality: Add offline price contribution (data synced when a connection is available) using the current background task system
      Project Information
      Repository: https://github.com/openfoodfacts/smooth-app
      Slack channels: #prices
      Potential mentors: Raphael O., Edouard M., Pierre (contacted via Slack/GitHub)
      Project duration: ~175 hours (can be adjusted based on specific feature scope)
      Skills required: Flutter, mobile app development experience, familiarity with RESTful APIs, basic understanding of data visualization.
      Difficulty rating: Medium (due to mobile development complexities and API integration)
      Enhancing Developer Experience Through Automation and Workflow Optimization
      Description
      This project aims to significantly improve the developer experience (DevX) within Open Food Facts by automating workflows and streamlining processes. The initiative focuses on delivering practical code contributions that enhance productivity and simplify daily tasks for developers. Key components include automated documentation generation, optimized GitHub workflow management, integration of cloud-based development environments, automated deployment pipelines for testing changes, and conditional test execution to reduce build times.
      Expected outcomes
      Deliverables and KPI / benefits:
      KPIs: Reduced build/test times, faster issue resolution, and improved developer satisfaction.
      Automated Documentation Pipeline: A system that continuously updates project documentation (eg. OpenAPI specs) in sync with code changes.
      Examples include using markdown-based solutions such as MDX, nextra.site, fumadocs, or mintlify. For instance, Langufuse’s documentation (Langufuse Documentation) serves as both a technical resource and a marketing tool, illustrating how a well-maintained documentation system can elevate a project’s profile.
      Additional examples include the markdown-only page OSS LLMOps Stack and the documentation repository langfuse-docs.
      Modern Development Environments: Integration of solutions like GitPod or GitHub Codespaces to provide uniform, pre-configured setups for contributors.
      Automated Deployment for Testing: Pipelines that deploy changes immediately for real-time testing feedback.
      Enhanced Testing Efficiency: Conditional test execution that reduces unnecessary build and test cycle times.
      Optimized GitHub Workflow: Automation scripts or GitHub Actions for issue triage, pull request management, and repository organization (example script to reduce labels).
      Develop an NLP/AI-powered solution to categorize, prioritize, and suggest resolutions for open GitHub issues within the Open Food Facts ecosystem.
      Implement a dashboard/overview (simple example) for better repository management, tracking contributions.
      Project information
      repositories: openfoodfacts-server, openfoodfacts-python, smooth-app, robotoff
      DevOps Issue tracker
      Slack channels: #dev, #infrastructure
      Potential mentors: Hangy, with assistance from Malte.
      Project duration: ~90 hours (focused implementation), ~175 hours (moderate scope), or ~350 hours (comprehensive integration)
      Skills required:
      Proficiency in scripting (Python, Bash)
      Experience with CI/CD systems (GitHub Actions, Jenkins)
      Familiarity with containerization (Docker)
      Knowledge of cloud-based development environments
      Understanding of testing frameworks and automation strategies
      Difficulty rating: Moderate to Advanced – Involves integrating diverse tools and workflows to significantly enhance developer experience.
      Your idea
      You are a candidate and have a specific project idea, that's really welcome.
      But to maximize your chances, please:
      Contribute to the project none the less in the bounding period
      Check with us that your idea is a good fit and align with our priorities
      Project template
      <DESCRIPTIVE TITLE>
      Description
      Explain what, why.
      Expected outcomes
      Deliverables and KPI / benefits
      Project information
      repository:
      Slack channels:
      Potential mentors:
      Project duration: ( ~90 hour, ~175 hours or ~350 hours)
      Skills required:
      Difficulty rating:
      Category: GSOC
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-food-facts/
    idea_list_url: https://wiki.openfoodfacts.org/GSOC/2025_ideas_list

  - organization_id: 103
    organization_name: Open HealthCare Network
    no_of_ideas:
    ideas_content: |
      ohc.network
      Contributions
      Leaderboard
      Contributors
      Projects
      Feed
      Releases
      Discussions
      Active Projects
      Google Summer Of Code
      /care_fe#10519
      Open in GitHub
      Offline Data Entry Support
      Google Summer Of Code
      /care_fe#10533
      Open in GitHub
      Enhancing Medication Notifications in CARE 3.0 for Palliative Care & Adherence
      Google Summer Of Code
      /care_fe#10475
      Open in GitHub
      FHIR Risk Assessment
      Google Summer Of Code
      /care_fe#10599
      Open in GitHub
      Whatsapp bot for CARE
      Google Summer Of Code
      /care_fe#10509
      Open in GitHub
      Copilot App Plugin For CARE
      Google Summer Of Code
      /care_fe#10470
      Open in GitHub
      Diet Management in CARE
      Google Summer Of Code
      /care_fe#10471
      Open in GitHub
      Nutrition Rehabilitation
      Google Summer Of Code
      /care_fe#10474
      Open in GitHub
      FHIR Immunization
      Google Summer Of Code
      /care_fe#10477
      Open in GitHub
      ABDM – Patient Centric Flows (PHR Flows)
      Google Summer Of Code
      /care_fe#10478
      Open in GitHub
      Improve the Package Showing Health Information
      Google Summer Of Code
      /care_fe#10508
      Open in GitHub
      HR Management Module
      Google Summer Of Code
      /care_fe#10521
      Open in GitHub
      On-Prem Deployment Support
      Google Summer Of Code
      /care_fe#10532
      Open in GitHub
      Integrate UHI as a Plug
      Google Summer Of Code
      /care_fe#10534
      Open in GitHub
      SSO Support
      Google Summer Of Code
      /care_fe#10531
      Open in GitHub
      Integrate Beckn as Plug
      Google Summer Of Code
      /care_fe#10476
      Open in GitHub
      Terminology Server from Google Sheet
      About Us
      Powered by
      Connecting healthcare through open data and innovative solutions.
      Resources
      Data Repository
      Flat Repository Explorer
      Connect
      Leaderboard scrapes data frequently.
      Data was last updated 5 hours ago.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-healthcare-network/
    idea_list_url: https://contributors.ohc.network/projects

  - organization_id: 104
    organization_name: Open Robotics
    no_of_ideas:
    ideas_content: |
      Overview
      This document describes a list of potential ideas created for the 2025 Google Summer of Code. However, the ideas are open to everyone with interest on collaborating, and OSRF is open to new ideas. Feel free to use our application template below to indicate your interest in some of the projects. If you would like to suggest new projects please email gsoc@openrobotics.org.
      The following list shows a set of ideas that can extend the functionality of some of the open source projects led by OSRF.
      ROS (Robot Operating System) provides libraries and tools to help software developers create robot applications. It provides hardware abstraction, device drivers, libraries, visualizers, message-passing, package management, and more.
      Gazebo is a multi-robot simulator for indoor and outdoor environments. It is capable of simulating a population of robots, sensors and objects in a three-dimensional world. It generates both realistic sensor feedback and interactions between physically plausible objects.
      Open-RMF is a free, open source, modular software system that enables robotic system interoperability. Open-RMF coordinates multiple fleets of indoor and outdoor robots with typical robotic use cases and integrates them with elevators/lifts, doors and other infrastructure.
      Infrastructure is the computing infrastructure that supports the above projects, such as by providing continuous integration services and building binary packages.
      The link between all projects is their open source nature and its relationship with robotics. Browse through the list and do not hesitate to contact us if you wish to participate in any of the projects. Share with us your thoughts and ideas on any future improvement or project you may have.
      ROS 2 projects list
      For a general introduction on how to start contributing to ROS 2, check out the Contributing page! If you have any technical questions feel free to ask them on Robotics Stack Exchange. For high-level conceptual discussions, post on ROS Discourse.
      Improvements to ROS 2 Doctor 👩🏻‍⚕️
      Prerequisites: Ubuntu and ROS 2 development environment, no need for specialized hardware.
      Necessary programming skills: Familiarity with C/C++/Python, CMake, ABI/API.
      Difficulty level: Medium.
      Potential mentors: Tomoya Fujita
      Expected size: 100 hours to 150 hours.
      Expected outcome: A ROS 2 command line interface ros2cli with doctor sub-command and ros2_documentation.
      Detailed description: Currently, the ROS 2 doctor subcommand, ros2 doctor, is lacking a lot of useful information, such as ROS environment variables, RMW-specific environment variables, and configuration and service information (number of endpoints, QoS compatibility status, etc). This information is really important and useful for debugging issues with ROS 2, and would greatly improve our ability to support issues reported by our user community. In other words, adding this new information to our existing ROS 2 Doctor command would accelerate community communication and make bug reports much more precise! Aligned with ros2cli development, this project also targets the implementation of improved documentation on how to create an issue report with a new issue template.
      Reference pull requests: Add default github issue templates, add: get clients, servers info
      Structured Parameter Support for ROS 2
      Prerequisites: Basic knowledge of the rclcpp. No need for specialized hardware.
      Necessary programming skills: Familiarity with C++, YAML, Python and CMake.
      Difficulty level: Medium
      Potential mentors: Janosch Machowinski
      Expected size: 175 hours
      Expected outcome: Ability to use structured parameters in rclcpp
      Detailed description: Currently the ROS 2 Parameter interface only supports ‘basic’ datatypes, or arrays of basic datatypes. (E.g. int, std::string, float, std::vector<int>, std::vector< std::string >, std::vector<float> etc) The scope of this task would be, to add support for structured parameters,this is to say C++ structs as parameters, E.g.
      struct MyConfigData 
      { 
      int id; 
      std::string interfaceName; 
      std::vector<struct SomeOtherData> data; 
      }; 
      To achieve this goal, the following tasks need to be completed:
      Modify ParameterValue -- A new member needs to be added to ParameterValue messages. The new member shall contain a structured parameter in the form of a YAML serialized structure.
      Modify rclcpp -- Currently there a checks in place, that forbid passing of complex structures as parameters, these need to be removed.
      Update parameter value -- The rclcpp::ParameterValue needs to be modified to return the serialized YAML structure.
      Convenience methods -- Add convenience functions to convert the serialized structure to a ROS message. ROS messages have a built-in introspection feature. This feature shall be used, to auto serialize the YAML blob into a ROS message. The introspection feature allows to iterate the ROS message. Therefore one can run over a given ROS message and check, if the YAML blob contains entries for all the members in the ROS message. One can also check, if no additional entries are present in the YAML blob. As the ROS message contains the data type of each member, and a generic function to write it, the deserialization of individual message members can also be implemented in a generic way.
      Stretch goal -- Implement tooling to generate YAML ‘layouts’ from a given ROS message. The goal is to implement a simple command line tool, for generating empty YAML structures for a given ROS message. These empty yaml structures are supposed to be used as templates / copied into configuration files.
      C/C++ Struct to ROS Message Converter
      Prerequisites: Basic knowledge of the rclcpp. No need for specialized hardware.
      Necessary programming skills: Familiarity with C++, jinja, YAML, Python and CMake.
      Difficulty level: Medium - Hard
      Potential mentors: Janosch Machowinski
      Expected size: 175 hours
      Expected outcome: Automatic wrapping and unwrapping of C++ structures to ROS messages!
      Detailed description:
      The goal of this proposal is to enable a workflow with ROS 2, were one only needs write C/C++ structures and ROS 2 tooling takes care of the generation of intermediate message generation and serialization. This tooling would greatly reduce the amount of boilerplate code needed to transfer a given structure from one node to another node. The outcome we desire would be a tool that can take input of the form:
      struct Foo { 
        int a; 
        float b; 
      }; 
      
      struct Bar { 
        std::vector<Foo> foos; 
      }; 
      and automatically generate the following two ROS messages along with the corresponding typeAdapters :
      Foo.msg: 
      Int a 
      Float32 b 
      
      Bar: 
      Foo[] foos 
      This goal shall be archived by the usage of castxml , Python and Jinja. Castxml is a tool, that converts C++ headers to an xml abstract syntax tree representation, without the hassle of parsing C/C++ code. Therefore castxml enables simple Python scripts to perform C++ introspection. Jinja is template code generation library, that can be used from Python. Combining castxml with jinja therefore allows us to parse arbitrary C++ structures, introspect them, and generate matching ROS message. It also allows for generation of serialization code from the structure to the ROS message and back.
      Stretch goal: opaque type support
      Opaque types are types, for which no automatic serialization and intermediate message can be generated For example, Eigen::Vector2d
      would be opaque, as some members are private. Therefore there should be the option, to register handlers for these opaque types. The handlers shall enable the user to specify custom messages and converter functions for the given opaque type. Library support would be a secondary stretch goal. The system shall generate installable files, that register (if included / loaded) known types as opaques. The auto-generated ‘library opaques’ should just refer to the already generated messages and converters of the originating library. This would effectively suppress type generation for types from other libraries.
      Improvements to ROS 2 Tracing
      Prerequisites: ROS 2 experience, some tracing/LTTng tracer experience, Linux, Git
      Necessary programming skills: C++, Python
      Difficulty level: Medium to Hard
      Potential mentors: Christophe Bédard
      Expected size: 175 hours to 350 hours
      Expected outcome: A solution to allow enabling the ROS 2 tracepoints after an application has already been launched.
      Detailed description: Software tracing is a method of collecting low-level runtime data to understand a system's execution. ros2_tracing is a collection of tracing instrumentation for ROS 2 and tools to configure tracing for ROS 2 applications. See the ros2_tracing repository and this ros2_tracing introduction in the ROS 2 docs. Currently, when tracing a ROS 2 application, the tracer has to be configured and tracing has to be started before launching an application. This is because important trace data is generated during the initialization phase of an application; without this information, trace data generated later (e.g., message publication data) cannot be decoded. This means we cannot decide to start collecting trace data for an application that is already running, which makes debugging a system that’s already running harder. The first goal of this project is to find a solution to allow configuring tracing at any point after the application has been launched. See ros2/ros2_tracing#44. This would also make live tracing easier: live tracing means processing the trace data live, as the application is executing, unlike the typical workflow, which is to process the trace data offline, after the execution. A stretch goal for this project would be to improve the tracing configuration tools (ros2 trace command, Trace launch action) to allow configuring a live tracing session. See ros2/ros2_tracing#149.
      Gazebo projects list
      For a general introduction on how to start contributing to Gazebo, check out the guided tutorials and Contributing guide! If you have any technical questions feel free to ask them on Robotics Stack Exchange or message @HelloWorld on Gazebo Community. For good first technical issues to tackle and become familiar with the development workflow, search on GitHub under the "gazebosim" organization for "good first issue" tags. The "help wanted" tag may contain more advanced tickets.
      Raytracing enabled Faster-Than-Realtime GPU based lidar plugin for Gazebo
      Prerequisites: Cursory understanding of what a GPU is and what "ray tracing" means in the context of graphics. Access to a ray tracing enabled GPU on a non-Apple platform (one can be provided remotely if necessary).
      Necessary programming skills: Familiarity with C++, CMake and an understanding of ABI.
      Difficulty level: Medium to hard.
      Potential mentors: Arjo Chakravarty.
      Expected size: 175 hours to 350 hours.
      Expected outcome: A source buildable package containing a LiDAR plugin for gazebo that exploits raytracing.
      Detailed description: This GSoC project exploits ray tracing GPUs in Gazebo. Recently, GPU manufacturers have been adding raytracing capabilities to their GPUs. This includes Apple, Intel, AMD and NVIDIA. Ray tracing has been shown to be an effective pathway for simulating faster-than-realtime depth sensors. Other simulators that do this only exploit NVIDIA's proprietary OptiX API. Recent work in the Rust wgpu community has made it easy to use the Vulkan APIs for raytracing. Early experiments show the ability to ray trace a 256x256 depth camera at 1000fps on a consumer laptop with a 4 year old GeForce 3090 GPU. A prototype has alreasdy been produced, so this project would be focused on extending the prototype into a complete solution. The prototype builds on the rust wgpu package and a thin C wrapper that enables integration into Gazebo. Potential extension work is to support various types of depth sensors including maritime sonars/radars, along with potential publication to a relevant robotics venue.
      Gazebo Plugin For Gaussian Splatting
      Prerequisites: Cursory understanding of what a GPU is. No need for specialized hardware. Some knowledge of what NeRFs and Gaussian Splats are.
      Necessary programming skills: Familiarity with C++, GLSL, and CMake.
      Difficulty level: Medium to hard.
      Potential mentors: Arjo Chakravarty.
      Expected size: 175 hours to 350 hours.
      Expected outcome: A ROS 2 package with the relevant Gazebo plugin to display splats.
      Detailed description: Gaussian splatting is an up and coming technique for realtime photo-realistic rendering. It could solve the problem of photo-realism without the need for a specialized 3D artist. This can be a game-changer for the way we simulate robots. The goal of this project is to write a simple shader plugin for Gazebo that renders these splats. Work in this project may lead to a publication. If the candidate wishes, we could also add ROS tools to generate such splats from ROS 2 bags.
      Physics-based sonar simulation and new examples with commonly used hardware for underwater robotics
      Prerequisites: Linux, Git, experience with ROS and Gazebo, familiarity with basic simulation concepts.
      Necessary programming skills: C++, Python and CUDA.
      Difficulty level: Medium
      Potential mentors: Woen-Sug Choi, Mabel Zhang and Rakesh Vivekanandan.
      Expected size: 350 hours.
      Expected outcome: Complete the migration and enhancement of a physics-based sonar simulation plugin, enriched with new example cases for underwater robotics. The project will leverage the ROS 2 framework and the latest long-term support (LTS) version of ROS and Gazebo (ROS Jazzy and Gazebo Harmonic). The ultimate goal is to provide a robust tool that can be optionally upstreamed to the new Gazebo, significantly benefiting the maritime robotics community.
      Detailed description: The focus of this project is migrating and enhancing the physics-based multi-beam sonar simulation from Project DAVE (a community library for maritime robotics using ROS and Gazebo), adapting it to function within the ROS 2 and new Gazebo environments. This includes selecting essential components of Project DAVE to maintain the integrity of example use cases. Key aspects of improvement are:
      Performance Enhancements: Introducing half-precision calculations in CUDA to boost refresh rates, potentially contributing to journal publications.
      Capability Expansion: Extending simulations to incorporate additional sonar types, such as side-scan and mechanical scanning sonar.
      Benchmark Integration: Incorporating benchmark cases for maritime robotics hardware, including notable examples like the BlueROV, to ensure the model's adaptability and accuracy in simulating hydrodynamic properties. This project is inspired by the latest advances in underwater sonar simulation technology, which employs acoustic scattering models and GPU-accelerated CUDA computations to deliver physically accurate sonar imagery at functional refresh rates, crucial for realistic robotics simulations. We believe that these enhancements will not only improve sonar simulation but also provide invaluable resources to the maritime robotics community in developing solutions that are both innovative and practical.
      Releasing sdformat in PyPI
      Prerequisites: Experience with Git, Python packaging, CMake and GitHub Actions.
      Necessary programming skills: CMake, Python and C++.
      Difficulty level: Medium
      Potential mentors: Jose Luis Rivero.
      Expected size: 350 hours.
      Expected outcome: A mechanism that allows the Gazebo project to release sdformat in PYPI.
      Detailed description: Implement a method to generate a Python Wheel from the SDFormat source code using standard Python packaging tools. Automate the process of releasing a Wheel by integrating the Wheel creation into the release pipeline of the Gazebo project. Integrate the PyPI publishing mechanism into the release pipeline. Try to generalize the solution so it can be applied to other Gazebo libraries.
      Open-RMF projects list
      Improve UI/UX of Site Editor
      Prerequisites: Proficiency with modern programming languages like C++, Python, JavaScript, or Rust. Experience creating UI, either using immediate mode (e.g. imgui, egui) or retained mode (e.g. angular, react, Qt) UI frameworks. Great to have: Familiarity with Rust and Bevy, experience with designing UIs, experience using 3D CAD tools Difficulty level: Easy to Medium
      Mentors: Xiyu Oh, Grey.
      Expected size: Medium to Large (320 hours to 480 hours).
      Expected outcome: An improved user experience for the site editor.
      Detailed description: The Open-RMF site editor is a 3D tool for creating and editing digital twins of facilities where robots operate. While the tool has a considerable amount of functionality, it currently suffers from a cluttered UI that might not be intuitive for users. At a minimum this project would aim to declutter and refine the UI by reorganizing the widgets and taking advantage of the builtin capabilities of egui, the UI framework that is currently being used by the site editor. A more ambitious candidate can consider migrating the site editor to a different UI library, perhaps one that is reactive and uses retained mode rendering. The site editor is fully implemented in Rust and the Bevy video game engine, so all work for this project will be done in Rust.
      Expected breakdown:
      Evaluate the current state of the site editor UI/UX by experimenting with its current usability.
      Identify usage pain points and draft ideas for what changes to the UI could improve it.
      Evaluate the capabilities of egui and identify whether it offers the capabilities needed to improve the UI or if another framework should be considered.
      Implement improvements to the UI and iterate. Gather feedback on usability from the team and continue to refine the improvements.
      Workflow Diagram Editor
      Prerequisites: Familiarity with graphical behavior models like Behavior Trees or Petri Nets. Proficiency with modern programming languages like C++, Python, JavaScript, or Rust. Great to have: Familiarity with Rust and Bevy, experience with programming 2D canvas widgets.
      Difficulty level: Medium to Hard
      Potential mentors: Grey / Luca Della Vedova
      Expected size: 400 hours to 480 hours
      Expected outcome: A Bevy-based library for graphically editing diagrams on a 2D canvas. The library’s capabilities should be suitable for a follow-up project to create an application to draw and edit workflow diagrams for bevy_impulse.
      Detailed description: bevy_impulse is a library in the Open-RMF project that allows users to define complex multi-agent workflows. Workflows are similar to Behavior Trees but are not limited to a tree structure. They can be considered a special case of Petri Nets. A 2D diagram editor that allows users to sketch workflow diagrams would allow us to unlock the full value of bevy_impulse by enabling visual programming of multi-agent behaviors. A fully realized workflow editing application might not be feasible for the scope of one GSoC term, so we primarily aim to start building a foundation for that application. The library will be developed in Rust using the Bevy game engine so it can be cross-platform and target web assembly for use in web browsers, and integrate well with bevy_impulse’s libraries.
      Expected breakdown:
      Get familiar with Bevy and its surrounding ecosystem of third party plugins.
      Get familiar with the workflow concepts that are used in bevy_impulse, e.g. its various operations and how they connect together.
      Investigate various diagram editing tools (e.g. Unreal’s Blueprint editor and Unity’s Visual Scripting editor) and draw inspiration for how the UI might work.
      Devise a strategy for how the widgets would be rendered in a Bevy application.
      Implement the rendering of the diagram widgets and connection curves
      Provide an API for downstream projects to decorate the diagram widgets according to their use cases.
      Multi-Agent Traffic Optimization
      Prerequisites: Proficiency with motion planning and graph search. Experience with Rust programming or familiarity with languages like C++, Python, and JavaScript.
      Great to have: Familiarity with Rust and Bevy, experience with multi-agent path finding algorithms.
      Difficulty level: Medium to Hard
      Potential mentors: Grey / Luca Della Vedova
      Expected size: 320 hours to 480 hours
      Expected outcome: The mapf library is a multi-agent path finding and planning framework developed for the next generation of Open-RMF. For this project the contributor will improve multi-agent traffic debug tools in the Open-RMF site editor and use them to ensure consistent, intuitive multi-agent paths are generated by Open-RMF’s mapf library.
      Detailed description: A key component of Open-RMF is the ability to route multi-agent traffic to avoid conflicts between mobile robot agents that are each performing independent tasks. The mapf library was designed to be a modular, customizable framework for multi-agent path finding. The goal of this project is to pressure test mapf, identify scenarios where it fails or gives inconsistent results, and resolve any underlying issues that could negatively impact its use in a deployment. The site editor will be used to generate test cases, to simulate the results of the mapf library, and to provide a tool to debug the planner. The debugging tool would visualize and step through each iteration of the mapf solving process, allowing the user to investigate how the solver works and identify where it could be improved. This role may involve enhancing the debugging tools in addition to the mapf library itself. Both mapf and the site editor are written in Rust, so this role will be done entirely in Rust.
      Expected breakdown:
      Familiarize yourself with the site editor and how to create different scenarios.
      Familiarize yourself with the debugging tool and how multi-agent plans are generated.
      Build different scenarios, looking for failure cases or sub-optimal solutions.
      Use the debugging tools to track down the causes of undesirable behaviors.
      Ambitious candidates may work on creating pipelines to automatically generate large scenarios and/or to add randomization to test cases.
      New Open-RMF Demo: Free Fleet Map Switching
      Prerequisites: Linux, Git, ROS 2, Gazebo, familiarity with Nav2 and Open-RMF are a plus
      Necessary programming skills: Python, C++.
      Difficulty level: Medium
      Potential mentors: Aaron Chong
      Expected size: 480 hours
      Expected outcome: A new Open-RMF demo simulation which showcases Open-RMF integration with a fleet of turtlebots running Nav2 and Free Fleet within a two story building. These two simulated robots will be capable of navigating and performing tasks across the multiple building levels and switching Nav2 maps when arriving at a particular floor via elevator. This new demo will serve as a starting point for folks new to Open-RMF and Free Fleet.
      Detailed description:
      Simulation demo and mapping: Re-use the existing rmf_demos hotel world, to create a new demo world and replace the existing robots with two simulated TurtleBots. These turtlebots will then map the simulation world and share the map between themselves to support single-floor navigation using Nav2.
      Integration of Open-RMF and Free Fleet: Set up a Free Fleet adapter, and integrate it with the two TurtleBots, to support basic single-floor Open-RMF tasks.
      Implement localization and map-switching command: This will allow the simulated robots to traverse levels using the virtual elevators, switch Nav2 maps, and still be able to localize, navigate, and receive Open-RMF commands to perform tasks across levels. Other supporting features within the Free Fleet Adapter will also require implementation. The fleet_adapter_mir can be used as a reference implementation.
      Documentation of usage, configuration and the new simulation as a "how to" guide for users .
      ROS Controls projects list
      ROS Infrastructure Projects
      vcstool Modernization and Improvements
      Prerequisites: git and other version control systems, GitHub Actions
      Necessary programming skills: Python
      Difficulty level: Medium
      Potential mentors: Christophe Bédard, Jose Luis Rivero, Clara Berendsen
      Expected size: 175 hours to 350 hours
      Expected outcome: Modernize use of Python, create new useful features
      Detailed description:
      vcstool is a meta version control system tool that interacts with multiple version control systems to make working with multiple repositories easier. It is heavily used in ROS and Gazebo environments, for example when building ROS 2 from source or in the Gazebo source installations. It is an official package in Debian and Ubuntu among other distributions and also available via PyPI. vcstool has not really been maintained over the last few years. The first goal of this project is to update it to bring modern Python support to the code and replace the ancient implementations. The GitHub Actions workflow also needs to be updated, since it uses older versions of actions. There are many bug reports, feature requests, and open PRs (see the original repository). The second goal of this project is to help fix bugs, identify interesting feature requests and implement them, and in general help shape the future direction of vcstool. Expanding vcstool’s API surface so it can be used in place of https://github.com/vcstools/vcstools would be an excellent stretch goal for the project.
      Relevant resources
      ROS
      ROS web page
      ROS tutorials
      ROS 2 tutorials
      ROS Q&A
      List of code repositories
      Gazebo
      Gazebo web page
      Gazebo tutorials
      Gazebo Q&A
      Gazebo mailing list
      GitHub (code and issue tracker)
      Open-RMF
      RMF root repository
      RMF Site Editor
      Open-RMF Workshop at ROSCon 2022)
      Application template for students
      If you would like to suggest new projects please message @HelloWorld at Gazebo Community or post at ROS Discourse.
      If you have specific questions to discuss about a project, send an email to gsoc@osrfoundation.org.
      If you meet the general requirements and are interested in working on one of the OSRF projects during Google Summer of Code, you can apply by submitting your application through the Google GSoC web site once participant applications open on March 25th, 2025. Your application should include the following information:
      Contact Information
      Your name
      A phone number
      An email address where we can reach you for daily communication
      Your Github profile or personal website
      Education and Coursework
      Please provide information about your university, degree type, and your expected graduation year. Please list relevant technical courses you have taken. In particular, we are interested in your background in:
      Robotics
      Software engineering
      Computer graphics
      Physics simulation
      Experience
      Please list any experience you’ve had in software development, including relevant class projects, internships, undergraduate or graduate research, and/or contributions to open source projects. For each example, please include a brief description of the overall project along with the specific contributions you made and when you made them.
      In addition to the above information, we are interested in concrete examples of your work, which may include:
      Sample code: please send an example of code you have written that you are proud of; be prepared to answer questions about it. A link to a Github repository works the best!
      Publications: if you have participated in undergraduate or graduate research, please include a link to a copy of any relevant publications.
      Specialized skills: if you have experience/skills in particular areas that you believe would be useful to one of our projects, please let us know.
      Personal website: if you have a website that discusses your research or other projects, please include a link.
      References: names and contact information for people you have worked with who can recommend you.
      Statement of Intent
      In a paragraph or two, describe your interests and background. Please tell us which of the project ideas you are interested in and why you’d like to work on it. If you have a proposal for a project not included on our list, please describe the idea clearly and provide a motivation for the work and a timeline for how you plan to accomplish it.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-robotics/
    idea_list_url: https://github.com/osrf/osrf_wiki/wiki/GSoC25

  - organization_id: 105
    organization_name: Open Science Initiative for Perfusion Imaging
    no_of_ideas:
    ideas_content: |
      Published using Google Docs
      Report abuseLearn more
      IdeasList_GSoC2025_OSIPI_Public
      Updated automatically every 5 minutes
      
      Project list of OSIPI for GSoC 2025
      Introduction
      Our organization deals with a sub-domain of medical imaging – quantitative MRI. Our projects then work with several different imaging techniques called DSC, DCE, ASL, and IVIM. While our project descriptions contain specific terminology, we do not require deep knowledge of the field, unless explicitly mentioned otherwise. Our mentors will provide all the necessary domain expertise so that the contributors will be able to focus on the tasks at hand.
      
      
      Python development:
      
      Where the current software resources of OSIPI are in separate repositories split by perfusion technique (ASL, DCE/DSC, and IVIM), our overall aim is to develop a unified OSIPI software package, where each technique is a submodule in the overall package. This will require a collaborative effort from multiple developers and is not expected to be fully developed through GSoC. Here we defined multiple medium to large subprojects to make the next steps towards the unified project.
      
      Extend and consolidate previous packages to implement several modeling and data processing options: DCE module, BBB module.
      Implement a general interface for ASL pipelines: ASL module, Preclinical extension, Testing module
      Work on introducing a novel processing module: IVIM package
      Implement a framework for scoring results from the ASL challenge, comparing several ASL pipelines.
      
      Database and web development:
      
      Extract ASL metadata and use them in a Methods section generator
      Web app to organize and display a lexicon
      Short project to work on HTML page output
      
      Automation and infrastructure:
      
      Create a dockerized version of the IVIM pipeline
      A short project to implement automatic ExploreASL pipeline testing on GitHub
      
      General GitHub link: https://github.com/OSIPI
      
      Python development
      OSIPI package – DCE Module
      Proposed mentors: Luis Torres, Sirisha Tadimalla
      
      Languages/skills: Python
      
      Estimated project length: 350 hours
      
      Difficulty: Moderate/Difficult
      
      Category: Core development
      
      Relevant links: OSIPI python package, GSoC 2024 project  
      
      Description: Building on the foundational work from last year’s GSoC project—which established the core infrastructure for the OSIPI perfusion package—this project focuses on creating the Dynamic Contrast Enhanced (DCE) MRI module. In keeping with OSIPI’s lexicon and guidelines, the DCE module will introduce a standardized toolkit for processing DCE datasets. Specifically, the contributor will implement robust data read/write functionalities, standard pharmacokinetic modeling algorithms, and advanced deconvolution methods to derive quantitative perfusion parameters — providing an end-to-end solution that simplifies the DCE image processing pipeline.
      
      Expected outcomes:
      
      The key outcome of this project will be the DCE module for our unified OSIPI package.
      
      Methods for handling DICOM and NIFTI/BIDS data.
      Methods for Pharmacokinetic Modeling for Estimation of Physiological Parameters
      Robust unit-testing
      Documentation
      Requirements:
      
      (Minimum) Background in linear algebra and python
      (Recommended) Git, Image Processing
      (Ideal) Background in medical image processing
      OSIPI package – Blood-brain barrier module
      Proposed mentors: Ben Dickie, Jan Petr
      
      Languages/skills: Python
      
      Estimated project length: 350 hours
      
      Difficulty: Difficult
      
      Category: Optimization
      
      Relevant links: ExploreASL, DCE module - GSoC 2024 project 
      
      Project description: Building on the foundational work from last year’s GSoC project—which established the core infrastructure for the OSIPI perfusion package—this project focuses on creating the functionality to model blood-brain barrier (BBB) water exchange. Specifically, the contributor will implement robust data read/write functionalities,and create Python functions to model BBB exchange — providing an end-to-end solution that simplifies and standardizes the estimation of BBB water exchange for ASL and DCE-MRI data.  
      
      Expected outcomes:
      
      The key outcome of this project will be the BBB module for our unified OSIPI package:
      
      Methods for handling DICOM and NIFTI/BIDS data.
      Methods for Pharmacokinetic Modeling for Estimation of Physiological Parameters of azeeBBB transfer in DCE and ASL data
      Robust unit-testing
      Documentation
      Requirements:
      
      (Minimum) Background in linear algebra
      (Recommended) Git, Image Processing and Python Modeling (e.g. SciPy, NumPy)
      (Optional) Background in medical image processing
      
      OSIPI package - ASL module
      Proposed mentors: Maria Mora, Zhiliang Wei
      
      Languages/skills: Python
      
      Estimated project length: 350 hours
      
      Difficulty: Moderate
      
      Category: Core development
      
      Relevant links: OSIPI Task Force 2.2,  ISMRM 2022 abstract, PyASLtoolbox, GSoC 2024 project
      
      Project description: The current version of the ASL module has no modularity to explore and test different preprocessing snippets (i.e., algorithms) across pipelines. In addition, these tools are designed for brain imaging and lack adaptability for broader applications beyond the brain. A modular PyASL library will bridge this gap, providing researchers and developers with a versatile platform to test and integrate new functionalities more efficiently, tailor pipelines to specific research needs, and support algorithmic exploration for population- or organ-specific ASL imaging processing.
      
      Expected outcomes:
      
      Redesign of the current PyASL architecture to incorporate modularity such that it can be integrated in the unified Python package, i.e., break down the existing pipelines into preprocessing snippets.
      Modification of current CBF quantification methods is also needed to quantify perfusion in other organs.
      Implementation of a framework for developers to add or modify specific preprocessing snippets or quantification approaches.
      Documentation of the improved PyASL.
      Requirements:
      
      (Minimum) Python proficiency
      (Recommended) Experience in modular software design.
      (Ideal) Familiarity with neuroimaging preprocessing pipelines.
      
      OSIPI package - ASL module extension for preclinical imaging
      Proposed mentors: Zhiliang Wei, Maria Mora
      
      Languages/skills: Python/Matlab
      
      Estimated project length: 175 h
      
      Relevant links: OSIPI TF 2.2, ISMRM abstract 2022, PyASL at GitHub, GSoC 2024 project
      
      Difficulty: Moderate
      
      Category: Core development
      
      Project description: The first version of the library was done within GSoC 2024. This project aims to extend the current repository with a preclinical ASL package, including scanner method files, parameter protocols, and data processing codes. Harmonizing processing is difficult when data comes from various sequences. There are too many variations to be considered. The preclinical ASL is a good chance to try standardization from sequences to imaging parameters and subsequently to processing.
      
      Expected outcomes:
      
      Established perfusion imaging package (including sequence, protocol, and processing tool) for small animals
      Pulsed and pseudo-continuous ASL packages usable for preclinical studies
      Requirements:
      
      (Minimum) Python proficiency
      (Recommended) Experience in modular software design
      (Ideal) Basic knowledge of neuroimaging processing
      OSIPI package - automated testing for ASL module
      Proposed mentors: Azeez Adebimpe, Yifan Shuai, Maria Mora
      
      Languages/skills: Python, CI/CD (GitHub Actions, Travis CI), pytest
      
      Estimated project length: 175
      
      Links: OSIPI TF 2.2, ISMRM 2022 abstract, PyASL at GitHub, GSoC 2024 project 
      
      Difficulty: Moderate
      
      Project description: The first version of the library was done within GSoC 2024. Currently, TF members are testing these contributions manually. This manual process involves writing code specifically for testing purposes and publishing the test results on a separate website. As new code contributions are added, the test results need to be manually updated,  making the process time-consuming and error-prone. The primary objective of this project is to develop a comprehensive framework that automates the entire testing process, starting from the creation of individual tests to the publication of results on the dedicated website. The ultimate goal is to establish an automated testing algorithm for each step in the processing pipeline.
      
      Expected outcomes:
      
      1. Development of an automated testing framework for the ASL processing module.
      
      2. Integrate CI/CD pipelines to run tests automatically and dynamically publish results to a dedicated website.
      
      
      Requirements:
      
      (Minimum) Strong proficiency in Python. Experience with automated testing frameworks (e.g., pytest, unittest).
      (Recommended) Familiarity with MRI processing pipelines
      (Ideal) Knowledge of CI/CD tools (e.g., GitHub Actions, Travis CI, or Jenkins)
      
      
      OSIPI package - IVIM module extends the testing framework for AI/Bayesian models
      Proposed mentors: Eric Peterson, Daan Kuppens
      
      Languages/skills: Python
      
      Estimated project length: 350 hours
      
      Difficulty: Moderate
      
      Category: core development
      
      Project description: This project aims to significantly enhance the existing IVIM repository testing framework to effectively evaluate the performance and reliability of AI and Bayesian models. The current framework has limitations in testing models with diverse requirements, such as difficulty in adapting to different model architectures, training procedures, and evaluation metrics; inadequate support for testing deep learning models, Bayesian networks, reinforcement learning algorithms, etc; difficulty in testing models under various conditions, including noisy data, missing values, and extreme parameter settings.
      
      Expected outcomes:
      
      This project will focus on refactoring the framework into reusable components to improve maintainability and facilitate customization; introducing flexible configuration options to allow for easy adjustment of testing parameters (e.g., dataset size, number of iterations, evaluation metrics); extensibility by developing a plugin system or similar mechanism to enable easy integration of new testing modules for different AI/ML algorithms.
      
      This project will result in a significantly improved testing framework that empowers developers and researchers to rigorously evaluate the performance and reliability of AI and Bayesian models, leading to more robust and trustworthy IVIM fitting.
      
      Requirements:
      
      (Required) Unittest, PyTest, or similar
      Basic understanding of AI/ML concepts (e.g., supervised learning, Bayesian inference)
      Version control (Git), code style, documentation
      
      Standardized scoring pipeline for OSIPI challenges
      Proposed mentors: Andre Paschoal, Soudabeh Kargar
      
      Languages/skills: Python, GitHub
      
      Estimated project length: 175 hours
      
      Links: OSIPI/TF6.2_DCE-DSC-MRI_Challenges: TF6.2, ASL OSIPI Challenge, DCE OSIPI Challenge, OSIPI TF 6.2
      
      Difficulty: Moderate
      
      Category: Low hanging-fruit
      
      Project description: OSIPI has organized two challenges in the past that focused on the analysis of perfusion imaging data. The aim of the challenges is to understand where differences between analysis pipelines come from and to determine best practices in the analysis of perfusion analysis. We are currently preparing for follow-up challenges. The analysis of the challenge data was done separately for both challenges but based on similar methods. To make future challenges more efficient and standardized, we would like to develop a standardized pipeline for the analysis of challenge data. The code from previous challenges will serve as a starting point.
      
      Expected outcomes:
      
      Standardized pipeline in Python for evaluation of OSIPI challenges
      Requirements:
      
      Python proficiency, GitHub
      
      Database and web development
      Methods section generator for ASL
      Proposed mentors: David Thomas, Jan Petr, Hanliang Xu
      
      Languages/skills: Python
      
      Estimated project length: 175 hours
      
      Difficulty: Moderate
      
      Category: Core development
      
      Relevant links: OSIPI TF4.1, ASL Lexicon, GSoC 2024 project, GSoC 2024 final report
      
      Project description: For transparency and reproducibility in MRI research studies, it is important to report the sequence acquisition parameters accurately. Accessing these parameters from the image file headers requires familiarity with file formats and interpretation of the information they contain. The aim of this project is to provide a simple-to-use Python-based software tool that reads the metadata from ASL MRI image files, extracts the important data acquisition parameters, and formats them in a short text paragraph that can be ‘cut-and-pasted’ into the “Methods/Acquisition” section of a scientific publication. The tool will work with known and standardized data definitions and will be able to handle exceptions and missing data, handle several different data types, and check/report data consistency.
      
      
      Expected outcomes: 
      
      The backend currently handles input from BIDS data (Brain imaging data structure = NiFTI and JSON data) and DICOM data (in a pilot mode). The web-based GUI allows file uploads and automated report generation. We would like to add the following features:
      
      Current GUI reports missing required parameters. Add a new feature that interactively asks the user to provide the missing parameters;
      Improve the testing framework for comparing the input database with manually checked reference reports;
      Improve and finalize the module for the DICOM input to handle hidden and private tags that are specific for different input data (mentors will provide the keys to interpret these tags);
      Improve the modularity of the software to make future extensions to other sequences (DSC/DCE/IVIM) easy.
      Requirements:
      
      (Minimal) Python and basic experience in the development of web-based frontends
      (Willing to) Learn and understand the basics of the particular MRI sequences
      (Optional) Experience in medical imaging, MRI, or DICOM format
      
      
      Knowledge Atlas for OSIPI perfusion lexicons
      Proposed mentors: Ben Dickie, Patricia Clement
      
      Languages/skills: SQL
      
      Estimated project length: 350 hours
      
      Difficulty: Moderate
      
      Category: Core development
      
      Languages/skills: Python, databases, web development
      
      Relevant links: https://github.com/OSIPI/OSIPI_CAPLEX
      
      Project description: A key problem in imaging science is the lack of reproducibility, which can arise from a number of sources, from the acquisition method itself, or simply whether or not the process is described clearly enough for others to follow. To address this, OSIPI has developed 2 lexicons (one for DCE/DSC and one for ASL). The contrast agent-based lexicon (CAPLEX) is currently hosted on a GitHub documentation site, whereas the ASL lexicon is still only accessible through Google Docs. This project will continue preliminary work to overhaul how the two lexicons are displayed and accessed by migrating to a database and building a web app to display the lexicon content and tools.
      
      Expected outcomes:
      
      A database consisting of lexicons, as well as providing room for future database projects
      Web app to display lexicon content and tools
      Requirements:
      
      Databases (e.g. SQL), Experience with data handling and manipulation (e.g., file I/O, databases)
      Basic knowledge of web development frameworks (e.g., Flask, Django, FastAPI) for API development
      Basic understanding of medical imaging concepts
      
      Unified HTML pages for OSIPI output
      Proposed mentors: Petra van Houdt, Luis Torres
      
      Languages/skills: Python, Markdown
      
      Estimated project length: 90 hours
      
      Difficulty: Easy
      
      Category: Low-hanging fruit
      
      Relevant links: OSIPI_CAPLEX, OSIPI DCE-DSC code
      
      Project description: Over time, OSIPI has produced several projects with published documentation.  However, due to the nature of our organization’s organic growth, their styles, structure, and fundamental set-ups are different, which leads to difficulty organizing, searching, and finding relevant information in our docs. In this project, we will standardize our approach by leveraging current best practices for HTML generation and styling and then subsequently port all of the existing documentation to this new approach. One of the outcomes of this project is to provide recommendations for future documentation tasks that comply with our styling.  
      
      Expected outcomes:
      
      The main outcome of this project is to create a unified standard/style for our documentation hosted via GitHub.
      A secondary outcome will be to unify current documentation with our defined standard.
      Requirements:
      
      (Required) Python, Markdown
      (Optional) HTML/CSS
      (Ideal) Github Pages, MkDocs, Admonitions
      
      Infrastructure/Automation
      Dockerized Data Processing Pipeline for Medical Imaging
      Proposed mentors: Eric Peterson, Luis Torres
      
      Languages/skills: Python
      
      Estimated project length: 350 hours
      
      Difficulty: Moderate
      
      Category: Infrastructure/automation
      
      Project description:
      
      This project aims to develop a containerized pipeline that can efficiently process medical imaging data using IVIM or other tools. The modularized docker images will encapsulate all necessary dependencies, enabling cross-platform deployment, execution and integration with clinical imaging pipelines. Finally, we want to enable visual orchestration of the resulting pipeline through a web-based interface.
      
      Expected outcomes:
      
      Key outcomes will include:
      
      Modular, containerized processing pipelines with support for reading and writing data as DICOM and NIfTI from local disks, cloud storage, and DICOM server integrations (such as PACS).
      A simple web-based interface for orchestrating the image processing pipeline enabling users to monitor the status of processing jobs, view logs, and configure runtime parameters.
      Ultimately this project will result in a valuable tool for medical imaging researchers and practitioners. The containerized pipeline will streamline data processing workflows, improve efficiency, and facilitate collaboration by providing a standardized and reproducible environment for image analysis tasks.
      
      
      Requirements:
      
      (Required) Unittest, pytest, Docker
      (Optional) Kubernetes, Airflow/Argo
      Basic understanding of medical imaging concepts (e.g., DICOM format)
      Experience with data handling and manipulation (e.g., file I/O, databases)
      Basic knowledge of web development frameworks (e.g., Flask, Django, FastAPI) for API development
      
      GitHub testing for ExploreASL pipeline 
      Proposed mentors: Henk-Jan Mutsaerts, Mathijs Dijsselhof, Jan Petr
      
      Languages/skills: GitHub, Matlab
      
      Estimated project length: 90 hours
      
      Difficulty: Easy
      
      Relevant links: ExploreASL code, ExploreASL publication
      
      Category: Low hanging-fruit
      
      Project description: While basic processing of ASL perfusion MRI data can be done using in-house scripts or GUIs, a dedicated pipeline able to batch-process large heterogeneous datasets is needed to process large clinical studies efficiently. ExploreASL is an open-source package that was developed specifically for this task. Testing is of the highest importance in sustaining further software development in a larger group of collaborators. While we have several tests in place, we lack their joint integration and automation.
      
      
      Expected outcomes: 
      
      We need to configure GitHub actions to run the collection of our test automatically:
      
      Configure and debug GitHub actions to run our Matlab test scripts on different OSes.
      Adapt the test result to the JUnit or similar format
      Requirements:
      
      (Minimal) GitHub and Matlab experience
      (Optional) Experience with GitHub actions and JUnit testing
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-science-initiative-for-perfusion-imaging/
    idea_list_url: https://docs.google.com/document/d/e/2PACX-1vSuYh57hsLUXbmrA5tozX4Ucne0sRXnmFt5xBA88gzDZJKZYD4-Bq04J9acer2d_i6NP6xhimmz4m5i/pub


  - organization_id: 106
    organization_name: Open Science Labs
    no_of_ideas:
    ideas_content: |
      Project Ideas
      Contributor Guide
      Project Idea Template
      Contributor Project Proposal Template
      OSL Project Ideas for GSoC 2025 #
      Welcome to the Open Science Labs (OSL) project ideas page for Google Summer of Code 2025. As an umbrella organization, OSL hosts links to the ideas pages of each member organization. You can explore these projects here.
      At OSL, we've assembled a selection of project ideas that not only embody our mission but also provide enriching experiences for student and newcomers open-source developpers. These projects cover a variety of topics and technologies, catering to diverse interests. Below, we've outlined some potential project ideas we're considering for GSoC. We believe these projects provide students with a valuable chance to engage with open-source efforts and develop their skills under the mentorship of seasoned professionals.
      This page details the sub-organizations available for GSoC 2025 participants. Applicants are welcome to reach out to us on our Discord or directly contact the sub-oganization/project mentors.
      Sub-Organizations #
      Note: Each organization includes a designated list of mentors. Please get in touch with them directly if you have any inquiries.
      Alpha One Labs #
      Description: Alpha One Labs is an education platform designed to facilitate both learning and teaching. The platform provides a comprehensive environment where educators can create and manage courses, while students can learn, collaborate, and engage with peers. With features like study groups, peer connections, and discussion forums, we aim to create a collaborative learning environment that goes beyond traditional online education.
      Project WEB Page: https://www.alphaonelabs.com/
      Repository: https://github.com/alphaonelabs/education-website
      Communication channel: Slack
      Project Ideas: link
      ArxLang/ASTx #
      Description: ASTx is an agnostic expression structure for AST. It is agnostic because it is not specific to any language.
      Project WEB Page: https://astx.arxlang.org/
      Repository: https://github.com/arxlang/astx
      Communication channel: Discord
      Project Ideas: link
      Makim #
      Description: Makim is based on make and focus on improving the way to define targets and dependencies. Instead of using the Makefile format, it uses yaml format.
      Project WEB Page: https://osl-incubator.github.io/makim/
      Repository: https://github.com/osl-incubator/makim
      Communication channel: Discord
      Project Ideas: link
      PyDataStructs #
      Description: PyDataStructs project aims to be a Python package for various data structures and algorithms (including their parallel implementations).
      Project WEB Page: https://pydatastructs.readthedocs.io/en/latest/
      Project Ideas: link
      Rago #
      Description: Rago is a lightweight framework for RAG.
      Project WEB Page: https://osl-incubator.github.io/rago/
      Repository: https://github.com/osl-incubator/rago
      Communication channel: Discord
      Project Ideas: link
      Sugar #
      Description: Sugar organizes your stack of containers, gathering some useful scripts and keeping this information centralized in a configuration file with a friendly command line interface.
      Project WEB Page: https://osl-incubator.github.io/sugar/
      Repository: https://github.com/osl-incubator/sugar
      Communication channel: Discord
      Project Ideas: link
      Last update: 2025-03-14
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-science-labs/
    idea_list_url: https://opensciencelabs.org/opportunities/gsoc/project-ideas/


  - organization_id: 107
    organization_name: Open Technologies Alliance - GFOSS
    no_of_ideas:
    ideas_content: |
      Google Summer of Code 2025 proposed ideas
      Jump to navigation
      Jump to search
      Contributors interested to participate should check which of the following projects fits their interests and skills.
      Τo communicate with the mentors and ask questions about the projects, students should subscribe to this list and post relevant questions. Please follow the Proposal Template
      For practical information, developers should visit this page.
      Contents
      1 Expanding HassIO smart home capabilities via low-code automation development
      1.1 Brief Explanation
      1.2 Expected Results
      1.3 Duration of the Project
      1.4 Related repositories
      1.5 Knowledge Prerequisites
      1.6 Mentors
      2 A Tool for Visualizing the Arguments, Sentiments and User Interactions of Online Discussions
      2.1 Brief Explanation
      2.2 Related repositories
      2.3 Expected Results
      2.4 Mentors
      3 PersonalAIs: Generative AI Agent for Personalized Music Recommendations
      3.1 Brief Explanation
      3.2 Core Features & Technologies:
      3.3 Expected Results
      3.4 Duration of the Project
      3.5 Knowledge Prerequisites
      3.6 Mentors
      4 OpenRF 3D
      4.1 Brief Explanation
      4.2 Expected Results
      4.3 Duration of the Project
      4.4 Related repositories
      4.5 Knowledge Prerequisites
      4.6 Mentors
      5 Exploring and Abstracting Triplestore Alternatives
      5.1 Brief Explanation
      5.2 Objective
      5.3 Background
      5.4 Project Description
      5.5 Methodology
      5.6 Expected Outcome
      5.7 Conclusion
      5.8 Duration of the Project
      5.9 Information links
      5.10 Knowledge Prerequisites
      5.11 Mentors:Alexios Zavras, TBD
      6 Flexible GovDoc Scanner
      6.1 Brief Explanation
      6.2 Related repositories
      6.3 Expected Outcome
      6.4 Knowledge Prerequisites
      6.5 Mentors:
      7 Extending the capabilities of OpenTRIM
      7.1 Brief Explanation
      7.2 Expected Outcome
      7.3 Duration of the Project
      7.4 Related repositories
      7.5 Knowledge Prerequisites
      7.6 Mentors:
      8 Cleaning of HPLT Greek v2 Dataset for GlossApi LLM
      8.1 Brief Explanation
      8.2 Expected Outcome
      8.3 Duration of the Project
      8.4 Related repositories
      8.5 Knowledge Prerequisites
      8.6 Mentors:
      9 Add SAML and OpenID Connect support to Consul Democracy
      9.1 Brief Explanation
      9.2 Expected Results.
      9.3 Duration of the Project
      9.4 Related Repositories
      9.5 Knowledge Prerequisites
      9.6 Mentors
      10 Docker for Consul Democracy citizen participation platform
      10.1 Brief Explanation
      10.2 Expected Results.
      10.3 Duration of the Project
      10.4 Related Repositories
      10.5 Knowledge Prerequisites
      10.6 Mentors
      11 Εxtending the apothesis factory pattern for seamless 2D and 3D lattice integration
      11.1 Overview
      11.2 Related work
      11.3 Details of your coding project
      11.4 Size
      11.5 Skills
      11.6 Expected impact
      11.7 Mentors
      11.8 Tests
      11.9 References
      12 Identifying transition points in the ZGB model using convolutional neural networks (CNNs)
      12.1 Overview
      12.2 Related work
      12.3 Details of your coding project
      12.4 Size
      12.5 Skills
      12.6 Expected impact
      12.7 Mentors
      12.8 Tests
      12.9 References
      13 MyUni
      13.1 Brief Explanation
      13.2 Expected Results.
      13.3 Duration of the Project
      13.4 Related repositories
      13.5 Knowledge Prerequisites
      13.6 Mentors:
      14 GlossAPI
      14.1 Brief Explanation
      14.2 Expected Results
      14.3 Duration of the Project
      14.4 Related Repositories
      14.5 Knowledge Prerequisites
      14.6 Mentors
      15 DIY IoT Physics Experiments for education
      15.1 Brief Explanation
      15.2 Related repositories
      15.3 https://github.com/totheworld2004/DIY-Physics-IoT
      15.4 Exprected Outcome:
      15.5 Knowledge Prerequisites
      15.6 Mentors:
      16 eCodeOrama, an educational interactive flow visualization tool for mit scratch programs
      16.1 Brief Explanation
      16.2 Expected Results
      16.3 Duration of the Project
      16.4 Related repositories
      16.5 Knowledge Prerequisites
      16.6 Mentors:
      Expanding HassIO smart home capabilities via low-code automation development[edit | edit source]
      Brief Explanation[edit | edit source]
      Smart environments are becoming quite popular in the home setting consisting of a broad range of connected devices. While offering a novel set of possibilities, this also contributes to the complexity of the environment, posing new challenges to allowing the full potential of a sensorized home to be made available to users. SmAuto, is a Domain Specific Language (DSL) that enables users to program complex automation scenarios and pipelines, for connected IoT devices in smart environments, that go beyond simple tasks. It was initially developed by the ISSEL research team (AUTH) as textual DSL and later evolved into a web-based low-code development environment. SmAuto lacks extra features like utilization of external REST data sources, time delays, semantic annotation, and accessing of in-house entities, etc., thus it should be expanded in this direction. Furthermore, HomeAssistant would benefit from the integration of a low-code approach for rapidly developing and deploying automations, using the entities existing in a smart environment.
      Expected Results[edit | edit source]
      • In the context of this project, we desire to expand the SmAuto DSL with the following features: a) support the REST protocol, so as for the automations to be able to access information from external data sources, b) incorporate auxiliary concepts like Delay, Switches, or Compute nodes, c) SmAuto integration in HA. The integration of SmAuto and HomeAssistant should occur, by creating a new open-source HA addon, where users will be able to design and deploy automations graphically, using the SmAuto low-code environment.
      Duration of the Project[edit | edit source]
      (350 hours).
      Related repositories[edit | edit source]
      https://github.com/robotics-4-all/smauto, https://www.home-assistant.io/
      Knowledge Prerequisites[edit | edit source]
      [Required]: Python, Software engineering, IoT concepts, Unix/Linux, [Desired]: Model Driven Engineering, HomeAssistant, Docker
      Mentors[edit | edit source]
      Konstantinos Panayiotou, Emmanouil Tsardoulias, Andreas Symeonidis
      A Tool for Visualizing the Arguments, Sentiments and User Interactions of Online Discussions[edit | edit source]
      Brief Explanation[edit | edit source]
      In recent years, the analysis and visualization of dialogue have gained prominence in fields such as computational linguistics, social sciences, and human-computer interaction. The ability to model, analyze, and visualize real-life discussions provides valuable insights into the flow of conversations, the exchange of arguments, and the sentiments conveyed. Such visualizations can improve the understanding of complex discussions, foster decision-making, and even help develop better AI systems for facilitating or mediating discussions. We are particularly interested in online text-only discussions (e.g. on platforms like Reddit).
      Various tools and platforms have been developed in order to facilitate structured discussions and multi-party decision making. Kialo is an online, structured debate platform, where the use of argumentation is the central component. It allows the construction of argument maps, in the form of trees. It promotes thoughtful discussion, understanding of different viewpoints and collaborative decision-making, through visualizations of argument maps.
      Debategraph is another online structured debate platform, using more complex graphs, called &quot;mind-maps&quot;, where arguments are interconnected in a web-like structure. It allows an even wider choice of visualizations of relationships between ideas.
      DebateVis is a tool that can help non-expert users explore and analyze debate transcripts. Given a transcript, the tool produces: (a) an Interactions Graph that summarizes how often each candidate spoke overall, mentioned other candidates and discussed each topic, (b) an Annotated Transcript with automatically extracted topic labels and speaker interactions, (c) a Timeline visualization providing an overview of the debate.
      Finally, VisArgue is a framework proposing a range of visualizations of dialogues, including: Lexical Episode Plots (a timeline representation of the topics discussed), (b) Conversational Topic Visualizations, representing the shifting of focus of individual user on topics, (c) various statistics measuring user participation, respect, justification and accommodation, (d) Lexical Units, which are timeline representations of features such as the amount of argumentation and emotions.
      Although tools such as the above offer important functionality, there are still issues: in most cases, either the source code is not available, or integration with new projects is not seamless, or it is difficult to parameterize the output. Furthermore, the tools above focus mostly on debate, whereas we are also interested in other types of online discussions (e.g. deliberation to improve legislation bills, non-adversarial discussions for intra-company decision making).
      Therefore, this project’s goal is the design and implementation of an open source tool for visualizing and analyzing real-life, online, text-only discussions, exploring subjects like: topics discussed, arguments exchanged and emotions conveyed. The project will also explore how these visualizations can be leveraged for improving public understanding of contentious issues, academic discourse, and online discussion platforms.
      Project Objectives / Contributions:
      - Select, from the literature, prominent dialogue visualization approaches / ideas (e.g. styles of graph-based, or timeline-based, visualizations used) to represent various aspects of real-life online discussions and collect available libraries (not necessarily discussion-specific) that can be used to implement them (e.g. Gephi, NetworkX).
      - Explore the open-source toolkits being developed in the Archimedes project “LLM3: LLMs as mediators and moderators” to measure dialogue quality aspects (e.g., sentiment, politeness, topics, user participation) and select those that can provide useful meta-data for visualizing on-line discussions.
      - Develop a tool capable of ingesting data from real-life online discussions generating relevant meta-data (possibly by calling other toolkits) and producing the desired visualizations of the discussions.
      - Potentially, evaluate the effectiveness of the tool and its visualizations in making complex online discussions understandable to diverse audiences, such as researchers, mediators, or general users.
      Project Impact:
      - A novel, easy-to-use, open source, visualization tool (with accompanying paper) for online, text-only discussions, that can help the analysis of discussions in different settings and domains (e.g. political discourse, academic debates, or customer feedback).
      - Expand the general understanding of how visualization techniques can make debates more accessible and informative (possibly also leading to a publication).
        - Contribution to the Archimedes project “LLM3: LLMs as mediators and moderators” which aims to develop and evaluate LLM-based mediation agents that will actively participate in online discussions, with or without additional human mediation.
      Key Types of Dialogue Visualizations:
      The project will develop and explore several types of dialogue visualizations. Some are briefly described below. The contributor will be free to propose and implement new ones.
          1) Timelines: they represent the chronological flow of a conversation, highlighting key moments such as topic shifts, argument introductions and emotional peaks. Possible Features: topic evolution over time, points of conflict or agreement, visual markers for significant events (e.g. emotional outbursts or resolution points).
          2) Argumentation Graphs: they visualize the logical structure of arguments, including claims, counterclaims and evidence. Possible Features: nodes representing arguments or claims, edges denoting relationships (e.g., support, contradiction).
          3) User Interaction Graphs: they map the relationships and interaction patterns between participants in the debate. Possible Features: nodes representing participants, weighted edges showing the frequency, tone, or sentiment of interactions, clusters indicating subgroups or coalitions in the dialogue.
          4) Sentiment Heatmaps: they analyze and visualize the emotional dynamics of a conversation. Possible Features: color-coded intensity for positive, negative, or neutral sentiments, overlay with timeline or topic visualization for richer insights.
          5) Topic Trees or Topic Flow Diagrams: they represent how topics are introduced, branched out, and revisited during the discussion. Possible Features: hierarchical or radial layouts for topic relationships, highlights of overlapping or transitioning topics.
          6) Hybrid Visualizations: by combining multiple visualization techniques.
      Importance of Dialogue Visualizations:
      Dialogue visualizations, such as those presented above, can support:
      - Topic Analysis: by identifying the main topics discussed and their transitions over time, and by highlighting overlapping topics and their importance to the dialogue.
      - Argumentation Analysis: by understanding the logical flow of arguments, counterarguments, and evidence, and by identifying circular reasoning, weak arguments, or areas of agreement.
      - Sentiment Analysis: by visualizing the emotional tone of the conversation and its impact on the debate, and by examining whether certain sentiments correlate with specific topics or arguments.
      - Participant Dynamics: by mapping the influence and activity of each participant, and by analyzing interaction patterns (e.g., dominance, interruptions, alliances).
      Methodology:
      - Data Collection and Preparation:
      The tool should be able to ingest data from various online debate platforms (e.g. Reddit, Kialo), from political debate transcripts, from academic discourse, as well as from debates among LLM-agents. Since the format of raw data may vary, we propose the use of the Convokit tool in order to homogenise and preprocess the data.
      - Development of Visualization Prototypes:
      Tools/Technologies: Python (matplotlib, seaborn, Plotly), D3.js for web-based visualizations, or tools like Gephi for network analysis. Use natural language processing (NLP) libraries (e.g., spaCy, Hugging Face Transformers) for topic modeling, sentiment analysis, and argument mining, along with tools being developed at the LLM3 project of Archimedes.
      - User Feedback and Iterative Improvement:
      Test the outputs (visualizations) with researchers, mediators, or other stakeholders. Refine designs based on usability feedback and task-specific performance.
      Evaluation
      If time allows, the contributor will contribute in evaluating the effectiveness of their dialogue visualizations, in the context of Archimedes’ LLM3 project, by using them for both real-life and LLM-generated dialogues. Their output will be measured on clarity, usability and informativeness.
      Desired Profile:
      We are looking for a contributor with the following characteristics:
      - Good programming skills in Python (experience in network analysis and / or NLP is a plus).
      - Experience (and interest for) coding visual representations of concepts with libraries such as: matplotlib, seaborn, Plotly, Gephi, D3.js.
      - Interest in the subject of human interaction through dialogue (more specifically, on themes such as: argumentation, topic identification, sentiment analysis).
      - A taste for concise, elegant and efficient solutions / visualizations.
      The contributor will be mentored/supported by members of the LLM3 project, the broader NLP group of Archimedes (https://archimedesai.gr/en/), as well as the NLP Group (http://nlp.cs.aueb.gr/) of the Department of Informatics, Athens University of Economics and Business.
      Conclusion:
      This GSOC project aims to develop an open-source tool that will make complex, online discussions more understandable, insightful, and actionable. By capturing the topics, arguments, sentiments, and participant dynamics, it will offer a comprehensive approach to online dialogue visualization that can benefit multiple fields, from education to public policy.
      Related repositories[edit | edit source]
      https://sites.google.com/view/llm3/home
      Expected Results[edit | edit source]
      A tool able to process real-life, text-only dialogues and produce selected visualizations capturing their essential points.
      Mentors[edit | edit source]
      Dionysios Kontarinis (denniskont@gmail.com), Ion Androutsopoulos, Ioannis Pavlopoulos
      PersonalAIs: Generative AI Agent for Personalized Music Recommendations[edit | edit source]
      Brief Explanation[edit | edit source]
      This project aims to develop an AI-powered agent that interacts with users in natural language to determine their emotional state and musical preferences in a conversational manner. The agent will then generate and refine music playlists accordingly. The system will integrate with the Spotify API to provide personalized recommendations based on user preferences, liked songs, and listening history. Users can opt-out of personal data usage for a more exploratory approach. The agent will also enable real-time conversational modifications to playlists, allowing users to tweak mood, energy, and genre preferences.
      Core Features & Technologies:[edit | edit source]
      - Natural Language Processing (NLP): Used to determine user mood and preferences based on conversation.
      - Generative AI: Small LLM models hosted locally or accessed via an API key for dialogue generation.
      - Spotify API Integration: Authentication, playlist management, retrieval of user metadata (liked songs, playlists, etc.).
      - Frontend UI: A web-based chatbot interface similar to ChatGPT.
      - Backend Processing: Handles AI model interactions, API requests, and user session management.
      - Real-time Modifications: Users can refine recommendations by requesting changes in mood, genre, energy, etc.
      Sources &amp;amp; References:
      - Spotify API Documentation: https://developer.spotify.com/documentation/web-api/
      Mood-Based Playlist Research:
      - Generating personalized music playlists based on mood and listening data
      - Moodify: Emotion recognition in songs for personalized recommendations
      Example Datasets:
      - Moodify Dataset (Spotify-based mood labels)
      - Awesome Music Emotion Recognition (MER) Dataset Collection
      Expected Results[edit | edit source]
      ''- A full-stack AI agent (local hosted and/or API Key) that generates personalized music playlists based on user input.  - Integration with Spotify API for user authentication, playlist creation, and retrieval of user metadata.  - Real-time, conversational playlist modifications through a chatbot-style UI.  - Advanced mood detection using NLP or audio analysis. Integration with external music recommendation sources.
      Duration of the Project[edit | edit source]
      (350 hours).
      Knowledge Prerequisites[edit | edit source]
      ''- Basics of Machine Learning and NLP.  - Experience with pre-trained generative models (e.g., GPT, BERT) and recommendation systems.  - Familiarity with APIs, particularly Spotify API.  - Frontend/backend development experience for a chatbot-style UI.
      Mentors[edit | edit source]
      Giannis Prokopiou, Thanos Aidinis
      OpenRF 3D[edit | edit source]
      Brief Explanation[edit | edit source]
      This project aims to bridge NVIDIA Sionna’s 6G simulation framework with Cesium’s 3D geospatial engine, enabling real-time, terrain-aware wireless network analysis. The student will develop a bidirectional WebSocket pipeline to dynamically stream Cesium’s elevation and 3D building data into Sionna, where channel models are enhanced to account for terrain-induced pathloss and urban blockages. Simultaneously, Sionna’s ray-traced outputs (e.g., signal strength, beamforming patterns) will be visualized in Cesium as interactive heatmaps and antenna coverage overlays. Key deliverables include a Python/JavaScript interface using Protocol Buffers for efficient data serialization, integration of 3GPP TR38.901 models with real-world terrain, and Jupyter notebooks demonstrating urban/rural 5G optimization.
      Expected Results[edit | edit source]
      By the end of GSoC, this project will deliver a fully functional bidirectional WebSocket pipeline that integrates NVIDIA Sionna’s 6G simulation framework with Cesium’s 3D geospatial engine, enabling real-time, terrain-aware wireless network analysis. The system will dynamically stream Cesium’s elevation and 3D building data into Sionna, enhancing 3GPP TR38.901 propagation models with terrain-induced pathloss and urban blockages. Simultaneously, Sionna’s ray-traced outputs (signal strength, beamforming patterns) will be visualized in Cesium as interactive heatmaps and antenna coverage overlays. The project will develop an optimized Python/JavaScript interface using Protocol Buffers, ensuring low-latency, high-performance data exchange between Cesium and Sionna. Additionally, Jupyter notebooks will demonstrate urban/rural 5G optimization, beamforming analysis, and comparative studies of RF propagation models. The final deliverables will include a fully documented API, setup guides, and tutorials, contributing to the NVIDIA Sionna and Cesium open-source communities. This integration will significantly improve realism in RF simulations, allowing for next-generation 6G research, network optimization, and smart city planning.
      Duration of the Project[edit | edit source]
      (350 hours).
      Related repositories[edit | edit source]
      https://github.com/NVlabs/sionna, https://github.com/CesiumGS/cesium
      Knowledge Prerequisites[edit | edit source]
      A developer with strong Python & JavaScript skills, and an understanding of real-time networking (WebSockets, Protobuf). Experience in wireless communications & 3D geospatial visualization, and prior exposure to Sionna, CesiumJS would be highly beneficial.
      Mentors[edit | edit source]
      Ilias Chrysovergis (https://www.linkedin.com/in/ilias-chrysovergis/), Iason Malkotsis (https://malkotsis.com/)
      Exploring and Abstracting Triplestore Alternatives[edit | edit source]
      Brief Explanation[edit | edit source]
      Objective[edit | edit source]
      The primary objective of this project is to explore, analyze, and abstract various triplestore alternatives. The project aims to provide young programmers with a comprehensive understanding of different back-end alternatives that allow for storing data in triple format, commonly known as triplestores.
      Background[edit | edit source]
      Triplestores are a type of database specialized in storing triples, a data structure for representing information in a subject-predicate-object format. They are crucial in semantic web technologies, such as RDF, SPARQL, and OWL. However, there are numerous triplestore alternatives available, each with its own strengths and weaknesses.
      Project Description[edit | edit source]
      This project will involve a detailed exploration of various triplestore alternatives. The participants will perform rudimentary tests and benchmarks on these alternatives to understand their performance, scalability, and other key features.
      The ultimate goal is to develop a library that can act as an abstraction layer for these triplestore alternatives. This library will "hide" the underlying implementation, allowing developers to switch between different triplestores without changing their application code. This abstraction layer can be compared to a library abstracting various specific relational database management systems, all providing very similar functionality, like supporting SQL.
      Methodology[edit | edit source]
      Research: Identify and study various triplestore alternatives. Understand their architecture, features, and limitations.
      Testing: Perform rudimentary tests and benchmarks on the identified triplestore alternatives.
      Analysis: Analyze the test results to understand the performance and scalability of each alternative.
      Development: Develop an abstraction layer that can interface with the various triplestore alternatives.
      Documentation: Document the findings and the usage of the developed library.
      Expected Outcome[edit | edit source]
      By the end of the project, we expect to have a well-documented library that can act as an abstraction layer for various triplestore alternatives. This will provide developers with the flexibility to choose the most suitable triplestore for their specific needs without having to modify their application code.
      Conclusion[edit | edit source]
      This project will not only enhance the understanding of participants about triplestore alternatives but also equip them with the skills to develop an abstraction layer, thereby broadening their programming skills and knowledge.
      Duration of the Project[edit | edit source]
      Long (350 hours)
      Related repositories
      New project, no existing repo available.
      Information links[edit | edit source]
      - Triplestore - Triples - Query language
      Knowledge Prerequisites[edit | edit source]
      Python (mandatory). Other programming languages like C, Go, Rust, Java, might prove useful.
      Mentors:Alexios Zavras, TBD[edit | edit source]
      Flexible GovDoc Scanner[edit | edit source]
      Brief Explanation[edit | edit source]
      The goal of this project is to develop the Flex GovDoc Scanner, an application that leverages the Node.js stack, AI tools, and cloud services to transform public incorporation documents from Greece's business portal (ΓΕΜΗ, https://publicity.businessportal.gr/) into structured, searchable data. This project aims to facilitate access to essential company information, such as legal representatives, board members, and incorporation history, by offering advanced discovery capabilities through a REST service.
      Project Overview:
      - Crawl and Index Public Documents:
        Develop a robust crawling mechanism to gather all relevant PDF documents from the ΓΕΜΗ portal while ensuring compliance with legal standards.
      - Extract and Structure Metadata:
        Utilize AI and OCR technologies to extract key metadata from these documents and store them in a structured format.
      - REST Service for Metadata Search:
        Create an efficient REST API to provide users with search functionalities on the extracted metadata, enabling easy access and analysis.
      Related repositories[edit | edit source]
      https://github.com/flexivian/govdoc-scanner
      Expected Outcome[edit | edit source]
      ''- Implement a nodejs application to Crawl and Index Public Documents, utilize an opensource DB optimized for documents - Enhance the application with AI and OCR capabilities to extract metadata from scanned documents - Implement a REST API using nodejs to provide users with search functionalities on the extracted metadata, enabling easy access and analysis.
      Knowledge Prerequisites[edit | edit source]
      nodejs, docker, git , AI concepts and tools, NLP, OCR, RESTful API design and implementation, Knowledge of databases (SQL or NoSQL)
      Mentors:[edit | edit source]
      iskitsas@gmail.com, vasilisnx@gmail.com
      Extending the capabilities of OpenTRIM[edit | edit source]
      Brief Explanation[edit | edit source]
      OpenTRIM is a new open-source code for simulating the passage of energetic ions through materials and calculating the associated modifications and damage that they cause to the these materials. It is based on the kinetic Monte-Carlo method and employs the Binary Collision Approximation to describe the interaction between ions and target atoms. OpenTRIM comprises of a set of C++ libraries, a command line program for executing simulations in batch mode and a Qt-based graphical user interface that can be used to configure &amp;amp; run a simulation and evaluate the results. Currently, there are various parts of OpenTRIM where work is needed for improving and extending the capabilities of the code.
      Expected Outcome[edit | edit source]
      1. Extend the base C++ simulation code to include new capabilities for user-defined “tallies”, i.e., scoring tables where data from the simulation are extracted as a function of ion energy, position, direction or other possible optional variables.  2. Create a tool for 2D or 3D visualization of the simulated ion trajectories. 3. Write a number of example simulations, complete with the required input files and evaluation of the output results, which will become a part of the code documentation.
      Duration of the Project[edit | edit source]
      Depending on the proposal
      Related repositories[edit | edit source]
      https://github.com/ir2-lab/OpenTRIM
      Knowledge Prerequisites[edit | edit source]
      C++, Qt (optional), OpenGL (optional)
      Mentors:[edit | edit source]
      George Apostolopoulos (https://github.com/gapost), Michail Axiotis (https://github.com/psaxioti), Eleni Mitsi (https://github.com/elmitsi)
      
      Cleaning of HPLT Greek v2 Dataset for GlossApi LLM[edit | edit source]
      Brief Explanation[edit | edit source]
      Cleanup of the Greek datasets at https://hplt-project.org/datasets/v2.0. The cleanup will be done with the help of the glossAPI team.
      For methodology see https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1+.
      Expected Outcome[edit | edit source]
      The goal is to isolate from the html Greek text with normal grammar and complete sentences (not fragmented).
      Duration of the Project[edit | edit source]
      Depending on the proposal
      Related repositories[edit | edit source]
      https://github.com/eellak/glossapi
      Knowledge Prerequisites[edit | edit source]
      Python, βιβλιοθήκες NLP
      Mentors:[edit | edit source]
      Foivos Karounos, Nikolaos Vidras
      
      Add SAML and OpenID Connect support to Consul Democracy[edit | edit source]
      Brief Explanation[edit | edit source]
      Consul Democracy is a web-based citizen participation tool written in Ruby, using the Ruby on Rails framework. Consul Democracy is licensed under the AGPL and its installations are decentralized, meaning there are more than 200 institutions across the world running their own independent server and using a custom version of Consul Democracy. Some of these institutions have authentication solutions based on either SAML or OpenID Connect; however, there's no built-in support for these authentication solutions in Consul Democracy, so each institution has to build their own.
      In Ruby, the OmniAuth library provides a standard way to manage multi-provider authentication. Consul Democracy currently uses several Ruby gems, all based on OmniAuth, to provide authentication via Facebook, Google, Twitter/X and WordPress. There's been an attempt at providing SAML support using the omniauth-saml Ruby gem, but its development hasn't been finished due to the lack of a SAML platform to test against.
      Consul Democracy also supports multitenancy, meaning the same application can be used to manage several institutions (with different domains or subdomains). For authentication using Facebook, Google, Twitter/X or WordPress, Consul Democracy provides the option to use the same configuration for each institution, to use different configurations for different institutions, or a mix of both (one default configuration which can be overwritten per institution).
      The aim of this proposal is to provide generic SAML and OpenID Connect authentication solutions in Consul Democracy so a variety of institutions can easily integrate their existing authentication platform.
      Expected Results.[edit | edit source]
      * Make it possible to authenticate in Consul Democracy using a SAML service
      * Make it possible to authenticate in Consul Democracy using an OpenID Connect service
      * Both SAML and OpenID Connect solutions must allow different configurations for different institutions in a multitenant environment
      * Both SAML and OpenID Connect solutions should be flexible enough so institutions don't have to change the source code in order to configure their service
      * The source code of the SAML and OpenID Connect solutions should be similar to the source code of the existing Facebook, Google, Twitter/X and WordPress solutions
      * Update the documentation with instructions on how to configure SAML and OpenID Connect
      Duration of the Project[edit | edit source]
      Medium Size 175 hrs
      Related Repositories[edit | edit source]
      https://github.com/consuldemocracy/consuldemocracy
      Knowledge Prerequisites[edit | edit source]
      * SAML and OpenID Connect authentication configuration * (Optional) Ruby on Rails and OmniAuth authentication
      Mentors[edit | edit source]
      Javier Martín - https://github.com/javierm, Sebastià Roig - https://github.com/taitus
      
      Docker for Consul Democracy citizen participation platform[edit | edit source]
      Brief Explanation[edit | edit source]
      Consul Democracy is a web-based citizen participation tool written in Ruby, using the Ruby on Rails framework. Consul Democracy is licensed under the AGPL and its installations are decentralized, meaning there are more than 200 institutions across the world running their own independent server and using a custom version of Consul Democracy. That means Consul Democracy developers don't have access to production machines, and so Consul Democracy must be as simple to install and maintain as possible so anyone can do it no matter how familiar they are with the technologies used by Consul Democracy.
      Currently, Consul Democracy is installed on production by running an ansible-based installer which installs all the project dependencies on a Debian GNU/Linux or Ubuntu Linux server. Deployment of new developments is then done using Capistrano.
      The source code of Consul Democracy contains a Dockerfile and a docker-compose.yml file that are exclusively meant for the development environment, in order to make it easier for developers who are familiar with Docker to contribute to the project. However, there's currently no way to deploy to a production environment using Docker, which is inconvenient for institutions who don't use Debian or Ubuntu on their servers, or for institutions who have adopted Docker as their preferred way to setup their servers. The main goal of this proposal is to solve this issue. Since 2024, Ruby on Rails applications are configured to use Kamal by default as a solution to deploy to production using a Docker container. To our knowledge, this would be the most simple solution to our problem.
      There's a third kind of Docker integration, which uses a devcontainer to allow developers to use tools like GitHub Codespaces to run the application in a development environment, which is also configured by default in new Rails applications since 2024, and we'd like to enable this option in Consul Democracy.
      With this developments, we could enable many more municipalities to utilise digital citizen participation - and thus offer their citizens greater involvement in the development of their cities.
      Expected Results.[edit | edit source]
      * Make it possible to install and deploy Consul Democracy applications using Docker in the most simple way (probably with Kamal)
      * Add a devcontainer for integration with GitHub Codespaces
      * Make sure the current development setup with Docker keeps working after the previous additions *
      The configuration files for all three environments mentioned above should have as little duplicate code as possible so they're easy to maintain
      * Update the technical documentation for both development and production environments
      Duration of the Project[edit | edit source]
      Medium Size 175 hrs
      Related Repositories[edit | edit source]
      https://github.com/consuldemocracy/consuldemocracy
      Knowledge Prerequisites[edit | edit source]
      * Experience deploying to production environments using Docker
      * (Optional) Experience using Docker in Ruby on Rails applications
      Mentors[edit | edit source]
      Javier Martín - https://github.com/javierm, Sebastià Roig - https://github.com/taitus
      Εxtending the apothesis factory pattern for seamless 2D and 3D lattice integration[edit | edit source]
      Overview[edit | edit source]
      Apothesis is a generalized software for designing, simulating, and analyzing deposition processes using the kinetic Monte Carlo method. It consists of two main components: a lattice (e.g., simple cubic, HPC, etc.) and the processes (adsorption, desorption, diffusion, and surface reactions) that occur within it. Currently, Apothesis includes a factory-based mechanism for lattice creation, but this implementation is limited in scope, primarily focusing on basic lattice structures. To enhance its flexibility and scalability, this proposal aims to extend the factory pattern to support a broader range of 2D and 3D surfaces in a seamless and modular way. This extension will involve introducing specialized lattice factories tailored for different geometries, such as hexagonal, face-centered cubic, and custom surface representations, ensuring compatibility with kinetic Monte Carlo processes. Additionally, a dynamic factory registry system will be implemented, allowing new lattice types to be registered and instantiated at runtime without modifying the core system. This approach will not only improve adaptability but also facilitate user-defined lattice structures while preserving maintainability and efficiency. By refining the factory mechanism, Apothesis will provide a more robust framework for deposition process simulations, enabling researchers and engineers to explore a wider range of surface dynamics with greater ease.
      Related work[edit | edit source]
      Apothesis already implements a factory pattern for lattice creation, but it needs to be expanded to support a broader range of 2D and 3D surfaces in a more seamless and flexible way. The current implementation primarily focuses on basic lattice structures, and extending it would involve introducing specialized factories for different geometries, such as hexagonal, face-centered cubic, and custom surface representations. Enhancing the factory pattern should include a more modular approach, allowing new lattice types to be dynamically registered and instantiated without modifying the core system. Additionally, ensuring that these new lattice structures fully integrate with kinetic Monte Carlo processes—such as adsorption, desorption, diffusion, and surface reactions—will be crucial for maintaining simulation accuracy and consistency. By refining the factory mechanism and introducing a more extensible registry system, Apothesis can achieve greater adaptability, making it easier for users to define and integrate new lattice types while preserving maintainability and scalability.
      Details of your coding project[edit | edit source]
      A potential practical approach to extending the factory pattern in Apothesis for 2D and 3D surfaces involves creating a modular and extensible lattice generation system. This can be achieved by defining an abstract LatticeFactory that enforces a standard way of creating lattice structures while delegating specific implementations to derived factories. Specialized factories such as SimpleCubicLatticeFactory, HexagonalLatticeFactory, FCCLatticeFactory, and GrapheneLatticeFactory can be implemented to handle different lattice geometries while ensuring compatibility with kinetic Monte Carlo processes like adsorption, desorption, diffusion, and surface reactions. Each factory produces a lattice object implementing a common ILattice interface, encapsulating geometry, boundary conditions, and process compatibility. A dynamic factory registry mechanism allows runtime selection and registration of new lattice types, enabling users to introduce custom lattices without modifying the core code. This approach ensures scalability, flexibility, and maintainability by decoupling lattice creation from simulation logic while seamlessly supporting both 2D and 3D structures.
      Size[edit | edit source]
      Large (350 hours)
      Skills[edit | edit source]
      Required: C++, desing patters, experience with physicochemical based software
      Expected impact[edit | edit source]
      The expected impact of extending the factory pattern in Apothesis includes enhanced flexibility, scalability, and efficiency in lattice creation for deposition process simulations. By introducing a more modular and extensible approach, researchers and engineers will be able to seamlessly integrate new 2D and 3D surface structures without modifying core code, reducing development time and increasing adaptability. The improved factory mechanism will ensure better compatibility with kinetic Monte Carlo processes, enabling more accurate and diverse simulations of adsorption, desorption, diffusion, and surface reactions. Additionally, the dynamic factory registry will foster customization and extensibility, allowing users to define and register their own lattice structures, thereby broadening the range of possible simulations. Overall, this enhancement will make Apothesis a more powerful and user-friendly tool, supporting advanced research, industrial applications, and innovation in surface science and material deposition technologies.
      Mentors[edit | edit source]
      • Nikolaos (Nikos) Cheimarios <n.cheimarios at gmail.com> is a researcher with contributions in scientific software development. He has previous experience as mentor in 2020, 2022, 2023 and 2024. He is one of the authors of Apothesis, Chameleon software and several web-based scientific numerical applications.
      • Christianna Gatsiou <christianna.gatsiou at gmail.com>.
      Tests[edit | edit source]
      Students, the following test will be helpful. • Easy: Compile and run Apothesis for the CO heterogeneous catalysis case. • Medium: Perform runs with SimpleCubic and HPC lattices. • Hard: Identify the part of code that creates the lattices. Briefly describe how you would implement the 2D graphene lattice. For tips and references contact the Mentors!
      References[edit | edit source]
      [1] N. Cheimarios, D. To, G. Kokkoris, G. Memos and A.G. Boudouvis “Monte Carlo & Kinetic Monte Carlo models for deposition processes: A review of recent works”, Frontiers in Physics, 9, 165 (2021).
      [2] N. Cheimarios, “Insights into the effect of growth on the Ziff-Gulari-Barshad model and the film properties”, Modelling and Simulation in Materials Science and Engineering, 31, 065007, (2023).
      [3] A.P.F Jansen, "An Introduction to Kinetic Monte Carlo Simulations of Surface Reactions", Springer Berlin, Heidelberg, 2012. https://doi.org/10.1007/978-3-642-29488-4
      [4] M. Andersen, C. Panosetti, K. Reuter, "A Practical Guide to Surface Kinetic Monte Carlo Simulations", Frontiers in Chemistry, 7, 202 (2019).
      
      Identifying transition points in the ZGB model using convolutional neural networks (CNNs)[edit | edit source]
      Scientific computing for physical/chemical sciences and engineering edited this page 3 weeks ago ·
      Overview[edit | edit source]
      In 1986, Ziff, Gulari, and Barshad introduced the ZGB model to computationally study the heterogeneous catalytic process of CO oxidation to CO₂ with O₂ on a metal surface (e.g., Pt). Using Monte Carlo simulations on a simple square lattice, with the partial pressure of CO, yCO, as the only parameter, they demonstrated that at low yCO values, the catalytic surface becomes poisoned (fully covered) by oxygen atoms, preventing the surface reaction and the conversion to CO₂. In this case, the system remains out of equilibrium. As yCO increases, at approximately y1 ≈ 0.389, the system transitions to an equilibrium state where CO begins to convert into CO₂. Further increasing yCO leads to a first-order, discontinuous phase transition at y2 ≈ 0.525, where CO conversion to CO₂ ceases again due to surface poisoning by CO atoms. In 1990, Jensen and Fogedby extended this model by incorporating diffusion phenomena, showing that the transition points shift depending on the diffusion rate, pd , but do not disappear.
      Related work[edit | edit source]
      Apothesis is a generalized open-source software for simulating heterogeneous catalysis and deposition processes via kMC. It is based on performing certain processes (adsorption, desorption, diffusion and surface reaction(s)) on lattices. Currently, Apothesis supports simple cubic, FCC, HPC and diamond lattices. It has been used to study both heterogeneous catalysis of CO and related type growth models [2].
      Details of your coding project[edit | edit source]
      This works aims to predict the transition points using machine learning methods, specifically convolutional neural networks (CNNs), based on surfaces derived from kinetic Monte Carlo simulations from Apothesis at equilibrium states. For that, an outer shell to Apothesis must be build that will read the data from Apothesis and use it for training a CNN and then for the prediction of the transition points.
      Size[edit | edit source]
      Large (350 hours)
      Skills[edit | edit source]
      Required: Python, Tensorflow, experience with physicochemical based software
      Expected impact[edit | edit source]
      The project will build an outer shell for Apothesis to be used in ML/AI applications.
      Mentors[edit | edit source]
      Nikolaos (Nikos) Cheimarios <n.cheimarios at gmail.com> is a researcher with contributions in scientific software development. He has previous experience as mentor in GSoC 2020, 2022, 2023 and 2024. He is one of the authors of Apothesis, Chameleon software and several web-based scientific numerical applications.
      Konstantinos (Kostas) Eftaxias is a data scientist with more than 15 years of experience in research and industry applications. His main interests are computer vision, time series modelling/prediction and reinforcement learning.
      Tests[edit | edit source]
      Students, the following test will be helpful. • Easy: Compile and run Apothesis for the CO heterogeneous catalysis case. • Medium: Take three surfaces (SurfaceSpecies_*.dat) generated by Apothesis and read it in Python. • Hard: Call Apothesis from Python and read the latest surface generated. For tips and references contact the Mentors!
      References[edit | edit source]
      [1] R. M. Ziff, E. Gulari, and Y. Barshad, Kinetic Phase Transitions in an Irreversible Surface-Reaction Model, Phys. Rev. Lett. 56, 2553 (1986).
      [2] I. Jensen and H. C. Fogedby, Kinetic Phase Transitions in a Surface-Reaction Model with Diffusion: Computer Simulations and Mean-Field Theory, Phys. Rev. A 42, 1969 (1990).
      [3] N. Cheimarios, Surface diffusion effects on the system and the film properties of a Ziff–Gulari–Barshad type growth model, Mat. Today Comm. 39, 109189 (2024).
      [4] N. Cheimarios, Mean field approximation of a surface-reaction growth model with dissociation, Phys. Lett. A 524, 129828 (2024).
      [5] Y. Bahri, J. Kadmon, J. Pennington, S. S. Schoenholz, J. Sohl-Dickstein, S. Ganguli, Statistical Mechanics of Deep Learning, Annu. Rev. Condens.Matter Phys. 11, 501 (2020).
      [6] D.W. Tola, M. Bekele, Machine Learning of Nonequilibrium Phase Transition in an Ising Model on Square Lattice, Condens. Matter 8, 83 (2023).
      MyUni[edit | edit source]
      Brief Explanation[edit | edit source]
      There is a University App called MyUoM for Greek universities in https://my.uom.gr/ (followed by an effort in University of West Attica, https://iam.uniwa.gr/). While the app serves as a centralized platform for students and faculty, it currently lacks essential features such as a robust login system, a scalable backend architecture, and the ability to provide real-time updates from official university sources. Additionally, the app does not support a unified framework that allows other universities to easily integrate and customize the platform for their specific needs.
      This project aims to address these limitations by developing a modern, scalable backend architecture and integrating a Content Management System (CMS) to manage frequently changing information. The CMS will enable universities to easily update and distribute news, announcements, and other critical data in real time. Furthermore, the backend will be designed to fetch and synchronize real-time information directly from official university websites, ensuring accuracy and timeliness.
      A key goal of this project is to unify and standardize the efforts of existing implementations (e.g., MyUoM and UniWA) and create a modular, extensible framework that other universities can adopt with minimal effort. By doing so, we aim to foster collaboration among Greek universities and provide a seamless, feature-rich experience for students and faculty across the country.
      This project will not only enhance the functionality of the existing app but also lay the foundation for a national university platform that can be easily extended to support additional institutions, features, and services in the future.
      Expected Results.[edit | edit source]
      Modular and Customizable Architecture: Develop a flexible, scalable structure that can be adapted to the unique needs of different universities. The system will allow each institution to fully customize the interface, content, and functionality to align with their specific requirements.
      Personalized Content and Homepage: Implement a dynamic homepage that displays customizable tiles and content, similar to a WordPress-style page builder. Institutions can personalize the content to highlight important information, announcements, or services.
      Student Portal: Create a dedicated student portal where all student-related data (personal information, academic records, etc.) will be centralized. This portal will serve as a one-stop reference point for students to access their information.
      Admin Panel for Customization: Build an intuitive admin panel that allows university administrators to define the appearance, content, and functionality of their institution's application. This will empower institutions to manage their app independently.
      Backend System for Data Management: Develop a robust backend system to handle all data, including student information, frequently updated content, and static resources (e.g., map images). The backend will ensure efficient data management and retrieval.
      Real-Time Data Integration: Set up a backend that fetches real-time information from official university sources (e.g., announcements, schedules) and integrates static resources to reduce frontend load and improve performance.
      TypeScript Rewrite for Maintainability: Rewrite the existing codebase in TypeScript to enhance code quality, maintainability, and scalability, ensuring the project is future-proof.
      Custom CMS for Dynamic Content: Create a custom Content Management System (CMS) consisting of both FrontEnd and BackEnd components. This CMS will allow universities to easily manage and update frequently changing information.
      Multi-Domain Support: Design a system where the application can be shared across multiple university domains by creating individual instances. This will enable seamless adoption by other institutions while maintaining customization for each.
      Deliverables (before means to help us decide and after means at the end of GSoC)
      Prepare the "Analysis and design" document. We want System Analysis, Feasibility Study, Business Procedures, User stories, EPICS, System Backlog, Requirements Analysis (before).
      Wireframes or mockups (before).
      Final Analysis and design document (after)
      Repository with the code (after).
      Docker image (after).
      Duration of the Project[edit | edit source]
      Depending on the scope
      Related repositories[edit | edit source]
      https://github.com/Open-Source-UoM/MyUoM
      Knowledge Prerequisites[edit | edit source]
         • React.js
         • Express.js (for BackEnd)
         • MySQL (for BackEnd)
         • JavaScript
         • TypeScript
         • Next.js (optional)
      Mentors:[edit | edit source]
      Anastasios Tsalmas tsalmanastasios@gmail.com,
      Efstathios Iosifidis eiosifidis@gmail.com
      Contact:
      There is a list. Please use the list. Write [myuni] as subject and cc both mentors. DON'T send us messages to social media (including Linkedin).
      GlossAPI[edit | edit source]
      Brief Explanation[edit | edit source]
      GlossAPI is an open source project seeking to develop a standard open access corpus of the Greek language, and benchmark it against existing and to-be-developed language models, with the objective of providing an upstream service to the Greek tech community. The project is named after a portmandeau of the Greek word for "language" and "API" which creates a visual resemblance to the word Glossary in Greek. This is to express our objective to provide an index of the Greek language via flexible programing interfaces.
      Greek is a language that is under-represented in existing LLMs, while it has a complex history, grammar and writing system. Our trials with existing models have shown lack of syntactic and semantic knowledge of advanced Greek and its nuances, and we have put forth a number of analyses showing that this poses a risk for digital divides, language extinction, and subpar experience for users of public services.
      To our knowledge other LLM projects that tackle the problem of the Greek language are either proprietary, closed code, narrow scope, or otherwise unfit for our purpose which is to provide publicly available, fully open source language models with respect to all code/weights/procedures/data. We reach out and bring together people that have the expertise, the passion, the collections, or the hardware, to take part in this endeavor, that will help the Greek stratup/tech scene catch up with the rapid developments in downstream applications that are now common place for developers of English language generative models.
      Expected Results[edit | edit source]
      The project will result to an Open Source Corpus, representative of the Greek language and its different varieties. At first emphasis will be given to the formal varieties used in government, education and the law. Additionally, we want to represent, in a subsequent training stage, a number of basic knowledge domains to an "undergraduate degree" level. The datasets will be versioned and benchmarked against different models and tokenizers. We also need to develop a sufficient set of evaluation tasks (such as Factual QA - Greek). Finally a couple of foundation models of different architectures will be fitted onto the dataset and the evaluation suite, and published to the community under an open source licence. With these moves we expect to pollinate the Greek tech ecosystem with reliable, inexpensive, and extensible models and datasets, that will help the Greek Open Source AI scence thrive. All data and models will be accompanied by thorough documentation and guides, to ensure replicability and reusability of the results.
      
      Duration of the Project[edit | edit source]
      350 hrs
      Related Repositories[edit | edit source]
      https://github.com/eellak/glossAPI/ https://github.com/eellak/glossAPI/wiki
      
      Knowledge Prerequisites[edit | edit source]
      Corpus Annotation for Language Models Quantitative Corpus Linguistics or Natural Language Processing Python with transformers library, sci-kit learn, numpy, pandas and streamlit, langchain or similar Mathematical statistics or similar discipline Django knowledge is good to have
      Mentors[edit | edit source]
      F.Karounos, A. Melidis, Greek Free Open Source Software/Hardware Alliance
      DIY IoT Physics Experiments for education[edit | edit source]
      Brief Explanation[edit | edit source]
      Remote physics experiments for students in all educational levels are the second best to hands-on experiments.  Especially for students who temporarily cannot attend school or in cases like Covid-19 and the lockdowns. In many practical cases, they are the only alternative, as they are available 24/7, they can involve dangerous materials or conditions, they can be accessed from anywhere and any device, they require less maintenance, have lower cost, can be easily modified, or arranged to perform another experiment, and are less probable to be damaged.  They are in line with the modern way of performing experiments, as it is desirable to have as little direct contact with the experiments as possible and use them online.  Examples include online telescopes and electronic microscopes.  This is possible due to automation; data acquisition and manipulation of the experimental data is done using a computer or a single board computer.  In this way students need not take pain stacking notes, especially for experiments that take a lot of time to collect data, sometimes days or months.  Students can concentrate on data processing, the analysis of the results, and arrive at scientifically valid conclusions.  Our laboratory has set up many remote experiments and has more than 10 years’ experience in designing, setting, and servicing remote experiments.  Our remote experiments are based on Arduino and readily available sensors and actuators. The previous year it was designed and implemented a way to make the sensors, and the actuators form an IoT local network so that it will be easier to easily utilize them in different experiments and to build new experiments.  The IoT sensors and actuators are DIY and based on open software.   The previous year GSoC stipend receiver, programed the ESP8266 to receive data from the sensor and transmit the data through MQTT to ThingsBoard. Similarly, for an actuator the ESP8266 to receive MQTT data from ThingsBoard. The stipend receiver prepared five DIY IoT sensors and five actuators. ThingsBoard provided users with visual representation of the data and the control of the experimental setup through dashboards.  There are produced five dashboards for five corresponding experiments.  The present successful applicant will have to produce a digital twin of the experiments.  This will involve open software for producing 3D models of five experiments, allowing them to manipulate the digital twins, view the evolution of the experiment, provide data presentation tools, and extract model parameters.
      Related repositories[edit | edit source]
      https://github.com/totheworld2004/DIY-Physics-IoT[edit | edit source]
      Exprected Outcome:[edit | edit source]
      Five digital twins of corresponding five experiments, their documentation and instructions of how to use them
      Knowledge Prerequisites[edit | edit source]
      Any one for case a)-e) or similar --- a) 3D Web-Based Physics Simulations: Three.js, Babylon.js, p5.js, Godot b) Interactive Dashboards: Plotly Dash, Panel, Bokeh c) Custom Data Visualizations: D3.js, Matplotlib, Jupyter Notebooks d) Game-Based Physics Experiments: Godot, Babylon.js e) Embedded 3D Simulations: Three.js, Babylon.js
      Mentors:[edit | edit source]
      Hariton Polatoglou and Panagiotis Koustoumpardis
      eCodeOrama, an educational interactive flow visualization tool for mit scratch programs[edit | edit source]
      Brief Explanation[edit | edit source]
      The project will create a interactive tool to extract, visualize graphically and edit (to improve the presentation of) the layout of the flow of code in blocks / scripts in a mit scratch program and their interaction with any messages or other external events. The tool will use rules to decide on many layout parameters (e.g. the position of the code blocks in the layout, the colors used, etc) but the user will be able to overwrite the default choices. The presentation will be compatible with the codeOrama code layout specification. The tool will also promote code understanding, especially to young students that use scratch, and will include debugging aids. The students can use this flow to better visualize and understand their program, to explain it to others, to debug it and to design extensions and modifications.
      
      Expected Results[edit | edit source]
      A tool to visualize and edit the layout of the event based script flow of a scratch program, keeping it compatible with the codeOrama code layout specification.
      Duration of the Project[edit | edit source]
      350 hours
      Related repositories[edit | edit source]
      https://github.com/sarantos40/eCodeOrama
      Knowledge Prerequisites[edit | edit source]
      python, mit scratch, gui development
      Mentors:[edit | edit source]
      Sarantos Kapidakis (sarantos.kapidakis@gmail.com), Chrysovalantis Sfyrakis
      Category: GSOC
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-technologies-alliance-gfoss/
    idea_list_url: https://ellak.gr/wiki/index.php?title=Google_Summer_of_Code_2025_proposed_ideas

  - organization_id: 108
    organization_name: Open Transit Software Foundation
    no_of_ideas:
    ideas_content: |
      Google Summer of Code 2025 Project Ideas
      Caution: Please do not consider this list to be definitive: we have lots of ideas for projects we want to see pursued as part of GSoC 2025, but will certainly not receive as many slots as we want. The order of the list is also not indicative of priority.
      AI/ML Projects
      Transit Stop Identification
      Difficulty: Advanced // Size: 350 hours
      Have you ever tried to find your specific bus or train stop in an app while you’re standing in your city center? Tall buildings make precise GPS location finding a challenge, you may not know which direction you’re facing, and finding the right stop on the OBA map can be really difficult! We want to begin introducing AI/ML features to OneBusAway with a small on-device model that can run on iOS and Android to help identify the ID of a transit stop from a sign and then automatically open the correct stop in the OBA app.
      You will be responsible for:
      Helping to create features in our mobile apps to allow existing users to submit training data (i.e. images of transit stop signs)
      Building the final model on top of MobileNet-v3-Small or another similar model
      Helping to integrate the final model into OBA on iOS and/or Android
      Web UI Projects
      Wayfinder Improvements
      Difficulty: Intermediate // Size: 175 hours
      Wayfinder is our best-in-class SvelteKit based web application. It needs a full accessibility audit and fixes made where applicable. Additionally, we’ve built a lot of great features, but they are largely untested today. We need someone to enhance our unit testing suite to ensure that changes don’t cause regressions. Finally, there are a handful of fit and finish improvements that we need to make to the project.
      Expected outcomes:
      An accessibility and usability audit report.
      Implementation of the top recommendations from the report.
      Improved test coverage.
      Fit and finish.
      Next Generation Sign Mode
      Difficulty: Intermediate // Size: 175 hours
      Next generation Sign Mode is a web application that will let transit agencies and businesses easily create public transit information systems. Our old web app includes a sign mode feature, but the feature didn’t make it into Wayfinder. Instead, we want to see a new, standalone web app built in SvelteKit that matches or exceeds the feature set of the old sign mode.
      See an example of sign mode in action.
      Read the docs to learn more about its options.
      Android App
      Accessibility Improvements
      Difficulty: Intermediate // Size: 90 hours
      Our Android app is reasonably accessible, but it needs a full accessibility audit and implementation of the findings/recommendations.
      If you have experience with building Android apps and a desire to make the preeminent open source public transit app for Android more accessible, this is a great project for you! You’ll review our Android app’s support for TalkBack, font sizing, appropriate color contrast, hit target sizing, and other features needed to help everyone take full advantage of the app, create a report documenting your findings, and then fix the top priority issues that you’ve discovered.
      Expected outcomes:
      An accessibility audit report.
      Implementation of the top recommendations from the report.
      Other Ideas
      We’d love to see OneBusAway for Android be updated with new experiences, work on new devices, and so much more. Tell us about your ideas or find some here: https://github.com/OneBusAway/onebusaway-android/issues
      iOS App/Apple Platforms
      Improve iOS App Accessibility
      Difficulty: Intermediate // Size: 90 hours
      Our iOS app is reasonably accessible, but it needs a full accessibility audit and implementation of the findings/recommendations.
      If you have experience with building iOS apps in Swift and a desire to make the preeminent open source public transit app for iOS more accessible, this is a great project for you! You’ll review our iOS app’s support for VoiceOver, dynamic text sizing, appropriate color contrast, hit target sizing, and other features needed to help everyone take full advantage of the app, create a report documenting your findings, and then fix the top priority issues that you’ve discovered.
      Expected Outcomes:
      An accessibility audit report.
      Implementation of the top recommendations from the report.
      Build a Trip Planner
      Difficulty: Advanced // Size: 350 hours
      The OneBusAway iOS app needs a trip planner! Be a founding engineer on the project to build the only Apache 2.0-licensed Open Trip Planner library for iOS, and help hundreds of thousands of people reach their destinations.
      The top feature request for the OBA iOS application for the past ten years running has been for a trip planner! Unfortunately, there are no open source libraries for iOS that are compatible with Open Trip Planner, and that’s where you come in. You’ll work with Aaron, our Executive Director and iOS app maintainer, to design an Apple-quality trip planning experience, and then build it from scratch in Swift and SwiftUI, taking care to incorporate user research findings and platform best practices along the way.
      The result of your work will help hundreds of thousands of people reach their destinations every day, and power the trip planning experiences for every iOS app that uses Open Trip Planner for the next ten years.
      Expected outcomes:
      A production-quality trip planning framework built in Swift/SwiftUI
      Full integration into OneBusAway
      Build an Apple Watch App
      Difficulty: Advanced // Size: 350 hours
      We’d love to add a companion Apple Watch app for OneBusAway. Ever wanted to build an Apple Watch app from the ground up that would be used by tens of thousands of people on day 1? Now’s your chance!
      Since the introduction of the Apple Watch, we’ve heard from countless users wondering when we’d finally launch a version of our app that is designed for a wrist-based experience. You will help to perform user research, determine the appropriate scope of features, and build our first Apple Watch app, exclusively for watchOS 11 in SwiftUI.
      Expected outcomes:
      A production-quality Apple Watch app, written in Swift and SwiftUI.
      Survey Features
      Difficulty: Intermediate // Size: 175 hours
      One of our GSoC 2024 participants created a survey feature for our Android app, and now we need to replicate that feature on iOS!
      Surveys play a key role in helping transit agencies understand the needs of their riders and ultimately to make transit easier to use. In this project, we hope to build short travel survey functionality into the OneBusAway iOS app that would allow riders to rate aspects of service or answer questions about how to improve their experience on transit.
      While OneBusAway has been a beloved app for our riders for more than a decade, at its roots is the conduct of research to examine the impacts of real-time traveler information on the attitudes and behavior of transit customers. This new functionality would allow us to grow this research arm of OneBusAway for the first time in years. A project for its use has already been identified to help transit agencies better serve women’s unique travel experiences such as mobility of care trips and more complicated travel patterns.
      Expected outcomes:
      A production-quality short survey interaction module (to ask single questions or provide ratings) that can be deployed in the iOS app.
      Golang/Backend Projects
      Historically, most of the OBA backend stack has been written in Java with Spring. We’re starting to move away from Java/Spring, and are hoping to slowly and organically transition our backend projects to Go.
      Watchdog
      Difficulty: Advanced / Size: 175 hours
      Our first Go-based project is a tool called Watchdog, which monitors the availability and behavior of OBA servers and reports out information to a Prometheus server.
      Expected outcomes:
      Build more metrics for Watchdog: right now, we only have a few metrics for Watchdog that have been created. The original Watchdog project had over a dozen. We need to replicate its behavior!
      Integration Test System
      Difficulty: Advanced / Size: 350 hours
      Even though we do have an OpenAPI spec that documents all of our API endpoints, the OBA API server does not have a formal spec or set of tests that define its behavior, or ensure that a breaking API change does not occur. We need a tool built that can validate the output of the OBA API server for a known set of inputs. In other words, given a known set of GTFS data bundle and GTFS-RT Protobuf files, verify that the JSON-over-HTTP output matches the expected output.
      Expected outcomes:
      Build a test harness (i.e. a specialized Docker image) for the OBA API server; it will need to simulate particular dates and times.
      Build a Ruby, Python, or Golang tool that can instantiate the OBA API server inside of its test harness and validate the correctness of the JSON output from a given HTTP call.
      Create a comprehensive test suite that verifies that the OBA API server works as expected for all of its most important API calls.
      Your Idea Here!
      We don’t have a monopoly on great ideas. Let us know what you think would be a great addition to the OBA platform!
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/open-transit-software-foundation/
    idea_list_url: https://opentransitsoftwarefoundation.org/2025/01/google-summer-of-code-2025-project-ideas/


  - organization_id: 109
    organization_name: OpenAFS
    no_of_ideas:
    ideas_content: >-

          
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openafs/
    idea_list_url: https://www.openafs.org/gsoc/project-ideas.html


  - organization_id: 110
    organization_name: OpenAstronomy
    no_of_ideas:
    ideas_content: |
      PROJECTS
      MENTORS
      FAQ
      EXPLORE
      Spectral timing in Julia
      Create a set of timing and spectral timing methods in Julia
      matteobachettistefanocovinofjebaker
      GSOC 350 h
      stingrayjuliaAstro
      Electronic spectra for RADIS
      The project aims at adding the possibility to calculated electronic spectra with RADIS, mainly using the newly available molecules in ExoMol
      minouHuberwanp
      GSOC 350 h
      radis
      Fast parsing of large databases and execution bottlenecks
      The conversion of large files from a compressed format to hdf5 should be accelerated
      minouHubTranHuuNhatHuydcmvdbekerom
      GSOC 175 h
      radis
      Optimizing Radis app
      Our project is all about enhancing user experience to the next level! We're committed to bringing you cutting-edge features and fine-tuning these features for maximum performance and efficiency, and rigorous testing to ensure they meet the needs of our highly valued end users
      erwanparunavabasucom
      GSOC 350 h
      radis
      Interactive Database for X-ray observations
      Create an interactive database for analyzing, storing, and classifying X-ray observations of accreting black holes
      mgullikmatteobachetti
      GSOC 350 h
      stingray
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openastronomy/
    idea_list_url: https://openastronomy.org/gsoc/gsoc2025/#/projects
  

  - organization_id: 111
    organization_name: OpenCV
    no_of_ideas:
    ideas_content: |
      OpenCV Google Summer of Code 2025
      Jump to Ideas List
      Example use of computer vision:
            Parent of this page   Last year's idea page   IDEAS LIST below
      OpenCV Accepted Projects:
      Mentor only list
      🚧 TBD Spreadheet of projects link
      Contributor Title Mentors Passed
      Important dates:
      Date (2025) Description Comment
      Jan 27 Organization Applications Open 👍
      Feb 11 Org Application Deadline 👍
      Feb 27 Accepted Orgs Announced 💯
      Mar 24 Contributor Proposals Open 🏃
      Apr 08 Contributor Proposal Deadline
      Apr 29 Contributor Ranking Deadline
      May 06 Slot Allocation Deadline
      May 08 Accepted Projects Announced
      May 8-Jun 1 Bonding
      Jun 2 Coding Starts
      jul 14-18 Midterm Evals
      Aug 25-Sep 1 Code in, Contrib Evals
      Sep 1-8 Mentor Evals
      Nov 10 Extended Contrib Evals
      Nov 17 Extended Mentor Evals
            GSoC Timeline   UTC time   UTC time converter
      Resources:
      GSoC Home Page
      TBD: GSoC OpenCV Project Page
      Project Discussion List   Mentor List
      OpenCV Home Site   OpenCV Wiki   OpenCV Forum Q&A   Developer meeting notes
      How to do a pull request/How to Contribute Code
      Source Code: GitHub/opencv and GitHub/opencv_contrib
      IRC Channel: #opencv Libera.chat,   Slack: https://open-cv.slack.com
      TBD: OpenCV GSoC Dashboard
      OpenCV Project Ideas List:
      Project Discussion list
      Index to Ideas Below
      Multi-camera calibration part 3
      Multi-camera calibration test
      Multi-camera calibration toolbox
      Quantized models for OpenCV Model Zoo
      RISC-V Optimizations
      Dynamic CUDA support in DNN
      Synchronized multi-camera video recorder
      libcamera back-end for VideoCapture
      Better LLMs support in OpenCV (1)
      Better LLMs support in OpenCV (2)
      Computational photography algorithms for better image quality
      Improve OpenCV security
      Integrate Fractal ArUco into OpenCV
      Integrate JuMarker ArUco into OpenCV
      LightGlue Matcher with Aliked Feature
      Basic SLAM
      QR/Barcode/ArUco detector
      Idea Template
      All work is in C++ unless otherwise noted.
      Ideas:
      IDEA: Multi-camera calibration part 3
      Description: During GSoC 2023 a new cool multi-camera calibration algorithm was improved: https://github.com/opencv/opencv/pull/24052. This year we would like to finish this work with more test cases, tune the accuracy and build higher-level user-friendly tool (based on the script from the tutorial) to perform multi-camera calibration. If this is completed before the internship is up, then we'll move on to leveraging the IMU or marker-free calibration.
      Expected Outcomes:
      A series of patches with more unit tests and bug fixes for the multi-camera calibration algorithm
      New/improved documentation on how to calibrate cameras
      A short YouTube video showing off how to use the calibration routines
      Skills Required: Mastery of C++ and Python, mathematical knowledge of camera calibration, ability to code up mathematical models
      Difficulty: Medium-Difficult
      Possible Mentors: Maksym Ivashechkin, Alexander Smorkalov
      Duration: 175 hours
      IDEA: Multi-camera calibration test
      Description: We are looking for a student to curate best of class calibration data, collect calibration data with various OpenCV Fiducials, and graphically produce calibration board and camera models data (script). Simultaneously, begin to write comprehensive test scripts of all the existing calibration functions. While doing this, if necessary, improve the calibration documentation. Derive from this expected accuracy of fiducial types for various camera types.
      Expected Outcomes:
      Curate camera calibration data from public datasets.
      Collect calibration data for various fiducials and camera types.
      Graphically create camera calibration data with ready to go scripts
      Write test functions for the OpenCV Calibration pipeline
      New/improved documentation on how to calibrate cameras as needed.
      Statistical analysis of the performance (accuracy and variance) of OpenCV fiducials, algorithms and camera types.
      A YouTube video showing describing and demonstrating the OpenCV Calibration testss.
      Resources: OpenCV Fiducial Markers, OpenCV Calibration Functions, OpenCV Camera Calibration Tutorial 1, OpenCV Camera Calibration Tutorial 2
      Skills Required: Mastery of C++ and Python, mathematical knowledge of camera calibration, ability to code up mathematical models
      Difficulty: Medium
      Possible Mentors: Jean-Yves Bouguet, Alexander Smorkalov
      Duration: 175 hours
      IDEA: Multi-camera calibration toolbox
      Description: Build a higher-level user-friendly tool (based on the script from the calibration tutorial) to perform multi-camera calibration. This should allow easy multi-camera calibration with at multiple Charco patterns and possibly other calibration fiducial patterns. The results will use Monte-Carlo sampling to determine parameter stability, allow easy switching of camera models and output the camera calibration parameters and the fiducial patterns pose in space as well as the extrinsic locations of each camera relative to the others.
      Expected Outcomes:
      Tool with convenient API that will be more or less comparable and compatible with Kalibr tool (https://github.com/ethz-asl/kalibr)
      New/improved documentation on how to calibrate cameras
      A Youtube video demonstrating how to use the box
      Skills Required: Python, mathematical knowledge of camera calibration, ability to code up mathematical models
      Difficulty: Medium-Difficult
      Possible Mentors: Jean-Yves Bouguet, Gary Bradski
      Duration: 175 hours
      IDEA: Quantized models for OpenCV Model Zoo
      Description: Many modern CPUs, GPUs and specialized NPUs include special instructions and hardware blocks for accelerated inference, especially for INT8 inference. The models don't just become ~4x smaller compared to FP32 original models, the inference speed increases significantly (by 2x-4x or more) as well. The number of quantized models steadily increases, however, beyond image classification there are not so many 8-bit computer vision models with proven high-quality results. We will be interested to add to our model zoo (https://github.com/opencv/opencv_zoo) 8-bit models for object detection, optical flow, pose estimation, text detection and recognition etc.
      Expected Outcomes:
      Series of patches to OpenCV Zoo and maybe to OpenCV DNN (when OpenCV DNN misses 8-bit flavors of certain operations) to add the corresponding models.
      If quantization is performed by student during the project, we will request the corresponding scripts to perform the quantization
      Benchmark results to prove the quality of the quantized models along with the corresponding scripts so that we can reproduce it.
      Skills Required: very good ML engineering skills, good Python programming skills, familiarity with model quantization algorithms and model quality assessment approaches
      Possible Mentors: Feng Yuantao, Zhong Wanli, Vadim Pisarevsky
      Difficulty: Medium
      Duration: 90 to 175 hours, depending on the particular model.
      IDEA: RISC-V Optimizations
      Description: RISC-V is one of main target platforms for OpenCV. During past several years we brought in some RISC-V optimizations based on RISC-V Vector extension by adding another backend to OpenCV scalable universal intrinsics. We refactored a lot of code in OpenCV to make the vectorized loops compatible with RISC-V backend and more or less efficient. Still, we see a lot of gaps and the performance of certain functions can be further improved. For some critical functions, like convolution in deep learning, it makes sense perhaps to implement custom loops using native RVV intrinsics instead of using OpenCV scalable universal intrinsics. This is what we invite you to do.
      Expected Outcomes:
      A series of patches for core, imgproc, video and dnn modules to bring improved loops that use OpenCV scalable universal intrinsics or native RVV intrinsics to improve the performance. In the first case the optimizations should not degrade performance on other major platforms like x86-64 or ARMv8 with NEON.
      Resources:
      OpenCV Wide Universal Intrinsics Guide
      Implementation of wide universal intrinsics for various platforms, including RISC-V
      Skills Required: mastery plus experience coding in C++; good skills of optimizing code using SIMD.
      Possible Mentors: Mingjie Xing, Maxim Shabunin
      Difficulty: Hard
      Duration: 350 hours
      IDEA: Dynamic CUDA support in DNN
      Description: OpenCV DNN module includes several backends for efficient inference on various platforms. Some of the backends are heavy and bring in a lot of dependencies, so it makes sense to make the backends dynamic. Recently, we did it with OpenVINO backend: https://github.com/opencv/opencv/pull/21745. The goal of this project is to make CUDA backend of OpenCV DNN dynamic as well. Once it's implemented, we can have a single set of OpenCV binaries and then add the necessary plugin (also in binary form) to accelerate inference on NVidia GPUs without recompiling OpenCV.
      Expected Outcomes:
      A series of patches for dnn and maybe core module to build OpenCV DNN CUDA plugin as a separate binary that could be used by OpenCV DNN. In this case OpenCV itself should not have any dependency of CUDA SDK or runtime - the plugin should encapsulate it. It is fine if the user-supplied tensors (cv::Mat) are automatically uploaded to GPU memory by the engine (cv::dnn::Net) before the inference and the output tensors are downloaded from GPU memory after the inference in such a case.
      Resources:
      Skills Required: mastery plus experience coding in C++; good practical experience in CUDA. Acquaintance with deep learning is desirable but not necessary, since the project is mostly about software engineering, not about ML algorithms or their optimization.
      Possible Mentors: Alexander Smorkalov
      Difficulty: Hard
      Duration: 350 hours
      IDEA: Synchronized multi camera video recorder
      Description: Multi-camera calibration and multi-view scenarios require synchronous recording with multiple cameras. Need to tune cv::VideoCapture or/and VideoWriter and implement sample for video recording with several cameras with timestamps
      Expected Outcomes:
      Sync video recording sample for several cameras: V4L2, RTSP(?)
      Resources: Overview
      Skills Required: C++
      Possible Mentors: Alexander S.
      Difficulty: Easy-Medium
      Duration: 175
      IDEA: libcamera back end for VideoCapture
      Description: Discussion: #21653
      Expected Outcomes:
      MIPI camera support on Raspberry Pi
      Resources:
      Skills Required: C++, Linux
      Possible Mentors: TBD
      Difficulty: Medium
      Duration: 175
      IDEA: Better LLMs support in OpenCV (1)
      Description: Large Language Models, or LLM, are AI models designed to understand, generate and manipulate human language. One of the barrier to better support LLMs is tokenizer support. A tokenizer can break down raw text into smaller pieces (tokens), which are easier for models to understand and process. This project aims to integrate tokenizer in dnn module.
      Expected Outcomes: A patch that integrates tokenizer in dnn module
      Resources:
      Let's Build the GPT Tokenzier https://youtu.be/zduSFxRajkE?si=JF725Ipnzc4R5Nnc
      OpenAI's tokenizer https://github.com/openai/tiktoken
      Hugging Face's AutoTokenizer https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py
      Skills Required: C++, Python, LLMs/Transformers
      Mentor: Yuantao Feng
      Difficulty: Hard
      Duration: 175
      IDEA: Better LLMs support in OpenCV (2)
      Description: LLMs support in OpenCV is unclear. One of the most key feature in the current dnn engine is fixed memory allocation after model importing, which helps speeding up model inference for CNNs but then becomes the limit of running LLMs that has flexible inputs. This project aims to try LLMs as many as possible with OpenCV, fix dnn engine to support more LLMs, and write demos to show LLMs inference with OpenCV.
      Expected Outcomes:
      Several patches that fix dnn engine to support more LLMs.
      Several patches that add demos to show LLMs inference with OpenCV.
      Resources:
      GPT2 inference with OpenCV https://github.com/opencv/opencv/blob/5.x/samples/dnn/gpt2_inference.py
      LLMs that llama.cpp supports https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#description
      Skills Required: C++, Python, LLMs/Transformers
      Mentor: Yuantao Feng
      Difficulty: Hard
      Duration: 175
      IDEA: Computational photography algorithms for better image quality
      Description: Improving image quality is important task, which is still not covered well in OpenCV. We already have "non-local means" (photo module) and BM3D (opencv_contrib) denoising algorithms, simple white balance algorithms (opencv_contrib), very simple exposure correction function (equalizeHist in imgproc: grayscale images only) and function for distortion correction (undistort function in imgproc), that's it. The following could be useful to have:
      more efficient/better-quality denoising algorithms
      vignetting correction
      chromatic aberration correction
      smarter white balance algorithms
      exposure correction for color images
      multi-frame (image burst) denoising
      superresolution for still images and video
      deblurring
      color enhancement, defogging
      etc.
      Note that:
      this idea is not about any special effects, 'beautification' etc. It's about improving pure technical image quality
      the idea is quite big, applicant(s) may and probably should suggest to implement a subset of the above items, they can also add something on top (as long as note (a) above is taken into account).
      Expected Outcomes:
      Several patches to opencv_photo module and/or opencv_contrib repo that add the new functionality, tests, samples etc.
      Resources:
      TBD
      Skills Required: C++, Python
      Mentor(s): Gursimar Singh, Vadim Pisarevsky as adviser.
      Difficulty: Hard
      Duration: 175
      IDEA: Improve OpenCV's security
      Description: OpenCV can be better integrated with https://oss-fuzz.com/ to get better fuzzing, mostly by moving the tests to the OpenCV repository and writing more tests (especially for imgcodecs and videoio). Additionally, sandboxing could be integrated into OpenCV to make sure invalid inputs are safely discarded by integrating sandbox2.
      Expected Outcomes:
      Several patches that improve the oss-fuz integration.
      Several patches that add an optional build of OpenCV with sandbox2 integrated for some functions.
      Resources:
      sandbox2 documentation https://developers.google.com/code-sandboxing/sandbox2
      fuzztest documentation https://github.com/google/fuzztest
      ongoing PR for fuzztest integration: https://github.com/opencv/opencv/pull/24193
      Skills Required: C++
      Mentor: Vincent Rabaud
      Difficulty: Hard
      Duration: 175
      IDEA: Integrate Fractal ArUco into OpenCV
      Description: Fractal markers are a new concept of marker, which is composed of several fiducial square markers of different size inside. Unlike traditional fiducial markers, the structure of this marker can be detected from a large number of distances, as well as solve problems of partial or total occlusion of the marker.
      Expected Outcomes:
      Integrate Fractal ArUco into OpenCV with a simple API, which should be similar to the ArUco API currently in OpenCV.
      Detailed documents for Fractal ArUco API in OpenCV
      A nice demo to show how to use the algorithm.
      Resources: Frictal ArUco
      Skills Required: C++, Python.
      Mentor: Rafael Muñoz Salinas, Shiqi Yu
      Difficulty: Easy
      Duration: 175 hours
      IDEA: Integrate JuMarker ArUco into OpenCV
      Description: Fiducial markers such as QR codes, ArUco, and AprilTag have become very popular tools for labeling and camera positioning. They are robust and easy to detect, even in devices with low computing power. However, their industrial appearance deters their use in scenarios where an attractive and visually appealing look is required. In these cases, it would be preferable to use customized markers showing, for instance, a company logo. This work proposes a novel method to design, detect, and track customizable fiducial markers. Our work allows creating markers templates imposing few restrictions on its design, e.g., a company logo or a picture can be used. The designer must indicate positions into the template where bits will encode a unique identifier for each marker. Then, our method will automatically create a dictionary of markers, all following the same design, but each with a unique identifier.
      Expected Outcomes:
      Integrate JuMarker ArUco into OpenCV with a simple API, which should be similar to the ArUco API currently in OpenCV.
      Detailed documents for Fractal ArUco API in OpenCV
      A nice demo to show how to create a JuMarker and to detect it.
      Resources: JuMarker ArUco
      Skills Required: C++, Python.
      Mentor: Rafael Muñoz Salinas, Shiqi Yu
      Difficulty: Hard
      Duration: 350 hours
      IDEA: LightGlue Matcher with Aliked Feature
      Description: Add the LightGlue feature matcher into opencv (to join the BFMatcher and the FLAAN matcher), then add the ALIKED feature to the feature detector descriptor so that we can use one of the features (ALIKED, SIFT, SURF, ORB, BRISK ...) and match points between two images. Extra, add subpixel accurate detectors keypt2subpx as a post processor on keypoints formatting them correctly.
      Expected Outcomes:
      Add LightGlue as a new feature matcher
      Add ALIKED to DNN as a feature detector descriptor, formatting the output data to work with OpenCV's feature matchers
      Add Subpixel accurate keypoint adjustment keypt2subpx
      Create an example of subpixel accurate feature matching between pairs of images
      Create test code, documentation and a video of it working
      Resources:
      LightGlue Code that works with ALIKED https://github.com/cvg/LightGlue
      LightGlue Paper
      ALIKED Code https://github.com/Shiaoming/ALIKED
      ALIKED Paper
      Subpixel accurate keypoint refinement code https://github.com/KimSinjeong/keypt2subpx
      Subpixel accurate point refinement paper keypt2subpx
      Skills Required: Python, Computer vision AI model training, pytorch
      Mentor: Gary Bradski, Gursimar Singh
      Difficulty: Medium
      Duration: 200
      IDEA: Basic SLAM
      Description: Using feature detector, descriptors such as LightGlue Code that works with ALIKED, create a SLAM framework for OpenCV (with help from an expert mentor)
      Expected Outcomes:
      Collect video sequences to be tracked such as with LightBlue+ALIKED above or in public SLAM databases
      Develop a SLAM algorithm
      Include unit test code and data
      Create a demo code and video of how to use it
      Resources:
      LightGlue Code that works with ALIKED
      Public SLAM databases
      Comprehensive Survey Paper of SLAM Databases
      Ceres Solver Code
      Skills Required: Python, Ceres, understanding of SLAM
      Mentor: Reza Amayeh
      Difficulty: Hard
      Duration: 200
      IDEA: QR/Barcode/ArUco detector
      Description: QR, Barcode and ArUco are all popular code in computer vision applications. OpenCV now support all of them, and can detect and decode them. But OpenCV still expect a better detector and decoder for them. If possible, one efficient deep detector for all kinds of codes can simplify the usage. If one efficent deep detector cannot be achieved, several deep models are also acceptable.
      Expected Outcomes:
      Train a deep detector for QR, Barcode and ArUco. Or train three different deep detectors for different codes specifically.
      The trained model should be easy to implement with the current algorithms in OpenCV on QR/Barcode/ArUco.
      A nice demo to show how to use the algorithm.
      Detailed report to demontrate if the trained detector(s) are better than the current solution in OpenCV.
      Resources:
      How to train an efficent face detection model
      YuNet: A Tiny Millisecond-level Face Detector
      Skills Required: C++, Python, and experience on object detection.
      Mentor: Shiqi Yu
      Difficulty: Hard
      Duration: 350 hours
      Idea Template:
      1. #### _IDEA:_ Your title here
         * ***Description:*** 3-7 sentences describing the task
         * ***Expected Outcomes:***
            * < Short bullet list describing what is to be accomplished >
            * <i.e. create a new module called "bla bla">
            * < Has method to accomplish X >
            * <...>
         * ***Resources:***
            * [For example a paper citation](https://arxiv.org/pdf/1802.08091.pdf)
            * [For example an existing feature request](https://github.com/opencv/opencv/issues/11013)
            * [Possibly an existing related module](https://github.com/opencv/opencv_contrib/tree/master/modules/optflow) that includes some new optical flow algorithms.
         * ***Skills Required:*** < for example mastery plus experience coding in C++, college course work in vision that covers optical flow, python. Best if you have also worked with deep neural networks. >
         * ***Mentor:*** < your name goes here >
         * ***Difficulty:*** <Easy, Medium, Hard>
         * ***Duration:*** <175 <normal> 350 <extended>>
      All Ideas Above
      Have these Additional Expected Outcomes:
      Use the OpenCV How to Contribute and see Line Descriptor as a high quality finished example.
      Add unit tests described here, see also the Line Descriptor example
      Add a tutorial, and sample code
      see the Line Descriptor tutorial and how they look on the web.
      See the Line Descriptor samples
      Make a short video showing off your algorithm and post it to Youtube. Here's an Example.
      Contributors
      How to Apply
      The process at Google is described at GSoC home page
      How contributors will be evaluated once working:
      Contributors will be paid only if:
      Phase 1:
      You must generate a pull request
      That builds
      Has at least stubbed out (place holder functions such as just displaying an image) functionality
      With OpenCV appropriate Doxygen documentation (example tutorial)
      Includes What the function or net is, what the function or net is used for
      Has at least stubbed out unit test
      Has a stubbed out example/tutorial of use that builds
      See the contribution guild
      and the coding style guild
      the line_descriptor is a good example of contribution
      Phase 2:
      You must generate a pull request
      That builds
      Has all or most of the planned functionality (but still usable without those missing parts)
      With OpenCV appropriate Doxygen documentation
      Includes What the function or net is, what the function or net is used for
      Has some unit tests
      Has a tutorial/sample of how to use the function or net and why you'd want to use it.
      Optionally, but highly desirable: create a (short! 30sec-1min) Movie (preferably on Youtube, but any movie) that demonstrates your project. We will use it to create the final video:
      The 2021 Movie
      The 2020 Movie
      The 2015 Movie
      The 2014 Movie
      The 2013 Movie
      Extended period:
      TBD
      Mentors:
      Contact us, preferably in February or early March, on the opencv-gsoc googlegroups mailing list above and ask to be a mentor (or we will ask you in some known cases)
      If we accept you, we will post a request from the Google Summer of Code OpenCV project site asking you to join.
      You must accept the request and you are a mentor!
      You will also need to get on:
      Mentor only list
      opencv-gsoc-202X mailing list
      You then:
      Look through the ideas above, choose one you'd like to mentor or create your own and post it for discussion on the mentor list.
      Go to the opencv-gsoc googlegroups mailing list above and look through the project proposals and discussions. Discuss the ideas you've chosen.
      Find likely contributors, ask them to apply to your project(s)
      You will get a list of contributors who have applied to your project. Go through them and select a contributor or rejecting them all if none suits and joining to co-mentor or to quit this year are acceptable outcomes.
      Make sure your contributors officially apply through the Google Summer of Code site prior to the deadline as indicate by the Contributor Application Period in the time line
      Then, when we get a slot allocation from Google, the administrators "spend" the slots in order of priority influenced by whether there's a capable mentor or not for each topic.
      Contributors must finally actually accept to do that project (some sign up for multiple organizations and then choose)
      Get to work!
      If you are accepted as a mentor and you find a suitable contributor and we give you a slot and the contributor signs up for it, then you are an actual mentor! Otherwise you are not a mentor and have no other obligations.
      Thank you for trying.
      You may contact other mentors and co-mentor a project.
      You get paid a modest stipend over the summer to mentor, typically $500 minus an org fee of 10%.
      Several mentors donate their salary, earning ever better positions in heaven when that comes.
      Potential Mentors List:
      Ankit Sachan
      Anatoliy Talamanov
      Clément Pinard
      Davis King
      Dmitry Kurtaev
      Dmitry Matveev
      Edgar Riba
      Gholamreza Amayeh
      Grace Vesom
      Jiri Hörner
      João Cartucho
      Justin Shenk
      Michael Tetelman
      Ningxin Hu
      Rafael Muñoz Salinas
      Rostislav Vasilikhin
      Satya Mallick
      Stefano Fabri
      Steven Puttemans
      Sunita Nayak
      Vikas Gupta
      Vincent Rabaud
      Vitaly Tuzov
      Vladimir Tyan
      Yida Wang
      Jia Wu
      Yuantao Feng
      Zihao Mu
      Admins
      Gary Bradski
      Vadim Pisarevsky
      Shiqi Yu
      GSoC Org Application Answers
      Answers from our OpenCV GSoC application
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/opencv/
    idea_list_url: https://github.com/opencv/opencv/wiki/GSoC_2025

  - organization_id: 112
    organization_name: OpenELIS Global
    no_of_ideas:
    ideas_content: |
      OpenELIS Global
      /
      GSoC 2025
      GSoC 2025
      Owned by mozzy mutesa
      Last updated: Feb 27, 2025
      4 min read
      GSoC 2025 Program Administrators
      Selected Projects for GSoC 2025
      Program Timeline
      Guidelines
      Student's guidelines
      Mentor's guidelines
      OpenELIS Global is hoping to be a mentoring organization for Google Summer of Code 2025 for the Second Time. We're extremely excited about the projects and mentorship opportunities available this year. Coding for OpenELIS Global is a great way to practice your coding skills and, at the same time help making a positive impact on the world through empowering labs with the best tools and support to deliver quality health care to clients.
      If you are new to OpenELIS Global, we recommend starting with our Installation and Developer Instructions
        Page Outline
      1
      GSoC 2025 Program Administrators
      2
      Selected Projects for GSoC 2024
      3
      Program Timeline
      4
      Guidelines
      GSoC 2025 Program Administrators
      Mutesasira Moses
      Casey Iiams-Hauser
      Herbert Yiga
      Brynn McKinney
      Selected Projects for GSoC 2025
      Project Name
      Project Size
      Project Description
      Expected Out Come
      Required Skills
      Selected Contributor
      Mentors
      Creating a generic robust reporting framework 
      350 hours
      OpenELIS already has support for pre-designed reports. This project aims to create a Robust reporting framework for users to be able to create ad-hoc Patient reports from the UI 
      Ability to create ad-hoc Patient reports from the UI
      React , Typescript, Java , Spring , REST
        Mutesasira Moses
      @mozzy mutesa 
      Improve Integration Tests coverage
      350 hours
      The current Integration Test coverage is still low. 
      This project aims at extending and  creating more Integration Tests to achieve a Test Coverage of at least 60% for the Backend service Layer
      60% Test coverage
      Java , Spring , J-Unit
        Herbert Yiga
      @Herbert Yiga 
        Re-Write Test management components in React
      350 hours
      Currently ,Most of test management components ie “Modify tests” , “Add Tests” are still not migrated to the new React Frontend. This project aims at migrating the Test management components and some other functionalities (not yet migrated)  to the new React Front End
      Test management components migrated to the new React FrontEnd
      React , Typescript, Java , Spring , REST
        Gita Cliff
      @cliff 
      Add Support for OpenELIS to use OCL to populate the Data Dictionary 
      350 hours
      Currently , The OpenELIS Data Dictionary is populated manually or through Liquibase scripts.
      This project aims at adding support for OpenELIS to be able to consume data dictionaries from Open Concept Lab(OCL) a Terminology Management System 
        Ability to populate the Data dictionary from OCL
      Built out test catalogs through using new initializer to parse new collection or from extract in initializer
      React , Typescript, java , Spring , REST
        Reagan Makoba
      @reagan meant 
      Intergrate OpenELIS with Odoo(OpenER)
      350 hours
      This project aims at adding an integration layer between OpenELIS Global2 and Odoo (OpenERP) in order to add support for Billing functionalities with  the OpenELIS Order workflow
      Added support for Billing functionalities with in OpenELIS
      React , Typescript, Java , Spring , REST
        Ragan Makoba
      @reagan meant 
      
      Improving E2E QA tests
      350 hours
      The current E2E tests have like a 30 % Coverage.
      This project is dedicated to improve the End-to-End (E2E) testing coverage for the New React front end to at least 80% Coverage and ensuring robust validation of the entire application workflow . 
      Improved and comprehensive E2E QA framework to at least 80% coverage
      React , Typescript, 
      Cypress
        Caesy Hauser
      @Casey Iiams-Hauser 
      Add support for multiple Translation Languages via Transfex
      350 hours
      OpenELIS currently support only two Languages ie English and French .
      This projects aims at adding more support for multiple languages via Transfex
      Spanish as a use case; adopt from 1 to many languages
      Ability to translate the UI messages into multiple Languages and Automated via Transfex
      Typescript, React ,
        Caesy Hauser
      @Casey Iiams-hauser 
      Program Timeline
      Date
      Status
      Activity
      Jan 14, 2025 
      DONE
         GSoC 2025 Announced
      Jan 27, 2025
      DONE
        Mentoring organizations can begin submitting applications to Google
      Feb 11, 2025
      DONE
        Mentoring organization application deadline
      Feb 27, 2025
      DONE
         List of accepted mentoring organizations announced
      Feb 27, 2025 - Mar 24, 2025
      IN PROGRESS
      Potential GSoC contributors discuss application ideas with mentoring organizations
      Mar 24, 2025
      PENDING
      GSoC contributor application period begins
      Apr 8, 2025
      PENDING
      GSoC contributor application deadline
      Apr 29, 2025
      PENDING
      GSoC contributor proposal rankings due from Org Admins
      Apr 29, 2025
      PENDING
      Slot Allocation Deadline
      Apr 30, 2025
      PENDING
      Projects Announced to Orgs
      May 8, 2025
      PENDING
      Accepted GSoC contributor projects announced
      May 8, 2025-Jun 1, 2025 
      PENDING
      Community Bonding Period. Students get to know mentors, read documentation, prepare for work on their projects
      Jun 2, 2025 
      PENDING
      Coding officially begins
      Jul 14, 2025 
      PENDING
      Mentors and GSoC contributors can begin submitting midterm evaluations
      Jul 18, 2025 
      PENDING
      Midterm evaluation deadline (standard coding period)
      Jul 14, 2025 -Aug 25, 2025 
      PENDING
      Work Period. GSoC contributors work on their project with guidance from Mentors
      Aug 25, 2025 -Sep 1, 2025 
      PENDING
      Final week. GSoC contributors submit their final work product and their final mentor evaluation (Standard coding period)
      Sep 1, 2025 -Sep 8, 2025 
      PENDING
      Mentors submit final GSoC contributor evaluations (standard coding period) for medium size project.
      Sep 1, 2025 -Nov 9, 2025 
      PENDING
      GSoC contributors with extended timelines continue coding
      Nov 10, 2025 
      PENDING
      Final date for all GSoC contributors to submit their final work product and final evaluation
      Nov 17, 2025
      PENDING
      Final date for mentors to submit evaluations for GSoC contributor projects with extended deadlines
      see full Timeline
      Guidelines
      Student's guidelines
      GSoC - Guidelines for Students
      Mentor's guidelines
      GSoC - Guidelines for Mentors
      
      Students MUST follow our Student Guidelines for their proposals to be selected
      Related content
      Info icon
      Collapse
      GSoC 2024
      GSoC 2024
      OpenELIS Global
      More like this
      GSoC ‐ Guidelines for Students
      GSoC ‐ Guidelines for Students
      OpenELIS Global
      More like this
      Dev Environment Setup Instructions
      Dev Environment Setup Instructions
      OpenELIS Global
      Read with this
      Install OpenELIS Global
      Install OpenELIS Global
      OpenELIS Global
      Read with this
      Developer Stages
      Developer Stages
      OpenELIS Global
      Read with this
      Volunteer of The Month.
      Volunteer of The Month.
      OpenELIS Global
      Read with this
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openelis-global/
    idea_list_url: https://uwdigi.atlassian.net/wiki/spaces/OG/pages/321224705/GSoC+2025

  - organization_id: 113
    organization_name: OpenMRS
    no_of_ideas:
    ideas_content: |
      Resources
      /
      Summer of Code 2025
      Summer of Code 2025
      +8
      Owned by Grace Potma
      Last updated: yesterday at 8:50 PM by Christopher Lumu
      10 min read
      Write Code. Save Lives.
      OpenMRS is hoping to be a mentoring organization for Google Summer of Code™ 2025! Since 2007, we've enjoyed participating in this great program and we're extremely excited about the projects and mentorship opportunities available this year. Coding for OpenMRS is a great way to practice your coding skills and, at the same time, help benefit people in developing countries who are on the front lines of public health challenges.
      If you are new to OpenMRS, we recommend starting with our Guide to the New & Curious. It will introduce you to our community, the tools and spaces we use, and help you get to know the different squads and teams working on various community projects. For a more detailed history of who we are and what we do, please see here. If you’re new to OpenMRS or wondering how to get started with your GSoC application, this video should help answer a lot of your questions: 
       GSoC 2025 with OpenMRS: An Insider's Guide
      On this page ....
      GSoC 2025 Program Administrators
      Project Ideas for GSoC 2025
      Pending Ideas
      Program Timeline
      Guidelines
      OpenMRS resources to know
      Google Summer of Code at OpenMRS 
      om.rs/gsoc
      Learn more about Google Summer of Code 2025:
      Google Summer of Code website
       Helpful Links
      Community GSOC Slack Channel: #gsoc on OpenMRS Slack
      Guidelines for GSOC Applicants
      GSOC Topics on the OpenMRS Forum
      GSoC 2025 Program Administrators
      @beryl  @Jayasanka Weerasinghe  
      Please see GSoC Admin Guidelines for more information, or Org Admin Tips and Program Rules.
      Project Ideas for GSoC 2025
      How and Where we Define Ideas
      Project Name & Expected Outcome
      Rating and Size
        Project Description
      Skills (Required / Preferred)
      Primary Mentor
      Secondary Mentor
        Support for horizontal scaling of OpenMRS instances 
      Large
      In the scope of the project would be (depending on the progress we make using other contribution channels):
      Adjust codebase across core and O3 modules to use a new storage service described here.
      Adjust code in core and O3 modules to use distributed caching
      Experiment with Hibernate Search using OpenSearch as backend instead of a local Lucene index.
      Java, Hibernate
      @Rafal Korytkowski 
          Interactive Builder for Form Translations within the Form Builder 
      Large
      Right now, in order to add translations to a form, the way to do this to add it to a configuration folder that can be picked up by Iniz. This is annoying because
      You’d need a developer’s help to know what to do and where to do it
      The JSON file format is quite different from that of a form, so its not very intuitive for a non-techy person to do
      There’s no a dynamic and user-friendly way to do it
      
      The ideas is to create a UI that would enable users to add the translations for a form for any language.
      React, CSS
      @nethmi 
          Performance Testing Enhancement Project
      Medium
      The current load tests cover only two scenarios, limiting performance insights. This project aims to:
      Identify key scenarios that should be tested for better system performance evaluation.
      Implement additional performance tests to ensure comprehensive coverage.
      Enhance the existing test framework for scalability and reliability.
      This will improve OpenMRS’s ability to handle high-load conditions and optimize system performance.
      Java, Gatling
      @Jayasanka Weerasinghe 
          Service Queues
      Medium
      We have a service queues app in O3, which is functional, but needs some attention, both to the frontend design and to the backend APIs that are used to populate it. The goal here would be to fix various UI issues and improve the overall performance and reliability of the queue module. The Service Queues view is incredibly useful for managing outpatient clinics, allowing users to track who is waiting for service, how long they’ve been waiting for etc.
      React, Java
      @Ian Bacher 
          Improved Audit Logging
      Medium
      We added Hibernate Envers for audit logging in OpenMRS 2.7.0, but right now, admin users cannot easily view or manage these logs. 
      This project aims to build a backend module that can
      Show Audit Logs: Pull and display audits for database tables.
      Filters: Let users filter logs by things like who made the changes, when, and what they changed.
      REST Endpoints: Add APIs so other systems can access the audit data.
      Java, Spring, Hibernate
      @Wikum Weerakutti 
      @Manoj Rathnapriya 
        Enhancing OpenAPI Documentation Generation 
        Medium
      Errors related to the Swagger documentation have been under review, with efforts made to upgrade it to the latest versions of OpenAPI (or a similar version). The necessary pull requests have already been submitted.
      For this GSoC, it is suggested that, in addition to the ongoing work, efforts should be directed towards developing tooling or a mechanism that would enable the automatic generation of Swagger documentation by analyzing Javadocs, return types, and other relevant elements. Some work has already been undertaken to achieve this, utilizing reflection to scan OpenMRS resource handlers. It is proposed that further developments be made on top of this existing foundation to enhance the envisioned tooling.
      The ultimate objective is for the OpenAPI specification to be generated at compile time rather than at runtime, as is currently the case. This shift would ensure that errors are identified at compile time rather than being detected during runtime.
      For reference,
      Improving Our Swagger Documentation Process
      Upgrade swagger from 2.0 to swagger/openapi 3.0
      Enhancing OpenAPI Documentation Generation 
      Java, OpenAPI
      @Chi Bong Ho 
      @herman muhereza 
        Fix the Fast Data Entry feature
      Medium
      The Bulk Data Entry feature (BDE) is broken and unusable in the OpenMRS community’s main product (the O3 RefApp). No community organization or contributor has had the time or ability to fix this, and yet it is an important foundational feature for OpenMRS users.
      The goal of this project is to fix the BDE feature and get it useable again in the O3 RefApp, primarily by engineering the feature to leverage the React Form Engine instead of the Angular Form Engine.
      React
      @Samuel Male 
          OpenMRS Standalone
      Large
      Replace the Standalone with something else. Very old, can’t even build in our latest releases - we disable it as the technology no longer works and is no longer supported. We now just ship the .war file and README. Suggestion to leverage Docker - something that works by double clicking and then just runs.
      We never intended to use the OpenMRS Standalone version in production. But it turned out to be used in a number of places because they found it easier to use for sites that did not have support staff with advanced IT skills. We are also seeing an increasing number of people in our community who do not have lots of computer skills and just want something to download, click and run for their hospitals.
      Java
      @Daniel Kayiwa 
      @Wikum Weerakutti 
        Integrating Data Filter for Data Segregation / Multi-tenancy
      Large
      Data Filter is a powerful module that uses Hibernate’s filtering APIs to add additional where clauses to various SELECT statements. The use-case for this is to allow system-wide filters to be applied to the data added. Currently Data Filter includes a default set of filters that restrict the availability of data on patients to a set of locations a user has access to. The point of this project would be to expand on these capabilities to add things like: an administrative UI for associating users and patients with specific locations, additional rules to account for the various modules used in the O3 RefApp, templates for additional rules that may be useful (i.e., tie the ability to see obs with certain codes to certain privileges).
      Java, Hibernate
      @Joshua Nsereko 
      @Wyclif Luyima 
          Immunization & Vaccination Schedule app for O3
      Medium
      Immunization Schedules (timings) are a key feature to make sure people (especially children) get the right vaccinations, at the right times, and enough of them, so that they are safely covered from diseases. 
      This visual project will make it easier for clinicians to see how many doses a child/person has had, and what immunizations they are due for.
      React
      @Dennis Kigen 
          Implement Stricter Typescript configuration
      Medium
      This project aims to enforce stricter TypeScript configurations across OpenMRS repositories, ensuring developers follow best practices for strong typing. The primary goal is to eliminate the use of any, enforce strict type safety, and refactor existing code to comply with these rules.
      By implementing stricter TypeScript settings and refining type definitions, this project will enhance code maintainability, reduce runtime errors, and improve the overall developer experience.
      React, Typescript
      @Christopher Lumu 
          Improved Implementer Tools
      Medium
      The Implementor Tools in OpenMRS can be enhanced for better usability and functionality.
      Proposed Improvements:
      Color Picker & Preview: Currently, only the hex code is shown. Or at least adding a color picker and visual preview would improve user experience.
      Better Nested Object Handling: The UI editor struggles with nested objects, making it harder to edit complex structures.
      Font Visibility Fixes: Some font colors blend into the background, affecting readability. Improved contrast would enhance accessibility.
      Other potential improvements include better validation, UI optimizations, and enhancements to streamline configuration. These changes will make the tool more intuitive and user-friendly.
      React
      @Vineet Sharma 
          Pending Ideas
      These ideas are either not well-defined or lack sufficient mentors. If you're interested in becoming a mentor, feel free to reach out to our organization admins.
      Backlog of Pending Ideas
         
      
      Program Timeline
      Look here for more info on the full GSoC 2025 program timeline.
      DONE
       GSoC 2025 preparations: Community Brainstorming
      DONE
       January 27: Mentoring organizations can begin submitting applications to Google
      DONE
       February 11: Mentoring organization application deadline
      PENDING
       February 27: List of accepted mentoring organizations announced
      February 27 - March 24: Prospective GSoC Contributors reach out to Accepted Mentoring Orgs, discuss application ideas
      March 24:  GSoC contributor application period begins
      DEADLINE
       April 8: GSoC contributor application deadline: Prospective GSoC Contributors Submit their 2025 Applications (includes proposals)
      DEADLINE
       TODO
       April 29: GSoC contributor proposal rankings due from Org Admins
      May 8: Accepted GSoC contributor projects announced
      May 8 - June 1: Community Bonding Period. Students get to know mentors, read documentation, prepare for work on their projects
      June 2:  Coding officially begins
      July 14: Mentors and GSoC contributors can begin submitting midterm evaluations (for standard 12 week coding projects)
      DEADLINE
       TODO
       July 18: Midterm evaluation deadline (standard coding period)
      July 14 - August 25: Work Period | GSoC contributors work on their project with guidance from Mentors
      August 25 - September 1: Final week: GSoC contributors submit their final work product and their final mentor evaluation (standard coding period)
      DEADLINE
       September 1 - 8th: Mentors submit final GSoC contributor evaluations (standard coding period)
      September 1 - November 9: GSoC contributors with extended timelines continue coding
      DEADLINE
       November 10: Final date for all GSoC contributors to submit their final work product and final evaluation
      DEADLINE
       November 17: Final date for mentors to submit evaluations for GSoC contributor projects with extended deadlines
      Guidelines
      Student's guidelines
      GSoC - Guidelines for Students
      GSoC - Proposal Guidelines
      Mentor's guidelines
      Mentor Guide https://google.github.io/gsocguides/mentor/
      Roles and Responsibilities https://developers.google.com/open-source/gsoc/help/responsibilities
      Org Admin Tips https://developers.google.com/open-source/gsoc/help/oa-tips
      Defining a Project Ideas List https://google.github.io/gsocguides/mentor/defining-a-project-ideas-list
      Program Rules https://summerofcode.withgoogle.com/rules
      GSoC Discord Chat channel    discord.gg/google-dev-community
      OpenMRS resources to know
      GitHub: https://github.com/openmrs
      Talk Forum: https://talk.openmrs.org
      Help Desk: https://help.openmrs.org
      Issue Tracker (JIRA): https://issues.openmrs.org
      Wiki: https://openmrs.atlassian.net
      Related content
      Info icon
      Collapse
      GSoC - Proposal Guidelines
      GSoC - Proposal Guidelines
      Resources
      More like this
      Guide for the New and Curious
      Guide for the New and Curious
      Documentation
      More like this
      GSoC - Guidelines for Students
      GSoC - Guidelines for Students
      Resources
      More like this
      Interactive Builder for Form Translations within the Form Builder (Interactive Translation Builder?)
      Interactive Builder for Form Translations within the Form Builder (Interactive Translation Builder?)
      Projects
      Read with this
      Summer of Code 2024
      Summer of Code 2024
      Resources
      More like this
      Fix the Fast Data Entry feature (GSOC 2025)
      Fix the Fast Data Entry feature (GSOC 2025)
      Projects
      Read with this
      Atlassian Intelligence
      5
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openmrs/
    idea_list_url: https://openmrs.atlassian.net/wiki/spaces/RES/pages/322404353/Summer+of+Code+2025

  - organization_id: 114
    organization_name: OpenMS
    no_of_ideas:
    ideas_content: |
      News
      Install
      Documentation
      Community
      About Us
      Use Cases
      On this page
      GSoC Contributors
      Submitting an Application:
      Theme A) Visualization and User-Friendly Tools
      1) Peptide m/z Calculator
      2) Write a generic visualization app for mzQC
      3) Improving PyOpenMS Tool Parameter Accessibility
      Theme B) Data Formats and Interoperability
      1) Pythonic mzML handling
      2) Write a C++ library to read/write mzQC
      3) Integrate Apache Parquet into OpenMS Build System
      4) Universal Mass Spectrometry Data Processing in Python
      Theme C) Machine Learning and Advanced Computational Methods
      1) Diffusion Deconvolution of DIA-MS/MS Data (D^4 | dquartic)
      2) Optimizing Casanovo for Fast and Accurate De Novo Peptide Sequencing
      GOOGLE SUMMER OF CODE 2025
      OPENMS INVITES THE COMPUTATIONAL MASS SPECTROMETRY COMMUNITY TO JOIN GOOGLE SUMMER OF CODE 2025!
      Google Summer of Code (GSoC) 2025 OpenMS is planning to apply as an umbrella organization and we would like to extend an invitation to other projects and groups within the computational mass spectrometry and proteomics/metabolomics communities to join us in this effort. If your project aligns with the goals of GSoC and you are interested in mentoring a student project, we encourage you to submit a short proposals by February 7th 2025 at 23:59 UTC.
      Note: Current status: We are no longer accepting project proposals from mentors.
      GSOC CONTRIBUTORS
      Make sure you are eligible to participate in GSoC 2025.
      remember the GSOC 2025 timeline
      Read the DOs and DON’Ts document to gauge your interest in participating in this year’s GSoC 2025.
      remember the GSOC 2025 timeline
      Review the list of themes and the projects available within. If you have specific questions about a project, our mentors are active on Discord and we will happily assist you.
      Follow our instructions below on how to submit a proposal to us.
      SUBMITTING AN APPLICATION:
      Proposal must be uploaded to the GSoC webpage before the official deadline. Ensure your CV and contact information are included in the proposal document.
      We highly recommend to get in touch with the mentors before submitting your proposal.
      AVAILABLE PROJECTS
      THEME A) VISUALIZATION AND USER-FRIENDLY TOOLS
      1) PEPTIDE M/Z CALCULATOR
      Proposed Mentors: Arslan Siraj, Tom Müller
      Skills: Python, Git, Streamlit
      Estimated Project Length: 90 hours | Difficulty: Easy
      In mass spectrometry (MS) proteomics and metabolomics, one common task is to compute the mass-to-charge (m/z) ratio of the analyte so that it can be located in a spectrum. Although the calculation is computationally simple and can easily be performed by the pyopenms package, this simple, commonly used calculation can be cumbersome for wet lab scientists with little programming experience. In this project the student will use the new OpenMS-WebApps template to create a simple GUI to allow researchers to perform this calculation. This calculation can be performed using pyopenms as demonstrated here Furthermore, this outcome web application further can be extend to other MS calculations tasks (e-g theoretical spectra generation etc) for quick interpretation of MS data.
      2) WRITE A GENERIC VISUALIZATION APP FOR MZQC
      Proposed Mentors: Chris Bielow, Arslan Siraj
      Skills: Visualization, Controlled Vocabularies, Python|R
      Estimated Project Length: 175 hours | Difficulty: Easy to Medium
      Adoption and public exposure of quality control in mass-spectrometry (MS) has gained increasing traction in recent years. The Proteomics Standard Initiative (PSI) has developed an open exchange format named mzQC, which aims to foster capturing, exchanging and archiving quality control related data across all MS-based OMICS, such as proteomics, metabolomics and lipidomics. Currently, there exists no package which is capable of visualizing and summarizing the content of any given mzQC file (e.g. as obtained from a publication’s supplemental material).
      Tasks:
      Pick a visualization framework of your choice (e.g. Streamlit or R Shiny) and write code (Python or R) to allow a user to explore the content of a given (uploaded) mzQC file.
      Visualization could be a textual summary as well as (interactive) plots for the QC data contained within the mzQC file. Depending on the metrics properties, automated plot types should be chosen.
      3) IMPROVING PYOPENMS TOOL PARAMETER ACCESSIBILITY
      Proposed Mentors: Tom Müller, Joshua Charkow
      Skills: Python, Cython, Git
      Estimated Project Length: 175 hours | Difficulty: Medium
      PyOpenMS provides Python bindings for OpenMS, a powerful open-source C++ library for computational mass spectrometry. These bindings are automatically generated using Cython and the autowrap package. While C++ developers prioritize performance and fine-grained control, Python developers emphasize readability and ease of use. Simply exposing a C++ API to Python often results in an interface that feels unnatural to Python users. One area where this is particularly evident in PyOpenMS is the handling of parameters in OpenMS algorithms. Currently, retrieving and modifying parameters requires multiple steps: instantiating an object from an algorithm class, calling a method to obtain parameters, modifying them through a dedicated ‘Param’ class, and applying them via a setter method. This workflow is complex and does not align with Pythonic conventions. The task is to improve the usability of PyOpenMS by enabling parameter setting directly via keyword arguments when instantiating objects of an algorithm class and making parameters easily accessible through the help() function for interactive exploration.
      Tasks:
      Modify the Cython binding for function type checking and conversion.
      Add Pythonic helper functions for type checking and conversion.
      Port the C++ tool documentation to Python.
      THEME B) DATA FORMATS AND INTEROPERABILITY
      1) PYTHONIC MZML HANDLING
      Proposed Mentors: Joshua Charkow, Tom Müller Skills: Python, Git Estimated Project Length: 175 hours | Difficulty: Easy
      Liquid-Chromatography-Mass Spectrometry data is commonly stored in sparse multidimensional data containing billions of peaks and can easily exceed a few gigabytes when compressed on disk. Python is commonly used in the field for exploratory analysis and development of novel data processing algorithms. The most common format for storing mass spectrometry data is in .mzML, an XML based format Although numerous libraries exist for parsing .mzML files in Python, an open source XML based format most commonly used in the field, each library contains its own UI which might not be intuitive for data scientists just starting with mass spectrometry. Recently, the alphatims package was introduced which stores mass spectrometry data in a pandas dataframe like structure making it quite accessible data manipulation and exploration. Notably, this format takes advantage of python’s slicing syntax making it intuitive for all data scientists. However, this package only supports “.d” files which are vendor specific and not applicable to the broader mass spectrometry community. In this project, the student will create a “pythonic” .mzML file reader inspired by alphatims by extending the current available .mzML python parsers.
      Tasks:
      Leaverage the pyopenms documentation to get familiar with pyopenms .mzML file reading.
      Create a class which allows for splicing of the .mzML file across various dimensions and returning a DataFrame object.
      Benchmarking this class on various .mzML files for read times and memory usage.
      creating a python package and releasing it on PyPI.
      2) WRITE A C++ LIBRARY TO READ/WRITE MZQC
      Proposed Mentors: Chris Bielow, Nils Hoffmann Skills: C++, Controlled Vocabularies, JSON, CMake, GitHub CI
      Estimated Project Length: 350 hours | Difficulty: Easy to Medium
      Adoption and public exposure of quality control in mass-spectrometry (MS) has gained increasing traction in recent years. The Proteomics Standard Initiative (PSI) has developed an open exchange format named mzQC,which aims to foster capturing, exchanging and archiving quality control related data across all MS-based OMICS, such as proteomics, metabolomics and lipidomics. Currently, there exist core libraries to read and write mzQC in Python, R, and Java. See MS-Quality-Hub.
      Tasks:
      implement a new mzQC Core library in C++ which supports reading/writing of mzQC
      publish the library on GitHub under a permissive license (BSD-3clause) as a subproject of MS-Quality-Hub.
      write class/unit tests and run them using GithubActions
      integrate your library into OpenMS (incl. adaptation of the build system to include your library) and substitute existing code to create an mzQC
      3) INTEGRATE APACHE PARQUET INTO OPENMS BUILD SYSTEM
      Proposed Mentors: Timo Sachsenberg, Samuel Wein
      Skills: CMake, GitHub CI, C++, Python
      Estimated Project Length: 350 hours | Difficulty: Medium
      Proteomics and metabolomics mass spectrometry studies are generating datasets of unprecedented size as they scale to include more and more samples. Managing and processing these large datasets efficiently requires robust and scalable data handling solutions to make results readily available for downstream processing tasks like machine learning.
      The task is to integrate Apache Parquet, a columnar storage format, into OpenMS as a fundamental step toward enabling faster data processing, reducing memory usage, and improving scalability. The integration will involve:
      Updating the OpenMS build system with new CMake configurations.
      Developing comprehensive tests to validate functionality and performance.
      Adapting CI/CD pipelines for macOS, Linux, and Windows to ensure cross-platform compatibility.
      4) UNIVERSAL MASS SPECTROMETRY DATA PROCESSING IN PYTHON
      Proposed Mentors: Wout Bittremieux, Janne Heirman
      Skills: Python, R, GitHub CI
      Estimated Project Length: 350 hours | Difficulty: Medium
      A major challenge in mass spectrometry (MS) data analysis is the lack of interoperability between different open-source software tools. While various data processing packages in Python exist, many of these suffer from development inefficiencies due to having to implement duplicate functionality.
      This project aims to address these inefficiences by integrating leading open-source MS processing and visualization tools, such as spectrum_utils, pyOpenMS, Pyteomics, and matchms. The goal is to seamlessly connect these tools, harnessing similar internal MS data representations across different tools, allowing users to easily move between different software tools without redundant re-implementation of core functionality.
      To achieve this, we will develop translation layers between different MS tools, enabling smooth data exchange both within and across programming languages; optimize existing algorithms to handle the ever-growing size of MS datasets efficiently, ensuring faster and more scalable data processing; and create a unified workflow that makes MS analysis more intuitive, accessible, and powerful for researchers worldwide.
      By building these bridges, this project will empower scientists to focus on discoveries rather than data format headaches, fostering collaboration and innovation across the mass spectrometry community.
      THEME C) MACHINE LEARNING AND ADVANCED COMPUTATIONAL METHODS
      1) DIFFUSION DECONVOLUTION OF DIA-MS/MS DATA (D^4 | DQUARTIC)
      Proposed Mentors: Justin Sing, Leon Xu
      Skills: Python, PyTorch, Deep Learning
      Estimated Project Length: 350 hours | Difficulty: Medium to Advanced
      Diffusion models have revolutionized generative AI, excelling in tasks like image enhancement and speech separation. This project applies similar principles to Data-Independent Acquisition Mass Spectrometry (DIA-MS)—a technique that captures complex, overlapping signals requiring deconvolution. This project offers an exciting opportunity to apply deep learning & generative AI techniques to a real-world bioinformatics challenge. If you enjoy working on AI models for signal processing, deconvolution, and scientific applications, we’d love to have you on board!
      Problem: DIA-MS produces two correlated data types: MS1: A low-resolution “overview” (analogous to a blurry image or background noise in audio). MS2: Detailed but highly multiplexed signals (akin to overlapping voices in an audio recording).
      The goal is to train a diffusion model to deconvolve and denoise MS2 signals, using MS1 as a guiding signal—similar to how Stable Diffusion refines blurry images or Whisper (OpenAI) separates speech from noise.
      Current Progress & Next Steps:
      A baseline U-Net-based diffusion model already shows promising results on synthetic mixtures of DIA-MS data. The next phase is to:
      a. Train the model on raw DIA-MS data for direct peptide signal separation. b. Integrate MS1 and MS2 peptide feature masks (from OpenSwath, DIA-NN, or Spectronaut) as conditioning signals—similar to how segmentation masks guide image super-resolution. c. Investigate pseudo-DDA spectra generation (e.g., diaUMPIRE, diaTracer) by incorporating intermediate deconvolution steps.
      Tasks:
      Optimize Data Loading: Implement efficient pipelines for handling large-scale DIA-MS data.
      Improve Memory Efficiency: Apply quantization to reduce model footprint, similar to vision models.
      Enhance Conditioning Signals: Refine how the model extracts targeted peptide signals from MS1/MS2 data.
      Explore Alternative Architectures: Test transformer-based backbones (e.g., ViTs) for potential performance gains.
      2) OPTIMIZING CASANOVO FOR FAST AND ACCURATE DE NOVO PEPTIDE SEQUENCING
      Proposed Mentors: William Stafford Noble, Wout Bittremieux
      Skills: Python, PyTorch, deep learning, profiling
      Estimated Project Length: 350 hours | Difficulty: Advanced
      De novo peptide sequencing is a powerful approach for molecular discovery by deciphering peptides directly from tandem mass spectrometry (MS/MS) data. Casanovo is a state-of-the-art AI tool that treats de novo sequencing like a language translation problem—converting sequences of peaks in an MS/MS spectrum into amino acid sequences, just like translating one language into another. Powered by a transformer deep neural network, Casanovo has already revolutionized peptide sequencing, but its inference speed remains a bottleneck, particularly during beam search decoding, the step responsible for selecting the best peptide candidates.
      By making Casanovo faster and more efficient, we can unlock new biological insights at an unprecedented scale. Whether it’s identifying unknown proteins, uncovering disease biomarkers, or advancing drug discovery, your contributions will have a real-world impact on science and healthcare. If you love machine learning, performance optimization, and AI-driven discovery, this project is your chance to make a difference in computational biology!
      This project aims to optimize Casanovo’s speed, enabling researchers to process larger datasets, make new discoveries faster, and push the boundaries of proteomics research. You will:
      a. Profile performance bottlenecks in Casanovo’s inference pipeline to pinpoint slowdowns. b. Optimize beam search decoding and other key computations to improve runtime efficiency. c. Enhance scalability, ensuring Casanovo can handle the growing demands of big-data proteomics.
      OpenMS
      Install
      Documentation
      Citing OpenMS
      Community
      Contribute
      Code of conduct
      About us
      Help
      Jobs
      Terms of use
      Privacy
      Press kit
      Impressum
      © 2025 OpenMS. All rights reserved.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openms/
    idea_list_url: https://www.openms.org/news/gsoc2025/

  - organization_id: 115
    organization_name: OpenStreetMap
    no_of_ideas:
    ideas_content: |
      Google Summer of Code/2025/Project ideas
      < Google Summer of Code | 2025
      Jump to navigation
      Jump to search
      This page lists a number of ideas for potential Google Summer of Code 2025 projects. This page's primary purpose is to help to give potential applicants ideas that they can build on to turn into applications for the program. Members of the OSM developer community are encouraged to identify ideas for projects, and indicate whether they would be willing to act as a mentor for a GSoC contributor attempting the project, using the GSoC idea template.
      Contents
      1 Participant project ideas
      2 General
      2.1 Modernize the 3D Model Repository
      2.2 Temporary road closures database and API
      3 Searching
      3.1 Nominatim - Transliteration of Search Results
      3.2 Nominatim - Category search using ID presets
      4 Routing
      4.1 Valhalla - Faster Tile Builds
      4.2 Ferrostar - Snapshot Recording, Testing, and Replay
      5 iD editor
      5.1 MapRoulette Integration in iD
      5.2 Improve Sidewalk mapping in iD
      5.3 Widget for opening hours
      5.4 Add a "kbar" for an alternative way to configure iD
      5.5 «Come up with your own idea!»
      6 Vespucci
      6.1 AI extraction of information from camera captured images
      7 Every Door
      7.1 Photos in Every Door
      7.2 Test coverage for Every Door
      Participant project ideas
      GSoC contributors can base their application on one of the ideas below, but we also encourage potential GSOC contributors to come up with their own ideas for projects around OpenStreetMap software. Do you have a pet annoyance you want fixed? A feature you think should be implemented? If you believe you are capable of implementing it and it fits within the time constraints and the GSOC eligibility criteria feel free to bring the idea forward.
      Please get in touch with the organizers (at gsoc-orga@openstreetmap.org) as soon as possible if you want to work on something not listed here, so that we can make sure you get the best support possible. We would suggest supplying the same information as in the templates below, if you don't have a potential mentor it may be possible for us to find one for you.
      General
      Modernize the 3D Model Repository
      Suggested By
      Tordanik
      Summary
      The 3D Model Repository (3DMR) is a website which lets users upload openly licensed 3D models and link them with OSM data. Renderers such as OSM2World can use this to create 3D scenes of real-world locations. The goal of this project is to improve the 3DMR by adopting glTF as the format for 3D models, and to upgrade the codebase to current versions of Django and Oauth. In addition to these essential updates, the project would be an opportunity to improve the website UI and API.
      Mandatory skills
      Python
      Useful skills
      Django, JavaScript, 3D graphics
      Length
      350 hours
      Difficulty
      medium
      Possible Mentors
      Lonvia, Tordanik
      Notes
      As a minimum requirement for applicants, we expect you to set up a local copy of the existing codebase on your own prior to submitting your application so you have a starting point for your work.
      Temporary road closures database and API
      Suggested By
      SimonPoole
      Summary
      Produce a prototype repository and API for temporary road closures and similar for use in OSM (navigation) apps that supports user submitted data, at least one prototype integration in an OSM Navigation app is expected.
      Mandatory skills
      Postgres/SQL, languages suitable for prototyping for an UI and an API
      Useful skills
      having a brain
      Length
      350 hours
      Difficulty
      advanced
      Possible Mentors
      SimonPoole
      Notes
      The assumption is that the API will deliver the information in OpenLR format and that data entry can either be via an extension to an app, or a web UI. For an implementation of OpenLR and matching to OSM data see https://github.com/FraunhoferIVI/openlr Contribution guidelines for projects that I mentor contribution guidelines https://github.com/simonpoole/GSOC/blob/main/guidelines.md
      Searching
      Nominatim - Transliteration of Search Results
      Suggested By
      Lonvia
      Summary
      OpenStreetMap registers names of streets, POIs and places usually in the local language. Larger features like cities or states have translations into other languages but simple POIs like restaurants or hotels often have the local name only. That means that it is quite possible that when searching in OSM data, results are returned that are not only in an unknown language but also in an unknown script, making it impossible to read. Transliteration solves this problem by transfering an unknown script into one the user knows an can read. For this project we want to add transliteration to results of the search engine Nominatim when there are a results that the user may not be able to read.
      Mandatory skills
      Python
      Useful skills
      knowledge of a non-Latin script or the willingness to learn basic reading of one during the project
      Length
      175 hours
      Difficulty
      medium (some research is expected and smaller road blocks that need to be solved independently)
      Possible Mentors
      Lonvia, mtmail
      Notes
      The map on openstreetmap.de shows transliterated names. Have a look especially at Asia and compare with the standard map on [1]. The code for the localisation of the German map can give some useful pointers to libraries for transliteration.
      Comments
      Please also see the general hints for contributing to Nominatim for GSOC at User:Lonvia/GSoC_2021_Nominatim_Projects.
      Nominatim - Category search using ID presets
      Suggested By
      Lonvia
      Summary
      When users search places, they often like to use category words ("hotels in Berlin", "Eiffel tower bus stop", ...). Nominatim has limited support for such category searches. It defines Nominatim/Special_Phrases which are detected in the search query and then used to filter the results. The manually curated lists in the wiki are rather tedious to keep and duplicate other community-maintained lists. For this project, you should explore the tagging presets of the ID editor. The presets contain an extensive list of category names for OSM tags with many translations. The goal of this project is to make these terms searchable with Nominatim. Given that the editors and search engines have very different goals, this will not be a straightforward translation. You will have to experiment and research how category words are used in search, which may include thinking about into simple linguistic problems in a multi-lingual setting.
      Mandatory skills
      basic understanding of OSM tagging including some experience with editing OSM data, basic Python
      Useful skills
      SQL(Postgresql, Postgis)
      Required experience
      intermediate
      Length
      175 or 350 hours
      Difficulty
      medium to advanced
      Possible Mentors
      Lonvia, mtmail
      Notes
      This idea can be either done as a shorter 175h project concentrating on extracting and using simple category words from ID's presets. This would be of medium difficulty. At a length of 350h, students can dive more deeply into the search algorithms for categories and improve them to also find subcategories ("vegan restaurants").
      Comments
      Original issue at [2]. Please also see the general hints for contributing to Nominatim for GSOC at User:Lonvia/GSoC_2021_Nominatim_Projects.
      Routing
      Valhalla - Faster Tile Builds
      Suggested By
      Kevinkreiser
      Summary
      The router relies on a preprocessing step to build a graph from OSM data. This graph tile build is a multiphase process that takes around a day to run on modern hardware. There are a number optimization experiments we can try to bring the overall build time down. More info here: https://github.com/valhalla/valhalla/issues/5099
      Mandatory skills
      familiarity with c-like languages
      Useful skills
      multithreading, performance profiling, knowledge of graph structures
      Required experience
      novice
      Length
      175 hours
      Difficulty
      moderate
      Possible Mentors
      Kevinkreiser
      Notes
      Comments
      Experimentation is encouraged, we should pull whatever threads look to be most promising in our experiments.
      Ferrostar - Snapshot Recording, Testing, and Replay
      Suggested By
      Ian Wagner (on osm, edits, contrib, heatmap, chngset com.)
      Summary
      Ferrostar is a rust based cross-platform turn-by-turn navigation SDK. Ferrostar works with multiple routing engines and using tools like Mozilla's UniFFI and TSify, integrates with modular UI for native iOS, Android and a web PWA (thanks to GSOC 2024!).
      But not all navigation goes according to plan! If we could record the inputs from a navigation session (GPS etc.), and the new state after each update, we can “see through the user’s eyes” when something goes wrong. The contributor will help build such a session logging and snapshot testing tool.
      In addition to the backend (Rust), the contributor will also build a frontend integration for at least one platform (Native iOS or Android, or Typescript web components).
      Mandatory skills
      Rust; some mobile or web
      Useful skills
      Most work will be in Rust, but there will also be some work in a frontend platform of your choice (iOS, Android, Web); you don’t need to be an excellent frontend designer or anything, but some existing knowledge will help.
      Length
      175 hours
      Difficulty
      medium
      Possible Mentors
      Ian Wagner (on osm, edits, contrib, heatmap, chngset com.) and Jacob Fielding
      Notes
      GitHub discussion
      iD editor
      MapRoulette Integration in iD
      Suggested By
      @tordans
      Summary
      Similar to the QA Layers in iD, add a MapRoulette integration to see and resolve tasks. The UI can be mostly backported from Rapid. However, the underlying code will likely need to be changed to fit into the iD architecture. More at https://github.com/openstreetmap/iD/issues/10758
      Mandatory skills
      JavaScript, D3
      Useful skills
      Working with APIs in JavaScript, OSM mapping experience
      Required experience
      intermediate
      Length
      175 hours
      Difficulty
      medium
      Possible Mentors
      Martin Raifer
      Notes
      -
      Comments
      -
      Improve Sidewalk mapping in iD
      Suggested By
      @tordans
      Summary
      Backport the improvements for Sidewalk mapping from Rapid to iD and modify them based on community feedback. More at https://github.com/openstreetmap/iD/issues/10757 and https://github.com/openstreetmap/iD/issues/10743
      Mandatory skills
      JavaScript, D3, strong OSM mapping background
      Useful skills
      -
      Required experience
      advanced
      Length
      175 hours
      Difficulty
      medium
      Possible Mentors
      Martin Raifer
      Notes
      -
      Comments
      -
      Widget for opening hours
      Suggested By
      Martin Raifer
      Summary
      The goal of this project would be to implement a user interface widget which should a) provide a better visual interpretation of already mapped Key:opening_hours (for example in the form of a time table), b) checks for the validity of the contents of the tag, and c) allow to more easily add or modify such information. The widget should be able to take the most common formats into account and allow a fallback to show the full tag content for more complex situations.
      Mandatory skills
      JavaScript
      Useful skills
      Experience with the D3.js framework, OSM tagging/mapping workflows, and iD development
      Required experience
      intermediate
      Length
      90 or 175 hours
      Difficulty
      medium
      Possible Mentors
      Martin Raifer
      Notes
      This project could be extended to 175 hours by enhancing the functionality of the widget also to UI fields for tags with temporal conditions.
      
      Add a "kbar" for an alternative way to configure iD
      Suggested By
      @tordans
      Summary
      iD has many options that can be toggled during a mapping session. The concept of a "kbar" (https://kbar.vercel.app/) provides an alternative way to reach those options. This would allow power users to quickly change settings without adding keyboard shortcuts to each setting (and memorizing them). See https://github.com/openstreetmap/iD/issues/8801 for more
      Mandatory skills
      JavaScript, D3
      Useful skills
      -
      Required experience
      advanced
      Length
      175 hours
      Difficulty
      medium
      Possible Mentors
      Martin Raifer, Tobias
      Notes
      -
      Comments
      -
      
      «Come up with your own idea!»
      Suggested By
      you!
      Summary
      Do you have a feature that you think would be a good fit for iD and would like to get it implemented? Does it fit into a time frame between 90 to 350 hours? Is it somewhat self-contained (i.e. does not require to change too many different parts of the iD editor at the same time)? Does it improve the usability/accessibility of the iD editor, does it add more improve mapping workflows, data validations, localization features and/or performance? If the answers to most questions are yes, please be welcome to put in your own idea as a project proposal for the iD editor!
      Mandatory skills
      JavaScript, D3, OSM mapping
      Useful skills
      UI/UX, …
      Required experience
      advanced
      Length
      90, 175 or 350 hours
      Difficulty
      hard
      Possible Mentors
      Martin Raifer
      Notes
      -
      Comments
      -
      Vespucci
      AI extraction of information from camera captured images
      Suggested By
      SimonPoole
      Summary
      Develop a solution to extract text from a captured image or directly from the camera. The captured text should either be able to be used as a tag value, or to generate a set of tags that can be directly applied to an osm object. It is mandatory that this only uses resources available on device.
      Mandatory skills
      Java or Kotlin
      Useful skills
      gradle, experience with Android development
      Length
      350 hours
      Difficulty
      medium to challenging
      Possible Mentors
      SimonPoole
      Notes
      The successful candidate will need to have access to a suitably powerful Android device. Googles MLkit might be a potential starting point for text recognition. Note that the use of models and code that cannot be distributed on open terms is not possible. Vespucci repo: https://github.com/MarcusWolschon/osmeditor4android , contribution guidelines https://github.com/simonpoole/GSOC/blob/main/guidelines.md
      Every Door
      Photos in Every Door
      Suggested By
      User:Zverik
      Summary
      Many people have asked for photos in Every Door. They need to be of two kinds: photo notes, and pictures of OpenStreetMap objects. The former may be probably attached to OSM notes and share the StreetComplete infrastructure, while the latter must use Panoramax and add relevant tags. There will be an authentication hurdle, probably related to sharing OAuth tokens. This might also involve collaborating with MapComplete author on their instance.
      Mandatory skills
      Flutter + Dart
      Useful skills
      UX design, Riverpod
      Required experience
      intermediate
      Length
      175 hours
      Difficulty
      medium
      Possible Mentors
      User:Zverik
      Notes
      The Every Door code base is currently undergoing a major refactoring, so it's unclear how easy or hard this would be. But with an experience in basic app design this should be not very hard.
      Test coverage for Every Door
      Suggested By
      User:Zverik
      Summary
      Every Door has grown into a big application with a lot of moving parts. Modifying it is sometimes risky, which leads to bugs not patched for a long time. Some little things are covered with tests, but there are absolutely no widget tests, and data tests are also largely missing. Here we need to cover with tests three main areas: providers, field widgets and classes, and helper classes.
      Mandatory skills
      Flutter + Dart, QA
      Useful skills
      Riverpod
      Required experience
      high
      Length
      350 hours
      Difficulty
      medium
      Possible Mentors
      User:Zverik
      Notes
      This is not a front-facing tasks: the app won't get better from your work. But it hardens the foundation for future improvements. You need to have some experience in planning and writing tests, and reading flutter code.
      Categories: Google Summer of Code 2025Google Summer of Code ideas
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openstreetmap/
    idea_list_url: https://wiki.openstreetmap.org/wiki/Google_Summer_of_Code/2025/Project_ideas


  - organization_id: 116
    organization_name: OpenVINO Toolkit
    no_of_ideas:
    ideas_content: |
      Spend your summer doing something exciting and valuable for the open-source community, and join Google Summer of Code. Read more about how the program works on this page.
      OpenVINO Toolkit has been a mentoring organization since 2022!
      Announcements
      Please subscribe this discussion and check it regularly for important announcements.
      Prerequisite task
      We require one pull request sent to our OpenVINO repository from each potential GSoC contributor before accepting participation for GSoC. We would like to see if you know how to code, use git and GitHub, and your coding style. To fulfill this requirement, please:
      Visit the OpenVINO Good First Issues board or Anomalib Good First Issues.
      Select one of the unassigned tickets ("Contributors Needed" column) and ask for the assignment.
      Discuss the solution with the OpenVINO developers.
      Implement it according to the OpenVINO contribution guide or Anomalib contribution guide.
      If you encounter any issues talk to our developers on Discord.
      Create a new pull request with your work.
      Wait for the review and eventual merge.
      Please note the above task is mandatory. However, we reserve the right to review and merge only the selected PRs. Not merging or closing your PR doesn't change your chances of being accepted for GSoC. Due to the expected large number of requests, the review process can be delayed, so please be patient.
      If you're unfamiliar with git and GitHub, check out this blog. The blog is about contributing to OpenVINO core project, but the workflow is same for all projects.
      Application Template
      Your application should consist of the following parts:
      About you
      Your full name
      Your university/current enrollment
      The timezone you live in
      Short bio
      Your experience in programming (especially C++ and Python)
      Your experience in ML and DL
      About the project
      What is your choice?
      Why did you choose this specific idea?
      How much time do you plan to invest in the project?
      Provide an abstract of the solution
      Provide a detailed timeline of how you want to implement the project (include the main points you want to cover and dates)
      General questions
      How do you know OpenVINO?
      What do you know about OpenVINO?
      Have you already contributed to the OpenVINO project? (please include links)
      How could you apply it to your professional development?
      Describe any other career development plan you have for the summer in addition to GSoC.
      Why should we pick you?
      Tasks
      Link to your pull request (for the prerequisite task – the top part of this document), even if it is already merged or closed
      Proposal examples can be found here and here. Please get in touch with us early to discuss your application with the mentor.
      The proposal must be uploaded to the GSoC website during the GSoC contributor application period (according to the dates in timeline).
      Project ideas for 2025
      All project ideas for 2025 can be found here.
      Projects already implemented (2022-2024)
      Projects implemented in the past can be found here.
      Contribution guidelines
      Contribution guidelines can be found here.
      Contact us
      Open OpenVINO discussions tab
      Start a new discussion by pushing the green button (if you cannot see the button, it means you're not logged in)
      Select a "Google Summer of Code" category and add the "gsoc" label
      Ask your question (please be aware everything you post there is publicly available)
      Please get in touch with us early to discuss your application with the mentor. Mentors will do their best to reply to all contributors, but due to a large contributor interest this year, they may not be able to respond to all inquiries
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openvino-toolkit/
    idea_list_url: https://github.com/openvinotoolkit/openvino/wiki/Google-Summer-Of-Code#project-ideas-for-2025


  - organization_id: 117
    organization_name: OpenWISP
    no_of_ideas:
    ideas_content: |
      /
      Developer Resources
      /
      GSoC Project Ideas 2025
      GSoC Project Ideas 2025
      Tip
      Do you want to apply with us?
      We have a page that describes how to increase your chances of success. Please read it carefully.
      Read our Google Summer of Code guidelines.
      Table of Contents:
      GSoC Project Ideas 2025
      General suggestions and warnings
      Project Ideas
      Mass Commands
      X.509 Certificate Generator Templates
      WHOIS Information and IP Address-Based Geolocation
      Improve OpenWISP General Map: Indoor, Mobile, Linkable URLs
      Improve netjsongraph.js resiliency and visualization
      Improve UX and Flexibility of the Firmware Upgrader Module
      Add more timeseries database clients to OpenWISP Monitoring
      OpenWISP VPN Deployer Linux Package
      Enhancing Uspot Captive Portal for OpenWrt
      General suggestions and warnings
      Project ideas describe the goals we want to achieve but may miss details that have to be defined during the project: we expect applicants to do their own research, propose solutions and be ready to deal with uncertainty and solve challenges that will come up during the project
      Code and prototypes are preferred over detailed documents and unreliable estimates: rather than using your time to write a very long application document, we suggest to invest in writing a prototype (which means the code may be thrown out entirely) which will help you understand the challenges of the project you want to work on; your application should refer to the prototype or other Github contributions you made to OpenWISP that show you have the capability to succeed in the project idea you are applying for.
      Applicants who have either shown to have or have shown to be fast learners for the required hard and soft skills by contributing to OpenWISP have a lot more chances of being accepted: in order to get started contributing refer to the OpenWISP Contributing Guidelines
      Get trained in the projects you want to apply for: once applicants have completed some basic training by contributing to OpenWISP we highly suggest to start working on some aspects of the project they are interested in applying: all projects listed this year are improvements of existing modules so these modules already have a list of open issues which can be solved as part of your advanced training. It will also be possible to complete some of the tasks listed in the project idea right now before GSoC starts. We will list some easy tasks in the project idea for this purpose.
      Project Ideas
      Mass Commands
      Important
      Languages and technologies used: Python, Django, JavaScript, WebSockets, REST API.
      Mentors: Gagan Deep, Purhan Kaushik, Kapil Bansal.
      Project size: 350 hours.
      Difficulty rate: medium.
      This project idea aims to extend OpenWISP's remote device management capabilities by enabling users to execute shell commands on multiple devices simultaneously. Currently, OpenWISP supports executing commands on a single device at a time. This project will introduce a bulk execution feature while maintaining the existing security, rules, and limitations of the single-device command execution feature.
      The mass command operation will be accessible from two main entry points:
      An admin action on the device list page, allowing users to select multiple devices and send a shell command in bulk.
      A dedicated mass command admin section, where users can initiate bulk command execution with various targeting options:
      All devices in the system (restricted to superusers).
      All devices within a specific organization.
      All devices within a specific device group.
      All devices within a specific geographic location.
      Specific selected devices.
      The UI will guide users step-by-step, dynamically displaying relevant fields based on the selected target scope. For example, if a user selects "All devices in a specific organization", an auto-complete list of organizations will be displayed next.
      The system will provide real-time tracking of command execution results. Inspired by OpenWISP Firmware Upgrader's mass upgrade feature, the UI will receive live updates via WebSockets, displaying command output as soon as it is received from the devices. Additionally:
      The device detail page will show executed commands under the "Recent Commands" tab.
      Commands that were part of a mass operation will be clearly marked, with a link to the corresponding mass command operation page.
      To support API-based management, the REST API will be extended with the following capabilities:
      Create new mass command operations.
      Retrieve mass command operations and their results (with pagination).
      Delete mass command operations.
      Modify the single-shell command API to reference the mass command operation ID if applicable.
      Prerequisites to work on this project
      Applicants must demonstrate a solid understanding of Python, Django, HTML, CSS, JavaScript, WebSockets, and OpenWISP Controller.
      Expected outcomes
      Implementation of mass shell command execution in OpenWISP, replicating the rules and limitations of single-device execution.
      Development of an intuitive UI with the Django admin for selecting devices and tracking command results in real-time.
      Admin action for device list page.
      Enhancement of the device detail page to reflect mass command history for individual devices.
      Extension of the REST API to support mass command operations.
      Comprehensive automated tests covering the new feature.
      Updated documentation, including:
      Feature description with usage instructions.
      A short example usage video for YouTube that we can showcase on the website.
      X.509 Certificate Generator Templates
      Important
      Languages and technologies used: Python, Django, JavaScript.
      Mentors: Federico Capoano, Aryaman, Nitesh Sinha.
      Project size: 90 hours.
      Difficulty rate: medium.
      This GSoC project aims to enhance OpenWISP's certificate management capabilities by enabling the generation of x509 certificates for general use, beyond OpenVPN.
      Currently, OpenWISP supports generating x509 certificates exclusively for OpenVPN clients, where each VPN client template produces a certificate signed by the CA linked to the corresponding VPN server. However, many users have requested support for generating certificates for other purposes, such as securing web servers.
      The proposed solution involves introducing a new template type that allows users to generate certificates using a selected CA. This template should provide configurable options, including:
      Certificate duration
      Key length
      Digest algorithm
      If left unspecified, these options should default to the CA's standard settings.
      Prerequisites to work on this project
      Applicants must demonstrate a solid understanding of Python, Django, JavaScript, and OpenWISP Controller.
      Expected outcomes
      Implement a new certificate template type in OpenWISP to support general-purpose x509 certificate generation.
      Allow users to select a CA and configure certificate properties.
      Integrate with OpenWISP's configuration management to expose certificate details (public key, private key, and UUID) as variables for automated deployment.
      Write automated tests to ensure the correctness and reliability of the new functionality.
      Updated documentation, including:
      Feature overview in a dedicated page with step-by-step usage instructions.
      Short Video demonstration.
      WHOIS Information and IP Address-Based Geolocation
      Important
      Languages and technologies used: Python, Django, REST API.
      Mentors: Federico Capoano, Nitesh Sinha, Kapil Bansal
      Project size: 175 hours.
      Difficulty rate: Easy/Medium.
      This GSoC project aims to enhance OpenWISP’s device management capabilities by integrating WHOIS data retrieval and automatic fuzzy geolocation based on public IP addresses.
      The project consists of two main features:
      1. WHOIS Information Retrieval
      When a device reports a last_ip that is a public IP and differs from the previously stored value, OpenWISP should automatically trigger a background Celery task to retrieve and store its WHOIS information.
      A summary of key WHOIS details (e.g., organization name, country, ISP) will be displayed alongside the last_ip field on the device detail page.
      Users will have the option to expand this section to view additional details.
      The REST API should include WHOIS summary information in the device list and device detail endpoints.
      An additional API option in the device details endpoint should allow retrieving the complete WHOIS data stored in the database.
      2. Fuzzy Geolocation from IP Addresses
      The system should attempt to determine approximate geographic coordinates based on the device’s last_ip and create a Location object with this data, marking it as Fuzzy (a different term may be considered).
      IP-based geolocation must be processed in a background Celery task to avoid slowing down the main processes.
      The UI should clearly indicate that this location is estimated and encourage users to manually refine it for greater accuracy.
      A notification can be sent to users suggesting they review or confirm the estimated location.
      If the Location object remains unmodified and marked as fuzzy, OpenWISP should detect changes in the device's public IP address and reattempt IP-based geolocation, updating the coordinates if they differ.
      The Location admin list page should include a filter for fuzzy locations.
      The Device admin list page should include a filter for devices with fuzzy locations (expanding on the existing filter for devices with or without geographic locations).
      This feature should be configurable at both the global and organization levels, allowing administrators to enable or disable it as needed. Existing modules already provide organization settings that default to global configuration, see FallbackBooleanChoiceField for reference.
      The OpenWISP Controller REST API must be updated to support these functionalities:
      Include the fuzzy field in the Location list and detail endpoints.
      Allow filtering fuzzy locations.
      Allow filtering devices with fuzzy locations.
      Prerequisites to work on this project
      Applicants must demonstrate a solid understanding of Python, Django, REST APIs, HTML, CSS, JavaScript, OpenWISP Controller, and django-loci.
      Expected Outcomes
      Implementation of WHOIS data retrieval as a background operation and display within the OpenWISP Controller admin panel.
      Development of fuzzy geolocation based on public IPs, with clear UI explanations and manual override options.
      Integration with OpenWISP’s notification system to suggest location refinements.
      Admin filters to identify fuzzy locations and devices with fuzzy locations.
      Configurable settings to enable or disable the feature globally or per organization.
      REST API enhancements to reflect the new functionalities.
      Comprehensive automated tests ensuring feature reliability.
      Updated documentation, including:
      A feature overview with step-by-step usage instructions on dedicated pages.
      Videos demonstrating WHOIS data retrieval and geolocation results.
      Configuration details for enabling or disabling these features.
      Improve OpenWISP General Map: Indoor, Mobile, Linkable URLs
      Important
      Languages and technologies used: Python, Django, JavaScript, Leaflet, netjsongraph.js.
      Mentors: Federico Capoano, Nitesh Sinha, Gagan Deep.
      Project size: 350 hours.
      Difficulty rate: medium.
      This GSoC project aims to enhance the user experience of the general map within OpenWISP, a feature introduced in the last stable version.
      By developing a dedicated map page, facilitating precise device tracking, and seamlessly integrating indoor floor plans, the project endeavors to significantly improve the usability and functionality of the mapping interface, ensuring a more intuitive and effective user experience.
      Prerequisites to work on this project
      Applicants must demonstrate a solid understanding of Python, Django, Leaflet library, JavaScript, OpenWISP Controller, OpenWISP Monitoring. and netjsongraph.js.
      Expected outcomes
      Add a dedicated map page: Introduce a dedicated page to display all network devices on a map. This view will offer the same functionality as the map in the dashboard, with the sole difference being that this page focuses on rendering only the map. It will be used for linking specific points on the map within the rest of the OpenWISP UI.
      Allow tracking mobile coordinates: OpenWISP Controller provides a way for devices to update their co-ordinates, we want to make the map able to update in real time as devices send their updated coordinates.
      Integrate indoor floor plan functionality in the map: The netjsongraph.js library allows to render indoor maps, we want to make use of this feature to display the indoor location of devices and we want this feature to be accessible from the general map. When zooming in on a device which is flagged as indoor and has floor plans saved in the database, users should see an option to switch to the indoor view. This view would show the floor plan of the indoor location and any device located on the floor plan, it shall also account for the following use cases:
      An indoor location can have multiple floors. The view should be allow users to navigate between different floors.
      There can be multiple devices on the same floor. The view should show all the devices on a floor. This will require developing an API endpoint which returns location of devices on the floor plan
      Make map actions bookmarkable: Update the URL when clicking on a node/link to view its details. Visiting this URL should automatically focus on the specified node/link and display its details, if available. This functionality should also accommodate geo-maps using coordinates. Clicking on a node/link to view it's details should update the the page's URL. When visiting this URL, the map should automatically focus the said node/link. It shall also open the node's/link's details if they are available. This should work on geographic maps, indoor maps and logical maps.
      Add button to general map from device detail: Implement a button on the device detail page to allow users to navigate from the device detail to the general map and inspect the device's location on the map. The map should focus on the specific device in question. This feature should also be available for indoor maps, providing a button in the floor plan section to open the general map with the indoor view focused.
      Throughout the code changes, it is imperative to maintain stable test coverage and keep the README documentation up to date.
      Note
      The "expected outcomes" mentioned above include links to corresponding GitHub issues. However, these issues may not cover all aspects of the project and are primarily intended to gather technical details. Applicants are encouraged to seek clarification, propose solutions and open more issues if needed.
      Applicants are also expected to deepen their understanding of the UI changes required by preparing wireframes or mockups, which must be included in their application. Demonstrating a willingness and enthusiasm to learn about UI/UX development is crucial for the success of this project.
      Improve netjsongraph.js resiliency and visualization
      Important
      Languages and technologies used: Javascript, NodeJS, HTML, CSS
      Mentors: Nitesh Sinha, Federico Capoano.
      Project size: 175 hours.
      Difficulty rate: medium.
      The goal of this project is to improve the latest version of the netjsongraph.js visualization library to improve resiliency and functionality.
      Prerequisites to work on this project
      The contributor should have a proven track record and experience with Javascript, React JS, NodeJS, HTML and CSS.
      Familiarity with OpenWISP Network Topology and OpenWISP Monitoring is a plus.
      Expected outcomes
      The applicant must open pull requests for the following issues which must be merged by the final closing date of the program:
      Allow showing node names on geo map on high zoom levels: The node names should be shown by default on high zoom levels.
      Map should respect zoom levels of tile providers: We shall limit the map zoom levels based on the tile provider. We can make the supported zoom levels configurable and provide sensible defaults.
      Prevent overlapping of clusters: The clusters of different categories with the same location are overlapped. Instead, we should find a way to prevent this behavior.
      Add resiliency for invalid data: The library should not crash if invalid data is provided, e.g. different nodes with same ID. Instead, it should handle such cases gracefully and log the errors.
      Display additional data (connected clients) on nodes: It shall be possible to show connected clients on nodes. This feature needs to be flexible, such that it can be used to show different kinds of data.
      Show node labels only after hitting a certain zoom level: At present, the node labels become cluttered and unreadable when zoomed out excessively. To enhance readability, we need to add a feature in the library that allows configuring the zoom level at which node labels should start appearing.
      Each issue contains the details which the applicant needs to know in order to complete the project successfully.
      At each step of code changing the test coverage must be maintained stable and the documentation in the README must be kept up to date.
      Improve UX and Flexibility of the Firmware Upgrader Module
      Important
      Languages and technologies used: Python, Django, OpenWrt.
      Mentors: Oliver Kraitschy, Purhan Kaushik.
      Project size: 175 hours.
      Difficulty rate: easy/medium.
      The goal of this project is to improve the Firmware Upgrader module to make its mass upgrade operation feature more versatile and to improve the user experience by showing progress in real time.
      Prerequisites to work on this project
      The applicant must demonstrate good understanding of Python, Django, Javascript and OpenWISP Controller.
      They must demonstrate also a basic understanding of OpenWISP Firmware Upgrader, OpenWrt and UI development.
      Prior experience with OpenWrt is not extremely required but welcome.
      Expected outcomes
      The applicant must open pull-requests for the following issues which must be merged by the final closing date of the program:
      [feature] REST API is missing endpoints for DeviceFirmware
      [feature:UI] Show upgrade progress in real time in the UI
      [feature] Allow to perform mass upgrade of devices by their group
      [feature] Allow to perform mass upgrade of devices by their location
      Each issue contains the details which the applicant needs to know in order to complete the project successfully.
      At each step of code changing the test coverage must be maintained stable and the documentation in the README must be kept up to date.
      Training Issues
      The applicant may warm up in the application phase by working on the following issues:
      [bug] FileNotFoundError when trying to delete an image which links a non existing file
      [change] Improve endpoints to download firmware images
      [feature] Allow management of UpgradeOperation objects in the admin
      Add more timeseries database clients to OpenWISP Monitoring
      Important
      Languages and technologies used: Python, Django, InfluxDB, Elasticsearch.
      Mentors: Gagan Deep, Aryaman, Sankalp.
      Project size: 350 hours.
      Difficulty rate: medium.
      The goal of this project is to add more Time Series DB options to OpenWISP while keeping good maintainability.
      Prerequisites to work on this project
      The applicant must demonstrate good understanding of OpenWISP Monitoring, and demonstrate basic knowledge of NetJSON format, InfluxDB and Elasticsearch.
      Expected outcomes
      Complete the support to Elasticsearch. Support to Elasticsearch was added in 2020 but was not completed.
      The old pull request has to be updated on the current code base
      The merge conflicts have to be resolved
      All the tests must pass, new tests for new charts and metrics added to InfluxDB must be added (see [feature] Chart mobile (LTE/5G/UMTS/GSM) signal strength #270)
      The usage shall be documented, we must make sure there's at least one dedicated CI build for Elasticsearch
      We must allow to install and use Elasticsearch instead of InfluxDB from ansible-openwisp2 and docker-openwisp
      The requests to Elasticsearch shall be optimized as described in [timeseries] Optimize elasticsearch #168.
      Add support for InfluxDB 2.0 as a new timeseries backend, this way we can support both InfluxDB <= 1.8 and InfluxDB >= 2.0.
      All the automated tests for InfluxDB 1.8 must be replicated and must pass
      The usage and setup shall be documented
      We must make sure there's at least one dedicated CI build for Elasticsearch
      We must allow choosing between InfluxDB 1.8 and InfluxDB 2.0 from ansible-openwisp2 and docker-openwisp.
      OpenWISP VPN Deployer Linux Package
      Important
      Languages and technologies used: Linux, Python, Django, WebSockets, OpenVPN, WireGuard, WireGuard over VXLAN, ZeroTier.
      Mentors: Federico Capoano, Gagan Deep, Oliver Kraitschy.
      Project size: 350 hours.
      Difficulty level: medium/hard.
      This GSoC project aims to simplify the deployment and management of VPN servers integrated with OpenWISP.
      The goal is to develop an easy-to-install program that automates the deployment of VPN servers synchronized with OpenWISP in real time. This reduces manual intervention and ensures configuration consistency between the VPN server objects in the OpenWISP database and the deployed VPN instances.
      Key Features
      The program will run on Linux-based servers and will:
      Be implemented in Python to ensure maintainability and extensibility.
      Use a Makefile to generate installation packages for major Linux distributions:
      DEB (for Debian, Ubuntu, and related distributions)
      RPM (for Red Hat, Fedora, and similar systems)
      Snap (for broader Linux compatibility)
      Establish a WebSocket connection with OpenWISP to listen for changes in VPN server configurations and synchronize local settings accordingly.
      Keep the local list of peers and the certificate revocation list (CRL) updated whenever VPN clients are added, removed, or modified.
      Support the following VPN tunneling technologies:
      OpenVPN
      WireGuard
      WireGuard over VXLAN
      ZeroTier
      Provide a command-line utility to simplify the initial setup. This utility will:
      Guide users step by step, making it accessible even to those with limited experience.
      Allow users to select the VPN technology to be deployed.
      Verify that the necessary system packages are installed and provide clear warnings if dependencies are missing.
      Assist in securely connecting and synchronizing with OpenWISP.
      Note
      The command-line utility must apply all necessary changes in the OpenWISP database via the REST API. If any required modifications cannot be performed with the current API, the contributor will be responsible for implementing the missing functionality.
      To facilitate authentication, the utility will guide users in retrieving their OpenWISP REST API token. A proposed approach is to provide a link to the OpenWISP admin interface, where users can generate and copy their API token easily.
      Support running multiple instances, where each instance manages a separate VPN server independently.
      Implement structured logging with dedicated log files for each instance, adhering to Linux logging best practices and supporting log rotation.
      Provide comprehensive documentation in ReStructuredText format, following OpenWISP conventions:
      Documentation will be stored in a /docs directory, with a clear separation between user guides and developer documentation.
      A video demonstration will be included, which can be published on YouTube to increase project visibility.
      Update the OpenWISP documentation to cover installation, configuration, and best practices.
      To support this project, OpenWISP Controller will need to be updated to expose a WebSocket endpoint. This will allow the VPN synchronization program to receive real-time configuration updates.
      Prerequisites to work on this project
      Applicants should have a solid understanding of:
      Python and Django.
      WebSockets.
      At least one of the supported VPN technologies (OpenVPN, WireGuard, WireGuard over VXLAN, ZeroTier).
      System administration and Linux packaging (preferred but not required).
      Expected Outcomes
      A Python-based VPN synchronization tool.
      A command-line setup utility for easy first-time configuration.
      WebSocket-based synchronization between VPN servers and OpenWISP.
      Automated packaging for major Linux distributions.
      Structured logging with proper log rotation.
      Enhancements to OpenWISP Controller to support WebSocket-based synchronization and any required REST API modifications.
      Automated tests to ensure reliability and stability.
      Comprehensive documentation, including setup guides and best practices.
      A short tutorial video demonstrating installation and usage.
      Enhancing Uspot Captive Portal for OpenWrt
      Important
      Languages and technologies used: ucode, C, OpenWrt, RADIUS.
      Mentors: Federico Capoano, Sankalp.
      Project size: 350 hours.
      Difficulty rate: hard.
      This GSoC project aims to improve Uspot, a relatively new captive portal for OpenWrt, by implementing critical missing features that are essential for large-scale deployments. Uspot is a promising replacement for CoovaChilli, which is no longer actively developed and only receives occasional maintenance patches. However, Uspot lacks several important capabilities that CoovaChilli provides. This project will focus on adding the most critical missing features to ensure Uspot can be a viable alternative.
      Feature list
      1. Traffic Reporting for RADIUS Accounting Interim-Updates
      Implement RADIUS accounting interim-update support.
      Add an option to swap input and output traffic counters (similar to CoovaChilli's swapoctets option).
      2. No-Challenge Authentication Mode
      Implement a nochallenge mode where passwords are sent in plain-text to RADIUS.
      Justification: OpenWISP uses Django’s modern hashing algorithms, which are significantly stronger than those supported by RADIUS.
      Security: This method is secure as long as communication between the captive portal and RADIUS is encrypted using VPNs or RadSec.
      3. Support for RadSec (RADIUS over TLS)
      Ensure RadSec can be used to encrypt RADIUS packets.
      Provide documentation on how to configure Uspot with RadSec.
      4. Bandwidth Limitation Features
      Static Configuration: Applied to all users globally.
      Dynamic RADIUS-based Configuration: Bandwidth limits based on RADIUS attributes (e.g., WISPr-Bandwidth-Max-Down, WISPr-Bandwidth-Max-Up), allowing differentiated speeds based on user type.
      These features are available bu not documented right now, so let's make sure they're properly documented.
      5. Traffic Consumption Limits
      Implement RADIUS attributes to limit total data consumption per user:
      ChilliSpot-Max-Total-Octets
      WISPr-Bandwidth-Max-Total
      CoovaChilli-Max-Total-Gigawords (important for limits above 4.29 GB, overcoming 32-bit integer limitations).
      6. VLAN Tagging Support
      Allow tagging user traffic with VLANs:
      Global VLAN Configuration: Apply a default VLAN tag to all users.
      RADIUS-based VLAN Assignment: Dynamically assign VLANs based on RADIUS Access-Accept attributes, which allows to tag traffic with different VLANs based on rules defined at the application level.
      Prerequisites to work on this project
      Applicants must demonstrate a solid understanding of:
      ucode proficiency.
      C programming (for modifying Uspot’s core functionality).
      Networking protocols, including RADIUS and VLANs.
      OpenWrt development (building and packaging OpenWrt software).
      Secure authentication mechanisms (RadSec, HTTPS authentication).
      Linux network stack, particularly how OpenWrt handles network interfaces and firewall rules.
      Expected Outcomes
      Implementation of the missing features in Uspot, getting closer to parity with key CoovaChilli functionalities.
      Comprehensive testing and validation of each new feature.
      Ensure all changes are merged upstream into the Uspot repository.
      Update OpenWrt packages for the most recent two OpenWrt versions to include these enhancements.
      Provide documentation on how to configure all the features mentioned in the project description.
      Potential adoption of Uspot as a fully functional captive portal replacement for CoovaChilli in OpenWISP deployments by mentioning it in the documentation of OpenWISP.
      Google Summer of Code
      On this page
      General suggestions and warnings
      Project Ideas
      Mass Commands
      Prerequisites to work on this project
      Expected outcomes
      X.509 Certificate Generator Templates
      Prerequisites to work on this project
      Expected outcomes
      WHOIS Information and IP Address-Based Geolocation
      Prerequisites to work on this project
      Expected Outcomes
      Improve OpenWISP General Map: Indoor, Mobile, Linkable URLs
      Prerequisites to work on this project
      Expected outcomes
      Improve netjsongraph.js resiliency and visualization
      Prerequisites to work on this project
      Expected outcomes
      Improve UX and Flexibility of the Firmware Upgrader Module
      Prerequisites to work on this project
      Expected outcomes
      Training Issues
      Add more timeseries database clients to OpenWISP Monitoring
      Prerequisites to work on this project
      Expected outcomes
      OpenWISP VPN Deployer Linux Package
      Key Features
      Prerequisites to work on this project
      Expected Outcomes
      Enhancing Uspot Captive Portal for OpenWrt
      Feature list
      Prerequisites to work on this project
      Expected Outcomes
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/openwisp/
    idea_list_url: https://openwisp.io/docs/dev/developer/gsoc-ideas-2025.html

  - organization_id: 118
    organization_name: Oppia Foundation
    no_of_ideas:
    ideas_content: |
      Important: We are making some changes to how we run GSoC for 2025. Please read this page carefully, since some things have changed from previous years.
      Table of Contents
      Getting started
      FAQs
      Dates and Deadlines
      Types of work related to Oppia projects
      GSoC proposal template
      Tips for writing a good project plan
      What should applicants expect from mentors in a proposal review?
      Selection Criteria
      Communication
      Oppia's Project Ideas List
      This year marks the 10th year that Oppia will be participating in Google Summer of Code (GSoC)! GSoC is a global program which offers post-secondary students, as well as newcomers to open source, an opportunity to discover and work with open source organizations. The contributions are supported by a stipend. Contributors work closely with one or more mentors to implement either a project idea by the organization, or a proposal of their own.
      In order to receive updates about GSoC at Oppia, please subscribe to the Oppia GSoC Announce mailing list, as well as the Developer Announcements category on GitHub Discussions.
      This year, based on previous years' feedback, Oppia plans to follow a slightly extended GSoC timeline: projects will have 7 weeks for each milestone, with an additional "holiday week" between the milestones. Each milestone includes 5 weeks of coding time, 1 week for evaluations, and 1 week for fixes, as well as a product demo session after the 4th coding week. Please refer to the Dates and Deadlines section below for more details.
      Also, please note that acceptance into GSoC isn't a prerequisite for becoming an Oppia contributor. The Oppia project is run by a global community dedicated to making meaningful social change, and we warmly welcome anyone who'd like to help out! You can get started by following the instructions here (Web, Android).
      Contributors
      GSoC is an excellent opportunity for new contributors to get paid to work on an open source project. If you're interested in applying as a contributor, we strongly recommend reading this entire wiki page, including our FAQ which answers many of the common questions we receive.
      You should also definitely read the following resources:
      Google Summer of Code contributor guide
      Google's list of resources
      Google's GSoC FAQ
      Furthermore, note that GSoC isn't just about code -- it's also about communication and interaction with the open source community! Hear what some of our previous contributors have to say:
      I learnt a lot from this organisation -- tackling a huge codebase, writing clean and efficient code and communication.
      I learn a lot of things in Oppia which I didn't learn in my school and college. It's not necessary that only a software engineer can contribute, anyone can contribute to Oppia with his/her skill.
      I like the fact that the maintainers are so sincere in their work and are very responsive.
      Oppia Foundation is really awesome and I get to interact with amazing people and learn a lot. The best part is that everything is organised really well and that makes it easy to solve my issues.
      The Oppia Foundation excelled in fostering a supportive and inclusive environment for contributors. The responsiveness of the mentors and the community was remarkable, making it easy to seek guidance and get help whenever needed. The clear communication, structured processes, and well-documented codebase greatly helped my learning and development throughout GSoC.
      I really enjoyed the process, and the feeling of owning a feature end-to-end is fantastic, even with the challenges. Over the past three months, I've learned a lot about feature testing, release testing, PM demos, and more.
      You might also enjoy the "weekly journals" from some of our previous contributors: Rd4dev and @theMr17.
      Getting started
      Welcome! If you're interested in applying to work with Oppia for GSoC, please follow these steps:
      Sign up to the oppia-gsoc-announce@ mailing list and the Developer Announcements category on GitHub Discussions, so that you can receive important notifications about Oppia's participation in GSoC. Make sure to set your preferences correctly so that you actually get the emails!
      Get a better understanding of what Oppia is about:
      Read the user documentation to become familiar with important concepts like explorations and interactions.
      Play some lessons on Oppia.org, which hosts a live instance of Oppia.
      To get started with development, read and follow the instructions in the contributors' guide carefully (Oppia Web, Oppia Android). If you're interested in Oppia Web, you might also find these tutorials helpful.
      Do a few starter projects to become familiar with the contribution process. This will help us get an idea of what it's like to work with you. It will also help you get a better understanding of the codebase and our development process, which may help with writing a good project proposal. Once you've merged at least 2 pull requests, you will get an invitation to become a collaborator to the Oppia repository and be officially onboarded! This step is a prerequisite to applying for GSoC.
      Note
      You must be onboarded to the repository to which you will contribute during GSoC. For example, to work on an Oppia Web GSoC project, you need to be onboarded to the oppia/oppia repository, which means that your 2 pull requests need to be to oppia/oppia.
      Tip
      Quality is more important than quantity, so try to contribute to high-impact issues where possible. Also, we want to see examples of your best work, so please make sure to read the "getting started" guide and PR instructions carefully, follow the tips for success, manually test your code before submitting (to ensure it does what you want it to and doesn't break anything else), ensure that your code conforms to the style rules, and pay attention to small details. These are good skills to learn when developing software in general, and they will also help you build credibility as a responsible developer who can be trusted to be a good steward of the Oppia codebase.
      Select one or more GSoC project ideas that you're most interested in, and write your project proposal! You can get feedback from project mentors when you've completed a sufficient draft -- see the instructions in the GSoC proposal template section for details.
      We require that all general discussion about GSoC projects take place in open channels. If you have questions about a project, you can ask in GitHub Web Discussions or GitHub Android Discussions. Note that individual projects have their own categories, so please use those if you have project-specific questions. Please also be specific when asking questions, since this makes it easier for us to help you.
      Tip
      During the application period, your first goal should be to figure out how to become an effective contributor. Start developing your project proposal only once you have experience getting some PRs merged. This will give you a much better idea of what you want to work on, and how much you can accomplish.
      You might also want to ensure that you have the required skills for your chosen project. For guidance on how to do this, see the relevant section in the GSoC proposal template document and our FAQs.
      Good luck!
      FAQs
      Q: What technical skills do I need to work on Oppia?
      A: Please see the individual project ideas to determine which skills are recommended for the project in question. Also, in general:
      For Oppia Web, Angular 2+, Python 3.9, Google App Engine and Apache Beam are useful and recommended, and experience with Docker and GitHub Actions is useful for developer workflow projects. Also, it is important to be able to write tests for the code you submit (using Karma, Webdriverio and unittest). You might also find this page of learning resources helpful, as well as other pages on our wiki that provide guidance on Apache Beam, testing frameworks, etc.
      For Oppia Android, you will need to know how to program in Kotlin, and have experience with Android development. Knowledge of Bazel may also be helpful for some projects.
      Note that, although GSoC is aimed at both students and beginner contributors to open source, "beginner to open source" is not the same as "beginner to coding" -- the projects do assume that you have some proficiency with coding. The fact that GSoC projects produce high-quality code that solves real problems for open-source projects does make GSoC challenging, but this is also part of what makes GSoC such a valuable experience for our contributors.
      Q: How can I increase my chances of getting selected?
      A: The most important thing is to ensure that you have the required skills for the project -- see the "Required Skills" section of the proposal template for more details. Aside from that, writing a good project proposal with a solid solution approach, engaging with the community, helping other contributors, successfully contributing PRs for high-priority issues, and demonstrating that you can work independently can all help you. We've also compiled some notes below on the selection criteria we'll be using this year.
      Q: Which projects are most important for Oppia? Can you advise which project I should pick?
      A: All the projects we've listed in the Ideas List are treated as equally important during selection, and we'd be very happy to see good progress made on any of them! Note that the relative importance of a project to Oppia is not part of the selection criteria. In general, we recommend that you pick a project based on whether you already have (or will be able to learn) the skills required for it, and that you'd enjoy doing over the summer!
      Q: I do not have any experience in skill XYZ. What should I do?
      A: If you are missing a skill that is needed for a project, we recommend trying to learn it -- in software development, it is common to develop experience and expertise as you take up and complete projects successfully. Some ways to do this include working on issues that give you a chance to develop that skill, referring to our wiki documentation, and following tutorials from elsewhere on the Web. Please note that, in general, we are unlikely to accept applicants who lack the required skills for a project, since this tends to result in significant difficulties during the coding phase.
      Q: How will you assess whether I have the required skills for a project?
      We will assess your application based on your proposal and the skills that you have demonstrated in your PRs and other interactions with the community. Please see the guidance in the "Required Skills" section of the proposal template, which explains how to demonstrate that you have the required skills for a project, and provides pointers on how to develop those skills.
      Q: Is it okay if I only focus on the frontend or backend?
      A: This probably depends on the project(s) you wish to apply for; check their "required skills" sections. However, note that most projects are full-stack and require ability in both the frontend and backend. We recommend becoming familiar with both of these, since this will open up more opportunities for you, as the projects we work on at Oppia often touch multiple layers of the stack.
      Q: What is the minimum number of PRs that one should have?
      A: You should have at least 2 merged PRs. Beyond that, remember that quality is more important than quantity, so consider taking some high-priority or "impact: high" issues if you're able to, since those fixes are more valuable. You can find a list of high-priority issues on the respective teams' project boards: LaCE, Dev Workflow, Contributor Dashboard, Android CLaM, Android Dev Workflow. Additionally, you'll also want to demonstrate that you have the required skills to successfully complete your chosen project; please see the guidance in the "Required Skills" section of the proposal template, which explains how to do this.
      Q: Will I be penalized during selection if I ask for help while contributing?
      A: Not at all! Asking for help when you need it is part of the learning process, and the Oppia open-source community is more than happy to help and onboard new members. Please just ensure that your questions are well-formed and that you (a) have read the relevant docs on the wiki, (b) provide the necessary information (such as a debugging doc) to help responders understand what you've figured out so far and where you are stuck.
      Q: I only discovered Oppia recently. Does this mean that, during selection, my application would automatically be ranked lower than those by other applicants who have a longer tenure with Oppia?
      A: Definitely not! Here are the selection criteria we use when selecting contributors for GSoC. Note that tenure with Oppia is explicitly not part of these criteria.
      Q: How early should I start working on the proposal?
      A: We recommend developing your project proposal and engaging with the community via GitHub Discussions as early as possible, so that you have enough time to get feedback from mentors and improve the proposal before the submission deadline. Make sure to follow all instructions in the proposal template (especially around sharing and access) to reduce delays in reviewing your proposal. That said, it's important to note that the proposal is only one part of the application process, and it is probably more important to figure out how to become an effective contributor by getting some PRs merged and demonstrating that you have the required skills for the project.
      Q: Can I submit more than one proposal to Oppia?
      A: Yes, you can. However, we strongly recommend picking one project and writing a solid proposal for it. Splitting attention across multiple projects might not be a great idea. (That said, GSoC is offering projects of multiple lengths, and if you're interested in doing either the 'full version' or the 'half version' of a project idea that can support both modes, you can submit both the 'full version' and the 'half version' as separate applications. Just make sure that you'd be happy with either outcome if you are selected!)
      Q: If I only submit a proposal, without making any code contributions, will my application be considered?
      A: No. See our selection criteria for more details.
      Q: Can I use content from the project ideas list or PRD in my proposal?
      A: It is fine for proposals to draw from the GSoC idea in the wiki and any linked PRDs. However, please note that if you copy content directly from any source (even if it is an Oppia doc), you must cite and link to the original source. Also, remember from our selection criteria that when we review proposals, one of the things we look for is evidence that the applicant understands the project and existing codebase well. Strong proposals will therefore contain details that are original (e.g. that are not copied from the PRD).
      Q: I'm part of team X in Oppia. Can I submit a proposal for a project idea from a different team?
      A: Yes, you can; there are no issues with that. There is a space in the proposal template to list teams at Oppia you've participated in, and we will get feedback from members of those teams about what their experience of collaborating with you has been like.
      Q: What is the total number of contributors that will be accepted?
      A: We generally request slots for as many projects as we think will succeed. However, the Google GSoC admins may impose limits based on how they decide to distribute contributor slots among the different open-source organizations.
      Q: The Google GSoC FAQ mentions that the program is only for new contributors. I have already contributed to Oppia and I have write access. Can I still participate?
      A: The GSoC program is open to students, as well as beginner contributors to open source. If you do not qualify as a student, see this FAQ on the GSoC website for whether you would be considered a beginner.
      Q: Can you be flexible around my other summer commitments?
      A: Probably not. We have not had good experiences offering flexibility in previous years, so this year, Oppia will strictly adhere to the Oppia GSoC timeline. Please refer to the Dates and Deadlines section below, and avoid taking up major commitments alongside GSoC. Experience from previous years suggests that you will be unlikely to successfully balance both.
      Q: I'd love to contribute to open source, but I'm not sure I have enough time during the summer to do a GSoC project. Can I still help out?
      A: Yes, GSoC is probably not the best choice if you don't have enough time during the summer, since it requires focused commitment. However, you can still start contributing to Oppia by following the instructions in the contributors' guide (Oppia Web, Oppia Android).
      Dates and Deadlines
      Noteworthy dates for 2025 (see also the Official GSoC Timeline):
      Jan 27 - Feb 11: Mentoring organizations apply
      Feb 27: Mentoring organizations are announced
      Mar 1: GSoC Q&A session with Oppia
      Mar 24 - Apr 8: GSoC contributor application period
      May 8: Accepted GSoC contributors are announced
      May 8 - June 1: Community bonding ("greenlight") period
      May 10 at 3 pm UTC: Briefing for accepted GSoC contributors (mandatory)
      June 2 - Jul 18: Milestone 1 work period for GSoC
      Jul 4: Milestone 1 work due for internal evaluation
      Jul 5 - Jul 11: Testing of the milestone 1 work product
      Jul 12 - Jul 18: Buffer time for Milestone 1 revisions
      Jul 19 - Jul 25: Official GSoC midpoint evaluation
      Jul 26 - Sept 12: Milestone 2 work period for GSoC
      Aug 27: Milestone 2 work due for internal evaluation
      Aug 28 - Sept 3: Testing of the milestone 2 work product
      Sept 4 - Sept 10: Buffer time for Phase 2 revisions
      Sept 15 - Sept 22: Official GSoC mentor evaluation due
      Sep 23: GSoC period at Oppia officially ends
      Note! For Oppia's participation in GSoC 2025, the coding period dates are strict, and we will not be offering extensions. Please ensure that you have sufficient time during the summer to work on your projects.
      Types of work related to Oppia projects
      The Oppia team is committed to making GSoC an enriching educational experience for contributors. In general, our goal for GSoC is for contributors to have a really meaningful experience, and to do something worthwhile over the summer that they can look back on with pride.
      In order to ensure a well-rounded engineering experience, GSoC contributors will have the opportunity to do some or all of the following, depending on their project:
      Write design documents for technical projects
      Read and understand parts of the codebase related to their project
      Receive code reviews for all code they write for their project
      Develop user-focused, responsive and internationalized UIs.
      Write automated tests for their projects
      Meet regularly with other contributors on their Oppia development team (LaCE, Contributor Dashboard, Dev Workflow, Android)
      Meet 1:1 with their mentors regularly to get developmental feedback
      Give presentations and demos of their projects
      Get personalized feedback on their project from the product team or a technical lead
      Learn how to do code reviews
      We've also asked our previous GSoC contributors what specific things they learned during their GSoC projects. Here are their collated answers:
      Technical ability and domain knowledge
      Writing maintainable and readable code.
      Building an entirely new feature in a scalable way.
      Writing better automated tests.
      More confidence working with Angular.
      Making better design, UI and technical decisions.
      Getting a better understanding of overall full-stack development.
      Enhanced ability to debug and resolve technical issues.
      Technical leadership skills
      How to manage my time well, and how to achieve deadlines.
      Improved skills in managing and executing projects.
      How to give, respond to and understand reviews.
      How to effectively convey ideas.
      How to write a good project proposal.
      Becoming a better developer, not only in terms of technical skills, but also in thinking of actual application of the built product and the edge case scenarios that the user might face.
      Communication and personal development
      How to seek help when needed and overcome challenges.
      How to reach out to people, work with them, and help solve each other's problems.
      How to get myself unblocked.
      Putting forward my thoughts more systematically so that others can understand me well.
      Feeling more confident while joining online meetings.
      Contributors have also told us why they continue to stay engaged with the project after GSoC ends:
      Community
      It is really an awesome experience working with some amazing folks from all around the world at Oppia.
      The organisation is active and has a strong community bond.
      The kind of support the complete community provides is extraordinary.
      Giving back
      The main reason to stay connected is the purpose the community serves. Providing education to those who do not have access to it helps me give back to the society.
      It makes me very happy that I'm part of an organization which provides free education and I think the education is the biggest blessing we can give to one to make them stand on their feet.
      I would love to be part of this org by knowing that maybe not much but yes I'm trying to make an impact and my contribution in the educational field. I really want to do this because where I come from there is not much of education.
      Growth / learning:
      I like working in Oppia since it not only helps me improve my coding skills but also helps me grow as an individual.
      Working with Oppia has really helped me grow as a developer and I would really like to stick around to gain even more experience of real world software development.
      I feel my exponential growth while contributing in Oppia and got to learn many new things while getting help from mentors and other Oppia team members.
      The kind of work that Oppia does is really inspiring and there are a lot of opportunities to improve your skills be it be technical skills or leadership skills and most of all the people at Oppia are really fun to work with :)
      GSoC Proposal Template
      When submitting a proposal, please use the provided GSoC 2025 proposal template. We will only consider proposals submitted using this template. Note that there is a length limit: the proposal's technical "HOW" section should not exceed 20 pages at "Roboto 10" font size.
      Note: There's no formal minimum length requirement for your proposal. The quality of what you write is much more important than the amount of text you write, and we encourage you to write shorter proposals that still convey the main aim of the project.
      Important
      The 2025 template differs from the 2024 template. Please make sure that you are using the 2025 one.
      Some important notes:
      Your proposal must be original (see section 2.4 of the Contributor Participation Agreement). During the selection process, proposals that are found to have passed off others' work as their own will automatically be disqualified. If you include any text in your proposal that is copied from the Internet or other sources (even if it is an Oppia doc), you must provide a link or reference back to the source. Note that you must attribute sources even if you paraphrase (i.e. re-write their content in your own words). In cases of doubt, we would encourage you to err on the side of citing your sources (since not doing so may be construed as plagiarism).
      When the necessary criteria for requesting a review are met, add gsoc-2025-mentors@oppia.org as an editor for your proposal doc. (This makes some workflows, like inviting PMs or fixing typos, etc., easier, but if you're concerned about changes to your doc, then you can turn on notifications for edits.) After fixing the sharing settings, make a new post in the correct "proposal reviews" category in GitHub Discussions that is clearly titled with the name of the project that you are requesting a review for, and provide a link to the doc in your post.
      Please use only the above channel for proposal reviews: all proposal-related communication should happen through GitHub Discussions or directly through comments in the proposal doc. Do not send proposals directly to individual GSoC mentors.
      You can also request at most one "tech lead review" for at most one of your proposals during the pre-selection phase. To keep things fair, the tech lead will do only a single pass on your proposal and leave comments, but is not required to follow up on replies to those comments. Since you can only request a tech lead review once (per applicant), we recommend doing so after you have gotten feedback from mentors and completed a full draft of your proposal, but at least a week before the due date. Tech leads will process requests in the order they are received. To request a tech lead review, fill in this Google Form.
      Your final proposal should be self-contained. In particular, to be fair to all applicants, key components of the proposal should not be editable after the deadline. Don't assume that reviewers will follow external links.
      Tips for writing a good project plan
      Here's some advice about proposals and milestone timeline planning that we collated from previous contributors and mentors:
      Choose a project you're interested in! If you have a strong interest in your project, this might make it easier for you to pick up the necessary skills and tackle unforeseen difficulties that may arise during GSoC.
      Familiarize yourself with the technologies for your project and the relevant part of the codebase. Reviewers will want to see that you understand how to integrate your project with the current Oppia structure — don't design in a vacuum.
      Define milestones with enough detail to get a proper ETA. For example, don't just say "write e2e tests", otherwise you risk significantly underestimating the timeline.
      Communicate and present your ideas clearly. Your proposal should show that you have a good understanding of the codebase and the final goal of the project. For example, in a user-facing proposal, don't just make a list of files that need to be changed; you should also show detailed mocks and user flow diagrams that demonstrate a clear understanding of the requirements.
      Limit proposal length. A lengthy proposal is not necessarily better. In fact, adding large amounts of unnecessary detail can sometimes obscure the main points you are trying to get across.
      Pick a project idea that is within your limits to tackle. Make sure that what you're proposing is within your capabilities.
      What should applicants expect from mentors in a proposal review?
      Please write your proposal on the assumption that you "own" your chosen project. From your perspective, the submitted proposal should be proofread and in as good a condition as possible before you ask for a review. Make sure that you have a sufficiently good understanding of the codebase/project so that you can find and fix flaws in the design; reviewers will give you feedback but not do this for you. Note that your proposal doesn't need to be flawless — we expect that you might make mistakes, and reviewers will be happy to guide you on how to improve. Instead, by "as good a condition as possible", we mean that your proposal should demonstrate:
      Your ownership of the project
      The research you have put into writing it
      Your analytical skills
      Your independence in making complex decisions
      Make sure to present solutions and ask for feedback, rather than just asking for solutions. The proposal template contains a "key decisions" section which you can use to present the various options you came up with, analyze their advantages & disadvantages using a comparison table, and explain your proposed choice and the reasoning behind it. Note that this doesn't mean that you must always have multiple ideas to solve a problem, but you should instead always explain how you reached a solution, and why is it the best one from the end-user's perspective. Think about how you might gather data to validate your conclusions (e.g. by finding support in the peer-reviewed literature, or by showing your ideas to potential users in the target audience and asking for feedback, etc.).
      Reviewers' suggestions are suggestions, not mandates. We do not expect you to always agree with your reviewers! This means that, as the proposal owner, you are always welcome to decide whether to accept/reject such suggestions. In either case, when accepting/rejecting a suggestion provided by a reviewer, try to explain your reasoning and the research that led to your decision.
      If you're confused about something, try to identify the point of confusion and ask have specific discussions about it, rather than simply agreeing to whatever is proposed. Don't rely on an "appeal to authority" (e.g. "I am doing it this way because reviewer XXX said so") — the rational analysis and thought that underlie the decision are what's important, so make sure that you understand and clearly communicate the reasons behind the decisions you make.
      Note that the process Oppia uses to select GSoC contributors typically includes multiple independent reviewers, most of whom will not have looked at the earlier versions of your submitted proposal. Your initial proposal reviewers may or may not be involved in the final selection process, and it is not a requirement that you need to implement all your reviewer's suggestions/requests in order to be selected. Instead, please consider your reviewer as a friendly advisor who is available to help you and provide guidance, rather than the main future evaluator of your proposal.
      Selection Criteria
      To select contributors for GSoC, we will evaluate candidates based on a set of criteria designed to ensure we select individuals who not only possess the necessary skills but also demonstrate the ability to contribute effectively to the project. The criteria are as follows, listed in order of significance::
      Primary Criterion: Required Skills for the Project - This is the most critical factor in our selection process. A contributor must have the necessary skills for the project. Lack of these skills is a deal-breaker and can lead to immediate rejection of the proposal.
      Secondary Criteria (of equal importance):
      Quality of the Submitted Proposal - This criterion helps us gauge the applicant's understanding of the project requirements. The proposal should align with project goals, and be clear, thorough, and feasible.
      Prior Experience Working with the Contributor - We consider our previous interactions with the contributor, focusing on their reliability, communication skills, independence, initiative, responsiveness, and willingness to assist others. This assessment allows us to predict how well the contributor will integrate with the Oppia developer community and contribute to the success of the project.
      We believe that strong performance in these dimensions is likely to correlate well with the contributor having an enjoyable, fulfilling and productive experience over the summer, and successfully completing the GSoC program.
      For the proposal, we generally look for a clear indication that the contributor has a good, clear understanding of the project, and has broken it down sufficiently well, in a way that makes it very likely to succeed. Some indicators that could help with this include:
      Clear, unambiguous communication. (This is important; your proposal will be read by many mentors!)
      A clear analysis of (and good design decisions that build on top of) the original project idea, with a strong focus on creating a simple, intuitive experience for end users.
      A proposed solution approach which is sufficiently concrete and which demonstrates that the applicant has a good understanding of both the scope of the problem and the existing codebase.
      A description, if applicable, of how the applicant plans to mitigate risks that could potentially derail the project.
      A concrete, specific description of each milestone, together with a breakdown of the necessary work.
      Communication
      If you have questions pertaining to "how to get started with Oppia" or any other queries regarding GSoC at Oppia, please ask them on GitHub Discussions. Please be specific when asking questions; this makes it easier for us to help you. Also, please make sure to read the relevant "getting started" wiki page (Web, Android) first, since the answer to your question might already exist there!
      To receive important announcements and updates about GSoC at Oppia, please subscribe to the Oppia GSoC Announce mailing list, and the Developer Announcements category on GitHub Discussions.
      Oppia's Project Ideas List
      Note: If you're coming to this section from an external link, please make sure to scroll up and read this entire wiki page carefully, not just this section. There's a lot of useful information on the rest of the page, including a FAQ and a section describing selection criteria. Thanks!
      The following is a list of Oppia's 2025 GSoC project ideas. You are welcome to choose among these ideas, or propose your own! However, if you're planning to propose something original, it's essential to engage with the Oppia community beforehand in order to get feedback and guidance to improve the proposal. We'd also recommend taking a look at Oppia's mission and seeing if there is a natural way to tie your idea to the Oppia project's goals, otherwise it might not be a good fit at this time.
      Please note that the list of project ideas below is not set in stone: more projects may be added later, and some project descriptions may also change a bit, so check back regularly. In addition, the mentor assignments listed below are provisional, and may change depending on which proposals are eventually accepted. (If you want to see what changes have been made to this page since you last viewed it, you can use the History tab.)
      If you need clarification on any of these ideas, feel free to open a thread in GitHub Discussions following the process in this guide.
      Learner and Creator Experience (LaCE) team
      1.1. Clean up the structure for study guides and worked examples
      1.2. Fix the most common server errors
      1.3. Lesson player redesign
      Contributor Dashboard team
      2.1. Show AI-powered translation suggestions to translation submitters
      Developer Workflow team
      3.1. Acceptance tests
      3.2. Consolidate entity migration jobs
      3.3. Standardize and validate domain objects and storage models
      Android team
      4.1. Flashbacks
      4.2. Platform parameters dashboard
      4.3. Android lint infrastructure and fixes
      Learner and Creator Experience (LaCE) team
      1.1. Clean up the structure for study guides and worked examples
      Project Description:
      Oppia topics include a list of skills to teach. These skills are grouped into subtopics (like 'Basic Concepts of Division'), each with its own study guide (or 'subtopic page' in the backend). Currently, subtopic pages are implemented as a single large rich-text field, which makes them hard to translate and limits how we can display them. We'd like to split this rich-text field into multiple heading/content parts. In the above example, the updated subtopic page would have two sections ("What is division?" and "Parts of a division equation"), and the subtopic page editor would have a list of sections, each with its own "heading" plain-text field and "content" rich-text field.
      Additionally, both skill explanations and subtopic pages should be able to include worked examples. Previously, worked examples were implemented as an explicit subfield of the SkillContents object that is contained in the Skill model. We would like to implement worked examples as a general rich-text component instead, since this allows them to be used in contexts beyond skills as well.
      The aim of this project is therefore to clean up the incorrect modelling described above and make the necessary updates to the viewing and editing flows for subtopic pages, worked examples, and their associated translations/voiceovers.
      Links to PRD and mocks:
      Subtopic pages (study guides): Figma mocks and design thread
      Worked examples: Figma mocks, design thread, and reference PRD. Note that some parts of the PRD are excluded -- see the "not in scope" section below.
      Tracking issues: #18305, #19851
      Not in scope:
      Implementing new rich-text components other than "Worked Example".
      Implementing the "Words to know!" and "Otter Tip!" sections in the revision card Figma mocks.
      Enabling the use of worked examples in hints and feedback. (We will do this later once we have tried out the functionality in subtopic pages and skill descriptions.)
      Implementing the more detailed validation described in the PRD (for limiting the number of worked examples to 2 if there are no images, or limiting them to 3 if there are images). For now, we will go with a general limit of 2.
      Size: Large (~350 hours)
      Difficulty: Moderate/Hard
      Potential mentors: @kevintab95
      Product/technical clarifiers: @seanlip (product), @kevintab95 (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-1-lace-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Debug and fix CI failures/flakes.
      Write Python code with unit tests.
      Write TS + Angular code with unit tests.
      Write or modify e2e/acceptance tests.
      Write or modify Beam jobs, with tests.
      Related issues:
      RTE-related issues
      Validation (backend + frontend)
      Translation-related issues
      Suggested Milestones:
      Milestone 1: In SubtopicPageContents, carry out migrations to do the following:
      Convert the existing subtitled_html field into the new structure (a sections "repeated JsonProperty" field consisting of {heading: SubtitledUnicode, content: SubtitledHtml} dicts).
      Introduce a unique content ID for each translatable field, similar to explorations.
      Move the written translations and voiceovers for subtopic pages in EntityTranslationsModel and EntityVoiceoversModel, instead of within the SubtopicPage object (similar to explorations).
      Update the subtopic page editor UI to accommodate the new structure, and the learner UI to match the Figma mocks. Then, deprecate the old subtitled_html field.
      Milestone 2: Verify that the existing worked_examples fields are empty in production, then carry out a schema migration to safely deprecate the worked_examples field in the skill_contents part of the SkillModel, and remove it from the skill editor UI as well.
      Implement a new 'Worked Example' RTE component that appears only in the skill explanation and subtopic page RTEs, and validate that skill explanations cannot have more than 2 such components. Add acceptance tests for the learner and creator flows to verify that they align with these mocks. Ensure that this component is translatable in the contributor dashboard, and update the translation guide to include it.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points
      1.2. Fix the most common server errors
      Project Description:
      We currently see a number of unaddressed server errors on hosted instances of Oppia. Many server errors relate to user-facing bugs, and are a good clue that something is problematic in the application. Furthermore, frequently occurring errors result in the server logs getting noisy, to the point that they are no longer treated as alerts because the volume of errors is too high.
      The aim of this project is to address the 15 most common server errors, and improve/clarify the logging infrastructure to make server errors easier to debug in general. This would also make it easier to catch new issues during test deployments, and reduce the overall error rate of the app. "Addressing a server error" entails the following:
      Find a set of setup steps and actions that reliably reproduce the error on a local machine (see this tutorial). If more insight is needed, it is also fine to add some logging and do another deployment to get more information.
      Identify the root cause of the error.
      Confirm the expected behaviour with the product/tech leads, if needed.
      Fix the error and add tests (which could be frontend, backend, or full-stack) to ensure that the error does not happen again. Some of the other steps listed in this wiki page might also be of interest. Note that some errors may be due to data issues, in which case a migration job or direct editing might be required, as well as stricter typing/validation to ensure that the issue doesn't reoccur.
      Tracking issues:
      #21807, #21841 and #21872 are quality-of-life improvements to help make server errors easier to debug.
      See this link for a list of the most common server errors.
      Note that the project will only cover a subset of the above, per the milestones described below. This will be the subject of a discussion between the contributor, mentor and org admins at the start of CBP.
      Size: Medium (~175 hours)
      Difficulty: Moderate
      Potential mentors: @Nik-09
      Product/technical clarifiers: @kevintab95 (product), @Nik-09 (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-1-lace-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Write Python code with unit tests.
      Write TS + Angular code with unit tests.
      Write or modify e2e/acceptance tests.
      Write or modify Beam jobs, with tests. (This is because you might need to write audit jobs for debugging certain errors.)
      Figure out repro steps based on info from server logs.
      Related issues:
      Consider taking up issues like #21807, #21841 and/or #21872 to make errors easier to reproduce / debug.
      You might also want to try some issues from this list to see whether this project is a good fit. In any issues you attempt, try to demonstrate your ability to (a) reproduce server errors deterministically, (b) write a debugging doc to narrow down the source of an error if you can’t pinpoint it in one go, (c) find the clear root cause of an error, and (d) prevent the error from happening in the future.
      If you like, you can also suggest other improvements to the logging infrastructure that would make it easier to fix "server error" issues. (It is fine to file issues for these improvements and get assigned to them in the usual way. However, you should have tried to tackle at least one server error with a debugging doc, and the improvements you suggest should help address the problems you ran into while trying to figure out what caused the error.)
      Suggested Milestones:
      Milestone 1: Fix the 7 most common server errors, and improve the logging for server errors as needed.
      Milestone 2: Fix the 8 next-most common server errors.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points
      1.3. Lesson player redesign
      Project Description:
      The aim of this project is to redesign Oppia's existing lesson player according to these mocks. The goals of the redesign are to make the lesson player intuitive to navigate, easy to add features to in the future, and more engaging for younger audiences. The new lesson player should work well on mobile, desktop and tablet devices, as well as in RTL and LTR languages. (Note that some parts of the mocks are out of scope -- see the "Not in scope" section below.)
      The new functionality should be developed behind the /lesson URL (which should, for now, redirect to the same backend handlers as /explore), and be gated behind a feature flag. Once the lesson player is ready to launch, all /explore URLs should be redirected to /lesson instead, and the new lesson player should be used for all lessons.
      Relevant links: Mini-PRD and mocks
      Tracking issues: #19217
      Not in scope:
      Implementing the speed adjuster in the voiceover toolbar
      Implementing the "Get Help" control in the sidebar and the tutorials within it
      Size: Large (~350 hours)
      Difficulty: Hard
      Potential mentors: @amyyeung17
      Product/technical clarifiers: @seanlip (product), @amyyeung17 (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-1-lace-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Debug and fix CI failures/flakes.
      Write Python code with unit tests.
      Write TS + Angular code with unit tests.
      Write or modify e2e/acceptance tests.
      Related issues:
      Any non-backlog issues in the "Lesson Player CUJs" section of the LaCE project board (try to choose ones that relate specifically to the exploration player interface). Also, see the guidance in the last part of the "What we're looking for in proposals" section below.
      Suggested Milestones:
      Milestone 1: Move all non-UI-specific logic in the exploration player page to services, so that they can be used in both the existing and new exploration players. Then, build the following parts of the new exploration player page at the /lesson URL:
      The overall layout (sub-navbar, main player area, sidebar, footer, audio bar). Only the back-and-forth navigation and "Continue" buttons in the footer need to work at this stage; the rest can be implemented in Milestone 2.
      The main "conversation flow" UI (including all interactions).
      The "correct answer" pop-up and confetti.
      By the end of this milestone, it should be possible to play any Oppia exploration via the /lesson/{{exploration_id}} URL (if the feature flag is turned on), submit and view wrong answers, and navigate back-and-forth through the lesson. Also, the exploration editor preview tab, practice questions page and diagnostic test pages (which use components of the lesson player) should show the new UI if the flag is turned on, and the old UI if it is not. Finally, if the flag is turned on, the /explore URL should redirect to the corresponding /lesson page.
      Milestone 2: Transfer the remaining UI components to the new layout, updating or adding new acceptance tests as needed to verify their behaviour:
      Hints, solutions and concept cards
      The voiceover audio player
      The share, feedback, report and "exit lesson" buttons
      The progress-saving and checkpoints flow
      The end-of-lesson next steps (rate lesson, go to new lesson, practice, etc.)
      Flip the launch flag, and, once the new player is serving in production, remove the code for the old lesson player.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points
      Contributor Dashboard team
      2.1. Show AI-powered translation suggestions to translation submitters
      Project Description:
      This project involves showing auto-generated suggestions in the Contributor Dashboard translation submission modal, so that translation submitters can edit and submit those translations, rather than needing to generate completely new ones from scratch each time. These suggestions would arise from autogenerated translations from an AI-powered translation service.
      The project involves implementing a system for updating EntityTranslationsModel to associate each (content_id, language) pair with both a "manual" and "auto" translation (similar to VoiceoverType in feconf.py for voiceovers). The manual translation should only be populated once a translation is approved by a human reviewer (possibly after edits); this translation is shown to the learner when playing lessons. On the other hand, automatic translations will only be shown as suggestions to translation submitters via the contributor dashboard. To understand the effectiveness of the AI suggestions, the contributor admin dashboard will also display information about how many times the AI suggestions were used as-is, without any edits.
      There should also be a button on the Admin page that can bulk-generate auto-translations via a Beam job. This job should be run to populate the initial auto-translations once the pipeline is ready. Subsequently, any additions/edits to a curated entity (lesson, topic, skill, etc.) should trigger an auto-translation of the added/edited content, and publishing a curated entity should trigger an auto-translation of all strings in the entity. In other words, the auto-translations should always be up-to-date with the English strings in the current version of the entity.
      Link to PRD: Language Management and Lesson Auto-Translation PRD (a bit out of date)
      Tracking issues: #16164 (part), #19681
      Not in scope:
      Configuring the list of prioritized languages for translation
      Auto-generation of voiceovers (in any language)
      Enabling translations for concept cards, review cards, or practice questions
      Showing auto-generated translations in the learner view (see https://github.com/oppia/oppia/issues/16164 for more information).
      Size: Large (~350 hours)
      Difficulty: Hard
      Potential mentors: @chris7716
      Product/technical clarifiers: @seanlip (product), @chris7716 (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-2-contributor-dashboard-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Debug and fix CI failures/flakes.
      Write Python code with unit tests.
      Write TS + Angular code with unit tests.
      Write or modify e2e/acceptance tests.
      Write or modify Beam jobs, with tests.
      Related issues:
      Issues related to translation submitters are good ones to tackle: https://github.com/orgs/oppia/projects/18/views/4?sliceBy%5Bvalue%5D=Translation+submitters
      Suggested Milestones:
      Milestone 1: The computer-aided translation (CAT) backend is completed, and can process any rich-text field properly (including components like images, skill links, etc.), including validating that the autotranslated string has the same number and type of rich-text components as the original string. Storage models are updated to store these autogenerated translations, and the relevant statistics models and regeneration jobs are also updated to include the number of times a translation suggestion exactly matches the auto-translation. The wiki pages are also updated to explain how to add new languages and translation providers to the system.
      At the end of the milestone, admins should be able to configure the CAT service provider for each language, and run a job to generate auto-translations for any untranslated texts for curated lessons. (They can select 'all entities', 'all entities of a specific type', or a specific entity; and they can select 'all prioritized languages' or a particular language.)
      Milestone 2: When a curated entity (lesson, topic, skill, etc.) is edited, this should trigger an auto-translation of the added/edited content. When a curated entity is published, this should trigger a full auto-translation of all strings that don't have auto-translations yet. These auto-generated translations are then shown to contributors in the contributor dashboard UI, together with an annotation explaining their origin.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points
      Developer Workflow Team
      3.1. Acceptance tests
      Project Description:
      In order to streamline releases, we are planning to ensure that all critical user journeys (CUJs) on the Oppia web application are covered by acceptance tests. This is important because it will provide assurance that, on the merge of every PR, these critical user journeys still function correctly, which means that no major breakages will result if the develop branch gets deployed to production. Additionally, having a complete set of acceptance tests that are organized by CUJ makes it easier to audit whether or not a particular CUJ has been included, and it also helps developers add tests for new CUJs while still keeping the tests well-organized.
      This project includes:
      Writing acceptance tests for the as-yet-uncovered CUJs in a way that keeps the tests organized and maintainable. This might also include small updates to the acceptance test framework, e.g. extracting utility functions to enable code reuse or providing relevant functionality for a group of tests.
      Tightening all page utility functions to have pre/post checks (in the form of "wait" statements) and proper error messaging, so that it is easier to debug flakes. The pre-check wait ensures that the conditions are good for performing the action, and the post-check wait ensures that the action has fully completed.
      Deleting e2e tests whose functionality has been fully replaced by the acceptance tests.
      Relevant documents:
      Current CUJ tracker: Critical User Journeys v2
      Spreadsheet that details most of the tests that need to be written: Web QA Test Matrix (arranged by user type)
      Tracking issues: #21646
      Not in scope:
      Configuring the list of prioritized languages for translation
      Auto-generation of voiceovers (in any language)
      Enabling translations for concept cards, review cards, or practice questions
      Showing auto-generated translations in the learner view (see https://github.com/oppia/oppia/issues/16164 for more information).
      Size: Large (~350 hours)
      Difficulty: Easy / Moderate
      Potential mentors: @imchristie
      Product/technical clarifiers: @seanlip (product), @imchristie (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-3-dev-workflow-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Debug and fix CI failures/flakes.
      Write TS + Angular code with unit tests.
      Write or modify e2e/acceptance tests.
      Related issues:
      Acceptance test infrastructure: https://github.com/orgs/oppia/projects/8/views/11?sliceBy%5Bvalue%5D=Acceptance+Tests
      Suggested Milestones:
      Milestone 1: Tighten all existing page utility functions in core/tests/puppeteer-acceptance-tests to have appropriate pre/post checks. Complete all acceptance tests for exploration creators, logged-out users, and logged-in users (as specified in #21646), and ensure that they run on all PRs by adding them to the "acceptance test" GitHub workflow. Remove any existing webdriverio tests whose functionality is fully covered by the new acceptance tests.
      Milestone 2: Complete all other remaining acceptance tests (as specified in #21646), and ensure that they run on all PRs by adding them to the "acceptance test" GitHub workflow. Remove any existing webdriverio tests whose functionality is fully covered by the new acceptance tests. If any webdriverio tests remain after this step, translate them into CUJs and work with the QA team to make them part of the CUJ document, then implement the corresponding acceptance tests. Finally, remove the old webdriverio and e2e test framework completely.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points
      3.2. Consolidate entity migration jobs
      Project Description:
      The Oppia codebase includes several different versioned entities which store learning material: explorations, skills, stories, subtopic pages, questions, topics, and collections. The infrastructure to maintain each of these versioned entities has been developed separately, and is a bit patchy (for example, migrations of old snapshots have not been implemented for some of the entities). This is making it difficult to remove some of the old version upgrade functions in the codebase which are no longer needed.
      The aim of this project is to standardize these migration jobs so that there is a single, standard way to migrate and upgrade versioned models. This will (a) ensure that all the versioned models can be easily updated on a periodic basis, (b) let us delete the code for upgrading from old versions once all the entities of that version have been upgraded, and (c) simplify the remaining version upgrade code.
      Tracking issues: #22023
      Size: Medium (~175 hours)
      Difficulty: Moderate
      Potential mentors: @U8NWXD
      Product/technical clarifiers: @seanlip (product), @U8NWXD (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-3-dev-workflow-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Write Python code with unit tests.
      Write or modify Beam jobs, with tests.
      Additionally, strong technical design skills and a good sense of code architecture are helpful.
      Related issues:
      #16556 is a good issue to look into, since it will help you become familiar with the migration job infrastructure.
      Issues related to Beam jobs are also good ones to look at.
      Suggested Milestones:
      Milestone 1: Create a BaseVersionedDomainObject which specifies object member mappings to storage model properties in a declarative way, and also specifies the "schema version field" corresponding to each JsonProperty-related field. Add tests to ensure that all JsonProperties are accounted for. Then, replace all existing domain objects for versioned models with subclasses of BaseVersionedDomainObject. Additionally, ensure that all functions that convert storage models to domain objects also migrate domain objects to the latest schema version.
      Milestone 2: Create BaseMigrateVersionedModelJob and BaseMigrateVersionedModelSnapshotsJob classes with the core logic for upgrading models and snapshots to the latest schema versions, respectively. Use these to build both job and audit job subclasses for all versioned models (explorations, skills, stories, subtopic pages, questions, topics, collections) with proper logging and error reporting (e.g. if a migration fails, the model that could not be migrated should be logged for debugging). Test these jobs on production data to ensure that they work correctly, and fix any issues that arise. Finally, run all the jobs in all our production environments, so that all the models and snapshots on the server are upgraded to the latest schema versions, then remove the old jobs and the old conversion functions for all 7 versioned models, as well as the methods they call (similar to what was done in https://github.com/oppia/oppia/pull/12256/files).
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points
      3.3. Standardize and validate domain objects and storage models
      Project Description:
      Oppia's production data is organized using NDB storage models, which in simple terms can be thought of as objects having different properties. For instance, data related to a user can be stored in a UserSettingsModel with properties like username, user ID, etc.
      Different inter-model relationships exist as well, corresponding to relationships between prod data. For instance, a story includes a list of explorations. So, a StoryModel might include the IDs of all the ExplorationModels it is composed of.
      For proper functioning of the Oppia application, it is important to ensure that all the models are internally consistent and that the relationships between models are valid. The aim of this project is therefore to ensure that all production data is valid by:
      Ensuring that domain objects exist for all prod models, and that they have full validate() functions.
      Implementing Beam jobs that audit production data and flag any errors. These jobs should validate the model properties as well as inter-model relationships. After these jobs are run, any errors should be investigated, and checks should be implemented to ensure that such problems don’t reoccur in the future with new data.
      Tracking issues:
      #21970
      #21905
      #21869
      Not in scope: Migrating existing datastore data to address the validation issues found in the first milestone.
      Size: Large (~350 hours)
      Difficulty: Moderate
      Potential mentors: @ankita240796
      Product/technical clarifiers: @seanlip (product), @ankita240796 (technical)
      Discussion forum: https://github.com/oppia/oppia/discussions/categories/gsoc-q-a-3-dev-workflow-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Write Python code with unit tests.
      Write or modify Beam jobs, with tests.
      Related issues:
      https://github.com/oppia/oppia/issues/21970
      https://github.com/oppia/oppia/issues/21905
      https://github.com/oppia/oppia/issues/21869
      The first checkbox item from any of the following:
      https://github.com/oppia/oppia/issues/14968
      https://github.com/oppia/oppia/issues/14967
      https://github.com/oppia/oppia/issues/14969
      https://github.com/oppia/oppia/issues/14971
      https://github.com/oppia/oppia/issues/14972
      Suggested Milestones:
      Milestone 1: Domain objects exist for all storage models, and include validate() methods that fully validate the domain object's internal consistency and correctness. The usage of storage models in the domain layer is restricted to the interfaces for getting and saving datastore models, and they are not passed further around the codebase. 50% of the validation jobs for the storage models are implemented and run successfully. For each validation error found, an issue is filed with clear action steps for (a) stopping the error from happening for new data, and (b) migrating old data to fix the error.
      Milestone 2: All remaining validation jobs for the storage models are implemented and run successfully, and issues are filed for all validation errors as described in Milestone 1. All root causes of the validation issues found in Milestones 1 and 2 are identified and fixed, so that the error no longer happens for new data. (This corresponds to part (a) of each issue in Milestone 1.)
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points
      Android team
      4.1. Flashbacks
      Project Description:
      When learners make a mistake on a concept they have previously demonstrated in an earlier part of a lesson, it often makes sense to redirect them back to an earlier card to try and reinforce earlier concepts that the learner may have not fully understood. However, in the current app implementation, learners subsequently need to re-answer all the cards between the earlier state and the state they had reached, which is frustrating.
      This project aims to provide a new feature called 'flashbacks' which helps to bring the benefits of earlier redirection (i.e. reviewing an earlier concept that directly ties to the learner's likely misconception) without the frustrating experience of having to redo the all the questions up to returning back to the question that originally caused the learner to become stuck.
      Additionally, this project also includes improving the general look-and-feel of submitted answers for both multiple choice and item selection interactions as these both currently rely on HTML generation rather than having a cleaner, natively rendered experience. This change will also allow them to be displayed properly in the 'flashback' experience.
      Relevant links: Tracking issue with mocks links (https://github.com/oppia/design-team/issues/179) and PRD (incomplete). Please note the following regarding these mocks:
      The mocks don't include explicit changes for multiple choice and item selection.
      The mocks don't quite represent the correct 'inline' experience that needs to be introduced for the 'Learn Again' button (which should be part of the answer & response section of the incorrect answer that is prompting for a revisit).
      Only the mocks with the orange toolbars are actually correct and need to be implemented (except for the otter, and the return button should be part of the flow rather than overlaid).
      Tracking issues: #5732
      Size: Medium (~175 hours)
      Difficulty: Moderate
      Potential mentors: @adhiamboperes
      Product/technical clarifiers: @seanlip (product), @BenHenning (technical)
      Discussion forum: https://github.com/oppia/oppia-android/discussions/categories/gsoc-q-a-4-android-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Build the app and install it on a local device or emulator. Then verify that you can (a) build a non-test library target locally, (b) run a unit test locally, and (c) play through the app locally.
      Write new Kotlin code with unit tests.
      Change Android UIs, write tests for them, and manually verify that they work.
      Related issues:
      Key issue: #5572. This tracks introducing a short-term solution of the broader problem this GSoC project aims to solve.
      Issues related to portions of the codebase that will be affected by this project:
      #5728
      #5568
      #3646
      #2973
      #1273
      Suggested Milestones:
      Milestone 1:
      The new flashback dialog is implemented and hooked up to the existing soft redirection button. (The in-line flow does not need to work at this stage.)
      When a learner is redirected, the Flashback Dialog should appear. Upon confirmation, the learner is taken back to the most recent instance of the card without adding a duplicate to the stack. This ensures a smoother learning experience without unnecessary reattempts of intermediate questions.
      Milestone 2:
      Integrate the Flashback Dialog into the learner flow with an in-line view, where the "Learn Again" button is directly attached to the incorrect answer that triggered the flashback.
      Implement the updated designs for multiple choice and item selection interactions submitted answers to ensure a cleaner, natively rendered experience.
      Additionally, add relevant UI tests to verify the new functionality.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points
      4.2. Platform parameters dashboard
      Project Description:
      Feature flags are a special type of configurable platform parameter which allows the team to stage features behind remotely configurable flags until they're ready to be launched. This allows features to be developed across multiple releases without users seeing part of the feature (or app stability issues when the feature is enabled), ensuring the team releases high-quality features and doesn't hurt the overall quality and performance of the app. Broadly, platform parameters allow the team to configure the overall app (which can be useful both for feature flags, as described above, and safety 'knobs' such as controlling rate limits to remote APIs to help reduce the chance of server outages).
      This project entails introducing a developer-only UI (as part of the developer options section of the app) which displays all platform parameters and feature flags in the app, their current enabled/disabled status (for feature flags) or values (for platform parameters), and their sync status (i.e. whether they're being synced from the server or using a local developer default). It also allows an explicit manual override to force the feature on or off, or to override the platform parameter's value.
      Relevant links:
      Sample mocks for the new UI
      #5725: a reimplementation of the platform parameter and feature flag system
      #5565: introduction of cleaner support for overriding platform parameters and feature flags in tests
      Tracking issues: #5345
      Size: Medium (~175 hours)
      Difficulty: Moderate
      Potential mentors: @Rd4dev
      Product/technical clarifiers: @BenHenning (product + technical)
      Discussion forum: https://github.com/oppia/oppia-android/discussions/categories/gsoc-q-a-4-android-projects
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Build the app and install it on a local device or emulator. Then verify that you can (a) build a non-test library target locally, (b) run a unit test locally, and (c) play through the app locally.
      Write new Kotlin code with unit tests.
      Change Android UIs, write tests for them, and manually verify that they work.
      Related issues:
      Issues related to portions of the codebase that will be affected by this project:
      #46 - Note that this is a good issue to build familiarity with the developer workflow menu workings, and has smaller chunks that can be done in isolation.
      #5600 - Note that this is a specific part of #46 above.
      #5636
      #3506
      Suggested Milestones:
      Milestone 1: Key deliverables:
      Display a list of platform parameters and feature flags from a Developer Options menu, along with their current values and sync statuses.
      Set up initial tests to demonstrate that the UI displays correctly.
      The new UI correctly shows all platform parameters and feature flags, and their correct values and sync statuses.
      Milestone 2: Key deliverables:
      Support for overwriting and resetting both feature flags and platform parameters back to their default values, including force-restarting the app upon navigating away from the menu (so that the changes can take effect).
      Updated UI tests for the new functionality.
      The new screen fully supports overriding various platform parameters and feature flag values.
      Support for force downloading flags from Oppia web (i.e. by calling PlatformParameterController.downloadRemoteParameters() and asking for an app restart).
      Pending overrides and the indicator for downloading state both should 'survive' device rotations (that is, rotating the device should not cause any temporary state in the UI to be lost).
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points
      4.3. Android lint infrastructure and fixes
      Project Description:
      The Android build ecosystem supports a linting tool which catches a variety of Android-specific problems (beyond those that can be caught by more general-purpose linters like ktlint). Historically a Gradle feature, Android Lint is not yet directly supported in the Bazel world (though there are some alternatives available). This project involves:
      Introducing an Oppia Android script that runs Android lint directly.
      Supporting the same exemption override support (via XML) but using a textproto interface for parity with the allow-listing and deny-listing configurations used in other Oppia Android scripts.
      Pre-populating the exemption list with existing known failures.
      Adding wiki documentation to explain how to use the new script.
      Filing and/or updating issues with findings such that all remaining Android lint issues are properly tracked in the repository.
      Updating CI to run the Android lint script.
      Fixing the following categories of lint issues:
      All categories classified as 'errors' by the tool.
      All of the following 'warning' categories:
      OldTargetApi
      UnusedAttribute
      Typos
      StringFormatCount
      ObsoleteSdkInt
      UnusedResources
      UselessLeaf
      UselessParent
      UnusedIds
      DuplicateStrings
      SelectableText
      LabelFor
      RtlSymmetry
      UnknownNullness
      Tracking issues: #5734
      Size: Large (~350 hours)
      Difficulty: Hard
      Potential mentors: @BenHenning
      Product/technical clarifiers: @BenHenning (product + technical)
      Required knowledge/skills:
      Figure out the root cause of an issue and communicate it well using a debugging doc.
      Build the app and install it on a local device or emulator. Then verify that you can (a) build a non-test library target locally, (b) run a unit test locally, and (c) play through the app locally.
      Write new Kotlin code with unit tests.
      Related issues:
      Issues related to portions of the codebase that will be affected by this project:
      Most issues under the 'priority' section of the CLaM team board are likely to help build familiarity with broad parts of the codebase which will help with addressing lint issues.
      Adding tests for scripts will help build familiarity with the scripting work: #4971. The stats script is especially relevant, too, as it is built to wrap utilities normally used via the command line (not unlike Android lint), including AAPT and apkanalyzer.
      #5169 - currently tracked lint categories (note that these aren't all possible categories that can and will be found by the script).
      Suggested Milestones:
      Milestone 1: Key deliverables:
      Introduce a new script that can run Android lint checks with support for a local textproto file that can override specific failures to allow them to pass.
      Check in a populated exemption list with all known exemptions.
      Introduce a new wiki page explaining how to use the script and update the exemption list.
      Introduce CI support for the new script so that it runs for every change to develop and for all PRs.
      Milestone 2: Key deliverables:
      Fix all of the error categories of lint issues, plus the warning categories mentioned in the project description.
      Ensure all exemptions that aren't fixed as part of this project have corresponding tracking issues filed and spec'd with enough context for contributors to work on them.
      Org-admin/tech-lead commentary/advice
      What we are looking for in proposals
      Technical hints / guidance
      Suggested PM demo points
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/oppia-foundation/
    idea_list_url: https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#oppias-project-ideas-list


  - organization_id: 119
    organization_name: Organic Maps
    no_of_ideas:
    ideas_content: |
      Program
      Participating
      Ideas
      Bookmarks Backup to Google Drive on Android
      Bookmarks Backup to NextCloud on Android
      Opening Hours Parser Revamp
      HUD (Heads-Up Display) Mode
      CarPlay Improvements
      Photos from Wikidata
      OpenStreetMap Editor Improvements
      Program
      Organic Maps is excited to apply for the Google Summer of Code (GSoC) 2025, marking its fourth participation in the program. GSoC is a global initiative by Google that connects open-source organizations with contributors—primarily students and early-career developers—who work on real-world software projects under the guidance of experienced mentors. The program helps foster innovation, improve open-source projects, and provide invaluable learning experiences to participants.
      Over the past three years, Organic Maps has had a highly successful track record with GSoC, welcoming talented contributors who have made significant improvements to the project. These past collaborations have led to meaningful code contributions, feature enhancements, and improvements in usability and performance.
      2022 – Organic Maps GSoC 2022
      2023 – Organic Maps GSoC 2023
      2024 – Organic Maps GSoC 2024
      With three successful programs behind us, we are eager to once again collaborate with aspiring developers in GSoC 2025, continuing to improve Organic Maps while fostering a new generation of open-source contributors. 🚀
      Participating
      To participate in Google Summer of Code (GSoC), first ensure you meet the eligibility criteria, including being at least 18 years old and either enrolled in a degree program or a self-taught developer. Explore the list of project ideas below, choose one that aligns with your interests, and start contributing early by engaging with the community, understanding the codebase, and fixing small issues. Getting involved before the application process increases your chances of being selected and helps you build a strong foundation for your proposal.
      When preparing your proposal, clearly define the project scope, demonstrate your understanding of the problem, outline potential challenges, and provide a structured timeline. Include details about your skills and experience, along with links to your GitHub, CV, or LinkedIn. Submit your application through the GSoC portal before the deadline. If selected, work closely with mentors, provide regular progress updates, and meet evaluation milestones. Successfully completing GSoC not only earns you a stipend but also provides valuable open-source experience and the opportunity to continue contributing beyond the program.
      Ideas
      Explore the GitHub Issues for inspiration. Below is a curated list of ideas from the team, but you are welcome to suggest your own!
      Bookmarks Backup to Google Drive on Android
      Implement a bookmarks backup feature for Google Drive on Android, similar to the iCloud sync available on iOS and following WhatsApp's approach to Google Drive/iCloud backups. This functionality should enable users to securely store their bookmarks in Google Drive and restore them when needed, such as after reinstalling the app or switching to a new device. The implementation should integrate with the Google Drive API, ensuring secure authentication, proper permission management, and seamless multi-device support.
      Scope of Work:
      Develop a feature to allow both automatic and manual backups of bookmarks to Google Drive.
      Ensure effortless restoration when migrating to a new device or reinstalling the app.
      Integrate Google API to handle secure authentication and data access.
      Provide multi-device support to sync and restore bookmarks across different devices.
      Estimate:
      Medium complexity, 175 hours
      Required Skills:
      Android/Java
      Mentors:
      @rtsisyk
      @strump
      References:
      Google Drive Backup Issue
      Bookmarks Backup to NextCloud on Android
      Implement a bookmarks backup feature for Google Drive on Android, similar to the iCloud sync available on iOS and following WhatsApp's approach to Google Drive/iCloud backups. This functionality should allow users to securely store their bookmarks on any NextCloud server and restore them when needed, such as during device migration or after reinstalling the app. The implementation should integrate with the NextCloud API, ensuring secure authentication, proper permission handling, and multi-device support.
      Scope of Work:
      Implement automatic and manual backup of bookmarks to NextCloud.
      Ensure compatibility with any NextCloud server.
      Integrate with the NextCloud API for secure authentication.
      Provide multi-device support to sync and restore bookmarks across different devices.
      Estimate:
      Medium complexity, 175 hours
      Required Skills:
      Android/Java
      Mentors:
      @rtsisyk
      @strump
      References:
      NextCloud Backup Issue
      Opening Hours Parser Revamp
      This project aims to redesign and enhance the "opening hours" parser in Organic Maps, improving accuracy, compatibility, and robustness when interpreting OSM-based business hours. Organic Maps relies on OpenStreetMap (OSM) data to display place information, including operating hours. However, parsing these hours correctly is complex due to varying formats, regional differences, and nuanced rules embedded in OSM data.
      Scope of Work:
      Improve parsing logic to handle different time formats and regional variations.
      Fix known parsing errors and discrepancies.
      Optimize performance and efficiency of the parser.
      Ensure compatibility with the latest OSM opening hours format.
      Implement automated tests to maintain long-term accuracy.
      Estimate:
      Low complexity, 175 hours
      Required Skills:
      C++
      References:
      Opening Hours Issues
      Issue #7974
      HUD (Heads-Up Display) Mode
      Add a HUD (Heads-Up Display) Mode in Organic Maps to enhance navigation while driving. This feature should allow users to project a mirrored version of the navigation screen onto a car’s windshield using a reflective surface, improving visibility and reducing distractions.
      Scope of Work:
      HUD Mode Toggle: Add an option in the navigation settings to enable/disable HUD mode.
      Mirrored Display: Implement a mirrored interface to ensure correct readability when reflected on the windshield.
      High-Contrast UI: Optimize the UI for night and day modes to improve legibility.
      Auto-Dimming: Adjust brightness based on ambient light for better visibility at night.
      Compatibility: Ensure smooth performance across various Android and iOS devices.
      Estimate:
      Medium complexity, 175 hours
      Required Skills:
      Android (Kotlin/Java) and iOS (Swift) development
      UX/UI design for automotive displays
      References:
      HUD Mode Issue
      CarPlay Improvements
      Enhance the CarPlay experience in Organic Maps by addressing user-reported issues and implementing improvements based on feedback. The goal is to optimize usability, responsiveness, and overall integration for a smoother in-car navigation experience.
      Scope of Work:
      Review and prioritize user-reported CarPlay issues.
      Fix known bugs affecting CarPlay functionality.
      Improve UI/UX for better readability and interaction.
      Enhance performance and responsiveness.
      Ensure compatibility with the latest CarPlay updates.
      A standalone CarPlay-enabled device will be provided for testing and development purposes.
      Estimate:
      Medium (175 hours) to High (350 hours) - depending on the specific tasks chosen.
      Required Skills:
      iOS development (Swift, Objective-C, CarPlay framework)
      References:
      CarPlay Issues
      Photos from Wikidata
      Enable the app to dynamically fetch and display photos from Wikidata (Wikipedia) when users open a specific point on the map. This feature will enhance the user experience by providing real-time images of places, improving navigation and discovery.
      Scope of Work:
      Enhance the map generator to include links to Wikidata.
      Fetch photos dynamically from Wikidata when users select a place.
      Implement caching to optimize performance and reduce API requests.
      Create a consistent and intuitive UI/UX for displaying images.
      Estimate:
      High complexity, 350 hours
      Required Skills:
      Android (Kotlin/Java) and/or iOS (Swift) development
      References:
      Wikidata API Documentation
      Wikidata Photos Issue
      OpenStreetMap Editor Improvements
      Organic Maps allows adding or editing POIs on the map even offline, and uploading all edits directly into OpenStreetMap when the connection is available again. The Editor is designed to be easy-to-use, so that anyone (even your granny) can improve the map data for everyone. Improving and expanding the editing tool is crucial for improving the map data as it allow our users to fill gaps and keeping information up to date.
      There are several issues and features related to the Organic Maps Editor. For an overview over the most important ones, take a look at the Collection of Editor issues as well as the Editor UX issues.
      The scope of the project includes both fixing bugs as well as expanding the functionality. Some possible tasks to work on:
      Enable business change when editing a POI  #3491
      Allow adding and editing of more complex OSM types #4523
      Add category icons to the editor category list #9357
      Make it possible to add OSM note to the specific location #266
      Upload recorded tracks to OpenStreetMap to draw missing roads later, or directly draw roads using the recorded data
      List recently used categories when adding objects to openstreetmap #8033
      Scope of Work:
      TBD
      Estimate:
      TBD
      Required Skills:
      C++
      iOS/Android for the UI-related tasks
      References:
      https://www.openstreetmap.org/
      https://wiki.openstreetmap.org/wiki/Editors
      https://github.com/organicmaps/organicmaps/issues?q=is%3Aissue+is%3Aopen+label%3AEditor+
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/organic-maps/
    idea_list_url: https://github.com/organicmaps/organicmaps/wiki/GSoC-2025-ideas


  - organization_id: 120
    organization_name: PAL Robotics
    no_of_ideas:
    ideas_content: |
      2025 Google Summer of Code Proposals
      PAL Robotics is planning to participate in the Google Summer of Code. Below is a tentative list of project ideas, the content and scope is still being discussed and updated.
      Project Ideas
      Payload visualization/metrics
      This project aims to develop a ROS 2-based software tool that allows users to assess and visualize the useful payload a robot can handle, based on its kinematic and dynamic properties. The tool will process the robot’s URDF (Unified Robot Description Format), taking into account actuation constraints, it will provide intuitive visualizations of available payload in a specific configuration or a workspace representation of payload capabilities. Additionally, it will include functionality to extract joint requirements (torque, power, and stiffness) needed to achieve a desired payload, helping roboticists optimize robot design.
      Expected Impact
      This tool will benefit roboticists, engineers, and researchers working on mobile robots, manipulators, and humanoid platforms. It will provide an intuitive way to evaluate, optimize, and redesign robots based on payload requirements, making it easier to select suitable actuators during the design phase.
      Mentors: Luca Marchionni
      Project Size: 175 hours
      Difficulty: Medium
      Skills Required: C++ or Python, ROS 2 basics, experience with URDF, familiarity with RViz plugin development. Rigid Body Dynamics Libraries such as Pinnochio or RBDL
      Outcome:
      A C++ or Python tool to compute and visualize payload capacity in a specific robot joint configuration or inside the robot’s workspace.
      A joint requirement estimation module that suggests required actuator capabilities for achieving a specified payload.
      Integration with ROS 2, URDF, and RViz
      A custom RViz plugin to dynamically display payload constraints and actuator requirements.
      Documentation and example cases for different robotic platforms (TIAGo Pro, TALOS and other available open source robot models).
      ROS 2 Action Mux
      The ROS 2 Action Muxer could be a nice middleware tool designed to manage multiple action servers with predefined priority levels. It provides a client interface to an underlying action server while exposing multiple action servers that dynamically handle goals based on priority. Higher-priority goals preempt lower-priority ones, ensuring efficient resource management in multi-program frameworks.
      In robotic systems and automation frameworks, multiple programs often require access to shared resources. However, not all goals should be treated equally—some, like emergency stop actions, must take precedence over routine operations. A structured priority system is essential to ensure that critical goals are executed without disruption from lower-priority tasks.
      Mentors: Sai Kishor Kothakota
      Project Size: 175 hours
      Difficulty: Medium/Hard
      Skills Required: C++, ROS 2 Basics
      Outcome:
      Develop an action multiplexer that routes requests to a single action server while managing multiple priorities that work for any type of action message types
      Implement a preemption mechanism where high-priority goals interrupt lower-priority ones.
      Provide a user-friendly client API to integrate seamlessly with existing ROS 2 systems.
      Add proper tests for the mechanism of preemption and acceptance of the goals
      Propagate the feedback of the action to the appropriate action server
      RFID simulation plugin for Gazebo Harmonic
      This project aims to develop an RFID simulation plugin for Gazebo Harmonic to enable the testing of RFID-based applications in a virtual environment. This plugin will simulate RFID readers and tags, allowing developers to validate systems involving object identification, inventory management, and localization.
      Gazebo Classic had limited support for RFID sensors and tags, but it handled only very basic detection (binary presence/absence). However, this plugin was never ported to Gazebo Harmonic. With Gazebo Classic reaching its end-of-life in January 2025, there’s a need to re-implement RFID simulation capabilities in modern versions of Gazebo.
      The proposed plugin will simulate RFID systems by modeling physical wave transmission (e.g Friis transmission equation) and incorporating noise factors to achieve realistic behavior. This includes accounting for signal attenuation, interference, and environmental conditions that affect RFID performance.
      During the project, the RFID plugin will be validated making use of PAL open-source simulation packages.
      Mentors: Oscar Martinez
      Project Size: 175 hours
      Difficulty: Medium
      Skills Required: C++, ROS 2 basics, Gazebo simulation and plugin development, RFID
      Outcome:
      Implementation of a physically realistic RFID sensor plugin in Gazebo Harmonic, with configurable power (0-30 dBm), antenna gain and noise parameters.
      Integration with ROS 2 by publishing rfid_msgs/Detection (suggested name) messages with timestamped RSSI and tag metadata.
      Validation Scenarios: 3 demo worlds (static tags, mobile robot, cluttered environment).
      Documentation: API reference and tutorials for plugin configuration.
      ROS 2 Control Ecosystem Visualization
      The ROS 2 Control Ecosystem Visualization project aims to develop a tool, either as an RQT plugin or a web-based interface, to provide an intuitive and real-time representation of the state of a ROS 2 Control ecosystem. This tool will enable users to monitor the flow of data, visualize active controllers, and gain insights into system performance.
      Managing and debugging a ROS 2 Control ecosystem can be challenging due to the complexity of controllers, hardware interfaces, and data streams. Understanding how different components interact in real-time is crucial for ensuring optimal performance and troubleshooting system issues effectively. A dedicated visualization tool can bridge this gap by providing a clear and interactive overview of the control stack.
      Mentors: Sai Kishor Kothakota
      Project Size: 350 Hours
      Difficulty: Medium/Hard
      Skills Required: Qt framework, JavaScript, Proficiency in working with ROS 2 action, service, and topic communication
      Outcome:
      Develop an interactive visualization tool that represents the state of the ROS 2 Control ecosystem.
      Display data flow, including active controllers, hardware states, and command execution.
      Provide an intuitive user interface that supports filtering and customizing displayed information.
      Ensure seamless integration with existing ROS 2 systems and facilitate debugging and performance analysis.
      ROS2 python-launch-lsp-server
      The ROS 2 launchfile system manages the launch of and configuration of one or many processes and can also start other launchfiles. Python launchfiles use launch descriptions which are made of ordered lists of actions and groups of actions. It may also contain substitutions throughout the description, which are used to add some flexibility and configuration to the descriptions in a structured way.
      That high flexibility of this system comes with the downside of being hard to understand what parameters are being used by one project or what executables are being started before runtime. This is where LSP server can become handy for the development of large ros2 packages. It can help verify the proper use of arguments, use go to references when working with other files, pre-processing ros2 substitutions.
      Mentors: Thomas Ung
      Project Size: 175 hours
      Difficulty: Medium
      Skills Required: Rust, ROS 2 Basics, familiarity with LSP, AST
      Outcome:
      Implement go-to-definition for going through ros2launch file
      Implement code completion for Actions and Substitutions
      Implement find references
      Implement Executable argument suggestions
      Implement syntactic error diagnostic
      Documentation on how to integrate with lsp compatible editors
      PlayMotion2 plugin-based system
      PlayMotion2 is a motion control package designed for robots that use ROS 2. It allows you to load a set of pre-recorded motions and execute them on robots. Currently, the framework is limited to working with JointTrajectory controllers, which are commonly used for controlling robotic joints based on pre-defined trajectories.
      The primary goal of this project is to evolve PlayMotion2 into a modular, plugin-based system. This will allow for the development of specialized plugins tailored to different types of controllers, making the framework more flexible and extensible.
      This project will use ROS 2 Humble Hawksbill.
      Mentors: Noel Jiménez García
      Project Size: 350 hours
      Difficulty: Medium/Hard
      Skills Required: C++, Inheritance, ROS 2, ros2_control, Gazebo simulation and plugin development.
      Outcome:
      Plugin-based system for executing motions with different types of controllers
      Abstract class for plugin definition
      Plugin for JointTrajectoryController
      Plugin for other controller type (TBD)
      Documentation and tutorial for creating a controller plugin for PlayMotion2
      Tips for writing a successful Google Summer of Code application
      Follow GSoC’s Writing a proposal guidelines
      Include your GitHub profile
      Point us your contributions to any open source projects
      Provide us with your contact information in order to reach out for any communication
      Specify your technical background and any courses that you have taken
      Describe your background and experience in robotics and ROS 2
      Specify the project that you are interested in and why you would like to work on it
      Tell us what you hope to get out of the Summer of Code experience.
      Feel free to reach out to the project mentors on GitHub to discuss your ideas
      For further questions, please contact Sai Kishor Kothakota
      Application instructions for GSoC-2025
      Students are encouraged to reach out to relevant mentors before submitting their application on the GSoC official website. All project proposals must be built from scratch, with mentors providing guidance throughout the project. Note that specific requirements are listed for each project and will be considered during the selection process. If in doubt, feel free to send an email to the mentors or at gsocATgmail.com
      Join our Discord server : PAL Google Summer of Code, to discuss ideas and questions and also to connect with other peers.
      Basic requirements for all the projects
      Git experience
      C++ or Python programming experience (depending on the project)
      ROS 2 Basics
      At least one contribution to the open-source projects in the last 6 months
      Programming basic examples depending on the project:
      Payload visualization and metrics
      Describe the step you need to have ROS 2 in your PCs. Provide a link to a video that demonstrates that you can execute talker and listener nodes in your Ubuntu PC.
      Use https://github.com/pal-robotics/tiago_robot repository and provide a link to your YouTube video showing how you would publish the robot description and visualize the robot model in RViz.
      Create and share with us a github repo which contains a ROS 2 node which subscribe to robot description and uses Pinocchio (https://github.com/stack-of-tasks/pinocchio) Rigid Body Dynamics Library. Execute some tests:
      Creates Pinocchio Model
      Perform forward kinematics and get a transform.
      Get a Jacobian at a specific frame.
      Check collisions between 2 links
      ROS 2 Control Ecosystem Visualization
      Write a basic code in ROS 2 subscribing to a topic and sending a service request
      Write an RQT plugin (or) JavaScript (or) TypeScript to display a very simple directed acyclic graph
      Using TypeScript for the above programming gets extra score
      Making the graph interactive will also gets an extra score
      Showing some information of metadata of each node also gets an extra score
      You can use some existing tools such as : https://github.com/RobotWebTools/rclnodejs
      If you are planning to do with RQT, the output should be something similar to rqt_tf_tree
      ROS 2 Action Mux
      Write a basic code in ROS 2 writing an action server and the action client. However, the service request is received by subscribing a topic. If the topic is published at higher rate, it should be able to abort the previous goal and send a new one. The action server should wait for 5 seconds before succeeding and any abortion within 5 seconds should be properly handled
      Write a generic subscriber that can subscribe to a topic of any message type. Write different publishers to test the code, whenever it receives a message from a topic, print also the type of message that is received
      ROS2 python-launch-lsp-server
      Write a ros2 rust node publisher taking 5 different parameters and a subscriber taking 2 different parameters writing it to a file. The nodes should be started by different launch files and the entry point of the application should be 3 levels of scaffolding above the node launch file. Meaning you need to write 4 launch files in total.
      Comments should be added to the launch file on each different use cases for the lsp server that you can find. The more unique ones the better.
      RFID Simulation plugin for Gazebo Harmonic
      Describe the steps needed to have Gazebo Harmonic running on your PC. Setup a demo project with a robot of your choice. Provide a running example, with all the launch files and configuration you used. Be creative, bonus points if your simulated world is related with intralogistic robots.
      Write a new Gazebo Harmonic sensor plugin called DummySensor. You should be able to add it to your demo robot and load it in the simulation. On load, the sensor should publish “Hello World” into a ROS 2 topic using gz-transport.
      PlayMotion2 plugin-based system
      Execute a basic example of publish / subscribe in ROS 2 Humble.
      Create a C++ ROS 2 node that sends some trajectory for a TIAGo arm on simulation: https://github.com/pal-robotics/tiago_simulation/
      Write a basic plugin-based system in C++ that uses ROS 2 Humble and create two plugins for that system. The plugin system will interact with strings, one plugin will revert the string and the other will count the number of characters. The user should be able to select which plugin to use.
      Information we’d like to know about you
      After completing a basic programming example for one of the projects you’re interested in, please submit your work through this Google Form, including a link to the repository hosting your codebase along with other basic information about yourself. This may include your contact information and programming experience or more like the following:
      Contact Details
      Full name
      Email
      Country
      Your Resume / CV
      Public Repository links
      Previous contributions links
      LinkedIn profile
      Cover letter and Project ideas proposal
      Send us a cover letter explaining what you like about the project
      Explain your strategy or your ideas to solve the project
      Now, split your nice project idea into smaller milestones and show an estimated plan covering the GSoC period, and also include your other commitments such as exams, planned holidays, etc.
      Explain to us your serious commitment to this project and how this can contribute to your ongoing studies.
      Technical and Programming background
      Experience with the tools required for the projects you’re interested in
      Technical background and current studies
      Other programming languages you’ve used and your skill level in each
      Operating systems you use regularly
      GSoC Participation details
      Have you ever participated in a GSoC project?
      Have you applied to GSoC in the past but were not selected? If so, when and for what projects?
      Have you submitted proposals to other organizations for GSoC 2025?
      To improve the likelihood of your selection:
      Demonstrate your skills:
      A way to show us that you are the best candidate for the projects is by demonstrating that you’re familiar with the software and can at least do the basic demos requested by the respective project. Adding more features or functionality to the application gives some extra credits. You can also come up with some new ideas and demonstrate them along with your solutions.
      Documentation:
      Apart from writing a code that works, it is also important to see how well you document it to demonstrate to the mentor that, going through your repository, he/she should be able to reproduce it. Don’t forget to explain your approach to the solution.
      Be proactive:
      When you write your cover letter, describe your ideas or approach to the project and explain how you would divide the work into smaller milestones with time estimates. It’s also helpful to show what can be achieved and what future improvements or features could be added. This demonstrates to the mentor how you envision the project’s potential.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/pal-robotics/
    idea_list_url: https://pal-robotics.com/2025-google-summer-code-proposals/#tips-successful-gsoc
  

  - organization_id: 121
    organization_name: PEcAn Project
    no_of_ideas:
    ideas_content: |
      GSoC - PEcAn Project Ideas
      PEcAn is an open-source ecosystem modeling framework integrating data, models, and uncertainty quantification. Below is a list of potential ideas where contributors can help improve and expand PEcAn. Come find us on Slack to discuss. If you have questions or would like to propose your own idea, contact @kooper in Slack or join our gsoc-2025
      Project Ideas
      Below is a list of project ideas. Feel free to contact the listed mentors on Slack to discuss further or contact @kooper with new ideas and he can help connect you with mentors.
      Global Sensitivity Analysis / Uncertainty Partitioning
      Parallelization of Model Runs on HPC
      Database and Data Improvements
      Development of Notebook-based PEcAn Workflows
      Refactoring Compile-time Flags to Runtime Flags in SIPNET
      1. Global Sensitivity Analysis / Uncertainty Partitioning
      This project would extend PEcAn's existing uncertainty partitioning routines, which are primarily one-at-a-time and focused on model parameters, to also consider ensemble-based uncertainties in other model inputs (meteorology, soils, vegetation, phenology, etc). This project would employ Sobol' methods and some uncommitted code exists that manually prototyped how this would be done in PEcAn. The goal would be to refactor/reimplement this prototype into a reliable, automated system and apply it to some key test cases in both natural and managed ecosystems.
      Expected outcomes:
      A successful project would complete the following tasks:
      Reliable, automated Sobol sensitivity analyss and uncertainty partitioning across multiple model inputs.
      Applications to test case(s) in natural and / or managed ecosystems.
      Prerequisites:
      Required: R (existing workflow and prototype is in R)
      Helpful: familiarity with sensitivity analyses
      Contact person:
      Mike @Dietze
      Duration:
      Flexible to work as either a Medium (175hr) or Large (350 hr)
      Difficulty:
      Medium
      2. Parallelization of Model Runs on HPC
      This project would extend PEcAn's existing run mechanisms to be able to run on a High Performance Compute cluster (HPC) using Apptainer. For uncertaintity analysis, PEcAn will run the same model 1000s of times with small permutations. This is a perfect use for an HPC run. The goal is to not submit 1000s of jobs, but have a single job with multiple nodes that will run all of the ensembles efficiently. Running can be orchistrated using RabbitMQ, but other methods are also encouraged. The end goal should be for the PEcAn system to be launched, and run the full workflow on the HPC from start to finish leveraging as many nodes as it is given during the submission.
      Expected outcomes:
      A successful project would complete the following tasks:
      Show different ways to launch jobs (rabbitmq, lock files, simple round robin, etc)
      Report of different options and how they can be enabled.
      Prerequisites:
      Required: R (existing workflow and prototype is in R), Docker
      Helpful: Familiarity with HPC and Apptainer
      Contact person:
      Rob @Kooper
      Duration:
      Flexible to work as either a Medium (175hr) or Large (350 hr)
      Difficulty:
      Medium
      3. Database and Data Improvements
      PEcAn relies on the BETYdb database to store trait and yield data as well as model provenance information. This project aims to separate trait data from provenance tracking, ensure that PEcAn is able to run without the server currently required to run the Postgres database used by BETYdb, and enable flexible data sharing in place of a server-reliant sync mechanism. The goal is to make PEcAn workflows easier to test, deploy, and use while also making data more accessible.
      Potential Directions
      Minimal BETYdb Database: Create a simplified version of BETYdb for demonstrations and Integration tests, which might include:
      Review the provenance information we currently log, identify components that no longer need to be tracked or that should be temporary rather than permanent records, and build tools to clean unneeded records from the database.
      Design and create a freestanding version of the trait data, including choosing the format and distribution method, implementing whatever pipelines are needed to move the data over, and documenting how to use and update the result.
      Review the information we currently log, identify components that no longer need to be tracked or that should be temporary rather than permanent, and build tools to clean unneeded/expired records from the database.
      Non-Database Setup: Enable workflows that do not require PostgreSQL or a web front-end, potentially including:
      Identify PEcAn modules that are still DB-dependent and refactor them to allow freestanding use
      Implement mechanisms for decoupling the DB from the model pipelines in time and space while still tracking provenance. Perhaps this could involve separate prep/execution/post-logging phases, but we encourage your creative suggestions.
      Create tools that maximize interoperability with data from other sources, including from external databases or the user's own observations.
      Identify functionality from the "BETYdb network" sync system that is out of date and replace or remove it as needed.
      Expected outcomes:
      A successful project would complete a subset of the following tasks:
      A lightweight, distributable demo Postgres database.
      A distributable dataset of the existing trait and yield records in a maximally reusable format (i.e. maybe not Postgres)
      A workflow that is independent of the Postgres database.
      Skills Required:
      Familiarity with database concepts required
      Postgres experience helpful (and required if proposing DB cleanup tasks)
      R experience helpful (and required if proposing PEcAn code changes)
      Contact person:
      Chris Black (@infotroph)
      Duration:
      Suitable for a Medium (175hr) or Large (350 hr) project.
      Difficulty:
      Intermediate to hard
      4. Development of Notebook-based PEcAn Workflows
      The PEcAn workflow is currently run using either a web based user interface, an API, or custom R scripts. The web based user interface is easiest to use, but has limited functionality whereas the custom R scripts and API are more flexible, but require more experience.
      This project will focus on building Quarto notebooks that provide an interface to PEcAn that is both welcoming to new users and flexible enough to be a starting point for more advanced users. It will build on existing Pull Request 1733.
      Expected outcomes:
      Two or more template workflows for running the PEcAn workflow.
      Written vignette and video tutorial introducing their use.
      Prerequisites:
      Familiarity with R.
      Familiarity with R studio and Quarto or Rmarkdown is a plus.
      Contact person: David LeBauer @dlebauer, Nihar Sanda @koolgax99
      Duration: Medium (175hr)
      Difficulty: Medium
      5. Refactoring Compile-time Flags to Runtime Flags in SIPNET
      Project Overview
      The ecosystem SIPNET is a core component of many PEcAn analyses. SIPNET is compiled with multiple compile-time flags that control whether different features are turned on and off. Thus, as currently configured, each model structure requires a separate compiled binary.
      This project will refactor these flags to be runtime-configurable via command-line arguments or a configuration file, improving usability and testing efficiency.
      Expected Outcomes
      Convert selected SIPNET compile-time flags to runtime options.
      Develop a global configuration object for managing runtime flags.
      Improve testability by enabling different configurations without recompiling.
      Prerequisites
      Required: C, experience with compilers and build systems.
      Helpful: Understanding of simulation models.
      Mentor(s)
      David LeBauer (@dlebauer)
      Mike Longfritz
      Duration
      Medium (175hr) or Large (350hr)
      Difficulty
      Medium to Hard
      Project Ideas
      1. Global Sensitivity Analysis / Uncertainty Partitioning
      2. Parallelization of Model Runs on HPC
      3. Database and Data Improvements
      4. Development of Notebook-based PEcAn Workflows
      5. Refactoring Compile-time Flags to Runtime Flags in SIPNET
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/pecan-project/
    idea_list_url: https://pecanproject.github.io/gsoc_ideas

  - organization_id: 122
    organization_name: Pharo Consortium
    no_of_ideas:
    ideas_content: |
      HomeProject Ideas
      Pharo GSoC Project Ideas
      Below is the list of project ideas that were proposed by the Pharo community. You can apply to any of those projects by sending an email to one of its mentors. Do not hesitate to propose your own idea but make sure that there is at least one mentor in the community who would agree to supervise you.
      Level
      +
      Keywords
      +
      
      Supervisors
      +
      
      Phizura: Live Music Coding!
      Phizura is a cool music recording project that uses the Coypu package in Pharo to help DJs create an (...)
      Pharo VM running as Docker Scratch image
      This project aims to enable an efficient deployment mechanism for Pharo applications, where they run (...)
      Improve coding UX
      Improve the text editor capabilities for coding. It includes text drag n drop, better parenthesis su (...)
      Implementation of standard data structures and algorithms
      Support for data structures such as various kinds of lists and trees are weakly supported in Pharo, (...)
      Optimisations for a Meta-Compiler
      This project has the objective of improving the optimisation capabilities of the Druid meta-compiler (...)
      Optimizing the Pharo Compiler with Bytecode-Level Inlining
      This project explores inlining Pharo methods at the bytecode level to improve performance. The appro (...)
      Virtual Devices for PharoThings
      PharoThings implements communication with a connected physical hardware or with a remote one through (...)
      Using CFG to analyze tests
      To produce an initial model that represents the Control-Graph-Flow (CFG) of an Pharo application, in (...)
      Meta-Object Protocol for Object-Centric Debugging Tools Implementation
      In this project, the student will start for a MOP prototype, improve the MOP design, extend it, test (...)
      Fault Location DrTest Plugin
      In this project, the student will implement two or three different fault location algorithms, for th (...)
      A Seamless interface between LLMs and Pharo
      This project aims to create an intuitive interface between Pharo and large language models (LLMs). B (...)
      Enhancing Pharo’s Refactoring Engine for a Smarter Development Experience
      One of its key strengths is its powerful development environment, which includes an advanced refacto (...)
      Adding Game Tiles and Sprites to Cormas
      The current version of Cormas allows us to visualize the space and agents in the simulation using co (...)
      Sound Effect Library for Agent-Based Simulations
      In Pharo, there is a library for generating and synthesizing music. We want to use it to add sound e (...)
      Analysing Cormas Code with Moose
      [Moose](https://moosetechnology.org/) is a platform for software and data analysis implemented in Ph (...)
      Computer Vision for Game Piece Detection
      The goal of this project is to enhance the interactive functionality of Cormas by building a compute (...)
      Adding Hexagonal Cells to Cormas Pharo
      In VisualWorks version of Cormas, we had a good support for hexagonal cells. In the current version (...)
      A text-to-speech (TTS) tool for Pharo
      The project, named PAM (Pharo Automated Mouth), is inspired by the JavaScript/Web Audio adaptation o (...)
      Improve the Green threads / Fiber
      Pharo currently implements Green Threads / Fiber through the Process class. However, certain edge ca (...)
      Enhance Register Allocation at Control Flow Merge Points During JIT Compilation
      The JIT compiler in the Pharo VM uses an Abstract Interpreter to translate Pharo methods into machin (...)
      Enhance Slang with Separate Compilation
      Slang is a framework for writing Virtual Machines in Smalltalk and compiling them to C for performan (...)
      Eliminate Object Pointers in JIT-Compiled Code for Better GC Performance
      In the Pharo VM, JIT compilation embeds object pointers directly into compiled machine code. These p (...)
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/pharo-consortium/
    idea_list_url: https://gsoc.pharo.org/ideas

  - organization_id: 123
    organization_name: Plone Foundation
    no_of_ideas:
    ideas_content: |
      Google Summer of Code 2025 Guidelines and Project Ideas
      Project ideas are proposed by mentors from the Plone organization, not potential contributors. The Plone organization was accepted to participate in GSoC on February 27, 2025. Potential contributors should discuss ideas (see below section) in the Community Forum's Google Summer of Code category. See the Google Summer of Code 2025 Timeline.
      Plone Google Summer of Code guidelines
      The Plone Foundation has been a mentoring organization for the Google Summer of Code program for many years. It is great to have students working on Plone and related projects during the summer. It has brought many new contributors to the community.
      Since a few years ago, the number of candidates has been significantly growing, and we are very happy about that. However, the amount of candidates is not easy to manage for us as a community. Please remember, Plone mentors and community members are all unpaid volunteers.
      The following dos and don'ts for the GSoC candidates are a guide to help them get started with Plone, and to help us manage the number of candidates.
      Don't create issues, pull requests, or comments in GitHub
      GitHub is used by contributors who use Plone for their work. GitHub is not a place for GSoC candidates to ask for guidance, help, or support. GSoC candidates should not create pull requests, issues, or comments.
      Don't request to ask to become a member of the Plone GitHub organization. You will become one only if your GSoC project is accepted.
      Doing any of the above actions may result in your suspension or banishment from the Plone GitHub organization. Additionally, it will prevent you from being selected to participate in GSoC.
      Don't contact individuals
      Please don't contact us individually via chat, private message, email, or any other account or social media service. Doing so will prevent you from being selected to participate in GSoC.
      Don't be disrespectful
      Candidates must treat other developers and GSOC mentors with respect, both in text and communication. Disrespect will prevent you from being selected to participate in GSoC.
      Do watch this page for updates
      This page is the authoritative source for everything to do with GSoC. Check back often.
      Do your reading and research first
      Please ensure that you have reviewed our training and documentation.
      Doing so should answer most of your questions on how to install, use, and develop Plone.
      Do learn about Plone
      Plone is a complex system, and it is not easy to get started with it. We expect that you have started to learn about Plone before applying.
      The best way to learn about Plone is to follow our online trainings and our documentation.
      Do use our community forum
      If, after you have reviewed our training and documentation, you have questions, use our community forum's search feature to check if your question has already been answered.
      If your question has not yet been answered or you require further clarification, ask in the community forum.
      If you have technical questions, such as running into a problem installing Plone, read our guidelines on how to ask for help.
      You are welcome to ask questions about the GSoC projects on their dedicated threads. You can propose your own ideas in new threads.
      When you post to the forum, use the category "Google Summer of Code".
      Do focus on your application
      The primary criteria for selection to GSoC is the quality of your application. Make your application stand out by showing that you have learned about Plone and that you have a good understanding of the project you are applying for.
      Don't use artificial intelligence (AI) to generate your application. We can tell the difference between thoughtful and AI-generated applications. We will throw away AI applications.
      The GSoC contributor application period will start on March 24, 2025.
      Ideas
      Note: This is a draft list, the ideas listed here will be refined and detailed in the coming days, and we might add new ones too.
      Volto themes
      Skills: React
      The objective of this project is to create new ready-to-use Volto themes.
      Size: 175
      Rating: intermediate
      Possible mentors: Rafael, E.S. Tyrer
      Expected outcome: Volto themes and documentation
      Workflow manager for Volto
      Skills: React and Python
      Size: 350
      Rating: hard
      Possible mentors: Rafael, E.S. Tyrer
      Expected outcome: a working Plone add-on implementing the feature, with tests and documentation.
      Update pas.plugins.authomatic to the current state of different providers
      Skills: React, Python
      Size: 175
      Rating: intermediate
      Possible mentor: Jens W. Klein
      Expected outcome: a working Plone add-on implementing the feature, with tests and documentation.
      Repeater block
      Skills: React, Python
      The ability to reuse blocks types as the items in a listing to make listings more powerful. e.g. teaser listing, image listing etc.
      In addition the ability to have sources plugins so listings can be other kinds of data not just plone search, for example social media posts, RSS feeds, related/recommended items to this content or links to search pages with different facets preselected.
      Size: 175
      Rating: intermediate
      Possible mentors: Rafael, E.S. Tyrer
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/plone-foundation/
    idea_list_url: https://plone.org/community/gsoc/2025

  - organization_id: 124
    organization_name: PostgreSQL
    no_of_ideas:
    ideas_content: |
      Want to edit, but don't see an edit button when logged in? Click here.
      GSoC 2025
      Jump to navigation
      Jump to search
      This page is for collecting ideas for Google Summer of Code 2025 projects. This page is for IDEAS ONLY.
      IF YOU ARE A CONTRIBUTOR: there is a top-level GSoC page for PostgreSQL here: PostgreSQL General GSoC Page - please read this first before proceeding to contact mentors! Contribution guidelines, channels and communication methods are in this page too. PLEASE make sure you have read everything thoroughly.
      If you are a mentor and would like to participate, feel free to edit this page and put your name below.
      Mentors mailing list for proposals: gsoc2025-mentors@lists.postgresql.org
      Contents
      1 Proposals
      2 Admins
      3 Mentors
      4 Upgrade pgwatch Grafana dashboards to v11
      4.1 Project Description
      4.2 Skills needed
      4.3 Difficulty level
      4.4 Project size
      4.5 Mentors
      4.6 Expected outcomes
      4.7 References
      5 Enhancements to pgwatch v3 RPC integration
      5.1 Project Description
      5.2 Skills needed
      5.3 Difficulty level
      5.4 Project size
      5.5 Mentors
      5.6 Expected outcomes
      5.7 References
      6 ABI Compliance Checker
      6.1 Project Description
      6.2 Background
      6.3 Skills needed
      6.4 Difficulty level
      6.5 Project size
      6.6 Mentors
      6.7 Expected outcomes
      6.8 References
      7 Performance Farm: BuildBot test result data transformation
      7.1 Project Description
      7.2 Skills needed
      7.3 Difficulty level
      7.4 Project size
      7.5 Mentors
      7.6 Expected outcomes
      7.7 References
      8 Performance Farm: Web user interface for navigating results
      8.1 Project Description
      8.2 Skills needed
      8.3 Difficulty level
      8.4 Project size
      8.5 Mentors
      8.6 Expected outcomes
      8.7 References
      9 pgexporter: Extension support
      9.1 Project Description
      9.2 Skills needed
      9.3 Difficulty level
      9.4 Project size
      9.5 Mentors
      9.6 Expected outcomes
      9.7 References
      10 pgmoneta: WAL record filtering
      10.1 Project Description
      10.2 Skills needed
      10.3 Difficulty level
      10.4 Project size
      10.5 Mentors
      10.6 Expected outcomes
      10.7 References
      11 pgmoneta: Incremental backup for PostgreSQL 13-16
      11.1 Project Description
      11.2 Skills needed
      11.3 Difficulty level
      11.4 Project size
      11.5 Mentors
      11.6 Expected outcomes
      11.7 References
      12 pgmoneta: Clustering support
      12.1 Project Description
      12.2 Skills needed
      12.3 Difficulty level
      12.4 Project size
      12.5 Mentors
      12.6 Expected outcomes
      12.7 References
      13 pgagroal: Enhance security
      13.1 Project Description
      13.2 Skills needed
      13.3 Difficulty level
      13.4 Project size
      13.5 Mentors
      13.6 Expected outcomes
      13.7 References
      14 WAL-G: Investigating incremental backup bug using WAL summary
      14.1 Project Description
      14.2 Skills needed
      14.3 Difficulty level
      14.4 Project size
      14.5 Mentors
      14.6 Expected outcomes
      14.7 References
      Proposals
      Proposals are still work in progress. If you are a mentor and would like to participate, feel free to edit this page and put your name below.
      Admins
      Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>
      Pavlo Golub <pavlo (dot) golub (at) gmail (dot) com>
      Mentors
      The following individuals have been listed as possible mentors on the below projects, and/or offered to be mentors for student-proposed projects:
      Pavlo Golub
      Jesper Pedersen
      David Wheeler
      Mark Wong
      Akshat Jaimini
      Saurav Pal
      Shahryar Soltanpour
      Haoran Zhang
      Luca Ferrari
      Rajiv Harlalka
      Andreas Scherbaum
      Marat Bogatyrev
      Dan Zakhlystov
      Upgrade pgwatch Grafana dashboards to v11
      Project Description
      The project focuses on updating the current pgwatch Grafana dashboards to ensure full compatibility with Grafana version 11. While a portion of the dashboards have already been automatically migrated to the new Grafana v11 model, they still require polishing and manual rework to fully leverage the new features and to address any discrepancies caused by differences between Grafana v10 and v11. Key differences include the removal of AngularJS-based components, modifications in panel JSON structure, and enhanced transformation capabilities. The mentee is welcome to improve the overall dashboarding experience by integrating new features, updating deprecated elements, and enhancing panels as needed.
      Skills needed
      Proficiency in Grafana dashboard configuration and JSON model modifications
      Familiarity with the differences between Grafana v10 and v11
      Experience with Docker and Linux environments
      Basic understanding of web development concepts (HTML, CSS, JavaScript)
      PostgreSQL
      Difficulty level
      Moderate
      Project size
      Medium (~175 hours)
      Mentors
      Pavlo Golub
      Akshat Jaimini
      Rajiv Harlalka
      Expected outcomes
      A refined set of Grafana dashboards for pgwatch that are fully compatible with Grafana v11
      Updated and polished JSON definitions that correctly incorporate new v11 features (such as improved visualizations, transformation options, and updated panel configurations)
      Enhanced dashboards and panels that integrate new features, account for deprecated features, and improve the overall user experience
      Documentation outlining the migration process with guidelines for future dashboard updates
      References
      pgwatch
      Breaking changes in Grafana v11.0
      Removal of AngularJS support in Grafana: what you need to know
      Angular support deprecation
      Custom v10 dashboards by postgres.ai (example of customization)
      Enhancements to pgwatch v3 RPC integration
      Project Description
      In GSoC 2024, we integrated Remote Procedure Calls within pgwatch v3 to provide a functionality called Remote Sinks. In 2025 we would like to enhance this implementation by adding more features and utilizing the full capabilities of Remote Procedure Calls. In this iteration of GSoC, we want to improve the existing implementation and add more features that can make remote sinks more useful and extensible.
      Skills needed
      Go
      PostgreSQL
      Difficulty level
      Easy
      Project size
      Medium (175 hours)
      Can be modified according to proposed solution
      Mentors
      Akshat Jaimini
      Pavlo Golub
      Andreas Scherbaum
      Expected outcomes
      Provide an authentication protocol for the current RPC implementation
      Additional sink implementations that showcase extensibility of RPC sinks
      Optimized architecture
      Improved developer experience for building custom sinks
      This is not a strict & exhaustive list and we encourage contributors to provide their own creative input as well
      References
      pgwatch v3: [1]
      Remote Sinks implementation for pgwatch: [2]
      
      ABI Compliance Checker
      Project Description
      Develop and deploy an "ABI Compliance Checker", to be integrated into the PostgreSQL development process similar to coverage.postgresql.org. The checker should run on every commit to the project and produce an ABI compliance report, and trigger an alert when an ABI has changed in an incompatible way. See this thread for an example of such a report, and some details on how it was implemented. Use it as starting point for building the tool.
      Once the tool reliably produces reports, work with the infrastructure team to get it added to the development pipeline and to publicly publish its reports.
      Background
      PostgreSQL recently added Server API and ABI Stability Guidance to help extension authors to understand how and when the server API and ABI are and are not likely to change. In practice, the guidance is that the API and ABI should maintain compatibility between minor releases (e.g., 17.0 to 17.1), but not major releases. This has long been the implicit guidance, but now it is explicit, and due to be included in the PostgreSQL 18 docs.
      Today the committers adhere to this policy purely through the review process, which means once in a while an incompatible change will be included in a minor release. Such changes have been extremely rare, but this past fall an ABI change was unexpectedly shipped in PostgreSQL 17.1. It was quickly reversed in PostgreSQL 17.2, but highlights the need for some process to catch such changes before they're released.
      This project will help reduce the change of such an incident again by automatically checking for ABI changes. This will improve the adherence to the guidance, perhaps allow it to be upgraded to a reliability _policy_, and give extension developers and package maintainers assurance about the reliability of extension builds on PostgreSQL minor releases.
      Skills needed
      C Programming
      Command-line tooling
      HTML & CSS
      Service deployment
      Automation
      Difficulty level
      Medium
      Project size
      Medium (175 hours)
      Mentors
      David Wheeler
      Pavlo Golub
      Expected outcomes
      Working implementation of a subdomain of postgresql.org or as part of the build farm featuring ABI compatibility reports for every commit pushed to a back branch of PostgreSQL
      Notifications of failures sent via email to the committers
      Git repository for the project for ongoing maintenance
      Integration into the PostgreSQL infrastructure build and deploy processes
      References
      abi-dumper, a potential tool
      PostgreSQL Build Farm
      Build Farm Server Code
      pgsql-hackers discussion of an example of a report and the need for a project like this
      Server API and ABI Stability Guidance
      Performance Farm: BuildBot test result data transformation
      Project Description
      Buildbot is a continuous integration framework being used to proof the next generation of the PostgreSQL Performance Farm project. This project is to extract data from BuildBot's database of test results, the PostgreSQL git repository, and the data saved on the Buildbot Worker to transform it, and load it into a new reporting database so that is it easier to query results.
      The contributor is not expected to be familiar with Buildbot's database schema prior to starting, or the details of the various tests that are being run. An introduction to some of those details will be part of the start of the project.
      The reference section has a link to a script that does the data transformation on the fly, so the goal to do something similar. Define a database scheme and perform the data transformation to load new data.
      Skills needed
      SQL
      POSIX Shell Scripting
      git
      Difficulty level
      Easy
      Project size
      Medium (175 hours)
      Mentors
      Andreas Scherbaum
      Mark Wong
      Expected outcomes
      Schema design of new reporting database
      A set of SQL and shell scripts that can be used in the Performance Farm project
      References
      git
      PostgreSQL
      Example script building a static report for DBT-2 test results doing the data transformation on the fly.
      Performance Farm: Web user interface for navigating results
      Project Description
      Develop a front end in interface in JavaScript for navigating test data.
      The Performance Farm prototype runs various tests against all supported branches of PostgreSQL, but the prototype doesn't really have a good interface.
      Here is an example of a static way data is visualized for the results of a single system. The primary way test results are views are for on specific test (e.g. DBT-2), only on one system at a time (e.g. vanillaleaf), and at one specific scale. Then metrics from multiple git branches (e.g. HEAD, REL_17_STABLE, REL_16_STABLE, etc) may all be viewed at the same time, for any code change (i.e. commit) in the PostgreSQL repository.
      Here is an excerpt of raw data from one specific test for one specific system:
         branch,revision,scale,ctime,metric,complete_at
         REL_13_STABLE,3850fcca69b5db0694ceb5d1134699dc247f201e,100,1708386677,564578.0,1728363218
         REL_13_STABLE,9061fd23c28faebcb29bdfb262975639715975c0,100,1708719713,557362.69,1728362912
         REL_13_STABLE,43cca9de9a0adf3fb47aaa6310cc0022a78eee8a,100,1708895707,570032.0,1728362591
      An ideal interface will let the user:
      select the branches to display
      adjust the date range on the fly
      mouse over any data point to see
      commit hash
      brief commit description
      url link to full commit
      Skills needed
      JavaScript
      Difficulty level
      Medium
      Project size
      Long (350 hours)
      Mentors
      Rajiv Harlalka
      Mark Wong
      Andreas Scherbaum
      Expected outcomes
      Working implementation of a JavaScript interface
      References
      git repository - where code is expected to live, but currently no existing javascript code
      pgexporter: Extension support
      Project Description
      pgexporter [1] is a Prometheus [5] exporter for PostgreSQL [4]. This project looks to enhance its functionality with support for PostgreSQL extensions. There needs to be a general framework such that it is easy to add extensions or use different versions. Top extensions like pg_stat_statements should be supported by the distribution.
      Skills needed
      C
      PostgreSQL
      Difficulty level
      Medium
      Project size
      Long (350 hours)
      Mentors
      Saurav Pal <palsaurav (dot) 2020 (at) gmail (dot) com>
      Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>
      Expected outcomes
      Top PostgreSQL extensions working out-of-the-box in pgexporter releases
      References
      [1] https://github.com/pgexporter/pgexporter
      [2] https://github.com/pgexporter/pgexporter_ext
      [3] https://pgexporter.github.io/
      [4] https://www.postgresql.org/
      [5] https://prometheus.io/
      pgmoneta: WAL record filtering
      Project Description
      Apply custom filtering rules to WAL records before generating new files.
      Filter based on:
      Transaction type (INSERT, UPDATE, DELETE, etc.).
      Schema or table names to allow selective replication.
      Custom conditions for targeted processing.
      Expand with Cross-Version WAL Streaming where these files can be streamed to other versions of PostgreSQL based backups.
      Skills needed
      C
      PostgreSQL
      Difficulty level
      Hard
      Project size
      Long (350 hours)
      Mentors
      Shahryar Soltanpour <shahryar (dot) soltanpour (at) gmail (dot) com>
      Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>
      Expected outcomes
      Implement filtering mechanism that can generate PostgreSQL WAL files for different versions.
      References
      [1] https://github.com/pgmoneta/pgmoneta
      [2] https://pgmoneta.github.io/
      [3] https://www.postgresql.org/
      pgmoneta: Incremental backup for PostgreSQL 13-16
      Project Description
      Implement functionality in pgmoneta and pgmoneta_ext such that an incremental backup can be taken from PostgreSQL 13 to 16.
      This work can build upon the work done in the incremental backup support for PostgreSQL 17 inside of pgmoneta.
      Skills needed
      C
      PostgreSQL
      Difficulty level
      Hard
      Project size
      Long (350 hours)
      Mentors
      Haoran Zhang <andrewzhr9911 (at) gmail (dot) com>
      Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>
      Expected outcomes
      Incremental backup working inside pgmoneta for PostgreSQL 13 - 16
      References
      [1] https://github.com/pgmoneta/pgmoneta
      [2] https://github.com/pgmoneta/pgmoneta_ext
      [3] https://pgmoneta.github.io/
      [4] https://www.postgresql.org/
      pgmoneta: Clustering support
      Project Description
      Implement functionality in pgmoneta and pgmoneta_ext such that pgmoneta can operate in a clustered way meaning f.ex. the result of a backup operation is replicated to another pgmoneta node.
      It should be possible to control which node replicates to which node(s).
      Skills needed
      C
      PostgreSQL
      Difficulty level
      Hard
      Project size
      Long (350 hours)
      Mentors
      Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>
      Haoran Zhang <andrewzhr9911 (at) gmail (dot) com>
      Expected outcomes
      Have backup replicate between pgmoneta nodes
      References
      [1] https://github.com/pgmoneta/pgmoneta
      [2] https://github.com/pgmoneta/pgmoneta_ext
      [3] https://pgmoneta.github.io/
      [4] https://www.postgresql.org/
      pgagroal: Enhance security
      Project Description
      This project looks to enhance the security in pgagroal.
      Areas could include
      Database aliases
      Better support for X.509 certificates
      Improve the vault implementation
      Skills needed
      C
      PostgreSQL
      Difficulty level
      Medium
      Project size
      Long (350 hours)
      Mentors
      Luca Ferrari <fluca1978 (at) gmail (dot) com>
      Jesper Pedersen <jesperpedersen (dot) db (at) gmail (dot) com>
      Expected outcomes
      Allow users to configure pgagroal in a more secure way
      References
      [1] https://github.com/agroal/pgagroal
      [2] https://agroal.github.io/pgagroal/
      [3] https://www.postgresql.org/
      WAL-G: Investigating incremental backup bug using WAL summary
      Project Description
      WAL-G has supported incremental backups since 2019 by tracking changed pages in WAL records (WAL-delta backups [3]). However, a critical bug [4] was discovered in 2022, leading to the temporary disabling of this feature. Debugging the issue was challenging due to the lack of a reference implementation for comparison.
      PostgreSQL 17 introduced incremental backup based on WAL summaries, providing a built-in way to track modified pages. This functionality now allows us to compare WAL summary files generated by PostgreSQL 17 and WAL-G to:
      Identify differences in how changed pages are recorded.
      Detect inconsistencies that might explain the WAL-G bug.
      Contribute to fixing WAL-G’s incremental backup mechanism.
      This investigation is essential for improving incremental backup reliability in WAL-G.
      Skills needed
      Go (for working with WAL-G’s implementation)
      C (optional)
      PostgreSQL
      Difficulty level
      Medium
      Project size
      Long (350 hours)
      Mentors
      Marat Bogatyrev
      Dan Zakhlystov
      Akshat Jaimini
      Expected outcomes
      A tool that compares WAL summary files from WAL-G and PostgreSQL 17.
      Identification of discrepancies in changed page tracking between WAL-G and PostgreSQL 17.
      References
      WAL-G: [5]
      PostgreSQL 17 - Incremental Backup Documentation: [6]
      WAL summarizer process in PostgreSQL 17 - commit: [7]
      Category: Google Summer of Code
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/postgresql/
    idea_list_url: https://wiki.postgresql.org/wiki/GSoC_2025

  - organization_id: 125
    organization_name: Processing Foundation
    no_of_ideas:
    ideas_content: |
      About the Processing Foundation
      Our mission at the Processing Foundation is to promote software learning within the arts, artistic learning within technology-related fields, and to celebrate the diverse communities that make these fields vibrant, liberatory, and innovative. Our goal is to support people of all backgrounds in learning how to program and make creative work with code, especially those who might not otherwise have access to tools and resources. We also believe that some of the most radical futures and innovative technologies are being built by communities that have been pushed to the margins by dominant tech.
      To learn more about the Processing Foundation, see our official website at processingfoundation.org.
      What makes a good proposal?
      For all of our projects, it's incredibly important that things are kept as simple and user-friendly as possible. We aim to make our work accessible to everyone, especially those new to coding. Therefore, we focus on making everyday tasks easier for as many people as possible more than on adding features for experts. Keep these values in mind when writing your proposal and you'll greatly increase your chances to get selected by the Processing Foundation for the GSoC program.
      For more information about GSoC and instructions on how to apply, please see our 📄README.
      🌸 Have questions about the organization or the projects? Check out the GSoC 2025 Discourse thread! 🌸
      Project ideas
      This section contains a list of ideas and how you can help contribute to the Processing Foundation's work on Processing, p5.js, and p5.js Editor. Each project has both a potential technical outcome, and a significant possible community impact - we are excited to hear your creative approaches to any of these timely technical challenges!
      Good First Issues in p5.js
      Good First Issues in p5.js Editor
      Help Wanted Issues in Processing4
      p5.sound.js Issues
      Friendly Sketch Embedder for p5.js
      Create a user-friendly tool that guides a p5.js user of any level to help showcase their work in their own websites. Anyone can make a sketch with p5.js - as interactive art, as teaching material, as data visualization, as game, as diary, and as anything else they can imagine! A p5.js sketch is a canvas element that can be included in any website, and existing tutorials help to do this. How can embedding a sketch be streamlined, and support all the different kinds of use-cases and customizations? For example, a teacher may want to include code snippets; an artist may want to arrange multiple sketches next to one another.
      Expected outcomes: A possible technical outcome could be a standalone interactive webpage with user-friendly settings that helps visitors to generate sketch embed code depending on their needs. The community impact can be very wide, making it easier for users to take their work beyond a classroom or a tutorial and into their own interactive online space.
      Skills: Some familiarity of JavaScript is needed, but this could be a good project to sharpen your skills!
      Possible mentor: Dora Do
      Size and Rating: 90H, Easy/Medium
      User-Friendly Features in the p5.js Editor
      The p5.js Editor has thousands of users, and 15% of them use the current autocomplete feature - try it out by turning it on in the settings! How can this feature be improved or expanded to make writing code in the p5.js Editor even friendlier? For a longer/larger project, you can propose a custom context menu for the p5.js Editor: when a user right-clicks, what would be helpful for them to able to see and do? Alternatively, we welcome proposals that focus on improving the accessibility of the autocomplete hinter, such as for screenreader users.
      Expected outcomes: A possible technical outcome could be a pull request or a release in the p5.js-web-editor project that updates the autocomplete widget, or adds a custom context menu widget. The community impact will be among those who use the p5.js Editor, which gets around 200,000 views weekly!
      Skills: Some experience with JavaScript required. Familiarity with digital accessibility (a11y); TypeScript; and/or documentation.js/JSDoc can be a plus.
      Possible mentor: Diya Solanki
      Size and Rating: 90H-175H, Medium
      Approachable Accessibility for p5.js Editor Contributors
      Accessibility is very important for the p5.js Editor, but contributors sometimes face challenges testing and implementing accessibility feature. This project starts with ARIA-roles to the File Manager, Project List View, or User Account Settings. Based on the challenges encountered by the contributor, they can explore ways to make accessibility testing more approachable for future contributors by creating a proof-of-concept tool in the following areas: seamless integration of manual testing, increasing understanding of UX for screen reader users, or strategies for ARIA internationalization. We have found that automated accessibility testing tools alone are not thorough enough, but accessibility testing (both manual and automated) is needed for every feature addition.
      Expected outcomes: A possible technical outcome could be pull request(s) in the p5.js-web-editor repository that implements editor accessibility improvements. This project idea focuses on improving developer tooling, so the community impact extends to both users of the p5.js Editor, and to its contributors.
      Skills: Some familiarity of JavaScript is needed, but this could be a good project to sharpen your skills!
      Possible Mentor: Tristan Espinoza
      Size and Rating: 90H, Easy/Medium
      Bring Visual Tests to Processing
      This project aims to implement a visual snapshot testing system for Processing, inspired by the one used in p5.js (read about it in the p5.js documentation or in a recent contributor blogpost). Snapshot tests help catch visual regressions by automatically comparing generated images before and after code changes. The project will focus on building the testing framework, automating comparisons using pixel matching, and integrating the system into GitHub workflows for optional testing on pull requests. This project also involves porting existing p5.js snapshot tests and developing new ones for Processing’s Java environment. This will improve test coverage, help catch regressions, and make it easier for contributors to propose changes with confidence.
      Expected Outcomes: The technical outcome would be an automated snapshot testing system for Processing with pixel comparisons, GitHub integration, baseline snapshots, and documentation. This project idea focuses on improving developer tooling, so the community impact extends to both users of Processing, and to its current and future contributors!
      Possible Mentors: Claudine Chen
      Skills required/preferred: Java, JavaScript, GitHub Actions/Workflows
      Size and Rating: 175H, Medium
      Code Translation between Processing Sound and p5.sound.js
      Both p5.js and Processing support sound synthesis, playback, and analysis, but only p5.js does it directly in the web browser with p5.sound.js. An automated tool converting Processing Sound to p5.sound.js and vice versa would benefit both communities: Processing Sound users could more easily share work on the web, and p5.sound.js users could more easily adapt their sketches to a wide variety of devices. A code translation tool could also serve as a proof of concept for broader Processing–p5.js translation, which would improve sharing and collaboration across platforms beyond sound.
      Expected Outcomes: A possible technical outcome could be a standalone interactive webpage with user-friendly settings that helps convert Processing Sound sketches into p5.sound.js sketches, and vice versa. This project idea focuses on improving developer tooling, so the community impact extends to both users of Processing Sound and p5.sound.js, and to current and future contributors!
      Possible Mentors: Kevin Stadler
      Skills: experience with both Java and JavaScript essential; optionally: some familiarity with p5.sound.js, Processing Sound, or Web Audio technologies can be a plus
      Size and Rating: 175H, Medium/Hard
      Friendly p5.js Reference Translation Tasks
      The p5.js website provides the most up-to-date reference for p5.js and p5.sound.js in five languages. The reference is automatically generated from inline documentation in the code, and translations are provided by contributors. How can friendlier developer tools - such as GitHub automations - could help contributors work on translating documentation? The p5.js reference strives to be user-friendly, welcoming, and accurate, so it is important that translation itself is not automated. Making it easier to contribute a translation helps invite more users of p5.js around the world to get involved in contributing to p5.js!
      Expected Outcomes: The technical outcome would be GitHub Action(s) in the p5.js reference website repository. This project idea focuses on improving developer tooling, so the community impact extends to p5.js contributors and users worldwide!
      Skills/tech: JavaScript, Astro, Github Actions/Workflows; optional: JSDoc, documentation.js
      Possible mentor: Stalgia Grigg
      Size and Rating: 175H, Medium/Hard
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/processing-foundation/
    idea_list_url: https://github.com/processing/Processing-Foundation-GSoC/wiki/Project-Ideas-List-(GSoC-2025)


  - organization_id: 126
    organization_name: Project Mesa
    no_of_ideas:
    ideas_content: |
      GSoC with Mesa
      Mentoring, Community, and Open Source Collaboration
      Top 3 Ideas
      Additional Ideas
      Philosophy
      Based on the dynamics of complex adaptive systems, Mesa assesses the open source community is the most powerful problem solving network in history. By connecting passionate people from across the world to explore potential solutions through computationally stored knowledge (i.e. code), humanity can solve problems faster and more effectively than ever.
      Values
      Be polite, we are all volunteers
      Everyone has something to learn
      Be curious, not judgmental
      Every contributor's contributions ebbs and flows, its fine, contribute as you can
      What to Expect
      First, if you don't get selected it does not mean your proposal was not awesome and if you want you can absolutely still contribute. We welcome everyone who wants to participate. If Mesa gets selected this will be our second year, from our first year we were incredibly humbled by the number of proposals and the passion of the people who submitted. It truly hurts to say no to so many exceptional people.
      Second, if you are selected, the typical rhythm is a weekly meetings that alternate between a discussion about what you are specifically working on for your project and the broader Mesa dev meeting (usually scheduled for 12:30 GMT on Tuesdays). We understand that this time might not work for everyone, so please don’t worry — if you have scheduling conflicts, we are more than happy to work with you to find an alternative that fits your availability. For your project you will be assigned a mentor with backups who will be available for one-on-one meetings, and you can also connect with us via chat and GitHub.
      Always remember, the goal primary goal is not to complete the expected outcomes (although we will be ecstatic if that happens). The primary goal, in line with GSoC, is to give you development experience and help you gain an understanding of open source coding and community.
      Explore the projects below to see where your skills and interests might fit in. Please feel free to reach out via Mesa's Matrix chat or via email to tpike3@gmu.edu with any questions.
      Ideas List
      Front End Upgrade - Enhance and stabilize Mesa's new Solara-based visualization system to improve robustness, performance, and user experience.
      Mesa-LLM - Create an extension for integrating large language models as decision-making agents in Mesa simulations.
      Mesa-Frames Upgrade - Stabilize and enhance Mesa-frames to provide production-ready support for large-scale agent-based modeling.
      Front End Upgrade
      Summary
      Mesa recently transitioned to a new Solara-based visualization system that enables interactive, browser-based model exploration. While the core functionality is in place, there are several opportunities to enhance its robustness, performance, and user experience. This project aims to stabilize and extend Mesa's visualization capabilities, making them more powerful and user-friendly.
      Motivation
      The visualization system is one of Mesa's most important features - it allows modelers to see complex emergent behaviors and share their models with others. The recent transition from a Tornado-based system to Solara (PR #2263) brought modern web technologies and improved interactivity, but also revealed areas needing refinement. A well-functioning visualization system is crucial for Mesa's adoption and usability.
      Historical Context
      Mesa's visualization evolved significantly:
      Initially used a Tornado-based server system
      In Mesa 2.x, added experimental Jupyter support using Solara
      Mesa 3.0 fully transitioned to Solara-based visualization
      Recent major improvements include unified plotting backends (PR #2430) and API refinements (PR #2299)
      Overall Goal
      Create a visualization system that is:
      Robust and performant
      Easy to use for basic cases
      Flexible for advanced customization
      Well-documented with clear examples
      Consistent across different spaces (grid, network, continuous)
      Expected GSoC Outcomes
      Core Improvements:
      Add support for rotating markers to visualize agent orientation/heading (#2342)
      Enable configurable visualization update intervals for performance (#2579)
      Create an AgentPortrayalStyle class to replace the current dictionary system (#2436)
      Allow direct model access and control from visualization (#2176)
      Update Mesa Examples to use the new visualization approach
      Visual Enhancements:
      Improve grid drawing aesthetics and styling options (#2438)
      Refactor Altair plotting backend to match Matplotlib's clean architecture (#2435)
      Add support for all space types and property layers
      Enable customizable color schemes and visual themes
      Documentation:
      Extend and improve the visualization tutorial
      Document all visualization components and their customization options
      Provide example implementations for common visualization patterns
      Testing:
      Add automated tests for visualization components
      Create benchmarks for visualization performance
      Set up CI testing for example visualizations (mesa-examples#137)
      Skills Required
      Required:
      Python programming
      Experience with data visualization libraries (Matplotlib, Altair)
      Understanding of software design patterns
      Basic knowledge of frontend development
      Preferred:
      Familiarity with Solara or similar frameworks
      Experience with interactive visualizations
      Understanding of agent-based modeling concepts
      Level: Medium/Hard
      Size 350 hours
      Mentors
      Primary: Tom
      Backup: Jackie, Ewout
      Getting Started
      Review the Visualization Tutorial
      Study examples using the new visualization system
      Examine the visualization code in mesa/visualization/solara_viz.py
      Try implementing a small enhancement in one of the example models
      Mesa-LLM: Generative Agent-Based Modeling with Large Language Models Empowered Agents
      Summary
      This project aims to integrate large language models (LLMs) as decision-making agents into the Mesa agent-based modeling (ABM) framework. This project will enable more sophisticated, language-driven agent behaviors, allowing researchers to model scenarios involving communication, negotiation, and decision-making influenced by natural language.
      Motivation
      Current implementations of LLM-based agents often require significant manual coding effort and lack a streamlined interface for designing modular agent architectures. By providing an accessible and flexible API, this project will make it easier for researchers and practitioners to develop, test, and iterate on complex LLM-based agents for applications in areas such as collaborative problem-solving, simulation of human-like reasoning, and dynamic decision-making.
      Overall Goal
      To design and implement an extension for Mesa that allows users to create LLM-powered agents using a modular and user-friendly approach, by assembling reusable components like planning, memory, and reasoning modules. The extension will enable agents to interact using natural language, process textual data, and make decisions informed by LLM capabilities. The project will design and implement robust APIs, integration tools, and documentation to enable rapid prototyping of agents (e.g., Chain-of-Thought, ReWOO, Tree-of-Thought, etc) using different paradigms (e.g., sequential, class-based, functional approach, etc), facilitating research and experimentation in agent-based modeling and natural language reasoning.
      Expected Outcomes
      Core Features:
      Develop modular components for defining and configuring LLM-based agents (e.g., interaction modules, memory systems, decision-making units).
      Create built-in templates and presets for common use cases (e.g., ReACT agent).
      These components will seamlessly integrate with existing Mesa functionality, leveraging the established framework for agent behaviors and environment interactions.
      Users will be able to plug these modules into their existing simulations with minimal adjustments.
      Enhancement & Improvements:
      Support for integrating various LLMs and frameworks (e.g., Hugging Face, LLama, OpenAI).
      Tools for visualizing and debugging agent behavior at the module level.
      Documentation:
      Comprehensive user guides for building agents using the modular API.
      Tutorials demonstrating step-by-step construction of popular LLM-based agents.
      Developer documentation for extending and customizing the API.
      Testing & Quality Assurance:
      Unit tests for individual modules and their integration.
      Benchmarking against standard agent-based tasks to ensure performance and usability.
      CI/CD pipeline to maintain high code quality and reliability.
      Scientific Contribution
      This project is expected to produce at least one scientific publication, such as a submission to the Journal of Open Source Software (JOSS) or a relevant venue in computational social science or agent-based modeling (e.g., SIMULATION). Selected candidate will have the opportunity to contribute to the publication process. This will include help drafting, refining the paper, and being listed as one of the authors, depending on the level of contributions.
      Skills Required
      Required:
      Strong Python programming skills.
      Familiarity with agent-based modeling frameworks like Mesa.
      Experience working with large language models and their APIs.
      Preferred:
      Knowledge of advanced LLM techniques.
      Familiarity with modular library design principles.
      Experience in designing intuitive APIs for scientific computing.
      Knowledge areas:
      Agent-based modeling
      Modular system design
      Natural language reasoning and planning with LLMs
      Project Size: 175/350 hours
      Mentors
      Primary: Boyu
      Backup: Tom, Jackie
      Recommended Bibliography
      Cheng, Y., Zhang, C., Zhang, Z., Meng, X., Hong, S., Li, W., ... & He, X. (2024). Exploring large language model based intelligent agents: Definitions, methods, and prospects. arXiv preprint arXiv:2401.03428. https://doi.org/10.48550/arXiv.2401.03428
      Gao, C., Lan, X., Li, N., Yuan, Y., Ding, J., Zhou, Z., ... & Li, Y. (2024). Large language models empowered agent-based modeling and simulation: A survey and perspectives. Humanities and Social Sciences Communications, 11(1), 1-24. https://doi.org/10.1057/s41599-024-03611-3
      Ghaffarzadegan, N., Majumdar, A., Williams, R., & Hosseinichimeh, N. (2024). Generative agent‐based modeling: an introduction and tutorial. System Dynamics Review, 40(1), e1761. https://doi.org/10.1002/sdr.1761
      Guo, T., Chen, X., Wang, Y., Chang, R., Pei, S., Chawla, N. V., ... & Zhang, X. (2024). Large language model based multi-agents: A survey of progress and challenges. arXiv preprint arXiv:2402.01680. https://doi.org/10.48550/arXiv.2402.01680
      Lu, Y., Aleta, A., Du, C., Shi, L., & Moreno, Y. (2024). LLMs and generative agent-based models for complex systems research. Physics of Life Reviews. https://doi.org/10.1016/j.plrev.2024.10.013
      Ma, Q., Xue, X., Zhou, D., Yu, X., Liu, D., Zhang, X., ... & Ma, W. (2024). Computational experiments meet large language model based agents: A survey and perspective. arXiv preprint arXiv:2402.00262. https://doi.org/10.48550/arXiv.2402.00262
      Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., ... & Wen, J. (2024). A survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6), 186345. https://doi.org/10.1007/s11704-024-40231-1
      Mesa-frames Upgrade
      Summary
      Mesa-frames has proven to be a powerful extension for Mesa, offering significant performance improvements through vectorized operations on dataframes. This project aims to stabilize Mesa-frames, improve its integration with Mesa's core functionality, and establish it as a production-ready solution for large-scale agent-based modeling.
      Motivation
      Mesa-frames has demonstrated impressive performance gains (up to 200x speedup) by leveraging pandas and polars for vectorized operations. While the initial implementation is promising, there are opportunities to improve stability, expand functionality, and better integrate with Mesa's core features. Making Mesa-frames production-ready would provide the Mesa community with a robust solution for scaling agent-based models to handle thousands or millions of agents efficiently.
      Historical Context
      Mesa-frames was developed in 2024 as a GSoC project to address Mesa's performance limitations with large numbers of agents. Key developments include:
      Initial proof-of-concept showing significant performance gains (Discussion #1939)
      Support for both pandas and polars backends
      Integration with Mesa's AgentSet API
      Basic implementation of core Mesa functionality
      Overall Goal
      Create a stable, well-tested, and fully-featured version of Mesa-frames that seamlessly integrates with Mesa while maintaining its performance advantages. This includes expanding documentation, improving test coverage, and implementing missing Mesa functionality.
      Expected Outcomes
      Core Features:
      Address outstanding issues in the mesa-frames repo
      Implement missing Mesa functionality (e.g., PropertyLayers, NetworkGrid support)
      Create a stable release cadence aligned with Mesa's releases
      Improve continuous integration and testing infrastructure
      Enhancement & Improvements:
      Add support for more of Mesa's spaces (mesa-frames#6)
      Implement GPU support through cuDF (mesa-frames#10)
      Optimize performance for common agent-based modeling patterns
      Support for discrete event scheduling (mesa-frames#9)
      Documentation:
      Expand tutorials with advanced usage examples
      Create migration guides from Mesa to Mesa-frames
      Add performance optimization guidelines
      Document integration patterns with other Mesa extensions
      Testing & Quality Assurance:
      Implement comprehensive test suite covering all features
      Add performance regression tests
      Create benchmarks comparing Mesa and Mesa-frames implementations
      Set up continuous performance monitoring
      Skills Required
      Required:
      Strong Python programming skills
      Experience with pandas and/or polars
      Understanding of vectorized operations
      Familiarity with agent-based modeling concepts
      Preferred:
      Experience with Mesa or similar ABM frameworks
      Knowledge of GPU computing (cuDF)
      Background in performance optimization
      Understanding of continuous integration practices
      Level: Medium/Hard
      Size: 175 / 350 hours
      Mentors
      Primary: Adam
      Backup: Tom, Jackie, Jan
      Getting Started
      Review the Mesa-frames source code and documentation
      Study the introductory tutorial
      Examine open issues in the Mesa-frames repository
      Try implementing a simple model using both Mesa and Mesa-frames to understand the differences
      Additional Ideas
      These are projects Mesa would also like to pursue. Based on discussions among the contributor community, we prioritized the top 3. However, exceptional proposals can result in the community selecting these proposals contingent upon if Mesa is selected for GSoC and the number of projects we are allowed to execute.
      Behavioral Framework - Build a comprehensive framework for managing complex agent behaviors, states, and decision-making processes.
      Unifying Geospatial Support - Integrate Mesa-geo's capabilities directly into Mesa as a unified spatial modeling framework.
      Mesa Blocks - Build an extension to Mesa that provide a low code/ no code capability so users can rapidly build custom models.
      Behavioral Framework
      Summary
      Create a comprehensive behavior and state management framework for Mesa that allows agents to have continuously changing states, perform time-consuming tasks, and make decisions based on established behavioral theories. This project aims to provide Mesa users with powerful tools for creating sophisticated agents that can realistically model both discrete and continuous behaviors while following established behavioral theories.
      Motivation
      Mesa currently lacks first-class support for modeling complex agent behaviors that involve continuous state changes, time-consuming actions, and sophisticated decision-making. This makes it difficult to implement realistic agent behaviors like continuous resource depletion, parallel activities, or adaptive decision-making. By providing a unified framework, we can make it easier for modelers to create more sophisticated and realistic agent behaviors.
      Historical Context
      Mesa has evolved from simple discrete-time steps to support more flexible timing through the DiscreteEventScheduler. Recent discussions (#2529, #2526, #2538) and work (PR #2547) have laid the groundwork for more sophisticated agent modeling capabilities. This project would unify and expand these efforts into a cohesive framework.
      Overall Goal
      Create a unified behavioral framework that integrates continuous states, task management, and behavioral decision-making, allowing modelers to create sophisticated agents that can realistically simulate complex real-world behaviors.
      Expected Outcomes
      Core Features:
      State management system for both discrete and continuous states
      Task system for handling time-consuming activities
      Behavioral framework supporting multiple decision-making approaches
      Integration between states, tasks and behaviors
      Enhancement & Improvements:
      Priority and scheduling system for tasks
      Support for interrupting and resuming tasks
      State history tracking and analysis tools
      Event system for state changes and task completion
      Documentation:
      Comprehensive API documentation
      Set of tutorials demonstrating common use cases
      Example models showcasing framework capabilities
      Integration guide with existing Mesa features
      Testing & Quality Assurance:
      Unit tests for all components
      Integration tests for framework interactions
      Performance benchmarks
      Example model tests
      Skills Required
      Required:
      Strong Python programming experience
      Good understanding of OOP and design patterns
      Familiarity with agent-based modeling concepts
      Experience with automated testing
      Preferred:
      Knowledge of behavioral modeling theories
      Experience with discrete event simulation
      Familiarity with state machines
      Background in social science or ecology
      Difficulty: Hard
      Project Size: 350 hours
      Mentors
      Primary: Jackie
      Backup: Ewout
      Getting Started
      Key Documentation:
      Review discussions #2529, #2526, #2538
      Study implementation in PR #2547
      Examine Mesa's time management and event scheduling systems
      Initial Tasks:
      Review and understand the state management PR
      Set up a test environment with Mesa's development version
      Try implementing a simple model using continuous states
      Join discussions on behavioral framework design
      Read up on relevant literature
      Unifying Geospatial Support in Mesa
      Summary
      Integrate Mesa-geo's geospatial capabilities directly into Mesa as a mesa.geo module, leveraging Mesa's new cell and continuous spaces architecture while preserving GIS functionality. This will simplify dependency management, ensure API consistency, and make spatial modeling more accessible.
      Motivation
      Mesa and Mesa-geo have evolved separately, leading to duplicate implementations and compatibility challenges. As Mesa adopts new space abstractions like the experimental cell space and reimplements continuous space, there's an opportunity to unify spatial modeling in Mesa. This would simplify maintenance, ensure consistent APIs, and make GIS features a first-class citizen in Mesa.
      Historical Context
      Mesa's spatial modeling has evolved significantly. The current grid system is being replaced by the experimental cell space system, which provides more flexibility and better performance.
      Mesa-geo was originally developed as a separate package to add GIS capabilities to Mesa. Recent discussions about moving to a monorepo and the development of Mesa's new conceptual model of Space suggest the time is right for integration.
      Overall Goal
      Create a unified spatial modeling framework in Mesa that handles both regular and geospatial spaces through a consistent API, while maintaining full GIS functionality.
      Expected Outcomes
      Core Features:
      Integrate Mesa-geo's core functionality (GeoSpace, GeoAgent) into Mesa as mesa.geo module
      Adapt Mesa-geo to use Mesa's new cell space system as its foundation
      Integration of GIS coordinate systems and transformations into Mesa's space framework
      Unified property layer system that works across all space types (addressing #2431)
      Migration path for existing Mesa-geo users
      Enhancement & Improvements:
      Refactor RasterLayer to use Mesa's PropertyLayer (mesa-geo#201)
      Extend Mesa's continuous space to handle geographic coordinates
      Support for GIS file formats (GeoJSON, shapefiles) in Mesa's core I/O
      Improved integration with visualization system
      Documentation:
      Updated space concepts documentation
      Migration guide for Mesa-geo users
      New tutorials demonstrating integrated GIS features
      API reference for geospatial functionality
      Testing & Quality Assurance:
      Test suite covering GIS-specific functionality
      Benchmark suite for spatial operations
      Example models demonstrating migration
      CI/CD integration for GIS dependencies
      Skills Required
      Required:
      Python programming
      Understanding of GIS concepts
      Experience with Mesa and/or Mesa-geo
      Familiarity with spatial data libraries (Shapely, GeoPandas)
      Preferred:
      Experience with coordinate reference systems
      Understanding of Mesa's architecture
      Knowledge areas: Medium/Hard difficulty
      Project Size: 350 hours:
      Mentors
      Primary: Jackie
      Backup: Boyu
      Getting Started
      Review Mesa's space conceptual model
      Study the new continuous space implementation
      Examine Mesa-geo's COVID-19 example model
      Join discussions about property layers
      Mesa Blocks
      Summary
      Build a low code/no code extension so users can rapidly assemble and run custom agent based models
      Motivation
      Agent Based Models have always been challenge by the reality of complex systems - every detail does matter. This does not however, mean that building blocks from models cannot be reused. Have easily reusable building blocks that can be connected together with other core model parts or even opened up and customized can help users more rapidly assemble and customize valid models, while also helping people get better models faster to aid in their decision making.
      Historical Context
      Developing ways to rapidly build models has always been a hard challenge for ABMs and reusable building blocks represents an proven way to help mitigate this challenge. Mesa tried to build the ecosystem first but could not maintain it and there are other efforts to find solutions, notably Reusable Building Blocks for ABMS
      Overall Goal
      To have a prototype of low code/ show code approach that allows users to rapidly build and explore models.
      Expected Outcomes
      Core Features:
      Users can drag and drop blocks to rapidly assemble models
      Easily build new blocks and share with the Mesa community
      Allow users to go into and customize blocks
      Skills Required
      Required:
      Python programming
      Experience with Mesa and/or Mesa-geo
      Preferred:
      Knowledge of No code/low code tools
      Understanding of Mesa's architecture
      Knowledge areas: Hard difficulty
      Project Size: 350 hours:
      Mentors
      Primary: Tom
      Backup: Jackie
      Getting Started
      Some possible starting libraries. The below was created with the help of ChatGPT but there may be some better options.
      Library Strength Integration with Mesa
      NodeGraphQt Full Python drag & drop system Possible best for custom Mesa UI
      NoFlo Flow-based programming Needs custom Python adaptation
      Node-RED Web-based flow editor Requires Node.js but works with Python
      Unreal Blueprints No-code game simulation Best for Wargame AI/Mesa in Unreal
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/project-mesa/
    idea_list_url: https://github.com/projectmesa/mesa/wiki/Google-Summer-of-Code-2025


  - organization_id: 127
    organization_name: Prometheus-Operator
    no_of_ideas:
    ideas_content: |
      Project Ideas
      If you are a Prometheus-Operator team member and consider mentoring during the GSoC 2025 cycle, please, submit your ideas below using the template.
      If you are a GSoC candidate, please check out our contributor guidance.
      Google summer of code timeline.
      NOTE: Please note that GSoC is a program known for its strict deadlines. In addition to responding to your mentee on time, you will be required to submit evaluations on time. Failures to meet the deadlines might affect Prometheus-Operator's future participation in GSoC.
      While we submit 2 topics this year, you can notice that both have the same mentors. Because we consider that it isn't sustainable and respectful for the 3 mentors to follow 2 projects in parallel, we intend to select only one project in the end. The selection will be based on the quality of the answers received.
      Template
      ### Project Title
      
      - Description:
      - Expected Outcome:
      - Recommended Skills:
      - Expected project size: # one of small (~90 hour projects), medium (~175 hour projects) and large (~350 hour projects)
      - Mentor(s): #For GSoC, it is **required** to have at least 2 mentors with 1 being a primary mentor.
        - Jane Doe (@jane-github, jane@email.address) - primary
        - John Doe (@john-github, john@email.address)
      - Upstream Issue (URL):
      Ideas
      Status for configuration objects
      Description: A frequent pain point for users is to understand whether their configuration resources are applied and if it's not the case, what's the issue. We improved a bit the situation by emitting events when the reconciliation loop rejects configuration resources but it would be even better if the information was persisted in the status subresource (for instance comparing the resource's generation against the observed generation can indicate if the latest version is reconciled or not).
      While workload resources like Prometheus and Alertmanager have gained a Status subresource, there's no such thing (yet) for configuration resources like ServiceMonitor, PodMonitor, AlertmanagerConfig, Probe, ScrapeConfig and PrometheusRule. The main difference between workload and configuration resources is that configuration resources can be selected by multiple workloads: for example, 2 different Prometheus resources can select the same ServiceMonitor resource. As a consequence, we can't use the same API already defined for workload resources. Please note that we don't want to forbid this situation since it is a perfectly valid and supported use case (for instance running 2 stacks in parallel during migrations).
      Recommended Skills: Go, Kubernetes
      Expected project size: large
      Mentors:
      Jayapriya Pai (@slashpai, slashpai9@gmail.com)
      Simon Pasquier (@simonpasquier, pasquier.simon@gmail.com)
      M Vishwanath Sai (@mviswanathsai, mviswanath.sai.met21@itbhu.ac.in)
      Upstream Issue (URL): prometheus-operator/prometheus-operator#3335
      Daemonset mode for the Prometheus Agent
      Description: During the last GSoC, Prometheus Operator gained the option to deploy a PrometheusAgent custom resource as a DaemonSet (instead of the default StatefulSet mode). The project was a success and met its objectives but the feature is still behind a feature flag because not all the functionalities have been implemented. The expectations for this year are to identify the remaining gaps, write a plan of action, implement the missing features and write documentation (tutorials for instance).
      Recommended Skills: Go, Kubernetes
      Expected project size: medium
      Mentor(s):
      Jayapriya Pai (@slashpai, slashpai9@gmail.com)
      Simon Pasquier (@simonpasquier, pasquier.simon@gmail.com)
      M Vishwanath Sai (@mviswanathsai, mviswanath.sai.met21@itbhu.ac.in)
      Upstream Issue (URL): prometheus-operator/prometheus-operator#5495
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/prometheus-operator/
    idea_list_url: https://github.com/prometheus-operator/community/blob/main/mentoring/gsoc/2025/project_ideas.md

  - organization_id: 128
    organization_name: Python Software Foundation
    no_of_ideas:
    ideas_content: |
      IDEAS
      Students: Instructions on getting started. Right now, we're still preparing for GSoC 2025; check back regularly for project updates.
      If you're a sub-org who wants to join, please read the information for sub-orgs.
      
      MSS - Mission Support System
      
      The Mission Support System (MSS) is a software that is written by scientists in the field of atmospheric science. The purpose is to have a tool that simplifies the process for planning a scientific flight in which parameters of the atmosphere are measured. MSS helps to optimize the scientific outcome of the research flights by displaying the planned flight route and the corresponding model parameters in the same platform for many discussed options. It does therefore reduce somehow the amount of flight hours that is needed to answer a scientific question and thus saves in the end taxpayers money.
      Contact Links
      Chat
      Mailing List
      Twitter Url
      Blog Url
      Homepage
      Ideas Page
      Source Code
      ilastik
      
      ilastik allows users without computational expertise to leverage machine learning to easily segment and classify cells and other structures in biological images. It is designed to be user-friendly, while still providing powerful tools for image analysis.
      Contact Links
      Email
      Homepage
      Chat (DM to B. Best)
      Ideas Page
      Source Code
      pocketpy
      
      pocketpy is a portable Python 3.x interpreter, written in C11. It aims to be an alternative to Lua for game scripting, with elegant syntax, powerful features and competitive performance. pocketpy has no dependencies other than the C standard library, which can be easily integrated into your C/C++ project. Developers are able to write Python bindings via C-API or pybind11 compatible interfaces.
      Contact Links
      Chat
      Homepage
      blueloveth@foxmail.com
      Ideas Page
      Source Code
      CVE Binary Tool
      
      The CVE Binary Tool helps you determine if your system includes known vulnerabilities. You can scan binaries for over 200 common, vulnerable components (openssl, libpng, libxml2, expat and others), or if you know the components used, you can get a list of known vulnerabilities associated with an SBOM or a list of components and versions.
      Contact Links
      Chat
      Homepage
      Ideas Page
      Source Code
      Tölvera
      
      Tölvera is a Python library for composing together and interacting with self-organising systems and artificial life. It provides creative coding-style APIs that allow users to combine and compose various built-in behaviours, such as flocking, slime mold growth, and swarming. With built-in support for Open Sound Control (OSC) and interactive machine learning (IML), Tölvera interfaces with music software and hardware for exploring diverse intelligence in artistic contexts.
      Contact Links
      Chat
      Homepage
      Email
      Ideas Page
      Source Code
      MNE-Python
      
      MNE-Python software is an open-source Python package for exploring, visualizing, and analyzing human neurophysiological data such as MEG, EEG, sEEG, ECoG, and more. It includes modules for data input/output, preprocessing, visualization, source estimation, time-frequency analysis, connectivity analysis, machine learning, and statistics.
      Contact Links
      Chat
      Mailing List
      Homepage
      Ideas Page
      Source Code
      Borg Collective
      
      We are the Borg Collective and maintain multiple Python-based backup tools that are often used in combination: Borg, Borgmatic and Vorta. The core Borg tool is a deduplicating archiver with compression and deduplication. Vorta is a desktop backp client that integrtes with Linux and macOS desktops. Borgmatic is a wrapper for server systems that also takes care of database backups and pre-backup commands.
      Contact Links
      Chat
      Mailing List
      Homepage
      Ideas Page
      Source Code
      FRIENDS OF THE PSF
      Here's some more interesting organizations that use Python!
      TARDIS TARDIS is an open-source Monte Carlo radiative-transfer spectral synthesis code for 1D models of supernova ejecta. It is designed for rapid spectral modelling of supernovae. It is developed and maintained by a multi-disciplinary team iincluding software engineers, computer scientists, statisticians, and astrophysicists.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/python-software-foundation/
    idea_list_url: https://python-gsoc.org/ideas.html

  

  - organization_id: 129
    organization_name: QC-Devs
    no_of_ideas:
    ideas_content: |
      Google Summer of Code 2025
      GSoC
      Project Ideas
      Contributor Guidance
      Previous Projects
      This document provides guidance for individuals interested in participating in the Google Summer of Code (GSoC) program with QC-Devs. We are looking forward to your contributions.
      Project Ideas
      We store project ideas as GitHub issues. The below links refer to these issues, where you can find more information about the package, the project, the task, and the expected outcomes. While QC-Devs supports quite a few packages (we released 7 in the last 12 months!), each year we select a few to focus on, as this makes it easier for mentors to engage with participants.
      Project Hours Difficulty
      AtomDB: Refactor Database Structure 175 🤔
      Gbasis: Improve Performance Using Screening 350 🤔
      GBasis: Arbitrary-Order Overlap Integrals + Applications 350 😰
      Grid: Integration on the Sphere Using Maximum Determinant Points 90 🤓
      Grid: Adaptive Molecular Quadrature 175 🤔
      Grid: Transformed Cubic Grids 175 🤔
      Grid: Improve Robustness of Poisson Solver 350 🤔
      ModelHamiltonian: Manipulating Model Hamiltonians and Building Interfaces to External Packages 350 😰
      ModelHamiltonian: An Alternative Approach to Spin Hamiltonians 90 🤔
      NICE.jl: Add Exact Solver for Chemical Kinetics 175 🤔
      Contributor Guidance
      QC-Devs GSoC Contributor Guidance.
      QC-Devs community health files, including our code-of-conduct and contribution guidelines
      Previous Projects
      A web interface for the Selector package. See the result and the original issue. A scientific publication has been submitted for publication. (2024)
      A new API and additional functionality for the ModelHamiltonian package. See the original issue. This led to a scientific publication. (2024)
      Updated: February 15, 2025
      Previous
      Next
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/qc-devs/
    idea_list_url: https://qcdevs.org/join/qcdevs_gsoc/


  - organization_id: 130
    organization_name: QEMU
    no_of_ideas:
    ideas_content: |
      Google Summer of Code 2025
      Page
      Discussion
      Read
      View source
      View history
      Introduction
      QEMU is participating in Google Summer of Code 2025. This page contains our ideas list and information for applicants and mentors. Google Summer of Code is an open source internship program offering paid remote work.
      Status: Applicants can discuss project ideas with mentors. Applications are open March 24 - April 8 18:00 UTC. See #Application Process below for information on how to apply.
      Project Ideas
      This is the listing of suggested project ideas. Students are free to suggest their own projects, see #How to propose a custom project idea below.
      Tracing and logging in Rust
      Expected outcome: Implement Rust APIs for tracing and logging.
      The QEMU project is currently experimenting with using the Rust programming language to create new devices. As part of this, we have to write bindings to the C code that make it possible to use it from Rust safely. For example, QEMU needs to include Rust code to manage timers, interrupts and memory regions with safe and idiomatic Rust code.
      QEMU integrates support for tracing using various backends---ranging from good old stdio to systemtap---thanks to a code generator that can produce tracing routines for the hundreds of tracepoints that QEMU supports; for more information see the links below. As part of this project, you will work on adding support for tracing and logging to Rust code.
      The project spans multiple programming languages: the code generator is written in Python, the generated code will of course be Rust, and you will have to read some C to understand the subsystem.
      Among similarly large open source C projects, QEMU is an early adopter for Rust! So you will also have a look at how the two languages can be integrated through the Meson build system.
      Tasks:
      implement bindings for QEMU's logging subsystem (logging is one of the tracing backends)
      analyze the code generated by tracetool for C for the various tracing backends
      try to implement by hand a few tracepoints in Rust
      modify tracetool to generate the Rust code automatically
      Links:
      Tracing in QEMU
      Rust in QEMU status
      Details:
      Project size: 350 hours
      Skill level: intermediate/advanced
      Languages: Python, Rust, C
      Mentor: Paolo Bonzini (OFTC: bonzini, Email: pbonzini@redhat.com)
      Adding Kani proofs for Virtqueues in Rust-vmm
      Expected outcome: Verify conformance of the virtqueue implementation in rust-vmm to the VirtIO specification.
      In the rust-vmm project, devices rely on the virtqueue implementation provided by the `vm-virtio` crate. This implementation is based on the VirtIO specification, which defines the behavior and requirements for virtqueues. To ensure that the implementation meets these specifications, we have been relying on unit tests that check the output of the code given specific inputs.
      However, writing unit tests can be incomplete, as it's challenging to cover all possible scenarios and edge cases. During this internship, we propose a more comprehensive approach: using Kani proofs to verify that the virtqueue implementation conforms to the VirtIO specification.
      Kani allows us to write exhaustive checks for all possible values, going beyond what unit tests can achieve. By writing Kani proofs, we can confirm that our implementation meets the requirements of the VirtIO specification. If a proof passes, it provides strong evidence that the virtqueue implementation is correct and conformant.
      Kani is an open-source tool and any issues like regarding performance can be reported on GitHub. For more information, the blog[1] contains several examples on how to use Kani in real codebases (including Firecracker). Also, there is a current effort for verifying the Rust Standard Library using Kani [2].
      Tasks:
      Finish current PR that adds a proof for the notification suppression mechanism
      Port add_used() proof
      Port verify_prepare_kick() proof
      Port other proofs from queue.rs
      Links:
      LPC Talk about how we may check conformance in the VirtIO specification (video)
      FOSDEM'25 talk current effort to use Kani
      Kani Blog
      Details:
      Project size: 175 or 350 hours, depending on how many proofs you wish to tackle
      Skill level: intermediate
      Language: Rust
      Mentor: Matias Ezequiel Vara Larsen (mvaralar@redhat.com)
      FUSE-over-io_uring exports
      Expected outcome: Extend QEMU's FUSE export type with FUSE-over-io_uring support
      FUSE-over-io_uring is a new high-performance interface for Filesystem in Userspace (FUSE) servers. The FUSE kernel code has added uring_cmd support so that FUSE servers can send and receive data directly over io_uring instead of reading/writing from/to the FUSE device. This reduces the number of system calls, as well as allowing for batching and polling, so that CPU overhead should be reduced.
      QEMU's FUSE export type presents a file containing the contents of a disk image. This is a convenient way of using tools like fdisk(1) or dd(1) on a non-raw disk image file, like qcow2, that these tools would otherwise not be able to operate on. The current FUSE export implementation uses libfuse's FUSE device file descriptor handling APIs (fuse_session_fd(), fuse_session_receive_buf(), etc) to read(2)/write(2) in the traditional way.
      Your task is to add FUSE-over-io_uring support as an alternative mode on systems where FUSE-over-io_uring is available.
      Tasks:
      Integrate FUSE-over-io_uring mode into the QEMU FUSE export
      Add support for multiple in-flight requests
      Benchmark with and without FUSE-over-io_uring using the fio(1) tool
      Add support support multiple IOThreads
      Links:
      QEMU FUSE export code
      libfuse branch with FUSE-over-io_uring support
      Overview of low-level FUSE-over-io_uring interface (handled by libfuse, but good background info)
      Details:
      Project size: 350 hours
      Skill level: intermediate
      Language: C
      Mentors: Kevin Wolf (kwolf@redhat.com), Stefan Hajnoczi (stefanha@redhat.com)
      Asynchronous request handling for virtiofsd
      Expected outcome: Make virtiofsd’s request handling asynchronous, allowing single-threaded parallel request processing.
      virtiofsd is a virtio-fs device implementation, i.e. grants VM guests access to host directories. In its current state, it processes guest requests one by one, which means operations of long duration will block processing of others that could be processed more quickly.
      With asynchronous request processing, longer-lasting operations could continue in the background while other requests with lower latency are fetched and processed in parallel. This should improve performance especially for mixed workloads, i.e. one guest process executing longer-lasting filesystem operations, while another runs random small read requests on a single file.
      Your task is to:
      Get familiar with a Linux AIO interface, preferably io_uring
      Have virtiofsd make use of that interface for its operations
      Make the virtiofsd request loop process requests asynchronously, so requests can be fetched and processed while others are continuing in the background
      Evaluate the resulting performance with different workloads
      How you make the request loop asynchronous will largely be left to your discretion. You can use Rust async together with a runtime like tokio, some other runtime, or an entirely custom one; or keep the code synchronous, but allow deferring operations to the background, and when they complete, return the virtio descriptors to the guest then. That said, we assume that using async would provide the better long-term solution, as long as you’re comfortable to use/learn it.
      Links:
      virtiofsd repository: https://gitlab.com/virtio-fs/virtiofsd
      virtiofsd’s filesystem operations: https://gitlab.com/virtio-fs/virtiofsd/-/blob/main/src/passthrough/mod.rs#L1490
      virtiofsd’s request processing loop: https://gitlab.com/virtio-fs/virtiofsd/-/blob/main/src/vhost_user.rs#L244
      Details:
      Project size: 350 hours
      Skill level: intermediate
      Language: Rust
      Mentors: Hanna Czenczek (hreitz@redhat.com), German Maglione (gmaglione@redhat.com)
      Implement LASI network card and/or NCR 710 SCSI controller device models
      Expected outcome: Develop device emulations of the HP PA-RISC LASI network card and/or NCR 710 SCSI controller
      QEMU can emulate a lot of physical machines. Beside widely used x86 machines as used with KVM, this includes historic machines based on PowerPC, Alpha or HP PA-RISC CPUs too. To emulate additional historic machine models, device models that emulate specific hardware like network or SCSI cards need to be developed.
      This project is about developing such a device model for the historic HP PA-RISC architecture. Based on the knowledge and interest of the applicant, here are two non-exclusive options:
      1. LASI network card. This is basically an Intel 82596 network chip, which was integrated into another ASIC in the HP 700 series. That chip was used in SUN machines as well, and the full Linux driver source code for the various machines is available. A QEMU device model exists (see here and here), but it's not fully functional yet. Datasheets for this chip exists too. This project is about debugging and analyzing existing code, including development of missing code.
      2. First-generation NCR 710 SCSI controller. Really old machines used a NCR 710 SCSI controller, for which currently no QEMU device model exists. QEMU has a LSI53C895A device model, which partly even allows emulating a LSI53C810, but those chips are "too new" and as such are not accepted and supported on old operating systems (e.g. HP-UX9). The WinUAE project seem to have modified the existing QEMU device model to emulate a NCR 710 to support the Amiga. The goal of this project is to develop a nice & clean NCR 710 device model that can be merged into QEMU.
      Links:
      https://parisc.docs.kernel.org/en/latest/technical_documentation.html
      Details:
      Project size: 350 hours
      Skill level: advanced
      Language: C
      Mentor: Helge Deller (deller@gmx.de)
      vhost-user devices in Rust on macOS and *BSD
      Expected outcome: Extend rust-vmm crates to support vhost-user devices running on POSIX system like macOS and *BSD.
      VIRTIO devices can be emulated in an external process to QEMU thanks to the vhost-user protocol, which allows QEMU to offload the entire emulation to a daemon. This is done through an AF_UNIX socket used as a control path between the frontend (i.e. QEMU) and the backend (i.e. the vhost-user daemon). QEMU will share guest memory with the daemon, provide all the information for data path setup, and notification mechanisms.
      Moving the emulation of VIRTIO devices to a separate process from QEMU offers significant advantages, primarily in terms of safety, if a device crashes, we can restart it without affecting QEMU. Additionally, this approach simplifies updating device implementations, allows development in other languages (such as Rust as we do in the rust-vmm community), and enhances isolation through seccomp, cgroups, and similar mechanisms.
      The rust-vmm community already provides several crates (e.g. vhost, vhost-user-backend, etc.) to implement a vhost-user backend in an external daemon. For example, these crates are used by virtiofsd (virtio-fs vhost-user device) but also by all vhost-user devices maintained by the rust-vmm community in the rust-vmm/vhost-device workspace. These crates work great on Linux, but unfortunately they use some Linux-specific system calls such as epoll(7) and eventfd(2) that make them impossible to use on other POSIX systems.
      The goal of this project is to make sure that we can use rust-vmm's vhost and vhost-user-backend crates on other POSIX systems besides Linux. If time permits, we could also fix up simple devices such as vhost-device-console or vhost-device-vsock to run on any POSIX systems.
      Tasks:
      Run QEMU with a vhost-user device on macOS or FreeBSD/OpenBSD as covered in the FOSDEM 2025 talk
      Analyze rust-vmm crates (vmm-sys-util, vhost, vhost-user-backend) to understand which components are Linux-specific
      Replace epoll(7) with alternatives such as https://github.com/smol-rs/polling
      Automatic fallback to pipe()/pipe2() if eventfd(2) is not available as QEMU already does
      Handle any other cases discovered during the analysis
      Adapt a simple device such as vhost-device-console or vhost-device-vsock to test that everything works on macOS or FreeBSD/OpenBSD
      Links:
      FOSDEM 2025 talk: Can QEMU and vhost-user devices be used on macOS and *BSD?
      vhost-user spacification
      QEMU series to support vhost-user on any POSIX
      sgarzare's tree where to find some missing QEMU patches
      rust-vmm vhost & vhost-user-backend crates
      rust-vmm vmm-sys-util crate
      rust-vmm vhost-device workspace
      virtio-fs vhost-user device
      Mac build support #110 - rust-vmm/vhost
      Add macOS support #169 - virtio-fs/virtiofsd
      Details:
      Project size: 350 hours
      Skill level: intermediate
      Language: Rust
      Mentors: Stefano Garzarella <sgarzare@redhat.com>, German Maglione <gmaglione@redhat.com>, Oliver Steffen <osteffen@redhat.com>
      Application Process
      1. Discuss the project idea with the mentor(s)
      Read the project ideas list and choose one you are interested in. Read the links in the project idea description and start thinking about how you would approach this. Ask yourself:
      Do I have the necessary technical skills to complete this project?
      Will I be able to work independently without the physical presence of my mentor?
      Note that QEMU does not accept AI generated patches from agents/composers, so keep that in mind when considering your technical skills and ability to work independently.
      If you answer no to these questions, choose another project idea and/or organization that fits your skills.
      Once you have identified a suitable project idea, email the mentor(s) your questions about the idea and explain your understanding of the project idea to them to verify that you are on the right track.
      2. Submit your proposal
      Upload your proposal PDF file to the Google Summer of Code website and notify your mentor(s) so they can give you feedback. Do not use AI to generate your proposal. Using AI to adjust the wording of your proposal is allowed, this can be useful if you are not a native speaker.
      You can make changes and upload the PDF again until the application deadline. Your proposal must include the following:
      Project idea (title)
      Your name and email address
      Outline of your solution
      Do some background research by looking at source code, browsing relevant specifications, etc in order to decide how to tackle the project. Discuss any questions with your mentor. This section will explain how your solution will work.
      Project schedule
      Create a week-by-week schedule of the coding period. Breaking down the project into tasks and estimate how many weeks they will take. The schedule can be adjusted during the summer so don't worry about getting everything right ahead of time.
      Relevant experience (programming language knowledge, hobby projects, etc)
      Are you available to work with no other commitments (jobs, university, vacation, etc) for the duration of your project? If not, please give details about the working hours and dates.
      3. Contribution task
      Once you have submitted your proposal PDF, let your mentor know and request a contribution task. The task will be a real bug or small feature that should not take more than 1 or 2 days to complete. This will allow you to demonstrate your skills in a realistic setting. Do not use AI composers/agents or vibe coding to generate the code. Your mentor will provide you the details and help you with any questions.
      Key Dates
      From the timeline:
      February 27 18:00 UTC - Organizations and project ideas announced
      March 24 - April 8 18:00 UTC - Application period
      April 15 - Contribution task deadline
      May 8 18:00 UTC - Accepted applicants announced
      June 2 - September 1 - Standard coding period (an extended timeline is possible depending on your project)
      Find Us
      IRC (GSoC specific): #qemu-gsoc on irc.oftc.net
      IRC (development):
      QEMU: #qemu on irc.oftc.net
      KVM: #kvm on chat.freenode.net
      Mailing lists:
      QEMU: qemu-devel
      KVM: linux-kvm
      For general questions about QEMU in GSoC, please contact the following people:
      Stefan Hajnoczi <stefanha@gmail.com> (stefanha on IRC)
      How to add a project idea
      Create a new wiki page under "Internships/ProjectIdeas/YourIdea" and follow #Project idea template.
      Add a link from this page like this: {{:Internships/ProjectIdeas/YourIdea}}
      This is the listing of suggested project ideas. Students are free to suggest their own projects, see #How to propose a custom project idea below.
      Project idea template
      === TITLE ===
       
       '''Summary:''' Short description of the project
       
       Detailed description of the project.
       
       '''Links:'''
       * Wiki links to relevant material
       * External links to mailing lists or web sites
       
       '''Details:'''
       * Skill level: beginner or intermediate or advanced
       * Language: C
       * Mentor: Email address and IRC nick
       * Suggested by: Person who suggested the idea
      How to propose a custom project idea
      Applicants are welcome to propose their own project ideas. The process is as follows:
      Email your project idea to qemu-devel@nongnu.org. CC Stefan Hajnoczi <stefanha@gmail.com> and regular QEMU contributors who you think might be interested in mentoring.
      If a mentor is willing to take on the project idea, work with them to fill out the "Project idea template" above and email Stefan Hajnoczi <stefanha@gmail.com>.
      Stefan will add the project idea to the wiki.
      Note that other candidates can apply for newly added project ideas. This ensures that custom project ideas are fair and open.
      How to get familiar with our software
      See what people are developing and talking about on the mailing lists:
      qemu-devel
      libvir-list
      kvm
      Grab the source code or browse it:
      qemu.git
      libvirt.git
      kvm.git
      Build QEMU and run it: QEMU on Linux Hosts
      Links
      Student Manual
      FAQ
      Timeline
      Advice for students applying (from 2011 but still relevant!)
      Information for mentors
      Mentors are responsible for keeping in touch with their intern and assessing progress. GSoC has evaluations where both the mentor and intern assess each other.
      The mentor typically gives advice, reviews the intern's code, and has regular communication with the intern to ensure progress is being made.
      Being a mentor is a significant time commitment, plan for 5 hours per week. Make sure you can make this commitment because backing out during the summer will affect the intern's experience.
      The mentor chooses their intern by reviewing application forms and conducting IRC interviews with applicants. Depending on the number of candidates, this can be time-consuming in itself. Choosing the right intern is critical so that both the mentor and the intern can have a successful experience.
      Category: GSoC
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/qemu/
    idea_list_url: https://wiki.qemu.org/Google_Summer_of_Code_2025
  

  - organization_id: 131
    organization_name: R project for statistical computing
    no_of_ideas:
    ideas_content: |
      Mentors, please edit this wiki page, and add your ideas to the table below.
      Contributors, please look for a project that interests you in the table below. Before emailing project mentors, please do at least one project Test and post a link to your solution on the proposal’s wiki page.
      Proposal Hours Status/Results Mentors Non-R languages?
      MENTORS-COPY-THIS-TEMPLATE
      Animated interactive ggplots 175 or 350 Need contributor TD Hocking, Y Fei JavaScript
      Time-dependent constraints in gfpop 350 Need contributor V Runge, G Romano C++
      dirichletprocess improvements 350 Need contributor Dean Markwick, TD Hocking ?
      data.table 175 or 350 Need contributor TD Hocking, A Chetia C
      sundialr-(Package-for-solving-ODEs-in-R) 175 or 350 Need contributor S Nayak C/C++
      r2sbml-(An-interface-to-SBML-in-R) 175 or 350 Need contributor S Nayak C/C++
      torchvision in R improvements 175 or 350 Need contributor C Regouby, TD Hocking C++
      Optimizing a performance testing workflow by reusing minified R package versions between CI runs 175 Need contributor TD Hocking, Ani Shell
      Updates in VedicDateTime R Package 350 Need contributor ND Bokde, A Gupta
      imputeTestbench for multivariate time series 350 Need contributor A Gupta, ND Bokde
      DBmaps R Package Development 175 Need contributor D Shilane, TD Hocking
      grepreaper R Package Development 175 Need contributor D Shilane, TD Hocking grep
      spinebil: Package to provide diagnostics for projection pursuit 350 Need contributor D Cook, J Leung, U Laa
      ecotourism: data package containing tourism records and endangered wildlife reports 350 Need contributor D Cook, L Cook
      Structured covariance matrices for lme4 175 or 350 Writeup in progress B Bolker, E Tanaka, M Jagan possibly some C++
      pandemonium: GUI for cluster analysis with interactive visualization 350 Need contributor U Laa, G Valencia
      Enhancing the Jaya R Package for Efficient Optimization 350 Need contributor V Tiwari, ND Bokde
      Refining the R Dev Container 350 Need contributor H Turner, I Emsley, A Shirdhankar bash
      Project ideas have a ‘Status’ column which describes the current status of mentor and contributor interest. Project ideas where no contributor has yet contacted mentors should be listed as ‘need contributor’. Project ideas where one or more potential contributors are communicating with mentors should have a status of ‘potential contributors’. You can still communicate your interest to mentors to apply to projects with status “potential contributor” – that implies that there is another contributor who has already shown some capability for that project (see below for more details on how we evaluate applications). Projects that need to identify another mentor (e.g. to find a mentor with a specific skill, or from a different institution) should be marked with a status of ‘need mentor’ and the idea page should provide details in the ‘Mentors’ section.
      All contributor applications will be discussed by the R mentor community, and proposals will be ranked considering factors such as quality, difficulty, and impact for the R community. Slots are a finite resource granted to R by Google, and only the best proposals will get chosen. In prior years, R has received 4-5 times more applications than slots, so application quality is key.
      Contributors, if you have an idea for an R package coding project that is not listed above, please try to find mentors by posting a description of your project idea on the r-gsoc google group. If you find mentors, feel free to add your project idea to this wiki. You should NOT submit any project applications to Google without finding TWO mentors for your project proposal.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/r-project-for-statistical-computing/
    idea_list_url: https://github.com/rstats-gsoc/gsoc2025/wiki/table-of-proposed-coding-projects

  - organization_id: 132
    organization_name: RTEMS Project
    no_of_ideas:
    ideas_content: |
      RTEMS is proud to have been in multiple editions of the Google Summer of Code and we are applying to be a participating organization in Google Summer of Code 2025.
      This page is a jumping off point for participating with RTEMS. The best thing you can do for yourself is to join our Discord and ask questions. We want you to be a part of the RTEMS community!
      APPLYING GSOC CONTRIBUTORS MUST FILL OUT A Google APPLICATION
      Potential Contributors:
      Read through all the material on this page.
      The current, unreleased version of the RTEMS development on git is 7.
      Talk to us on Discord or the RTEMS Users Forum. The best place to find answers to common questions is the Users Forum! You can also use the #gsoc channel on our Discord.
      Do not privately message RTEMS community members including mentors. You may publicly ask for permission to speak with someone privately. Private messsages are likely to be ignored.
      We require you to build, modify, and run RTEMS from git. The details are explained in our GSoC Getting Started Guide. Ask on Discord in the #gsoc channel for help.
      Contributors applying to the RTEMS Project will need to fill out an application at Google Summer of Code.
      Pick a project from the list below. This is by no means an all-inclusive list and we are open to suggestions. Submissions of ports to new architectures, new BSPs, new device drivers, and test improvements are always welcomed. Mentors can be reached on Discord.
      The order of projects in the list does not reflect their importance, difficulty, or feasibility. Our project list is not exclusive: if you have an idea, solicit feedback from the project’s Discord. Many developers sit in Discord and check it infrequently throughout the day, so be patient!
      Work with potential mentors to appropriately scope projects for the time available through the program. The project descriptions often require additional knowledge to flesh out a project proposal. Scoping a project is especially challenging as each contributor brings their own experience and capabilities to bear. Since some projects have multiple steps, contributors should work with prospective mentors to define the scope of work in their proposal. Similarly, some projects might be a starting point for a class project or graduate thesis. We generally underspecify our project descriptions for students and new contributors on purpose. The scope that can be accomplished in the timeframe varies depending on individual contributor’s experience and skills. So, we like to let new contributors explore the projects and discuss with potential mentors in order to shape the proposal in a way that suits the contributor’s and mentors’ interests with a scope that is appropriate.
      You might also like to check out our full list of identified projects which has some projects we have not tagged as suitable for GSoC. Some of those projects can be good for beginners. Ask on Discord or the Users Forum!
      Write your proposal using our proposal template.
      Code your heart out and have a great summer!
      
      Large Projects
      PROJECT NAME CREATED UPDATED LANGUAGE
      Add new DOSFS file system to RTEMS 28/02/2025 14/03/2025 lang::c
      Adding I2C, PWM and Mailbox Support to the Raspberry Pi 4B BSP 29/01/2025 14/03/2025 lang::c
      Support Rust std lib on RTEMS 20/01/2025 20/01/2025 lang::rust
      Port TinyUSB to RTEMS. 24/03/2023 18/01/2025 lang::c
      Intel Time Coordinated Computing x86-64 BSP Support 04/12/2022 18/01/2025 lang::c
      Add SATA support in libbsd 11/03/2022 18/01/2025 lang::c
      Integrate Software License Bill of Materials (BOM) using SPDX Tooling 27/02/2022 18/01/2025 lang::python
      Port an OpenGL Implementation to RTEMS 20/02/2022 18/01/2025 lang::python
      Provide SPARC greth Network Drivers for libbsd 09/02/2022 25/01/2025 lang::c
      Provide SPARC greth Network Drivers for lwip 09/02/2022 25/01/2025 lang::c
      Add support for Eclipse Target Communications Framework (TCF) 13/02/2019 25/01/2025 lang::c++
      Google Go run-time library support needs an update 07/12/2016 18/01/2025 lang::go
      Medium Projects
      PROJECT NAME CREATED UPDATED LANGUAGE
      Add packaging options to RTEMS Deployment 15/02/2025 15/02/2025 lang::python
      Add support for C11 Annex K Bounds Checking Functions 29/02/2024 25/01/2025 lang::c
      malloc_info() changes the state of the heap 19/08/2023 25/01/2025 lang::c
      Several arm BSPs cannot build libdebugger with -O0 03/08/2023 25/01/2025 lang::asm
      Add RSB for LLVM targeting RTEMS 25/02/2022 25/01/2025 lang::python
      Codeql Static Analyzer and RTEMS 24/02/2022 18/01/2025 lang::python
      Cobra Static Analyzer and RTEMS 10/02/2022 14/03/2025 lang::python
      Continue support for renode.io Simulator 09/02/2022 25/01/2025 lang::python
      Package Micro Python 19/03/2021 05/03/2025 lang::python
      libbsd: Reduce footprint of minimal buildset 07/01/2021 25/01/2025 lang::c
      MIPS Malta BSP Qemu Support 15/01/2020 25/01/2025 lang::c
      Add Filesystem Benchmarking tools to RTEMS 09/05/2018 28/02/2025 lang::c
      Improve PC386 BSP 06/02/2017 25/01/2025 lang::c
      Small Projects
      PROJECT NAME CREATED UPDATED LANGUAGE
      Remove set_vector() across all architectures and BSPs 15/02/2025 12/03/2025 lang::c
      Tooling Support Needed to Ease Updates to RSB Bset files 25/01/2025 19/02/2025 lang::python
      Add glibc malloc family extension malloc_usable_size() 20/08/2021 25/01/2025 lang::c
      New APIs Added to POSIX Standard (Issue 8) 10/03/2021 24/02/2025 lang::c
      Add support for sigaction SA_RESETHAND 16/06/2020 25/01/2025 lang::c
      Export Issues from Coverity Scan 11/04/2020 25/01/2025 lang::python
      RISC-V libbsd support 05/04/2020 25/01/2025 lang::c
      Tests needed for CLOCK_MONOTONIC 28/02/2020 25/01/2025 lang::c
      Code Formatting and Style Check for RTEMS score 02/02/2020 25/01/2025 lang::c++
      BSP Buildset for EPICS 15/01/2020 18/01/2025 lang::python
      Add Classic API Barrier "get number waiting" Service 21/05/2019 08/03/2025 lang::c
      rtems-test needs a --version option or similar 08/01/2019 23/01/2025 lang::python
      IMFS - Add configurable allocator support 24/07/2018 25/01/2025 lang::c
      IMFS - Improve Bytes Per Block Handling 24/07/2018 25/01/2025 lang::c
      POSIX Compliance 02/04/2017 25/01/2025 lang::c
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/rtems-project/
    idea_list_url: https://projects.rtems.org/gsoc/

  - organization_id: 133
    organization_name: Rizin
    no_of_ideas:
    ideas_content: |
      Home
       » 
      Rizin ❤️ Google Summer of Code
      GSoC 2025
      January 26, 2025
       · Rizin
      Table of Contents
      TL;DR Jump to the Ideas list.
      Introduction
      This year, we participate again, effectively continuing the tradition since 2015.
      Mentors
      Members of the Rizin and Cutter core teams have volunteered to guide participants for GSoC’25. They have already been guiding the participants for the GSoC and RSoC in past years. Please feel free to reach out to any of them if you need any help in selecting a project.
      Anton Kochkov Mattermost: xvilka – @akochkov
      Florian Märkl Mattermost/Telegram: @thestr4ng3r – @thestr4ng3r
      Giovanni Dante Grazioli Mattermost/Telegram: @deroad @der0ad
      And many others
      Development methodology
      Currently, all repositories are hosted on GitHub main organization account and bugs are tracked on GitHub issues too. We are primarily using our own Mattermost instance, IRC, and Telegram) for communication. We have a testsuite (which is running on GitHub Actions, Travis CI, AppVeyor and SourceHut) to test and verify that all the features are still working and that a pull requests or commits don’t break anything, to ensure the support of different operating systems (Linux, MacOS, Windows, FreeBSD, OpenBSD), different architectures (x86/x86_64, ARM64, PowerPC, SystemZ), and to find regressions. We encourage contributors to write test cases and documentation in order to verify the implementation and ensure that everything fits well together. For complex bugs and examples, we’re using ASCIInema to record the sessions.
      See also our guides for corresponding projects:
      Rizin Contributing Guide and Developers Intro
      Cutter Contributing Guide and Developers Intro
      For those who want to get introduced to the Rizin codebase and practices, we recommend to pick one of the easy issues for Rizin or Cutter to start with.
      License
      Rizin is modular: this means that it aims to make all the elements and features easily reusable from other projects. The choice of LGPL3 as a license is the minimum requirement to get code merged in Rizin. Contributors can choose Apache, BSD, MIT, Public Domain, or other similar licenses. The reason to exclude GPL as a valid license for the project is because we aim to support proprietary software that uses Rizin while protecting our free codebase.
      Instructions for participants
      Participants who want to apply to the Rizin project for the Google Summer of Code 2025 are required to submit a small pull request accomplishing one of the microtasks (see below) as part of their application. You can also choose any of the GitHub issues for Rizin if they are big enough to be a qualification task and still small enough to be finished in no more than a couple of weeks. To help participants understand how to contribute to the project, there are issues marked as “good first issue” for both Rizin and Cutter.
      Programming languages
      Most of Rizin is written in C (conforming to the C99 standard), and hence, we expect participants to be familiar with C programming language. For some of our tasks or microtasks, such as rz-pm, they should know the Go programming language. For the Cutter tasks, it is a requirement to know C++ and Qt framework basics.
      Recommended steps
      Read Google’s instructions for participating
      Grab any of the projects from the list of ideas that you’re interested in (or propose your own).
      Write a first draft proposal using Google Docs and our template and ask one of the mentors or administrators to review it with you.
      Submit it using Google’s web interface.
      Participant proposal guidelines
      Keep it simple enough to fit in no more than a couple of pages. Try to be clear and concise in your writing.
      Try to split the entire GSoC period into tasks and each task into subtasks. It helps us understand how you plan to accomplish your goals, but more importantly, it’ll help you understand the task deep enough before starting and prioritize important things to do first.
      Please note how much time a day/week you can spend on this project.
      Please specify which category you apply for - medium task or extended deadline one.
      Specify your timezone so we can assign you a mentor in the same one to ease communication.
      Submit your proposal early, not at the last minute!
      Be sure to choose a “backup” idea (the second task you want to do) so that conflicts (two participants for one task) can be resolved.
      Project Ideas
      Cutter
      Improving usability and user experience (175 hour project)
      The Cutter’s backend provides many features that are not exposed or exposed in Cutter efficiently. The goal of this task would be to figure out the users’ biggest pain points and address them by improving or reworking the interface. Some of the issues are already in our GitHub, while others might be figured during the cross-comparison with other tools.
      Task
      Add a scrollbar to the disassembly and hexdump widgets
      Better syntax highlight and theming
      Managing window/widget overlays
      Add information about status of the analysis, signature searching, and other operations
      Address various small UI problems that make user’s life harder than necessary
      Skills
      The participant should be comfortable with the C++ and be familiar with Qt framework. Basics of the design/UX would be a plus.
      Difficulty
      Advanced
      Benefits for the participant
      The participant will gain an experience of creating comfortable and efficient user interface with C++/Qt.
      Benefits for the project
      It will make interface and user experience more consistent, on par with Rizin itself, and other tools.
      Assess requirements for midterm/final evaluation
      1st term: Add scrollbar to necessary widget, improve theming and syntax highlight
      Final term: Managing widgets layouts, docking; provide action status information
      Mentors
      thestr4ng3r
      xvilka
      Megabeets
      Links/Resources
      User Experience project for Cutter
      User Experience project for Rizin
      Plugins and Python High Level API (175 hour project)
      Our current public API to be used by plugin authors is somewhat limited. We need to improve a lot of things about our Plugins support and take it few steps ahead. This task is only about improving the public C++ and Python interface of Cutter, specifically its graphical user interface components. For a task about exposing Rizin’s API for disassembly, analysis and other purposes, see the Rizin bindings task above.
      Task
      Expose everything Cutter can offer for plugin authors. This includes high level API, integration of the plugin management etc.
      Accessing everything from Python (like Blender) - see issue #1662
      Python integration and IPython console.
      Skills
      The participant should be comfortable with the C++ and Python languages, and be familiar with Qt framework
      Difficulty
      Advanced
      Benefits for the participant
      The participant will gain an experience of creating a suitable API for scripting graphical interface programs.
      Benefits for the project
      It will greatly improve the scripting experience, will make API more consistent and will ease creating Cutter plugins by the community. Moreover, it will simplify testing of the Cutter features.
      Assess requirements for midterm/final evaluation
      1st term: Design of the high level API and required Rizin changes. Review and implement all missing API functions that are accessible as interface controls.
      Final term: Implement the way to show the API when hovered over some interface control, create documentation.
      Mentors
      thestr4ng3r
      Megabeets
      Links/Resources
      SDB Module/API for Cutter Python/Jupyter integration
      Jupyter plugin for Cutter
      Multi-Tasking and Event-driven architecture (350 hour project)
      The information Cutter gets about functions, strings, imports, and the analysis are all performed in Rizin and only displayed in Cutter. Currently, it is pulling most information from Rizin only on demand. This is problematic because sometimes the user performs changes (via plugins, the console widget, and more) that are affecting the information from Rizin, but Cutter doesn’t know about these changes to apply the to the UI. For example, if a user will define a new function in a Python script or via the console widget by using the Rizin command af @ <addr>, Cutter will not show this new function in the Functions widget until the user will refresh the interface manually (Edit -> Refresh Contents). The goal of this task is to use an event-driven architecture to overcome this limitation.
      In addition, this task will also handle the analysis in the background feature, to allow the analysis performed by Rizin to happen while the interface is active.
      Tasks
      The overall implementation of this task should start from Rizin by adding events to many of the functions. This can be done using rz_events. For example, add an even for function creating, for section creation, for flag deletion, for name changed, and more
      Add events to all the relevant functions inside Rizin
      Add support for these events in Cutter and refresh and update the relevant widgets per each event
      Support analysis in the background and allow the user to start its session while Rizin is analyzing (see #1856, #1574)
      Skills
      The participant should be comfortable with the C++ for Cutter and C for Rizin. They should also be familiar with Qt framework. Experience in GUI code architecture, for example using functional reactive programming or Elm-like approaches is a plus.
      Difficulty
      Advanced
      Benefits for the participant
      The participant will gain an experience of creating complex event-driven software in both C and C++ languages.
      Benefits for the project
      It will allow to work on big files effortlessly in Cutter, will improve analysis quality as well.
      Assess requirements for midterm/final evaluation
      1st term: Implement events everywhere in the relevant places across Rizin code and event-driven interaction with Cutter.
      Final term: Add support for the Cutter interface refresh based on the events from Rizin, implement analysis in background.
      Mentors
      thestr4ng3r
      Heap viewer completion (175 hour project)
      Thanks to the work that was done in the previous GSoC, Cutter and Rizin have nice visualizations of the heap and memory maps. We would like to expand on this feature with performance improvements to the heap parsers and support more memory allocators.
      Task
      Complete Cutter’s implementation of the windows heap widget #2723
      Improve the performance of the Windows heap parser
      Fix Windows heap parsing errors
      Make the implementation work with remote debugging modes
      Skills
      The participant should be comfortable with the C++, and be familiar with Qt framework
      Difficulty
      Medium
      Benefits for the participant
      The participant will gain the understanding on how modern runtimes provide the heap for various programs, which will be beneficial for the binary exploitation skills.
      Benefits for the project
      It will greatly improve the debugging and reverse engineering experience for complex programs, also provides the way to design the exploitation techniques with the help of Rizin/Cutter.
      Assess requirements for midterm/final evaluation
      1st term: Design and implement heap visualization widgets, add Rizin test and fixes
      Final term: Various bugfixes related to the heap inspection support on various platforms and allocators, tests and documentation.
      Mentors
      xvilka
      Megabeets
      Links/Resources
      Issue #1041
      Heap Viewer plugin for IDA Pro
      Heap parsing for MacOS, tmalloc, jmalloc
      Dynamic Allocator Detection
      “heap”-marked Rizin issues
      Diffing mode (175 hour project)
      Binary diffing is one of the most common tasks for the reverse engineer. There are many tools available, but most of them are either detached from the main RE toolbox or poorly integrated. Rizin provides basic diffing features out of the box with rz-diff tool, but Cutter has no interface to represent similar functionality.
      Task
      Expose basic rz-diff features in the Cutter
      Create the interface to choose two files for diffing
      Create the way to show the differences in all main widgets:
      Hexadecimal view
      Disassembly view
      Graph view
      Pseudocode view
      Skills
      The participant should be comfortable with the C++ language, and be familiar with Qt framework
      Difficulty
      Medium
      Benefits for the participant
      The participant will gain an experience of creating efficient graphical interfaces.
      Benefits for the project
      It will greatly benefit the project since Cutter will be the only FOSS RE tool to provide this feature out of the box.
      Assess requirements for midterm/final evaluation
      1st term: Expose the rz-diff features in the Cutter core and create the interface for opening files for diffing. Implement the diff modes for hexadecimal and disassembly views.
      Final term: Implement the diff modes for graph and pseudocode views, create the documentation.
      Mentors
      xvilka
      deroad
      Links/Resources
      Issue #1104
      BinDiff
      Diaphora
      Rizin
      Classes analysis for C++/ObjectiveC/Swift/Dlang/Java (350 hour project)
      Analysis classes, accessible under the ac command, is a relatively new feature of rizin. They provide a way to both manually and automatically manage and use information about classes in the binary. But their support is only bare bones, without supporting various analysis integration, as well as display in the disassembly output.
      Consider the following call: call dword [eax + 0x6c] Let’s assume eax is the base pointer of a vtable we have saved in class analysis and we want to find out the actual address of the called method.
      So there should be a command that takes the offset (in this case 0x6c) and looks up the actual destination. It should be possible to call this command with a specific class, so it only looks into its vtable, or without a class, so it gives a list of possible destinations for all vtables that are not too small for the offset.
      When that is implemented, one could also add a command that does the same thing, but automatically takes the offset from the opcode at the current seek.
      Task
      Connecting classes with their methods
      Class inheritance - nesting data structs
      Constructors and destructors autorecognition
      try/catch/finally recognition and marking
      arguments recognition
      ASCII/graphviz graph of class inheritance/structure inheritance
      Tests with sources for C++, FreePascal, D language, ObjC and Swift, for rizin-testbins
      Classes list via Vb. It already supports browsing bin classes. The same thing should be implemented for classes from analysis.
      Skills
      Good knowledge of the C language
      Good knowledge of the C++ language (other languages, like ObjC, Swift, D, etc are a plus)
      Difficulty
      Hard
      Benefits for the participant
      Participant will understand how OOP languages work under the hood, and will master technique of detecting various high level (classes, methods) abstractions in the binary code.
      Benefits for the project
      It will greatly benefit the project to allow efficient reverse engineering of the programs written in C++ and other OOP languages.
      Assess requirements for midterm/final evaluation
      1st term: implement classes integration into the analysis, type inference; detect constructors and destructors, try/catch blocks.
      Final term: Class inheritance recognition, virtual methods detection, building class inheritance graphs, visual mode to inspect classes and methods relationships.
      Mentors
      xvilka
      deroad
      Links and resources
      Improve vtable detection for C++, ObjectiveC, Dlang and Swift binaries - issue #416
      Devirtualize method calls using class vtables - issue #414
      Debugger improvements and portability (175 hour project)
      Rizin debugger already supports most of the platforms, including native and remote debugging. Nevertheless, for most platforms it’s limited mostly to the x86/x86_64 and ARMv8, often lacking the tests. The task would be to add missing architectures to the native debugger, e.g. MIPS to the Linux Native, ARMv7/ARMv8 to the FreeBSD, System Z debugger for Linux, HPPA debugger for Linux, VAX debugger for NetBSD, and so on. Moreover, some information isn’t available during the debugging mode, e.g. source-level breakpoints or names, it would be necessary to make sure debug commands understand those.
      With the help of emulators like QEMU and OpenSIMH we could extend our CI to automatically test these debuggers.
      Task
      Integrated source-level information loaded from DWARF or PDB into debug commands and print p commands
      Support for missing architectures that are supported by Rizin statically in the Linux native debugger
      Support for missing architectures that are supported by Rizin statically in the BSD native debugger
      Cover more platforms supported by the debugger with automated tests, with CI whenever it’s possible
      Fix the bugs in debuggers, minor refactorings of the code
      Skills
      Good knowledge of the C language
      Some experience in debugging with GDB or LLDB
      Difficulty
      Hard
      Benefits for the participant
      Participant will understand how debugging works on the low level, and will gain experience with variety of different platforms and operating systems.
      Benefits for the project
      It will allow efficient low-level debugging on various supported platforms, not only the mainstream ones, greatly improving Rizin’s usefulness in reversing some domain-specific software.
      Assess requirements for midterm/final evaluation
      1st term: `SystemZ, MIPS, HPPA support in Linux native, remote GDB debuggers
      Final term: ARM and SPARC support in *BSD debuggers, VAX support in NetBSD
      Mentors
      xvilka
      thestr4ng3r
      ret2libc
      Links/Resources
      Debug-labeled issues
      RzDebug-labaled issues
      New Platform support
      New Architecture support
      FRIDA integration (175 hour project)
      FRIDA is the famous dynamic instrumentation toolkit that is immensely popular among mobile device researches. Rizin could be easily integrated with Frida by creating a plugin that will allow to connect to the Frida instance, receive traces, set breakpoints, get information and events from it.
      Task
      Create the basic plugin that allows attaching, spwaning, launching processes within Frida loco ally
      Support remote connection
      Add feature to receive information from the Frida instanced
      Add breakpoints and run/step/continue feature’s
      Support calling functions and scripts in the context of the instrumented process
      Skills
      Participant should know C as well as have the experience of working with debuggers.
      Difficulty
      Hard
      Benefits for the participant
      Participant will understand and learn how to use Frida toolkit, also the internals of the debugging and instrumentation processes.
      Benefits for the project
      It will allow easy dynamic code instrumentation right from the Rizin or Cutter session, allowing tracing and code inspection.
      Assess requirements for midterm/final evaluation
      1st term: Implement core of the FRIDA plugin, allowing local and remote debugging features
      Final term: Add support for extended features like calling functions or scripts within the context
      Mentors
      xvilka
      thestr4ng3r
      wargio
      Links/Resources
      FRIDA
      FRIDA (GitHub)
      r2frida
      Exploitation capabilities improvements (175 hour project)
      Since modern architectures are now enforcing W^X, exploiters are using ROP. (Un)fortunately, building ROP chain by hand can be tedious, this is why some tools can be used to ease this construction: ImmunityDBG has mona.py, there is also ROPgadget and dropper.There exist even tools that can generate ROP chains automatically, for example exrop. It’s a shame that despite having RzIL, Rizin doesn’t have something similar yet. One of the possible solutions would be to build an external plugin or tool which will reuse power of librz and rz-gg. Moreover it makes sense to think about SROP, COOP and BROP support.
      The last year (GSoC'24) one of our participants started implementing this feature, but it wasn’t finished. You could check the rz-solver repository for more details.
      Also, the rz-gg tool while has the ability to create a custom shellcode but there is still a lot of work required.
      Task
      Fix rz-gg issues
      Write a compiler which uses SMT solver (like Z3 for example) to produce the ropchain: #4563.
      Support main architectures - x86, ARM, MIPS, PowerPC at the very least
      Skills
      The participant should be comfortable with the C language, know some assembly and a high-level language. Also, knowing a little bit of automatic binary analysis wouldn’t hurt.
      Difficulty
      Advanced
      Benefits for the participant
      The participant will improve their skills in software exploitation and solvers.
      Benefits for the project
      This feature would greatly help during exploits development, and people would be able to ditch mona.py for Rizin ;)
      Assess requirements for evaluation
      1st term: Creating the language for defining the ROP chain semantics and integrating it with SMT solver
      Final term: Working ropchain compiler, covered by tests and documented in the Rizin book.
      Mentors
      xvilka
      ret2libc
      Links/Resources
      ROPGadget
      Ropper
      Angrop
      ROPC
      exrop
      roper2
      mona.py from corelan
      Hunting for ROP Gadgets in Style (2012)
      dropper a BARF-based rop chain generator
      Materials about the exloitation workshop at Hack.lu 2014
      Slides for the exploitation part of workshop at Hack.lu 2015
      RzEgg related bugs
      Binary case reduce tool (175 hours project)
      Similar to Csmith/Creduce but operating on the binary files, to reduce the size of the test and to avoid sharing proprietary/classified files.
      It can perform these operations:
      cut bytes
      shift
      zero/0xFF/mask bytes
      remove section
      Since it requires some knowledge of the file format, existing libraries like LIEF could be used.
      Task
      Make a tool to reduce the size of ELF using specified operations
      Extend it to other formats - PE, MachO
      Create tests for this tool
      Research the possibility of minimizing some testcases that are already in the Rizin repository.
      Skills
      The participant should be comfortable with the C language, as well as the high-level language of a choice (Python or Rust).
      Difficulty
      Advanced
      Benefits for the participant
      The participant will improve their understanding in file formats and their mutation.
      Benefits for the project
      This feature would greatly help in minimizing and anonimizing testcases for the Rizin and any other binary analysis tool.
      Assess requirements for evaluation
      1st term: Create the simple tool to reduce the ELF size
      Final term: Extend it to other formats, improve the “compression” rate, cover with tests.
      Mentors
      xvilka
      deroad
      Links/Resources
      https://github.com/rizinorg/ideas/issues/52
      Microtasks
      When taking any of microtasks please be sure someone isn’t already working on them, and let us know if you are going to work on a particular one.
      Cutter UX improvements
      There are many small issues and missing features that when implemented will improve the user experience significantly:
      Allow adding new flags from hexdump
      Scrollbar inside disasssembly windows
      Variables and values popup widgets on mouse hover
      Allow to set RzRun profiles from the GUI during debugging
      Double-click on the type in Disasm and Graph widgets should switch to the Types windows and show the selected type
      Set breakpoint inside X-Refs window
      Unified dialogue to set debug symbols servers
      See full list at our User Experience project covering all parts of RizinOrg: Rizin, Cutter, RzGhidra, rz-pm.
      File formats
      Implementing the support for any new file format counts as a microtask. See New File-Format label for pending issues.
      Disassemblers and assemblers
      Implementing the support for any new architecture counts as a microtask. See New-Architecture label for pending issues.
      Two notable examples are updating existing bytecode plugins to support newer versions of the respective languages:
      Support for the Lua 5.2 language changes
      Support for the Python 3.11 and 3.12 language changes
      Analysis
      The current code analysis has many caveats and issues which need addressing. Fixing them and writing more tests is important to stabilize and enhance rizin’s analysis engine.
      See these issues on our GitHub dashboard.
      Heap analysis #157
      Currently Rizin has support for heap exploration and analysis, but the feature is still basic and can be improved. Additionally, other allocators can be added (MacOS, tmalloc, etc.), but this should be done after a proper refactoring, because heap analysis shouldn’t depend on the debugger backend, and we may be able to use different heap tools.
      Rizin legacy code refactoring
      Miscellaneous
      rz-ar - code archives unpacking tool
      https://github.com/rizinorg/rizin/issues/4866
      Improving regression suite and testing
      It is required to solve numerous issues, along with improving parallel execution and performance. The next interesting idea is to setup and reuse Godbolt compilation engine for generating tests for different compilers and compilation options. There is even a command line tool for interacting with Godbolt - cce.
      Unbreaking broken tests
      Almost one thousand of tests marked as “broken” in our testsuite. The task is to take any of those, investigate why it fails, if the test makes sense now or already irrelevant today. Then to try to fix some of the broken tests.
      RzGhidra
      There are many small issues in the decompiler output:
      pdgsd commands showing incorrect P-code
      Improvements in recovering jump tables
      rz-ghidra can’t detect string
      Ghidra Decompiler Error: Could not finish collapsing block structure
      Prioritize keeping vars with lower addresses
      Minor improvements for the SLEIGH plugin
      Some of these issues might be related on how Rizin and RzGhidra integrate and might require changes in the Rizin side.
      Also note that most of these issues should be paired with the test to verify it will not break in the future.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/rizin/
    idea_list_url: https://rizin.re/gsoc/2025/

  - organization_id: 134
    organization_name: Rspamd
    no_of_ideas:
    ideas_content: |
      Downloads 
      Documentation
      News
      Usage policies
      Extra services
      Community
      List removal
       GitHub
       Edit
      Donate
      Rspamd project ideas for GSOC 2025
      Introduction
      This page lists project ideas for contributors to Rspamd, particularly for programs like Google Summer of Code (GSoC). We welcome contributors who are passionate about open-source development, email/spam filtering, and modern technologies like AI and Rust.
      Information for GSoC Participants
      Prospective contributors should:
      Have a GitHub account and familiarity with Git workflows.
      Review the Rspamd repository.
      Join our Telegram channel rspamd for discussions.
      Demonstrate proficiency in C (or C++), Lua or Rust (depending on the project).
      All code must be licensed under Apache 2.0.
      Mentors
      Mentor Email Role
      Vsevolod Stakhov vsevolod@rspamd.com Core Development, Admin
      Andrew Lewis alewis@rspamd.com Core Development, Lua plugins development
      Anton Yuzhaninov citrin@rspamd.com Protocols, Integrations
      List of Projects
      Multi-Class Bayesian Classifier
      Description: Extend Rspamd’s Bayesian classifier to support multiple categories (beyond spam/ham) and integrate AI-driven learning via a GPT plugin for dynamic model updates.
      Difficulty: Medium/Hard
      Timeline: 22 weeks
      Skills: Machine Learning (Bayesian methods), Lua, Python (for GPT integration)
      Mentors: Vsevolod Stakhov, Andrew Lewis
      Benefits: Gain expertise in AI/ML integration, probabilistic classifiers, and large-language model APIs.
      Evaluation:
      Midterm: Basic multi-class support in Bayes module; GPT plugin prototype.
      Final: Full integration with GPT for automated learning; performance benchmarks.
      Full Telegram Support (Bot for Spam Filtering)
      Description: Implement integration of with Telegram bot for spam filtering, including rule-based automation (e.g., user reports, admin moderation).
      Difficulty: Medium
      Timeline: 12 weeks
      Skills: Rust (Telegram Bot API), Lua, Rule Engine Design
      Mentors: Andrew Lewis, Anton Yuzhaninov
      Benefits: Learn real-time bot development, protocol integration, and spam rule optimization.
      Evaluation:
      Midterm: Functional Telegram bot with basic spam reporting.
      Final: Advanced rules (e.g., rate limiting, user reputation), moderation UI, and documentation.
      Settings Manager (UI + Rust Backend)
      Description: Build a user-friendly UI for managing Rspamd settings and a Rust-based backend for storing configurations in MySQL/PostgreSQL.
      Difficulty: Medium
      Timeline: 12 weeks
      Skills: Rust, JavaScript/TypeScript (React/Vue), SQL
      Mentors: Andrew Lewis, Vsevolod Stakhov
      Benefits: Master full-stack development, Rust database integration, and secure UI design.
      Evaluation:
      Midterm: Rust backend with CRUD operations; UI prototype.
      Final: Full UI feature set (import/export, versioning), performance optimizations.
      GnuPG Signing and Verification Support
      Description: Enhance Rspamd’s GnuPG support for signing/verifying emails, including key management and policy enforcement.
      Difficulty: Hard
      Skills: C, Cryptography (PGP/GnuPG), Lua
      Timeline: 22 weeks
      Mentors: Vsevolod Stakhov
      Benefits: Deepen knowledge of cryptographic protocols and secure C programming.
      Evaluation:
      Midterm: Basic message signing/verification workflow.
      Final: Key rotation policies, WebUI integration, and attack-resistance testing.
      How to Proceed
      Fork the Rspamd repo and explore the codebase.
      Discuss your proposal with mentors on Telegram or the mailing list.
      Submit a detailed timeline with milestones matching GSoC’s 12-week schedule.
      We value passion, clarity, and realistic planning!
      IRC
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/rspamd/
    idea_list_url: https://rspamd.com/gsoc2025_ideas.html

  - organization_id: 135
    organization_name: SQLancer
    no_of_ideas:
    ideas_content: |
      Contributor Guidance
      When reaching out to us, please understand that we might not respond to overly generic messages that could be sent to any of the GSoC organizations. We appreciate specific and informed requests, thoughts, or ideas.
      To maximize your chance of submitting a successful proposal, we recommend the following:
      Read the GSoC student guide.
      Go through the SQLancer resources, in particular, the CONTRIBUTING.md document as well as the SQLancer YouTube tutorial.
      Join the SQLancer Slack, which is the main means of communication used by the SQLancer developers, and introduce yourself. We also encourage you to share your ideas with us using this platform, so we can support you with your proposal.
      It would significantly strengthen your case if you could show your aptitude by finding an opportunity to create one or multiple PRs. Refactorings would be a low-hanging fruit. For example, you could factor out common functionality in statement generators like in a previous PR for UPDATE SQL statements. As another example, you could update an outdated database system version.
      Projects Ideas
      Adding Grammars to Test New Database Systems
      SQLancer supports close to 20 database systems (see the subdirectories with the relevant database names at src/sqlancer). Adding support for a new database system involves developing generators that generate SQL statements specific to the database system under test. The process of adding a new database system is described in the CONTRIBUTING.md guide.
      Recently, we have developed a new domain-specific language called SQL Generation Language (SGL) which should be used to aid you with this process. SGL takes in a grammar file that describes syntaxes of the target SQL dialect. The language is designed based on ANTLR which describes context-free grammars (to be exact, parser expression grammars) for parsing, on top of which language constructs for maintaining fuzzing contexts and enforcing semantic constraints are added.
      Required skills: Experience with using Git as well as basic SQL knowledge is expected
      Expected size: Either 175 or 350 hour
      Difficulty: Medium
      Expected outcomes: Support for one (or multiple) new database systems as well as reporting of bugs found in that system
      Potential mentors: @albertZhangTJ
      Various additional hints:
      Most implementations use JDBC, which is well-supported by SQLancer.
      To get an idea of what database systems you could consider supporting, the DB-Engines ranking or the Database of Databases might be useful.
      It would be useful to first contact the developers of the database system to check whether they would welcome a testing effort of their system.
      Adding a Feedback-guided Fuzzing Approach
      Currently, the main approach used by SQLancer to generate test cases is generation-based and black-box. The goal of this project is to add mutation-based fuzzing support to SQLancer. To this end, random decisions in the generators (mostly implemented in the Randomly class) should be recorded as seed inputs (so-called decision seeds), and further mutated. Different ways of measuring whether a test input triggers an interesting behavior should be tried and experimented with; for example, query plans are one potential feedback signal.
      Required skills: Strong Java skills are essential and experience with using Git as well as basic SQL knowledge is expected
      Expected size: Either 175 or 350 hour
      Difficulty: Medium
      Expected outcomes: Initial prototype that can be merged into the main SQLancer repository
      Potential mentors: @albertZhangTJ
      Adding support for latest Postgres version
      Today, SQLancer only supports Postgres version 12, which became End-of-Life in Nov 2024. The goal of this project is to advance SQLancer to support the latest version of Postgres, which would involve not just modifying generators to address deprecations and new features launched.
      Changes in a Postgres version can be reviewed in the release notes (for e.g. in order to make SQLancer support version 17 of Postgres, the v17 release notes would highlight the key changes). A stretch goal would be to add support for features, such as additional data-types (JSON), procedural extensions, etc. Additionally, for databases that are already supported by SQLancer, it would be beneficial to extend support to their latest versions.
      Required skills: Strong Java skills are essential and experience with using Git as well as basic SQL knowledge is expected
      Expected size: Either 175 or 350 hour
      Difficulty: Medium
      Expected outcomes: Support the latest version of Postgres (HEAD branch)
      Potential mentors: @robins
      Architecture redesign for SQLancer
      SQLancer has undergone efforts to redesign its architecture to improve reusability of test oracles across different database management systems (DBMSes). However, this effort faced challenges due to incorrect assumptions regarding the DBProvider and DBConnection components. For example, the majority of DBMSes have a JDBC implementation, but CnosDB does not, requiring the development of a custom client. This means that common test oracle will not work in such cases.
      The goal of this project is to design and implement a common connection mechanism that will standardize how oracles send and receive data from DBMSes. By doing so, we aim to reduce code duplication, simplify the integration of new DBMSes, and facilitate further development in SQLancer. Additionally, we aim to continue the creation of common test oracles, particularly by expanding on the subtypes of Ternary Logic Partitioning (see implementation for Postgres).
      Required skills: Moderate Java programming skills and Unix/Linux familiarity. SQL knowledge is not necessary
      Expected size: 175 hours
      Difficulty: Medium
      Expected outcomes: A unified connection component and more implementations of common test oracles
      Potential mentors: @malwaregarry
      Supporting Automated Scripts for DBMS Deployment
      SQLancer is a tool to automatically test Database Management Systems, but setting up the corresponding DBMS instances for testing demands significant manual effort. Beginners often find it challenging to navigate the process, which involves carefully reading documentation to build and start the server, followed by configuring SQLancer to initiate fuzzing.
      The goal of this project is to develop a suite of automation scripts that streamline the entire process: automatically building DBMSs, starting them, configuring SQLancer, and launching tests. Docker is a potential solution. Additionally, providing these unified deployment scripts can make the bug reproduction both simpler and more reliable.
      Required skills: Moderate Docker and Unix/Linux familiarity. SQL or Java knowledge is not necessary
      Expected size: Either 90 or 175 hours
      Difficulty: Easy
      Expected outcomes: Scripts to deploy the DBMS and start SQLancer testing
      Potential mentors: @suyZhong
      Automating Testing Workflow of SQLancer
      SQLancer supports close to 20 database systems (see the subdirectories with the relevant database names at src/sqlancer); however, testing a new DBMS demands manual tasks such as building the system, starting the DBMS server, running SQLancer to execute tests, and subsequently reporting any discovered bugs.
      To address these challenges, the project will design and implement an intelligent automation tool--potentially leveraging a large language model (LLM) agent--that delivers a push-button testing procedure. This tool will automatically build and initiate the DBMS server according to its documentation, run SQLancer tests, and generate bug reports automatically.
      Required skills: Moderate Python programming skills, Docker and Unix/Linux familiarity. SQL or Java knowledge is not necessary
      Expected size: 350 hours
      Difficulty: Hard
      Expected outcomes: An LLM agent that can automatically deploy the DBMS and start SQLancer testing
      Potential mentors: @suyZhong
      Integrating Published Testing Approaches into SQLancer
      Various effective automated testing approaches for database systems such as Differential Query Execution (DQE) have been published, but not integrated into SQLancer. The goal of this project is to integrate DQE and potentially also other testing approaches into SQLancer.
      The integration should happen while minimizing invasive changes to the existing architecture and aiming to make it easier to integrate future approaches. Thus, this project will require understanding SQLancer's architecture and how existing approaches could be elegantly integrated.
      Required skills: Java programming skills. SQL knowledge is not necessary
      Expected size: 175 hours
      Difficulty: Medium
      Expected outcomes: Integration of DQE and potentially other automated testing approaches
      Potential mentors: @JensonSung
      Enhancing SQLancer with External Reducer Support
      This project aims to improve SQLancer’s test reduction framework by enabling seamless integration of external reducers. Currently, SQLancer includes an experimental delta-debugging approach using StatementReducer and ASTBasedReducer, but these components are tightly coupled, making it difficult to incorporate alternative reducers. Previously, SQLancer used C-Reduce, which required specifying the test oracle in a script.
      To address these limitations, this project will introduce a flexible interface that allows different test reducers to be easily integrated and configured. This will enable SQLancer to support a wider range of database engines while allowing users to switch between reduction strategies as needed. Additionally, the project will refine both the Delta Debugging (DD) and AST-Based Reducer by incorporating Hierarchical Delta Debugging (HDD) as a preprocessing step. This will enable an initial hierarchical grouping of test cases to simplify the input space before applying both DD and AST-based reductions, improving the efficiency and effectiveness of the bug-reduction process.
      Objectives:
      Develop a modular interface for integrating external reducers.
      Improve SQLancer’s existing AST-based reduction and DD with HDD preprocessing.
      Enable seamless integration of reducers like C-Reduce and Perses.
      Required Skills: Strong Java and SQL skills are essential and experience with using Git.
      Expected size: Either 175 or 350 hour
      Difficulty: Medium
      Expected Outcome: A flexible and efficient test reduction system in SQLancer, enabling easy integration of external reducers and improving both DD and AST-based reductions through Hierarchical Delta Debugging (HDD).
      Potential mentor: @kabilanma
      Additional links:
      Using C-Reduce with SQLancer: https://www.youtube.com/watch?v=vkfdYyn40Qw
      HDD: https://users.cs.northwestern.edu/~robby/courses/395-495-2009-fall/hdd.pdf
      C-Reduce: https://github.com/csmith-project/creduce
      Perses: https://github.com/uw-pluverse/perses
      DD: https://www.debuggingbook.org/html/DeltaDebugger.html
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/sqlancer/
    idea_list_url: https://github.com/sqlancer/sqlancer/wiki/GSoC-2025-Ideas


  - organization_id: 136
    organization_name: SW360
    no_of_ideas:
    ideas_content: |
      GSoC Idea List - 2025
      Welcome to the idea page for all GSoC 2025 related information.
      Check https://github.com/eclipse-sw360/sw360/discussions/2868
      Intro
      SW360 project has been selected as a mentoring Org with GSoC 2025. Thank you, Google!
      Please see two main resources for finding out more SW360 in general:
      Check https://eclipse.dev/sw360/ and development and deployment section.
      Try to install SW360 from source or your can try the Docker
      Meetings: Checkout the Meetings table
      Interested in Application? - Getting Grip
      If you are interested in an application - great! We encourage your application. So the question is how to get started with the topic, just a few points:
      Check https://eclipse.dev/sw360/docs/ for development and operational guides.
      Check the frontend project for UI: https://github.com/eclipse-sw360/sw360-frontend
      Try to install SW360, either from source or Docker
      https://github.com/eclipse-sw360/sw360/blob/main/docker-compose.yml
      Read the proposed topics
      Use the mailing list sw360-dev@eclipse.org or contact proposed mentors for further steps.
      Matrix group
      GitHub discussion
      If you are interested in trying to make contributions, see contribution guidelines.
      Mentors
      Interested in becoming a mentor? Please reach out to us!
      Volunteers so far:
      Akshit Joshi
      Amrit Kumar Verma
      Arun Azhakesan
      Gaurav Mishra
      Helio Chissini de Castro
      Katharina Ettinger
      Keerthi BL
      Kouki Hama
      Rudra Chopra
      Topic Proposals
      Please reach out to us to add more proposals for GSoC 2025.
      Currently, discussion happening on https://github.com/eclipse-sw360/sw360/discussions/2868
      Topic Proposals from 2025
      License Change Detection
      Improve integration with FOSSology
      Thrift layer removal
      Improve tests for all REST API endpoints
      SBOM based recommendation
      Creating Project as a Service
      []
      License Change Detection
      Goal: Understand the changes in licensing between two versions of a software package.
      This would be combined effort between SW360 and FOSSology.
      As the software evolves in time, so does their licensing. A scenario where a package (say “mylib-v1.2”) was scanned by FOSSology and cleaned by a clearing team. The new version of the package (say “mylib-v1.5”) was released and uploaded again to FOSSology for clearing. Now, another metric can be generated showing the files from both packages against the change in licensing per file (addition, removal, change of license or new file).
      This either can be shown in FOSSology itself, but also when doing an initial scan report (ISR), triggered from SW360. Then it would be very visible for the requester if there are changes in the new version of the release or not. Also, the diff could be shown in the CLI files.
      It can generate a table like:
      File path mylib-v1.2 mylib-v1.5
      path/to/file MIT MIT
      path/to/file2 MIT,BSD MIT
      path/to/file3 GPL-2.0 GPL-3.0
      path/to/new-file BSD
      Category Rating
      Low Hanging Fruit **
      Risk/Exploratory *
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure **
      Project size Medium
      Preferred contributor Student/professional
      Skills needed XML, Java
      Contact @EttingerK @GMishx
      Improve integration with FOSSology
      Goal: Use extended REST API of FOSSology to improve the “Send to FOSSology” feature
      SW360 already have ways to interact with FOSSology, however the interaction as of now is very limited. The idea is to expand on this interaction and make use of extended REST API of FOSSology and have features like:
      Upload source to FOSSology
      Search and link to existing sources with checksum match
      Reuse previous version of release uploaded/existing in FOSSology
      Provide option to select agents for scanning in FOSSology
      Fetch different kind of reports from FOSSology, not just SPDX
      Relevant information:
      FOSSology REST API: https://github.com/fossology/fossology/blob/master/src/www/ui/api/documentation/openapiv2.yaml
      SW360 existing endpoints: releases/{id}/checkFossologyProcessStatus
      SW360 existing endpoints: releases/{id}/triggerFossologyProcess
      Category Rating
      Low Hanging Fruit ***
      Risk/Exploratory **
      Fun/Peripheral ***
      Core Development **
      Project Infrastructure **
      Project size Large
      Preferred contributor Student/professional
      Skills needed Java, REST & HTTP libraries
      Contact @GMishx, @rudra-superrr
      Thrift layer removal
      Goal: Remove thrift layer for communication with Database
      Remove thrift layer which is used to interact with DB as it is not required and makes the installation process of SW360 unnecessarily complex. This change will help project moving forward with modern architectures like microservices.
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory ***
      Fun/Peripheral **
      Core Development ***
      Project Infrastructure **
      Project size Large
      Preferred contributor Student/professional
      Skills needed Java, CouchDB
      Contact @GMishx @smrutis1 @heliocastro
      Improve tests for all REST API endpoints
      Goal: Improve existing tests for all REST API endpoints and write new tests
      Write unit and integration tests for all REST API endpoints. This will help in improving the code quality and make the project more robust.
      Category Rating
      Low Hanging Fruit ***
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development ***
      Project Infrastructure **
      Project size Medium
      Preferred contributor Student/professional
      Skills needed Java, JUnit, REST API
      Contact @GMishx @heliocastro @keerthi-bl
      SBOM based recommendation
      Goal: Recommendation of packages based on SBOM of a project
      When a user imports a SBOM file, the tool will share the information about the cleared & uncleared packages used in that project based on existing knowledge available in SW360. In addition to that if any package is uncleared,
      The tool will recommend equivalent package, which is already cleared in SW360, which in turn will reduce the project clearing time.
      If the user still wants to use the same uncleared package, the tool will give an estimated time to clear the package as well as the project using reports like ISR.
      Category Rating
      Low Hanging Fruit **
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development **
      Project Infrastructure **
      Project size Large
      Preferred contributor Student/professional
      Skills needed Java, Python, AI/ML
      Contact @amritkv @GMishx
      Creating Project as a Service
      Goal: Separate out the Project and related modules as a separate microservice
      The idea is to separate the Project related modules as a separate microservice which can then be customized independently for different organizations while still reusing the common Component repository.
      Category Rating
      Low Hanging Fruit *
      Risk/Exploratory ***
      Fun/Peripheral ***
      Core Development *
      Project Infrastructure ***
      Project size Large
      Preferred contributor Student/professional
      Skills needed Java, Spring, Microservices, REST
      Contact @keerthi-bl @GMishx @heliocastro
      Update Official Documentation Page
      Goal: Separate out the Project and related modules as a separate microservice
      Motivation
      The current official documentation page (https://eclipse.dev/sw360/) lacks clear instructions regarding environment configurations and upgrade procedures for recent software versions. This discrepancy often confuses users and negatively affects productivity during installation or updating processes. Keeping the official documentation accurate and up-to-date helps attract new users and fosters an active user community. Moreover, documentation updates do not require direct changes to the software source code, allowing contributors to undertake this task concurrently with other development or testing activities, thus lowering the barriers for OSS contributions.
      Proposed Changes
      Clearly document environment setup instructions and upgrade procedures corresponding to the latest software versions.
      Complement missing details in documentation, such as updates to dependencies and version compatibility, reducing user confusion.
      Enhance visual clarity by adding practical examples and screenshots illustrating the updated procedures.
      Notes
      This task involves no source code modifications, making it easy to execute alongside other development tasks or community activities.
      Documentation updates are valuable contributions to OSS projects and serve as excellent entry points for new contributors.
      It is advisable to explicitly recognize documentation maintenance as a significant and formally acknowledged form of OSS contribution.
      Category Rating
      Low Hanging Fruit ***
      Risk/Exploratory *
      Fun/Peripheral **
      Core Development *
      Project Infrastructure ***
      Project size Medium
      Preferred contributor Student/professional
      Skills needed Markdown, Hugo
      Contact @GMishx @heliocastro @KoukiHama
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/sw360/
    idea_list_url: https://eclipse.dev/sw360/gsoc/gsoc-projects-2025/


  - organization_id: 137
    organization_name: SageMath
    no_of_ideas:
    ideas_content: |
      This website is down for maintenance, please come back later (~7h expected downtime, until 20:00 Europe/Paris).
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/sagemath/
    idea_list_url: https://wiki.sagemath.org/GSoC/2025

  - organization_id: 138
    organization_name: Scala Center
    no_of_ideas:
    ideas_content: |
      In this document, you can find a list of ideas that are proposed by the Scala Organisation for Google Summer of Code 2025.
      Application
      If you are interested in becoming a contributor on any idea, please reach out to your potential mentor using their email address specified with the project. You can also reach Scala Center at scala-gsoc(at)epfl.ch.
      If you would like to be a mentor and propose your own idea, please submit a PR editing this file (e.g. see 2024's projects), adding your project to the list, following the format of other projects below.
      Rules
      You can read the full rules of the program at the following links: Rules, Terms and Conditions, Help.
      And here are the requirements for the potential contributor's proposal: Writing a proposal.
      However, here are some rules that we'd like to emphasize since they are not visible enough at the above links:
      The program is geared towards beginners first and foremost. It is intended to be a learning experience for people at the very beginning of their careers. It is also intended to give an opportunity to people who would otherwise not have one. It is NOT a freelance job. Therefore, when making an acceptance decision on a potential contributor, we will prioritize disadvantaged backgrounds and contributors at the very beginning of their careers.
      IMPORTANT - EPFL Students: Please note that, according to GSoC rules, there are restrictions on accepting students from an organization's host university. For Scala Center, the host university is EPFL. We can only accept up to 1 student from EPFL, so please take it into account if you're studying at EPFL and consider applying.
      Project Ideas
      Doodle Bitmap Convolutions
      Title Doodle Bitmap Convolutions
      Link to Project creativescala/doodle#94
      Brief Description Add support for bitmap convolutions to Doodle. The link has more, including a Github project laying out the steps.
      Expected Outcome Working code and documentation.
      Prerequisites Some Scala knowledge.
      Ideal Prerequisites Basic knowledge of bitmap convolutions, some understanding of tagless final.
      Expected Difficulty Easy – straightforward task, path for execution visible right now, very little uncertainty
      Expected Time Commitment Medium project – 175 hours
      Mentor Noel Welsh (GitHub: @noelwelsh, Email: noel@noelwelsh.com)
      Co-mentor
      Doodle Skia Backend
      Title Doodle Skia Backend
      Link to Project creativescala/doodle#175
      Brief Description Add a Skia backend for Doodle, using the Skiaj bindings.
      Expected Outcome Working code and documentation.
      Prerequisites Some Scala knowledge.
      Ideal Prerequisites Some understanding of type classes or tagless final.
      Expected Difficulty Easy – straightforward task, path for execution visible right now, very little uncertainty
      Expected Time Commitment Medium project – 175 hours
      Mentor Noel Welsh (GitHub: @noelwelsh, Email: noel@noelwelsh.com)
      Co-mentor
      Krop Template Engine
      Title Krop Template Engine
      Link to Project creativescala/krop#14
      Brief Description Create an HTML template engine for the Krop web framework.
      Expected Outcome Working code and documentation.
      Prerequisites Intermediate Scala knowledge and basic HTML knowledge.
      Ideal Prerequisites An understanding of parsing.
      Expected Difficulty Medium – some design decisions need to be made and the implementation is not straightforward.
      Expected Time Commitment Medium project – 175 hours
      Mentor Noel Welsh (GitHub: @noelwelsh, Email: noel@noelwelsh.com)
      Co-mentor
      Business4s: Workflows4s Web UI
      Title Workflows4s Web UI
      Link to Project https://github.com/business4s/workflows4s
      Brief Description Implement web user interface for Workflows4s. Design the API and implement both server and web side using scala and scala.js. See business4s/workflows4s#19 for details.
      Expected Outcome Proof of concept of the UI that can present progress of a workflow instance.
      Prerequisites Basic scala skills, basic frontend skills, basic knowledge of HTTP APIs (e.g. REST).
      Expected Difficulty Medium
      Expected Time Commitment Large project - 350 hours
      Spoken Language English
      Mentor Voytek Pituła (GitHub: @Krever, Email: w.pitula@gmail.com)
      Co-mentor Dave Smith (Github: @davesmith00000, Email: david.smith@purplekingdomgames.com)
      Business4s: ChatOps4s Prototype
      Title ChatOps4s Prototype
      Link to Project To be created under https://github.com/business4s
      Brief Description Prototype of library/toolkit allowing to easily send messages and receive input from chat platforms (e.g. Slack)
      Expected Outcome Prototype that allows getting information in and out Slack with as little effort as possible. Research on how hard will it be to support other platforms.
      Prerequisites Ability to research and consume external APIs. Basic exposure to some chat platform (Slack, Discord, MS Teams)
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Voytek Pituła (GitHub: @Krever, Email: w.pitula@gmail.com)
      Co-mentor -
      Play Framework Support in Metals
      Title Play Framework Support in Metals
      Link to Project scalameta/metals-feature-requests#50 scalameta/metals-feature-requests#89
      Brief Description Add support for Play Framework specific files in Metals language server
      Expected Outcome Working code and documentation.
      Prerequisites Intermediate Scala knowledge and basic HTML knowledge.
      Ideal Prerequisites An understanding of parsing and language server protocol.
      Expected Difficulty Medium – some design decisions need to be made and the implementation is not straightforward.
      Expected Time Commitment Medium project – 175 hours
      Mentor Tomasz Godzik (GitHub: @tgodzik, Email: tomek.godzik@gmail.com)
      Co-mentor
      Cyfra: Support for basic GPU computations on data streams with fs2 integration
      Title
      Link to Project https://github.com/ComputeNode/cyfra
      Brief Description Cyfra is a GPU runtime and a DSL that makes Scala a viable choice for GPU programming. Goal of the project is to implement support for GPU computations on data streams with focus on usability.
      Expected Outcome Cyfra should enable developers that do not have background in GPU programming to write a simple data processing pipeline in Cyfra that performs compute on GPU and efficiently manages memory. The pipeline should be interoperable with fs2.
      Prerequisites Some experience with Scala, and interest to learn a bit about GPUs.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Szymon Rodziewicz (LinkedIn, Github: szymon-rd, Email: szymonrodant@gmail.com)
      Co-mentor -
      Cyfra: Real-time rendering pipeline
      Title
      Link to Project https://github.com/ComputeNode/cyfra
      Brief Description Cyfra is a GPU runtime and a DSL that makes Scala a viable choice for GPU programming. Goal of the project is to implement a basic real-time Vulkan rendering pipeline.
      Expected Outcome Cyfra should enable developers to create programs that will render scenes from a basic one-step Vulkan pipeline in real time. It should support rendering to a window, a data stream, and a file.
      Prerequisites No Scala experience is required, but basic experience with GPU programming would be helpful.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Szymon Rodziewicz (LinkedIn, Github: szymon-rd, Email: szymonrodant@gmail.com)
      Co-mentor -
      Cyfra: Real time SDF editor
      Title
      Link to Project https://github.com/ComputeNode/cyfra
      Brief Description Cyfra is a GPU runtime and a DSL that makes Scala a viable choice for GPU programming. Goal of the project is to implement a real-time SDF (signed distance fields) editor as a VSCode extension.
      Expected Outcome Cyfra vscode extension should be tool that would allow its users to render 3D SDF-based scenes and see changes in their code reflected in the output in real time.
      Prerequisites Some experience with Scala or TypeScript, and interest to learn a bit about GPUs, Scala, and VSCode extension development.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Szymon Rodziewicz (LinkedIn, Github: szymon-rd, Email: szymonrodant@gmail.com)
      Co-mentor -
      Cyfra: Scala Native MVP
      Title
      Link to Project https://github.com/ComputeNode/cyfra
      Brief Description Cyfra is a GPU runtime and a DSL that makes Scala a viable choice for GPU programming. Goal of the project is to make it run on Scala Native.
      Expected Outcome Fundamental features of the cyfra library should run on Scala Native and make it possible to build efficient real-time rendering and data processing applications.
      Prerequisites Some experience with Scala, and interest to learn a bit about GPUs.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Szymon Rodziewicz (LinkedIn, Github: szymon-rd, Email: szymonrodant@gmail.com)
      Co-mentor -
      Scala Native / Scala.js Projects
      Title Scala Bazel Rules for Scala.js and Scala Native
      Link to Project https://github.com/bazelbuild/rules_scala
      Brief Description This project aims to develop Bazel build rules for Scala.js and Scala Native, enabling efficient and reproducible builds for both platforms. The project will provide first-class support for Scala projects within the Bazel ecosystem, improving integration and developer experience.
      Expected Outcome Functional and well-documented Bazel rules that allow compiling, testing, and packaging Scala.js and Scala Native projects. Demonstration projects showcasing usage.
      Prerequisites Experience with Scala, build tools (SBT, Bazel), and Scala.js/Scala Native basics. Some familiarity with Bazel rule definitions is a plus.
      Expected Difficulty Medium
      Expected Time Commitment Large project - 350 hours
      Mentor Wojciech Mazur (GitHub: @WojciechMazur, Email: wmazur@virtuslab.com)
      Co-mentor TODO
      Title JMH-Compliant Benchmarking Framework for Scala Native & Scala.js
      Link to Project Scala Native / Scala.js
      Brief Description This project aims to implement a benchmarking framework similar to JMH (Java Microbenchmark Harness) allowing for accurate and reliable performance measurements on non JVM platforms. Both Scala Native and Scala.js cannot consume a modified JVM bytecode emitted by JMH framework. The goal is to create a runtime implementation for executing microbenchmarks and a Scala compiler plugin performing required transformations of Scala.js / Scala Native code based on JMH framework compiletime annotations.
      Expected Outcome A benchmarking framework that mimics JMH APIs and produces reliable results for Scala Native and Scala.js. Demonstration benchmarks showcasing usage.
      Prerequisites Good understanding of benchmarking principles, Scala Native, Scala.js, and Scala compiler plugins. Some knowledge of JMH is beneficial.
      Expected Difficulty Hard
      Expected Time Commitment Medium project - 175 hours
      Mentor Wojciech Mazur (GitHub: @WojciechMazur, Email: wmazur@virtuslab.com )
      Co-mentor Sébastien Doeraene (GitHub: @sjrd, Email: sjrdoeraene@gmail.com )
      Scala Native Projects
      Title Incremental Optimization of Scala Native IR
      Link to Project Scala Native
      Brief Description This project aims to implement incremental optimization for Scala Native’s Intermediate Representation (IR), improving compilation speed by reusing results from previous compilation runs instead of optimizing the entire program from scratch.
      Expected Outcome A working prototype of an incremental optimization pipeline for Scala Native IR, with measurable speedups over full optimizations.
      Prerequisites Strong understanding of compilers, Scala Native IR, and optimization techniques. Knowledge of LLVM and incremental compilation strategies is a plus.
      Expected Difficulty Hard
      Expected Time Commitment Large project - 350 hours
      Mentor Wojciech Mazur (GitHub: @WojciechMazur, Email: wmazur@virtuslab.com )
      Co-mentor Sébastien Doeraene (GitHub: @sjrd, Email: sjrdoeraene@gmail.com )
      Difflicious UI
      Title Difflicious UI
      Link to Project https://github.com/jatcwang/difflicious
      Brief Description Implement a Web UI for Difflicious which allows users to explore diffs (test failures) reported by Difflicious. The UI should allow the user to expand and minimize section of the diff output in an interactive manner.
      Expected Outcome Working UI and documentation
      Prerequisites Good working knowledge of Scala and web technologies (Javascript, CSS, HTML). The project will be implemented in Scala.js (most likely with Laminar
      Expected Difficulty Hard
      Expected Time Commitment Large project - 350 hours
      Spoken Language English
      Mentor Jacob Wang (GitHub: @jatcwang, Email: jatcwang@gmail.com)
      Difflicious: Differ for Json type
      Title Difflicious: Differ for Json type
      Link to Project https://github.com/jatcwang/difflicious
      Brief Description Implement a differ which supports JSON types from popular Scala libraries (e.g. Circe). The current sealed trait Differ will be completely reworked to support any general disjoint union.
      Expected Outcome A differ that can diff two two io.circe.Json values
      Prerequisites Good working knowledge of Scala
      Expected Difficulty Hard
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Jacob Wang (GitHub: @jatcwang, Email: jatcwang@gmail.com)
      A Pandas Experience
      Title One line CSV import in scala
      Link to Project https://github.com/Quafadas/scautable
      Brief Description Python through Pandas has a great data import experience. This project aims to replicate parts of that by parsing parts of the datasource at compile time, i.e. bringing knowledge of the structure and headers of your datasource inside the compilers knowledge. It's goal is to help you discover your data, rather than force to you to write out it's metadata in advance. It's target audience will be writing non production, data sciency type scripts. Many of the motivating examples come from kaggle.com
      Expected Outcome Can be measured in the increased number of successful test cases. I believe the "fundamental" idea has legs, but is currently limited to a small number of scenarios explored in my free time. The goal of the project is to expand the set of scenarios in which it is useful. Initial easy issues surround details such as correctly parsing headers, checking special characters, improving error messages and writing data back to (e.g. CSV). From there it should be possible to graduate to adding more datasources, for example SQL (hopefully simple - or harder, for example exploring apache parquet.) Stretch goals could include exploring strategies for streaming statistics, deriving visualisations, critiquing the design vs e.g. Kantan.csv, and / or attempting to help the consumer identify the "types" of the data at compile time.
      Prerequisites Basic scala / java knowledge. The barrier to "getting started" ought to be rather low. The initial issues are largely detail driven rather than design driven. Basic experience with testing (munit), CI (GHA) and scala standard library would be enough to contribute.
      Expected Difficulty Easy
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Simon Parten (GitHub: @quafadas, Email: quafadas@gmail.com)
      Co-mentor Volunteers wanted here too I guess :-)
      Scalus – Scala 3 compiler backend and DApps development platform for Cardano
      Title
      Link to Project https://github.com/nau/scalus
      Brief Description Scalus is a platform for developing full-stacke decentralized applications (DApps) on the Cardano blockchain using a single language, Scala 3, tools and code for frontend, backend and smart contracts development. Scalus implements a Scala 3 compiler backend that compiles Scala to Cardano Plutus Core – a lambda calculus inspired smart contracts language.
      Expected Outcome Enable more Scala 3 features to be compiled to Plutus Core: arbitrary size Tuples, better pattern-matching conversion algorithm. Improvements in our code generator, and various lambda calculus optimizations: inliner, common subexpression eliminator etc. We also expect improvements in Scalus standard library, test coverage and documentations.
      Prerequisites Basic Scala knowledge. Basic understanding of compiler theory and blockchain technology is a plus.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Alex Nemish Github, Email: anemish@gmail.com
      Co-mentor Ruslan Shevchenko. Github Email: ruslan@shevchenko.kiev.ua
      Scaladex: Support for Compiler Plugins
      Title Scaladex: Support for Compiler Plugins
      Link to Project https://github.com/scalacenter/scaladex/
      Brief Description Add support for compiler plugins in Scaladex, the index website of open source Scala artifacts. Adapt the UI of the front page, search page and project page to allow searching, and browsing compiler plugins and their versions. See full description in scalacenter/scaladex#865
      Expected Outcome Scaladex should index compiler plugin artifacts, such as org.typelevel:kind-projector_2.13.16:0.13.3. It should show them as a separate platform on the front page, search page and project page.
      Prerequisites Some experience with Scala and SQL. Good knowledge about HTML and css
      Ideal Prerequisites Some knowledge of the Scala ecosystem, such as Scala platforms and binary versions
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Kannupriya Kalra (LinkedIn, Email: kannupriyakalra@gmail.com)
      Co-mentor Adrien Piquerez (GitHub: @adpi2, Email: adrien.piquerez@gmail.com)
      LLM4S - Implement an agentic toolkit for Large Language Models
      Title LLM4S - Implement an agentic toolkit for Large Language Models
      Link to Project https://github.com/rorygraves/llm4s
      Brief Description LLM4S is creating a Large Language Model (LLM) toolkit for Scala. This project uses the power of Scala to make building LLM based applications easier. LLMs can be used in an agentic style where the LLM is allowed to call provided tools to access resources (such as reading a webpage, or calling an API service to perform a task). The goal of this project is to implement an agentic loop and basic tools supporting infrastructure within the toolkil.
      Expected Outcome LLM4S should have an agentic LLM toolkit wtih, documentation, examples and basic tools such as file and webbrower usage to allow users to immediately start building agentic style applications.
      Prerequisites Some exerience of Scala and LLMs.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Kannupriya Kalra (LinkedIn, Email: kannupriyakalra@gmail.com)
      Co-mentor Rory Graves (LinkedIn, Email: rory.graves@fieldmark.co.uk)
      LLM4S - RAG in a box
      Title LLM4S - RAG in a box
      Link to Project https://github.com/rorygraves/llm4s
      Brief Description LLM4S is creating a Large Language Model (LLM) toolkit for Scala. This project uses the power of Scala to make building LLM based applications easier. Beyond simple chat use cases we want to make it easy to build LLM based apps. One of the most common facilities is RAG (Retrieval Augmented Generation) where documents are chunked and embedded and then retrieved to provide context to the question being asked. The goal is to extend the LLM framework with RAG tools to make building RAG Search easy.
      Expected Outcome LLM4S should have a RAG framework which allows integration with an embedding store. The framework should support pushing documents into external stores (e.g. Postgress with pgVector or Azure AI Search Service) and implement RAG search over the top of the store, and include documentation, examples.
      Prerequisites Some exerience of Scala and LLMs.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Kannupriya Kalra (LinkedIn, Email: kannupriyakalra@gmail.com)
      Co-mentor Rory Graves (LinkedIn, Email: rory.graves@fieldmark.co.uk)
      LLM4S - Support image, voice and other LLM modalites
      Title LLM4S - Support image, voice and other LLM modalites
      Link to Project https://github.com/rorygraves/llm4s
      Brief Description LLM4S is creating a Large Language Model (LLM) toolkit for Scala. This project uses the power of Scala to make building LLM based applications easier. LLMs support a number of modalities other than chat, e.g., image generation, voice and embeddings. The goal of this project is to extend the API created in LLM4S to create APIs for calling these other use cases.
      Expected Outcome As well as chat, LLM4S LLM interface should now have support for image, voice (speech to text and text to speech) and embeddeding, giving users access to more usecases. As well as the API, we will provide examples and documentation.
      Prerequisites Some exerience of Scala and LLMs.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Kannupriya Kalra (LinkedIn, Email: kannupriyakalra@gmail.com)
      Co-mentor Rory Graves (LinkedIn, Email: rory.graves@fieldmark.co.uk)
      LLM4S - Tracing Support
      Title LLM4S - Tracing support
      Link to Project https://github.com/rorygraves/llm4s
      Brief Description LLM4S is creating a Large Language Model (LLM) toolkit for Scala. This project uses the power of Scala to make building LLM based applications easier. As LLM based apps grow it becomes harder to understand the application and LLM interaction flow. We want to add tracing support into the application and a UI allowing exploration of the application traces, showing the calls, spans, timing and other information to help understand the flow.
      Expected Outcome An exampling tracing feature within the core of LLM5S that emits tracing data consumable by a created UI to allow a user to follow the execution flow of a user developed application.
      Prerequisites Some exerience of Scala and LLMs.
      Expected Difficulty Medium
      Expected Time Commitment Medium project - 175 hours
      Spoken Language English
      Mentor Kannupriya Kalra (LinkedIn, Email: kannupriyakalra@gmail.com)
      Co-mentor Rory Graves (LinkedIn, Email: rory.graves@fieldmark.co.uk)
      Template
      Title
      Link to Project Provide a link to a website or a Git repository of your project.
      Brief Description Please describe in a few sentences what the project is about.
      Expected Outcome Specify the success criteria for the project. What are the deliverables, how do you know that it is done?
      Prerequisites What minimal skills and knowledge the contributor needs to have to succeed on this project?
      Expected Difficulty Easy, Medium of Hard
      Expected Time Commitment Can be either: "Medium project - 175 hours" or "Large project - 350 hours"
      Spoken Language English
      Mentor FirstName LastName (GitHub: @foo, Email: foo@gmail.com)
      Co-mentor FirstName LastName (GitHub: @foo, Email: foo@gmail.com)
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/scala-center/
    idea_list_url: https://github.com/scalacenter/GoogleSummerOfCode

  - organization_id: 139
    organization_name: ScummVM
    no_of_ideas:
    ideas_content: |
      Summer of Code/GSoC Ideas 2025
      < Summer of Code
      Jump to navigation
      Jump to search
      If you'd like to get involved in ScummVM, we'd love to help you get started!
      We've had a lot of successful student projects as part of Google's Summer of Code in previous years -- we hope to inspire you to work with us and (hopefully) add your own success.
      We often get asks by participants with no experience with ScummVM whether they have the necessary skills to participate with us. The idea of GSoC is to introduce students to open source development, so we are not expecting you to have experience with ScummVM. You will have time during the application and community bonding periods to familiarize yourself with the project. The technical skills required to work with us varies from task to task. For any work on ScummVM, you'll probably need to already be comfortable with a basic level of C++. Some of the tasks might need more specialized knowledge (working on a 3D game engine may need you to understand some OpenGL and 3D math, and some engine tasks may require some assembly or reverse engineering knowledge); we give our thoughts about this alongside each suggested task, below.
      Most importantly, we'd like you to join our community. There are many previous GSoC participants who are still involved in our project, and whether or not you participate as part of Summer of Code, we'd love for you to get involved too.
      You should come to our Discord Server and introduce yourself in the #scummvm-gsoc channel! We're friendly, and it's often the easiest way to ask questions about the tasks and the code in general. The channel is the main form of everyday communication for the project, and there will almost always be developers there who can discuss your project ideas, answer questions and help out.
      You can find more information about what we expect from you before you apply at GSoC Application.
      Contents
      1 Introduction
      2 Tasks
      3 Game Tasks
      3.1 Macromedia Director
      3.2 Amnesia: The Dark Descent and A Machine for Pigs (HPL2 engine)
      3.3 Finishing implementation of incomplete engines
      3.4 Porting ADL to ScummVM
      3.5 Porting ACK engine to ScummVM
      3.6 Porting Ambermoon/Amberstar engine to ScummVM
      3.7 Porting FITD (Alone in the Dark) engine to ScummVM
      3.8 Bring your own Adventure or RPG Reimplementation (only existing games)
      4 Smaller Tasks
      4.1 Add Keymapper to more games
      4.2 Add Text-to-Speech to more games
      4.3 Implementing minigame interface in qdEngine
      4.4 Porting ALIS engine to ScummVM
      4.5 YAGA engine
      4.6 System for checking the game files integrity
      5 Infrastructure Tasks
      Introduction
      We have a list of potential tasks further down on this page, but before you look at them, perhaps you'd like to take a look at some of the successful projects from previous years! We encourage all of our students to maintain a blog during their summer work, which is a nice way to get some sense of what they accomplished.
      One popular type of task is to improve our support for the games you love, whether this means a new game engine, or helping us to perfect an existing one.
      Sometimes source code is available - in recent summers, students integrated code supporting games such as QdEngine (blog) and Unrest (blog)into ScummVM. In fact, our support for the Wintermute engine was not only started by a GSoC student (blog), who integrated the code into our tree, but also drastically improved by another student a year later (blog).
      A more challenging (but hopefully rewarding) idea is to start (or continue) reverse engineering a game where no source is available. Two good examples are the pair of students who drastically improved support for Escape from Monkey Island (blog, blog), and the work on improving Operation Stealth (blog). Another option is to work on merging (and improving) someone else's reverse engineering work, such as was done with the ZVision engine (blog).
      If you'd prefer to improve ScummVM more directly, there are even more options available there; in the past, students have (to give some examples) improved our OpenGL support, added support to keymapper to multiple engines (blog), improved our scaler code (blog), written a new GUI framework, added loadable modules for embedded platforms (blog), rearchitected our keyboard input code (blog) and added support for high-colour (16bpp and above) graphics. It's difficult for us to imagine ScummVM as it was before some of these projects, you can make a huge difference!
      Tasks
      General contacts: Our Discord server our mailing list, or contact sev, Arnaud Boutonné
      The ideas here are meant to be just that - ideas. We hope they help inspire your proposals, but you should also consider suggesting your own completely new project ideas. Pick something you really want to see improved/fixed, and come and talk to us about it!
      If you're looking for more inspiration for ideas, beware of our TODO (and the other TODO lists linked from there) and our OpenTasks pages. Many of the tasks listed there might be incomplete or outdated, or too difficult for a new developer. The best thing to do is to come and talk to us!
      Game Tasks
      Technical contacts: Our Discord channel, our mailing list, or contact sev, John Willis, Arnaud Boutonné, Filippos Karapetis,
      If you already have reverse engineering experience, you could consider working on one of the external in-development game engines, or even on support for a new game. However, doing this kind of work is very difficult and time-consuming - you would have to convince us that you have the necessary skills to actually be sufficiently productive, probably by demonstrating some actual progress first.
      If you don't feel quite up to that level of challenge, we have lots of other suggestions:
      Macromedia Director
      Technical contacts: sev
      Difficulty level: Medium. You'll need a reasonable level of programming experience, and probably some Director games.
      Size: 175 or 350 hours
      Many 90s-era adventure games were developed using the Macromedia (now Adobe) Director tool. We added so far support for Director 3 and Director 4, but there is much more work related to the specific Xtras, increasing compatibility and working on Director 5 support.
      These days, due to the relatively high compatibility our approach is taking an interesting Director title, trying to play it and fix any issues along the way, thus making the process pretty fun. During playback, we often compare the titles and behaviors with the original.
      Often, we implement stubs for XObjects, which are extensions for Director functionality.
      Besides the core engine development, there is a lot of work on the visual source level debugger, written with use of ImGUI.
      Amnesia: The Dark Descent and A Machine for Pigs (HPL2 engine)
      Technical contacts aquadran or sev
      Difficulty level: Hard. OpenGL knowledge is required
      Size: 350 hours
      Frictional Games has released full sources for their HPL2 engine under GPLv3 license. In 2022 we added HPL1 engine and now we could consider adding HPL2. The size of the task is huge since the engines are 275k and 240k lines of code respectively, but we already have experience from working on Penumbra.
      The purpose of this project is to port the HPL2 engine to ScummVM, with the goal of supporting Amnesia: The Dark Descent and Amnesia: A Machine for Pigs.
      Finishing implementation of incomplete engines
      Technical contacts: sev or strangerke
      Difficulty level: Medium or High
      Size: 175 hours or 350 hours
      ScummVM currently has a number of engines that are very close to completion. Many of them were parts of previous GSoCs. For them, we need a playthrough and slight bug fixing, or additional portability fixes.
      Some of the engines are:
      MacVenture, based on a JavaScript reimplementation. Very close to completion, playthrough is missing and rechecking ties to our Mac GUI emulation.
      Avalanche, some engine parts like Outro are not finished. Complete list is here
      DM
      Comprehend, finishing support for Transylvania (V2), and adding support for the 16-color Apple IIgs versions
      Porting ADL to ScummVM
      Technical contacts: sev
      Difficulty level: Medium or High
      Size: 350 hours
      ADL (Adventure Definition Language, not to be confused with Sierra's ADL) was created in 1987 by Tim Brengle and Ross Cunniff and released as freeware. Subsequent modifications to the engine have been made since and released under GPL. Documentation as well as a compiler and interpreter can be found at this link.
      Only one commercial game is known to have been released using ADL: Transylvania III. The previous 2 entries in the series use the Comprehend engine.
      The purpose of this task is to port this engine to ScummVM's Glk engine.
      Porting ACK engine to ScummVM
      Technical contacts: sev
      Difficulty level: Medium
      Size: 350 hours
      ACK (Adventure Creation Kit) was a Pascal-written game development system. Its sources were released under Public Domain, and there is a port to Free Pascal. The whole solution is mid-size, around 16k lines of code, but it must be converted to C++ before porting. A program such as p2c (Pascal-to-C) converter could be used for the initial code conversion, but then, the manual work on making things work will follow.
      There are several RPG-like games build on the engine, the most notable one is Ultima-like games.
      The purpose of this task is to port this engine to ScummVM as a separate engine engine.
      Porting Ambermoon/Amberstar engine to ScummVM
      Technical contacts: sev
      Difficulty level: Hard / Very Hard
      Size: 350 hours
      Ambermoon and Amberstar were nice Amiga RPGs created by Thalion Software GmbH, a German company in early 90s. There are complete sources released for both games: here and [here. It is technically possible to rewrite them in C++.
      The task will require learning or knowledge of the beautiful Motorola Assembly language and some knowledge on how Amiga worked with graphics and sound.
      Porting FITD (Alone in the Dark) engine to ScummVM
      Technical contacts: sev, somaen
      Difficulty level: Hard
      Size: 350 hours
      FITD is an engine for playing Alone in the Dark 1-3 games. It is a mid-size engine with 23k lines of code, not in active development now.
      The goal of this project is porting the engine code to ScummVM's OSystem framework. o
      The goal of this project is to rewrite/convert all of this into C++ and add to ScummVM.
      Bring your own Adventure or RPG Reimplementation (only existing games)
      Technical contacts: Talk to us on Discord, or send us an email.
      Difficulty: Hard. You'll need good knowledge of C++, as well as knowledge of (reading) assembly.
      Size: 350 hours
      Our project consists of re-implementations of classic games, and we have listed a number of potential new game engines that you could work on here on our ideas page. However, you may have a classic 2D Adventure game or Role Playing Game (RPG) you are interested in yourself that is suitable for ScummVM that you would like to reverse engineer and re-implement. If so, great!
      Adding a completely new game engine is not easy, and you will have to convince us that you are aware of the challenges involved, that the game you are interested in is feasible, and that you have the necessary skills. Preferably, you will already have done some preliminary investigation, into for example data file formats, disassembly, etc.
      Please come talk to us to see if we have a mentor who would be interested in working with you on such a game. We'd be happy to help out.
      Smaller Tasks
      Add Keymapper to more games
      Technical contacts: sev
      Difficulty: Easy
      Size: 175 or 350 hours, depending on the number of games
      ScummVM includes a global fully configurable keymapper, but this requires engines to be adapted to use it. The feature documentation: Keymapper, some reference implementations: Wintermute has per-game keymaps; a pull request with adding keymapper to HDB engine; a commit with adding Keymapper to a simpler engine, Griffon.
      The current status can be found at Keymapper_and_TTS_status page.
      
      Add Text-to-Speech to more games
      Technical contacts: sev
      Difficulty: Easy
      Size: 175 or 350 hours, depending on the number of games
      ScummVM has Text-to-Speech (TTS) functionality that we are using for the games that have no speech (or limited options for speech). That improved the usability of the games and, obviously, their accessibility.
      The current status per engine can be found on the Keymapper_and_TTS_status page.
      For each engine, the task varies from straightforward to a mid-complexity:
      Identify routines that show text on the screen
      Potentially, clean up text from things like colors and fonts
      Feed this text to TTS
      Define GUI options for triggering the option
      Implementing minigame interface in qdEngine
      Technical contacts: sev
      Difficulty level: Medium
      Size: 175 hours
      Last year, we successfully ported qdEngine to ScummVM. However, there are a few smaller tasks left:
      Implementing interface for advanced mini-games
      Fixing pathfinding
      Fixing actor lighting in some circumstances
      Adding more features to the debugger, written in ImGui
      This could be a good introductory task into general engine development for a well-established engine codebase.
      If you can understand Russian, you may also help with playtesting the rest of the games and perhaps fixing any issues that we discover.
      Porting ALIS engine to ScummVM
      Technical contacts: sev
      Difficulty level: Medium
      Size: 175 hours
      ALIS (Actor Language Integrated System) is an engine that was used by Simlarils for most of their games and about 17 of them are expected to work on this engine. There is an engine that is almost complete, it is pretty small, less than 10k lines of code and is distributed under MIT license. Engline and we also have Ghidra projects for the engine.
      The purpose of this task is to port this engine to ScummVM as a separate engine engine.
      YAGA engine
      Technical contacts: sev or strangerke
      Difficulty level: Medium.
      Size: 175 hours
      This engine was used for two later Humongous Entertainment games, Pajama Sam: Life is Rough When You Lose Your Stuff and Putt-Putt: Pep's Birthday Surprise. The engine is basically an extension of Python 2.2. There exists an almost complete reimplementation by cyx on GitHub (which we have permission to use) that can be used as a base, and we also have the complete source code for the original game.
      The task is relatively straightforward, the only difficulty with it is adding Python as an external dependency, but a mentor is there to help. Implementing the missing "Lip Sync" feature will be the main part of this task.
      The goal is to bring cyx's code to ScummVM and use the original code as a reference later.
      System for checking the game files integrity
      Technical contacts: sev
      Languages: Python, optionally C++
      Difficulty: Medium
      Size: 175 hours
      ScummVM requires game data files to operate. Very often, especially when copying from the old media, the files could be damaged. Thus, we need a system that could let the end-users compute all the checksums and compare them with the reference.
      The solution consists of two parts: server and additional functionality within ScummVM. In order to avoid any potential problems with the copyrighted material, only checksums could be passed to the server.
      We already have a bulk of this task implemented but not yet fully integrated with ScummVM. There are two parts: Server, written in Python, and the original ScummVM Pull Request.
      We need to complete this task and make it fully functional.
      Infrastructure Tasks
      Finally, there are always plenty of other practical tasks on our wishlist!
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/scummvm/
    idea_list_url: https://www.scummvm.org/gsoc-2025-ideas


  - organization_id: 140
    organization_name: Society for Arts and Technology (SAT)
    no_of_ideas:
    ideas_content: |
      Ideas
      RSS feed
      2025-02-20Compute-Agnostic Compilation of Audio and Media Processing Objects for FPGA Acceleration by Jean-Michaël Celerier
      2025-02-20Exploration of Advanced Rendering Pipelines in ossia score with Raytracing for Fulldome Content by Jean-Michaël Celerier
      2025-02-20GPU-Independent Pipeline for Large-Scale Point Cloud and Gaussian Splat Rendering by Jean-Michaël Celerier
      2025-02-20GPU rendering for the score GUI by Jean-Michaël Celerier
      2025-02-20A library-content-manager by Jean-Michaël Celerier
      2025-02-20CLAP Audio Plug-in Integration in ossia score by Jean-Michaël Celerier
      2025-02-20A cross-platform API for GPU texture sharing by Jean-Michaël Celerier
      2025-02-12Improving collaborative & distributed interactive scoring by Sarah Al Mamoun
      2025-02-06A Media-over-QUIC C++ implementation by Jean-Michaël Celerier
      2025-02-06Object Detection on Point Cloud Streams by Manuel Bolduc
      2025-01-29Porting Puara-gestures to Avendish and creating ossia score objects for each gestural descriptor by Edu Meneses
      2024-02-20Adding custom Satellite features to the hubs blender add-on by Rochana (closed)
      2024-02-12Adding gestures to puara-gestures, a library for creating high-level gestural descriptors for IoT devices and New Interfaces for Musical Expression by Edu Meneses (closed)
      2024-02-12Integration of a YOLOv8 backend in LivePose by Manuel Bolduc (closed)
      2024-02-09Towards a full-featured embedded media sequencer by Jean-Michaël Celerier (closed)
      2023-03-28Haptic and audio interaction design with Feelix supporting TorqueTuner and/or DeformableHapticSurfaces by Christian Frisson (filled by Maxwell Gentili-Morin)
      2023-03-10Motion Capture in WebXR by Manuel Bolduc (filled by Fanny Cacilie)
      2023-02-07SATIE Multispatializer Mapper by Edu Meneses (filled by Haokun Song)
      2023-02-07Using markerless motion capture for music generation, music creativity and music-dance interactions by Suresh Krishna, Christian Frisson (closed)
      2023-02-022023 project ideas welcome! by Christian Frisson (closed)
      2022-03-07Create a WebUI for data mapping and software control in embedded systems by Edu Meneses (filled by Yash Raj)
      2022-02-19Explorable explanations for teaching digital arts concepts in hybrid telepresence campus by Christian Frisson (filled by Pedro Andrade Ferreira Sobrinho)
      2022-02-18Replace OpenGL by a multi-API rendering library in Splash by Emmanuel Durand (filled by Tarek Yasser)
      2022-02-18Face tracking for improving accessibility in hybrid telepresence interactions by Christian Frisson (filled by Matt Wiese)
      2022-02-17Add support of Unix permission in the Shmdata library by Nicolas Bouillot (filled by Vanshita Verma)
      2022-02-162022 project ideas welcome! by Christian Frisson (closed)
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/society-for-arts-and-technology-(sat)/
    idea_list_url: https://sat-mtl.gitlab.io/collaborations/google-summer-of-code/categories/ideas/
  

  - organization_id: 141
    organization_name: Software and Computational Systems Lab at LMU Munich
    no_of_ideas:
    ideas_content: |
      Google Summer of Code 2025
      Ideas
      Instructions
      Ideas
      Below you can find a list of selected project ideas for GSoC, categorized according to our main development projects. If you are searching for more topics or want to propose your own, there is a list with more ideas available. You can also take a look into the tickets for the specific projects on the corresponding repository websites. The assigned mentors listed below are not fixed yet and might be changed.
      If you have any questions, please contact us!
      CPAchecker (website)
      CPAchecker is an award-winning open-source framework for software verification. It is written in Java and based on a highly modular architecture that allows to develop and combine a wide range of different analyses. CPAchecker is used for verification of the Linux kernel and has helped to find hundreds of bugs in the kernel. To get started with CPAchecker you can take a look at its Tutorial Paper.
      Exporting and Validating Correctness Witnesses for Memory Safety in CPAchecker
      Automatic Software Verifiers like CPAchecker, while great at finding bugs may also contain some bugs themselves. In order to increase the confidence in the results of the verifiers, they export an argument for their result in a machine-readable format called a witness. A witness can be validated independently by another tool, increasing the confidence in the result of the tool which exported them. Currently CPAchecker does not export relevant information when it finds a proof about memory safety properties. As a GSoC student, you will have the opportunity to extend CPAchecker by a new witness export to provide relevant information about memory safety proofs. Additionally you will be implementing the validation of these witnesses inside CPAchecker in order to evaluate the correctness of the exported witnesses. Your work will involve learning about the existing analyses for memory safety, the witness export and the witness validation in CPAchecker in order to develop the required components.
      Expected outcome: An prototype for the export and validation of correctness witnesses for memory safety in CPAchecker.
      Requirements: Programming in Java, reading C code, basic understanding of software verification
      Difficulty: intermediate
      Project size: large (~350 hours)
      Mentor: Marian Lingsch-Rosenfeld
      Infrastructure for Software Verification
      Automated software verifiers are powerful tools to find bugs in programs, but they are often complex and difficult to use. Our team aims to simplify this and make it easy to integrate software verifiers into the software-development process.
      Design and Implementation of Behavior-driven Tests
      CPA-Daemon is a gRPC-based microservice that enables users to run the award-winning verifier CPAchecker in a cloud setup. It focuses on ease of use and continuous verification.
      You will improve the maintainability and reliability of our tests in CPA-Daemon. We plan to do this in two dimensions: First, you improve the maintainability of our tests through behavior-driven tests with Cucumber. You analyze the existing tests (written with plain JUnit), design an improved test architecture on the foundation of Cucumber, and implement that.
      Issue related to this project: CPA-Daemon#33
      Expected outcome: A running integration-test suite for CPA-Daemon based on Cucumber that reaches the same or more branch coverage than the existing integration tests that are based on basic JUnit. The test suite lists features and test cases with a granularity similar to the existing tests.
      Requirements: Experience in Java and on the command line. Strong knowledge on the concepts of microservices.
      Project size: small (90 hours)
      Mentor: Thomas Lemberger
      Difficulty: easy
      Chat room for communication at Matrix: #sosylab-gsoc:matrix.org
      Design and Implementation of a Web Application for the Visualization of Analysis Work in Distributed Summary Synthesis
      Distributed Summary Synthesis (DSS) is a technique to distributed an expensive software verification task in the cloud. DSS decomposes the program-under-analysis into individual blocks, and then analyzes each block separately and in parallel. Whenever a block analysis is finished, the produced result is communicated to strengthen the analysis of the other blocks. DSS uses a microservice architecture with a central coordinator service that composes individual block analyses from the available results. Worker services are then responsible to handle individual block analyses. The produced result can be post-conditions or violation conditions: A post-condition is produced when the analysis proves the block safe (under the currently available information). It represents all possible program states that are possible at the end of the block. A violation condition is produced when the analysis finds a potential error (under the currently available information). It represents a condition that, if it holds at the block entry, leads to an error. Conditions are communicated as logical formulas in the SMT-Lib format. (Scientific paper on the concept of DSS).
      You will implement a new web application that visualizes the work done by the worker services in DSS. The coordinator already uses a database to store basic information about each block analysis, like the start-time and end-time, and the produced messages. Your web application will connect to this database and render the performed analyses (for a single verification run) in a graph-based visualization. The user should be able to toggle different layers of visualization (for example a visualization of the individual run times, or a visualization of the code-block size that was analyzed). The visualization should provide a high-level overview of the analysis work, and enable a drill-down into the statistics of individual runs. A prototype of the microservice is implemented here. The final implementation should be in Javascript (with next.js and react).
      Expected outcomes:
      Implementation of the described web application
      Automated integration tests for the backend of the web application
      Extensive documentation
      Issue related to this project: Distributed Summary Synthesis#30
      Requirements: Experience in Javascript (next.js/react), foundational knowledge of formal software verification.
      Project size: large (350 hours)
      Mentor: Akshay Warrier and Thomas Lemberger
      Difficulty: medium
      Chat room for communication at Matrix: #sosylab-gsoc:matrix.org
      Design and Implementation of a Microservice for AI-based, Formal Code-Summary Synthesis
      Distributed Summary Synthesis (DSS) is a technique to distributed an expensive software verification task in the cloud. DSS decomposes the program-under-analysis into individual blocks, and then analyzes each block separately and in parallel. Whenever a block analysis is finished, the produced result is communicated to strengthen the analysis of the other blocks. DSS uses a microservice architecture with a central coordinator service that composes individual block analyses from the available results. Worker services are then responsible to handle individual block analyses. The produced result can be post-conditions or violation conditions: A post-condition is produced when the analysis proves the block safe (under the currently available information). It represents all possible program states that are possible at the end of the block. A violation condition is produced when the analysis finds a potential error (under the currently available information). It represents a condition that, if it holds at the block entry, leads to an error. Conditions are communicated as logical formulas in the SMT-Lib format. (Scientific paper on the concept of DSS).
      You will implement a new worker service that uses LLMs to produce post-conditions or violation conditions for a given code block. The worker service receives a C code block, a program specification, a set of pre-conditions that are known to hold at the block entry (in SMT-Lib), and violation conditions that are known at the block exit. The worker service then uses LLMs to produce a new post-condition or violation condition. Before sending the result back to the coordinator, the worker performs some validity checks on the expected properties of the logical formulas to increase the chance of correctness. For communication, the worker uses gRPC. It must be implemented in Python.
      Expected outcomes:
      Implementation of the described Python microservice.
      Automated integration tests for the microservice
      Extensive documentation
      Requirements: Experience in Python. Strong knowledge on the concepts of microservices.
      Project size: large (350 hours)
      Mentor: Thomas Lemberger
      Difficulty: hard
      Chat room for communication at Matrix: #sosylab-gsoc:matrix.org
      Finding initial Predicates for Predicate Analysis using AI
      To proof a program correct, usually the most difficult task is to come up with invariants which show its correctness. Nowadays there are multiple approaches which try to find invariants using AI, for example Code2Inv, Neural Termination, using LLMs, refining invariants using LLMs, between many others. While invariants are very useful tools to proof software correct, it is sometimes difficult to find them, since they need to fulfill strict correctness criteria. Another very successful approach in software verification is predicate analysis. In contrast to invariants, the predicates used by the analysis to proof the program correct, do not need to fulfill strict correctness criteria to be useful. But still coming up with good predicates is very difficult, in particular since good predicates are invariants. As a GSoC student, you will have the opportunity to implement an open-source tool which using ML techniques provides initial predicates for CPAchecker to improve its performance.
      Expected outcome: An open-source tool which takes a program and uses machine learning techniques to synthesize candidates for initial predicates encoded as C-Expressions.
      Requirements: Programming in Python, reading C code, basic understanding of software verification and ML
      Difficulty: intermediate
      Project size: large (~350 hours)
      Mentor: Marian Lingsch-Rosenfeld
      Verifier Selection using LLMs
      With the rise of LLMs, there have been large advances in code summarization, coding assistance, between many others. In particular it has now become possible to get good low dimensional embeddings of code, for example NV-Embed or LLM2Vec. These embeddings offer the possibility to improve the selection of best performing verifiers for a task. Current approaches, like Pesco or Graves usually either compute program features manually or train a custom ML algorithm for the selection. As a GSoC student, you will have the opportunity to create your own open-source tool which uses LLMs to encode the task passed to a verifier and predicts which verifier will perform the best on it.
      Expected outcome: An open-source tool which takes a program and returns the verifier which is likely to perform the best on the given verification task.
      Requirements: Programming in Python, reading C code, basic understanding of software verification and LLMs
      Difficulty: intermediate
      Project size: large (~350 hours)
      Mentor: Marian Lingsch-Rosenfeld
      Reimplementing MetaVal in MetaVal++
      MetaVal is a tool and approach to validate witnesses using verifiers by instrumenting the program with the witness. Its current implementation uses deprecated technology and a re-implementation is necessary. In particular the approach could only handle witnesses in version 1.0, while the current standard for witnesses is version 2.0. As a GSoC student, you will have the opportunity to reimplement MetaVal in a new tool called MetaVal++ for witnesses in version 2.0.
      Expected outcome: An implementation of the MetaVal algorithm adapted to witnesses version 2.0 in MetaVal++.
      Requirements: Programming in Python, reading C code, basic understanding of software verification
      Difficulty: intermediate
      Project size: Medium (~175 hours)
      Mentor: Marian Lingsch-Rosenfeld
      BenchExec (website)
      BenchExec is a benchmarking framework for Linux (written in Python) that is aimed at a high reliability of the results. It can measure the CPU-time and peak memory usage of whole groups of processes. To do so, it makes use of modern Linux features such as cgroups and namespaces, effectively creating a benchmarking container whose resource usage is measured. The concepts and architecture of BenchExec are described in a paper (open access).
      Timestamps in logs
      During benchmarking runs, BenchExec collects the output of the benchmarked tool into files. In some use cases, it would be beneficial if each produced line would be prefixed with a timestamp. For this we need to pipe the tool output through the BenchExec process instead of writing it directly (GitHub issue). While implementing this it might be possible to solve some related issues as well: #408, #535, and #536.
      Requirements: Python, Linux
      Skill level: intermediate to advanced
      Mentor: Philipp Wendler
      Project size: small (90h) or medium (175h) depending on whether the additional issues are worked on
      Instructions for Contributors
      Prospective contributors wishing to participate in Google Summer of Code must realize that this is an important professional opportunity. You will contribute code for an award-winning tool chain or parts of its infrastructure. Therefore, we seek contributors who are committed to helping our tools long-term and are willing to both do quality work, and be proactive in communication with their mentors.
      You don't have to be a proven developer - in fact, this whole program is meant to facilitate joining our group and take a look at open source communities. However, experience in coding is welcome and should be mentioned in your proposal.
      You should take a look at the tools that you plan to work on before the start date. The timeline from Google reserves a lot of time for bonding periods; use that time wisely. Good communication is important. The group members are available via mail (or online/in-person meeting, if needed). You should communicate with your mentor, and formally report progress and plans weekly.
      Recommended steps
      Read Google's instructions for participating and the GSoC Contributor Manual.
      Take a look at the list of ideas.
      Get familiar with the project you are interested in, e.g., by trying it out, reading the documentation, etc. If you already see something that can be improved, file a pull request!
      Contact the developers of the project of your choice, e.g., via the mailing list or the mentor, introduce yourself, and meet your fellow developers.
      Come up with a topic for a GSoC project that you're interested in.
      Write a first draft proposal and get someone to review it.
      Submit your proposal using Google's web interface ahead of the deadline.
      Contributor Proposal Guidelines
      Proposals are the basis of the GSoC projects. Write a clear proposal on what you plan to do, the scope of your work, and why we should choose you to do it. The proposals are the basis of our decisions of which contributor to choose.
      Contributors can use the following application template:
      Introduction and Background: You can either choose a problem from the list of ideas or state a new problem for our group. Before offering the solution (your GSoC project), you should first define the problem. What is the current state of things? What is the issue you wish to solve and why? What is your solution?
      Project Goals: Propose a clear list of deliverables, explaining exactly what you promise to do and what you do not plan to do.
      Implementation: Describe what you plan to do as a solution for the problem you defined above. Include technical details, showing that you understand the technology.
      Timeline: Show that you understand the problem and have a solution. Divide the solution into manageable parts (estimated work items, milestones) and describe a detailed realistic plan on how to accomplish your goal. Include time for searching and fixing bugs, and communication. Do not promise what you cannot keep.
      Other commitments during GSoC, such as a job, vacation, and exams should also be mentioned. GSoC should be treated like a full-time job, and we will expect approximately 30 hours of work per week. Explain how you will work around conflicts.
      Describe your plans for communication. You will need to participate on weekly communication such as detailed email or personal meeting with your mentor or the team.
      About Me: Provide your contact information (address, email, phone) and write a few sentences about you and why you think you are the best for this job. Previous contributions to our projects are appreciated. Name people (other developers, students, professors) who can act as a reference for you. Mention your field of study if necessary.
      Tell us if you are submitting proposals to other organizations, and whether or not you would choose our group if given the choice.
      If your native language is not German or English, you should be able to communicate in one of those languages.
      Accepted Contributors
      Your primary responsibility is finishing your project under the guidance of your mentors. To do that, you must submit code regularly and stay in frequent communication with your mentor and our team. For the evaluation, you must succeed with communication, coding, and documentation.
      Hints
      Submit your proposal early! Early submissions will be read and discussed by mentors more eagerly.
      Keep it simple! Be concise and precise. Provide a clear, descriptive title.
      Know what you are talking about! Do not submit ideas that cannot be accomplished realistically or that are not related to our projects.
      Aim wide! You can submit more than one proposal, with different ideas. If you do submit more than one proposal, tell us which of them you would prefer, if more were selected.
      Google Summer of Code in Previous Years
      To get information about former projects and ideas, you can take a look at the pages from previous years:
      GSoC 2024 webpage and GSoC 2024 project site
      GSoC 2023 webpage and GSoC 2023 project site
      GSoC 2019 webpage and GSoC 2019 project site
      GSoC 2018 webpage and GSoC 2018 project site
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/software-and-computational-systems-lab-at-lmu-munich/
    idea_list_url: https://www.sosy-lab.org/gsoc/gsoc2025.php

  - organization_id: 142
    organization_name: St. Jude Children's Research Hospital
    no_of_ideas:
    ideas_content: |
      St. Jude GSoC 2025
       Request edit access
      +3
       Share
      Sign in
      FileEditViewToolsHelp
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/st.-jude-children's-research-hospital/
    idea_list_url: https://docs.google.com/document/d/1ze8OpsltCbAkksjmhd3hCeS6VDqAaolAhWAQQRJZBpc/edit?tab=t.0

  - organization_id: 143
    organization_name: Ste||ar group
    no_of_ideas:
    ideas_content: |
      Introduction
      Welcome to the Google Summer of Code (GSoC) page for the HPX project. Here you can find information about student projects, proposal submission templates, advice on writing good proposals, and links to information on getting started with HPX. The STE||AR Group will apply as an organization and our goal is to have at least five funded students working on HPX related projects.
      Requirements
      Students must submit a proposal. A template for the proposal is available here. Find hints for writing a good proposal here.
      We strongly suggest that students interested in developing a proposal for HPX discuss their ideas on the Discord channel or the mailing list to help refine the requirements and goals. Students who actively plan and discuss projects with developers are generally ranked before those that do not.
      We have intentionally left the descriptions of these projects vague and open to interpretation because we expect students to develop their proposals' requirements by doing initial background research on the topic and interacting with the community. In addition, it is important to note that the suggested projects on this page are not binding -- if you have an interest in parallel task-based programming and have an idea for a project that would either improve HPX or demonstrate how well it applies to your problem, then feel free to suggest your idea as a project and write a proposal for it. We will be glad to help you with project goals to improve your proposal if you have ideas, so do not leave them until the last minute.
      We will expect students to demonstrate that they have the required level of C++ and CMake knowledge by showing us some of their previous work (e.g., a GitHub repository), or preferably, by them making a small demonstration program using HPX that shows a simple example of something they have created themselves.
      Potential Additional Funding
      For students who perform at or above expectations on both GSoC evaluations, the Center of Computation and Technology (CCT) at Louisiana State University (LSU) may fund up to an additional four weeks' work on the project for no more than the GSoC rate of pay. This funding is not guaranteed and is independent of the GSoC program. Students accepted for additional funding will be paid through LSU for the additional weeks and affiliated with LSU during that time. Additional paperwork through LSU will be required.
      Tips for Prospective Students
      Some of our former GSoC students that still contribute to our projects have put together the following list. All of them had to go through the same learning experience. Prospective students most probably face this challenge now, so the list provides pointwise help to get into HPX smoothly.
      The first thing we suggest is to build HPX from the source using the CMake build system. An example guide to build HPX is here. Various ways of building HPX (e.g., memory allocators, OTF2 traces, CUDA support) will enable you to understand the capabilities of HPX as a runtime.
      Once you're acquainted with the build system, we suggest you read our docs/wiki and try to familiarize yourself with the basic terminology (e.g., locality, LCO, futurization, etc.).
      Next, we suggest you watch talks on HPX on YouTube. Doing so should give you a brief overview of the motivations and implementation design of the components within HPX.
      At this point, try building and playing with the examples in HPX. Furthermore, we have a basic tutorial that takes you through the features and their usage with code examples.
      Going through the examples may be an overwhelming experience, so we suggest you become familiar with our way of writing code through our summer lecture series. (Hint: Pay attention to Lecture #4)
      The C++ style used in HPX might not seem intuitive at first, but this guide will help you build an intuition for why it is used.
      When you're familiar with basic usage, we suggest you try writing demo HPX programs (e.g., matrix-matrix multiplication). Go through our Issue tracker and see if you can find an issue you would like to investigate. Working on bugs is the easiest way to dive into the code base and contribute to HPX.
      Dig into our currently active GSoC issues and Pull Requests relevant to them. Furthermore, leave comments and discuss with the corresponding authors.
      We highly recommend joining our channel, on Discord, where you can ask questions, discuss issues, pull requests, and your potential GSoC project. Remember, questions are the key to start contributing!
      2025 HPX Project Ideas
      There are new projects this year, and also ones revamped from previous years (legacy) that are still of interest. These projects have mentors ready and waiting to help students.
      Core HPX Projects
      These are projects that involve making changes/improvements/extensions to the core HPX library.
      Annotate HPX with Contracts
      Integrate HPX algorithms with Nvidia CCCL (Thrust)
      Expose HPX using C++ Modules
      Implement the make_receiver_for optimization for HPX Senders
      Implement hpx::system_scheduler as described in P2079 (System Execution Context)
      Integrate HPX with the Tracy profiler
      Use C++26 reflection for HPX serialization
      Implement parallel hpx::uninitialized_relocate_* algorithms for overlapping ranges
      Async I/O using Coroutines and S/R
      "Green out" our Continuous Integration tests
      Port HPX to iOS and Mac (M1 architecture)
      Study the performance of Halide applications running on HPX threads
      Bring the HPX distributed algorithms up to date
      Fix libCDS broken dependency
      (Re-)Implement executor API on top of sender/receiver infrastructure
      Update Build System to automatically fetch HPX dependencies when not available
      Explicit Visualization of Accelerators for HPX Trace Visualization
      Improved Scalability for HPX OTF2 Trace Visualization
      Multiple File Load in HPX Trace Visualization
      Annotate HPX with Contracts
      Abstract: Recent standardization developments indicate that C++26 will introduce contracts P2900. Their primary use is to increase language safety by providing developers with ergonomic tools to handle false assertions. They can be used to give defined behavior to pre-condition and post-condition violations of functions. The companion proposal to contracts: P3471 introduces the notion of a hardened STL, which implements the expected conditions to standard library functions (e.g. vector.front() has a precondition that vector.empty() is false). HPX provides multiple debugging mechanisms, and a rich test suite. Annotating the HPX library functions would further safety and debugging ability.
      Additional References:
      Proposal P2900 (Contracts)
      Proposal P3471 (Hardened STL)
      Difficulty: Medium/Advanced
      Expected result: Annotate a significant portion of HPX's public facing API with contracts.
      Knowledge Prerequisite: C++, Git
      Mentor: Hartmut Kaiser (), Isidoros Tsaousis-Seiras (tsa.isidoros [at] gmail.com)
      Project Size: 350 hour (medium project)
      Integrate HPX algorithms with Nvidia CCCL (Thrust)
      Abstract: Nvidia provides C++ abstractions for CUDA developers in their CUDA Core Compute Libraries (CCCL). Specifically, Thrust implements C++ parallel algorithms that match those in the C++ Standard. Integrating Thrust with HPX would allow calling GPU Thrust algorithms through HPX parallel algorithms API, perhaps even taking advantage of HPX facilities for asynchronous execution (e.g. futures).
      Difficulty: Medium/Advanced
      Expected result: Integrate Thrust with the HPX algorithms API
      Knowledge Prerequisite: C++, Git
      Mentor: Hartmut Kaiser (), Panagiotis Syskakis (pansysk75 [at] gmail.com)
      Project Size: 350 hour (large project)
      Expose HPX using C++ Modules
      Abstract: Modules were introduced in C++20 as an alternative to header files for sharing declarations and definitions across translation units. C++ Modules can improve compilation times and code isolation. There are several differences when using C++ Modules, mainly they cannot export macros, and declarations have to be explicitly exported using the export keyword. We are interested in exposing HPX using C++ Modules (in addition to header files).
      Additional References: Rubén Pérez on bringing C++ Modules to the Boost library: Part 1, Part 2, Part 3
      Difficulty: Medium/Advanced
      Expected result: Make HPX available to users through C++ Modules
      Knowledge Prerequisite: C++, Git
      Mentor: Hartmut Kaiser (), Panagiotis Syskakis (pansysk75 [at] gmail.com)
      Project Size: 350 hour (large project)
      Implement the make_receiver_for optimization for HPX Senders
      Abstract: The Senders/Receivers (P2300) framework is constantly evolving to become more optimized and user-friendly. One of the papers accelerating this evolution is P3425 It proposes that since chained operations have a known byte-size and are stacked contiguously in memory, we can avoid holding pointers to each of them, and we can calculate their addresses on the fly based on the offsets. This presents a massive object size reduction and also aids the compiler in optimizing the code. HPX's senders would greatly benefit from implementing the proposed interface to support this feature.
      Additional References:
      Proposal P2300
      Proposal P3425
      Difficulty: Medium/Advanced
      Expected result: Implement the make_receiver_for interface for hpx::bulk as described in P3425.
      Knowledge Prerequisite: C++, Git, Concurrency
      Mentor: Hartmut Kaiser (), Isidoros Tsaousis-Seiras (tsa.isidoros [at] gmail.com)
      Project Size: 175 hour (medium project)
      Implement hpx::system_scheduler as described in P2079 (System Execution Context)
      Abstract: C++26 Has evolved to include a modern API for parallelism and task scheduling (P2300). HPX implements the proposed interface, as well as multiple schedulers. Proposal (P2079) proposes a generic scheduler to OS-provided threads. hpx::system_scheduler is the HPX analogue that maps to hpx::threads instead, and an excellent way to expose an HPX scheduler with a Sender/Receiver interface.
      Additional References:
      Proposal P2300
      Proposal P2079
      Difficulty: Medium/Advanced
      Expected result: Implement system_scheduler as described in P2079.
      Knowledge Prerequisite: C++, Git, Concurrency
      Mentor: Hartmut Kaiser (), Isidoros Tsaousis-Seiras (tsa.isidoros [at] gmail.com)
      Project Size: 350 hour (large project)
      Integrate HPX with the Tracy profiler
      Abstract: HPX is already integrated with the Intel VTune and APEX profilers. Adding support for using Tracy to HPX will extend the available set of introspective and embedded profiling tools for HPX applications. The integration would include annotating key functions, mutexes, thread scheduling, etc. The work would also require implementing a CMake based build system integration to simplify using Tracy with HPX and its applications.
      Additional References:
      Tracy
      Difficulty: Medium/Advanced
      Expected result: Integrate the Tracy profiler with HPX.
      Knowledge Prerequisite: C++, Git, CMake
      Mentor: Hartmut Kaiser ()
      Project Size: 350 hour (large project)
      Use C++26 reflection for HPX serialization
      Abstract: HPX has already a serialization framework that allows to turn any C++ object into a byte stream for transmission over the network. Obviously this framework can turn a byte stream back into the corresponding C++ object instance. The current implementation of serialization n the general case relies on the user providing intrusive serialization functionality to the types that have to be sent over the wire. With C++26 reflection becoming available, we should add support for serializing arbitrary type (including lambdas with captures) that relies on using these new language facilities.
      Additional References:
      C++ 26 Reflecton
      Difficulty: Medium/Advanced
      Expected result: Arbitrary C++ types can be serialized.
      Knowledge Prerequisite: C++, Git, CMake
      Mentor: Hartmut Kaiser ()
      Project Size: 350 hour (large project)
      Implement parallel hpx::uninitialized_relocate_* algorithms for overlapping ranges
      Abstract: HPX implements the full set of the C++ standard algorithms. This includes algorithms that copy data (e.g. hpx::copy copies the elements from a source range to a destination range). Recent proposals (see additional references below) suggest the addition of a new type trait (std::is_trivially_relocatable) that defines a new group of types that can benefit from trivial relocation. When relocating an object, the relocation algorithms will determine if it is valid to reduce the move-constructor and destructor call to a single memcpy(). In that way, relocation improves performance and increases safety. The relocation algorithms are: A) relocate, relocate_at, to operate on single objects and B) uninitialized_relocate, uninitialized_relocate_backward to operate on ranges of elements. These were added to HPX in a GSoC 2023 Contribution. However, the parallel versions of hpx::uninitialized_relocate and hpx::uninitialized_relocate_backward cannot handle overlapping ranges properly, as the forward and backward order of the algorithms is not preserved when running in parallel. The contributor is expected to correct the parallelization of these algorithms for overlapping ranges, as well as benchmark, write tests, and evaluate their solution.
      Additional References:
      P1144 Object relocation in terms of move plus destroy
      C++Now 2019: "Trivially Relocatable"
      GSoC 2023: Relocation Semantics in HPX
      Possible choice for a parallelization method
      Difficulty: Medium/Advanced
      Expected result: Parallel implementations of uninitialized_relocate and uninitialized_relocate_backward that work on overlapping ranges, as well as written tests and benchmarks.
      Knowledge Prerequisite: C++, Git, parallel algorithms
      Mentor: Hartmut Kaiser () and Isidoros Tsaousis-Seiras (tsa.isidoros [at] gmail.com)
      Project Size: 175 hour (Medium/Advanced project)
      Async I/O using Coroutines and S/R
      Abstract: Coroutines along with S/R make a really good use case for async I/O Ref 1. Using the recently added HPX S/R facilities to develop an interface for a relatively faster I/O example would be the goal of this project. Additionally for Linux based platforms with io_uring support can have even more performance benefits.
      Additional References:
      https://github.com/L-v-M/async
      https://pabloariasal.github.io/2022/11/12/couring-1/
      Difficulty: Easy/Medium
      Expected result: Develop a non-trivial use case using the above described tools and HPX.
      Knowledge Prerequisite: C++, CMake
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com) and Shreyas Atre (Discord: Shreyas)
      Project Size: 175 hour (Easy/Medium project)
      "Green out" our Continuous Integration tests
      Abstract: There are tests in our Continuous Integration (CI) that are currently failing. These are mainly under our tests.regressions, tests.segmented_algorithms targets, performance tests and certain new compilers tests (clang-13/14, gcc-12). One can see all the tests that are failing if they randomly select an open PR and scroll down to check the list items indicated with a red 'X'. Fixing those tests would include a wide range of bug hunting tasks and creativity from the student side in order to reproduce them locally until they figure out and fix the errors.
      Difficulty: Easy/Medium
      Expected result: All tests in our CI pass (are green).
      Knowledge Prerequisite: C++, CMake, slurm
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com)
      Project Size: 175 hour (Easy/Medium project)
      Port HPX to iOS and Mac (M1 architecture)
      Abstract: HPX has already proven to run efficiently on ARM-based systems. This has been demonstrated with an application written for Android tablet devices. A port to handheld devices running with iOS would be the next logical step! On top of that since the new Apple M1 ARM-based processors have proven to be very efficient the student should consider providing an HPX version for this architecture as well. To run HPX efficiently on there, we need to adapt our build system to be able to cross-compile for iOS and Mac and add a code to interface with the iOS GUI and other system services. A preexisting Mac support infrastructure exists but the student will need to adapt and update it to current releases.
      Difficulty: Easy/Medium
      Expected result: Provide a prototype HPX application running on an iPhone or iPad.
      Knowledge Prerequisite: C++, Objective-C, iOS
      Mentor: Hartmut Kaiser () and Thomas Heller ()
      Project Size: 350 hour (large project)
      Study the performance of Halide applications running on HPX threads.
      Abstract: Halide is a programming language designed to facilitate developing high-performance array-based code with regular access to memory on a wide range of modern architectures. Halide also makes it possible to use custom runtimes, such as HPX, in situ of the native runtime. A preliminary work has shown promising results for the HPX runtime in code generated by Halide. The goal of this project is to investigate the effectiveness of code generated by Halide in libraries that use HPX as a backend. We are notably interested in improving the performance of level 2, and 3 BLAS operations in the Blaze math library.
      Difficulty: Medium
      Expected result: Comprehensive performance analysis of Halide code in Blaze and other stencil-like applications.
      Knowledge Prerequisite: C++
      Mentor: Hartmut Kaiser () and Rod Tohid (rtohid [at] cct.lsu.edu)
      Project Size: 175 hour (medium project)
      Bring the HPX distributed algorithms up to date
      Abstract: Along with the standard parallel algorithms provided by the C++ standard, HPX extends its infrastructure by providing (some of) the corresponding distributed versions of those algorithms that run on multiple nodes and on top of that they take care of communication. The set of the implemented algorithms can be found here. Due to lack of maintainance these algorithms do not compile properly to some systems according to our latest continuous integration tests and they are considered the last missing piece for HPX to be a fully integrated and portable library. Part of this project is to investigate the reasons that the tests of these algorithms fail (either on the algorithm source code side or on the integration tests side) and "repair" them. Providing further implementations of the remaining algorithms could facilitate as an extension of the project for the prospective students that are interested in a long-term project. Here you can find the corresponding ticket.
      Difficulty: Easy
      Expected result: Repair the segmented algorithms so continuous integration does not fail on them and implement the remaining segmented algorithms.
      Knowledge Prerequisite: C++, CMake, CircleCI, Jenkins
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com)
      Project Size: 175 hour (medium sized)
      Fix libCDS broken dependency
      Abstract: libCDS is a Concurrent Data Structures library which provides containers that alleviate the user from taking care of synchronization. HPX provides an integration with libCDS which is currently broken. We are looking for a prospective developer that will bring that libCDS up to date with the current version of HPX and provide testing and benchmarking with the contemporary results.
      Difficulty: Easy
      Expected result: libCDS current version full integration with the latest HPX.
      Knowledge Prerequisite: CMake, Data Parallelism, C++.
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com)
      Project Size: 350 hour (large project)
      (Re-)Implement executor API on top of sender/receiver infrastructure
      Abstract: P2300 will most likely be accepted for C++26. Our executor API (customization points) currently dispatch to an executor interface defined by wg21.link/p0443R3. All HPX facilities related to scheduling tasks (algorithms, future, dataflow, async, etc.) rely on the executor customization points to perform their operations. Although major steps have been taken for the integration of the executors proposal to HPX there is still many facilities that need to be implemented. The project can be correlated with the Coroutine-like interface project project and the P2300 proposed awaitables.
      Difficulty: Medium
      Expected result: The result should be functioning executor customization points built upon senders/receivers.
      Knowledge Prerequisite: Parallel algorithms.
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com)
      See issue #5219 on HPX bug tracker and the corresponding Pull Request that's on the works already.
      Project Size: 350 hour (large project)
      Coroutine-like Interface
      Abstract: HPX is an excellent runtime system for doing task-based parallelism. In its current form, however, the results of tasks can only be expressed in terms of returning from a function. However, there are scenarios where this is not sufficient. One example would be lazy ranges of integers (for example, Fibonacci, 0 to n, etc.). For those, a generator/yield construct would be perfect (more on coroutines)! Additionally, an option would be to rely on top of the senders/receivers proposed facilities, a completely new interface for execution in standard C++ that may (or not) revolutionize the way we implement concurrency.
      Difficulty: Medium
      Expected result: Implement yield and demonstrate on at least one example
      Knowledge Prerequisite: C++
      Mentor: Hartmut Kaiser () and Thomas Heller ()
      Project Size: 350 hour (large project)
      Update Build System to automatically fetch HPX dependencies when not available
      Abstract: HPX currently depends on three libraries. Although our build system supports a CMake flag to fetch and use a default Asio version, there are no analogous options for Boost and HWLOC. Adding these options would make building HPX easier and would attract more prospective users. The idea is to fetch and install these dependencies with HPX if the user does not have them installed. Further improvements and automation on the build system may be proposed. Updates to the HPX documentation wrt build changes are expected. Feel free to check on the related issues #3440, #5728.
      Difficulty: Medium
      Expected result: Provide a renewed user-friendly build system environment.
      Knowledge Prerequisite: CMake
      Mentor: Nikunj Gupta (nikunj [at] illinois.edu), Hartmut Kaiser (), and Giannis Gonidelis (gonidelis [at] hotmail.com)
      Project Size: 175 hour (medium sized)
      Explicit Visualization of Accelerators for HPX Trace Visualization
      Abstract: HPX traces are collected with APEX and written in as OTF2 files with extensions. These trace files are typically visualized using a Gantt chart or collection of timelines. Presently, there is no differentiation between tasks executed on an accelerator versus other hardware. This project requires (1) investigation regarding what data can be collected about accelerators through HPX and APEX, and (2) design and implementation of how accelerator data is implemented in Traveler. Collection will require C++, while the Traveler alterations will also require Python (backend) and Javascript (frontend).
      Difficulty: Medium-Hard
      Expected result: Traveler trace visualization includes query support and visual indicators of data regarding accelerators.
      Knowledge Prerequisite: C++, Python, Javascript.
      Mentor: Kate Isaacs ()
      Project Size: Could be 175 hour (medium sized) or 350 hour (large sized) depending on proposal
      Improved Scalability for HPX OTF2 Trace Visualization
      Abstract: HPX traces are collected with APEX and written in as OTF2 files with extensions. These trace files are typically visualized using a Gantt chart or collection of timelines in Traveler. The present implementation reads the entirety of the trace file before generating the visualization using one of the older APIs to do so. However, the OTF2 interface has support for partial reading of the file and a parallel backend. This project would modify the Gantt chart backend (C++/Python) to utilize these features, thus supporting larger files. The project could also modify the front end to use WebGL (Javascript) when the number of data items is large.
      Difficulty: Medium-Hard
      Expected result: Files that require more memory than on a single machine can be run from that machine. The time from program-start to visualization is decreased due to the use of large file features.
      Knowledge Prerequisite: C++, Python, Javascript.
      Mentor: Kate Isaacs ()
      Project Size: 175 hour (medium sized)
      Multiple File Load in HPX Trace Visualization
      Abstract: HPX traces are collected with APEX and written in as OTF2 files with extensions. These trace files are typically visualized using a Gantt chart or collection of timelines. We want to load multiple of these files at the same time and align the views between the like-charts for comparison in Traveler. Traveler alterations will also require Python (backend) and Javascript (frontend).
      Difficulty: Medium-Hard
      Expected result: Traveler trace visualization can open multiple files and arranges views so performance can be compared across files.
      Knowledge Prerequisite: Python, Javascript.
      Mentor: Kate Isaacs ()
      Project Size: Could be 175 hour (medium sized)
      Past Year Projects
      These are projects that were worked on in previous years of Google Summer of Code, but still have not been fully resolved. Contributors interested in learning more are encouraged to reach out for further details on these projects.
      Add Vectorization to the par_unseq Implementations of the Parallel Algorithms
      Add HPX to Compiler Explorer (godbolt.org)
      Conflict (range-based) Locks
      Standardize and Visualize HPX Benchmarks
      Rustize HPX!
      Pythonize HPX!
      Create Generic Histogram Performance Counter
      Add Vectorization to par_unseq Implementations of Parallel Algorithms
      Abstract: Our parallel algorithms currently don't support the par_unseq execution policy. This project is centered around the idea to implement this execution policy for at least some of the existing algorithms (such as for_each and similar).
      Difficulty: Medium/Hard
      Expected result: The result should be functioning parallel algorithms when used with the par_unseq execution policy. The loop body should end up being vectorized.
      Knowledge Prerequisite: Vectorization, parallel algorithms.
      Mentor: Hartmut Kaiser (), Srinivas Yadav (vasu.srinivasvasu.14 [at] gmail.com), Nikunj Gupta (nikunj [at] illinois.edu), Giannis Gonidelis (gonidelis [at] hotmail.com)
      See issue #2271 on HPX bug tracker
      Project Size: 350 hour (large project)
      Add HPX to Compiler Explorer (godbolt.org)
      Abstract: Compiler Explorer https://godbolt.org/ is a widely popular web based application which provides easy access to multiple C++ compilers and environments allowing their users to write, test and share anything from small C++ scripts to large CMake-based projects quickly. Given its versatility we thought that it would be a convenient for HPX to have an integration with Compiler Explorer in some way. A preliminary idea is that we will maintain our own fork of Compiler Explorer (which is open source) and experiment with the HPX integration locally before making the integration public through a Pull Request to Compiler Explorer. The result could even be constrained to an environment somewhat similar to Compiler Explorer just for HPX where prospective users would experiment with quick HPX scripts before downloading, building and running the whole library.
      Difficulty: Medium/Hard
      Expected result: Develop a fork of Compiler Explorer (or application with similar basis) where HPX is integrated and available for quick testing and scripting.
      Knowledge Prerequisite: C++, CMake, Compilers, Node.js
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com)
      Project Size: 175 (Medium project)
      Conflict (Range-Based) Locks
      Abstract: Some multi-threaded algorithms may require resources that must be held using a lock, but the locking mechanism may be range-based rather than absolute. Consider a large array of N items where a task requires some small subset of the items to be locked while a second task requires a second range. If these tasks are placed into a DAG so that task2 can only run once task1 has been completed, it will be inefficient when the range of items used by task2 does not overlap the range from task1. When many tasks operate on the range, with randomly overlapping or non-overlapping regions, DAG-based task scheduling leads to a highly inefficient strategy. We need a range based lock that can be templated over <items>, and that can then be locked/unlocked on ranges (of those items) and interact with our future<> based scheduling so that items will become ready when the range they need has no locks outstanding, and so that when a task releases a lock, any other tasks that overlap the range are in turn signaled as possibly ready. (For an example of how this is used in conventional HPC programming, look up Byte Range locks in MPI for Parallel IO to a single file). A successful implementation can be extended to multi-dimensional locking *2D/3D etc., ideally templated over dimensions and types).
      Difficulty: Medium/Hard
      Expected result: A test application that creates arrays of items and randomly assigns tasks to operate on regions of those items with locking and schedules the tasks to operate in a non-conflicting way.
      Knowledge Prerequisite: Thread-safe programming. Futures.
      Mentor: John Biddiscombe ()
      Project Size: 350 hour (large project)
      Standardize and Visualize HPX Benchmarks
      Abstract: HPX, as a high-performance computing framework, includes various benchmarks to measure the performance of its algorithms and runtime system. However, these benchmarks lack a standardized format and a comprehensive visualization tool that can help in analyzing performance trends over time and across different computing environments. This project aims to standardize the benchmark formats within HPX using third party benchmarking tools (recommendations below) and develop a visualization tool that can display benchmark results in an intuitive manner. The tool will used in conjunction with CI/CD to track and display performance regressions or improvements, and provide insights into the scalability and efficiency of new components.
      Additional References:
      Recommended Benchmarking Frameworks: Google Benchmark, Nanobench
      Nanobench in HPX
      Google Benchmark in HPX
      Difficulty: Medium/Advanced
      Expected result: 1) A unified format for HPX benchmarking using chosen benchmarking framework. 2) Automating the installation of the chosen benchmarking framework in the HPX build system. 3) A visualization tool (suggestion: a python script) to display the results.
      Knowledge Prerequisite: C++, Git, Python or plotting framework of your choice
      Mentor: Hartmut Kaiser () and Isidoros Tsaousis-Seiras (tsa.isidoros [at] gmail.com).
      Project Size: 350 hour (Advanced project)
      Rustize HPX!
      Abstract: Rust is an increasingly widely adopted language used because of it's performance and apparent safety. Providing performant HPX functionality written in C++ with Rust APIs would facilitate both safety and ease of learning HPX. The student shall design and implement Rust bindings for HPX, exposing all or parts of the HPX functionality with a Rust API.
      Difficulty: Medium
      Expected result: Demonstrate functioning bindings by implementing small example scripts for different simple use cases
      Knowledge Prerequisite: C++, Rust
      Mentor: Hartmut Kaiser ()
      Project Size: 350 hour (large project)
      Pythonize HPX!
      Abstract: Python is a widely adopted language due to its simplicity. Providing performant HPX functionality written in C++ with Pythonic APIs would facilitate both usage and ease of learning HPX. The student shall design and implement Python bindings for HPX, exposing all or parts of the HPX functionality with a 'Pythonic' API. This should be possible as Python has a much more dynamic type system than C++. Using Boost.Python and/or Pybind11 seem to be good choices for this.
      Difficulty: Medium
      Expected result: Demonstrate functioning bindings by implementing small example scripts for different simple use cases
      Knowledge Prerequisite: C++, Python
      Mentor: Hartmut Kaiser ()
      Project Size: 350 hour (large project)
      Create Generic Histogram Performance Counter
      Abstract: HPX supports performance counters that return a set of values for each invocation. We have used this to implement performance counters collecting histograms for various characteristics related to parcel coalescing (such as the histogram of the time intervals between parcels). The idea of this project is to create a general-purpose performance counter which collects the value of any other given performance at given time intervals and calculates a histogram for those values. This project could be combined with Add more arithmetic performance counters.
      Difficulty: Medium
      Expected result: Implement a functioning performance counter which returns the histogram for any other given performance counter as collected at given time intervals.
      Knowledge Prerequisite: Minimal knowledge of statistical analysis is required.
      Mentor: Hartmut Kaiser () and Mikael Simberg ()
      See issue #2237 on HPX bug tracker
      Project Size: 350 hour (large project)
      HPX User Projects
      These are projects that improve code that uses HPX. In general, the primary goal with these projects is to improve user uptake of HPX by demonstrating its use in other projects, and only minor fixes/changes/extensions should be necessary for the main HPX library itself.
      Implement your favorite Computational Algorithm in HPX
      Abstract: This is an open project for prospective students who don't want to get their hands dirty into core HPX development. The student shall utilize HPX to implement a short independent project that will utilize HPX for performance boost. The program can implement any given problem that requires heavy computational effort from the literature. Efficient matrix multiplication, sorting, stencil variations or any AI, Physics related problem would be a good candidate. An extensive list of use-case examples is already available in our source code. The goal of this project is for the student to get acquainted with HPX development and contribute to our vast range of applications.
      Difficulty: Easy
      Expected result: Implement a standalone program that utilizes HPX for performance.
      Knowledge Prerequisite: C++
      Mentor: Hartmut Kaiser () and Giannis Gonidelis (gonidelis [at] hotmail.com)
      Project Size: 175 hour (medium sized)
      Conduct a thorough Performance Analysis on HPX Parallel Algorithms (and optimize)
      Abstract: HPX implements all the C++ standard algorithms along with their ranges counterparts. Conducting extensive performance analysis on the existing implementations and coming up with possible optimizations would improve the efficiency of our parallel algorithms and boost HPX performance in general. The student shall expect to work both on top of HPX by writing custom benchmarks for weak and strong scaling, evaluate the results and perform source optimizations under the hood (core development).
      Difficulty: Medium
      Expected result: Boost the performance of at least one C++ standard algorithm in HPX.
      Knowledge Prerequisite: C++
      Mentor: Giannis Gonidelis (gonidelis [at] hotmail.com) and Hartmut Kaiser ()
      Project Size: 350 hour (large project)
      Legacy Project Ideas
      These are project ideas from previous Summer of Code years that we are still interested in working on, but it might be harder to find a mentor willing to supervise a student. Therefore, we would expect only very self-motivated and capable students to select a project from the legacy category. We cannot guarantee that we will select a project from this list unless we are quite satisfied that the student can complete the work.
      Implement Your Favorite Parcelport Backend
      Implement A Faster Associative Container for GIDs
      Create A Parcelport Based on WebSockets
      All to All Communications
      Distributed Component Placement
      Port Graph500 to HPX
      Port Mantevo MiniApps to HPX
      Distributed solver and load balancing for Peridynamics using asynchronous parallelism
      Bug Hunter
      Project Template
      We are looking to fund work on a number of different kinds of proposals (for more details about concrete project ideas, see below):
      Extensions to existing library features,
      New distributed data structures and algorithms
      Multiple competing proposals for the same project
      Implement Your Favorite Parcelport Backend
      Abstract: The HPX runtime system uses a module called Parcelport to deliver packages over the network. An efficient implementation of this layer is indispensable and we are searching for new backend implementations based on CCI, ucx, libfabric, or GASNet. These mentioned abstractions over various network transport layers offer the ability to do fast, one-sided RDMA transfers. The purpose of this project is to explore one of these and implement a parcelport using it.
      Difficulty: Medium-Hard
      Expected result: A proof of concept for a chosen backend implementation with performance results
      Knowledge Prerequisite: C++, Basic understanding of Network transports
      Mentor: Thomas Heller ()
      Project Size: 350 hour (large project)
      Implement a Faster Associative Container for GIDs
      Abstract: The HPX runtime system uses Active Global Address Space (AGAS) to address global objects. Objects in HPX are identified by a 128-bit unique global identifier, abbreviated as a GID. The performance of HPX relies on fast lookups of GIDs in associative containers. We have experimented with binary search trees (std::map) and hash maps (std::unordered_map). However, we believe that we can implement a search data structure based on n-ary trees, tries, or radix trees that exploit the structure of GIDs such that it allows us to have faster lookup and insertion.
      Difficulty: Medium-Hard
      Expected result: Various container approaches to choose from together with realistic benchmarks to show the performance properties
      Knowledge Prerequisite: C++, Algorithms
      Mentor: Thomas Heller ()
      Project Size: 350 hour (large project)
      Create A Parcelport Based on WebSockets
      Abstract: Create a new parcelport that is based on WebSockets. The WebSockets++ library seems to be a perfect starting point to avoid having to dig into the WebSocket protocol too deeply.
      Difficulty: Medium-Hard
      Expected result: A proof of concept parcelport based on WebSockets with benchmark results
      Knowledge Prerequisite: C++, knowing WebSockets is a plus
      Mentor: Hartmut Kaiser () and Thomas Heller ()
      Project Size: 350 hour (large project)
      All to All Communications
      Abstract: Design and implement efficient all-to-all communication LCOs. While MPI provides mechanisms for broadcasting, scattering and gathering with all MPI processes inside a communicator, HPX currently misses this feature. It should be possible to exploit the Active Global Address Space to mimic global all-to-all communications without actually communicating with every participating locality. Different strategies should be implemented and tested. A first and very basic implementation of broadcast already exists which tries to tackle the above-described problem. However, more strategies for granularity control and locality exploitation need to be investigated and implemented. We also have the first version of a gather utility implemented.
      Difficulty: Medium-Hard
      Expected result: Implement benchmarks and provide performance results for the implemented algorithms
      Knowledge Prerequisite: C++
      Mentor: Thomas Heller () and Andreas Schaefer ()
      Project Size: 175 hour (medium sized)
      Distributed Component Placement
      Abstract: Implement an EDSL to specify the placement policies for components. This could be done similar to [Chapels Domain Maps] (http://chapel.cray.com/tutorials/SC12/SC12-6-DomainMaps.pdf). In Addition, allocators can be built on top of those domain maps to use with C++ standard library containers. This is one of the key features to allow users to efficiently write parallel algorithms without having them worried too much about the initial placement of their distributed objects in the Global Address space
      Difficulty: Medium-Hard
      Expected result: Provide at least one policy that automatically creates components in the global address space
      Knowledge Prerequisite: C++
      Mentor: Thomas Heller () and Hartmut Kaiser ()
      Project Size: 350 hour (large project)
      Port Graph500 to HPX
      Abstract: Implement Graph500 using the HPX Runtime System. Graph500 is the benchmark used by the HPC industry to model important factors of many modern parallel analytical workloads. The Graph500 list is a performance list of systems using the benchmark and was designed to augment the Top 500 list. The current Graph500 benchmarks are implemented using OpenMP and MPI. HPX is well suited for the fine-grain and irregular workloads of graph applications. Porting Graph500 to HPX would require replacing the inherent barrier synchronization with asynchronous communications of HPX, producing a new benchmark for the HPC community as well as an addition to the HPX benchmark suite. See http://www.graph500.org/ for information on the present Graph500 implementations.
      Difficulty: Medium
      Expected result: New implementation of the Graph500 benchmark.
      Knowledge Prerequisite: C++
      Mentor: Patricia Grubel (), and Thomas Heller ()
      Project Size: 350 hour (large project)
      Port Mantevo MiniApps to HPX
      Abstract: Implement a version of one or more mini-apps from the Mantevo project (http://mantevo.org/ "Mantevo Project Home Page") using HPX Runtime System. We are interested in mini-applications ported to HPX that have irregular workloads. Some of these are under development, and we will have access to them in addition to those listed on the site. On the site, MiniFE and phdMESH would be good addition to include in HPX benchmark suites. Porting the mini-apps would require porting the apps from C to C++ and replacing the inherent barrier synchronization with HPX's asynchronous communication. This project would be a great addition to the HPX benchmark suite and the HPC community.
      Difficulty: Medium
      Expected result: New implementation of a Mantevo mini-app or apps.
      Knowledge Prerequisite: C, C++
      Mentor: Patricia Grubel () and Thomas Heller ()
      Project Size: 175 hour (medium sized)
      Distributed solver and load balancing for Peridynamics using asynchronous parallelism
      Abstract: Peridynamics is a reformulation of classical continuum mechanics (e.g., linear elastodynamics). The internal force at any point in the solid results from the interaction of that point with neighboring points within some distance ϵ. Typically, ϵ is much larger than the mesh size. As a result, the computation is more intensive and introduces more substantial data dependencies when partitioning the domain for parallel implementation. This project aims to develop and implement a distributed solver for Peridynamics in an existing codebase [1]. This project will benefit from the last year's GSoC student's effort on a similar goal but for a simplified nonlocal model [2]. In [2], several challenges associated with the parallelization of nonlocal models are highlighted, and algorithms are developed to address the challenges. In this project, we will apply techniques in [2] to the Peridynamics problem; first, we will implement the distributed solver; second, we will optimize the code so that compute node does the information exchange and calculation on the free degree of freedoms (DoFs) simultaneously to minimize the wait time. Finally, if possible, we will add the load balancing algorithm [2]. Here for the given compute node, free DoFs are those DoFs that do not depend on the data owned by other compute nodes. After GSoC, we intend to write a workshop paper based on this project's efforts and possibly present it at a computer science conference.
      Difficulty: Medium-Hard
      Expected result: Extend the existing shared memory code to a distributd code
      Knowledge Prerequisite: C++
      Mentor: Patrick Diehl () and Prashant K. Jha ()
      Project Size: 350 hour (large project)
      [1] https://github.com/nonlocalmodels/NLMech
      [2] https://arxiv.org/abs/2102.03819
      Port the GAP Benchmark Suite to HPX
      Abstract:
      GAP [1] provides a benchmark suite for the following graph algorithms:
      Breadth-First Search (BFS) - direction optimizing
      Single-Source Shortest Paths (SSSP) - delta stepping
      PageRank (PR) - iterative method in pull direction, Gauss-Seidel & Jacobi
      Connected Components (CC) - Afforest & Shiloach-Vishkin
      Betweenness Centrality (BC) - Brandes
      Triangle Counting (TC) - order invariant with possible degree relabelling
      This project requires modifying the existing benchmark suite to use HPX's data parallelism and asynchrony capabilities. This project serves as a stepping stone to a distributed implementation. After GSoC, we intend to write a workshop paper based on this project's efforts and possibly present it at a computer science conference.
      Difficulty: Easy-Medium
      Expected result: Provide an HPX implementation of the existing shared memory code
      Knowledge Prerequisite: C++
      Mentor: Chris Taylor
      [1] http://gap.cs.berkeley.edu/benchmark.html
      [2] https://github.com/sbeamer/gapbs
      HPX backend for OpenMPI
      Abstract:
      This project requires modifying the existing OpenMPI implementation to include HPX support. This project will improve distributed HPX application performance. After GSoC, we intend to write a workshop paper based on this project's efforts and possibly present it at a computer science conference.
      Difficulty: Medium
      Expected result: HPX integration with OpenMPI
      Knowledge Prerequisite: C/C++
      Mentor: Chris Taylor
      Bug Hunter
      Abstract: In addition to our extensive ideas list, several active tickets are listed in our issue tracker which are worth tackling as a separate project. Feel free to talk to us if you find something interesting. A prospective student should pick at least one ticket with medium to hard difficulty and discuss how to resolve it.
      Difficulty: Medium-Hard
      Expected result: The selected issues need to be fixed
      Knowledge Prerequisite: C++
      Mentor: Thomas Heller ()
      Project Size: 175 hour (medium sized)
      AI Project Ideas
      These are project ideas that involve AI methodologies in different applications.
      Spatio-Temporal Extrapolation with Generative AI: Advancing Storm Surge Forecast Accuracy through Bias Correction in Unmonitored Areas
      Spatio-Temporal Extrapolation with GNN: Advancing Storm Surge Forecast Accuracy through Bias Correction in Unmonitored Areas
      Transformer-based Image-to-Graph Conversion
      Spatio-Temporal Extrapolation with Generative AI: Advancing Storm Surge Forecast Accuracy through Bias Correction in Unmonitored Areas
      Abstract: In 2022, severe storms and tropical cyclones represented 14 out of the 18 documented weather and/or climate related disasters reported in the U.S., leading to a dreadful cost in human lives, but also to an overall financial cost exceeding 135 billion dollars [1]. The pronounced frequency and severity of such events demonstrates the critical importance of improving storm surge forecast tools in terms of both accuracy and efficiency. In this context, recent work aims to predict the systemic error between physics-based storm surge forecast model and observed water level data were obtained from gauge stations and use it to correct the simulation results on gauge stations. However, ensuring the accuracy of water level simulations across extensive and unevenly monitored locations remains a critical challenge. Given the limitations of traditional interpolation methods and the sparse distribution of gauge stations, we propose the innovative use of Generative Artificial Intelligence (AI) to address the challenge of extrapolating bias correction values to unmonitored areas. Generative AI, through its capacity to learn and mimic the distribution of complex datasets, offers a groundbreaking approach to understanding and predicting environmental variables across spatial and temporal scales. By training on available data from gauge stations, Generative AI models can generate accurate bias correction predictions for regions beyond the gauge stations. The proposed methodology leverages the latest advancements in Generative AI, including techniques like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), to model the complex interdependencies within the offsets data. By incorporating spatial correlations and environmental covariates, the Generative AI framework aims to produce spatially coherent and temporally consistent bias corrections across the simulation area. A case study implementing this Generative AI approach will be conducted to validate its effectiveness in enhancing model accuracy.
      Difficulty: Medium-Hard
      Expected result: Implementation of generative AI AI model for Spatio-Temporal Extrapolation of offsets.
      Knowledge Prerequisite: Python, Machine learning basics
      Mentor: Noujoud Nader (noujoude.nader [at] gmail.com) and Hartmut Kaiser ()
      Project Size: 350 hour (large project)
      Spatio-Temporal Extrapolation with GNN: Advancing Storm Surge Forecast Accuracy through Bias Correction in Unmonitored Areas
      Abstract: In 2022, severe storms and tropical cyclones represented 14 out of the 18 documented weather and/or climate related disasters reported in the U.S., leading to a dreadful cost in human lives, but also to an overall financial cost exceeding 135 billion dollars [1]. The pronounced frequency and severity of such events demonstrates the critical importance of improving storm surge forecast tools in terms of both accuracy and efficiency. In this context, recent work aims to predict the systemic error between physics-based storm surge forecast model and observed water level data were obtained from gauge stations and use it to correct the simulation results on gauge stations. However, ensuring the accuracy of water level simulations across extensive and unevenly monitored locations remains a critical challenge. Given the limitations of traditional interpolation methods and the sparse distribution of gauge stations, we propose the innovative use of Graph Neural Network (GNN) to address the challenge of extrapolating bias correction values to unmonitored areas. GNNs are inherently good at capturing spatial relationships and dependencies between nodes in a graph. This can be particularly useful for modeling the influence of nearby gauge stations on unmonitored areas. In addition, GNNs can integrate various types of information, including physical properties and geographical context, which can be critical for accurate extrapolation in environmental sciences. They can easily integrate heterogeneous data, making them suitable for our complex environmental systems where offset data is affected by the presence of natural barriers and geographical features, like a lake between two gauge stations.
      Difficulty: Medium-Hard
      Expected result: Implementation of GNN AI model for Spatio-Temporal Extrapolation of offsets.
      Knowledge Prerequisite: Python, Machine learning basics
      Mentor: Noujoud Nader (noujoude.nader [at] gmail.com) and Hartmut Kaiser ()
      Project Size: 350 hour (large project)
      Transformer-based Image-to-Graph Conversion
      Abstract: The process of reconstructing graph representations from medical images, known as Image-to-Graph conversion, is a common task, particularly evident in biomedical imaging for extracting vessel graphs. Here, we propose a novel Machine Learning (ML)-based Image-to-Graph pipeline that emphasizes edge features, which are critical for applications such as blood flow simulation. This pipeline incorporates advanced ML algorithms, including the use of the Transformer model, to serve dual purposes: firstly, to objectively extract vascular features from medical images without relying on subjective judgment or requiring extensive user skill; and secondly, to facilitate rigorous model validation. For our model training and validation, we will utilize 3D image datasets of healthy and diseased subjects, including those of the brain and lungs.
      Difficulty: Medium-Hard
      Expected result: Implementation of transformer model for image to graph conversion.
      Knowledge Prerequisite: Python, Machine learning basics, tranformers
      Mentor: Noujoud Nader (noujoude.nader [at] gmail.com) and Hartmut Kaiser ()
      Project Size: 350 hour (large project)
      Project: Template
      Abstract:
      Difficulty:
      Expected result:
      Knowledge Prerequisite:
      Mentor:
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/steororar-group/
    idea_list_url: https://github.com/STEllAR-GROUP/hpx/wiki/Google-Summer-of-Code-%28GSoC%29-2025#2025-hpx-project-ideas

  - organization_id: 144
    organization_name: Stichting SU2
    no_of_ideas:
    ideas_content: |
      [Sponsors]
      Home
      News
      Forums
      Wiki
      Links
      Jobs
      Events
      Tools
      Feeds
      About
      Search
      Home > Forums > Software User Forums > SU2 > SU2 News & Announcements
      GSoC 2025 Projects
      User Name Remember Me
      Password
      Register Blogs Community New Posts Updated Threads Search
      
        LinkBack Thread Tools Search this Thread Display Modes
        February 7, 2025, 17:44
      GSoC 2025 Projects
        #1
      bigfootedrockmidget
      Senior Member
       
      bigfoot
      Join Date: Dec 2011
      Location: Netherlands
      Posts: 736
      Rep Power: 21
      Dear SU2 friends,
      The SU2 Foundation is applying for Google Summer of Code 2025! From all the possible projects, we have made a selection of the topics that could be used in a GSoC project.
      The document can be viewed here:
      
      
      GSOC 2025 ideas list
      
      
      For more information on Google Summer of code, please see here:
      https://summerofcode.withgoogle.com/
      
      
      Please also read our other announcement on How to Apply:
      GSoC 2025 : How to apply
      Last edited by bigfootedrockmidget; February 16, 2025 at 19:34.
       
        February 7, 2025, 17:51
        #2
      bigfootedrockmidget
      Senior Member
       
      bigfoot
      Join Date: Dec 2011
      Location: Netherlands
      Posts: 736
      Rep Power: 21
      For completeness, the complete project description has been copied below. Note that the most up to date description can be found in the link to the document above
      
      
      Project 1: Adding pressure-based solver
      
      Project Description (max. 5 Sentences)
      The pressure-based solver has been requested for a long time. This solver is an important addition to the CFD solvers, especially for low Mach and incompressible flows. People have worked on it (detailed documentation available), and there is a branch that contains a working version, but this was never finalized and added to the main SU2 branch. Hence, the project's objective is to evaluate the current status of attempts, and propose a strategy for getting the pressure-based solver in the latest version of SU2.
      Expected Outcome (deliverables): Finalize pressure-based solver, validate with test cases, tutorial and merge the PR.
      Skills Required: C++, experience with CFD and numerical methods
      Possible Mentors: Nitish Anand and Edwin van der Weide
      Expected Project Size: 175 hrs/medium
      Difficulty rating: medium-hard (needs experience with Computational Fluid Dynamics)
      
      
      Project 2: Using data-driven, physics-informed machine learning to model fluid properties in computational fluid dynamics.
      
      Project Description (max. 5 Sentences)
      The properties of complex fluids can be modeled in SU2 by using a data-driven method that uses physics-informed neural networks (PINNs). This method is very efficient and accurate, but is sometimes not robust when it comes to inverse regression. The main goals of this project are:
      Develop and implement a smart method for choosing the starting point of inverse regression.
      Indicate in the flow solution where predictions of the fluid properties may be unreliable (due to phase transition or inaccurate inverse regression).
      Improve the efficiency of the neural network evaluation algorithm.
      Expected Outcome (deliverables): Validation of regression algorithm robustness and validation study of algorithmic efficiency of neural network evaluation algorithm. Addition of tutorial to SU2 tutorial library and merge changes with a PR.
      Skills Required: C++, python, SU2
      Possible Mentors: Evert Bunschoten (lead)
      Expected Project Size: 175 hrs/medium
      Difficulty rating: easy-medium (experience in CFD or fluid modeling preferred)
      
      
      
      
      Project 3: Graphical User Interface: coupling to python wrapper and json validation
      
      Project Description (max. 5 Sentences)
      In GSoC 2024 we improved the SU2 GUI and made it suitable for basic use. We would like to keep the momentum and focus in this project on two main things: 1. coupling with the python wrapper so users are able to write python scripts inside the GUI, and export the GUI setup in python format; and 2. Write a json validation for the configuration file. The goal is also that the json validation will replace the hardcoded c++ validation that we have in the main SU2 solver.
      Expected Outcome (deliverables): SU2-GUI (python+trame library), availability on github, json validation scheme, python coupling for initialization and boundary condition.
      Skills Required: Python, Paraview, SU2, Trame, json
      Possible Mentors: Nijso Beishuizen, Ujjawal Agrawal (2024 GSoC Alumnus)
      Expected Project Size: 175 hrs/medium
      Difficulty rating: medium
      
      
      Project 4: Make it easy to add and update unit tests
      
      Project Description (max. 5 Sentences)
      One of the most important requirements for a CFD code is that users trust the outcome. This trust is gained by performing Unit Tests, as well as Verification and Validation tests. We need more online tests, and these tests should be 1. Easy to add and 2. Complete in their testing. We therefore need to automate the creation, adding and maintaining of these tests.
      Expected Outcome (deliverables) Templated and Automated unit and V&V tests, putting current tests in the new system, regeneration of the results (figures, data, etc.), possible creation of new results.
      Skills Required: python, C++
      Possible Mentors: Nijso Beishuizen (lead)
      Expected Project Size (90 hrs/ small , 175 hrs/medium, 350 hrs/large): 90hrs, small
      Difficulty rating (easy (little experience/background), medium (some experience/background), hard (experienced)): easy
      
      
      
      Project 5: Continuation of GPU acceleration in SU2
      
      Project Description (max. 5 Sentences)
      The SU2 code relies heavily on sparse linear algebra. In this area, there is significant speed-up potential with the adoption of GPU-based processing, as was demonstrated in the GSOC 24 project that applied CUDA to sparse matrix-vector multiplications in SU2. The objective of this project is to move more linear algebra operations to GPU in order to avoid host-device communication bottlenecks within the sparse linear system solver.
      Expected Outcome (deliverables) Make SU2’s sparse linear solver GPU-native, i.e. minimal host-device communication after the initial setup of the system.
      Skills Required C++
      Possible Mentors: Pedro Gomes (lead), Ole Burghardt
      Expected Project Size (90 hrs/ small , 175 hrs/medium, 350 hrs/large): 175 hrs (medium)
      Difficulty rating (easy (little experience/background), medium (some experience/background), hard (experienced)): medium
      
      Project 6: Extending turbomachinery geometry handling for mixed-flow applications
      
      Project Description (max. 5 Sentences)
      Mixed-flow turbomachinery components, such as NASA’s High Efficiency Centrifugal Compressor, combine the properties of both axial and radial machines. Such geometries can be difficult to simulate due to their complex geometric dependencies. This project aims to refactor SU2’s current turbomachinery geometry handling and extend it to be able to handle mixed-flow machinery.
      Expected Outcome (deliverables) Merged PR containing the new, flexible axes of rotation, and validation of the NASA HECC testcase
      Skills RequiredC++, SU2
      Possible Mentors: Josh Kelly
      Expected Project Size (90 hrs/ small , 175 hrs/medium, 350 hrs/large):175 hrs (medium)
      Difficulty rating (easy (little experience/background), medium (some experience/background), hard (experienced)): easy/medium
      Last edited by bigfootedrockmidget; February 10, 2025 at 16:48.
       
      
      
      Posting Rules
      You may not post new threads
      You may not post replies
      You may not post attachments
      You may not edit your posts
      BB code is On
      Smilies are On
      [IMG] code is On
      HTML code is Off
      Trackbacks are Off
      Pingbacks are On
      Refbacks are On
      Forum Rules
      
      Similar Threads
      Thread Thread Starter Forum Replies Last Post
      GSoC Applications - How to Apply bigfootedrockmidget SU2 News & Announcements 17 March 12, 2025 14:38
      Marine 2025 Conference: Invited Session (IS03) about OpenFOAM IHFOAM Team OpenFOAM Announcements from Other Sources 0 December 19, 2024 10:45
      Help merging workbench projects gtarroyo ANSYS 1 May 19, 2021 06:39
      openFoam freelancer for short projects sts CFD Freelancers 7 March 24, 2021 12:32
      Skill increasing projects for 18 months (or more) tohell92 Lounge 1 January 25, 2021 01:47
      
      
      All times are GMT -4. The time now is 10:56.
      
      Contact Us - CFD Online - Privacy Statement - Top
        © CFD Online
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/stichting-su2/
    idea_list_url: https://www.cfd-online.com/Forums/su2-news-announcements/259420-gsoc-2025-projects.html

  - organization_id: 145
    organization_name: Sugar Labs
    no_of_ideas:
    ideas_content: |
      GSoC 2025 Ideas
      Project Ideas
      Git backend for Turtle Blocks and Music Blocks
      Color sensor for Music Blocks for photos and real-time video
      AI-powered Debugger for Music Blocks
      Improve synth and sample features in Music Blocks
      Generative AI Instrument Sample Generation for Music Blocks
      AI Code generation for lesson plans and model abstraction layer
      AI tools for reflection
      Music Blocks 4 Program Engine
      Music Blocks 4 Masonry Module
      Add AI-assistant to the Write Activity
      Refactor the Infoslicer Activity to generate plain-language summaries
      Refactor the chatbot in the Speak Activity to use gen-AI
      GTK4 exploration
      JS internationalization
      Sugarizer Human Activity pack
      Pippy Debugger
      Math Games
      Git backend for Turtle Blocks and Music Blocks
      Prerequisites
      Experience with Git
      Experience with JavaScript
      Experience with Music Blocks and Turtle Blocks
      Description
      Portfolio creation, reflection, and collaboration are important parts of the educational philosophy at Sugar Labs, and Git version control is a great way to explore all these things.
      At Sugar Labs, we've created some initial designs](https://drive.google.com/file/d/15G0vtr-1JyzCorwmgjvXE-37vwZMLgJD/view?usp=sharing) for a couple approaches to introducing Git version control to young learners. This proposal focuses on introducing Git version control through our existing web-based programs, namely Turtle Blocks and Music Blocks. Both these programs have a feature to publish projects to a server called the "Planet". Currently the Planet just stores projects that users have made, without any sort of version control features like fork, history, or checkout.
      This project requires a contributor to work closely with Sugar Labs mentors to implement a system of Git version control features, running on a backend server, that are exposed to the user.
      References:
      https://drive.google.com/file/d/15G0vtr-1JyzCorwmgjvXE-37vwZMLgJD/view?usp=sharing
      Project Length
      350 hours
      Difficulty
      Hard
      Coding Mentors
      Walter Bender Sumit Srivastava
      Assisting Mentors
      Devin Ulibarri
      Color sensor for Music Blocks for photos and real-time video
      Prerequisites
      Experience with JavaScript
      Experience with Music Blocks
      Description
      Music Blocks has a feature to detect the color of pixels generated from drawing within the program, but it cannot detect the color of pixels from images that are either uploaded or from a webcam. By adding a feature to detect color from both uploaded images and a live webcam stream, users would be able to implement Lego music notation for the blind and similarly interactive programs.
      The goal of the project is to develop extended functionality to our existing tools of turtle/mouse glyph movement and limited color detection to sense color from uploaded images, as well as the real-time feed from a webcam. Upon successful implementation, the turtle/mouse glyph will be able to detect the color of pixels underneath it, regardless of whether those pixels were drawn by the turtle/mouse itself, part of an uploaded image stamped to the canvas, or part of a live webcam video feed into Music Blocks. One test of success is to run our Lego music notation for the blind project with a live feed. The result should be able to playback and record the abstract brick notation based on its contrasting colors.
      References:
      https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c
      https://vimeo.com/983707992
      https://vimeo.com/983697295
      Project Length
      175 hours
      Difficulty
      Medium
      Coding Mentors
      Walter Bender
      Assisting Mentors
      Devin Ulibarri
      AI-powered Debugger for Music Blocks
      Prerequisites
      Experience with Python
      Experience with Music Blocks
      Experience with LLMs/Chatbots
      Experience with AWS
      Experience with FastAPI
      Description
      The idea is to enhance Music Blocks with an AI-powered debugger. This feature aims to bridge the gap between users' creative ideas and their ability to troubleshoot or fully utilize the platform's features. This AI-powered debugger will provide real-time assistance by answering questions, explaining features, and offering creative suggestions. It will help users quickly identify and resolve issues in their projects or block connections This enhancement would make the platform more accessible for beginners while streamlining the debugging and experimentation process for advanced users.
      Specifically, we aim to achieve the following:
      Train an open-source LLM to understand Music Blocks projects and develop the ability to debug them effectively.
      Implement robust Retrieval-Augmented Generation (RAG) for the LLM model to enhance contextual understanding.
      Integrate the AI chatbot and debugger into the Music Blocks platform.
      Develop FastAPI endpoints to deploy the model efficiently.
      Work on techniques to minimize hallucinations and improve accuracy.
      Project Length
      350 hours
      Difficulty
      Hard
      Coding Mentors
      Walter Bender Sumit Srivastava
      Assisting Mentors
      Devin Ulibarri
      Improve synth and sample features in Music Blocks
      Prerequisites
      Experience with JavaScript
      Experience with Music Blocks
      Experience with Tone.JS
      Description
      Users have two main methods within Music Blocks to play with sound: synths and samples. For our synth, we use tone.js. For samples, we use .wav binaries and transpose the sound to different pitches. While these features work "well enough," there is still more that can been to make them useful. For this project, a contributor would work closely with their mentors to 1) update the sampler widget, 2) port a list of free/libre/open samples into Music Blocks, and 3) add to the Set Instrument feature and Sampler Widget the ability to assign multiple samples for the same instrument with criteria (e.g. high and low, short and long) for a more natural sound.
      Updating the sampler widget will involve updating tone.js to its current version, debugging any issues that updates may cause, and making improvements to the UI/UX of the widget itself. Improvements include adding a tuner feature in Sampler Widget, just like https://www.musicca.com/tuner and adding a way to do micro adjustments in cents.
      Porting samples into Music Blocks will require following the directions specified in the Music Blocks documentation to convert a curated list of samples. After completing this, the user-facing menus showing the samples will need to be updated and organized based on instrument type. There is some room to get creative with the presentation of the instruments, perhaps adding icons for each instrument.
      The final part of the project is perhaps the most challenging. It will require adding additional functionality so that a user can either upload or record multiple samples of an instrument or voice to be assigned to a custom instrument in Music Blocks. Doing this will make the overall tone of the instruments more persuasive. For example, if the Music Blocks project has short, staccato sounds, the playback can use the short sample created by a recorded instrument.
      References:
      https://github.com/sugarlabs/musicblocks/tree/master/sounds/samples
      "Processing for pitched (non-percussion) samples" section of https://wiki.sugarlabs.org/go/Music_Blocks/2025-02-09-meeting
      A professionals guide to creating "virtual instruments": https://www.nicolastiteux.com/en/blog/making-a-virtual-instrument-a-guide-to-sampling/
      Possible samples: https://philharmonia.co.uk/resources/sound-samples/
      Possible samples: https://github.com/sonic-pi-net/sonic-pi/tree/dev/etc/samples
      Possible samples: https://freesound.org/people/MTG/
      Project Length
      350 hours
      Difficulty
      Hard
      Coding Mentors
      Walter Bender
      Assisting Mentors
      Devin Ulibarri
      Generative AI Instrument Sample Generation for Music Blocks
      Prerequisites
      Experience with JavaScript and Python
      Experience with Music Blocks
      Experience with Tone.JS
      Experience with LLMs/neural-networks
      Description
      For this project, a contributor would work closely with their mentors create an API to a gen-AI to generate samples based on a user prompt.
      In order to give users (nearly) limitless options for samples, we are adding to the project's scope a gen-AI-enabled sample generator. A user should be able to prompt a sound font, such as "something between a heavy metal guitar and a lion roar" or "something between a clarinet and a human singing 'ah'" additionally, a user should be able to play an instrument or upload recorded audio of an instrument and prompt modifications for the gen-AI to make to the sound, such as "make this recording of my acoustic cello sound like an electric cello with heavy distortion and get a result that they can use in their project's code. A contributor will need to extend our sample widget (which currently records audio) to accept a user prompt, create an API to call an LLM/neural-network backend, and test/tweak the gen-AI backend to create an appropriate sample for the user. The results of this part of the project need not be "perfect" by the end of the summer. A solid proof of concept will be sufficient.
      In particular, our focus will be on achieving the following objectives:
      Extend the sample widget to support user prompts for AI-generated sound samples.
      Develop an LLM-based generative AI backend to produce high-quality, relevant sound samples.
      Build a high-performance API using FastAPI to streamline interactions between the widget and the LLM.
      Project Length
      350 hours
      Difficulty
      Hard
      Coding Mentors
      Walter Bender Sumit Srivastava
      Assisting Mentors
      Devin Ulibarri
      AI Code generation for lesson plans and model abstraction layer
      Prerequisites
      Experience with Python
      Experience with Music Blocks
      Experience with LLMs/Chatbots
      Experience with Fine tuning methods and RAG.
      Description
      Develop and train an open-source Large Language Model to generate Music Blocks project code, enabling the integration of code snippets into the lesson plan generator for better understanding of the projects. Additionally, by implementing a model abstraction layer, the AI system will remain flexible and model-agnostic, allowing seamless integration of different AI models while maintaining consistent code generation capabilities. This approach ensures long-term sustainability and adaptability as AI technology evolves while keeping the core functionality of Music Blocks accessible and extensible.
      Specifically, we would be working toward accomplishing the following:
      Train open source LLM to generate code to create new Music Blocks projects.
      Implement model abstraction layer to make the AI system model agnostic and robust.
      Increase database size by including more lesson plans and projects' data to get better response related to the projects.
      Implement Approximate Nearest Neighbor (ANN) algorithms for faster retrieval.
      Develop FastAPI endpoints to deploy the model.
      Work on and implement techniques to minimize hallucination.
      Project Length
      350 hours
      Difficulty
      Hard
      Coding Mentors
      Walter Bender Sumit Srivastava
      Assisting Mentors
      Devin Ulibarri
      AI tools for reflection
      Prerequisites
      Experience with Python/JavaScript
      Experience with LLMs/Chatbots
      Description
      While off-the-shelf Generative AI tools are great at helping a learner to create, they offer little in regard to reflecting upon those creations. But reflection is a critical (and too often overlooked) part of the Constructionist learning pedagogy. With some prompting -- something LLMs are quite good at -- we can engage the learner in a quality relfective practice. The dialog could occur when exiting any Sugar activity as part of the journaling process or whenever a Music Blocks or Turtle Blocks project is saved to the Planet. Rather than just being presented with an empty form, the learner will be prompted to talk about what they did, why they did it, what they learned and what they might do next.
      Specifically, we would be working toward accomplishing the following:
      Research different approaches to reflective practice
      Train open source LLM to generate code to prompt the learn with a multitude of these approaches to reflection
      Develop FastApi endpoints to deploy the model.
      Deploy this model in either the Music Blocks Planet or the Sugar Journal or the Sugarizer Journal to be triggered whenever a project is paused or saved
      Project Length
      350 hours
      Difficulty
      Hard
      Coding Mentors
      Walter Bender Sumit Srivastava
      Assisting Mentors
      Devin Ulibarri
      Music Blocks 4 Masonry Module
      Prerequisites
      Proficiency in TypeScript
      Proficiency in JavaScript DOM API
      Experience with React Functional Components and Hooks
      Familiarity with Storybook and Vitest
      Familiarity with SVG paths and groups
      Description
      Music Blocks programs are designed to be built interactively by connecting program constructs, which are visually represented as snap-together, Lego-like graphical bricks. The goal is to develop a module for Music Blocks (v4) that enables the creation of Music Blocks programs.
      The project will begin with the development of a framework for generating individual brick components that represent various program syntax constructs. This will be followed by the creation of utilities to represent any program structure through visual connections between the bricks. Next, a component will be built to display all available program bricks, organized into categories, sections, and groups. Finally, a workspace will be developed where users can drag-and-drop, as well as connect and disconnect the program bricks to create their programs.
      To draw the bricks, we will use SVG paths, so a solid understanding of SVG path commands is crucial. The development will follow an Object-Oriented Programming approach in TypeScript, with the rendering and management of visual states handled using React Functional Components. A strong understanding of both TypeScript and React is expected.
      This project began last year, and you will be expected to build upon the progress made and complete the module.
      The overall objectives are as follows:
      Collaborate with project maintainers to create a design document outlining functional requirements, UI considerations, both high-level and low-level designs, and a technical specification.
      Develop utilities to generate SVG paths for the bricks based on configurations.
      Build utilities to represent and manipulate Music Blocks programs in-memory.
      Develop the four individual submodules outlined above.
      Write Storybook stories to document and showcase UI components.
      Implement unit tests for functions and classes using Vitest.
      Focus on optimizing processing performance.
      Export a minimal API for integration with other parts of the application.
      Project Length: 350 hours
      Difficulty: Hard (★ ★ ★ ★ ★)
      Tech Stack
      TypeScript 5, React 18, Sass, Storybook, Vitest, Vite
      Mentors
      Anindya Kundu
      Assisting Mentors
      Walter Bender
      Devin Ulibarri
      Music Blocks 4 Program Engine
      Prerequisites
      Proficiency in TypeScript and Object-Oriented Programming
      Experience with writing unit tests using Jest/Vitest
      Good understanding of the JavaScript Event Loop
      Understanding of Abstract Syntax Trees (AST)
      Tech Stack
      TypeScript 5, Vitest, Vite
      Description
      Music Blocks is a programming platform, and at its core is the execution engine responsible for running Music Blocks programs. This project will focus on building the execution engine and the necessary components to represent and execute Music Blocks programs in-memory.
      The project will begin by refining the Object-Oriented program syntax constructs. These constructs will encapsulate the logic for each syntax element and will serve as the foundation for developing a framework to represent Abstract Syntax Trees (ASTs) for Music Blocks programs. Additional utilities will be built to manage instances of these syntax constructs, thus completing the static pieces.
      Next, several components will need to be developed to execute the program ASTs, forming the dynamic pieces of the project. Key components include:
      Parser: Responsible for parsing the nodes of the ASTs in inorder traversal.
      State Manager: Manages the program state at any given point during execution.
      Interpreter: Executes individual expressions and instructions.
      It’s important to note that Music Blocks programs combine both imperative and declarative constructs. Additionally, some instructions in the programs execute over a time duration, and the programs themselves are multi-threaded. These threads must run concurrently while ensuring proper synchronization.
      We currently have a work-in-progress on github.com/sugarlabs/musicblocks-v4-lib, but some design decisions need to be revisited. This project will involve understanding and refining these design choices and completing the remaining components.
      The overall objectives are as follows:
      Collaborate with project maintainers to define all expected functionalities and behaviors, and write a technical specification.
      Collaborate with project maintainers to develop a concrete execution algorithm, addressing time-based instructions, concurrency, and synchronization.
      Refine and complete the static components responsible for program representation.
      Refine and complete the dynamic components responsible for program execution.
      Write comprehensive unit tests for all components.
      Focus on optimizing runtime performance.
      Project Length: 350 hours
      Difficulty: High (★ ★ ★ ★ ☆)
      Mentors
      Anindya Kundu
      Assisting Mentors
      Walter Bender
      Devin Ulibarri
      Add an AI-assistant to the Write Activity
      Prerequisites
      Experience with Python
      Experience with Sugar activities
      Experience with LLMs/Chatbots
      Description
      Sugar pioneered peer editing in its Write Activity. However, the Write Activity has never had any serious support for grammar correction (just spell check) and none of the more recent developments around AI-assisted writing. The goal of this project is to add AI-assistance to the writing process: both in the form of providing feedback as to what has been written and making suggestions as to what might be written.
      The challenge will be both in terms of workflow integration and UX.
      Project Length
      350 hours
      Difficulty
      High
      Coding Mentors
      Walter Bender Ibiam Chihurumnaya
      Assisting Mentors
      Refactor the Infoslicer Activity to generate plain-language summaries
      Prerequisites
      Experience with Python
      Experience with Sugar activities
      Experience with LLMs/Chatbots
      Description
      The Infoslicer Activity is designed to help teachers extract content from the Wikipedia in order to create lesson plans. This is currently a manual, extractive process. It is well suited to generative AI. The goal would be to have a teacher type in a theme for a lesson and have the AI create a simple lesson plan, which the teacher can then edit.
      The biggest challenge to summarization using generative AI is hallucinations. A work-around for this is to include a validation step that surfaces evidence (or lack of evidence) for each assertion in the lesson plan. This will introduce some workflow and UX challenges.
      Project Length
      350 hours
      Difficulty
      High
      Coding Mentors
      Walter Bender Ibiam Chihurumnaya
      Assisting Mentors
      Refactor the chatbot in the Speak Activity to use gen-AI
      Prerequisites
      Experience with Python
      Experience with Sugar activities
      Experience with LLMs/Chatbots
      Description
      The Speak Activity is one of most popular Sugar activities. It allows someone just beginning to familiarize themselves with reading to interact with synthetic speech. It has both chat and chatbot capabilities, so that learners can share what they type with others, often using invented spelling. It would be a nice improvement if there were a chatbot option to allow a learner to have a conversation with a more modern chatbot -- LLM-based. This would contextualize the learner's experience with writing -- a tool for both self expression and communication.
      The project would entail both enabling the LLM chatbot and doing some tuning in order to accommodate invented spelling. Finally, it will be important to create the proper persona, in this case, an adult explaining to a young child.
      Project Length
      175 hours
      Difficulty
      Medium
      Coding Mentors
      Ibiam Chihurumnaya
      Assisting Mentors
      Walter Bender
      GTK4 Exploration
      Prerequisites
      Experience with C
      Experience with Python
      Experience with GTK
      Good understanding of Sugar Core architecture
      Description
      Sugar 0.120 runs on GTK3 and needs to be ported to GT4, we need to port Sugar and its core activities to support GTK4 before GTK3 gets to its EOL.
      Project Task Checklist
      Migrate minimal sugar-toolkit-gtk3 components to support Hello World activity, in particular the activity and graphics classes.
      Migrate Hello World activity.
      Document migration strategy based on extending any existing upstream GTK3 to GTK4 porting documentation.
      Migrate remaining toolkit components.
      Extend Hello World to use remaining toolkit components, and rename as a Toolkit Test activity,
      Migrate Sugar.
      Migrate the Fructose activity set, as time permits.
      Steps to start
      Plan migration.
      Setup a live build development environment.
      See the GTK4 migrating doc.
      Project length
      350 hours
      Difficulty:
      High
      Coding Mentors
      Ibiam Chihurumnaya
      JS internationalization
      Prerequisites
      Experience with JavaScript
      Description
      Our JavaScript activities are using a somewhat antiquated mechanism for internationalization, the webL10n.js library. It does not even support plurals or any language-specific formatting. i18next looks like a well-maintained and promising alternative.
      This project involves: (a) researching the state of art of language localization for JavaScript, keeping in mind that we are currently maintaining PO files; (b) making a recommendation as to the framework; (c) proposing a path to implementation; and (d) implementing the solution in Music Blocks. (Other JS projects can follow along.)
      Project Task Checklist
      research
      recommendation
      plan
      coding
      Project length
      175 hours
      Difficulty:
      Medium
      Coding Mentors
      Walter Bender
      Sugarizer Human Activity pack
      Prerequisites
      Experience with JavaScript/HTML5 in VanillaJS or with Vue.js
      Experience with three.js 3D framework
      Knowledge of 3D tools, capacity to create/combine 3D assets
      Description
      The objective of this project is to:
      Finalize the 3D Human Body activity
      Create a new activity named Stickman Animation
      
      
      3D Human Body activity
      The human Body activity has been started on https://github.com/llaske/sugarizer/tree/feature/humanbody.
      Tasks to do:
      Identify the missing assets for the body layer and the organs layer (only skeleton layer is here today)
      Integrate these layers in the activity and the way to change layer
      Implement the shared mode for doctor mode
      Review the UI for toolbar and popups
      Localize the activity
      Suggest other improvements
      
      Stickman Animation activity
      Create a new activity to allow creation of animated sequence of a stickman.
      The idea of the activity is a "keyframe animation" tool that lets you pose and program a stick figure to rotate, twist, turn, tumble, and dance. The new activity can be integrated into many school subject areas such as creative writing, art, drama, geometry and computer programming. Students can make figures that relate to a subject the class is studying, and share them with peers using collaboration feature. It helps children develop spatial and analytical thinking skills and to express ideas that they might not have words for yet.
      Features expected:
      Put the stickman figure in different poses by moving dots
      Create and order frames with the different poses created
      Play/Pause the whole frames
      Change speed
      Share and collaborate
      Export as a video
      Access to a list of existing fun templates
      Import a photo of an human body to create a stickman figure in the same pose
      Inspirations:
      https://activities.sugarlabs.org/en/sugar/addon/4044
      https://www.spatial.io/g/stick-animator
      https://flipanim.com/
      https://pivotanimator.net/
      https://drawastickman.com
      https://stickfigure-recorder.web.app/
      First steps to starts
      Complete the Sugarizer Vanilla Javascript activity development tutorial or the Sugarizer Vue.js activity development tutorial. Publish on Discord a video of the Pawn activity running.
      Start working of tasks listed for Human Body activity
      Create a mockup of the Stickman Animation activity
      Project length
      175 hours
      Difficulty: ★ ★ ☆ (medium)
      Coding Mentors
      Lionel Laské
      Assisting Mentors
      Samarth Bagga
      Pippy Debugger
      Prerequisites
      Experience with Python
      Experience with Sugar activities
      Experience with LLMs/Chatbots
      Description
      Many LLM programs for coding are almost exclusively marketed as "helping you write code for you". However, we believe that LLMs can also assist learners to debug their code. This project proposal is to create an LLM-powered debugger for Pippy, the Sugar Activity for creating code in Python.
      The proposed Pippy Debugger integrates with the existing Pippy Activity. The LLM-powered debugger should be able to read a learner's code and offer suggestions for improvement when prompted. It should also help engage the learning in a conversation about how to discover where to look to find bugs and how to think about resolving them -- in other words, take the learning on a debugging journey as opposed to just spoon-feeding a solution. And since we work with youth, we need to make sure that the debugger's output is age-appropriate. The Pippy interface will also be updated to expose the new feature to a user.
      Project Length
      175 hours
      Difficulty
      Medium
      Coding Mentors
      Walter Bender Ibiam Chihurumnaya Kshitij Shah
      Math Games
      Prerequisites
      Experience with Python
      Experience with Sugar activities
      Interest in math puzzles and games
      Description
      While Sugar has lots of activities, you can never have enough math games and puzzles.This project would be to develop 8 new maths activities.
      These are some of the tentative Maths games of interest:
      Four Color map game
      Broken Calculator
      Soma cubes,
      Fifteen Puzzle.
      Euclid's Game
      Odd Scoring
      Make An Identity
      Number Detective - Number Detective is a fun math game that teaches pattern recognition and AI basics.
      User input a number sequence, and the AI predicts the next number.
      If the AI is wrong, the user corrects it, helping it learn over time!
      The game uses simple rule-based logic and machine learning for predictions.
      Sorting Hat AI - Sorting Hat AI is an interactive game that teaches how AI classifies objects.
      User label animals, shapes, or numbers, and the AI learns to classify new ones.
      If the AI makes a mistake, kids correct it, improving its learning over time!
      The game uses Decision Trees or k-Nearest Neighbors (k-NN) for classification.
      Note: These are some tentative ideas for math games. Further updates, additions, or modifications can be made through discussions with mentors to develop the best possible games.
      Project Length
      350 hours
      Difficulty
      Medium
      Coding Mentors
      Ibiam Chihurumnaya
      Assisting Mentors
      Walter Bender
      Administrative notes
      Above are a list of ideas we've planned for GSoC 2025 projects. If you have any ideas which can be useful to us, but are not in the list, we'd love to hear from you. You need not be a potential student or a mentor to suggest ideas.
      Criteria for Ideas
      Coding Mentors
      Assisting Mentors
      Everyone Else
      Suggested Issues
      Criteria for Ideas
      Does it fill an empty pedagogy niche in the activity set for Sugar or Sugarizer,
      Does it increase quality of our software products (Sugar, activities, Music Blocks, or Sugarizer),
      Does it not involve any project infrastructure, e.g. not another app store, web site, or developer landing page,
      Do we have a developer now who would be willing and able to do it if a student was not available, and who can promise to do it if a student is not selected; these are shown as a coding mentor,
      Coding Mentors
      For each idea, we must have offers from one or more coding mentors willing and able to assist students with coding questions.
      Requirements for a coding mentor are a demonstrated coding ability in the form of contributions of code to Sugar Labs.
      Mentors for a project will be assigned after proposals are received.
      Assisting Mentors For each idea, we may have offers from
      mentors who do not code willing to assist students in various other ways, such as gathering requirements, visual design, testing, and deployment; these are shown as an assisting mentor.
      The only requirement for an assisting mentor is knowledge of the project.
      Mentors for a project will be assigned after proposals are received.
      Everyone Else
      Everyone else in Sugar Labs may also be involved with these projects, through mailing lists, Wiki, and GitHub.
      The difference between a mentor and everyone else, is that a mentor is obliged to respond when a student has a question, even if the answer is "I don't know." When a mentor receives a question for which the best forum is everyone else, then they are to respectively redirect the student to ask everyone else. See "Be flexible" and "When you are unsure, ask for help" in our Code of Conduct.
      Suggested Issues
      For some ideas, there is a list of 'Suggested issues to work on'. These may help you to get familiar with the project. The more you work on these issues, the more experienced you will be for the project. However, this is not a strict list. You should try and explore other issues as well.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/sugar-labs/
    idea_list_url: https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md


  - organization_id: 146
    organization_name: Swift
    no_of_ideas:
    ideas_content: |
      Project Ideas for GSoC 2025
      This page contains a non-exhaustive list of potential project ideas that we are keen to develop during Google Summer of Code 2025. If you would like to apply to GSoC as a contributor, please follow these steps to get started:
      Read through this page and the Google Summer of Code guides,
      Identify, or come up with your own project ideas you find interesting.
      Check out the Development forum to connect with potential mentors.
      Feel free to mention the project mentors on the forums, when starting a thread about your interest in participating in a specific project they are offering to mentor.
      When posting on the forums about GSoC this year, please use the gsoc-2025 tag, so it is easy to identify.
      Tips for contacting mentors
      The Swift forums are powered by discourse, a discussion forums platform with spam avoidance mechanisms built-in. If this is your first time joining the forums, you may not be able to send mentors a direct message, as this requires a minimum amount of prior participation before the “send private message” feature is automatically enabled.
      To start things off, we recommend starting a new thread or joining an existing discussion about the project you are interested in on the dedicated GSoC forums category. You should also tag your thread with the gsoc-2025 tag. It is best if you start a thread after having explored the topic a little bit already, and come up with specific questions about parts of the project you are not sure about. For example, you may have tried to build the project, but not sure where a functionality would be implemented; or you may not be sure about the scope of the project.
      Please use the forums to tag and communicate with the project’s mentor to figure out the details of the project, such that when it comes to writing the official proposal plan, and submitting it on the Summer of Code website, you have a firm understanding of the project and can write a good, detailed proposal (see next section about hints on that).
      If you would like to reach out to a mentor privately rather than making a public forum post, and the forums are not allowing you to send private messages yet, please reach out to Konrad Malawski at ktoso AT apple.com directly via email with the [gsoc2025] tag in the email subject and describe the project you would like to work on. We will route you to the appropriate mentor. In general, public communications on the forums are preferred though, as this is closer to the normal open-source way of getting things done in the Swift project.
      Writing a proposal
      Getting familiar with the codebase you are interested in working on during GSoC helps to write a good proposal because it helps you get a better understanding of how everything works and how you might best approach the project you are interested in. How you want to do that is really up to you and your style of learning. You could just clone the repository, read through the source code and follow the execution path of a test case by setting a breakpoint and stepping through the different instructions, read the available documentation or try to fix a simple bug in the codebase. The latter is how many open-source contributors got started, but it’s really up to you. If you do want to go and fix a simple bug, our repositories contain a label “good first issue” that marks issues that should be easy to fix and doable by newcomers to the project.
      When it comes to writing the proposal, the Google Summer of Code Guide contains general, good advice.
      Potential Projects
      We are currently collecting project ideas on the forums in the dedicated GSoC category.
      Potential mentors, please feel free to propose project ideas to this page directly, by opening a pull request to the Swift website.
      You can browse previous year’s project ideas here: 2024, 2023, 2022, 2021, 2020, 2019.
      Re-implement property wrappers with macros
      Project size: 350 hours (large)
      Estimated difficulty: Intermediate
      Recommended skills
      Proficiency in Swift and C++
      Description
      Property wrappers feature is currently implemented purely within the compiler but with the addition of Swift Macros and init accessors it’s now possible to remove all ad-hoc code from the compiler and implement property wrappers by using existing features.
      This work would remove a lot of property wrapper-specific code throughout the compiler - parsing, semantic analysis, SIL generation etc. which brings great benefits by facilitating code reuse, cleaning up the codebase and potentially fixing implementation corner cases. Macros and init accessors in their current state might not be sufficient to cover all of the property wrapper use scenarios, so the project is most likely going to require improving and expanding the aforementioned features as well.
      Expected outcomes/benefits/deliverables
      The outcome of this project is the complete removal of all property wrappers-specific code from the compiler. This benefits the Swift project in multiple areas - stability, testability and code health.
      Potential mentors
      Pavel Yaskevich
      Improve the display of documentation during code completion in SourceKit-LSP
      Project size: 175 hours (medium)
      Estimated difficulty: Intermediate
      Recommended skills
      Proficiency in Swift and C++
      Description
      The Language Server Protocol (LSP) offers two rich ways of displaying documentation while invoking code completion: Every code completion item can have documentation associated with it and while completing a function signature, the editor can display the available overloads, parameter names and their documentation through signature help. Currently, SourceKit-LSP only displays the first line of an item’s documentation in the code completion results and does not provide any signature help.
      This project would implement functionality to return the entire documentation for all code completion items and also implement the LSP signature help request. Both of these will require functionality to be added in SourceKit-LSP and the compiler’s code base, which determines the list of feasible code completion results.
      Expected outcomes/benefits/deliverables
      SourceKit-LSP will display more information and documentation about the code completion items it offers, allowing developers to pick the item that they are interested in more easily.
      Potential mentors
      Alex Hoppen
      Refactor sourcekitd to use Swift Concurrency
      Project size: 175 hours (medium)
      Estimated difficulty: Intermediate
      Recommended skills
      Proficiency in Swift, including Swift 6’s concurrency model
      Basic proficiency in C++
      Description
      sourcekitd is implemented in the Swift compiler’s repository to use the compiler’s understanding of Swift code to provide semantic functionality. It is currently implemented in C++. By refactoring its request handling and AST manager to Swift, we can take advantage of Swift’s concurrency safety, improving its data race safety, making it easier to reason about and maintain.
      On macOS, sourcekitd is run as an XPC service, while on all other platforms, sourcekitd is run in the sourcekit-lsp process. As a stretch goal, refactoring the request handling would allow us to run sourcekitd in a separate process on Linux and Windows as well improving SourceKit-LSP’s resilience as crashes inside sourcekitd would not cause a crash of the LSP process itself.
      Expected outcomes/benefits/deliverables
      Improved concurrency-safety of sourcekitd and better maintainability.
      Potential mentors
      Alex Hoppen
      Add more refactoring actions to SourceKit-LSP
      Project size: 90 hours (small)
      Estimated difficulty: Intermediate
      Recommended skills
      Proficiency in Swift
      Description
      Refactoring actions assist a developer by automatically performing repetitive and mechanical tasks, such as renaming a variable. SourceKit-LSP already provides refactoring actions and this project would add new actions to SourceKit-LSP. A few new refactoring actions have already been proposed but this project is not necessarily limited to those ideas.
      Expected outcomes/benefits/deliverables
      A richer set of refactorings in SourceKit-LSP that aid developers in performing mechanical tasks.
      Potential mentors
      Alex Hoppen
      Qualified name lookup for swift-syntax
      Project size: 350 hours (large)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Description
      Qualified name lookup is the process by which a compiler resolves a reference A.f into a lookup for entities named f within A. In Swift, this can mean looking into the type A and all of its extensions, superclass, protocols, and so on to find visible members. The project involves building a new library to be integrated into the swift-syntax package that implements Swift’s qualified name lookup semantics, making it easy to build source tools that resolve names. The library will likely include a symbol table implementation that provides efficient lookup of a given name within a given type. It should also integrate with last year’s unqualified name lookup library project, to provide complete support for name lookup on Swift code processed with swift-syntax.
      Expected outcomes/benefits/deliverables
      Swift library providing APIs for qualified name lookup in swift-syntax
      Documentation and tutorial for the library
      Integration of the Swift library with the SwiftLexicalLookup library that implements unqualified name lookup
      Potential mentors
      Doug Gregor
      Swiftly Integration in VS Code
      Project size: 175 hours (medium)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Basic proficiency in TypeScript.
      Basic proficiency in VS Code extension development.
      Description
      Swiftly is a toolchain manager written in and built for Swift. In order to aid adoption in the Swift community, it would be beneficial to provide a rich editor integration with the existing Swift extension for VS Code. This editor integration should aid the user in installing Swiftly itself as well as with installing and selecting Swift toolchains. This will require some effort in Swiftly itself to provide a machine readable interface that any editor could use to manage Swift toolchain installations.
      Expected outcomes/benefits/deliverables
      Editor integration API in Swiftly for querying available toolchains
      VS Code should be able to install Swiftly for the user
      VS Code should be able to install Swift toolchains via Swiftly
      VS Code should be able to select the active Swift toolchain via Swiftly
      VS Code should show the version of the Swift toolchain in use
      Potential mentors
      Chris McGee
      Matthew Bastien
      DocC Language Features in SourceKit-LSP
      Project size: 90 hours (medium)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Description
      SourceKit-LSP has recently added a feature to support DocC Live Preview for editors such as VS Code. This feature could be further improved by providing language features such as go to definition as well as diagnostics for invalid/missing symbol names.
      Expected outcomes/benefits/deliverables
      Syntax highlighting for DocC markdown and tutorial files
      Go to definition for symbols that appear in DocC documentation
      Diagnostics that report missing/invalid symbol names in DocC documentation
      Potential mentors
      Matthew Bastien
      Alex Hoppen
      Tutorial mode for the VS Code Swift extension
      Project size: 90 hours (small)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift
      Basic proficiency in TypeScript
      Basic proficiency in VS Code extension development
      Description
      This project can possibly be combined with the Swiftly Integration in VS Code project and the Tutorial mode for Swift project. When submitting project application for both together, please then mark it as a medium (175 hours) project.
      Right now there isn’t a whole lot of guidance on how to use the Swift extension for VS Code once it is installed. Apart from reading an article about it and the “Details” tab of the Swift extension in VS Code it’s up to the user to realize that a Swift toolchain will have to be installed and figure out the workflow to Build, Run, Test and Debug code. As well, people who are installing the extension could be new to programming and Swift in general. A tutorial mode that will show the features of the extension will be greatly beneficial for first time users.
      The feature can possibly be implemented with VS Code Walkthrough mode or something similar to the CodeTour extension.
      Expected outcomes/benefits/deliverables
      A better onboarding experience for first time users of the VS Code Swift extension
      Users learn about the features of the extension
      Potential mentors
      Either Adam Ward or Paul Lemarquand or Matthew Bastien
      Rishi Benegal
      Tutorial mode for Swift in the VS Code Extension
      Project size: 90 hours (small)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift
      Basic proficiency in TypeScript
      Basic proficiency in VS Code extension development
      Description
      This project can possibly be combined with the Swiftly Integration in VS Code project and the Tutorial mode for VS Code Swift project.
      Many users who install the VS Code swift extension could be new to Swift and programming in general. A tutorial mode that will show features of the programming language could allow users to experiment with their programs interactively and greatly enhance their learning experience. This tutorial mode can include examples from the Swift Book, a VS Code version of the DocC tutorials, swift-testing tutorials and code formatting tutorials using swift-format.
      The feature can possibly be implemented with VS Code Walkthrough mode or something similar to the CodeTour extension.
      Expected outcomes/benefits/deliverables
      A better onboarding experience for users who want to learn more about Swift
      Users learn about the features of the Swift programming language
      Potential mentors
      Either Adam Ward or Paul Lemarquand or Matthew Bastien
      Rishi Benegal
      Improved console output for Swift Testing
      Project size: 175 hours (medium)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Description
      Enhance Swift Testing’s reporting of test results to the console/terminal. Consider adding features like live progress reporting, nested output reflecting suite hierarchy, test metadata (display names, tags), parameterized test arguments, and more terminal colors. Perhaps include user-configurable options. If time allows, implement several alternatives and present them to the community (and the Testing Workgroup) for consideration. Factor code as portably as possible to support many platforms, and so it could be incorporated into a supervisory “harness” process in the future.
      Expected outcomes/benefits/deliverables
      Add a new component in the swift-testing repository which receives events from the testing library and decides how to reflect them in console output.
      Modify supporting tools such as Swift Package Manager to allow enabling or configuring this functionality.
      Land the changes behind an experimental feature flag initially.
      Submit a proposal to the community and the Testing Workgroup to formally enable the feature.
      Summarize your effort with a demo of the new functionality including screenshots or recordings.
      Potential mentors
      Stuart Montgomery
      Improved command line tool documentation
      Project size: 175 hours (medium)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Description
      Swift Argument Parser recently added a command plugin to generate documentation markup for a command line tool. This plugin could be improved by providing support for generating separate pages for each command and by leveraging additional markdown syntax to organize command line flags into sections and display possible values and default values.
      Beyond the markdown output, this plugin could be further improved by generating a “symbol graph” that describe each command and its flags, options, and subcommands. By describing the commands’ structure, tools like Swift DocC can further customize the display of command line tool documentation, support links to individual flags, and allow developers to extend or override the documentation for individual flags in ways that isn’t overwritten when regenerating the documentation markup from the plugin. If time allows, prototype some enhancement to command line documentation in Swift DocC that leverage the information from the command symbol graph file.
      Expected outcomes/benefits/deliverables
      A richer markdown output from the plugin.
      Support for generating separate pages for each command.
      Output a supplementary symbol graph file that describe the commands’ structure.
      Potential mentors
      David Rönnqvist
      Documentation coverage
      Project size: 90 hours (small)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Description
      Enhance Swift DocC’s experimental documentation coverage feature to write coverage metrics in a new extensible format that other tools can read and display. Define a few types of metrics—for example Boolean (has documentation: true/false), Fraction (2/3 parameters are documented), Percentage, etc.—for this format. Explore ideas for what documentation coverage information would be useful to emit. Explore ideas for how another tool could display that coverage information.
      Expected outcomes/benefits/deliverables
      Land the documentation coverage output format changes for the experimental feature in DocC.
      Submit a pitch to the community and the Documentation Workgroup to formally enable the documentation coverage feature in DocC.
      Summarize your effort with a demo of the new metrics and examples of how another tool could display that information.
      Potential mentors
      David Rönnqvist
      OpenAPI integration with DocC
      Project size: 350 hours (large)
      Estimated difficulty: Intermediate
      Recommended skills
      Basic proficiency in Swift.
      Basic knowledge in HTTP APIs.
      Description
      OpenAPI is a standard for documenting HTTP services. It allows creating documents in YAML or JSON format that can be utilized by various tools to automate workflows, such as generating the required code for sending and receiving HTTP requests.
      OpenAPI is known for its tooling to generate documentation, but in the Swift ecosystem, developers are already familiar with how DocC renders documentation for Swift and Objective-C APIs. To enhance consistency and improve the developer experience, we aim to extend DocC’s support to OpenAPI documents.
      Expected outcomes/benefits/deliverables
      As part of the Google Summer of Code project, the student will develop a library/tool that can generate DocC documentation from an OpenAPI document.
      Strech goals:
      Integrate the tool into the Swift OpenAPI Generator.
      Create OpenAPI Doc to DocC Live Preview plugin for VS Code.
      Potential mentors
      Sofía Rodríguez
      Si Beaumont
      Honza Dvorsky
      Example project name
      Project size: N hours
      Estimated difficulty: ???
      Recommended skills
      Basic proficiency in Swift.
      …
      Description
      Description of the project goes here.
      Expected outcomes/benefits/deliverables
      Expected deliverables of the project go here
      Potential mentors
      Mentor name and link to their github
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/swift/
    idea_list_url: https://www.swift.org/gsoc2025/


  - organization_id: 147
    organization_name: SymPy
    no_of_ideas:
    ideas_content: |
      Introduction
      This is the list of ideas for students wishing to apply for Google Summer of Code. For more information on how to apply, see the GSoC Student Instructions. This list is here for inspiration and to give students an idea of what directions may be good for SymPy.
      If you want to pursue an idea listed here, you should contact us on our mailing list and discuss it. Be sure to always ask about these ideas to get the latest information about what is implemented and what exactly has to be done.
      The order of ideas in this list has no bearing to the chances of an idea to be accepted. All of them are equally good and your chances depend on the quality of your application. Also do not worry if there are no mentors assigned to a given idea. If the application is good, we will find a mentor. As already said, you can very well submit your own idea not listed here.
      Project length
      GSoC allows three different project lengths, 90 hours, 175, hours and 350 hours. The ideas below specify which project length is the best fit.
      In some cases, it may be possible to extend a smaller project into a larger one by extending the ideas of what can be done in the project. Similarly, in some cases a larger project can be shortened by only implementing part of the full idea and leaving the rest for a future project. In either case, if you want to do this, please discuss it with us first.
      Submitting Your Own Idea
      You can apply with something completely different if you like. The best project for you is one you are interested in, and are knowledgeable about. That way, you will be the most successful in your project and have the most fun doing it, while we will be the most confident in your commitment and your ability to complete it.
      If you do want to suggest your own idea, please discuss it with us first, so we can determine if it is already been implemented, if it is enough work to constitute a summer's worth of coding, if it is not too much work, and if it is within the scope of our project.
      Please be aware that some ideas are specifically out of scope for SymPy and may be a better fit for other GSoC organizations. Also be aware that ideas that propose completely new modules to SymPy are less likely to be accepted, unless they have already been mentioned on this page or somewhere in the SymPy issue tracker. This is because most of the things that are in-scope for SymPy already have at least a partial implementation in a submodule in SymPy. However, many of these things are not fleshed out very well yet and doing so can often make a good project. If you are unsure, it doesn't hurt to ask us.
      Potential Mentors
      If you are willing to mentor, please add yourself here. Also please register at https://summerofcode.withgoogle.com and add your email that you registered with. Finally, list your name with any projects below that you would be willing to mentor.
      (Note from Aaron, the org admin: if your name is on this list, I'm assuming you're willing to either mentor or at least help review applications. If you aren't able to help this year, please remove your name from the list. If you have any questions about mentoring feel free to email me.)
      Aaron Meurer - asmeurer@gmail.com
      Oscar Benjamin - oscar.j.benjamin@gmail.com
      Sachin Agarwal - sachinagarwal0499@gmail.com (for sympy.series)
      Smit Lunagariya - smitplunagariya@gmail.com
      Francesco Bonazzi - franz.bonazzi@gmail.com
      Amit Kumar - dtu.amit@gmail.com (for sympy.solvers)
      Jason Moore - moorepants@gmail.com (physics.vector/mechanics/biomechanics, parsing.autolev, utilities.autowrap/codegen/lambdify)
      Yathartha Joshi - yathartha32@gmail.com
      Naman Gera - namangera15@gmail.com (for sympy.physics)
      Akshansh Bhatt - qaz.akshansh@gmail.com (for sympy.physics.control)
      Ishan Joshi - ishanaj98@gmail.com
      Nijso Beishuizen - nijso.beishuizen@gmail.com (for ode and pde solvers)
      Faisal Riyaz - faisalriyaz011@gmail.com
      Prakhar Saxena - prakharrsaxena@gmail.com (for sympy.physics.continuum_mechanics)
      Naveen Sai - naveensaisreenivas@gmail.com
      Sudeep Sidhu - sudeepmanilsidhu@gmail.com (physics.vector/mechanics)
      Mohit Balwani - mohitbalwani.ict17@gmail.com (for sympy.solvers.ode)
      Sidharth Mundhra - sidharthmundhra16@gmail.com (for 'sympy.series')
      Mohit Gupta - mohitgupta6678@gmail.com
      Nikhil Maan - nikhilmaan22@gmail.com
      Advait Pote - apote2050@gmail.com (for sympy.physics.continuum_mechanics)
      Anurag Bhat - anuragbhatgsoc23@gmail.com
      Anutosh Bhat - anutosh.bhat.21@gmail.com (for sympy.series, sympy.concrete)
      Timo Stienstra - timostienstra00@gmail.com (for sympy.physics.mechanics/vector/biomechanics)
      Ishan Pandhare - ishan9096137017@gmail.com
      Peter Stahlecker - peter.stahlecker@gmail.com (for sympy.physics.mechanics (Kane's method)`)
      Hwayeon Kang - hwayeonniii@gmail.com (for sympy.physics.mechanics)
      Table of Contents
      High Priority
      Polynomial GCD
      Benchmarks and performance
      Assumptions
      Mathematics Projects
      Solvers
      Optimize floating point expressions
      Group theory
      Risch algorithm for symbolic integration
      Rule-based symbolic integration
      ODE ideas
      Improving Series Expansions & Limit Computations
      Cylindrical algebraic decomposition
      Efficient Groebner bases and their applications
      Multivariate polynomials and factorization
      Univariate polynomials over algebraic domains
      Concrete module: Implement Karr algorithm, a decision procedure for symbolic summation
      Physics Projects
      Symbolic Control Systems (sympy.physics.control)
      Symbolic quantum mechanics (sympy.physics.quantum)
      Continuum Mechanics: Create a Rich 2D Beam Solving System
      Classical Mechanics
      Classical Mechanics: Generalize the Equations of Motion System Output
      Classical Mechanics: Implement and Benchmark Equations of Motion Methods
      Classical Mechanics: Efficient Equations of Motion Generation
      Classical Mechanics: Implement Wrapping Geometry and Pathways for Musculoskeletal Modeling
      Classical Mechanics: Implement Specific Forces and Torques
      Classical Mechanics: Constructing Systems From Bodies and Joints
      Classical Mechanics: Implement an O(N) Equations of Motion Method
      Computer Science, Graphics, and Infrastructure Projects
      Official LLM Tool Agent for SymPy
      Enhancing the flexibility of MatchPy
      Code Generation
      Code Generation: Efficient Jacobian and Hessian Evaluation for Optimization and ODE Integration
      Parsing
      Improve the plotting module
      Documentation tooling
      Hypothesis testing
      User Application Projects
      LFortran SymPy Project Ideas
      SymPy -> Fortran Code Generation and JIT
      Parsing Fortran code to SymPy
      Idea Prompts
      Other Related Projects
      Non-Ideas
      Mentors, please use the following template to add ideas to this page:
      ## Title
      
      **Idea**
      
      (Specify your idea with proper explanation)
      
      **Status**
      
      (What is the Status of this Idea in the Sympy Community currently, previous
      work done and Issues)
      
      **Involved Software**
      
      (Any other Software Involved that would be required to implement your idea)
      
      **Difficulty**
      
      (Advanced, Intermediate, or Beginner and any specific comments on the
      difficulty)
      
      **Prerequisite Knowledge**
      
      (Any prerequisite knowledge or approach needed)
      
      **Project Length**
      
      Whether this project is appropriate for a 90, 175, or 350 hours GSoC project.
      The same idea can have different project length sub-ideas.
      
      NOTE: This section is required by Google. Be sure to include it for
      any idea!
      High Priority
      Polynomial GCD
      Idea
      Add new algorithms for computing the greatest common divisor (GCD) of polynomials in the sparse representation. This would improve the speed of many parts of sympy such as matrices, solvers, integration and so on.
      The issues and potential solutions along with many references are discussed in this issue: https://github.com/sympy/sympy/issues/23131
      Status
      There is plenty of work that can be done in this area so this is effectively an open-ended area for improvement in sympy.
      Involved Software
      Difficulty
      Medium to high difficulty
      Prerequisite Knowledge
      Python, some understanding of abstract algebra and of algorithms.
      Project Length
      175 or 350 hours, depending on the scope of the project.
      Benchmarks and performance
      Idea
      Speed is important for SymPy. One issue is that it's difficult to tell what is too slow, and, more importantly, if a given change makes things faster or slower.
      SymPy needs more benchmarks. It also needs an automated system to run them. That way, when someone adds some code that slows things down in an unexpected way, we will know about it.
      There are already some benchmarks at https://github.com/sympy/sympy_benchmarks, and some others in the main SymPy repo. But not all benchmarks are in the sympy_benchmarks repo. Also, the repo uses asv, but the results are run and hosted ad hoc, as we don't have a dedicated machine to run the benchmarks.
      This project should do the following:
      Move benchmarks from the sympy repo to the sympy_benchmarks repo.
      Add new benchmarks as needed.
      Work with the community to set up a dedicated machine that can constantly run asv to warn about benchmarks. It would also be nice if this could be set up to warn for performance regressions on PRs.
      Make improvements to SymPy to improve performance issues found throughout the project.
      Improve the usability of the current GitHub Actions bot that adds benchmarks outputs to pull requests.
      Some prior art:
      ASV (what we are using now)
      PyPy benchmarks page
      See https://www.youtube.com/watch?v=d65dCD3VH9Q for some ideas/warnings about setting up benchmarking.
      See this issue for ways to run benchmarks on GitHub Actions https://github.com/sympy/sympy/issues/21374.
      Status
      We currently have a benchmarking suite and run the benchmarks on GitHub Actions, but this is limited and is often buggy.
      Involved Software
      Difficulty
      Medium to low difficulty
      Prerequisite Knowledge
      Python
      Project Length
      175 hours or 350 hours, depending on the scope of the project.
      Assumptions
      Idea
      The project is to completely remove our old assumptions system, replacing it with the new one. The difference between the two systems is outlined in the first two sections of this blog post.
      This project is challenging. It requires deep understanding of the core of SymPy, basic logical inference, excellent code organization, and attention to performance. It is also very important and of high value to the SymPy community.
      Numerous related tasks are mentioned in the "Ideas" section.
      Status
      There has been a significant amount of merged and unmerged work on this topic. A list of detailed issues can be found at this issue. You should take a look at the work started at https://github.com/sympy/sympy/pull/2508.
      This mailing list post by Aaron Meurer outlines the status of the project and some ideas of what to do. It is from 2015 but most of what is written there is still true. The main thing that is new is that the new assumptions call the old assumptions (ask(Q.real(Symbol('x', real=True)))). See also the prior GSoC projects on assumptions, including this one, which was accepted, but there may be parts of it that were not completed, and https://github.com/sympy/sympy/wiki/GSoC-2013-Application-Tom-Bachmann:-Removing-the-old-assumptions-module, which was not accepted (the student chose to do another project), but contains some good ideas.
      Involved Software
      None
      Difficulty
      Advanced
      Prerequisite Knowledge
      Number theory, Boolean algebra, etc.
      Project Length
      350 hours
      Mathematics Projects
      Solvers
      Idea
      SymPy already has a pretty powerful solve function. But it has a lot of major issues
      It doesn't have a consistent output for various types of solutions It needs to return a lot of types of solutions consistently:
      single solution : x == 1
      Multiple solutions: x**2 == 1
      No Solution: x**2 + 1 == 0; x is real
      Interval of solution: floor(x) == 0
      Infinitely many solutions: sin(x) == 0
      Multivariate functions with point solutions x**2 + y**2 == 0
      Multivariate functions with non point solution x**2 + y**2 == 1
      System of equations x + y == 1 and x - y == 0
      Relational x > 0
      And the most important case "We don't Know"
      The input API is also a mess, there are a lot of parameter. Many of them are not needed and they makes it hard for the user and the developers to work on solvers.
      There are cases like finding the maxima and minima of function using critical points where it is important to know if it has returned all the solutions. solve does not guarantee this.
      Salient Features of solveset
      solveset has a cleaner input and output interface: solveset returns a set object and a set object take care of all the types of the output. For cases where it doesn't "know" all the solutions a NotImplementedError is raised. For input only takes the equation and the variables for which the equations has to be solved.
      solveset can return infinitely many solutions. For example solving for sin(x) = 0 returns {2⋅n⋅π | n ∊ ℤ} ∪ {2⋅n⋅π + π | n ∊ ℤ} Whereas solve only returns [0, π]
      There is a clear code level and interface level separation between solvers for equations in complex domain and equations in real domain. For example solving exp(x) = 1 when x is complex returns the set of all solutions that is {2⋅n⋅ⅈ⋅π | n ∊ ℤ} . Whereas if x is a real symbol then only {0} is returned.
      solveset returns a solution only when it can guarantee that it is returning all the solutions.
      Status
      GSoC 2014 Project: Harsh Gupta During the summer of 2014 Harsh Gupta worked to improve solvers as part of his GSoC project. Instead of making changes in the current solve function a new submodule named solveset was written.
      GSoC 2015 Project: Amit Kumar In the summer of 2015 Amit Kumar worked on this project to improve solveset, implement complex sets as a part of his GSoC project.
      GSoC 2016 Project: Kshitij SaraogiKshitij Saraogi | GSoC 2016 Project: Shekhar Rajak In the summer of 2016, two projects were selected to participate in Google Summer of Code to work on the Solvers. New solver helper functions such as solve_decomposition and nonlinsolve were implemented to facilitate the porting from solve to solveset. Also, the inequality solver solve_univariate_inequality was refactored and added to solveset. Several methods related to functional analysis, such as periodicty, continuous_domain and function_range were implemented.
      GSoC 2018 Project: Yathartha Joshi In the summer of 2018, Yathartha worked on the project to implement transcendental equation solver for solveset. transolve alongwith its helper solvers was implemented as a result of it.
      TODOs
      Extending transolve: As part of the work done in the summer of 2018, transolve is fully designed and is now able to handle logarithmic and exponential equations for solveset. To make solveset fully fledged and replace solve completely we expect it to handle equations like:
      Lambert type equations (PR #14972)
      Handling modular equations (#13178)
      Solving transcendental equations in complex domain.
      There may be other types of equations that transolve can be made to handle. It's still under development!! Feel free to propose any of your ideas.
      Integrating helper solvers with solveset: Currently, solveset only solves a single equation for a single variable. In the future, we expect it to be capable of solving a system of equations and for more than one variable. linsolve: Solves a system of linear equations nonlinsolve: Solves a system of non-linear equations solve_decomposition: Solves a varied class of equations using the concept of Rewriting and Decomposition These are the helper functions that have been implemented in solveset during the past few years. We would like to have all these solvers(including transolve) to be integrating in solveset so as to increase its power.
      Build the set infrastructure: This includes implementing functions to handle multidimensional ImageSet etc., This part must go hand in hand with the improvements in the solvers as set module can be a universe in itself. Also there can be fundamental limits on the things you can do.
      nonlinsolve is not able to handle system having trigonometric/transcendental equations correctly all the time. Improve solveset's trigonometric solver and handle trig system of equations separately in nonlinsolve.
      References There had been a lot of discussion during and before the project and you should know why we did what we did. Here are some links:
      Discussion on the mailing list
      Action Plan on solvers
      Harsh Gupta's proposal for GSoC 2014
      Harsh's blog for GSoC
      solveset pull request
      Amit's blog for GSoC
      Solveset Documentation
      GSoC 2016 Solvers Progress and blog links
      Yathartha's blog for GSoC
      transolve pull request
      GSoC 2018 Solvers Progress
      Involved Software
      SymPy
      Difficulty
      This project is difficult because it requires a good deal of thought in the application period. You should have a clear plan of most of what you plan to do in your application: waiting until the Summer to do the designing will not work.
      #10006 and #8711 can be good entry points.
      Prerequisite Knowledge
      Algebraic and differential equations
      Potential mentor - Co-mentor: Shekhar (@Shekharrajak)
      Project Length
      350 hours.
      Optimize floating point expressions
      Idea
      Optimize floating point expressions (à la https://herbie.uwplse.org/). The user will supply a SymPy expression and an optional range of "x" (and other variables) and the module would determine which symbolic simplifications make sense to make things more accurate and/or faster.
      Part of this project would also be to provide faster implementations of special functions, say if it is determined that "x" in sin(x) is in the range [0, 1e-3], then there are much faster polynomial approximations that give the same accuracy (the same is possible for other finite ranges, e.g., [1.5, 1.7]).
      One mode is to concentrate on accuracy (possibly with larger/slower expression). Another mode is to concentrate on speed, and this mode can have a user prescribed accuracy, say 1e-16 for machine precision, or 1e-3 for lower accuracy. For lower accuracies one can replace functions like sin(x) with a much faster polynomial approximation.
      Difficulty
      Intermediate, Advanced
      Project Length
      350 hours, although you may propose a 175 hour project with a more limited scope.
      Group theory
      Idea
      Continue developing the group theory functionality of the combinatorics module. You should take a look at the GAP library, as this is the canonical group theory computation system right now.
      Algorithms to think about implementing:
      Computation of various subgroups of infinite finitely presented groups
      Computation of Galois groups for a given polynomial
      Finding kernels of homomorphisms with infinite domains
      Extend functionalities of polycyclic groups
      Quotient groups
      Automorphism groups
      Status
      Previous projects on the topic include:
      GSoC 2012 Aleksandar Makelov: Computational Group Theory
      GSoC 2016 Gaurav Dhingra: Computational Group Theory
      GSoC 2017 Valeriia Gladkova: Computational Group Theory
      GSoC 2018 Ravi Charan: Computational Group Theory
      GSoC 2019 Divyanshu Thakur: Computational Group Theory
      A good amount of work has been done on polycyclic groups, polycyclic presentation with the base class collector were introduced in 2019 GSoC project but still there are a lot of things to be added for e.g. polycyclic orbit stabilizer and canonical polycyclic sequence to check if two polycylic subgroups are equal or not could be implemented. In addition, few other algorithms like abelian invariants and composition series implemented in 2019 GSoC project can be extended for infinite groups.
      Some major algorithms for finitely presented groups include coset enumeration (there's been work on modified Todd-Coxeter in the 2018 GSoC project: see this PR), low index subgroup search and Reidemeister-Schreier algorithm for subgroup presentation. Rewriting systems together with the Knuth-Bendix completion algorithm are available but could be made more efficient.
      Additionally, the 2017 project implemented group homomorphisms and the 2018 project implemented the computation of the isomorphism between 2 groups, an automaton for word reduction and a few additional algorithms. Find the complete work done during 2018 in the project report in the link below.
      See the 2016, 2017 and 2019 reports for suggestions on where the work could continue.
      Quite a lot of work has been done on permutation groups, but still, some things remain (some of those mentioned in GSoC 2012 Report by Aleksandar Makelov are still relevant, e.g. subgroup intersection). Some work is already done on discrete groups. Nonetheless, there is still much that can be done both for discrete groups and for Lie groups.
      Difficulty: Medium/Difficult
      Resources: Handbook of Computational Group Theory by Derek F. Holt, Bettina Eick and Eamonn A. O'Brien
      Prerequisite Knowledge: Basic knowledge of Abstract Algebra
      Potential mentor - Co-mentor: Divyanshu Thakur (@divyanshu132)
      Project Length
      350 hours.
      Risch algorithm for symbolic integration
      Idea
      The Risch algorithm is a complete algorithm to integrate any elementary function. Given an elementary function, it will either produce an antiderivative, or prove that none exists. The algorithm described in Bronstein's book deals with transcendental functions (functions that do not have algebraic functions, so log(x) is transcendental, but sqrt(x) and sqrt(log(x)) are not).
      Status
      The project is to continue where Aaron Meurer left off in his 2010 GSoC project, implementing the algorithm from Manuel Bronstein's book, Symbolic Integration I: Transcendental Functions. If you want to do this project, be sure to ask on the mailing list or our IRC channel to get the status of the current project.
      The algorithm has already been partially implemented, but there is plenty of work remaining to do. Contact Aaron Meurer for more information. There was also work done in 2013, which hasn't been completely merged yet. A good place to start would be to look at finishing this work: https://github.com/sympy/sympy/pulls/cheatiiit. See https://groups.google.com/forum/#!msg/sympy/bYHtVOmKEFs/UZoyDX81eP4J for some more details on this project (nothing has changed since that email thread).
      Involved Software
      Difficulty
      Prerequisite Knowledge
      You should have at least a semester's worth of knowledge in abstract algebra. Knowing more, especially about differential algebra, will be beneficial, as you will be starting from the middle of a project. Take a look at the first chapter of Bronstein's book (you should be able to read it for free via Google Books) and see how much of that you already know. If you are unsure, discuss this with Aaron Meurer (asmeurer).
      Project Length
      350 hours.
      Rule-based symbolic integration
      Idea
      Symbolic integration can also be performed with a "rule-based" system, which pattern matches the integrand against a set of known integrals uses them to return a result. This is a different approach to the Risch algorithm discussed in the previous approach, and is generally seen as complementary to it. For instance, the Risch algorithm can handle very complex expressions but it can only work with elementary integrals. Rule-based systems are limited to expressions that can match the given set or rules, but it can work with a large set of special functions.
      Status
      The main work here is a software called RUBI, which is a rule-based integration system written in Wolfram Language. Several previous GSoC projects have worked on integrating RUBI in SymPy, but this work has not yet been successfully completed.
      See
      GSoC-2017-Report-Abdullah-Javed-Nesar:-Rule-based-Integrator
      GSoC 2018 Rubi Final Report
      Improving-Rule-Based-Integrator
      Tracking issue #12233
      The RUBI code that has been written is now at https://github.com/sympy/rubi. The primary issue with it is that RUBI is very large and the Python translation is too slow to be useful.
      RUBI also involves using MatchPy (see Enhancing the flexibility of MatchPy), which enables the sort of Mathematica-style pattern matching needed for integration.
      Because previous projects have failed to integrate the entirety of RUBI due to its size, a project working on RUBI should focus on integrating parts of it at a time.
      SymPy also has a separate module called manualintegrate which implements a pattern-based integration system. It only has a limited of patterns right now, but could be extended. A potential project could just be to extend manualintegrate and not involve RUBI.
      Involved Software
      MatchPy
      RUBI
      Difficulty
      Intermediate to difficult
      Prerequisite Knowledge
      If working on RUBI knowledge of Mathematica code will be useful, but not required. Prior knowledge of special functions will be useful, but can also quite easily be learned.
      Project Length
      For anything involving RUBI, this should be 350 hours.
      Smaller 175 or even 90 hour projects to just improve manualintegrate are possible. Discuss with us.
      ODE ideas
      You also might want to look at Manuel Bronstein's sumit.
      "Solving Differential Equations in Terms of Bessel Functions" by Ruben Debeerst. (basic idea is already implemented.)
      Webpage: http://rubendebeerst.de/master/
      Master Thesis: http://rubendebeerst.de/master/master.pdf
      Corresponding ISSAC 08 paper: http://rubendebeerst.de/master/paper_issac2008.pdf
      Lie groups and symmetry related:
      "Integrating factors for second order ODEs" by E.S. Cheb-Terrab and A.D. Roche
      "Abel ODEs: Equivalence and Integrable Classes" by E.S. Cheb-Terrab and A.D. Roche Note: Original version (12 pages): July 1999. Revised version (31 pages): January 2000
      Status
      Involved Software
      Difficulty
      Medium
      Prerequisite Knowledge
      Differential equations
      Project Length
      175 hours or 350 hours, depending on the project details (discuss with us).
      Improving Series Expansions & Limit Computations
      Idea
      This includes numerous smaller subprojects and is more of a bug burn down project than implementing things from scratch. Hence we should aim at solving as many bugs and possible issues having the label series or limits on them. There are around 146 open issues with the series label & around 26 open issues with the limits label with some overlap and the proposal should have a comprehensive list of ideas to fix a significant portion of these issues.
      improve series expansions
      relevant issues
      improve limit computations
      relevant issues
      improve formal power series
      asymptotic series (for instance aseries for gamma, bessel, error type functions)
      issue 1, issue 2, issue 3, issue 4
      Better support for Order term arithmetic (for example, expression of the order term of the series around a point that is not 0, like O((x - a)**3)).
      issue 1
      Read through discussion & comments for fixing issue
      Fix _eval_subs method to hanlde issue 1, issue 2, issue 3, issue 4
      Fix limit computations for piecewise functions
      revamp work on PR and test properly, relevant issue
      All other problems, which are described in wiki page about series and current situation
      Status
      There is already a fast implementation called rs_series in SymPy. This project would extend it to work for all functions and then make it the default series expansion in SymPy.
      SymPy now has support for Formal Power Series (series.formal). The algorithm is more or less complete. The module should be made faster. There are also a lot of XFAIL tests that can be made to pass.
      A new algorithm for computing limits of sequences has also been added (series.limitseq). There are still XFAIL tests that can be made to pass.
      Some references
      "Formal Power Series" by Dominik Gruntz and Wolfram Koepf
      "A New Algorithm Computing for Asymptotic Series" by Dominik Gruntz
      "Computing limits of Sequences" by Manuel Kauers
      "Symbolic Asymptotics: Functions of Two Variables, Implicit Functions" by Bruno Savly and John Shackell
      "Symbolic Asymptotics: Multiseries of Inverse Functions" by Bruno Savly and John Shackell
      Involved Software
      SymPy
      Difficulty
      Medium
      Prerequisite Knowledge
      Calculus
      Project Length
      175 hours or 350 hours, depending on the project details (discuss with us).
      Cylindrical algebraic decomposition
      Idea
      Implement the Cylindrical algebraic decomposition algorithm
      Use CAD to do quantifier elimination
      Provide an interface for solving systems of polynomial inequalities
      Some references:
      Cylindrical Algebraic Decomposition http://mathworld.wolfram.com/CylindricalAlgebraicDecomposition.html
      "Algorithms in Real Algebraic Geometry" http://perso.univ-rennes1.fr/marie-francoise.roy/bpr-ed2-posted1.html (useful background resource, but contains much more information)
      "Cylindrical Algebraic Decomposition I: The Basic Algorithm" by Dennis S. Arnon, George E. Collins, Scot McCallum
      "Computing Cylindrical Algebraic Decomposition via Triangular Decomposition" by Marc Moreno Maza, Changbo Chen, Bican Xia, Lu Yang
      "Simple CAD Construction and its Applications" by Christopher W. Brown
      "Improved Projection for Cylindrical Algebraic Decomposition" by Christopher W. Brown
      "Symbolic Computation for Inequalities" by Manuel Kauers http://www.sfb013.uni-linz.ac.at/uploads/media/SymCompIneq.pdf
      "How To Use Cylindrical Algebraic Decomposition" by Manuel Kauers
      Status
      Involved Software
      Difficulty
      Prerequisite Knowledge
      Project Length
      350 hours
      Efficient Groebner bases and their applications
      Idea
      Groebner bases computation is one of the most important tools in computer algebra, which can be used for computing multivariate polynomial LCM and GCD, solving systems of polynomial equations, symbolic integration, simplification of rational expressions, etc. Currently there is an efficient version of Buchberger algorithm implemented and of the F5B algorithm, along with naive multivariate polynomial arithmetic in monomial form. There is also the FGLM algorithm converting reduced Groebner bases of zero-dimensional ideals from one ordering to another.
      Improve efficiency of Groebner basis algorithm by using better selection strategy (e.g. sugar method) and implement Faugere F4 algorithm and analyze which approach is better in what contexts. Implement the generic Groebner walk converting between Groebner basis of finite-dimensional ideals; there are efficient algorithms for it, by Tran (2000) and Fukuda et al. (2005).
      Apply Groebner bases in integration of rational and transcendental functions and simplification of rational expressions modulo a polynomial ideal (e.g. trigonometric functions).
      Status
      There was a project last year relating to Groebner bases. Please take a look a the source and discuss things with us to see what remains to be done.
      Some Groebner bases algorithms, in particular F4, require strong linear algebra. Thus, if you want to do that, you may have to first improve our matrices (see the ideas relating to this above).
      Involved Software
      Difficulty
      Prerequisite Knowledge
      Project Length
      350 hours
      Multivariate polynomials and factorization
      Idea
      Factorization of multivariate polynomials is an important tool in algebra systems, very useful by its own, also used in symbolic integration algorithms, simplification of expressions, partial fractions, etc. Currently multivariate factorization algorithm is based on Kronecker's method, which is impractical for real life problems. Undergo there is implementation of Wang's algorithm, the most widely used method for the task.
      Start with implementing efficient multivariate polynomial arithmetic and GCD algorithm. You do this by improving existing code, which is based on recursive dense representation or implement new methods based on your research in the field. There are many interesting methods, like Yan's geobuckets or heap based algorithms (Monagan & Pearce). Having this, implement efficient GCD algorithm over integers, which is not a heuristic, e.g. Zippel's SPMOD, Musser's EZ-GCD, Wang's EEZ-GCD. Help with implementing Wang's EEZ factorization algorithm or implement your favorite method, e.g. Gao's partial differential equations approach. You can go further and extend all this to polynomials with coefficients in algebraic domains or implement efficient multivariate factorization over finite fields.
      Status
      Some work on this may already be done. Take a look at sympy/polys/factortools.py in the SymPy source code.
      Involved Software
      Difficulty
      Advanced
      Prerequisite Knowledge
      Project Length
      350 hours
      Univariate polynomials over algebraic domains
      Idea
      Choose a univariate polynomial representation in which elements of algebraic domains will be efficiently encoded. By algebraic domains we mean algebraic numbers and algebraic function fields. Having a good representation, implement efficient arithmetic and GCD algorithm. You should refer to work due to Monagan, Pearce, van Hoeij et. al. Having this, implement your favorite algorithm for factorization over discussed domains. This will require algorithms for computing minimal polynomials (this can be done by using LLL or Groebner bases). You can also go ahead and do all this in multivariate case.
      Status
      Currently SymPy features efficient univariate polynomial arithmetic, GCD and factorization over modular rings and integers (rationals). This is, however, insufficient in solving real life problems, and has limited use for symbolic integration and simplification algorithms. For example, the support for finite fields GF(p^n) is missing.
      Involved Software
      Difficulty
      Advanced
      Prerequisite Knowledge
      Project Length
      350 hours
      Concrete module: Implement Karr algorithm, a decision procedure for symbolic summation
      Idea
      Algorithm due to Karr is the most powerful tool in the field of symbolic summation, which you will implement in SymPy. There are strong similarities between this method and Risch algorithm for the integration problem. You will start with implementing the indefinite case and later can extend it to support definite summation (see work due to Schneider and Kauers). Possibly you will also need to work on solving difference equations.
      Some references:
      "A=B" by Marko Petkovsek, Herbert S. Wilf, Doron Zeilberger
      "Symbolic Summation with Radical Expressions" by Manuel Kauers and Carsten Schneider
      "An Implementation of Karr's Summation Algorithm in Mathematica" by Carsten Schneider
      Manuel Kauers, webpage: http://www.risc.jku.at/home/mkauers
      Carsten Schneider, webpage: http://www.risc.jku.at/people/cschneid
      "Algorithmen für mehrfache Summen", by Torsten Sprenger
      Status
      SymPy currently features Gosper algorithm and some heuristics for computing sums of expressions. Special preference is for summations of hypergeometric type. It would be very convenient to support more classes of expressions, like (generalized) harmonic numbers etc. There is already an complete algorithm rational expression summation.
      Involved Software
      Difficulty
      Advanced
      Prerequisite Knowledge
      Project Length
      350 hours
      Physics Projects
      Symbolic Control Systems (sympy.physics.control)
      Idea
      A Control Systems subpackage (sympy.physics.control) was added to SymPy in the summer of 2020, by Naman Gera. This was built upon further by Akshansh Bhatt in 2021 and Anurag Bhat in 2023. It would be great to continue its development and make it more accessible to the public. Since the users are mostly students and researchers in the field of Control theory, a set of problems from a textbook can be solved in the documentation, as the development proceeds.
      https://www.cds.caltech.edu/~murray/amwiki/Second_Edition.html can be used as a reference.
      Status
      The functionalities of the project can be viewed here:
      https://docs.sympy.org/latest/modules/physics/control/lti.html#module-sympy.physics.control.lti
      Future Work (can be modified after discussion):
      Refactor the old plots - All the plots that were implemented previously namely - Pole Zero, Step Response, Impulse Response, Ramp Response, Bode Magnitude and Bode Phase plot use numpy and matplotlib. The numerical methods were used for speed but they sacrifice on precision. Sympy's symbolic methods are used in the first place to the precision they provide, hence these numerical methods should be replaced by algebraic methods.
      Davide, a fellow contributor has been revamping the plotting module. I would like to point out this roadmap, according to which SymPy will soon have it's own plot_list function after which this refactoring could be done with ease.
      Complete newly implemented plots - The plots added in this GSoC project namely - Root Locus, Nichols and Nyquist plot are draft pull requests. The have clear ideas to follow and some comments which can be addressed once SymPy no longer depends upon matplotlib and numpy.
      Implementations for the StateSpace class -
      Solve examples mentioned in #25502 and add them to the control_problems file . The required functionality is already supported in the pull request.
      Add a symbolic solver (and a numeric solver if required) with the help of the ODE module to solve x' = Ax + Bu form.
      Make the class more feature rich:
      Read about Laub's or Horner's method to evaluate system transfer function at complex frequency. This will be the equivalent of eval_frequency for Transfer Functions.
      Add Feedback interconnection between 2 state space LTI systems.
      Other features can be picked up on comparison with MATLAB and python-control.
      Adding a Discrete time model - A Discrete-time TransferFunction and Discrete-time StateSpace model. Discussing the API and making things compatible with the current implementation is a challenging task. It has already been a component of the MATLAB CST package from the beginning. As a control module, we have to realize that all signals in practical real life use are always discrete in nature. This is my motivation for wanting this model, so that users can have extensive use of SymPy’s CST package in their projects.
      It is best to follow the final report and blog to know more about the status.
      Involved Software
      Python, Git
      Difficulty
      Intermediate
      Prerequisite Knowledge
      Undergraduate level Control Systems knowledge will suffice. Otherwise, one can complete the project if they self-learn required topics and then contribute voraciously.
      Project Length
      350 hours.
      Symbolic quantum mechanics (sympy.physics.quantum)
      In the past, Brian Granger was the maintainer of the sympy.physics.quantum subpackage. He has stepped down from this position. Until someone takes over the maintenance of this subpackage, we will not be able to mentor any GSoC projects in this area. If you have questions about this, please contact Ondřej Čertík.
      Continuum Mechanics: Create a Rich 2D Beam Solving System
      Idea
      Singularity functions are a popular tool for solving beam bending stress and deflection problems in mechanical design. This is traditionally done by hand calculations and can be very tedious and error prone. This process could be improved greatly by a CAS implementation of the functions and some high level abstractions for constructing beam loading profiles.
      The deliverable would be a unit tested and documented sub-package for SymPy 2D and 3D beams that can solve many beam problems, add in arbitrary cross sections, plotting, be robust, and add any other relevant features.
      Status
      Sampad Saha implemented Singularity Functions in 2016. The 2017 and 2018 GSoC projects created the functionality shown here:
      https://docs.sympy.org/dev/modules/physics/continuum_mechanics/beam_problems.html
      The next steps involve making it easier to define complex cross sectional geometry via the geometry package, developing the 3D Beam into a well tested and robust class, and polishing to the plotting for 2D and 3D beams. Adding a large set of example problems that exercise the functionally.
      Involved Software
      Python, Git
      Difficulty
      Intermediate
      Prerequisite Knowledge
      No specific prerequisite knowledge is necessary but it would help if the student had some knowledge of beam stress/strain analysis methods.
      Project Length
      350 hours.
      Classical Mechanics
      The following project ideas are in approximate order of priority.
      Classical Mechanics: Generalize the Equations of Motion System Output
      Idea
      We would like an ecosystem in which you can define/create your mechanical system in a general way using joints, bodies, forces, torques, etc., compute the equations of motion based on different methods like LagrangesMethod and KanesMethod, to be used in numerical purposes, like simulations and optimizations.
      The above is the general picture for which a lot of work has been done over the years on the different parts. However, some parts are disjoint while other parts are still missing or should almost be entirely replaced.
      Note that defining/creating the mechanical system falls into two other projects, namely:
      Classical Mechanics: Constructing Systems From Bodies and Joints
      Classical Mechanics: Implement Specific Forces and Torques
      Classical Mechanics: Implement and Benchmark Equations of Motion Methods
      Status
      Previous work covers quite a few different parts, which can be improved and extended, but mostly require to be tied together more properly:
      An abstract base class as an interface to the different equations of motion generation methods has been introduced in #21778.
      Refer to the project Classical Mechanics: Constructing Systems From Bodies and Joints for the status of bodies and joints.
      Refer to the project Classical Mechanics: Implement Specific Forces and Torques for the status of implementing specific loads.
      In #25560 a System class was introduced as a general frontend to define a mechanical system and generate the equations of motion using either of the implemented methods, i.e. LagrangesMethod and KanesMethod.
      In #11431 as SymbolicSystem was introduced as a data class to store all information about a system and its equations of motion in a general format.
      In PyDy there also exists a System class, which can be used to simulate a system that was solved using KanesMethod.
      The goal of this project is to implement a class to function as a general interface of a system from which the equations of motion can be used for numerical purposes. This class would be an extension or replacement of sympy.physics.mechanics.system.SymbolicSystem. Some of the features it should offer are:
      A general representation of the equations of motion and the algebraic constraints.
      Methods to code generate the functions to be used in simulation purposes, like with scipy.integrate.solve_ivp and scikits.odes.dae.
      It should use sympy.physics.mechanics.system.System for the basic system information. It could possibly have multiple methods to be instantiated, like a normal __init__ where all equations and things need to be provided as is currently the case with SymbolicSystem, and a classmethod from_system, where it extracts most information from the System instance.
      Involved Software
      Python, Git
      Difficulty
      Advanced
      Prerequisite Knowledge
      This project requires basic understanding of dynamical systems and at least understanding of one method of generating the equations of motion for a multi-body system.
      Project Length
      350 hours.
      Classical Mechanics: Implement and Benchmark Equations of Motion Methods
      Idea
      There are many methods to derive the equations of motion. Each method has its advantageous and disadvantageous when modeling different systems. SymPy currently contains only two methods: KanesMethod and LagrangesMethod. The idea of this project is to develop more methods to form the equations of motion and to benchmark them for different models to also give users more insight what model they should use for their application.
      Status
      An abstract base class as an interface to the different equations of motion generation methods has been introduced in #21778.
      This project could roughly entail the following steps:
      Improve the abstract base class, sympy.physics.mechanics.method._Methods of the equations of motion generation methods, e.g. KanesMethod.
      Improve the implementation of KanesMethod and LagrangesMethod.
      Implementing more methods to generate the equations of motion, like NetwonEulersMethod or HamiltonsMethod.
      Develop a benchmark suite deriving the equations of motion using the different methods and measure their performance. Examples could include a 5-DoF planar kinematic chain, a four-bar linkage, and the Carvallo-Whipple bicycle model.
      Involved Software
      Python, Git
      Difficulty
      Intermediate
      Prerequisite Knowledge
      This project requires basic understanding of dynamical systems and at least understanding of one method of generating the equations of motion for a multi-body system.
      Project Length
      175 or 350 hours.
      Classical Mechanics: Efficient Equations of Motion Generation
      Idea
      Currently we have basic equation of motion generation with automated Kane's and Lagrange's methods. These methods work well but can take many minutes to complete for hard problems. The algorithms that derive these equations of motion can be improved in both speed of computation and the resulting simplification of the equations of motion. This project would involve profiling to find the slow functions and speeding up the slow parts. This may involve digging into the SymPy codebase for trigonometric simplification and other relevant function calls to speed up the EoM generation. These modification will help speed up both the entire SymPy codebase and the Mechanics package.
      Status
      There is no previous work on this topic.
      Involved Software
      Python, Git
      Difficulty
      Beginner
      Prerequisite Knowledge
      There are no prequisites to this project.
      Project Length
      175 or 350 hours.
      Classical Mechanics: Implement Wrapping Geometry and Pathways for Musculoskeletal Modeling
      Idea
      SymPy Mechanics includes classes to manage how forces and torques act on connected bodies when the path of action is a complex pathway that wraps over geometric features. This is critical for accurate musculotendon force generation. The Biomechanical Model Example shows a simple cylindrical wrapping of a muscle around the elbow. This idea involves adding more wrapping surfaces and pathways that are useful for musculoskeletal modeling.
      Status
      Cylinder and sphere wrapping geometry exist
      Linear and obstacle pathway exist
      Involved Software
      Python, Git
      Difficulty
      Beginner to intermediate
      Prerequisite Knowledge
      This project requires basic understanding geometry, forces, and anatomy.
      Project Length
      90, 175, or 350 hours (depends on how many features you'd like to implement)
      Classical Mechanics: Implement Specific Forces and Torques
      Idea
      Many forces and torques still have to be manually created by the user. It would be helpful if we had a set of typical and common forces and torques. Some possible examples:
      Actuator forces and torques
      Aerodynamic forces
      Contact force models
      Friction force models
      Linear and nonlinear springs and dampers
      Musculotendon models, like the Hill type muscle model
      Controller forces (like PID or full state feedback)
      Eardrum model
      Some kind of force and torque objects will likely be needed as well as symbolic mathematical descriptions of the force and torque models. The forces and torques should work with SymPy's code generation to generate efficient and robust numerical codes. Here is a soft introduction to forces and torques.
      Status
      Timo Stienstra introduced a Force and Torque class, refer to #24258 and #24641.
      Sam Brockie implemented an abstract base class to define actuators and implemented several types of actuators, like a LinearSpring and LinearDamper, refer to #25518.
      Sam Brockie implemented base classes for Musculotendon force generators, refer to the musculotendon API
      Hwayeon Kang implemented CoulombKineticFriction and DuffingSpring classes, refer to #26438 and #26412.
      Initial idea for the Hill muscle model is introduced in #26443 -- it will be helpful to refer to the DeGroote2016 classes in sympy.physics.biomechanics.activation together.
      Some load types that could be worked on are:
      Contact force models
      Aerodynamic forces
      Nonlinear springs and dampers
      Models involving biomechanics, refer to #24240 for ideas.
      Involved Software
      Python, Git
      Difficulty
      Beginner to intermediate
      Prerequisite Knowledge
      This project requires basic understanding of dynamics and numerical methods.
      Project Length
      90, 175, or 350 hours (depends on how many features you'd like to implement)
      Classical Mechanics: Constructing Systems From Bodies and Joints
      Idea
      We'd like to be able to construct multibody systems by specifying descriptions of rigid bodies and the joints and constraints that connect them.
      Status
      Sahil Shekewat worked on implementing a joint-based descriptor for systems: https://github.com/sympy/sympy/pulls/sahilshekhawat
      Sudeep Sidhu completed Sahil's work and merged a functioning joint-based system that can solve open-chain problems. See his report: https://github.com/sympy/sympy/wiki/GSoC-2021-Report-Sudeep-Sidhu-:-Implement-JointsMethod
      Timo Steinstra furthered the work by enhancing the joint definition, adding new joints, and developing examples of using the joints framework.
      The next steps are, in order of priority:
      Fix any existing bugs with the joints.
      Add many different example problems to test the robustness of the implementation.
      Allow parsing constants as generalized coordinates to Joint, such as pi / 2 to the PinJoint, as if it is just a fixed pin.
      Implement and test quaternion rotations.
      Implement a Mobilizer joint or CustomJoint for describing complex motions, refer to (#23920 comment).
      Implement an option to choose the generalized speeds efficiently, refer to #24053 comment.
      Involved Software
      Python, Git
      Difficulty
      Intermediate to Advanced
      Prerequisite Knowledge
      This project requires familiarity with multibody dynamics. At the least, one should know how to form the equations of motion of complex systems with one method.
      Project Length
      90, 175, or 350 hours
      Classical Mechanics: Implement an O(N) Equations of Motion Method
      Idea
      Roy Featherstone, Abhi Jain, and others developed recursive methods of forming the right-hand side of the differential equations for complex multibody systems that have an evaluation time of O(N) instead of O(N^3). This project would be dedicated to implementing a symbolic O(N) method to complement the LagrangesMethod and KanesMethod classes. This project would involve implementing 6D vectors and spatial operators, as well as the recursive methods. This would give a significant speed boost in numerical evaluation for systems with bodies greater than 20 or so.
      Status
      Brandom Milam made significant headway in this project in 2016. See:
      https://github.com/sympy/sympy/wiki/GSoC-2016-Application-James-Brandon-Milam:-Base-Class-and-Increased-Efficiency-for-Equation-of-Motion-Generators
      https://github.com/sympy/sympy/pulls/jbm950
      Involved Software
      Python, Git
      Difficulty
      Extremely Advanced
      Prerequisite Knowledge
      This project requires proficiency with multibody dynamics. At the least, one should know how to form the equations of motion of complex systems with one method. The ideal candidate will have experience forming the equations of motion with the aforementioned Featherstone or Jain methods.
      Project Length
      350 hours.
      Computer Science, Graphics, and Infrastructure Projects
      Official LLM Tool Agent for SymPy
      Idea
      This project proposes developing an official LLM tool agent for SymPy. Large Language Models (LLMs) are increasingly used to interact with interfaces through function calling. While SymPy's extensive library interface offers powerful symbolic computation capabilities, it's not readily accessible to LLMs. This agent will bridge this gap by providing a structured interface that allows LLMs to discover and execute SymPy functions based on natural language user requests. This involves creating a machine-readable description of SymPy's public interface (function and class definitions, docstrings, usage examples) that LLMs can understand and use to construct valid function calls. The agent will be designed to be framework-agnostic, supporting popular LLM frameworks like LangChain, LlamaIndex, Haystack, and ell-ai. This project aims to:
      Create templates for LLM tools wrapping SymPy’s library interface.
      Implement integrations with multiple LLM frameworks (LangChain, llama-index, ...), demonstrating usability.
      Design a testing interface that evaluates and reports statistical metrics to assess the correctness of results.
      Develop an interface to facilitate debugging of LLM agent traces.
      Examples of Multi-Step SymPy Operations:
      A key motivation for this project is the ability to handle mathematical problems requiring multiple SymPy function calls. Here are some examples:
      Finding the minimum of a function subject to a constraint: This typically involves:
      Defining the function and the constraint using SymPy symbols.
      Calculating the derivative of the function using diff().
      Solving the system of equations formed by setting the derivative to zero and applying the constraint using solve().
      Potentially evaluating the second derivative using diff() again to confirm that the solution is a minimum (second derivative test).
      For example: "Find the minimum of x^2 + y^2 subject to x + y = 1."
      Solving a differential equation and then evaluating it at a point: This requires:
      Defining the differential equation using Eq() and Function().
      Solving the differential equation using dsolve().
      Substituting a specific value for the independent variable into the solution using subs().
      For example: "Solve dy/dx = y with y(0) = 1 and evaluate the solution at x = 2."
      Calculating the area under a curve and then finding the centroid of that area: This involves:
      Defining the function using SymPy symbols.
      Integrating the function using integrate().
      Calculating the moments of the area using integrate() again (with appropriate weighting functions).
      Calculating the centroid coordinates by dividing the moments by the area.
      For example: "Find the area under the curve y = x^3 from x = 0 to x = 2 and then find the x-coordinate of the centroid of that area."
      These examples demonstrate the need for an LLM agent that can orchestrate multiple function calls within SymPy to solve more complex mathematical problems. The agent needs to understand the dependencies between different operations and handle intermediate results effectively. This capability is beyond the scope of simple one-to-one function call mappings and requires the more sophisticated approach proposed in this project.
      Status
      Currently, there is no official, structured approach for LLMs to interact with SymPy. While users can attempt to use LLMs to generate SymPy code, this approach is unreliable and prone to errors due to the LLM's limitation for code generation.
      Involved Software
      Libraries for LLM interaction/frameworks (LangChain, LlamaIndex, Haystack, LLM-AI)
      An LLM available. If no APIs
      Difficulty
      Intermediate to Advanced. This project requires:
      Familiarity with SymPy’s library interface and codebase.
      Understanding of LLM concepts and function calling.
      Prerequisite Knowledge
      Python programming.
      LLM agents and tool calling.
      Self-host an LLM with tool support.
      Project Length
      This project is suitable for both 175-hour and 350-hour GSoC projects.
      Enhancing the flexibility of MatchPy
      Idea
      MatchPy, a Python library, provides associative-commutative pattern matching and replacement rules for expression trees. This functionality enhances the usability of computer algebra systems, simplifying the formulation of transformation rules for mathematical formulas.
      In essence, MatchPy expressions can be likened to "regular expressions with an awareness of commutative and associative properties”. MatchPy also supports the simultaneous execution of multiple matches, contributing to its exceptional efficiency.
      However, the current requirement for expression trees and wildcards to be subclasses of MatchPy objects presents a significant inflexibility. This constraint forces SymPy to delve into metaclass intricacies to function, limiting the ability to work with expression trees whose node type lacks identification by an object.
      This proposal seeks to enhance MatchPy by restructuring its node type identification, the iteration criteria and wildcard definitions. This involves replacing type checks with custom node identification and iteration rules, fostering greater flexibility in working with various expression tree structures.
      Since MatchPy is currently under a separate project and has experienced a period of inactivity, forking MatchPy becomes necessary for the progress of this project.
      Additionally, if time allows it, this project also envisions exploring the possibility of a Rust implementation of MatchPy, aiming to enhance its speed and efficiency.
      Status
      An experimental connector to MatchPy has been successfully implemented and can be found in sympy.utilities.matchpy_connector. For a comprehensive understanding of the algorithm that drives MatchPy, refer to the paper authored by its creators, available at https://arxiv.org/abs/1710.06915. Furthermore, it's worth noting that MatchPyCpp, an integral submodule of SymEngine, features a translation of the main MatchPy algorithms into C++. However, its performance is presently constrained by the absence of support for coroutines.
      Involved software
      Python, MatchPy
      Difficulty
      Advanced.
      This project very likely requires the MatchPy library to be forked.
      This project necessitates proficiency in executing tree-visiting algorithms.
      Project Length
      350 hours.
      Code Generation
      Idea
      There are quite a few potential projects for codegen.
      The code generation system in SymPy has been overhauled to use AST nodes from sympy.codegen.ast, there are however lot of more nodes that can be added for e.g. Fortran in sympy.codegen.fnodes. It could also be useful if the code printers could output parallel code using OpenMP directives (e.g. parallel for loops for C and Fortran, including use of reduction). Most printers do not yet support the new AST nodes, it would be useful if those were extended so that they can express ASTs created e.g. by functions in sympy.codegen.algorithms.
      Another idea for codegen is to add more support for directly working with matrices. For instance, matrix expressions (sympy.matrices.expressions objects) should print LAPACK calls.
      Status
      We have support for a number of backends and basic code gen classes in place. There is work on updating the system ongoing. Please ask on the mailing list.
      You can check out the work done by Ankit Pandey to extend codegen to support matrix operations at Extending Codegen GSoC 2019
      Involved Software
      Fortran, C, C++, Julia, Rust, Python, LLVM, Javascript, Octave, Matlab, etc.
      Difficulty
      Intermediate to Advanced
      Prerequisite Knowledge
      Project Length
      175 hours or 350 hours, depending on the project details (discuss with us).
      Code Generation: Efficient Jacobian and Hessian Evaluation for Optimization and ODE Integration
      Idea
      When solving optimization problems with gradient based solutions, you typically need to evaluate the function to optimize along with its Jacobian and/or Hessian (or the Lagrangian of the Hessian). SciPy offers many optimization routines, many which accept three functions for evaluating the function, the Jacobian, and the Hessian. If you create a function in SymPy, then having the ability to do something like:
      rosenbrock_expr = (a - x)**2 + b*(y - x**2)**2
      eval_f, eval_j, eval_h = generate_minimize_derivative_funcs(expr, (x, y), extra_args=(a, b))
      result = minimize(eval_f, x0, jac=eval_j, hess=eval_h)
      would make it very easy to solve optimization problems from functions defined in SymPy. If the expression is very large, the computational cost of evaluating those three functions needs to be minimized. With careful use of lambdify, autorwrap, and shared common sub expressions, SymPy can generate very efficient versions of these functions.
      Similarly, when numerically integrating ordinary differential equations, the Jacobian of the integrand (and its sparsity information) can be useful for the integration algorithms.
      rhs = [
          v(t),
          (-sign(v(t))*B*v(t)**2 - k*x(t) - c*v(t) + A*sin(w*t))/m
      ]
      eval_f, eval_j, sparsity = generate_ode_derivative_funcs(rhs, (x(t), v(t)), extra_args=(A, B, m, c, k))
      result = solve_ivp(eval_f, (0.0, 1.0), y0, jac=eval_j, jac_sparsity=sparsity)
      Once again, for very large expressions, generating computationally efficient code becomes very important for fast integration performance.
      Status
      There are existing tools where these basic ideas have been implemented outside of SymPy. For example:
      pyodesys: integrates ODEs defined with SymPy
      symopt: optimizes functions defined with SymPy
      opty: generates a numerical function and its sparse jacobian
      simple stackoverflow question
      optimization problem that doesn't quite connect sympy to scipy
      symjit has a simple API for generated numerical functions on-the-fly.
      Riccardo added a new Jacobian function in 2024 that efficiently computes Jacobians of very large expressions in #26773. We should be able to use this, at least optionally, for computing derivatives.
      See the SciPy documentation:
      SciPy Optimization
      solve_ivp
      Involved Software
      None
      Difficulty
      Intermediate to Advanced
      Prerequisite Knowledge
      Knowledge of optimization and ODE integration and their associated numerical methods.
      Project Length
      175 or 350
      Parsing
      Idea
      SymPy has the ability to generate Python, C, and Fortran code from SymPy expressions.
      It would be very interesting to go the other way, to be able to parse Python, C, and Fortran code and produce SymPy expressions. This would allow SymPy to easily read in, alter, and write out computational code. This project would enable many other projects in the future. Ideally, this project would create a general framework for parsers and then use this system to implement parsers for a few of the languages listed above. See the other parsing ideas on this page, as well as Parsing.
      Status
      SymPy currently has a parsing module that supports parsing LaTeX and autolev using ANTLR, C, and Fortran. The parsing module also supports a Python parser, with special extensions to support things like implicit multiplication (2a -> 2*a) and implicit function application (sin x -> sin(x)), which uses the Python tokenize module.
      You can check out the work done on the C and Fortran parsers at Creating a C and Fortran Parser GSoC 2019
      The existing parsers could be improved by adding support for more features of the programming languages, or new parsers could be added for other languages like Julia, Octave, MATLAB, etc.
      Involved Software
      Fortran, C, C++, Julia, Rust, Python, LLVM, Octave, Matlab, etc.
      Difficulty
      Intermediate to Advanced
      Prerequisite Knowledge
      Project Length
      175 hours or 350 hours, depending on the project details (discuss with us).
      Improve the plotting module
      Idea
      A new plotting module sympy-plot-backends has been written, which is planned to replace the existing sympy.plot module (see https://github.com/sympy/sympy/issues/23036).
      The idea is to merge this module into SymPy, also implementing substantial improvements and possibly new functionalities.
      A very approximate guesstimate is given.
      medium/hard: Refactoring of *Series classes in order to reduce code repetition and allow the implementation of new features.
      easy/medium: Improve numerical evaluation.
      medium/hard: implement custom theming for interactive applications and fix a behaviour affecting the current interactive module.
      easy/medium: Implement new functionalities:
      2D and 3D linear operators (the effect of a matrix on a plane/3D space)
      Phase portrait for Ordinary Differential Equations.
      Improve plot_parametric_region to better visualize complex maps.
      Animations.
      easy/medium: Packaging: while the main plotting functionalities work just with sympy, numpy and matplotlib, the full plotting module relies on several other packages. It has been observed that building a conda package with the full dependencies is difficult: most of the time the build succeed but the installation fails. Debug and fix it.
      easy/medium: Implement a intelligent routine that automatically determines the regions of interest for plotting.
      Fix related things/bugs in SymPy
      More detailed information can be found on this page.
      Status
      Currently, the new plotting module lives on an external repository: sympy-plot-backends
      Involved Software
      Python, HTML, Javascript, CSS
      Difficulty
      Intermediate to Advanced: working with several different packages can be overwhelming.
      Prerequisite Knowledge
      Project Length
      350 hours.
      Documentation tooling
      Idea
      SymPy's documentation makes use of Sphinx and several Sphinx extensions. The idea here is to improve the tooling around the docs by developing some Sphinx extensions. Some ideas here
      Write a Sphinx extension that improves the way autodoc cross references work (see https://github.com/sympy/sympy/issues/23081)
      Add autosummary to our docs so that each function is on a separate page. This may require writing a Sphinx extension or some other tooling. See https://github.com/sympy/sympy/pull/22589 for why default autosummary does not work.
      Implement linters for various parts of markup so that people can avoid common mistakes. Mistakes include:
      Using the wrong type of markup for math, code, and cross-references (see also https://github.com/sympy/sympy/issues/13519)
      Common mistakes in LaTeX
      m
      a
      t
      h
      (see for instance https://github.com/sympy/sympy/issues/17803)
      Various things outlined in the documentation style guide
      Improved tooling to make sure every docstring is included in Sphinx and every docstring has a doctest (see the bin/coverage_doctest script in the SymPy repo, which needs improvement)
      Some way to make it so that headers in docstrings can be easily linked to and cross-referenced https://github.com/sympy/sympy/issues/17599
      Allow subheaders in docstrings https://github.com/sympy/sympy/issues/17618
      Several other small issues, mostly relating to the way autodoc generates documentation. See these issues for some additional ideas https://github.com/sympy/sympy/labels/GSoD.
      NOTE: Google requires that any GSoC project be primarily coding. This project is not primarily about writing documentation, as such a project is not allowed. It is instead about developing tooling to improve the SymPy documentation system.
      Status
      Some things are already implemented, for instance, we have an extension that lets us use dollar signs for math in RST https://github.com/sympy/sphinx-math-dollar. See the above issues for the status of any specific item.
      Involved Software
      This would primarily involve working with Sphinx and building Sphinx extensions or modifying existing ones. If relevant, we may prefer to upstream changes to Sphinx itself (although the Sphinx developers will not be mentors on this project, so we should not rely on this happening).
      Difficulty
      Intermediate to advanced (working with Sphinx can often be difficult)
      Prerequisite Knowledge
      Prior experience with RST and using autodoc is recommended.
      Project Length
      A project to implement all or the majority of the above ideas would require a 350 hours project, but a 175 hours or even 90 hours project can also be done that only implements a subset of the above ideas.
      Hypothesis testing
      Idea
      Hypothesis is a Python library for property-based testing. Hypothesis tests work by specifying properties that a function should satisfy, and automatically generating inputs to test it. There are more details of the idea of adding hypothesis to SymPy in this issue.
      The idea is to explore adding hypothesis testing to SymPy. We should start small, ideally with a function that is already well tested and has relatively easy to generate inputs. From there we can expand the testing.
      Some work has begun on this but hypothesis is currently only used in a couple of tests (search the sympy codebase for "hypothesis" to see where it is currently used). However, we would like for much larger fractions of the tests to use hypothesis.
      Work on this project will involve adding tests to more functions, adding more hypothesis strategies for different kinds of inputs, and reporting and potentially fixing any SymPy bugs that you find along the way.
      It's expected that throughout this process you will find many bugs in SymPy. You may end up spending a lot of time in this project debugging failures, fixing bugs, or working around bugs that are not so easily fixed.
      Status
      SymPy has some basic hypothesis tests, which demonstrate a proof-of-concept of using it. However, the usage could be expanded significantly, as only a handful of functions currently have hypothesis tests.
      Involved Software
      The hypothesis testing library.
      Difficulty
      Intermediate to Advanced.
      Hypothesis testing is simple in principle, but using it in practice can be difficult because it will uncover many bugs in SymPy. It will also not be straightforward to use hypothesis to test symbolic expressions (there are some ideas on how to do this outlined in the issue).
      Prerequisite Knowledge
      Prior experience with using hypothesis would be a huge plus, but it is not a hard requirement. If you have not used hypothesis before it is recommended that you play around with it and perhaps try adding some simple tests for something (in SymPy or somewhere else) to get familiar with it.
      Project Length
      350 hours (175 hours is possible, but the longer is preferred since there will be many things to do for this project).
      User Application Projects
      LFortran SymPy Project Ideas
      LFortran is a modern open-source (BSD licensed) interactive Fortran compiler built on top of LLVM. It can execute user's code interactively to allow exploratory work (much like Python, MATLAB or Julia) as well as compile to binaries with the goal to run user's code on modern architectures such as multi-core CPUs and GPUs.
      The basic idea of LFortran is to provide the infrastructure that can be used as a foundation to do anything related to Fortran (tools that need any of: parsing, source code generation, code transformation, machine code generation, etc.)
      LFortran is currently written in Python. Down the line it will get rewritten into C++ for speed and robustness, but even then it will have Python wrappers, so the Python API should not change much.
      There are many potential projects regarding Fortran in general and . Please see the two ideas here first for background information:
      https://github.com/sympy/sympy/wiki/GSoC-Ideas#code-generation https://github.com/sympy/sympy/wiki/GSoC-Ideas#parsing
      And then read through LFortran's documentation, mainly the Developer Tutorial to understand LFortran's AST and ASR.
      This page contains a few well developed ideas.
      SymPy -> Fortran Code Generation and JIT
      Idea
      Code generation from SymPy -> ASR, and then have two options: ASR -> AST -> source code, or ASR -> LLVM -> JIT and load it from Python to test it out.
      Down the road the LLVM route might even be producing better (faster) code than using SymEngine->LLVM, because one can do optimizations on the ASR itself and before it is lowered to LLVM (as part of LFortran down the road), especially if one starts using do loops and arrays, because one knows more semantic information at the Fortran level than the LLVM level. And one can at least see the high level Fortran code (for debugging), as opposed to the relatively low level LLVM IR.
      Currently SymPy represents Fortran code as a SymPy AST which is a combination of sympy.codegen.ast and sympy.codegen.fnodes. The sympy.printing.fcode module then has a visitor pattern that transforms this ast/fnodes AST into Fortran source code.
      As a first step, one would change fcode() to transform this SymPy AST to LFortran's ASR. That will greatly simplify the printing, as LFortran will take care of transforming ASR -> AST (adding variable definitions mostly) and AST->source code. So SymPy code will get simplified. But also this will enable to then use LFortran to just in time compile this ASR and execute it from Python, thus allowing to interactively test the generated code.
      One would port all the features from fcode() into LFortran, where it makes sense. SymPy should only do things which are SymPy specific.
      After this is done, one can implement more features. For example it could be useful if the code printers could output parallel code using OpenMP directives (e.g. parallel for loops for C and Fortran, including use of reduction). Most printers do not yet support the new AST nodes, it would be useful if those were extended so that they can express ASTs created e.g. by functions in sympy.codegen.algorithms.
      Another idea for codegen is to add more support for directly working with matrices. For instance, matrix expressions (sympy.matrices.expressions objects) should print LAPACK calls.
      Project Length
      350 hours.
      Parsing Fortran code to SymPy
      Idea
      LFortran can parse Fortran source code to AST and then convert AST to ASR. This ASR will then get inspected and Fortran expressions identified and converted to SymPy expressions. This would allow SymPy to easily read in, alter, and write out computational Fortran code. This project would enable many other projects in the future.
      This would be a general framework, some applications of this (some of which can be part of this project):
      load the right hand side expressions and generate manufactured solution
      check that a special function (e.g., spherical harmonics) Fortran implementation has the right expressions in it
      Part of this project can also be to implement a capability in LFortran to track the values of variables ("x") that go into an expression when you actually run the code on production data.
      A separate project idea is to:
      optimize floating point expressions (à la https://herbie.uwplse.org/)
      Based on the range of "x" (and other variables), determine which symbolic simplifications make sense to make things more accurate --- and to provide faster implementations of special functions, say if it is determined that "x" in sin(x) is in the range [0, 1e-3], then there are much faster polynomial approximations that give the same accuracy (the same might be possible if the range is say [1.5, 1.7], or any other finite range).
      See https://github.com/sympy/sympy/wiki/GSoC-Ideas#optimize-floating-point-expressions for the expansion of this idea, as this capability is independent of LFortran.
      Project Length
      350 hours.
      Idea Prompts
      Linear algebra
      Improve the matrices module documentation
      Refactor the MatrixBase class.
      Add more special matrices to the matrix expressions module, and migrate some special matrices from the quantum physics module.
      Add more matrix decomposition methods: Schur Decomposition, Polar Decomposition, Hermite Decomposition, ...
      Make the matrices use the specialized data types (Modular Integers, Gaussian Rationals, Polynomial Ring, ...) from the polys module.
      improve the integration algorithm
      integration of functions on domains of maximum extent, etc.
      Interesting idea: "SYMBOLIC COMPUTATION OF INTEGRALS BY RECURRENCE" by MICHAEL P. BARNETT
      A Simple Method for Computing Some Pseudo-Elliptic Integrals in Terms of Elementary Functions, https://arxiv.org/pdf/2004.04910.pdf
      definite integration & integration on complex plane using residues. Note that we already have a strong algorithm that uses Meijer G-Functions implemented. So we need to first determine if such an algorithm would be worthwhile, or if it would be better to extend the current algorithm. Note that there are many integrals that are easy to compute using residues that cannot be computed by the current engine. Other possibilities: the ability to closed path integrals in the complex plane, which is not possible with the Meijer G algorithm.
      https://www.researchgate.net/publication/312366307_Contour_Integration_or_what_is_still_missing_in_Mathematica_Part_1_Residues_and_Contour_Integration
      https://www.researchgate.net/publication/312343785_Contour_Integration_or_what_is_still_missing_in_Mathematica_Part_2_Construction_of_sophisticated_Contour_Paths_Location_of_Poles_insideoutside_Closed_Contours_Special_Functions_Representations_by_Cont
      https://www.researchgate.net/publication/319554309_Contour_Integration_or_what_is_still_missing_in_Mathematica_Part_3_Contour_Integrals_of_Functions_with_Branch_Cuts
      http://www.cs.kent.edu/~pwang/Paul-phd-dissertation.pdf
      Groebner bases and their applications in geometry, simplification and integration
      improve Buchberger's algorithm and implement Faugere F4 (compare their speed) Note: This has already been implemented by a previous GSoC student. Please check with us to see the current state of Groebner bases in SymPy
      improve polynomial algorithms (gcd, factorization) by allowing coefficients in algebraic extensions of the ground domain
      implement efficient multivariate polynomials (arithmetic, gcd, factorization)
      Implement a sparse representation for polynomials (see the dummy files in sympy/polys/ starting with "sparse" in the SymPy source code for a start to this project).
      Figure out which representations to use where (sparse vs. dense).
      implement efficient arithmetic (e.g. using geobuckets (Yan) or heaps (Monagan & Pearce))
      improve SymPy's pattern matching abilities (efficiency and generality)
      implement similarity measure between expression trees
      expression complexity measures (e.g. Kolmogorov's complexity)
      implement expressions signatures and heuristic equivalence testing
      implement semantic matching (e.g. expression: cos(x), pattern: sin(a*x) + b)
      e.g by using power series for this purpose (improve series speed)
      Expand the capabilities of Wild() and match() to support regular expression-like quantifiers.
      improve simplification and term rewriting algorithms
      add (improve) verbatim and semi-verbatim modes (more control on expression rewriting)
      implement more expression rewrite functions (to an exact form that user specifies). This may involve rewriting the rewrite framework to be more expressive. For example, should cos(x).rewrite(sin) return sqrt(1 - sin(x)**2) or sin(pi/2 - x)?
      maybe put transformation rules in an external database (e.g. prolog), what about speed?
      improve context (e.g. input) depended simplification steps in different algorithms
      e.g. the integrator needs different sets of rules to return "better" output for different input
      but there are more: recurrences, summations, solvers, polynomials with arbitrary coefficients
      what about information carried by expressions?
      what is simpler: chebyshevt(1, x) or x ?
      what is simpler: chebyshevt(1000, x) or (...) ?
      improve trigonometric simplification. See for example the paper by fu et. al.
      implement symbolic (formal) logic and set theory
      implement predicate (e.g. first-order), modal, temporal, description logic
      implement multivalued logic; fuzzy and uncertain logic and variables
      implement rewriting, minimization, normalization (e.g. Skolem) of expressions
      implement set theory, cardinal numbers, relations etc.
      This task is heavily tied to the assumptions system.
      implement symbolic global optimization (value, argument) with/without constraints, use assumptions
      continue work on objects with indices (tensors)
      include the index simplification algorithms used in xAct and cadabra.
      generalized functions - Dirac delta, P(1/x), etc... Convolution, Fourier and Laplace transforms
      Fourier and Laplace transforms are implemented but we can not do many cases involving distributions Is this enough alone for a project though? -Aaron
      vector calculus, differential fields, maybe Lie algebras & groups
      parametric integrals asymptotic expansion (integral series)
      Integral equations. See for example the work started at http://code.google.com/p/sympy/issues/detail?id=2344. This could be part of a project on ODEs, for example.
      partial differential equations. Currently, SymPy can't solve any PDEs, though a few tools related to separation of variables are implemented. The PDE module should be structured similarly to the ODE module (see the source code of sympy/solvers/ode.py).
      improve SymPy's Common Subexpression Elimination (CSE) abilities.
      Poly factorization http://cseweb.ucsd.edu/~kastner/papers/tcad06-poly_factorization_cse.pdf
      Singular analysis and test continuous.
      find singularities of the function and classify them.
      test the function whether it is continuous at some point or not. And in the interval. Note: Please discuss this idea with us if you are interested, as as it currently presented, it is somewhat vague.
      Control theory. systems for Maple and Mathematica might provide insight here. http://www.mcs.anl.gov/~wozniak/papers/wozniak_mmath.pdf might be useful.
      Diophantine Equations: SymPy does have substantial support for solving these, nevertheless there is more work possible to improve the solver.
      Other Related Projects
      Non-Ideas
      Every year, people ask about implementing various things that we have already decided do not belong in SymPy. Among these are:
      Out-of-scope ideas. SymPy is primarily a symbolic mathematics software. Ideas that are not related to symbolic mathematics are generally out of scope (with the exception of related topics like plotting or code generation, which are already mentioned here).
      Graph theory. The NetworkX package already does a great job of graph theory in Python. If you are interested in working in graph theory, you should contact them.
      Numerical solvers. SymPy is a symbolic library, so the code should focus on solving things symbolically. There are already many libraries for solving problems numerically (NumPy, SciPy, ...).
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/sympy/
    idea_list_url: https://github.com/sympy/sympy/wiki/GSoC-Ideas

  - organization_id: 148
    organization_name: Synfig
    no_of_ideas:
    ideas_content: |
      Ideas List
      This year we plan to apply to Google Summer of Code. Currently we are looking for project ideas. If you are a contributor, you are welcome to explore existing project ideas towards the GSoC application phase. There are ways to reach out to mentors, and many projects have lists of newcomer friendly issues you can start from. Contributors are also welcome to propose their own project ideas.
      Projects Ideas
      macOS app bundle (175 or 350 hrs)
      Description:
      We are currently using a script to create a macOS app bundle, but it has some issues (This script can be found at: https://github.com/synfig/synfig/blob/master/3-package-osx-dmg.sh). Generation takes a long time (could be greatly improved), it uses incorrect paths in some places and does not sign files.
      Requirements: macOS or access to macOS command-line (so you can test your script)
      add script/program to collect executable/library dependencies (python/c++ preferred) to SynfigStudio.app folder
      add support for signing binary files (this should be done in reverse order, files without dependencies should be signed first, SynfigStudio.app should be signed last)
      remove the macOS launcher script, add the code to set up the required macOS environment from the synfig/synfigstudio apps
      add cpack support to build installer on macOS
      add python and lxml packaging to .app (with signing))
      interface/menu improvements for more native macOS support
      Where to begin:
      create prototype script/program to collect executable/library dependencies
      Expected outcome:
      175 hours
      CMake/CPack builds SynfigStudio.app ready for distribution
      350 hours
      Synfig Studio is better adopted to macOS guidelines
      Difficulty: Medium
      Skills required/preferred: Python/C++
      Possible mentor(s): Dhairya Bahl, Rodolfo Ribeiro Gomes
      Expected size of project: 175 or 350 hours
      Synfig Android Version (350hrs)
      Description: This project aims at providing a solid ground for a Synfig Android version. It aims to do so through two main parts.
      1- Prototype UI (Using Qt for android) that uses synfigapp and -in turn- synfig-core
      There are two main goals here: 1. To have a basic android UI for synfig working. 2. While making this prototype certain parts of the synfig api would be fixed. Which would make SynfigApp and Synfig-Core able to be used with any other UI not just the current gtkmm UI (synfig-studio).
      2- Add more features to the UI Synfig is quite a huge application. Most likely this app would start with only very basic needed synfig features added. Then gradually adding more features from synfig-studio to the new prototype UI.
      Where to begin:
      Start out by understanding and gathering the basic features for animation in synfig. In your proposal include these features and expand on how you plan to include them.
      Research the available mobile/tablet animation apps and prototype a ui design using any ui design software (e.g. canva). This is not required but it will definetly help your proposal.
      Expected outcome
      Prototype Synfig Android Version
      Improved synfig-app and (possibly) synfig-core that can work with any other UI.
      Difficulty: Medium/High
      Skills required/preferred: C++, gtkmm, Qt, using Qt for Android
      Possible mentor(s): Mohamed Adham , Rodolfo Ribeiro Gomes
      Expected size of project: 350 hours
      Brush tool (175hrs)
      Description:
      Synfig is primarily designed for vector-based animation, but it also supports the use of raster images within animations. However, the current functionality only allows for the use of raster images imported from external files (usually BMP, JPG or PNG), limiting users from drawing directly within the application. The goal of this project is to implement the missing Brush tool for raster drawing, allowing users to draw raster content directly in the app. An early attempt to implement this feature, called 'Brush,' exists, but it is entirely nonfunctional. Users are unable to make even a single stroke with the tool.
      Where to begin:
      Look for the code of how tools are implemented in Synfig. As they are coded as a finite state machine, the correspondent files are name as state_
      2. synfigapp is responsible for handling the interface between the graphical user interface (GUI) and the underlying core engine of Synfig (which handles the animation and rendering processes). There are some synfigapp::Actions trying to implement it, as in synfig-studio/src/synfigapp/actions/layerpaint.h
      Expected outcome
      A working tool that allows users to freely hand-draw their artwork, which can then be animated within Synfig, with undo/redo functionality while drawing and features like brush selection, coloring options, and erasing.
      Difficulty: Medium/High
      Skills required/preferred: C++, gtkmm, 2D-drawing
      Possible mentor(s): Rodolfo Ribeiro Gomes , Mohamed Adham
      Expected size of project: 175 hours
      Exporter to Spine file format (175hrs)
      Description:
      The goal of this project is to implement a feature in Synfig Studio that enables exporting skeleton-based animations to the Spine file format. This would allow users to seamlessly transfer their Synfig animations, those created using bone-based rigs and skeleton systems, to Spine for additional refinement or game engine integration. This would involve creating an export function in Synfig that outputs the necessary JSON or binary format that Spine can read. The project will ensure that all essential animation data, such as bone movements, and keyframe timing, are accurately preserved during the export. Thus, users can leverage Synfig's powerful animation tools while taking advantage of Spine's advanced features, such as runtime support in various game engines.
      Where to begin:
      Check Synfig skeleton layer code
      Check Spine JSON format (https://en.esotericsoftware.com/spine-json-format)
      Try to add new menu option "Export to Spine format" to Skeleton layer, which should create basic Spine JSON file.
      Expected outcome * A fully functional export tool in Synfig Studio capable of converting skeleton-based animations into the Spine file format. * The exported Spine file should retain all key elements of the animation, including bones, mesh deformation, and animation keyframes. * The ability to open and refine the exported Spine animation in Spine's editor or integrate it directly into a game engine.
      Difficulty: Medium
      Skills required/preferred: Python (or C++), XML and JSON, understanding of Synfig's animation system, especially skeleton-based animation and bone rigs, and Synfig file format.
      Possible mentor(s): Rodolfo Ribeiro Gomes , Mohamed Adham
      Expected size of project: 175 hours
      Propose a Project
      If you have a project idea, edit the "Project Ideas" section below by filling the required details and sending a pull request (this page is editable at https://github.com/synfig/synfig-docs-dev/blob/master/docs/gsoc/2025/ideas.rst), even if you could not mentor (we will find a mentor).
      Required information for project proposal
      A descriptive title (175 or 350 hrs)
      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      **Description**
      
      A brief description about the project
      
      **Expected outcome**
      
      What benefit this deliver?
      
      **Difficulty** Easy | Medium | High
      
      **Skills required/preferred:** Knowledge Prerequisite
      
      **Possible mentor(s):** Put your name if you are willing to mentor + other mentors.
      
      **Expected size of project:** 90, 175 or 350 hours
      Please mention the following as comment on your proposal pr
      Your name: :)
      Your profile: github | linkedin | etc
      Your role: I am a making this proposal as a <student | mentor | community member | contributor | etc>
      Contacts
      https://www.synfig.org/contact/
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/synfig/
    idea_list_url: https://github.com/synfig/synfig-docs-dev/blob/master/docs/gsoc/2025/ideas.rst

  - organization_id: 149
    organization_name: TARDIS RT Collaboration
    no_of_ideas:
    ideas_content: |
      GSoC 2025 Ideas
      Table of Contents
      Astronomy and Astrophysics Background
      The TARDIS Project
      List of GSoC 2025 Project Ideas
      Rewrite the TARDIS visualisation module using Panel
      Line Identification Plotting Functionality
      Regression Data Dashboard
      Adding HDF Writing Capabilities to TARDIS Modules
      Benchmark Optimization
      Metadata for atomic data
      Continuum opacity source reader
      CARSUS Dashboard
      Astronomy and Astrophysics Background:
      A supernova(here we show SN1994D in the Galaxy NGC4526 - image source: wikipedia) marks the brilliant death throes of a star, during which it outshines its entire galaxy. It not only marks death, though: supernova ejecta change the evolution of the universe and enable the formation of planets and life as we know it. From the iron in your blood to the silicon in your laptop, supernovae return heavy elements assembled from the primordial hydrogen and helium left after the big bang.
      There are still many mysteries surrounding supernovae (e.g. their precise origins, inner workings, …). One way to study these objects in more detail is to split the light coming from these objects into its components (like using a prism) and analyzing the resulting data (which is called a spectrum). Here, we show spectra (black lines) of a number of different supernova types (image courtesy Daniel Kasen and LBL). Different chemical elements present in the supernova leave their mark on the spectra by imprinting characteristic features, so-called atomic lines (regions highlighted in colour). Thus, studying and interpreting such spectra allows us to identify what supernovae are made of.
      With sophisticated computer simulations astronomers try to reproduce the observed spectra to draw conclusion about the properties of the supernova ejecta and ultimately the explosion mechanism and progenitor stars. TARDIS is such a numerical code. It calculates theoretical spectra based on a number of input parameters, such as the supernova brightness and the abundances of the different chemical elements present in the ejecta (e.g. Oxygen, Silicon, Iron, etc.). The main idea for this procedure is that by finding a close match between theoretical and observed spectra we identify the parameters that actually describe the supernovae.
      The TARDIS Project
      As mentioned in the background information above, TARDIS is a scientific tool (more specifically a Monte Carlo radiative transfer code) whose primary goal is the calculation of theoretical spectra for supernovae. Below, you find the typical result of a TARDIS calculation. It shows the calculated synthetic spectra for a simple supernova model. This particular setup (tardis_example) is officially provided by the TARDIS collaboration on the documentation.
      List of GSoC 2025 Project Ideas
      In the TARDIS collaboration we first establish a detailed plan on implementing new features before starting the actual work. This is an important step that ensures that the entire TARDIS collaboration is informed about the development efforts and that the team members can help shape the ideas during the discussion phase. We call these documents TEP - TARDIS Enhancement Proposals. We already have a great list of ideas here that we need help with. Some of these we have specially selected for GSoC 2025 and are listed with specific “warm-up” tasks below. But feel free to propose your own TEP and make a PR on that.
      If you use one of our TEPs, you can definitely add more detail to the implementation, but what we really want to see is a detailed timeline with milestones that shows us that you have thought about how to implement the feature in three months. For any questions about the projects, please ask on Gitter.
      Putting in a Pull Request with the First objective is essential for each proposal to allow to see how you work.
      Rewrite the TARDIS visualisation module using Panel
      Panel
      Visualisation
      Project Length: 350 Hours
      Difficulty: Hard
      Mentors: Abhinav Ohri, Andrew Fullard, Atharva Arya, James Gillanders
      Description: TARDIS has a collection of visualisation tools and widgets to interactively explore TARDIS simulations which run inside Jupyter Notebooks. A lot of these modules currently depend on dependencies like IPython and Qgrid which do not work well with our Sphinx documentation. We want to migrate our tools to depend entirely on Panel instead of these tools and want to showcase their interactivity on our documentation.
      Visualisation Module- https://tardis-sn.github.io/tardis/pull/2872/io/visualization/index.html#tardis-widgets-graphical-user-interfaces
      First Objective: Use Panel to show any hierarchical dataset as 2 interlinked tables, where selecting a row in the first table updates the 2nd table with the data corresponding to the selected row. Bonus points for using TARDIS’ SimulationShellInfo to make the 1st table display shell data and the 2nd table display element abundances.
      Expected Outcomes:
      All visualisation modules moved to Panel.
      Dependencies like qgrid/qgridnext removed.
      Visualisation tools and widgets can be embedded on the website allowing users to interact with them.
      Comprehensive documentation and tests for all code written.
      Line Identification Plotting Functionality
      Visualisation
      Plotly
      Matplotlib
      Project Length: 350 hours
      Difficulty: Medium
      Mentors: Abhinav Ohri, Andrew Fullard, James Gillanders
      Description: TARDIS and STARDIS produce spectra that contain information about the elements and molecules that are part of the simulation. Both software record information about which elements produce which parts of the output spectrum. For TARDIS and STARDIS, you will access the information about where lines originate and plot the frequencies or wavelengths of the originating elements or molecules as requested by the user. This functionality will be incorporated into any of the existing spectral visualizations in TARDIS and STARDIS, so it must be modular.
      First Objective: Produce a table of energy packets that can be filtered by the originating element. Provide a Jupyter notebook showing a plot of the table with labels and style that matches other TARDIS visualizations.
      Expected Outcomes:
      Visualisation Module that builds the plot using existing dependencies.
      Comprehensive documentation and tests for all code written.
      Regression Data Dashboard
      Data Visualisation
      Dashboards
      Python
      Git
      HDF
      Project Length: 350 Hours
      Difficulty: Hard
      Mentors: Abhinav Ohri, Andrew Fullard, Atharva Arya
      Description: TARDIS implements a regression testing framework that compares current output to an already saved version to validate code. The goal of this project is to develop a dashboard to see exactly where the values of the files changed. Other than this, this project will also improve TARDIS HDF writing capabilities and add functionality to restore simulations from HDF and to create simulation checkpoints which work with the regression data.
      TARDIS Regression Data: https://github.com/tardis-sn/tardis-regression-data
      First objective:
      Run the comparison notebook for the past 10 TARDIS commits and share a graph of how any file changed over the course of these commits. Hint: Each TARDIS commit will generate its own regression data that you need to compare to the data the previous commit produced.
      Expected Outcomes:
      Dashboard preferably using existing TARDIS dependencies(see Conda environment)
      Visualisation that allows seeing how regression data files changed over a large commit range. Commits which produce large changes are recorded permanently.
      Flexible code that works with changes in the TARDIS environment.
      Comprehensive documentation and tests for all code written.
      Adding HDF Writing Capabilities to TARDIS Modules
      Data Storage
      HDF5
      Python
      Project Length: 350 Hours
      Mentors: Andrew Fullard, Atharva Arya, Abhinav Ohri
      Difficulty: Hard
      Description: This project will improve TARDIS HDF writing capabilities and add functionality to restore simulations from HDF and to create simulation checkpoints which work with the regression data.
      TARDIS Regression Data: https://github.com/tardis-sn/tardis-regression-data
      First objective: Add a method to the spectrum class that allows restoring the class from an HDF. Share the notebook in a pull request.
      Expected Outcomes:
      Modular code that allows recreating TARDIS modules from HDF files exactly the way they were before.
      Comprehensive documentation and tests for all code written.
      Benchmark Optimization
      Performance
      Benchmarking
      Python
      Airspeed Velocity
      Project Length: 350 Hours
      Mentors: Andrew Fullard, Atharva Arya, Abhinav Ohri
      Difficulty: Hard
      Description: TARDIS commits are monitored by a benchmarking framework to detect performance regressions. But the current framework only tests 5 commits at a time and not with much detail. The goal of this project is to improve the benchmarking framework by adding more benchmarks. This project will also add more benchmarks to STARDIS, a related code. The second stage of the project will use the benchmarks to investigate possible performance improvements to TARDIS and STARDIS.
      TARDIS Benchmarks: https://tardis-sn.github.io/tardis-benchmarks/
      STARDIS Benchmarks: https://tardis-sn.github.io/stardis-benchmarks/
      First objective: Benchmark the Plasma solver factory and share the ASV results for the last 5 commits along with the code in a pull request.
      Expected Outcomes:
      Exhaustive benchmarks that time important TARDIS modules like plasma, transport, visualisation to name a few.
      Larger history of benchmarks(currently only 5) and regenerating benchmarks for failed commits to avoid losing benchmark history.
      Comprehensive documentation and tests for all code written.
      Metadata for atomic data
      Data Management
      Atomic Data
      Pandas
      Project Length: 350 Hours
      Mentors: Andreas Flörs, Andrew Fullard
      Difficulty: Easy
      Description: Carsus provides atomic data to astrophysicists. It would be useful to provide additional data, “metadata”, along with the atomic data, so that users know the source and details of how the data were processed. For this project, you will add metadata to the Carsus atomic data output. This metadata will include physical units, git commit hashes, article citations, and more. You will also work on TARDIS to enable reading of this metadata.
      Carsus- https://tardis-sn.github.io/carsus/
      First objective: add a metadata table to an existing Carsus output, with a DOI link to a journal article of your choice, some physical units (e.g. Hertz, meters, erg). The output could be the Carsus HDF file, or a Pandas DataFrame. Some form of automation is a bonus.
      Expected Outcomes:
      Metadata for all Carsus outputs.
      Comprehensive documentation and tests for all code written.
      Continuum opacity source reader
      Data Processing
      Scientific Data
      Project Length: 350 Hours
      Mentors: Andrew Fullard, Josh Shields
      Difficulty: Hard
      Description: There’s a lot of literature with useful tables for the TARDIS codebase and other scientific codes in pdfs ( example ), or often in dataproducts. Carsus currently reads in data from standard sources and archives( Chianti , CMFGEN ), but does not flexibly read data from sources in the literature. The goal of this project is to expand Carsus to read datatables like ones in this work, with potential expansion for a future-proof workflow (new opacity tables). These could all go in a new tardis repository called “carsus-literature-tables” or something along those lines. You can look at this for a preprocessed datatables ready to be ingested by Carsus might look.
      Carsus- https://tardis-sn.github.io/carsus/
      First objective: Read one of the datatables from the linked paper here (try s92.201.gz, under ftp) and process it into a pandas dataframe. Look to do this in a programmatic way that could be reused for similar files, like the other tables found here. See section 6.4 for more details on table contents and formatting if desired.
      Expected Outcomes:
      Code that reads in the new dataproducts and integrates with Carsus.
      Comprehensive documentation and tests for all code written.
      CARSUS Dashboard
      GitHub Actions
      Python Scripting
      Pandas
      Notebooks
      Project Length: 350 Hours
      Mentors: Josh Shields
      Difficulty: Hard
      Description: Carsus is a package to manage atomic datasets. It can read data from a variety of sources and output them to file formats readable by radiative transfer codes like TARDIS. The goal of this project is to build python APIs and Jupyter Notebook scripts to investigate different atomic datasets from various sources. The scripts help researchers analyze key components of atomic data files, including metadata, lines/levels structure and element composition, while enabling web access to examine and compare different atomic datasets.
      Regression Data Repository: https://github.com/tardis-sn/tardis-regression-data
      Carsus: https://github.com/tardis-sn/carsus
      First objective: Use Jinja2 to generate an HTML Report that investigates an atomic file. Display top 50 rows of levels and lines dataframes from the atomic file for Silicon. Here are a few example notebooks-
      Quickstart Notebook
      Compare atomic files . You can find atomic files in the TARDIS regression data repository
      Expected Outcomes:
      Python APIs and notebooks that investigate custom atomic data files from external parameters and can be triggered using GitHub Actions.
      Modular code that is compatible with both legacy atom data files and is future-proof.
      Comprehensive documentation and tests for all code written.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/tardis-rt-collaboration/
    idea_list_url: https://tardis-sn.github.io/summer_of_code/ideas/


  - organization_id: 150
    organization_name: The Apache Software Foundation
    no_of_ideas:
    ideas_content: |
      Pages
      ComDev Wiki
      GSoC
      GSoC 2025 Ideas list
      Created by Maxim Solodovnik, last modified about 5 hours ago
      This page is auto-generated! Please do NOT edit it, all changes will be lost on next update
      Contents
      Airavata
      Streamline Grouping and Filtering in the Experiment Browser UI
      Update Airavata Django Portal to a Supported Python Version
      Migrate Apache Airavata Deployment from Ansible to OpenTofu
      Develop an Integrated Feature Test Environment for Apache Airavata
      A Central Admin Dashboard to Inspect Health + Logs of Airavata Services
      Containerized Deployment of Airavata Services
      Apache Dubbo
      GSoC 2025 - Service Discovery
      GSoC 2025 - Add more traffic management rule support for Dubbo Proxyless Mesh
      GSoC 2025 - Dubbo Admin traffic management feature
      GSoC 2025 - Enhancing Dubbo Python Serialization
      GSoC 2025 - Dubbo triple protocol for go language implementation
      GSoC 2025 - Dubbo Gradle IDL Plugin
      DolphinScheduler
      Enhancing Apache DolphinScheduler with Generalized OIDC Authentication
      Lucene.NET
      Apache Lucene.NET Replicator and Dependency Injection Enhancements
      CloudStack
      Apache CloudStack DRS improvements
      verification of LDAP connection
      SSL - LetsEncrypt the Console Proxy
      Autodetect IPs used inside the VM on L2 networks
      [GSoC] [CloudStack] Improve CloudMonkey user experience by enhancing autocompletion
      add securitata integration to cloudstack
      eBPF-based Network Observability for CloudStack
      Enhancing CloudStack Monitoring with eBPF
      StreamPipes
      Extend visualization capabilities of Apache StreamPipes
      Kvrocks
      [GSOC][Kvrocks] Improve the controller UI
      [GSOC][Kvrocks] Support database backup to cloud storage
      Beam
      Simplify management of Beam infrastructure, access control and permissions via Platform features
      Enhancing Apache Beam JupyterLab Sidepanel for JupyterLab 4.x and Improved UI/UX
      Enhance lineage support in Beam
      Beam ML Vector DB/Feature Store integrations
      Beam YAML ML, Iceberg, and Kafka User Accessibility
      RocketMQ
      Refactoring the RocketMQ Dashboard UI and Enhancing Usability
      Optimizing Apache RocketMQ's POP Orderly Consumption Process
      SkyWalking
      SkyWalking BanyanDB Extend remote.FS with Object Storage Support for AWS, Google Cloud, and Azure
      Seata
      GSoC 2025 - Apache Seata(Incubating) Extend multi-raft cluster mode
      GSoC 2025 - Apache Seata(Incubating)Unlocking the Power of Metadata in Apache Seata From Load Balancing to Advanced Routing
      GSoC 2025 - Apache Seata(Incubating) Enhancing Connection Pool Management for Apache Seata AT/XA Transaction Modes
      HugeGraph
      [GSoC][HugeGraph] Implement Agentic GraphRAG Architecture
      Mahout
      Apache Mahout Refactoring the Website
      Doris
      Apache DorisEvaluating Column Encoding and Optimization
      Apache Doris Enhancing Group Commit Functionality
      HertzBeat
      [GSOC][HertzBeat] AI Agent Based on the MCP Protocol for Monitoring Info Interaction
      Airavata
      Streamline Grouping and Filtering in the Experiment Browser UI
      Embed a researcher-focused dashboard to group and preview experiments in the Django portal. The goal is to improve how past experiment runs can be tracked, grouped, and arranged for faster lookup and insights.
      Proposed Improvements:
      Group submitted experiments by project, application, allocation, etc.
      Clean, customizable dashboard elements (e.g., charts) to preview past experiments.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Yasith Jayawardana, mail: yasithmilinda (at) apache.org
      Project Devs, mail: dev (at) airavata.apache.org
      Update Airavata Django Portal to a Supported Python Version
      The Airavata Django Portal currently runs on Python 3.6, which reached its end-of-life (EOL) in 2022. Continuing to use an unsupported Python version poses security risks and limits access to new features and package updates. Upgrading to a supported version (Python 3.12 or later) will ensure long-term maintainability, security, and compatibility with modern dependencies.
      Status of Python versions
      Impact:
      • Improved security and stability
      • Access to the latest language features and performance improvements
      • Compatibility with actively maintained third-party packages
      Proposed Solution: Update the codebase and dependencies for compatibility with Python 3.12+, and ensure everything works as expected post-upgrade.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Yasith Jayawardana, mail: yasithmilinda (at) apache.org
      Project Devs, mail: dev (at) airavata.apache.org
      Migrate Apache Airavata Deployment from Ansible to OpenTofu
      Objective
      Replace existing Ansible deployment scripts with OpenTofu configurations to improve deployment efficiency and maintainability for bare-metal environments.
      Requirements
      Assessment of Current Ansible Scripts
      Review Existing Playbooks: Analyze the current Ansible playbooks located in the Airavata GitHub repository to understand the deployment processes and dependencies.
      Identify Core Components: Determine the essential services and configurations managed by Ansible, such as Kafka, RabbitMQ, Zookeeper, MariaDB, etc.
      Development of OpenTofu Configurations
      Define Infrastructure as Code (IaC): Utilize OpenTofu's declarative language to codify the infrastructure components identified in the assessment phase.
      Module Creation: Develop reusable modules for each service (e.g., Kafka, RabbitMQ, Zookeeper) to promote consistency and ease of management.
      Testing and Validation
      Simulate Deployments: Use OpenTofu's planning capabilities to simulate deployments, ensuring configurations align with the desired infrastructure state.
      Iterative Refinement: Address any discrepancies or issues identified during testing to refine the OpenTofu configurations.
      Documentation
      Update Deployment Guides: Revise existing documentation to reflect the new OpenTofu-based deployment process, providing clear instructions for users.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Lahiru Jayathilake, mail: lahirujayathilake (at) apache.org
      Project Devs, mail: dev (at) airavata.apache.org
      Develop an Integrated Feature Test Environment for Apache Airavata
      Objective
      Enhance the current development workflow by incorporating a simulated High-Performance Computing (HPC) environment into Apache Airavata's existing Integrated Development Environment (IDE) integration. This will enable developers to test and validate features locally without relying on physical HPC resources.
      Requirements
      Simulated HPC Environment Integration
      Dockerized Slurm Simulation: Develop a Docker container that emulates an HPC environment using Slurm, facilitating the testing of job scheduling and execution.
      Seamless IDE Integration: Ensure that this simulated environment integrates smoothly with the existing IDE setup, allowing developers to initiate and monitor jobs as they would in a real HPC setting.
      Development of Comprehensive Test Scenarios
      Job Submission Tests: Create scripts to test various job submission scenarios, including successful executions, intentional failures, and long-running processes.
      Feature Validation: Ensure that all features exposed by Apache Airavata can be tested within this simulated environment.
      User-Friendly Setup
      Simplified Configuration: Design the setup process to require minimal configuration, enabling developers to initiate the environment and execute tests with just a few commands
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Lahiru Jayathilake, mail: lahirujayathilake (at) apache.org
      Project Devs, mail: dev (at) airavata.apache.org
      A Central Admin Dashboard to Inspect Health + Logs of Airavata Services
      Develop a devops dashboard to monitor Apache Airavata services, enabling real-time tracking of service health, uptime, and logs independent of the science gateway(s).
      This centralized tool will help administrators efficiently monitor service performance and troubleshoot issues. The dashboard will feature a user-friendly monitoring UI that displays real-time status updates and logs for each service.
      Proposed Solution:
      A logging subproces alongside each service, pushing logs to an external service.
      A devops dashboard that aggregates the logs and provides a unified view into the system.
      API calls from devops dashboard to each service, for proactive health-checking.
      Ability to monitor multiple gateways from the same dashboard.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Yasith Jayawardana, mail: yasithmilinda (at) apache.org
      Project Devs, mail: dev (at) airavata.apache.org
      Containerized Deployment of Airavata Services
      Currently, all Airavata services are packaged and deployed as Java bundles. The goal is to containerize each service by wrapping it within a Dockerfile, allowing seamless deployment on container-enabled resources while also enabling local execution for development purposes.
      This enhancement has potential to improve deployment consistency, simplify dependency management, and provide greater flexibility in running Airavata services across different environments, for both testing and production use cases.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Yasith Jayawardana, mail: yasithmilinda (at) apache.org
      Project Devs, mail: dev (at) airavata.apache.org
      Apache Dubbo
      GSoC 2025 - Service Discovery
      Background and Goal
      Service Discovery
      Well organized logs
      Actuator endpoints
      Tools
      Relevant Skills
      Familiar with Java
      Familiar with Microservice architecture
      Potential Mentors
      Jun Liu, Apache Dubbo PMC Chair, junliu@apache.org
      dev@dubbo.apache.org
       
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Jun Liu, mail: liujun (at) apache.org
      Project Devs, mail:
      GSoC 2025 - Add more traffic management rule support for Dubbo Proxyless Mesh
      Background and Goal
      The concept of[ Proxyless Mesh|https://istio.io/v1.15/blog/2021/proxyless-grpc/] was first introduced in this blog. Please read it to learn more concept details.
      We have started the development of Dubbo Proxyss Mesh for a while, so that means you don't have to start the project from scratch, anyone who gets involved can start with a specific task at hand. 
      In this specific GSoC project, we need developers to mainly focus on implementing more traffic management features of Istio for Dubbo.
      Relevant Skills
      Familiar with Java
      Familiar with Service Mesh, istio and Microservice architectures
      Familiar with Kubernetes
      Potential Mentors
      Jun Liu, Apache Dubbo PMC Chair, junliu@apache.org
      
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Jun Liu, mail: liujun (at) apache.org
      Project Devs, mail:
      GSoC 2025 - Dubbo Admin traffic management feature
      Background and Goal
      Dubbo is an easy-to-use, high-performance microservice framework that provides both RPC and rich enterprise-level traffic management features.
      The community has been working on the improvement of Dubbo's traffic management abilities, to make it support rich features like traffic spliting, canary release, a/b testing, circuit breaker, mocking, etc. The complete traffic management architecture in Dubbo consists of two major parts, Control Plane and Data Plane. In Dubbo, Control Plane refers to Dubbo Admin, with source code in apache/dubbo-kubernetes. Dubbo Data Plane is implemented by Dubbo sdk (Java, Go, etc)
      The traffic management rules Dubbo ueses now is compatible with the rules in Istio. That means the rules generated by Dubbo Admin and sent to SDK is Istio compatible rules. In this project, we need developers to work mainly on Dubbo Admin to make sure it generates and sends those rules correctly.
      
      Relevant Skills
      Familiar with Golang
      Familiar with Service Mesh, istio and Microservice architectures
      Familiar with Kubernetes
      Potential Mentors
      Jun Liu, Apache Dubbo PMC Chair, junliu@apache.org
      dev@dubbo.apache.org
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Jun Liu, mail: liujun (at) apache.org
      Project Devs, mail:
      GSoC 2025 - Enhancing Dubbo Python Serialization
      Background and Goal
      Currently, Dubbo Python exposes a serialization function interface that requires users to implement their own serialization methods. For commonly used serialization formats such as JSON and Protobuf, users must manually configure them each time. To streamline this process, we aim to build a built-in serialization layer that provides support for these common serialization formats by default.
      Goal
      We recommend using Pydantic to achieve this. Therefore, we expect the implementation to:
      1. an internal serialization layer based on Pydantic, with support for at least JSON and Protobuf.
      2. Leverage Pydantic's additional features, including data validation and other useful functionalities.
      Relevant Skills
      1. Familiar with Python
      2. Familiar with RPC
      Potential Mentors
      Albumen Kevin, Apache Dubbo PMC, albumenj@apache.org
      dev@dubbo.apache.org
        
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Albumen Kevin, mail: albumenj (at) apache.org
      Project Devs, mail:
      GSoC 2025 - Dubbo triple protocol for go language implementation
      Background and Goal
      Dubbo is an easy-to-use, high-performance microservice framework that provides both RPC and rich enterprise-level traffic management features.
      keep-alive
      connection management
      programming api
      error code
      Relevant Skills
      Familiar with Golang
      Familiar with RPC
      Familiar HTTP/1/2/3 protocol
      Potential Mentors
      Jun Liu, Apache Dubbo PMC Chair, junliu@apache.org
      dev@dubbo.apache.org
        Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Jun Liu, mail: liujun (at) apache.org
      Project Devs, mail:
      GSoC 2025 - Dubbo Gradle IDL Plugin
      Background and Goal
      In the API-First design paradigm, IDL (Interface Definition Language) and its corresponding generation tools have become essential. IDL files are the specifications for defining service interfaces, and generation tools can convert IDL files into executable code, thereby simplifying the development process and improving efficiency.
      Currently, Apache Dubbo only provides a Maven IDL generation plugin, lacking a Gradle plugin. This brings inconvenience to developers using Gradle to build projects.
      Necessity
      Unify Build Tools: Gradle is the preferred build tool for Android projects and many Java projects. Providing a Dubbo Gradle IDL plugin can maintain the consistency of build tools and reduce the cost for developers to switch between different build tools.
      Simplify Configuration: Gradle plugins can simplify the configuration and generation process of IDL files. Developers only need to add plugin dependencies and simple configurations in the `build.gradle` file to complete the generation of IDL files without manually executing complex commands.
      Integrate Development Process: Gradle plugins can be better integrated with IDEs (Integrated Development Environments). Developers can directly execute Gradle tasks in the IDE, thereby realizing the automatic generation of IDL files and improving development efficiency.
      Implementation Plan
      Plugin Development: Develop a Gradle plugin that encapsulates the Dubbo IDL generation tool and provides a concise configuration interface.
      Configuration: In the `build.gradle` file, developers can configure parameters such as the path of the IDL file and the directory of the generated code.
      Task: The plugin provides a Gradle task for executing the generation of IDL files. Developers can execute the task through the command line or the IDE.
      Dependency Management: The plugin can automatically manage the dependencies of the Dubbo IDL generation tool, ensuring that developers do not need to manually download and configure it.
      Expected Results
      Developers can use Gradle to build Dubbo projects and easily generate the code corresponding to the IDL.
      Simplify the configuration and generation process of IDL files, and improve development efficiency.
      Better integration with IDEs to achieve automatic generation of IDL files.
      Potential Mentors
      Albumen Kevin, Apache Dubbo PMC, albumenj@apache.org
      dev@dubbo.apache.org
        
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Albumen Kevin, mail: albumenj (at) apache.org
      Project Devs, mail:
      DolphinScheduler
      Enhancing Apache DolphinScheduler with Generalized OIDC Authentication
      Background
      Apache DolphinScheduler is a distributed and extensible workflow scheduler platform designed to orchestrate complex data processing tasks. It provides a user-friendly interface for defining, scheduling, and monitoring workflows, making it easier to manage and automate data pipelines. DolphinScheduler supports various types of tasks, including shell scripts, SQL queries, and custom scripts, and integrates seamlessly with popular big data ecosystems.
      Currently, the Apache DolphinScheduler system supports user login via Password, LDAP, Casdoor SSO, and OAuth. However, as a data platform, it frequently needs to integrate with enterprise - internal user accounts to achieve unified identity authentication, which is crucial for ensuring system security and unified user account management. The existing implementation of Casdoor has a high degree of dependence on the Casdoor project, and the OAuth implementation lacks universality and flexibility.
      Our objective is to implement a more generalized OIDC (OpenID Connect) login authentication mechanism. This will enable users to make better use of unified login authentication. Moreover, popular open source login authentication projects like Dexidp, Keycloak, and OAuthProxy all support OIDC. By supporting OIDC, users can integrate with both internal and third-party login authentication methods, such as Feishu Login and WeChat Work Login.
      Relevant Skills
      Strong proficiency in Java development.
      Experience in modern frontend technologies and frameworks.
      Highlevel expertise in Spring Boot development.
      Thorough familiarity with OIDC and OAuth2 protocols.
      Keen interest in opensource projects and eagerness to learn and adapt.
      Tasks
      Initiate and conduct experiments with Apache DolphinScheduler to comprehensively understand its current functionalities.
      Implement and support a more generalized OIDC (OpenID Connect) login authentication mechanism.
      Compose corresponding E2E test cases.
      Create corresponding documentation for third-party login integrations, covering Keycloak, Dexidp, OAuthProxy, as well as Feishu Login and WeChat Work Login.
      Optimize the UI of the Apache DolphinScheduler login page.
      Ensure compatibility with the existing functionalities of Apache DolphinScheduler during the process of focusing on enhancements.
      Learning Material
       
      Apache DolphinScheduler HomePage: https://dolphinscheduler.apache.org
      Apache DolphinScheduler GitHub Repository: https://github.com/apache/dolphinscheduler
      Sprint OAuth 2.0 Client: https://docs.spring.io/spring-security/reference/reactive/oauth2/client/index.html
      pac4j OIDC: https://www.pac4j.org/docs/clients/openid-connect.html
      OIDC (OpenID Connect): https://openid.net/developers/how-connect-works/
      Mentor
      Gallardot, Apache DolphinScheduler committer, gallardot@apache.org
      SbloodyS, Apache DolphinScheduler PMC, zihaoxiang@apache.org
      Difficulty: Medium
      Project Size: ~150 hours (medium)
      Difficulty: Major
      Project size: ~175 hour (medium)
      Potential mentors:
      Hengliang Tan, mail: gallardot (at) apache.org
      Project Devs, mail: dev (at) dolphinscheduler.apache.org
      Lucene.NET
      Apache Lucene.NET Replicator and Dependency Injection Enhancements
      Background and Goal
      Apache Lucene.NET is a .NET port of the Apache Lucene search engine (originally written in Java). This powerful library enables indexing and searching of documents with custom queries, making it a core component in many production environments. With over 100 million NuGet downloads, Lucene.NET is utilized in diverse scenarios, from local search functionality in mobile apps to supporting large-scale cloud infrastructures.
      Lucene.NET already provides a foundation for replicating a search index from a primary node to one or more replica nodes, enabling High Availability (HA) and scalability through load balancing. Currently, our Lucene.Net.Replicator.AspNetCore project offers minimal replication support for ASP.NET Core servers, but it remains unpublished on NuGet and lacks the robustness required for most use cases. Your focus for this project will be to enhance and finalize the ASP.NET Core library, ensuring a seamless user experience by adhering to best practices and making replication setup as straightforward as possible – ideally requiring just one line of code.
      Additionally, users may need replication support for applications outside ASP.NET Core, such as cloud-based distributed architectures, Windows services, or command-line tools running on Linux. To address this, we propose creating modular intermediate libraries using Microsoft.Extensions.DependencyInjection.Abstractions, enabling flexible and reusable replication configurations. This approach should also ensure that essential components like IndexWriter and IndexReader are configured in a straightforward and user-friendly manner.
      Your task will also include creating one or more sample projects that demonstrate how to effectively use the enhanced replication functionality. These projects should serve as practical, real-world examples for the community, showcasing best practices and ease of use. Additionally, you will be responsible for thoroughly testing the code changes to ensure they work as intended in real-world scenarios. This includes writing comprehensive unit tests to guarantee the reliability and quality of the solution.
      We plan for this to be a hands-on mentorship, and we will set up any infrastructure for you. As a contributor, your responsibilities will include analyzing the problem, developing a detailed plan, refining it with input from the project team, and collaborating regularly to implement the solution through pull requests and code reviews.
      Relevant Skills
      Familiarity with C# and unit testing
      Strong grasp of design patterns and practices, such as dependency injection and i.e. the fluent builder and abstract factory patterns
      Basic understanding of HTTP(S) and networking
      Not required, but good to have:
      Familiarity with ASP.NET Core 5 or later
      Understanding of distributed architectures
      Familiarity with Lucene(.NET) search indexes
      Difficulty: Normal
      Project size: ~175 hour (medium)
      Potential mentors:
      Paul Irwin, mail: paulirwin (at) apache.org
      Project Devs, mail: dev (at) lucenenet.apache.org
      CloudStack
      Apache CloudStack DRS improvements
      As a Operator I would like to have the loads on my systems more evenly/centrally distributed. At the moment there is a simple DRS for clusterwide distribution of loads, this is however not applying zone wide distribution or based on automated queries/improvements.
      In addition we should add historic data for the VM in planning possible migrations.
      At the moment allocated metrics are used. An first improvement would be to use actual metrics.
      
      ref: cloudstack issue: https://github.com/apache/cloudstack/issues/10397
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org
      verification of LDAP connection
      When a new ldap connection is added there is no diagnostics to verify the validity/usability of the connection, making trouble shooting troublesome. This issue aims to facilitate ldap configuration.
      ref. cloudstack issue: https://github.com/apache/cloudstack/issues/6934
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org
      SSL - LetsEncrypt the Console Proxy
      New Global Option For Letsencrypt enable on console proxy. Letsencrypt domain name option for letsencrypt ssl auto renew
      ref. cloudstack issue: https://github.com/apache/cloudstack/issues/3141
      Difficulty: Major
      Project size: ~175 hour (medium)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org
      Autodetect IPs used inside the VM on L2 networks
      With regards to IP info reporting, Cloudstack relies entirely on it's DHCP data bases and so on. When this is not available (L2 networks etc) no IP information is shown for a given VM.
      I propose we introduce a mechanism for "IP autodetection" and try to discover the IPs used inside the machines by means of querying the hypervisors. For example with KVM/libvirt we can simply do something like this:
       {{root@fedora35 ~]# virsh domifaddr win2k22 --source agent
      Name MAC address Protocol Address
      -------------------------------------------------------------------------------
      Ethernet 52:54:00:7b:23:6a ipv4 192.168.0.68/24
      Loopback Pseudo-Interface 1 ipv6 ::1/128
      - ipv4 127.0.0.1/8}}
       
      The above command queries the qemu-guest-agent inside the Windows VM. The VM needs to have the qemu-guest-agent installed and running as well as the virtio serial drivers (easily done in this case with virtio-win-guest-tools.exe ) as well as a guest-agent socket channel defined in libvirt.
      ref. cloudstack issue: https://github.com/apache/cloudstack/issues/7142
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org
      [GSoC] [CloudStack] Improve CloudMonkey user experience by enhancing autocompletion
      Summary
      Currently a lot of API parameters do not get auto-completed as cloudmonkey isn't able to deduce the probable values for those parameters based on the list APIs heuristics. A lot of these parameters are enums on CloudStack end and by finding a way to expose these and consume them on cloudmonkey side, we could improve the usability of the CLI greatly.
      Benefits to CloudStack
      Improved end user experience when using CLI
      Reduce incorrect inputs
      Deliverables
      Expose enums and all other relevant information that can be used to enhance auto-completion of parameters on CloudStack end -
      May require framework level changes and changes to APIs
      Consume these exposed details on Cloudmonkey end
      Dependent projects
      https://github.com/apache/cloudstack-cloudmonkey/
      Ref CloudStack Issue: https://github.com/apache/cloudstack/issues/10442
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Pearl Dsilva, mail: pearl11594 (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org
      add securitata integration to cloudstack
      Currently, Cloudstack only has ACLs (in Advanced Networks) that as a layer of securing access to the networks (VPCs). However, these only operate in the Layer 3 and 4 of OSI Layer.
      In todays day and age, where Cybersecurity threats become more advanced, complex and operate in Layer 7 OSI layer, there needs to be a way for Cloudstack to allow its own tenants to implement its own form of mature cybersecurity solution.
      The problem all this while is that if a user is using a VPC or L2 Networks, 3rd party firewalls such as PFsense, FortinetVM Firwall etc cant be implemented effectively due to a lack of being able to set static routes that stays with the VR after it is recreated.
      There needs to be a better option for users of cloudstack to implement a deeper form of cybersecurity to protect their workloads.
      ref. github issue:  https://github.com/apache/cloudstack/issues/10445
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org
      eBPF-based Network Observability for CloudStack
      CloudStack’s network monitoring is mostly based on logs and external agents, making real-time traffic analysis difficult. This project will integrate eBPF-based network observability to capture per-VM traffic metrics, detect anomalies, and improve tenant isolation.
      Benefits to CloudStack
      Enhanced security: Detect suspicious activity at the kernel level.
      Real-time traffic monitoring: Gain deep insights into VM networking.
      Better tenant isolation: Identify cross-tenant traffic issues.
      Deliverables
      Develop eBPF probes to capture:
      Per-VM network traffic metrics (packets, bytes, latency)
      Connection tracking for detecting unauthorized access patterns
      Packet drops and retransmission rates
      Expose network metrics via CloudStack’s API.
      Provide visualization through Prometheus/Grafana.
      Document setup, usage, and performance benchmarks.
      Expected Outcome
      An eBPF-based solution that improves network observability in CloudStack, providing security and performance insights with minimal resource usage.
      
      Difficulty: Major
      Project size: ~175 hour (medium)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org
      Enhancing CloudStack Monitoring with eBPF
      Apache CloudStack currently relies on traditional monitoring tools, which may lack deep visibility into kernel-level events and networking performance. This project aims to integrate eBPF-based monitoring into CloudStack to provide lightweight, real-time performance analysis and security auditing.
      Benefits to CloudStack
      Improved observability: Gain fine-grained insights into VM performance metrics.
      Lower overhead: eBPF runs in the kernel and avoids the performance penalties of user-space monitoring tools.
      Enhanced security auditing: Detect and log anomalies in system behavior.
      Deliverables
      Implement eBPF programs to track:
      VM CPU usage
      Memory consumption
      Disk I/O metrics
      Network traffic analysis
      Develop a CloudStack-compatible API or CLI for retrieving eBPF-generated insights.
      Provide visualization support using Prometheus/Grafana.
      Write documentation for setup and usage.
      Expected Outcome
      A robust eBPF-based monitoring solution integrated into CloudStack, offering real-time performance insights with minimal overhead.
      ref. cloudstack issue: https://github.com/apache/cloudstack/issues/10415
      
      This project is marked as part-time, but the scope can be extended to full-time. This depends largely on whether the full amount of metrics to track is implemented or only one, as a proof of concept.
      Difficulty: Major
      Project size: ~175 hour (medium)
      Potential mentors:
      Daan, mail: dahn (at) apache.org
      Project Devs, mail: dev (at) cloudstack.apache.org
      StreamPipes
      Extend visualization capabilities of Apache StreamPipes
      Background
       
      Apache StreamPipes is a self-service Industrial IoT toolbox which helps users to connect, analyze and exploit industrial data streams. StreamPipes offers a variety of tools which help users to interact with data from industrial sources such as PLCs. An adapter library allows to get real-time data from industrial controllers or other systems, a pipeline editor allows to build stream processing pipelines using either graphical or code-based flow modeling, and a data explorer allows to quickly create visualizations based on connected adapters.
       Current Challenges
      The StreamPipes data explorer consists of a chart view, where users can create charts based on live data, and a dashboard view, where users can create live dashboards based on charts.
      The data explorer provides a set of charts, which are mainly based on Apache ECharts. The currently available chart library includes time-series line/bar charts, heatmaps, scatter plots, density charts and others. To improve the user experience and add additional capabilities, we plan to extend this chart library with additional charts that are useful for industrial data analytics. 
       Objectives
      The primary objectives of this project are as follows:
      Explore the Apache ECharts library and identify useful additional charts for industrial data analytics
      Improve the StreamPipes data explorer by adding new chart types using Apache ECharts
      Add a more advanced table visualization
      Extend existing charts with additional configurations (e.g., axis configurations, labels, data transformations)
      Add a data preview for all charts, which is shown below the actual chart in the chart view
      Design and implement end-to-end-tests using Cypress
       Recommended Skills
      
      Proficiency in TypeScript programming + testing 
      Proficiency in Angular
      Excellent logical thinking and problem-solving skills.
      Good sense for beautifully looking user interfaces 
      
      Mentor
      
      Dominik Riemer, Apache StreamPipes PMC, riemer@apache.org
      Difficulty: Major
      Project Size: ~350 hours (large)
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Dominik Riemer, mail: riemer (at) apache.org
      Project Devs, mail: dev (at) streampipes.apache.org
      Kvrocks
      [GSOC][Kvrocks] Improve the controller UI
      Background
      Apache Kvrocks is a distributed key-value NoSQL database that uses RocksDB as its storage engine and is compatible with Redis protocol.
       
      In the past, basic Web UI capabilities have been provided for Apache Kvrocks Controller, including features such as cluster creation and migration. In the future, we aim to offer a better and more modern UI experience, also enhancing centralized visualization capabilities.
      Objectives
      The key objectives of the project include the following:
      Refactor the existing UI pages
      Enhance the visualization capabilities for cluster migration
      Provide a cluster Overview dashboard
      
      Recommend Skills
      Familiar with next.js & tailwind
      Have a basic understanding of RESTFul
      Have an experience of Apache Kvrocks
      
      Mentor: Hulk Lin, Apache Apache Kvrocks PMC,  hulk@apache.org
      Mailing List: dev@kvrocks.apache.org
      Please leave comments if you want to be a mentor
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Hulk Lin, mail: hulk (at) apache.org
      Project Devs, mail: dev (at) kvrocks.apache.org
      [GSOC][Kvrocks] Support database backup to cloud storage
      Backgroud:
      Kvrocks is a key-value database that provides a Redis-compatible API on top of RocksDB. Currently, Kvrocks lacks a built-in mechanism for database backup to cloud storage, which is crucial for data durability, disaster recovery, and scalability in cloud environments.
      This project aims to implement a robust backup system that allows users to store Kvrocks backups directly in cloud storage services such as Amazon S3, Google Cloud Storage, and/or Azure Blob Storage. The solution will integrate with the existing Kvrocks backup and restore mechanisms while ensuring efficient and secure data transfer.
      Deliverables:
      Cloud Storage Integration: Implement backup storage support for Amazon S3, Google Cloud Storage, and Azure Blob Storage using SDKs, REST APIs or libraries (e.g. Apache OpenDAL).
      Backup & Restore Commands: Extend Kvrocks’ backup functionality to allow exporting and importing database snapshots from cloud storage.
      Configuration & Authentication: Provide user-configurable options to specify storage credentials and backup parameters.
      Incremental Backup Support (Stretch Goal): Optimize storage usage by implementing differential or incremental backup capabilities.
      Documentation & Tests: Comprehensive documentation and test coverage to ensure reliability and ease of use.
      Recommended Skills:
      Good at coding in C++;
      Knowledge about database internals and cloud storage;
      Knowledge about Kvrocks or Redis.
      Mentor: Mingyang Liu, Apache Kvrocks PMC member,  twice@apache.org
      Mailing List: dev@kvrocks.apache.org
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Mingyang Liu, mail: twice (at) apache.org
      Project Devs, mail: dev (at) kvrocks.apache.org
      Beam
      Simplify management of Beam infrastructure, access control and permissions via Platform features
      This project consists in a series of tasks that build a sort of 'infra platform' for Beam. Some tasks include:
      Automated cleaning of infrastructure: [Task]: Build a cleaner for assets in the GCP test environment #33644
      Implement Infra-as-code for Beam infrastructure
      Implement access permissions using IaC: [Task]: Build a cleaner for assets in the GCP test environment #33644
      Implement drift detection for IaC resources for Beam
      Implement 'best-practice' key management for Beam (i.e. force key rotation for service account keys, and store in secret manager secrets)
      
      A quality proposal will include a series of features beyond the ones listed above. Some ideas:
      Detection of policy breakages, and nagging to fix
      Security detections based on cloud logging
      others?
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Pablo Estrada, mail: pabloem (at) apache.org
      Project Devs, mail: dev (at) beam.apache.org
      Enhancing Apache Beam JupyterLab Sidepanel for JupyterLab 4.x and Improved UI/UX
      The Apache Beam JupyterLab Sidepanel provides a valuable tool for interactive development and visualization of Apache Beam pipelines within the JupyterLab environment. This project aims to significantly enhance the sidepanel by achieving full compatibility with the latest JupyterLab 4.x release and implementing substantial UI/UX improvements. This will ensure seamless integration with modern JupyterLab workflows and provide a more intuitive and user-friendly experience for Apache Beam developers.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      XQ Hu, mail: xqhu (at) apache.org
      Project Devs, mail: dev (at) beam.apache.org
      Enhance lineage support in Beam
      Apache Beam provides a powerful way to define data processing pipelines. However, it is increasingly important for users to be able to track how their data is moving through Beam so that they can make informed choices on how they manage their data at the source or sink of their pipeline. To solve for this, we have recently introduced data lineage in Beam - https://en.wikipedia.org/wiki/Data_lineage - to this point support is still relatively limited though.
      
      For this project, the focus would be on adding broader lineage support to Beam. This could include:
      
      adding column level lineage to more transforms
      adding direct runner support for lineage graphs (https://github.com/apache/beam/issues/33980)
      Integrating Beam with Open Lineage (https://github.com/apache/beam/issues/33981)
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Danny McCormick, mail: damccorm (at) apache.org
      Project Devs, mail: dev (at) beam.apache.org
      Beam ML Vector DB/Feature Store integrations
      Apache Beam's Python SDK provides a powerful way to define data processing pipelines. In particular, many users want to use Beam for machine learning use cases like feature generation, embedding generation, and retrieval augmented generation (RAG). Today, however, Beam integrates with a relatively limited set of feature stores and vector DBs for these use cases. This project aims to build out a rich ecosystem of connectors to systems like Pinecone and Tecton to enable these ML use cases.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Danny McCormick, mail: damccorm (at) apache.org
      Project Devs, mail: dev (at) beam.apache.org
      Beam YAML ML, Iceberg, and Kafka User Accessibility
      Apache Beam's YAML DSL provides a powerful and declarative way to define data processing pipelines. However, its adoption for complex use cases like Machine Learning (ML) and Managed IO (specifically Apache Iceberg and Kafka) is hindered by a lack of comprehensive documentation and practical examples. This project aims to significantly improve the Beam YAML documentation and create illustrative examples focused on ML workflows and Iceberg/Kafka integration, making these advanced features more accessible to users.
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      XQ Hu, mail: xqhu (at) apache.org
      Project Devs, mail: dev (at) beam.apache.org
      RocketMQ
      Refactoring the RocketMQ Dashboard UI and Enhancing Usability
      Background
      
      Apache RocketMQ is renowned as a cloud-native messaging and streaming platform, enabling the creation of event-driven applications with simplicity and flexibility. The RocketMQ Dashboard is a crucial component that provides users with insight into system performance and client interactions through intuitive graphs and statistical data. Despite its fundamental role, the current user interface (UI) of the RocketMQ Dashboard is outdated, affecting user experience and interaction efficiency. Additionally, while the Dashboard offers valuable functionalities, there is a pressing need to enhance its usability and ensure robust security. This project aims to refactor the RocketMQ Dashboard by redesigning its UI with a more contemporary and user-friendly approach, improving overall usability, and introducing effective security measures to safeguard data and user interactions.
      Relevant Skills
      Strong Java development skills.
      Experience with modern front-end technologies and frameworks
      Proficiency in Spring Boot development.
      Understanding of UX/UI design principles. - Knowledge of security best practices in web applications.
      A keen interest in open-source projects and a willingness to learn and adapt.
      Tasks
      
      Launch and experiment with the RocketMQ Dashboard to understand current functionalities.
      Refactor the UI of the RocketMQ Dashboard to align with modern user interface standards, ensuring it is intuitive and visually appealing.  
      Improve usability by streamlining workflows, enhancing navigation, and incorporating responsive design. 
      Integrate security features to protect user data, prevent unauthorized access, and mitigate potential vulnerabilities.
      Maintain compatibility with existing RocketMQ functionalities while focusing on enhancements. 
      Learning Material
      
      RocketMQ HomePage: https://rocketmq.apache.org([https://rocketmq.apache.org|https://rocketmq.apache.org/])
      RocketMQ GitHub Repository: https://github.com/apache/rocketmq([https://github.com/apache/rocketmq]) 
      RocketMQ Dashboard GitHub Repository: https://github.com/apache/rocketmq-dashboard([https://github.com/apache/rocketmq-dashboard]) 
      
      Mentor
      Rongtong Jin, Apache RocketMQ PMC, jinrongtong@apache.org
      Potential Mentor
      Juntao Ji, 3160102420@zju.edu.cn
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Rongtong Jin, mail: jinrongtong (at) apache.org
      Project Devs, mail: dev (at) rocketmq.apache.org
      Optimizing Apache RocketMQ's POP Orderly Consumption Process
      Background
       
      Apache RocketMQ is a distributed messaging and streaming platform that supports various messaging protocols. One of the key features of RocketMQ is its orderly message consumption capability, which guarantees that messages are processed in the order they are sent. However, there are existing issues with the POP Orderly consumption process that need to be addressed to enhance its reliability and performance.
       Current Challenges
      
      Currently, the POP Orderly feature faces several shortcomings, particularly in scenarios where network instability leads to the loss of the attemptId carried by the consumer from the previous round. This issue can result in message consumption getting stuck until the acknowledgment response (ack) for the previous message pull times out. Such situations hinder the efficient processing of messages and reduce the overall effectiveness of the messaging system.
       Objectives
      The primary objectives of this project are as follows:
      ●Refactor the POP Orderly Code: Analyze and redesign the existing codebase to improve its structure, maintainability, and performance.
      ●Optimize Performance: Implement performance enhancements that allow the POP Orderly feature to cope with network fluctuations and reduce the likelihood of consumption halting.
      ●Elegant Process Resolution: Develop a more graceful approach to handling the issue of consumption stalling, ensuring that the system can recover more smoothly from failures.
       Recommended Skills
      
      1. Proficiency in Java programming.
      2. Strong understanding of concurrent programming.
      3. Excellent logical thinking and problem-solving skills.
      4. Familiarity with message queue systems, particularly Apache RocketMQ.
       
       Mentor
      
      Rongtong Jin, Apache RocketMQ PMC, jinrongtong@apache.org
      Potential Mentor
      Juntao Ji, 3160102420@zju.edu.cn
      
      Difficulty: Major
      Project Size: ~350 hours (large)
      
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Rongtong Jin, mail: jinrongtong (at) apache.org
      Project Devs, mail: dev (at) rocketmq.apache.org
      SkyWalking
      SkyWalking BanyanDB Extend remote.FS with Object Storage Support for AWS, Google Cloud, and Azure
      Overview:
      The current implementation of the remote.FS interface only supports a local file system (via the implementation in local.go). This GSOC2025 project proposes to extend remote.FS with popular object storage services—namely AWS S3, Google Cloud Storage, and Azure Blob Storage. This enhancement will allow the project to support robust cloud-based backup and restore operations in addition to local storage.
      Proposed Features:
      AWS S3 Implementation:
      Implement methods for Upload, Download, List, and Delete operations using the AWS S3 API.
      Google Cloud Storage Implementation:
      Provide a module that integrates with Google Cloud Storage to perform similar operations.
      Azure Blob Storage Implementation:
      Develop functionality to access and manage Azure Blob Storage via the remote.FS interface.
      Implementation Details:
      Interface Compliance:
      Each object storage implementation must adhere to the remote.FS interface defined in remote.go.
      Error Handling & Resilience:
      Implement robust error handling, logging, and retry mechanisms to ensure reliable operations across different cloud services.
      Testing:
      Develop comprehensive unit and integration tests to cover edge cases and guarantee compatibility and stability.
      Documentation:
      Update the project documentation to detail configuration, deployment, and usage of each cloud storage option.
      
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Hongtao Gao, mail: hanahmily (at) apache.org
      Project Devs, mail: dev (at) skywalking.apache.org
      Seata
      GSoC 2025 - Apache Seata(Incubating) Extend multi-raft cluster mode
      Description
      Synopsis
      The current Apache Seata Server supports the Raft cluster mode, but the performance and throughput of the cluster are significantly limited due to the single leader in a single Raft group. Therefore, the goal is to extend Seata Server to support multi-raft capability.
      
      Benefits to Community
      Due to the characteristics of Raft, requests are processed on the leader node and the results are submitted to the followers through the Raft consensus protocol. As a result, a significant amount of computational load is placed on the leader node, while followers only need to receive the final computed result. This causes the CPU, memory, and other metrics of the leader to be much higher than those of the followers. Additionally, the throughput of a single leader is limited by the machine configuration of the highest-spec node in the cluster, making it difficult to balance the traffic effectively. Therefore, supporting multi-raft would make the load distribution more balanced across all nodes in the cluster, improving throughput and performance, while also reducing the waste of machine resources.
      
      Deliverables
      The expected delivery goal is to apply the multi-raft capability of the sofa-jraft component to Seata Server through detailed learning and practice
      
      The step expected are the following:
      Learning and using the sofa-jraft component
      Understanding and practicing the transaction grouping capability in Seata
      Gaining a certain level of understanding of Seata's communication protocol
      Gaining a certain level of understanding of Seata's storage model, especially the Raft mode
      Ensuring compatibility between different versions
      Useful links
      seata-raft-detailed-explanation
      transaction-group
      sofa-jraft
      Mentor
      Mentor: Jianbin Chen, Apache Seata(Incubating) PPMC Member jianbin@apache.org
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Jianbin Chen, mail: jianbin (at) apache.org
      Project Devs, mail: dev (at) seata.apache.org
      GSoC 2025 - Apache Seata(Incubating)Unlocking the Power of Metadata in Apache Seata From Load Balancing to Advanced Routing
      Synopsis
      Currently, Apache Seata relies on a registry (e.g., Nacos, Zookeeper, Eureka, Etcd3, Consul, Seata Naming Server) for service discovery and load balancing. However, the existing registry mechanism lacks support for custom metadata, which limits the flexibility of client-side load balancing strategies. For example, clients cannot dynamically adjust traffic distribution based on server-side metadata such as weight, region, or version. This project aims to enhance the registry module in Apache Seata by adding metadata support and enabling clients to implement advanced load balancing strategies based on this metadata.
      Benefits to Community
      Improved Load Balancing Flexibility: By allowing Seata Server instances to register custom metadata (e.g., weight, region, version), clients can implement more sophisticated load balancing strategies, such as weighted round-robin, zone-aware routing, or version-based routing. This ensures better resource utilization and improved system performance.
      Enhanced Scalability: With metadata-driven load balancing, Seata can better handle large-scale deployments by distributing traffic more intelligently across server instances. For example, high-traffic regions can be assigned more resources, while low-traffic regions can operate with minimal overhead.
      Better Resource Utilization: Metadata such as server weight or capacity can help clients avoid overloading specific instances, leading to more balanced resource usage across the cluster.
      Extensibility: The addition of metadata support opens the door for future enhancements, such as dynamic traffic shaping, A/B testing, or canary deployments.
      
      Deliverables
      The expected deliverables for this project include:
      Registry Metadata Support:
      Extend the registry module (e.g., Nacos, Zookeeper, Eureka, Etcd3, Consul, Seata Naming Server) to allow Seata Server instances to register custom metadata (e.g., weight, region, version).
      Ensure backward compatibility with existing registry implementations.
      Client-Side Load Balancing Enhancements:
      Implement a metadata-aware load balancing mechanism in the Seata client (TM/RM).
      Provide built-in load balancing strategies (e.g., weighted random, zone-aware) and allow users to plug in custom strategies via SPI.
      Documentation and Testing:
      Update the Seata documentation to explain how to configure and use metadata for load balancing.
      Write unit tests and integration tests to validate the new functionality
      
      Steps Expected
      1.Understand Seata's Registry Mechanism:
      Study how Seata integrates with various registries (e.g., Nacos, Zookeeper, Eureka, Etcd3, Consul, Seata Naming Server).
      Identify the current limitations in metadata support and load balancing.
      2.Extend Registry Module:
      Modify the registry module to allow Seata Server instances to register custom metadata.
      Ensure the metadata is propagated to clients during service discovery.
      3.Implement Metadata-Aware Load Balancing:
      Enhance the client-side load balancing logic to consider metadata (e.g., weight, region) when selecting a server instance.
      Provide built-in strategies (e.g., weighted random, zone-aware) and support custom strategies via SPI.
      4.Ensure Compatibility and Performance:
      Test the new functionality with different registry implementations (e.g., Nacos, Zookeeper, Eureka, Etcd3, Consul, Seata Naming Server).
      Optimize performance to minimize the overhead of metadata processing.
      5.Documentation and Testing:
      Write clear documentation on how to configure and use the new metadata and load balancing features.
      Develop comprehensive unit tests and integration tests.
      
      Useful Links
      Apache Seata Documentation
      Nacos
      Zookeeper
      Eureka
      Consul
      Etcd3
      Seata Naming Server
      Load Balancing Strategies
      Mentor
      Mentor: Jiangke Wu, Apache Seata(Incubating) PPMC Member xingfudeshi@apache.org
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Jiangke Wu, mail: xingfudeshi (at) apache.org
      Project Devs, mail: dev (at) seata.apache.org
      GSoC 2025 - Apache Seata(Incubating) Enhancing Connection Pool Management for Apache Seata AT/XA Transaction Modes
      Project Overview
      Title
      Enhancing Connection Pool Management for Apache Seata AT/XA Transaction Modes
      
      Abstract
      Apache Seata(incubating) is a popular distributed transaction solution, providing solutions like AT, TCC, and XA for ensuring data consistency in microservice architectures. This project aims to enhance the connection pool management for Seata's AT/XA transaction modes by integrating a comprehensive monitoring and configuration management system within the Seata console. The enhanced functionality will facilitate better resource management and operational efficiency for organizations utilizing Seata.
      
      Detailed Description
      Objectives
      1. Console Metrics Visualization: Develop functionality to view various metrics related to the connection pool in the Seata console. The metrics should be displayed based on IP/connection pool granularity, helping users easily identify resource allocation and utilization.
      2. Metrics Control via Console: Allow users to control various aspects of the connection pools directly from the Seata console. This includes the ability to adjust minimum and maximum connection counts, configure connection acquisition timeout, and manage connection pool keep-alive settings.
      
      Deliverables
      1. Connection Pool Metrics Monitoring:
      Visual display of connection pool metrics including current connections, idle connections, active connections, etc.
      Granular view based on IP and connection pool, enabling detailed monitoring and management.
      Connection Pool Configuration Management:
      2. Implement functions in the Seata console to change connection pool settings:
      Adjust minimum and maximum connection thresholds.
      Set and modify the timeout for obtaining connections.
      Configure keep-alive settings for maintaining active pool connections.
      3. Comprehensive Documentation:
      Provide documentation on how to use the new connection pool features.
      Include developer notes for future contributions and improvements.
      
      Implementation Plan
      Phase 1: Requirement Analysis and Design
      Collaborate with mentors to finalize requirements and design a detailed architecture plan.
      Explore existing Seata console features and connection pool management libraries.
      Phase 2: Development of Monitoring Features
      Implement backend logic to gather connection pool metrics.
      Develop Seata console UI components for metric visualization.
      Phase 3: Development of Control Features
      Integrate functionality to dynamically adjust connection pool configurations via the console.
      Ensure robust validation and error-handling mechanisms are in place.
      Phase 4: Testing and Documentation
      Conduct thorough testing to ensure reliability and performance.
      Write user and developer documentation explaining features, usage, and configuration.
      
      Required Skills
      Passion for Open Source: Enthusiasm to contribute consistently to open-source projects, with a curiosity for technology.
      Understanding of Seata Architecture: Basic knowledge of Apache Seata’s architecture and transaction models.
      Java Proficiency: Strong command of Java programming for backend development.
      
      Benefits to Apache Seata
      The project will enhance Apache Seata’s usability by providing detailed insights and management capabilities for connection pools. This will lead to more efficient resource utilization, aiding organizations in maintaining system performance and reliability within their distributed transactions.
      
      Conclusion
      This project represents an opportunity to significantly improve the operational capabilities of Seata AT/XA transaction modes by enriching the connection pool management features. With rigorous execution, it will provide valuable resources for both users and developers within the Apache Seata community.
      
      Useful Link
      [Apache Seata website](https://seata.apache.org/)
      
      Contact Information
      Mentor Name: [Min Ji](jimin@apache.org) , Apache Seata(incubating) PPMC member
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Min Ji, mail: jimin (at) apache.org
      Project Devs, mail: dev (at) seata.apache.org
      HugeGraph
      [GSoC][HugeGraph] Implement Agentic GraphRAG Architecture
      Apache HugeGraph(incubating) is a fast-speed and highly-scalable graph database/computing/AI ecosystem. Billions of vertices and edges can be easily stored into and queried from HugeGraph due to its excellent OLTP/OLAP ability.
       
      Website: https://hugegraph.apache.org/
      GitHub:
      https://github.com/apache/incubator-hugegraph/
      https://github.com/apache/incubator-hugegraph-ai/
       Description
      Currently, we have implemented a basic GraphRAG that relies on fixed processing workflows (e.g., knowledge retrieval & graph structure updates using the same execution pipeline), leading to insufficient flexibility and high overhead in complex scenarios. The proposed task introduces an Agentic architecture based on the principles of "dynamic awareness, lightweight scheduling, concurrent execution," focusing on solving the following issues:
      Rigid Intent Recognition: Existing systems cannot effectively distinguish between simple retrievals (e.g., entity queries) and complex operations (e.g., multi-hop reasoning), often defaulting to BFS-based template subgraph searches.
      Coupled Execution Resources: Memory/computational resources are not isolated based on task characteristics, causing long-tail tasks to block high-priority requests.
      Lack of Feedback Mechanisms: Absence of self-correction capabilities for erroneous operations (e.g., automatically switching to similar vertices/entities after path retrieval failures).
      The task will include three core parts:
      1. Dynamic Awareness Layer
      Implement an LLM-based real-time (as of February 14, 2025) intent classifier that categorizes tasks (L1 simple retrieval/L2 path reasoning/L3 graph computation/L4+ etc.) based on semantic features (verb types/entity complexity/temporal modifiers).
      Build a lightweight operation cache to generate feature hashes for high-frequency requests, enabling millisecond-level intent matching.
      2. Task Orchestration Layer
      Introduce a suitable workflow/taskflow framework emphasizing low coupling, high performance, and flexibility.
      Adopt a preemptive scheduling mechanism allowing high-priority tasks to pause non-critical phases of low-priority tasks (e.g., suspending subgraph preloading without interrupting core computations).
      3. Concurrent Execution
      Decouple traditional RAG pipelines into composable operations (entity recall → path validation → context enhancement → result refinement), with dynamic enable/disable support for each component.
      Implement automatic execution engine degradation, triggering fallback strategies upon sub-operation failures (e.g., switching to alternative methods if Gremlin queries timeout).
      Recommended Skills
      Proficiency in Python and familiarity with at least one open/closed-source LLM.
      Experience with one LLM RAG/Agent framework like LangGraph/RAGflow/LLamaindex/Dify.
      Knowledge of LLM optimization techniques and RAG construction (KG extraction/construction experience is a plus).
      Strong algorithmic engineering skills (problem abstraction, algorithm research, big data processing, model tuning).
      Familiarity with VectorDB/Graph/KG/HugeGraph read-write workflows and principles.
      Understanding of graph algorithms (e.g., community detection, centrality, PageRank) and open-source community experience preferred.
      Task List
      Develop a hierarchical triggering mechanism for the intent classifier to categorize L1~LN tasks within milliseconds (accuracy >90%).
      Semi-automatically generate Graph Schema/extraction prompts.
      Support dynamic routing and query decomposition.
      Design an execution trace tracker to log micro-operation resource consumption and generate optimization reports.
      Enhance retrieval with graph algorithms: Apply node importance evaluation, path search, etc., to optimize knowledge recall.
      Implement a dialogue memory management module for context-aware state tracking and information reuse.
      Size
      Difficulty: Hard
      Project size: ~350 hours (full-time/large)
      Potential Mentors
      Imba Jin: jin@apache.org (Apache HugeGraph PPMC)
      Simon: ming@apache.org (Apache HugeGraph PPMC)
       Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Imba Jin, mail: jin (at) apache.org
      Project Devs, mail:
      Mahout
      Apache Mahout Refactoring the Website
      Synopsis
      Apache Mahout has been evolving, with a recent shift in focus toward Quantum Computing (Qumat). However, the official website does not currently reflect this transition, making it difficult for developers and contributors to engage with Mahout’s new direction. Additionally, legacy components like MapReduce and Samsara are no longer actively developed but still occupy prominent space on the website.
      This project aims to refactor the Apache Mahout website to:
      Bring Quantum Computing (Qumat) front and center as the new core focus of the project.
      Deprecate outdated technologies (MapReduce and Samsara) while keeping the documentation intact with clear deprecation warnings.
      Improve website structure, navigation, and content organization to enhance accessibility and usability.
      By executing these changes, this project will ensure that new and existing users can quickly access relevant information while keeping historical documentation available in a structured manner.
      Benefits to the Community
      A well-organized and up-to-date website is essential for any open-source project. This proposal offers multiple benefits to the Apache Mahout community:
      1. Highlighting Quantum Computing (Qumat)
      Restructure the website so that Qumat-related content is the primary focus.
      Ensure that all documentation, blogs, and tutorials related to Qumat are easily discoverable from the homepage.
      2. Deprecating MapReduce and Samsara
      Add clear deprecation warnings to pages related to MapReduce and Samsara.
      Ensure these technologies remain accessible for historical reference but indicate that they are no longer actively maintained.
      3. Improved Navigation and Accessibility
      Design a more intuitive navigation system for easy exploration of different sections.
      Ensure smooth access to documentation, blogs, and learning resources.
      4. Updating Outdated Content
      Perform a full website audit to identify obsolete articles, guides, and references.
      Refresh and rewrite content where necessary, focusing on Mahout’s latest advancements.
      5. Engaging New Contributors
      A modern, user-friendly website will attract more developers, researchers, and open-source contributors to the project.
      Deliverables
      1. Website Restructuring
      Modify the homepage and navigation bar to prominently feature Quantum Computing (Qumat) as the main focus.
      Ensure Qumat-related documentation and blog posts are front and center.
      2. Deprecation of MapReduce and Samsara
      Add banner notifications on all MapReduce and Samsara pages marking them as deprecated.
      Ensure clear explanations so users understand these technologies are no longer in active development.
      3. Content Review & Updates
      Perform a recursive LS audit to identify outdated and redundant content.
      Update old blogs and articles to align with Mahout’s latest developments.
      4. Improved Website Navigation
      Implement a modern, responsive, and mobile-friendly navigation system.
      Optimize loading speed and ensure smooth user experience.
      5. Documentation Enhancement
      Ensure all essential documentation is accessible from the homepage.
      Improve the readability and structure of the docs.
      Technical Details
      The project will utilize:
      HTML, CSS, JavaScript for website front-end improvements.
      Modern front-end frameworks (if required) to enhance UX/UI.
      Shell scripting or Python to perform a recursive LS audit of the website structure.
      Version control via GitHub for tracking changes and ensuring collaboration.
      Expected Outcomes
      ✅ A refactored website that clearly emphasizes Quantum Computing (Qumat).
      ✅ A deprecated but accessible archive for MapReduce and Samsara.
      ✅ An updated and well-structured content repository for Mahout users and contributors.
      ✅ An intuitive, user-friendly website that engages both new and existing users.
      Timeline (12+ Weeks, Full-Time Commitment - 30 hrs/week)
      Community Bonding (Weeks 1-2)
      Engage with mentors and the Mahout community.
      Gather feedback on website restructuring priorities.
      Set up the development environment and review existing website architecture.
      Phase 1: Planning & Initial Development (Weeks 3-6)
      Redesign homepage and navigation bar to prioritize Qumat.
      Identify and start modifying MapReduce and Samsara pages with deprecation warnings.
      Conduct a recursive LS audit to locate outdated files and redundant content.
      Phase 2: Implementation & Testing (Weeks 7-10)
      Implement the new website navigation and homepage.
      Update and restructure documentation and blog content.
      Optimize the website’s file structure based on LS audit findings.
      Conduct extensive testing for responsiveness, accessibility, and performance.
      Phase 3: Content Finalization & Refinement (Weeks 11-12+)
      Finalize deprecation notices for MapReduce and Samsara.
      Ensure all Qumat-related content is easily accessible.
      Perform last-minute optimizations and bug fixes.
      Gather final feedback from the community and document all changes.
      🔹 Total Timeline: 350+ hrs
      Why This Should Be a GSoC Project
      This project directly aligns with Google Summer of Code’s mission to enhance open-source software. By modernizing the Apache Mahout website, we ensure that its new focus on Quantum Computing (Qumat) is clearly reflected, making it easier for developers and researchers to engage with Mahout’s latest advancements.
      Additionally, this project is well-scoped for GSoC, combining front-end development, content management, and structured auditing—all crucial aspects for a website overhaul.
      Mentorship & Feasibility
      The project has clear, well-defined goals and structured milestones.
      It will be mentored by an experienced Apache Mahout maintainer who is applying for the mentor role.
      The tasks are technically feasible within the GSoC timeframe.
      Conclusion
      Refactoring the Apache Mahout website is essential for reflecting its new focus on Quantum Computing (Qumat) while ensuring historical documentation remains accessible. By modernizing the site, we enhance usability, improve accessibility, and help new users quickly understand Mahout’s direction.
      This project will significantly enhance Mahout’s online presence and ensure the community stays well-informed and engaged.
      
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Trevor Grant, mail: rawkintrevo (at) apache.org
      Project Devs, mail: dev (at) mahout.apache.org
      Doris
      Apache DorisEvaluating Column Encoding and Optimization
      Synopsis
      Apache Doris is a real-time data warehouse that utilizes columnar storage. Currently, Doris applies default encoding methods based on column data types. This project aims to evaluate the efficiency of these default encodings (e.g., encoding/decoding time and compression ratios) using benchmark datasets like TPC-DS, HTTP logs, and TPC-H. The findings will guide optimizations to improve performance.
      Key Objectives
      A. Develop a tool to evaluate encoding efficiency. The tool will take a column of data and an encoding method as input and output metrics such as compression ratio and processing speed.
      B. Optimize dictionary encoding for string columns. Current implementations apply dictionary encoding by default without evaluating data suitability, leading to inefficiencies for non-dictionary-friendly data.
      C. Assess the effectiveness of BitShuffle encoding for enhancing downstream compression.
      Benefits to the Community
      
      Improve data compression efficiency in Apache Doris.
      Enhance query performance through optimized encoding/decoding.
      Technical Details
      Languages/Tools: C++ for encoding logic, GitHub for version control.
      Methodology:
      
      Benchmark existing encoding methods (e.g., dictionary, BitShuffle).
      
      Develop an evaluation framework to measure compression ratios and processing overhead.
      Implement optimizations for specific data types and use cases.
      Timeline (12+ Weeks, Full-Time Commitment - 30 hrs/week)
      Community Bonding (Weeks 1-2)
      
      Engage with mentors and the Doris community.
      
      Set up the development environment and study the codebase.
      
      Document current column encoding strategies for all data types.
      Phase 1: Planning & Initial Development (Weeks 3-6)
      
      Build a tool to evaluate encoding schemes across data types.
      
      Run benchmarks using TPC-DS, HTTP logs, and TPC-H datasets.
      Phase 2: Analysis & Optimization (Weeks 7-10)
      Optimize Dictionary Encoding: Automatically detect and skip non-dictionary-friendly data (e.g., high-cardinality strings).
      BitShuffle Evaluation: Quantify its impact on compression ratios and processing speed.
      
      Address additional optimization opportunities identified during analysis.
      Phase 3: Finalization & Refinement (Weeks 11-12+)
      
      Refine code and documentation based on community feedback.
      Submit PRs and ensure their merge into the Doris master branch.
       
      🔹 Total Effort: 350+ hours
      Expected Outcomes
      
      A tool to evaluate encoding efficiency for all Doris column types.
      
      Optimized dictionary encoding logic with automated suitability checks.
      
      Improved BitShuffle integration for enhanced compression.
      Additional optimizations identified during the project.
      This project will strengthen Apache Doris’s performance in real-time analytics scenarios while fostering collaboration within the open-source community.
      Contact Information *
      Mentor Name: [Yongqiang Yang](dataroaring@apache.org) , Apache Doris PMC member
      
      Mentor Name:[Chen Zhang](zhangchen@apache.org) Apache Doris Committer
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Calvin Kirs, mail: kirs (at) apache.org
      Project Devs, mail: dev (at) doris.apache.org
      Apache Doris Enhancing Group Commit Functionality
      Synopsis
         The current Group Commit mechanism in Apache Doris batches data until a predefined size or time threshold is met before committing. This project aims to improve flexibility and control over data visibility by introducing the following enhancements: #
      Trigger Immediate Flush After a Specified Number of Imports: Allow data to be committed automatically after accumulating a configurable number of import operations.
      SYNC TABLE Syntax Support: Enable users to explicitly trigger Group Commit for a table via SQL (e.g., SYNC TABLE table_name), ensuring the command returns only after the commit completes.
      System Table for Monitoring: Add an information_schema.group_commit system table to track Group Commit status, including columns such as BE host, table ID, and commit metadata (e.g., batch size, latency).
      Technical Details
      Languages: C++ (core) and Java (SQL syntax integration).
      Tools: GitHub for version control and collaborative development.
      Timeline (12+ Weeks, Full-Time Commitment - 30 hrs/week)
      Community Bonding (Weeks 1-2)
      
      Collaborate with mentors and the Apache Doris community.
      
      Set up the development environment and review the existing Group Commit implementation.
      
      Document the current Group Commit workflow and proposed optimizations.
      Phase 1: Implementation & Testing (Weeks 3-6)
      
      Develop support for flushing data after a configurable number of imports.
      
      Implement the SYNC TABLE syntax to trigger manual Group Commit.
      
      Design and integrate the information_schema.group_commit system table.
      
      Conduct performance benchmarking and rigorous testing.
      Phase 2: Refinement & Integration (Weeks 7+)
      
      Address feedback from code reviews and community testing.
      
      Finalize documentation and ensure backward compatibility.
      Submit pull requests (PRs) and work toward merging changes into the master branch.
      🔹 Total Effort: 210+ hours
      Expected Outcomes
      
      Enhanced flexibility in Group Commit with configurable flush triggers (size, time, or import count).
      
      A user-friendly SYNC TABLE SQL command for explicit commit control.
      
      A monitoring system table (information_schema.group_commit) for real-time visibility into commit operations.
      Robust performance validation and integration into Apache Doris’s core workflow.
      This project will empower users with finer control over data ingestion and visibility while maintaining Doris’s high-throughput capabilities.
       
      Contact Information *
      Mentor Name: [Yongqiang Yang](dataroaring@apache.org) , Apache Doris PMC member
      
      Mentor Name:[Yi Mei](zhangchen@apache.org) Apache Hbase Committer
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Calvin Kirs, mail: kirs (at) apache.org
      Project Devs, mail: dev (at) doris.apache.org
      HertzBeat
      [GSOC][HertzBeat] AI Agent Based on the MCP Protocol for Monitoring Info Interaction
      Website: https://hertzbeat.apache.org/
      Github: http://github.com/apache/hertzbeat/
      *Background*
      Apache HertzBeat is an open-source real-time monitoring tool that supports a wide range of monitoring targets, including web services, databases, middleware, and more. It features high performance, scalability, and security.
      With the advancement of artificial intelligence (AI) technologies, integrating AI with monitoring systems can significantly enhance their usability and interactivity. By developing an AI Agent based on the Model Context Protocol (MCP), we aim to enable conversational interaction for querying monitoring information, adding new monitoring tasks, and retrieving monitoring metrics. This will provide a more user-friendly and intelligent monitoring management experience.
      *Objectives*
      1. Research and Implementation: Develop an AI Agent based on Apache HertzBeat and the MCP protocol to enable conversational interaction with users.
      2. Functional Implementation:
      Query Monitoring And Alarm Information: Allow users to query the status of monitoring targets (e.g., normal, abnormal) and retrieve metrics data (e.g., CPU usage, memory usage, response time), alarm data through conversational commands.
      Add New Monitoring Tasks: Enable users to add new monitoring targets (e.g., web services, databases, middleware) and configure alert thresholds via conversational commands.
      Retrieve Monitoring Metrics Data: Allow users to obtain metrics data for specific monitoring targets and support data visualization via conversational commands.
      *Requirements Analysis*
      Apache HertzBeat: As the core backend for the monitoring system, it provides functions for data collection, storage, and management.
      MCP Protocol: An open protocol that enables seamless integration between LLM applications and external data sources and tools.
      Front-end Interaction: Develop a user-friendly interface that supports voice or text input and displays monitoring information and interaction results.
      *Recommended Skills*
      Java + TypeScript: Apache HertzBeat is developed based on this technology stack. Therefore, mastering these technologies is crucial for integrating with HertzBeat.
      SpringAi: It is recommended to use SpringAi to build the AI agent.
      LLM + MCP: You need to have an understanding of LLM (Large Language Models) and the MCP protocol. SpringAi seem supports the MCP protocol or consider use the mcp-sdk directly.
      *Size*
      Difficulty: Hard
      Project size: ~350 hours
      *Potential Mentors*
      Chao Gong: gongchao@apache.org 
       Shenghang Zhang: shenghang@apache.org
      Difficulty: Major
      Project size: ~350 hour (large)
      Potential mentors:
      Chao Gong, mail: gongchao (at) apache.org
      Project Devs, mail: dev (at) hertzbeat.apache.org
      No labels
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-apache-software-foundation/
    idea_list_url: https://s.apache.org/gsoc2025ideas
  

  - organization_id: 151
    organization_name: The FreeBSD Project
    no_of_ideas: 22
    ideas_content: |
      
      Kernel Projects
      mac_do(4) improvements
      [last updated: 2025-01-28]
      Mentor
      Olivier Certner <olce AT FreeBSD DOT org>
      Skills
      C (intermediate), Parallel programming (intermediate preferred), Security (intermediate preferred)
      Duration
      90 hours
      Difficulty
      Medium
      Expected Outcome
      Support per-jail configuration of application paths. Support for traditional and standard credentials-changing system calls. If possible, add authorization logging.
      Please see also the related project mdo(1) improvements. To interested students: Please consider combining both in a single medium-duration project (175 hours).
      mac_do(4) is a kernel module that can enable controlled process credentials transitions, such as changing the user IDs or group IDs to particular values. Processes that make such requests and are authorized by mac_do(4) do not need to be root, in particular not to have been spawned from an executable tagged with the setuid bit.
      For more information about mac_do(4), please consult the 2024 Q3's status report. Note that all the changes evoked in this report have been completed and are now in the tree.
      (Remark: The online manual page for mac_do(4) (from man.freebsd.org) has not been updated to the current in-tree version. The latter's source can be found at https://cgit.freebsd.org/src/tree/share/man/man4/mac_do.4.)
      Currently, mac_do(4) only authorizes processes spawned from the /usr/bin/mdo executable, and this is not configurable. By contrast, credentials transition rules are configurable and per-jail (via the sysctl(8) knob security.mac.do.rules and the mac.do.rules jail parameter). We would like to enable mac_do(4) to support a list of executable that are authorized to request credential transitions (with the aim to leverage mac_do(4) with user applications in the future), and to be able to specify a specific list for each jail (to accomodate thin or custom jail scenarios). The framework to do that basically already exists, as it has been developed to implement the above-mentioned handling of rules. This task thus consists in leveraging it, changing some of the internal structures that are associated to jails to hold the allowed paths list, modifying the code that needs to read the list in order to support parallel accesses, and coding accessors so that an administrator can control the list via sysctl(8) and jail parameters.
      mac_do(4) currently can only authorize credential transitions that are requested via the companion setcred(2) system call. The reason for the need of this specific system call is explained in more details in the 2024 Q3's status report but, in a nutshell, as mac_do(4) only authorizes configured credential transitions, it needs to see both the current process credentials state unmodified and the requested final one. However, each call to traditional and/or standard credentials-changing functions, such as setuid(2), seteuid(2), etc., can be considered as a (limited) full transition on its own, which mac_do(4) could decide upon. This functionality could allow to control transitions to root and, combined with that of the previous point, to install credentials-granting programs without the setuid bit set. An earlier version of mac_do(4) used to hook some of these calls, and lead to developing an infrastructure that helps to code fine-grained checks on top of the MAC framework interfaces, which are too limited for a straigtforward implementation, and in a safe manner with respect to parallel changes (e.g., to configured rules). (In mac_do(4)'s code, see in particular struct mac_do_data_header and struct mac_do_setcred_data.) Leveraging this infrastructure, the student is expected to code in mac_do(4) the appropriate MAC hooks for all traditional and/or standard credentials-changing functions.
      While mac_do(4) can log diagnostics on failure to set rules (because of syntax errors), it currently does not log whether it denies or accepts credentials transition requests. Having this functionality to diagnose rule problems and/or unauthorized accesses would be desirable. If time permits, we could consider adding audit logging in mac_do(4) proper, in addition to what is already present in the various credentials-changing system calls.
      
      ~~~~~~~~~~
      
      Port FreeBSD to QEMU MicroVM
      [last updated: 2025-01-24]
      Mentor
      Co-Mentor
      Tom Jones (willing to co-mentor) <thj AT FreeBSD DOT org>
      Skills
      C, intermediate
      Mid-term deliverable
      Drivers and kernel configuration to boot on QEMU MicroVM
      Duration
      175 or 350 hours
      Difficulty
      Medium
      Expected Outcome
      Stable port to QEMU MicroVM which is able to run some stress tests
      Example tasks:
      Write device drivers for QEMU MicroVM
      Create kernel configuration
      Create FreeBSD boot images for MicroVM
      There is an existing POC of this port, by thj@, but it is unstable and needs further investigation. A log of this effort is here: https://adventurist.me/posts/00320
      
      ~~~~~~~~~~
      Implement a new VLAN filtering software bridge
      [last updated: 2025-01-24]
      Mentor
      -
      Skills
      C (intermediate), networking (intermediate)
      Mid-term deliverable
      Dynamic interface creation and destruction, addition and removal of member interfaces, static forwarding + unknown destination flooding
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      The new pseudo driver can replace if_bridge(4) for jail and bhyve hosts
      The existing if_bridge(4) driver impedes FreeBSD suitability as a host for virtual machines and vnet enabled jails in design and implementation. Its configuration interface encourages misconfigurations by being too permissive, yet it lacks expected features.
      Other operating systems have encountered similar design problems with their respective bridge drivers. After two attempts, OpenBSD came up with a clean design we can learn from: veb(4) and vport(4).
      Our bridge member interfaces remain usable as IP capable interfaces which violates IP's (both v4 and v6) interface scope rules. Several bhyve and jail managers attempt to use this to add already configured network interfaces as member to bridges they manage with minimal changes to the host network configuration resulting in unreliable IPv4 and completely broken IPv6 processing. The new driver should restrict member interfaces to be only switch ports refusing to add member interfaces with configured IP addresses and prevent adding IP addresses to members.
      In its current state the if_bridge(4) driver does not support VLAN filtering between member interfaces. Neither adding the (untagged) network interfaces nor creating one bridge per VLAN nor and using vlan(4) interfaces as members provides the correct semantics needed. Using IPFW express VLAN filtering between member interfaces or a member interface and a bridge interface is both slow and error prone. The new bridge driver should perform per member port VLAN and MAC address filtering.
      Unlike if_bridge(4) the new driver should not be an IP capable network interface. Instead virtual member ports should be created to connect the host to the bridge, acting similar to one half on an if_epair(4).
      Such a bridge would also provide the groundwork to improve bhyve(8)'s para-virtualised networking with an if_tap(4) like member port supporting multiple bidirectional packet transfers with a single system call.
      
      ~~~~~~~~~~
      Testing and CI Integration for Rust Device Drivers
      [last updated: 2025-02-12]
      Mentor
      George Neville-Neil <gnn AT FreeBSD DOT org>
      Co-Mentor
      Skills
      C and Rust programming, intermediate; Experience with testing frameworks and CI systems is a plus
      Mid-term deliverables
      1. A test suite for an existing Rust-based FreeBSD kernel module. 2. Basic integration of tests into FreeBSD’s CI infrastructure
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      A framework for testing Rust-based FreeBSD kernel modules, ensuring correctness and stability. This includes writing tests for existing Rust driver code, validating behavior, and integrating the tests into FreeBSD’s continuous integration (CI) system.
      Example tasks:
      Identify and analyze existing Rust-based kernel modules and related work
      Develop unit tests for core components of a Rust driver
      Implement kernel-space testing techniques (e.g., fault injection, performance benchmarking)
      Integrate tests with FreeBSD’s CI system to ensure automated validation
      Explore and document best practices for writing and testing Rust drivers in FreeBSD
      Reference: https://wiki.freebsd.org/Rust#Rust_in_the_FreeBSD_Kernel
      
      
      ~~~~~~~~~~
      Implement native OpenBFS for FreeBSD
      [last updated: 2025-03-03]
      Mentor
      Pedro Giffuni <pfg AT FreeBSD DOT org>
      Skills
      C (intermediate), filesystems (intermediate)
      Mid-term deliverable
      Basic read-only support
      Duration
      350 hours
      Difficulty
      Hard
      Expected Outcome
      BeOS file system support
      The Be File System was developed by Dominic Giampaolo and Cyril Meurillon to provide BeOS with a modern 64-bit-capable journalling file system. For basic documentation on the filesystem, the Practical File System Design book is available. The project would be to bring BFS support for FreeBSD, perhaps considering some reuse of the open implementation made by Haiku-OS.
      
      ~~~~~~~~~~
      Unified kernel tracing interface
      [last updated: 2024-03-15]
      Mentor
      George Neville-Neil <gnn AT FreeBSD DOT org> (willing to co-mentor)
      Skills
      C (advanced), Kernel
      Mid-term deliverable
      Implementation available for amd64
      Duration
      350 hours
      Difficulty
      Hard
      Expected Outcome
      Existing consumers converted to use the new interface
      Description
      The FreeBSD kernel contains several subsystems which add hooks to core pieces of the kernel. For example, the context switch code in the scheduler contains this snippet:
              if (td != newtd) {
      #ifdef  HWPMC_HOOKS
                      if (PMC_PROC_IS_USING_PMCS(td->td_proc))
                              PMC_SWITCH_CONTEXT(td, PMC_FN_CSW_OUT);
      #endif
                      SDT_PROBE2(sched, , , off__cpu, newtd, newtd->td_proc);
      
      #ifdef KDTRACE_HOOKS
                      /*
                       * If DTrace has set the active vtime enum to anything
                       * other than INACTIVE (0), then it should have set the
                       * function to call.
                       */
                      if (dtrace_vtime_active)
                              (*dtrace_vtime_switch_func)(newtd);
      #endif
                      td->td_oncpu = NOCPU;
                      cpu_switch(td, newtd, mtx);
                      cpuid = td->td_oncpu = PCPU_GET(cpuid);
      
                      SDT_PROBE0(sched, , , on__cpu);
      #ifdef  HWPMC_HOOKS
                      if (PMC_PROC_IS_USING_PMCS(td->td_proc))
                              PMC_SWITCH_CONTEXT(td, PMC_FN_CSW_IN);
      #endif
      There are three hooks that may be called before switching into the new thread, and two hooks that may be called after the switch. They are used by DTrace and HWPMC to collect information about context switch events. These hooks are disabled most of the time, but each hook introduces overhead even when disabled since we must check whether it is enabled each time the code is executed.
      The goal of the project is to identify useful kernel tracepoints, and design and implement a unified interface that can be used by different consumers to collect information about the event corresponding to a particular tracepoint. This would make it easier for new subsystems to collect information from existing tracepoints, rather than modifying the core kernel to add more hooks. An additional aim would be to ensure that such tracepoints have minimal overhead, probably by using hot-patching to enable and disable a particular tracepoint. FreeBSD-CURRENT now uses clang 10.0, which implements the "asm goto" construct that could be useful here.
      
      ~~~~~~~~~~
      Add IPv6 scoped-address support in in-kernel ONC RPC and NFS
      [last updated: 2024-01-31]
      Mentor
      Hiroki Sato <hrs AT FreeBSD DOT org>
      Skills
      C (intermediate), Kernel (intermediate)
      Duration
      175 hours
      Difficulty
      Medium
      Expected Outcome
      NFS works with IPv6-scoped addresses
      FreeBSD’s NFS and other implementations relying on ONC RPC do not work with non-global IPv6-scoped addresses (e.g., link-local) because the RPC universal address format specified in RFC 5665 is used and it does not include the scope ID. This project aims to eliminate this limitation. The required steps are as follows:
      Implement a function handling text representation of an IPv6 address with the scope ID and replace inet_ntop() with it.
      Add support for IPv6-scoped address format to conversions between a taddr and a uaddr in the kernel.
      
      ~~~~~~~~~~
      Implement MPLS support for FreeBSD
      [last updated: 2023-01-27]
      Mentor
      Alexander Chernikov <melifaro AT FreeBSD DOT org>
      Skills
      C (intermediate), networking (intermediate)
      Mid-term deliverable
      MPLS forwarding works on static labels
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      MPLS forwarding, encap/decap works, MPLS labels can be programmed via Netlink
      Multiprotocol Label Switching (MPLS) is an overlay network technology based on labels instead of IP addresses. The project would be to bring basic MPLS support for FreeBSD. Roughly, the implementation can be split into the following chunks:
      create MPLS routing tables, analogous to AF_INET[6] routing tables
      add the logic to handle MPLS packets (mpls_input(), mpls_forward(), mpls_output()) at various stages
      add the code to perform MPLS encap for IPv4/IPv6 routes, extending nexthops functionality
      add Netlink support for working with IP-MPLS, MPLS-MPLS and MPLS-IP routes
      Add userland support for working with MPLS routes to route(8) and netstat(8)
      [stretch] add fast fib lookup module to enable high-performance concurrent label lookups
      The OpenBSD's MPLS stack or the NetBSD's MPLS stack overviews of other *BSD implementations can provide more datapoints.
      
      ~~~~~~~~~~
      
      Improve netgraph concurrency
      [last updated: 2023-01-27]
      Mentor
      Alexander Chernikov <melifaro AT FreeBSD DOT org>
      Skills
      C (intermediate), networking (intermediate)
      Mid-term deliverable
      Traffic is able to pass in a lockless fashion in 2-node netgraph topology
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      Traffic is able to pass in a lockless fashion between ng_<ppp|car|tee|iface>, compatibility retained with non-converted nodes
      Netgraph is a traffic-processing subsystem based on the dynamically configured graph of nodes and directed edges. Each node apply a single specific manipulation to the packet. The core idea is similar to VPP. Currently netgraph uses topology lock and node/hook atomic refcounts to ensure safe passing of the packets between the nodes. The goal of the project is to make passing data between the nodes lockless. The necessary primitives like epoch-based object reclamation and lockless datastructures are available in the base system. The rough implementation sketch may look like the following:
      Enable delayed reclamation of netgraph hooks and nodes under existing NET_EPOCH
      Make core API like ng_address_hook() leverage existing NET_EPOCH and avoid taking topology locks / refcounts
      Test the implementation with a number of stateless nodes like ng_patch or ng_tee and ng_ipfw
      Evaluate and convert nodes on per-node basis on their reliance on the topology lock
      
      ~~~~~~~~~~
      Userland projects
      mdo(1) improvements
      [last updated: 2025-01-28]
      Mentor
      Olivier Certner <olce AT FreeBSD DOT org>
      Skills
      C (intermediate), Security (intermediate preferred)
      Duration
      90 hours
      Difficulty
      Medium
      Expected Outcome
      New arguments to specify target groups. New mode to output mac_do(4) rules.
      Please see also the related project mac_do(4) improvements. To interested students: Please consider combining both in a single medium-duration project (175 hours). This related project's proposal provides an overview of what mac_do(4) is, and is recommended reading anyway.
      mdo(1) is the companion userland program to mac_do(4). It currently can run another program as a different user, either keeping the calling process' groups or replacing them with the new user's ones.
      Since the recent revamp of mac_do(4), an administrator can authorize fine-grained transitions of both user and group IDs. However, mdo(1) has not yet been updated to provide the required functionality. In particular, mdo(1) should be able to:
      Specify any list of target groups (primary or supplementary), possibly based on user names (an implicit list would be constructed from the related content of both /etc/passwd and /etc/group) but also allowing some tweaks (such as excluding a particular group in the final credentials).
      Allow changes of groups only in an easier way than the current interface (requires specifying the current user if it isn't root).
      Grow a mode producing the target part of mac_do(4) rules corresponding to the requested transition.
      If time permits, ponder on an architecture and implementation for requesting a password before calling setcred(2) in certain cases.
      
      ~~~~~~~~~~
      Port virtual_oss to base
      [last updated: 2025-01-27]
      Mentor
      Christos Margiolis <christos AT FreeBSD DOT org>
      Co-mentor
      Robert Clausecker <fuz AT FreeBSD DOT org>
      Skills
      C (advanced), FreeBSD programming environment (intermediate), DSP/maths (moderate), kernel (basic)
      Duration
      175 hours
      Difficulty
      Medium
      Expected Outcome
      virtual_oss part of the base system
      virtual_oss is an audio server written by Hans Petter Selasky for FreeBSD's sound system, OSS (Open Sound System), which provides support for (de-)multiplexing audio devices, switching audio devices on the fly, as well as bluetooth sound, among other features. FreeBSD currently lacks a built-in audio server, since virtual_oss is only provided as a port.
      The goal of the project is to successfully port virtual_oss to the base system and integrate it in programs and scripts that might benefit from using it.
      Even though this project is largely about integration, virtual_oss uses third-party libraries, namely libsamplerate and fftw3, which will most likely need to be replaced by rolling our own code in order to make virtual_oss completely standalone.
      
      ~~~~~~~~~~
      sockstat UI improvements
      [last updated: 2025-01-24]
      Mentor
      Alan Somers <asomers AT FreeBSD DOT org>
      Skills
      C (beginner)
      Duration
      90 hours
      Difficulty
      Easy
      Expected Outcome
      Rewrite sockstat's CLI with libxo and automatically sized tables
      Sockstat is a utility that prints details about any connected socket on the system. It's useful, but the current user interface is lacking. It could greatly benefit from libxo output, and it's also a good candidate for a C++ conversion. The entire -w option is an avoidable hack, if output were printed more intelligently. Most ambitiously of all, this program is fairly begging for some kind of "xo_print_table" function, that would automatically size the columns.
      
      ~~~~~~~~~~
      Network Configuration Libraries
      [last updated: 2024-01-29]
      Mentor
      Allan Jude <allanjude AT FreeBSD DOT org>
      Co-Mentor
      Christos Margiolis <christos AT FreeBSD DOT org>
      Skills
      C (intermediate), knowledge of networking and NAT
      Mid-term deliverable
      Library to configure IPFW NAT to allow a bhyve VM guest to reach the Internet
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      A library to manage NAT configuration for VMs and Jails
      Deliverables: A simple tool to configure the network on a laptop to allow a bhyve VM to access the internet.
      Use Cases:
      A bhyve VM running on a laptop NAT'd out the laptop's wifi connection
      A bhyve VM bridged to the hosts Ethernet network
      Stretch goal: Extend the tool to support configuring network access for standard and VIMAGE jails
      Build a libipfw to enable programmatic configuration of the firewall, implement basic functionality to add rules and configure NAT instances.
      Optional: relocate most functionality available in the command line interface into the library and replace the replace the command line interface with a thin wrapper around the new library.
      Build a libbsdnat that can be used by bhyve VM managers and Jail management tools to configure NAT on the host to allow the guest access to the internet via the host's network. This library will then be extended to handle creating 'port forwarding' rules to expose services in the guest to the public network via the host. Network mappings will be ephemeral and will need to be recreated by the management tools when the VM or jail is restarted.
      Possible design for final tool:
      libifconfig - used to create and manage bridge interface for bhyve, epairs for jails
      libbsdnat - Configure NAT for outbound, and port forward rules for inbound.
      libipfw - Used to insert rules routing traffic via above NAT instances.
      netlink - Used for network stack configuration
      
      ~~~~~~~~~~
      IPv6 support and cleanup of address family dependency in userland utilities
      [last updated: 2024-02-11]
      Mentor
      Hiroki Sato <hrs AT FreeBSD DOT org>
      Skills
      C (intermediate), networking (intermediate)
      Duration
      175 hours
      Expected Outcome
      More userland utilities with better IPv6 support
      Many of our tools are not IPv6 "clean", such as these tools:
      rwhod(8)
      Various yp(8) daemons
      rpc.rquotad(8)
      This project could also include a broader survey of other network services in /usr/bin and /usr/sbin to make sure they're all IPv6 clean. Other possible work could involve
      remove/rework the about 200 gethostby*() calls all in the base system and contrib to use getaddrinfo().
      make more code to conditionally compile in INET or INET6 support.
      
      ~~~~~~~~~~
      Speed up the FreeBSD boot process
      [last updated: 2024-01-12]
      Mentor
      Colin Percival <cperciva AT FreeBSD DOT org>
      Skills
      C (intermediate), sh (intermediate), kernel (beginner)
      Mid-term deliverable
      Targets for boot speedup identified and some addressed
      Duration
      175 hours
      Difficulty
      Medium
      Expected Outcome
      FreeBSD will boot faster
      Using the TSLOG framework and one or more systems running FreeBSD, profile the boot process and identify targets for improving boot performance. This is likely to involve delving into multiple different parts of FreeBSD, ranging from the kernel to daemons launched from rc.d scripts; there are likely a large number of places where improvements can be made, and work will be guided by the amount of time which could potentially be saved and the likely complexity of making improvements. In many cases, a student will need to collaborate with other FreeBSD developers familiar with different parts of the system.
      
      ~~~~~~~~~~
      syzkaller improvements
      [last updated: 2020-03-04]
      Mentors
      Skills
      golang (intermediate), kernel (intermediate)
      Duration
      350 hours
      Difficulty
      Hard
      Expected Outcome
      Complete FreeBSD syzkaller extenstions described below
      syzkaller is a suite of tools that performs coverage-guided system call fuzzing. Originally targeting Linux, it can now fuzz many different operating system kernels and has been extremely effective at finding bugs, many with security implications. It creates, monitors and fuzzes a set of virtual machines running the target kernel. More information can be found in its documentation, and in these slides. Google kindly runs a public syzkaller instance targeting FreeBSD.
      For a while it has been possible to run syzkaller on FreeBSD; that is, fuzz FreeBSD on FreeBSD. syzkaller makes use of ZFS and bhyve (or QEMU) to do so. This makes development and testing of FreeBSD-specific syzkaller features much easier.
      Though syzkaller has found quite a few bugs in FreeBSD, it does not cover as much as it does on Linux, so it is virtually guaranteed that there are plenty of bugs waiting to be found. This project consists of several subtasks that would improve FreeBSD's coverage:
      Extend syzkaller's FreeBSD system call descriptions. For each system call, syzkaller requires a set of annotations that describe the system call's arguments. It is missing many of FreeBSD's system calls. syzkaller similarly needs to be taught about device-specific ioctls.
      Support fuzzing of FreeBSD's Linux system call compatibility layer. Since syzkaller can of course fuzz Linux natively, it should be straightforward to run a Linux fuzzer on FreeBSD.
      Support external injection of USB traffic.
      Support running the fuzzer in a jail, optionally with various resource limits in place.
      Test syzkaller with a ZFS root filesystem instead of UFS. Work with the syzkaller developers to get a FreeBSD+ZFS target running in syzbot.
      Port support for automated patch testing and crash bisection to FreeBSD. Some details are listed here.
      Work with the project mentor to triage and possibly fix any kernel bugs found in the process.
      Note: contributing to syzkaller requires signing the Google CLA. Please make sure that this is acceptable before attempting this project. Note also that working with syzkaller is probably easiest on a dedicated hardware system with a reasonably large amount of disk space (several hundred GB should be sufficient), ideally running FreeBSD on ZFS. syzkaller can instantiate VMs on Google Compute Engine and fuzz them, so this may be an option as well. Please contact the project mentors for details.
      
      ~~~~~~~~~~
      Capsicumization of the base system
      [last updated: 2020-03-02]
      Mentor
      Mariusz Zaborski <oshogbo AT FreeBSD DOT org>
      Co-Mentor
      Mark Johnston <markj AT FreeBSD DOT org>
      Skills
      C (intermediate), familiarity with the UNIX programming environment
      Mid-term deliverable
      Sandbox a few of the target applications
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      Sandbox the complete list of target applications
      Capsicum is a sandboxing technology used in FreeBSD. It is complemented by Casper, a framework for defining application-specific capabilities. A large number of utilities in the FreeBSD base system have been converted to run under Capsicum and Casper, but many programs have yet to be converted. The project would consist of identifying several high-profile daemons and utilities in the base system or ports, and modifying them to run in capability mode. One good candidate is syslogd, the system logging daemon.
      As part of this work it may be necessary or useful to add additional Casper services to the base system. For example, we do not yet have a Casper service which allows an application to make outbound network connections.
      Note: Converting applications to run under Capsicum/Casper can take a lot of effort, especially when they are large or when they are not designed with privilege separation in mind. Some applications, like a shell, can't really be run in capability mode at all. Before attempting to sandbox a given application, take care to study the ways in which it interacts with the system. For example, does the application need to open any files? If so, are the file names statically defined or are they derived from user input? This will provide insight into the difficulties that will arise when sandboxing the application.
      
      ~~~~~~~~~~
      Add QCOW2 compressed image support to mkimg(1)
      [last updated: 2025-02-04]
      mkimg(1) is a FreeBSD tool used for creating disk images in various formats, such as raw images, QCOW/QCOW2, VHD/VHDX, and VMDK. However, it currently lacks support for creating compressed QCOW2 (QEMU Copy-On-Write v2) images. QCOW2 is widely used in virtualization due to features like snapshot support, compression, and efficient disk space utilization through sparse file support.
      Integrating QCOW2 compression into mkimg(1) would extend its utility, allowing FreeBSD users to generate smaller QCOW2 images directly without relying on external tools. This enhancement will benefit those deploying FreeBSD in virtualized environments.
      There are (currently) two QCOW2 versions: v2 and v3. v2 supports only deflate (zlib) compression; v3 adds support for zstd. mkimg currently implements v2 support, without compression. The minimum scope for this project is implementing zlib compression, but the project may be made larger by support for QCOW2 v3 and zstd compression.
      This project will also include improvements to the mkimg test suite, in order to properly test the new functionality.
      References: QCOW2 spec https://github.com/qemu/qemu/blob/master/docs/interop/qcow2.txt
      Mentor
      Ed Maste <emaste AT FreeBSD DOT org>
      Skills
      C (Intermediate)
      Duration
      175 hour
      Difficulty
      Medium
      Expected Outcome
      mkimg can produce a compressed QCOW2 image, which can be successfully used with QEMU
      
      ~~~~~~~~~~
      Tools
      Improve LLDB on FreeBSD
      [last updated: 2024-03-12]
      Co-Mentors
      Ed Maste <emaste AT FreeBSD DOT org> , Moin <bofh AT FreeBSD DOT org>
      Skills
      shell scripting (intermediate), Lua (intermediate), debugger use (basic)
      Mid-term deliverable
      crashinfo invokes LLDB and extracts backtrace, subset of Lua bindings enabled
      Duration
      350 hours
      Difficulty
      Medium
      Expected Outcome
      LLDB Lua bindings at feature parity with Python bindings, crashinfo script successfully uses in-tree debugger, lldb
      The LLVM debugger, lldb, is part of the FreeBSD base system. This project aims to extend lldb on FreeBSD in two ways.
      1. Improve lldb Lua bindings
      lldb supports scripting in C++, Python, and Lua. The Lua bindings are a more recent addition, and some features that would make them much more usable on FreeBSD are missing. The first goal of this project is to improve Lua binding support, add documentation, and bring the Lua bindings to parity with the Python bindings.
      Example tasks:
      Enable Lua bindings to create new LLDB commands
      Generate Lua documentation similar to the Python documentation
      Write a tutorial for scripting LLDB with Lua
      Add convenience methods to support common FreeBSD kernel debugging tasks from Lua, such as those described in https://freebsdfoundation.org/wp-content/uploads/2019/01/Debugging-the-FreeBSD-Kernel.pdf
      2. Integration lldb into crashinfo
      FreeBSD provides a script, /usr/sbin/crashinfo, which runs after a system (kernel) crash and extracts information from the core dump to store in a text file. See the crashinfo man page for more information. crashinfo currently makes use of the GNU debugger, gdb, which must be installed from the package collection or ports tree. The second goal of this project will be to add lldb support to crashinfo, providing the same information that crashinfo's gdb integration provides. (gdb support should be retained in the script and used when gdb is available).
      
      ~~~~~~~~~~
      GEOM management UI
      [last updated: 2025-01-30]
      Mentor
      Robert Clausecker <fuz AT FreeBSD DOT org>
      Co-Mentor
      Joe Mingrone <jrm AT FreeBSD DOT org>
      Skills
      UI development, disk management
      Mid-term deliverable
      partially functional tool
      Duration
      175 or 350 hours
      Difficulty
      Medium
      Expected Outcome
      a working GUI/TUI manager for GEOMs, especially partitions
      On Linux, many users use the graphical gparted utility for disk and partition management. Such a utility is currently missing on FreeBSD; users have to make use of somewhat unintuitive command line utilities to set up disks. It would be great if that hole could be filled.
      The goal of this project is to have a partition management utility similar to gparted, but for FreeBSD. It could also mean porting gparted to FreeBSD. If this project is taken as a long (350 hours) project, it might be interesting to extend the utility to more GEOM classes, such as gstripe(8), geli(8), glabel(8), and gmirror(8). The management tool will be developed in a separate repository. It can be written in any programming language supported on FreeBSD, though ideally one that works on all architectures we support. The interaction with GELI can be done through libgeom(3) or by wrapping the various GEOM command line utilities. The project could be done either as a curses-based TUI or a GUI for X11/Wayland.
      Once a viable prototype (mid-term deliverable) is complete, the project is added to the FreeBSD ports collection. If a TUI and free of third-party dependencies, it could later be added to the base system.
      
      ~~~~~~~~~~
      WiFi Management UI
      [last updated: 2025-01-31]
      Mentor
      Getz Mikalsen <getz AT FreeBSD DOT org>
      Co-Mentor
      Aymeric Wibo <obiwac AT FreeBSD DOT org>
      Skills
      C (intermediate), familiarity with the UNIX programming environment
      Mid-term deliverable
      List networks and interact with them
      Duration
      175 hours
      Difficulty
      Medium
      Expected Outcome
      A new UI for easy connection to Wi-Fi networks
      Many new users install FreeBSD on their laptops but miss utilities common on other systems like Linux, our current tools are a bit obtuse. This project aims to bring some of those niceties to FreeBSD. This project proposes a tool that can act as nice single entry point to list available networks and connect and save configurations.
      The tool could be implemented as a REPL like iwctl on linux or as a TUI although the latter is preferred. The project can be completed in any programming language supported on FreeBSD (C, Rust, etc.) although some knowledge of C is expected. Once a viable prototype (mid-term deliverable) is complete, the project can be added to the FreeBSD ports collection. If free of third-party dependencies, it could later be added to the base system.
      PS. We are also very open to other project ideas revolving around things that makes life easier when using a laptop.
      
      ~~~~~~~~~~
      Power profiling tool
      [last updated: 2025-02-04]
      Mentor
      Aymeric Wibo <obiwac AT FreeBSD DOT org>
      Co-mentor
      Tom Jones <thj AT FreeBSD DOT org>
      Skills
      C (intermediate), kernel (intermediate)
      Mid-term deliverable
      Be able to roughly determine which processes are waking the CPU from idle the most.
      Duration
      175 or 350 hours
      Expected Outcome
      Expected outcome for final term is to have a tool equivalent to powertop on Linux.
      Currently, the only power statistics you can get on FreeBSD is the whole system's power consumption (reported by ACPI). If a certain process is using up a lot of power or something else is causing high power consumption, it can be difficult to debug this. This project aims to either port powertop from Linux to FreeBSD or write a wholly new tool.
      If we go the route of porting powertop as-is, this could be made into a port, but ideally we'd have a tool in the base system for doing this. It might also be interesting for this tool to run a suspend test and report common issues similar to what the amd_s2idle.py script does for AMD Linux systems.
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-freebsd-project/
    idea_list_url: https://wiki.freebsd.org/SummerOfCodeIdeas

  - organization_id: 152
    organization_name: The Honeynet Project
    no_of_ideas: 8
    ideas_content: |
     
      #1 - BuffaLogs: new alert notifications
      Mentor: Federico Foschini
      Project type: Improving an existing tool
      URL: https://github.com/certego/BuffaLogs
      Expected Project hours: 90 - 175 based on received proposal
      
      BuffaLogs currently does not support alert notification. We are expanding the system to allow alert be sent to various destinations.
      Project Objectives:
      Developing alert notifications for one or more of the following sources, depending on the project timeline:
      Email
      Http request
      Slack
      Additional sources to be considered based on project scope
      Technical Requirements:
      Develop modular and maintainable Python code for each implemented connector
      Create comprehensive unit tests and integration tests
      Provide detailed documentation

      ~~~~~~~~~~
      #2 - BuffaLogs: new ingestion sources
      Mentor: Federico Foschini
      Project type: Improving an existing tool
      URL: https://github.com/certego/BuffaLogs
      Expected Project hours: 90 - 175 based on received proposal
      
      BuffaLogs currently supports data ingestion exclusively from Elasticsearch. To enhance its functionality and versatility, we are expanding the system to accommodate multiple data sources.
      Project Objectives:
      Developing connectors for one or more of the following sources, depending on the project timeline:
      Relational Databases (MySQL, Postgres, etc.)
      File-based Data Sources (CSV, JSON)
      AWS CloudTrail Logs
      Additional sources to be considered based on project scope
      Technical Requirements:
      Develop modular and maintainable Python code for each implemented connector
      Create comprehensive unit tests and integration tests
      Provide detailed documentation
      
      ~~~~~~~~~~
      #3 - IntelOwl improvements: analyzers and integrations
      Mentor: Matteo Lodi, Daniele Rosetti, Federico Gibertoni
      Project type: Improving an existing tool
      URL: https://github.com/intelowlproject/IntelOwl
      Expected Project hours: 175
      
      This projects aims to improve the tests implemented in IntelOwl, in particular the ones regarding the Analyzers.
      Right now, the actual implementation is kinda limited due to the inheritance of a framework built years ago, based on monkeypatching the tests.
      The goal is to refactor this framework in a way that is easier to use and, at the same time, that it allows better tests implementation.
      A thorough explanation of the problem and deliverables is described here.
      This is a time-consuming project that requires focus and attention. We expect the contributor to refactor most of the analyzers’ tests and write additional checks.
      The ideal candidate for this project is someone who understand how IntelOwl’s framework works and knows testing frameworks like unittest very well.
      
      ~~~~~~~~~~
      #4 - Extending the Artemis scanner
      Mentor: Krzysztof Zając
      Project type: Improving an existing tool
      URL: https://github.com/CERT-Polska/Artemis
      Expected Project hours: 175 or 350 hours
      
      Artemis is a modular vulnerability scanner that checks multiple aspects of website security and builds easy-to-read messages to send to organizations to get the vulnerabilities fixed. Multiple national-level CSIRTs use it to improve the security of their constituencies - for example, since 2023, CERT PL has used Artemis to find and report more than half a million vulnerabilities.
      The goal is to improve the number and quality of detected vulnerabilities. There may be multiple ways of achieving this goal:
      Extend Artemis with modules detecting new types of vulnerabilities (for example, by integrating existing open-source tools),
      Improve Artemis in other aspects such as performance or ease of use.
      The primary required skills are Python programming and familiarity with Linux and Docker. Familiarity with web security topics is also desired.
      
      ~~~~~~~~~~
      #5 - IntelOwl improvements: analyzers and integrations
      Mentor: Matteo Lodi, Daniele Rosetti, Federico Gibertoni
      Project type: Improving an existing tool
      URL: https://github.com/intelowlproject/IntelOwl
      Expected Project hours: 90 - 175 based on received proposal
      
      Right now we have a lot of Analyzers implemented in IntelOwl.
      But they are not enough! They are one of the core parts of the application so we want to add even more of them!!!! :)
      This project aims to increment the number of available Analyzers and adjusting the old ones that are not working anymore as intended. We have about 10 different Analyzers that has been requested by the community members in Github and are still not implemented. Plus we have other analyzers that requires intervention, like Yara, YETI, DNS Detectors and so on.
      Plus, we would like this project to carry additional non-Analyzer related work, like the addition of new Ingestors or Playbooks for instance, which are pretty similar components.
      Another optional and very different task could be to add support for Podman for the overall project as an alternative of Docker. This would require working more with the documentation and the core parts of the projects.
      The ideal candidate for this project is someone who understand how IntelOwl’s framework works and already tried to implement some Analyzers.
      
      ~~~~~~~~~~
      #6 - Improving the SweetCam IP camera honeypot
      Mentor: Emmanouil Vasilomanolakis, Dario Maddaloni, Artur Cordeiro Urbano
      Project type: Improving an existing tool
      URL: https://github.com/Agachily/sweetcam
      Expected Project hours: 175 or 350 hours
      
      SweetCam is an open-source honeypot designed to emulate IP camera behaviors with minimal setup while offering robust modularity for extending functionality. It is built to support the emulation of key protocols commonly used by IP cameras, including SSH, RTSP, and HTTP. A distinguishing feature of SweetCam is its ability to create a realistic web interface resembling an IP camera’s dashboard. This includes a login page and a simulated camera interface that can be customized using user-defined 360-degree video streams and images, making it highly adaptable to various use cases. The modular architecture of SweetCam ensures flexibility, allowing users to easily integrate support for new camera models and configurations. By providing a realistic medium-interaction environment, SweetCam effectively lures and studies attackers targeting IP cameras, offering valuable insights for cybersecurity research and network defense strategies.
      GSoC 2025
      Outcomes
      template-based device emulation
      new protocol support
      enhance Docker Usability (Automation & Base setup)
      Various improvements: Error based handling on HTTP page, Language Button at HTTP page, forgot password, implementation of sound, day/night configurations
      Skills Preferred
      Basic Linux/Command Line skills
      Docker
      Shell, JavaScript

      ~~~~~~~~~~
      #7 - Improving the DICOMHawk medical honeypot
      Mentor: Emmanouil Vasilomanolakis, Karina Elzer, Georgios Theodoridis
      Project type: Improving an existing tool
      URL: https://github.com/gtheodoridis/DICOMHawk
      Expected Project hours: 175 or 350 hours
      
      DICOMHawk is a powerful and efficient honeypot for DICOM servers, designed to attract and log unauthorized access attempts and interactions. Built using Flask and pynetdicom, DICOMHawk offers a streamlined web interface for monitoring and managing DICOM interactions in real-time.
      Features
      DICOM Server Simulation: Supports C-ECHO, C-FIND, and C-STORE operations to simulate a realistic DICOM server environment.
      Logging: Detailed logging of DICOM associations, DIMSE messages, and event-specific data to track and analyze potential attacks.
      Web Interface: A user-friendly web interface to view server status, active associations, and logs.
      Custom Handlers: Easily extendable to support additional DICOM services and custom logging or handling requirements.
      GSoC 2025
      Outcomes
      Examine a potential integration with TPot
      Improve Docker usage (Security & Automation)
      Improve logging capabilities
      Integrate CanaryToken Webhook
      Potentially add additional protocol
      Documentation of the Implementations
      Testing
      Skills Preferred
      Basic Linux/Command Line skills
      Docker
      Python

      ~~~~~~~~~~
      #8 - Implementing Protocol Parsers for Glutton Using Spicy
      Mentor: Muhammad Bilal Arif
      Project type: Improving an existing tool
      URL: https://github.com/mushorg/glutton
      Expected Project hours: 175 or 350 hours
      
      Glutton is a powerful Generic Low Interaction Honeypot designed to emulate various network services and capture malicious activity for security analysis. Its strength lies in its generic nature, supporting a wide range of network protocols.
      The goal of this project is to:
      Develop a Go wrapper to integrate Spicy with Glutton.
      Implement protocol parsers for HTTP and DNS as initial examples.
      Provide documentation to explain the implementation.
      The primary required skill is proficiency in Go programming and familiarity with Linux networking.
      An understanding of network monitoring tools like Spicy or similar is a nice-to-have skill.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-honeynet-project/
    idea_list_url: https://www.honeynet.org/gsoc/gsoc-2025/google-summer-of-code-2025-project-ideas/

  - organization_id: 153
    organization_name: The JPF team
    no_of_ideas: 6
    ideas_content: |
  
      Support Java 11/17 for JPF extensions
      Description: jpf-core is essentially a JVM that currently fully supports only Java 8 and Java 11 (with limitations on bootstrap methods). Bootstrap methods are currently interpreted, which works for common usage but may not work for advanced cases. The goal of this project is to generate the call site code on the fly so bootstrap methods work as on the host JVM.
      Difficulty: Hard
      Scope: 350 hours
      Required skills: Knowledge of Java bytecode
      Preferred skills: Knowledge of private Java APIs Possible Mentors: Cyrille
      
      ~~~~~~~~~~
      Support for Java 17 for jpf-core
      Related to the project above, there are also some new features in Java 17 that are not yet supported by JPF. We have work in progress on branch java-17. Currently unsupported Java features include language features that are not supported at run time (e.g., records) and Java language features that are not fully analyzed (e.g., sealed classes). In this project, you would identify such unsupported features and extend JPF (jpf-core) to support them.
      Difficulty: Medium
      Scope: 175 hours
      Required skills: Knowledge of Java internals
      Possible Mentors: Cyrille

      ~~~~~~~~~~
      Robustify String solving for SPF
      Description: The goal of this project is to test SPF integration with Z3 string constraint solving; adding support cvc5 is a plus. This project will extend SPF branch sv-comp.
      Difficulty: Hard
      Scope: 350 hours
      Required skills: Knowledge of Symbolic Pathfinder
      Preferred skills: Knowledge of String constraint solving.
      Possible Mentors: Corina, Elena, Soha

      ~~~~~~~~~~
      Support runtime exception in SPF
      Description: The main goal of this project is to support throwing a runtime exception for some of the summarized functions such as String.substring. Also, this project should build on SPF Java 11 Gradle support, which implies fixing existing issues. This project will extend SPF branch sv-comp.
      Difficulty: Meduim
      Scope: 175 hours
      Required skills: Knowledge of Symbolic Pathfinder
      Possible Mentors: Soha

      ~~~~~~~~~~
      Support portfolio of solvers in SPF
      Description: The main goal of this project is to enable the simultaneous invocation of multiple solvers, terminating the wait as soon as any solver returns a satisfiable result. This approach is expected to enhance SPF's ability to handle a broader range of constraints. This project will extend SPF branch sv-comp.
      Difficulty: Hard
      Scope: 350 hours
      Required skills: Knowledge of Symbolic Pathfinder
      Preferred skills: Expeirence with various solvers
      Possible Mentors: Soha

      ~~~~~~~~~~
      Use LLM to generate sound reduction rules in SPF
      Description: Solver constraints can become very complex, and very large. In this project, we will use LLM in SPF to identify sound reduction rules that can be applied to the constraints before sending them to the solver, ideally improving its performance. See this paper for reference. This project will extend SPF branch sv-comp.
      Difficulty: Hard
      Scope: 350 hours
      Required skills: Knowledge of Symbolic Pathfinder
      Preferred skills: LLM
      Possible Mentors: Soha
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-jpf-team/
    idea_list_url: https://github.com/javapathfinder/jpf-core/wiki/GSoC-2025-Project-Ideas

  - organization_id: 154
    organization_name: The Julia Language
    no_of_ideas: 76
    ideas_content: |

      
      
      ClimaExplorer: An Interactive Visualizer of Climate Model Outputs
      Visualizing simulation output is crucial for both scientific understanding and outreach. This project involves developing ClimaExplorer, an interactive visualizer for the output of the CliMA Earth system model. ClimaExplorer will leverage the Makie ecosystem and web technologies, providing a user-friendly interface for exploring complex climate data. This will enable researchers to more easily analyze and interpret simulation results, accelerating scientific discovery. Furthermore, the web-based component will facilitate broader dissemination of results to a wider audience.

      Desired Skills: Familiarity with front-end web development (HTML, JavaScript, and CSS), Julia, and Makie.

      Difficulty: Medium

      Duration 175 hours

      Expected Results: ClimaExplorer, a new module for interactive visualization of simulation output (with tests and documentation).

      Mentor: Gabriele Bozzola

      Contact: Feel free to ask questions via email or Julia Slack (DM to Gabriele Bozzola).

      Interested in other aspects of climate modeling in Julia but not this particular project? Get in touch—we have many more projects!

      
      ~~~~~~~~~~
      
      

      Better debug information output for variables (175 hours)
      We have part of the infrastructure in place for representing DWARF information for our variables, but only from limited places. We could do much better since there are numerous opportunities for improvement!

      Expected Outcomes: Ability to see more variable, argument, and object details in gdb

      Recommended Skills: Most of these projects involve algorithms work, requiring a willingness and interest in seeing how to integrate with a large system.

      Difficulty: Medium

      Mentors: Jameson Nash, Gabriel Baraldi

      ~~~~~~~~~~

      Improving test coverage (175 hours)
      Code coverage reports very good coverage of all of the Julia Stdlib packages, but it's not complete. Additionally, the coverage tools themselves (–track-coverage and https://github.com/JuliaCI/Coverage.jl) could be further enhanced, such as to give better accuracy of statement coverage, or more precision. A successful project may combine a bit of both building code and finding faults in others' code.

      Another related side-project might be to explore adding Type information to the coverage reports?

      Recommended Skills: An eye for detail, a thrill for filing code issues, and the skill of breaking things.

      Contact: Jameson Nash

      ~~~~~~~~~~

      Tensor network contraction order optimization and visualization – Summer of Code
      OMEinsum.jl is a pure Julia package for tensor network computation, which has been used in various projects, including

      GenericTensorNetworks.jl for solving combinatorial optimization problems,

      YaoToEinsum.jl for simulating large scale quantum circuit and

      TensorInference.jl for Bayesian inference.

      Unlike other tensor contraction packages such as ITensors.jl and TensorOperations.jl, it is designed for large scale tensor networks with arbitrary topology. The key feature of OMEinsum.jl is that it can automatically optimize the contraction order of a tensor network. Related features are implemented in OMEinsumContractionOrders.jl.

      We are looking for a student to work on the following tasks:

      Implement a better contraction order optimizer based on Tamaki's algorithm.

      Implement a hyper-graph visualization tool based on arXiv:2308.05043

      Port the contraction order optimizers to TensorOperations.jl

      Recommended skills: familiarity with tensor networks, graph theory and high performance computing.

      Expected results:

      new features added to the package OMEinsumContractionOrders.jl along with tests and relevant documentation.

      a new package about hyper-graph visualization, and relevant feature added to OMEinsum.jl.

      a pull request to TensorOperations.jl for better contraction order optimization.

      Mentors: Jin-Guo Liu, Jutho Haegeman and Lukas Devos

      Project difficulty: Medium to Hard

      Project length: 350 hrs

      Contact: feel free to ask questions via email or the Julia slack (user name: JinGuo Liu).
  
      ~~~~~~~~~~
      
      Documentation tooling – Summer of Code
      Documenter.jl
      The Julia manual and the documentation for a large chunk of the ecosystem is generated using Documenter.jl – essentially a static site generator that integrates with Julia and its docsystem. There are tons of opportunities for improvements for anyone interested in working on the interface of Julia, documentation and various front-end technologies (web, LaTeX).

      Here are some features or areas that are looking for contributions:

      User-contributed notes and examples to documentation (e.g. backed by GitHub Discussions).

      One-page-per-function documentation listings (prototype for main Julia manual). See JuliaDocs/Documenter.jl#2133.

      JuliaSyntax-based code highlighter for Julia code that can be re-used for both the HTML and LaTeX/PDF output.

      Rework Documenter's page layout and navigation. See JuliaDocs/Documenter.jl#2177.

      Improve or rework Documenter's search index.

      Work on any of the ideas that have been marked as plugins, as they offer self-contained features to work on.

      If any of these sound interesting, please reach out to the mentors to ask for more details and to narrow down the project for a proposal. The possible projects vary in difficulty and size, depending on the project and the ultimate scope.

      Recommended skills: Depends on the project, but the work would generally involved both Julia programming, but also basic web development (HTML, CSS, JS).

      Mentors: Morten Piibeleht, Fredrik Ekre

      Contact
      Best way to reach out is to message in the #documentation channel on the JuliaLang Slack!

      
      ~~~~~~~~~~
      
      FastDifferentiation.jl – Summer of Code
      FastDifferentiation.jl is a Julia package for computing very efficient symbolic derivatives of Julia functions and for compiling the derivatives into efficient executables. It can differentiate much larger expressions than other symbolic systems, such as Symbolics.jl, and the resulting derivatives are also much more efficient, rivaling hand computed derivatives in some cases (see the website for benchmark examples).

      FastDifferentiation.jl also computes the exact sparsity patterns of Jacobians and Hessians (and any other order derivative) and detects common terms in derivatives of Rⁿ->Rᵐ functions for large n,m. As a consequence computation time of Jacobians generally scales sub-linearly as a function of n,m.

      However, the current system has several weaknesses. It is not currently possible to differentiate through conditional expressions so many commonly used Julia functions cannot be differentiated. Derivatives of any order can be computed but orders above 3 or 4 become increasingly inefficient. These projects aim to address these weaknesse.

      Add Conditionals to FastDifferentiation.jl
      FastDifferentiation supports conditionals in function definitions but cannot yet compute derivatives of functions with conditionals:

      julia> @variables x y

      julia> f = if_else(x>y,x^2,y^2)
      (if_else  (x > y) (x ^ 2) (y ^ 2))

      julia> derivative(f,x)
      ERROR: Your expression contained a if_else expression. FastDifferentiation does not yet support differentiation through this functionCopy
      The goal of this project is to modify the derivative graph analysis code so that it detects conditional subgraphs and then generates run time code to evaluate conditionals and branches to correct derivative expressions.

      Medium difficulty, 175 hours.

      Recommended Skills: Julia programming experience, previous work with graph algorithms helpful but not required.

      Expected Outcome: Well-tested and well-documented support for conditionals.

      Mentor: BrianGuenter

      ~~~~~~~~~~

      Add higher order derivatives to FastDifferentiation.jl
      FastDifferentiation.jl produces extremely efficient first derivatives. But, higher order derivatives become increasingly less efficient since they are computed by repeatedly applying the differentiation algorithm.

      The fundamental cause of this behavior is that repeated higher order intermediate derivative terms are not detected and reused; instead they are computed from scratch. The goal of this project is to extend the FastDifferentiation algorithm to detect these common higher order terms and to reuse, rather than recompute them.

      This will require a rewrite of the graph factorization code as well as some theoretical work to determine which higher order terms can be reused.

      Hard, 350 hours.

      Recommended Skills: Julia programming experience, previous work with graph algorithms helpful but not required. Understanding of Faa Di Bruno's and Leibniz's rule.

      Expected Outcome: Well-tested and well-documented support for higher order derivatives.

      Mentor: BrianGuenter

      ~~~~~~~~~~

      Integrate FastDifferentiation.jl into Symbolics.jl
      FastDifferentiation.jl uses a new symbolic algorithm for automatic differentiation that can be orders of magnitude faster than conventional symbolic differentiation methods. Symoblics.jl could compute derivatives much faster using the FastDifferentiation algorithm. However implementation and data structure differences between the two systems make it difficult to add FastDifferentiation capabilities to Symbolics.jl.

      For example, Symbolics.jl allows you to define a function 
      q
      (
      t
      )
      q(t) and then to compute a symbolic derivative 
      q
      ˙
      (
      t
      )
      q˙​(t) without defining 
      q
      q. Adding this capability to FastDifferentiation.jl requires a change in the graph representation of derivatives.

      The goal of this project is to first analyze the sources of the incompatibilities between the two systems and then to modify FastDifferentiation.jl, and perhaps Symbolics.jl, so that they interoperate.

      See this page for a more detailed description of tasks.

      Medium difficulty, 175 hours.

      Recommended Skills: Julia programming experience, previous work with graph algorithms helpful but not required.

      Expected Outcome: Well-tested and well-documented integration of FastDifferentiation into Symbolics.jl.

      Mentor: BrianGuenter


      ~~~~~~~~~~

      

      
      Fluid-Structure Interaction Example
      Difficulty: Easy-Medium (depending on your specific background)

      Project size: 150-300 hours

      Problem: Ferrite.jl is designed with the possibility to define partial differential equations on subdomains. This makes it well-suited for interface-coupled multi-physics problems, as for example fluid-structure interaction problems. However, we currently do not have an example showing this capability in our documentation. We also do not provide all necessary utilities for interface-coupled problems.

      Minimum goal: The minimal goal of this project is to create a functional and documented linear fluid-structure interaction example coupling linear elasticity with a stokes flow in a simple setup. The code should come with proper test coverage.

      Extended goal: With this minimally functional example it is possible to extend the project into different directions, e.g. optimized solvers or nonlinear fluid-structure interaction.

      Recommended skills:

      Basic knowledge the finite element method

      Basic knowledge about solids or fluids

      The ability (or eagerness to learn) to write fast code

      Mentors: Dennis Ogiermann and Fredrik Ekre

      ~~~~~~~~~~

      Investigation of Performant Assembly Strategies
      Difficulty: Medium

      Project size: 250-350 hours

      Problem: Ferrite.jl has an outstanding performance in single-threaded finite element simulations due to elaborate elimination of redundant workloads. However, we recently identified that the way the single-threaded assembly works makes parallel assembly memory bound, rendering the implementation for "cheap" assembly loops not scalable on a wide range of systems. This problem will also translate to high-order schemes, where the single-threaded strategy as is prevents certain common optimization strategies (e.g. sum factorization).

      Minimum goal: As a first step towards better parallel assembly performance it is the investion of different assembly strategies. Local and global matrix-free schemes are a possibility to explore here. The code has to be properly benchmarked and tested to identify different performance problems.

      Extended goal: With this minimally functional example it is possible to extend the project into different directions, e.g. optimized matrix-free solvers or GPU assembly.

      Recommended skills:

      Basic knowledge the finite element method

      Basic knowledge about benchmarking

      The ability (or eagerness to learn) to write fast code

      Mentors: Maximilian Köhler and Dennis Ogiermann

      ~~~~~~~~~~

      

      Efficient classical simulations of linear combinations of Gaussian quantum states
      Non-Gaussian quantum states cannot be simulated via their first- and second-order statistical moments in the phase space representation like Gaussian states. However, there exist fast classical algorithms for simulating superpositions of Gaussian states, which are non-Gaussian in nature. This project involves implementing such algorithmic support for analyzing certain classes of non-Gaussian states.

      Recommended skills: In-depth understanding of the quantum phase space formalism. This paper and also this paper are useful references.

      Mentors: Andrew Kille and Stefan Krastanov.

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Medium

      ~~~~~~~~~~

      Matrix product state representations of Gaussian and non-Gaussian quantum states
      A matrix product state (MPS) is a valuable tensor network method for simulating quantum many-body systems. In particular, large continuous variable quantum systems that contain low entanglement can be simulated extremely fast with the MPS method. This project involves implementing support for MPS representations of Gaussian and non-Gaussian systems.

      Recommended skills: In-depth understanding of the quantum phase space formalism. In addition, familiarity with tensor network methods and software such as ITensors.jl. For this project, this paper and also this paper are useful references.

      Mentors: Andrew Kille and Stefan Krastanov.

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Hard


      ~~~~~~~~~~

      Gaussian cluster states
      Due to the technological maturity of quantum measurement schemes for photons, one-way quantum computation is an attractive approach for photonic quantum processing. In the continuous variable formalism, Gaussian cluster states serve as an important piece of the measurement-based quantum computation model. This project involves the creation of conversion tools between phase space representations of Gaussian bosonic systems and Gaussian cluster states in the graph formalism.

      Recommended skills: Understanding of the quantum phase space formalism and the measurement-based quantum computation model. This review article and recent paper is a useful reference.

      Mentors: Andrew Kille and Stefan Krastanov.

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Easy

      

      ~~~~~~~~~~

      Adding models and examples
      As part of the documentation and for bootstrapping new projects, we want to add fully worked-out examples and applications of graph neural networks. We can start with entry-level tutorials and progressively introduce the reader to more advanced features.

      Duration: 175h.

      Expected difficulty: easy.

      Expected outcome: A few pedagogical and more advanced examples of graph neural network applications.

      
      ~~~~~~~~~~
      
      Adding graph datasets
      Provide Julia-friendly wrappers for common graph datasets in MLDatasets.jl. Create convenient interfaces for the Julia ML and data ecosystem.

      Duration: 175h.

      Expected difficulty: easy.

      Expected outcome: A large collection of graph datasets easily available to the Julia ecosystem.

      ~~~~~~~~~~
      
      Improving performance using sparse linear algebra
      Many graph convolutional layers can be expressed as non-materializing algebraic operations involving the adjacency matrix instead of the slower and more memory-consuming gather/scatter mechanism. We aim at extending as far as possible and in a gpu-friendly way these fused implementation. The project will involve fixing some outstanding issues in CUDA.jl that are blocking sparse adjacency matrix support on GPU.

      Duration: 350h.

      Expected difficulty: hard.

      Expected outcome: A noticeable performance increase for many graph convolutional operations.

      ~~~~~~~~~~
      
      Support for AMDGPU and Apple Silicon
      We currently support scatter/gather operation only on CPU and CUDA hardware. We aim to extend this to AMDGPU and Apple Silicon leveraging KernelAbstractions.jl, AMDGPU.jl, and Metal.jl.

      Duration: 175h.

      Expected difficulty: medium.

      Expected outcome: Graph convolution speedup for AMD GPU and Apple hardware, performance roughly on par with CUDA.

      Mentors
      Carlo Lucibello (author of GraphNeuralNetworks.jl). Feel free to contact me on the Julia Slack Workspace or by opening an issue in the GitHub repo.

      ~~~~~~~~~~

      Improving GPU Stack Portability
      Difficulty: Medium

      Duration: 175 or 350 hours (the scope of functionality to port can be adjusted accordingly)

      Description: The Julia GPU stack consists of several layers, from low-level vendor-specific packages like CUDA.jl to high-level abstractions like GPUArrays.jl. While the high-level packages aim to be vendor-agnostic, many optimized operations are still implemented in vendor-specific ways. This project aims to improve portability by moving these implementations to GPUArrays.jl using KernelAbstractions.jl.

      The project will involve:

      Identifying vendor-specific kernel implementations in packages like CUDA.jl

      Porting these kernels to KernelAbstractions.jl in GPUArrays.jl

      Improving KernelAbstractions.jl where needed to support these kernels

      Ensuring performance remains competitive with vendor-specific implementations

      Adding tests to verify correctness across different GPU backends

      Required Skills:

      Experience with Julia programming

      Familiarity with GPU programming concepts

      Experience with GPU programming in Julia is a plus

      Understanding of performance optimization

      Expected Results: A set of optimized GPU kernels in GPUArrays.jl that are vendor-agnostic and performant across different GPU backends. This will improve the portability of the Julia GPU stack and make it easier to support new GPU architectures.

      Mentors: Tim Besard, Valentin Churavy

      ~~~~~~~~~~

      Project 1: Optimizations
      Difficulty: Medium

      Estimated Duration: 350 hours

      Project Overview: Herb.jl has an outstanding performance in enumerating programs. Every generated program also needs to be evaluated, making evaluation the main bottleneck in finding a suitable program. We want to improve this aspect by leveraging various well-engineered projects from the Julia community.

      First, we have so far lessened the burden of evaluation by developing custom interpreters. This is time-consuming and error-prone, so we would like to avoid it. The core challenge here is that the explore programs don't have a fixed structure and are constructed during synthesis; therefore, they cannot be compiled ahead of time. The Julia package DynamicExpressions.jl is developed to overcome this exact problem, allowing for "ridiculously fast symbolic expressions". We would like to integrate DynamicExpressions.jl into our ecosystem and get a faster evaluation of Julia programs for free.

      Second, Herb is limited to Julia so far. Our goal is, however, to make Herb a language agnostic program synthesis library. We would like to extend Herb with connections to other interpreters for common languages like Python, Java, Prolog, et cetera. This would make it possible for Herb users to use any programming language that fits their needs.

      Third, another crucial aspect of every program synthesis engine is the construction of candidate programs. State-of-the-art program synthesis tools, like CVC5, have invested significant time into optimizing the program construction step, resulting in significantly improved performance. We want to map these ideas into Herb.

      Minimum goal: Connect DynamicExpressions.jl to Herb.jl. This involves implementing the expression interface from DynamicExpressions.jl for Herb.jl’s expression tree formulation.

      Extended goal: Add support for at least one non-Julia program interpreter or add tricks from CVC5 to Herb.

      Recommended skills:

      basic knowledge of data structures

      interest in program optimization

      the eagerness to learn to write and optimize code

      Mentors: Reuben Gardos-Reid, Tilman Hinnerichs and Sebastijan Dumancic

      Some literature:

      The Program Synthesis book (by Gulwani et al., link

      CVC4SY paper: link

      DynamicExpression.jl: link

      Our website: link

      ~~~~~~~~~~

      Project 2: HerbLearn Integration
      Difficulty: Medium

      Estimated Duration: 350h

      Problem description: Neurally-guided program synthesizers form a popular class of synthesizers, which learn a heuristic to guide program generation. Following Herb's paradigm to unify the field, we want to reach the same goal for this sub-field. Specifically, learning guiding policies comprise the same building blocks of 1. program sampling, 2. program-data-encoding, 3. policy learning with respect to a loss function, and 4. deploying that strategy.

      In this project, we want to implement these building blocks to allow researchers to reuse the modules directly. To guide this project, we implemented a template structure to follow and extend.

      Minimum goal: Implement a naive but modular strategy for all four steps. To allow for easy integration of with existing models, we aim to implement the machine learning part using Flux.jl.

      Extended goal: The extended goal is to deepen one or more of these modules that fit the student's interests. The literature provides numerous ideas on how to make all four steps smarter individually. Concretely, this could include

      smarter program-sampling,

      different program encoding strategies from the literature,

      implementing and applying different loss functions, and

      incorporating this with different search procedures.

      Recommended skills:

      Basic knowledge of machine learning principles (neural networks, model training, ...)

      Preferably prior experiences with Flux.jl

      Mentors: Tilman Hinnerichs, Reuben Gardos-Reid and Sebastijan Dumancic

      Some literature:

      The Program Synthesis book (by Gulwani et al., link

      Our website: https://herb-ai.github.io/

      BUSTLE: Bottom-up Program Synthesis through learning-guided exploration: link

      DeepCoder link

      DreamCoder link

      ~~~~~~~~~~

      
      Dynamic Scheduling for Mixture of Experts using Dagger.jl
      Difficulty: Hard (350h)

      Dynamic scheduling for Mixture of Experts (MoE) in LLM faces significant challenges due to the irregular computation patterns induced by expert routing, leading to load imbalances, underutilization of compute resources, and high communication overhead. Each token in MoE is routed to only a subset of experts, causing varying batch sizes and unbalanced workload distribution across experts. The traditional static scheduling approach does not efficiently handle these dynamic task assignments. By using Dagger.jl, we can implement a more dynamic, task-based scheduling system that assigns tokens to experts based on real-time compute availability, ensuring a more balanced workload. Dagger’s asynchronous scheduling allows for efficient parallel execution by dynamically distributing the tasks across multiple devices or compute units, improving GPU utilization and reducing bottlenecks. Furthermore, optimizations such as load balancing algorithms, soft routing mechanisms, and fine-grained task prioritization could be applied to maximize resource utilization and minimize execution time. Solving these optimization problems will not only enhance performance but also improve scalability, making MoE models more efficient and suitable for large-scale deployments.

      Skills: Familiarity with GPU, representing execution models as Flux.jl, DAGs, and CUDA.jl

      Mentors: Julian Samaroo, and Rabab Alomairy

      ~~~~~~~~~~

      Distributed Training
      Difficulty: Hard (350h)

      Add a distributed training API for Flux models built on top of Dagger.jl. More detailed milestones include building Dagger.jl abstractions for UCX.jl, then building tools to map Flux models into data parallel Dagger DAGs. The final result should demonstrate a Flux model training with multiple devices in parallel via the Dagger.jl APIs. A stretch goal will include mapping operations with a model to a DAG to facilitate model parallelism as well.

      There are projects now that host the building blocks: DaggerFlux.jl and Distributed Data Parallel Training which can serve as jumping off points.

      Skills: Familiarity with UCX, representing execution models as DAGs, Flux.jl, CUDA.jl and data/model parallelism in machine learning

      Mentors: Julian Samaroo, and Dhairya Gandhi

      ~~~~~~~~~~

      Optimizing GPU scheduler in Dagger.jl with Multistreams
      Difficulty: Hard (350h)

      This project aims to explore and enhance GPU performance by integrating Dagger.jl, Julia’s high-performance parallel computing framework, with GPU multistream capabilities. Dagger.jl enables task-based parallelism, allowing complex computations to be broken down into smaller, manageable tasks that can be efficiently scheduled across computing resources. By incorporating GPU multistreams, students will investigate how multiple streams can be used to overlap data transfers with kernel executions, enabling concurrent operations on the GPU. This overlapping reduces idle times, as data movement and computations occur simultaneously, thus maximizing GPU resource utilization. The project will focus on designing and implementing parallel workflows where independent tasks are executed concurrently, leveraging Dagger’s dynamic task scheduling and GPU’s ability to manage multiple streams effectively. Students will experiment with different workload patterns, measure performance improvements, and analyze the impact of multistream execution on throughput and latency. Through performance benchmarking and optimization, this project will provide hands-on experience in GPU programming, parallel algorithm design, and high-performance computing, equipping students with valuable skills for tackling real-world scientific and data-intensive applications.

      There are projects now that host the building blocks: DaggerGPU.jl and Dagger.jl which can serve as jumping off points.

      Skills: Familiarity with GPU, representing execution models as DAGs, CUDA.jl

      Mentors: Julian Samaroo, and Rabab Alomairy

      ~~~~~~~~~~

      Distributed Linear Algebra
      Difficulty: Hard (350h)

      Add distributed linear algebra capabilities to Dagger.jl. This project will involve building abstractions for distributed linear algebra operations, such as matrix multiplication, matrix factorizations, and different data distribution schemes (cyclic, block-cyclic, 2D, 3D). The student will build on top of Dagger.jl to enable distributed linear algebra operations across multiple devices. The final result should demonstrate a linear algebra operation running across multiple devices in parallel via the Dagger.jl APIs.

      Skills: Familiarity with distributed computing, numerical linear algebra, Dagger.jl

      Mentors: Felipe Tomé, and Rabab Alomairy

      ~~~~~~~~~~

      Optimizing MPI integration in Dagger.jl
      Difficulty: Hard (350h)

      This project aims to enhance the performance of the already implemented MPI integration in Dagger.jl. The student will investigate and optimize the communication patterns between ranks, focusing on reducing communication overhead and latency. The project will involve profiling and benchmarking different communication schemes, such as point-to-point, collective and Random Memory Access (RMA) strategies, and analyzing their impact on performance. Through performance benchmarking and optimization, this project will provide hands-on experience in parallel algorithm design and , distributed computing, equipping students with valuable skills for tackling real-world scientific and data-intensive applications.

      Skills: Familiarity with MPI, representing execution models as DAGs, Dagger.jl, RMA

      Mentors: Felipe Tomé, and Julian Samaroo

      ~~~~~~~~~~

      Dynamical systems, complex systems & nonlinear dynamics – Summer of Code
      Agents.jl
      Difficulty: Medium to Hard.

      Length: 175 to 350 hours depending on the project.

      Agents.jl is a pure Julia framework for agent-based modeling (ABM). It has an extensive list of features, excellent performance and is easy to learn, use, and extend. Comparisons with other popular frameworks written in Python or Java (NetLOGO, MASON, Mesa), show that Agents.jl outperforms all of them in computational speed, list of features and usability.

      In this project, contributors will be paired with lead developers of Agents.jl to improve Agents.jl with more features, better performance, and overall higher polish. We are open to discuss with potential candidate a project description and outline for it!

      Possible features to implement are:

      GPU and/or HPC support in Agents.jl by integrating existing ABM packages (Vanaha.jl or CellBasedModels.jl) into Agents.jl API.

      Integrating Agents.jl with ReinforcementLearning.jl

      Differentiation / parameter fitting of ABMs in Agents.jl by utilizing StochasticAD.jl or similar frameworks.

      Pre-requisite: Having already contributed to a Julia package either in JuliaDynamics or of sufficient relevance to JuliaDynamics.

      Recommended Skills: Familiarity with agent based modelling, Agents.jl and Julia's Type System, and achieving high-end computational performance within Julia. Research background in complex systems, sociology, agent based modelling, or nonlinear dynamics is not required but would be advantageous.

      Expected Results: Well-documented, well-tested useful new features for Agents.jl.

      Mentors: George Datseris.


      ~~~~~~~~~~

      DynamicalSystems.jl
      Difficulty: Easy to Medium to Hard, depending on the project.

      Length: 175 to 350 hours, depending on the project.

      DynamicalSystems.jl is an award-winning Julia software library for dynamical systems, nonlinear dynamics, deterministic chaos, and nonlinear time series analysis. It has an impressive list of features, but one can never have enough. In this project, contributors will be able to enrich DynamicalSystems.jl with new algorithms and enrich their knowledge of nonlinear dynamics and computer-assisted exploration of complex systems.

      Here is a list of high-impact, Hard (350 hours) projects that we want to prioritize.

      Local and global continuation in dynamical systems combined in one. This will be a ground-breaking feature, combining cutting edge research on multistable dynamical systems with the established bifurcation-continuation analysis.

      Other than that, we do not outline more possible projects here, and instead we invite interested candidates to explore the documentation and list of open features of any of the subpackages of DynamicalSystems.jl. Then the candidates can reach out to one of the developers of the subpackage to devise a project outline. We strongly welcome candidates that already have potential project ideas in mind already irrespectively of the open list of issues.

      Pre-requisite: Having already contributed to a Julia package either in JuliaDynamics or of sufficient relevance to JuliaDynamics.

      Recommended Skills: Familiarity with nonlinear dynamics and/or differential equations and/or timeseries analysis based on the Julia language.

      Expected Results: Well-documented, well-tested new algorithms for DynamicalSystems.jl.

      Mentors: George Datseris


      ~~~~~~~~~~

      
      Project 1: Supporting Patient Level Prediction Pipelines within JuliaHealth
      Description: Patient level prediction (PLP) is an important area of research in observational health research that involves using patient data to predict outcomes such as disease progression, response to treatment, and hospital readmissions. JuliaHealth is interested in developing supportive tooling for PLP that utilizes historical patient data, such as patient medical claims or electronic health records, that follow the OMOP Common Data Model (OMOP CDM), a widely used data standard that allows researchers to analyze large, heterogeneous healthcare datasets in a consistent and efficient manner. For this project, we are looking for students interested in developing supportive PLP tooling within JuliaHealth.

      Mentor: Jacob S. Zelko (aka TheCedarPrince) [email: jacobszelko@gmail.com]

      Difficulty: Medium

      Duration: 175 hours

      Suggested Skills and Background:

      Experience with Julia

      Exposure to machine learning concepts and ideas

      Familiarity with some of the following Julia packages would be a strong asset:

      DataFrames.jl

      OMOPCDMCohortCreator.jl

      MLJ.jl

      ModelingToolkit.jl

      Comfort with the OMOP Common Data Model (or a willingness to learn)

      Outcomes:

      This project will be very experimental and exploratory in nature. To constrain the expectations for this project, here is a possible approach students will follow while working on this project:

      Review existing literature on approaches to PLP

      Familiarize oneself with tools for machine learning and prediction within the Julia ecosystem

      Develop infrastructure needed for doing PLP within the JuliaHealth ecosystem such as:

      Consistent DataFrames.jl interface

      Data harmonization methods

      Sampling considerations for large scale patient data

      Document findings and novel software

      In whatever functionality that gets developed for tools within JuliaHealth, it will also be expected for students to contribute to the existing package documentation to highlight how new features can be used. Another perspective of this project is that its intended goal is to provide the foundational support needed within JuliaHealth to better accommodate multiple modalities of data available within public health settings. The long term goal is to use the development of foundational tooling with JuliaHealth to better support patient level prediction workflows across observational health data and additional information such as survey data, social determinants of health data, and climate data.

      Additionally, depending on the success of the package, there is a potential to run experiments on actual patient data to generate actual patient population insights based on a chosen research question. This could possibly turn into a separate research paper, conference submission, or poster submission. Whatever may occur in this situation will be supported by project mentors.

      
      ~~~~~~~~~~
      
      Medical Imaging Subecosystem Projects
      Julia Radiomics
      Project Title: Julia Radiomics Difficulty: Medium Duration: 375 hours (22 Weeks) Mentor: Jakub Mitura

      Description
      Radiomic features are quantitative metrics extracted from medical images using data-characterization algorithms. These features capture tissue and lesion characteristics, such as heterogeneity and shape, which may provide valuable insights beyond what the naked eye can perceive.

      This project aims to implement algorithms for extracting radiomic features from 2D and 3D medical images, similar to PyRadiomics, using Julia. The implementation will include Gray Level Co-occurrence Matrix (GLCM), Gray Level Size Zone Matrix (GLSZM), Gray Level Run Length Matrix (GLRM), Neighborhood Gray Tone Difference Matrix (NGTDM), and Gray Level Dependence Matrix (GLDM). The extracted features will be validated against PyRadiomics and applied to medical imaging data, such as the AutoPET dataset, to demonstrate the methodology.

      Deliverables
      Implementation of Radiomic Feature Extraction Algorithms
      First Group: GLCM, GLSZM, GLRM

      Second Group: NGTDM, GLDM

      Feature Extraction Pipeline
      Extract all features from segmented lesions in PET and CT modalities.

      Use MedImages.jl for image handling.

      Leverage KernelAbstractions.jl for performance optimization where possible.

      Validation
      Compare extracted features against PyRadiomics outputs.

      Ensure statistical equivalence in extracted features.

      Final Report & Code Repository
      Methodology, results, benchmarking.

      Public GitHub repository under an MIT license.

      Success Criteria and Timeline
      Literature Review and Setup (3 Weeks)

      Review PyRadiomics documentation, MedImages.jl, KernelAbstractions.jl APIs, and AutoPET dataset structure.

      Success Criteria: Understanding of feature definitions, dataset access, and GPU kernel design.

      Feature Implementation (6 Weeks)

      Implement GLCM, GLSZM, GLRM, NGTDM, and GLDM matrices.

      Validate outputs against PyRadiomics (>90% similarity in unit tests).

      Success Criteria: GPU-accelerated implementation for 3D volumes.

      Feature Extraction Pipeline (4 Weeks)

      Build a pipeline to process AutoPET lesions using MedImages.jl.

      Success Criteria: Extraction of 100+ features per lesion, support for batch processing.

      Validation (3 Weeks)

      Compare Julia feature extraction results with PyRadiomics.

      Success Criteria: Statistical equivalence (e.g., t-test p > 0.05), with documented discrepancies <5%.

      Documentation and Packaging (4 Weeks)

      Write documentation for the Julia-based radiomics library.

      Write automated tests for the proper functioning of the library.

      Register the package in the Julia package registry.

      Success Criteria: The final working library is successfully available in the Julia ecosystem.

      Reporting (2 Weeks)

      Document methodology, results, and benchmarking.

      Success Criteria: Reproducible code, Jupyter notebooks, open-source repository.

      Stretch Goals
      Implementation of additional radiomic features such as:

      Wavelet Features (Transform-based texture analysis)

      Fractal Analysis (Estimating complexity in medical images)

      Laplacian of Gaussian (LoG) Features (Edge detection-based feature extraction)

      Optimized parallel computation using GPU acceleration in KernelAbstractions.jl.

      Implementation of an interactive Julia-based visualization tool for extracted radiomic features.

      Clarification
      This implementation will be done entirely in Julia, and Python will not be used in any part of the implementation. Any cross-validation with PyRadiomics is purely for benchmarking purposes.

      Importance and Impact
      Technical Impact
      Julia Ecosystem Growth: First native Radiomics toolkit in Julia.

      GPU Acceleration: Utilizes KernelAbstractions.jl for efficient 3D feature extraction.

      Reproducibility: Open-source implementation ensures transparency in radiomics research.

      Clinical Impact
      Cancer Differentiation: Model insights may aid in non-invasive cancer subtyping.

      Standardization: Cross-tool validation enhances study comparability across different platforms.

      Community Impact
      Foundation for Future Work: Enables Julia-based radiomics pipelines for projects like TCIA.

      Educational Value: Demonstrates GPU-accelerated medical image processing in Julia for researchers and students.

      References
      PyRadiomics Documentation

      AutoPET Dataset

      MedImages.jl

      KernelAbstractions.jl

      Radiomics Research: Various studies on the clinical relevance of radiomics in medical imaging.

      Kumar, V., et al. "Radiomics: the process and the challenges." Magnetic Resonance Imaging, 2012.

      Gillies, R.J., et al. "Radiomics: images are more than pictures, they are data." Nature Reviews Cancer, 2016.

      Lambin, P., et al. "Radiomics: extracting more information from medical images using advanced feature analysis." European Journal of Cancer, 2012.




      ~~~~~~~~~~
      Enhancing MedPipe3D: Building a Comprehensive Medical Imaging Pipeline in Julia
      Description
      MedPipe3D was created to improve integration between other parts of the small ecosystem (MedEye3D, MedEval3D, and MedImage). Currently, it needs to be expanded and adapted to serve as the basis for a fully functional medical imaging pipeline.

      Mentor: Jakub Mitura [email: jakub.mitura14@gmail.com]

      Project Difficulty and Timeline
      Difficulty: Medium Duration: 12 weeks

      Required Skills and Background
      Strong knowledge of the Julia programming language is required.

      Experience with the following Julia packages is highly desirable:

      MedPipe3D.jl

      MedEye3D.jl

      MedEval3D.jl

      MedImage.jl

      Familiarity with the following packages would be a valuable asset:

      Lux.jl

      TensorBoard

      Logging.jl

      Potential Outcomes
      Implement comprehensive logging with TensorBoard Integration and Error and Warning Logs with Logging.jl for better tracking and debugging.

      Improve the performance of augmentations.

      Enable per-layer memory usage inspection of Lux models.

      Enable gradient checkpointing of chosen layers to save memory.

      Support loading tabular data (e.g., clinical data) together with the image into the supplied model.

      Enhance documentation with in-depth tutorial, code examples, and a refined README for easy onboarding.

      This set of changes, although time-consuming to implement, should not pose a significant issue to anyone with experience with the Julia programming language. Each feature will be implemented using existing Julia libraries and frameworks where possible. However, implementing these changes will be a huge step in making the Julia language a good alternative to Python for developing end-to-end medical imaging segmentation algorithms.

      Success Criteria and Time Needed
      Logging: Implement logging to track the progress and debug issues - 2 weeks.

      Performance Improvements: Optimize the performance of augmentations to ensure efficient processing - 2 weeks.

      Memory Usage Inspection: Enable per-layer memory usage inspection of Lux models to monitor and optimize memory consumption - 2 weeks.

      Gradient Checkpointing: Enable gradient checkpointing of chosen layers to save memory during training - 4 weeks.

      Tabular Data Support: Support loading tabular data (e.g., clinical data) together with the image into the supplied model - 1 week.

      Documentation: Improve documentation to provide clear instructions and examples for users - 1 week.

      Total estimated time: 12 weeks.

      Why Implementation of These Features is Important
      Implementing these features is crucial for advancing medical imaging technology. Enhanced logging with TensorBoard integration will allow for better insight into model training. Performance improvements ensure reliable and efficient processing of large datasets. Improved documentation and memory management make the tools more accessible and usable for medical professionals, facilitating better integration into clinical workflows. Supporting tabular data alongside imaging allows for comprehensive analysis, combining clinical and imaging data to improve diagnostic accuracy and patient outcomes.

      For each point, the mentor will also supply the person responsible for implementation with examples of required functionalities in Python or will point to the Julia libraries already implementing it (that just need to be integrated).

      
      ~~~~~~~~~~
      
      Project Title: A Digital Twin Approach for Advanced Supervoxel Visualization for Multi-Image View in Medical Imaging
      General Idea
      This project aims to develop visualization and interaction software for advanced supervoxel visualization on multi-image views. Building on the experiences from MedEye3D, the project will focus on creating a tool that allows users to interact with and visualize supervoxels across different imaging modalities (e.g., CT and MRI) simultaneously. The software will highlight corresponding supervoxels in different images when the user hovers over them, facilitating reliable analysis even in the presence of natural elastic deformations.

      Potential Outcomes
      Enhanced Visualization: A software tool that provides side-by-side views of different imaging studies, displaying supervoxel borders and highlighting corresponding supervoxels across images.

      Improved Interaction: An interactive interface allowing users to manually correct supervoxel associations by clicking and highlighting supervoxels in both images.

      Control Points Annotation: Support for annotating and displaying control points to aid in registration and user orientation.

      User Feedback Integration: Mechanisms for users to indicate incorrect supervoxel associations, improving the reliability of the tool.

      Success Criteria and Time Needed
      Software Development: [10 Weeks]

      Develop the core visualization tool with side-by-side image views.

      Implement supervoxel border display and highlighting functionality.

      Integrate control points annotation and display features.

      User Interaction Features: [6 Weeks]

      Develop interactive features for manual correction of supervoxel associations.

      Implement user feedback mechanisms for indicating incorrect associations.

      Testing and Validation: [2 Weeks]

      Conduct extensive testing with sample medical imaging data.

      Validate the tool's accuracy and reliability in highlighting corresponding supervoxels.

      Documentation and User Training: [2 Weeks]

      Create comprehensive documentation for the software.

      Develop training materials and conduct user training sessions.

      Final Review and Deployment: [2 Weeks]

      Review the project outcomes and make necessary adjustments.

      Deploy the software for use by the scientific community.

      The total estimated time for the project is approximately 22 weeks. Success will be measured by the tool's ability to accurately highlight corresponding supervoxels, ease of use, and positive feedback from users in the medical imaging community.

      Technical Requirements and Expected Expertise
      Strong programming skills in Julia/C++

      Experience with medical imaging libraries (ITK, SimpleITK, NIfTI)

      Familiarity with GUI development (preferably ModernGL.jl)

      Understanding of 3D visualization techniques

      Basic knowledge of medical image processing concepts

      Experience with version control (Git)

      Tools and Technologies
      Primary Language: Julia

      GUI Framework: ModernGL.jl/ Vulkan.jl

      Image Processing: ITK/SimpleITK

      Visualization: OpenGL

      Building upon: MedEye3D framework

      User Interaction Examples
      Hovering Over Supervoxels: When the user hovers the mouse over a supervoxel in one image (e.g., CT scan), the corresponding supervoxel in the other image (e.g., MRI scan) will be highlighted automatically.

      Manual Correction: If the user identifies an incorrect supervoxel association, they can click on the supervoxel in one image to freeze it, then manually find and click the correct supervoxel in the other image to establish the correct association.

      Control Points: Users can annotate control points by clicking on corresponding anatomical areas in both images. These points will be saved and displayed to assist in image registration and orientation.

      Importance and Impact
      This project is significant because it addresses the challenges of non-rigid registration in medical imaging, which is crucial for accurate diagnosis and treatment planning. By providing a reliable tool for visualizing and interacting with supervoxels across different imaging modalities, the project has the potential to:

      Enhance the accuracy of image registration and subsequent measurements.

      Reduce the time required for manual registration by radiologists and nuclear medicine specialists.

      Enable the development of new algorithms and methods in the medical imaging field.

      Improve clinical decision-making by providing more reliable imaging data.

      While various medical image visualization tools exist, there is currently no software solution that specifically addresses supervoxel-based visualization across multiple imaging modalities with interactive correction capabilities. This project builds upon MedEye3D as an independent extension, enhancing its capabilities with new features for supervoxel visualization and interaction.

      Visual Examples
      2 Different Patient's MRI and CT Studies on Transversal plane with supervoxels

      MRI and CT Supervoxels

      Highlighting the same anatomical region in both images with supervoxel display

      MRI and CT Supervoxels with same anatomical regions highlighted

      Overall, this project aims to contribute to the advancement of medical imaging technology, ultimately benefiting both the scientific community and patient care. Additionally, it will serve as a support tool for digital twin projects, enhancing the reliability of image registration and subsequent measurements.

      ~~~~~~~~~~

      MIDIfication of music from wave files
      Difficulty: Medium.

      Length: 350 hours.

      It is easy to analyze timing and intensity fluctuations in music that is the form of MIDI data. This format is already digitalized, and packages such as MIDI.jl and MusicManipulations.jl allow for seamless data processing. But arguably the most interesting kind of music to analyze is the live one. Live music performances are recorded in wave formats. Some algorithms exist that can detect the "onsets" of music hits, but they are typically focused only on the timing information and hence forfeit detecting e.g., the intensity of the played note. Plus, there are very few code implementations online for this problem, almost all of which are old and unmaintained. We would like to implement an algorithm in MusicProcessing.jl that given a recording of a single instrument, it can "MIDIfy" it, which means to digitalize it into the MIDI format.

      Recommended Skills: Background in music, familiarity with digital signal processing.

      Expected results: A well-tested, well-documented function midify in MusicProcessing.jl.

      Mentors: George Datseris.

      ~~~~~~~~~~

      

      Efficient symbolic-numeric set computations
      Difficulty: Medium.

      Description. LazySets is the core library of JuliaReach. It provides ways to symbolically compute with geometric sets, with a focus on lazy set representations and efficient high-dimensional processing. The library has been described in the article LazySets.jl: Scalable Symbolic-Numeric Set Computations.

      The main interest in this project is to implement algorithms that leverage the structure of the sets. Typical examples include polytopes and zonotopes (convex), polynomial zonotopes and Taylor models (non-convex) to name a few.

      Expected Results. The goal is to implement certain efficient state-of-the-art algorithms from the literature. The code is to be documented, tested, and evaluated in benchmarks. Specific tasks may include (to be driven by the interets of the candidate): efficient vertex enumeration of zonotopes; operations on polynomial zonotopes; operations on zonotope bundles; efficient disjointness checks between different set types; complex zonotopes.

      Expected Length. 175 hours.

      Recommended Skills. Familiarity with Julia and Git/GitHub is mandatory. Familiarity with LazySets is recommended. Basic knowledge of geometric terminology is appreciated but not required.

      Mentors: Marcelo Forets, Christian Schilling.

      ~~~~~~~~~~

      Reachability with sparse polynomial zonotopes
      Difficulty: Medium.

      Description. Sparse polynomial zonotopes are a new non-convex set representation that are well-suited for reachability analysis of nonlinear dynamical systems. This project is a continuation of GSoC'2022 - Reachability with sparse polynomial zonotopes, which implemented the basics in LazySets.

      Expected Results. It is expected to add efficient Julia implementations of a reachability algorithm for dynamical systems in ReachabilityAnalysis which leverages polynomial zonotopes. A successful project should:

      Replicate the results from the article [Reachability Analysis for Linear Systems with Uncertain Parameters using Polynomial Zonotopes

      ](https://dl.acm.org/doi/abs/10.1145/3575870.3587130).

      The code shall be documented, tested, and evaluated extensively in benchmarks.

      For ambitious candidates it is possible to draw connections with neural-network control systems as implemented in ClosedLoopReachability.jl.

      Expected Length. 175 hours.

      Recommended Skills. Familiarity with Julia and Git/GitHub is mandatory. Familiarity with the mentioned Julia packages is appreciated but not required. The project does not require theoretical contributions, but it requires reading a research literature, hence a certain level of academic experience is recommended.

      Literature and related packages. This video explains the concept of polynomial zonotopes (slides here). The relevant theory is described in this research article. There exists a Matlab implementation in CORA (the implementation of polynomial zonotopes can be found in this folder).

      Mentors: Marcelo Forets, Christian Schilling.

      ~~~~~~~~~~

      Improving the hybrid systems reachability API
      Difficulty: Medium.

      Description. ReachabilityAnalysis is a Julia library for set propagation of dynamical systems. One of the main aims is to handle systems with mixed discrete-continuous behaviors (known as hybrid systems in the literature). This project will focus on enhancing the capabilities of the library and overall improvement of the ecosystem for users.

      Expected Results. Specific tasks may include: problem-specific heuristics for hybrid systems; API for time-varying input sets; flowpipe underapproximations. The code is to be documented, tested, and evaluated in benchmarks. Integration with ModelingToolkit.jl can also be considered if there is interest.

      Expected Length. 175 hours.

      Recommended Skills. Familiarity with Julia and Git/GitHub is mandatory. Familiarity with LazySets and ReachabilityAnalysis is welcome but not required.

      Mentors: Marcelo Forets, Christian Schilling.

      

      Reinforcement Learning Environments
      Time: 175h

      Develop a series of reinforcement learning environments, in the spirit of the OpenAI Gym. Although we have wrappers for the gym available, it is hard to install (due to the Python dependency) and, since it's written in Python and C code, we can't do more interesting things with it (such as differentiate through the environments).

      Expected Outcome
      A pure-Julia version of selected environments that supports a similar API and visualisation options would be valuable to anyone doing RL with Flux.

      Mentors: Dhairya Gandhi.

      ~~~~~~~~~~

      Molecular Simulation
      Much of science can be explained by the movement and interaction of molecules. Molecular dynamics (MD) is a computational technique used to explore these phenomena, from noble gases to biological macromolecules. Molly.jl is a pure Julia package for MD, and for the simulation of physical systems more broadly. The package is currently under development with a focus on proteins and differentiable molecular simulation. There are a number of ways that the package could be improved:

      Machine learning potentials (duration: 175h, expected difficulty: easy to medium): in the last few years machine learning potentials have been improved significantly. Models such as ANI, ACE, NequIP and Allegro can be added to Molly.

      Better GPU performance (duration: 175h, expected difficulty: medium): custom GPU kernels can be written to significantly speed up molecular simulation and make the performance of Molly comparable to mature software.

      Constraint algorithms (duration: 175h, expected difficulty: medium): many simulations keep fast degrees of freedom such as bond lengths and bond angles fixed using approaches such as SHAKE, RATTLE and SETTLE. A fast implementation of these algorithms would be a valuable contribution.

      Electrostatic summation (duration: 175h, expected difficulty: medium to hard): methods such as particle-mesh Ewald (PME) are in wide use for molecular simulation. Developing fast, flexible implementations and exploring compatibility with GPU acceleration and automatic differentiation would be an important contribution.

      Recommended skills: familiarity with computational chemistry, structural bioinformatics or simulating physical systems.

      Expected results: new features added to the package along with tests and relevant documentation.

      Mentor: Joe Greener

      Contact: feel free to ask questions via email or #juliamolsim on the Julia Slack.

   
      ~~~~~~~~~~
      Matrix functions
      Matrix functions map matrices onto other matrices, and can often be interpreted as generalizations of ordinary functions like sine and exponential, which map numbers to numbers. Once considered a niche province of numerical algorithms, matrix functions now appear routinely in applications to cryptography, aircraft design, nonlinear dynamics, and finance.

      This project proposes to implement state of the art algorithms that extend the currently available matrix functions in Julia, as outlined in issue #5840. In addition to matrix generalizations of standard functions such as real matrix powers, surds and logarithms, contributors will be challenged to design generic interfaces for lifting general scalar-valued functions to their matrix analogues for the efficient computation of arbitrary (well-behaved) matrix functions and their derivatives.

      Recommended Skills: A strong understanding of calculus and numerical analysis.

      Expected Results: New and faster methods for evaluating matrix functions.

      Mentors: Jiahao Chen, Steven Johnson.

      Difficulty: Hard

      ~~~~~~~~~~

      Better Bignums Integration
      Julia currently supports big integers and rationals, making use of the GMP. However, GMP currently doesn't permit good integration with a garbage collector.

      This project therefore involves exploring ways to improve BigInt, possibly including:

      Modifying GMP to support high-performance garbage-collection

      Reimplementation of aspects of BigInt in Julia

      Lazy graph style APIs which can rewrite terms or apply optimisations

      This experimentation could be carried out as a package with a new implementation, or as patches over the existing implementation in Base.

      Expected Results: An implementation of BigInt in Julia with increased performance over the current one.

      Require Skills: Familiarity with extended precision numerics OR performance considerations. Familiarity either with Julia or GMP.

      Mentors: Jameson Nash

      Difficulty: Hard

      ~~~~~~~~~~

      

      Special functions
      As a technical computing language, Julia provides a huge number of special functions, both in Base as well as packages such as StatsFuns.jl. At the moment, many of these are implemented in external libraries such as Rmath and openspecfun. This project would involve implementing these functions in native Julia (possibly utilising the work in SpecialFunctions.jl), seeking out opportunities for possible improvements along the way, such as supporting Float32 and BigFloat, exploiting fused multiply-add operations, and improving errors and boundary cases.

      Recommended Skills: A strong understanding of calculus.

      Expected Results: New and faster methods for evaluating properties of special functions.

      Mentors: Steven Johnson, Oscar Smith. Ask on Discourse or on slack

      ~~~~~~~~~~
      
      A Julia-native CCSA optimization algorithm
      The CCSA algorithm by Svanberg (2001) is a nonlinear programming algorithm widely used in topology optimization and for other large-scale optimization problems: it is a robust algorithm that can handle arbitrary nonlinear inequality constraints and huge numbers of degrees of freedom. Moreover, the relative simplicity of the algorithm makes it possible to easily incorporate sparsity in the Jacobian matrix (for handling huge numbers of constraints), approximate-Hessian preconditioners, and as special-case optimizations for affine terms in the objective or constraints. However, currently it is only available in Julia via the NLopt.jl interface to an external C implementation, which greatly limits its flexibility.

      Recommended Skills: Experience with nonlinear optimization algorithms and understanding of Lagrange duality, familiarity with sparse matrices and other Julia data structures.

      Expected Results: A package implementing a native-Julia CCSA algorithm.

      Mentors: Steven Johnson.

      ~~~~~~~~~~

      

      Machine learning for nowcasting and forecasting
      This project involves developing scalable machine learning time series regressions for nowcasting and forecasting. Nowcasting in economics is the prediction of the present, the very near future, and the very recent past state of an economic indicator. The term is a contraction of "now" and "forecasting" and originates in meteorology.

      The objective of this project is to introduce scalable regression-based nowcasting and forecasting methodologies that demonstrated the empirical success in data-rich environment recently. Examples of existing popular packages for regression-based nowcasting on other platforms include the "MIDAS Matlab Toolbox", as well as the 'midasr' and 'midasml' packages in R. The starting point for this project is porting the 'midasml' package from R to Julia. Currently Pythia has the sparse-group LASSO regression functionality for forecasting.

      The following functions are of interest: in-sample and out-of sample forecasts/nowcasts, regularized MIDAS with Legendre polynomials, visualization of nowcasts, AIC/BIC and time series cross-validation tuning, forecast evaluation, pooled and fixed effects panel data regressions for forecasting and nowcasting, HAC-based inference for sparse-group LASSO, high-dimensional Granger causality tests. Other widely used existing functions from R/Python/Matlab are also of interest.

      Recommended skills: Graduate-level knowledge of time series analysis, machine learning, and optimization is helpful.

      Expected output: The contributor is expected to produce code, documentation, visualization, and real-data examples.

      References: Contact project mentors for references.

      ~~~~~~~~~~

      Time series forecasting at scales
      Modern business applications often involve forecasting hundreds of thousands of time series. Producing such a gigantic number of reliable and high-quality forecasts is computationally challenging, which limits the scope of potential methods that can be used in practice, see, e.g., the 'forecast', 'fable', or 'prophet' packages in R. Currently, Julia lacks the scalable time series forecasting functionality and this project aims to develop the automated data-driven and scalable time series forecasting methods.

      The following functionality is of interest: forecasting intermittent demand (Croston, adjusted Croston, INARMA), scalable seasonal ARIMA with covariates, loss-based forecasting (gradient boosting), unsupervised time series clustering, forecast combinations, unit root tests (ADF, KPSS). Other widely used existing functions from R/Python/Matlab are also of interest.

      Recommended skills: Graduate-level knowledge of time series analysis is helpful.

      Expected output: The contributor is expected to produce code, documentation, visualization, and real-data examples.

      References: Contact project mentors for references.

      ~~~~~~~~~~

      GPU accelerated simulator of Clifford Circuits.
      Simulation of Clifford circuits involves significant amounts of linear algebra with boolean matrices. This enables the use of many standard computation accelerators like GPUs, as long as these accelerators support bit-wise operations. The main complications is that the elements of the matrices under consideration are usually packed in order to increase performance and lower memory usage, i.e. a vector of 64 elements would be stored as a single 64 bit integer instead of as an array of 64 bools. A Summer of Code project could consist of implement the aforementioned linear algebra operations in GPU kernels, and then seamlessly integrating them in the rest of the QuantumClifford library. At a minimum that would include Pauli-Pauli products and certain small Clifford operators, but could extend to general stabilizer tableau multiplication and even tableau diagonalization. Some of these features are already implemented, but significant polish and further improvements and implementation of missing features is needed.

      Recommended skills: Basic knowledge of the stabilizer formalism used for simulating Clifford circuits. Familiarity with performance profiling tools in Julia and Julia's GPU stack, including KernelAbstractions and Tullio.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it to a longer project by including work on GPU-accelerated Gaussian elimination used in the canonicalization routines)

      Difficulty: Medium if the applicant is familiar with Julia, even without understanding of Quantum Information Science (but applicants can scope it to "hard" by including the aforementioned additional topics)

      ~~~~~~~~~~
      
      A Zoo of Quantum Error Correcting codes and/or decoders
      Quantum Error Correcting codes are typically represented in a form similar to the parity check matrix of a classical code. This form is referred to as a Stabilizer tableaux. This project would involve creating a comprehensive library of frequently used quantum error correcting codes and/or implementing syndrome-decoding algorithms for such codes. The library already includes some simple codes and interfaces to a few decoders – adding another small code or providing a small documentation pull request could be a good way to prove competence when applying for this project. The project can be extended to a much longer one if work on decoders is included. A large part of this project would involve literature surveys. Some suggestions for codes to include: color codes, higher-dimensional topological codes, hyper graph product codes, twists in codes, newer LDPC codes, honeycomb codes, Floquet codes. Some suggestions for decoders to work on: iterative, small-set flip, ordered statistical decoding, belief propagation, neural belief propagation.

      Recommended skills: Knowledge of the stabilizer formalism used for simulating Clifford circuits. Familiarity with tools like python's ldpc, pymatching, and stim can help. Consider checking out the PyQDecoders.jl julia wrapper package as well.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer, depending on the list of functionality they plan to implement)

      Difficulty: Medium. Easy with some basic knowledge of quantum error correction

      
      ~~~~~~~~~~
      
      Left/Right multiplications with small gates.
      Applying an n-qubit Clifford gate to an n-qubit state (tableaux) is an operation similar to matrix multiplication, requiring O(n^3) steps. However, applying a single-qubit or two-qubit gate to an n-qubit tableaux is much faster as it needs to address only one or two columns of the tableaux. This project would focus on extending the left-multiplication special cases already started in symbolic_cliffords.jl and creating additional right-multiplication special cases (for which the Stim library is a good reference).

      Recommended skills: Knowledge of the stabilizer formalism used for simulating Clifford circuits. Familiarity with performance profiling tools in Julia. Understanding of C/C++ if you plan to use the Stim library as a reference.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan for other significant optimization and API design work)

      Difficulty: Easy

      ~~~~~~~~~~
      
      Generation of Fault Tolerant ECC Circuits, Flag Qubit Circuits and more
      The QuantumClifford library already has some support for generating different types of circuits related to error correction (mostly in terms of syndrome measurement circuits like Shor's) and for evaluating the quality of error correcting codes and decoders. Significant improvement can be made by implementing more modern compilation schemes, especially ones relying on flag qubits.

      Recommended skills: Knowledge of the variety of flag qubit methods. Some useful references could be a, b, c, and this video lecture.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Hard

      ~~~~~~~~~~
      
      Measurement-Based Quantum Computing (MBQC) compiler
      The MBQC model of quantum computation has a lot of overlap with the study of Stabilizer states. This project would be about the creation of an MBQC compiler and potentially simulator in Julia. E.g. if one is given an arbitrary graph state and a circuit, how is this circuit to be compiled in an MBQC model.

      Recommended skills: Knowledge of the MBQC model of quantum computation. This paper and the related python library can be a useful reference. Consider also this reference.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Hard

      ~~~~~~~~~~
      
      Implementing a Graph State Simulator
      The graph states formalism is a way to work more efficiently with stabilizer states that have a sparse tableaux. This project would involve creation of the necessary gate simulation algorithms and conversions tools between graph formalism and stabilizer formalism (some of which are already available in the library).

      Recommended skills: Understanding of the graph formalism. This paper can be a useful reference.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Medium

      ~~~~~~~~~~
      
      Simulation of Slightly Non-Clifford Circuits and States
      There are various techniques used to augment Clifford circuit simulators to model circuits that are only "mostly" Clifford. Particularly famous are the Clifford+T gate simulators. This project is about implementing such extensions.

      Recommended skills: In-depth understanding of the Stabilizer formalism, and understanding of some of the extensions to that method. We have some initial implementations. This IBM paper can also be a useful reference for other methods.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Hard

      ~~~~~~~~~~
      
      Magic State Modeling - Distillation, Injection, Etc
      Magic states are important non-stabilizer states that can be used for inducing non-Clifford gates in otherwise Clifford circuits. They are crucial for the creation of error-corrected universal circuits. This project would involve contributing tools for the analysis of such states and for the evaluation of distillation circuits and ECC circuits involving such states.

      Recommended skills: In-depth understanding of the theory of magic states and their use in fault tolerance.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumClifford.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Hard

      ~~~~~~~~~~
      
      

      GPU accelerated operators and ODE solvers
      Much of the internal representation of quantum states in QuantumOptics.jl relies on standard dense arrays. Thanks to the multiple-dispatch nature of Julia, much of these objects can already work well with GPU arrays. This project would involve a thorough investigation and validation of the current interfaces to make sure they work well with GPU arrays. In particular, attention will have to be paid to the "lazy" operators as special kernels might need to be implemented for them.

      Recommended skills: Familiarity with performance profiling tools in Julia and Julia's GPU stack, potentially including KernelAbstractions.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumOptics.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Medium

      ~~~~~~~~~~

      Autodifferentiation
      Autodifferentiation is the capability of automatically generating efficient code to evaluate the numerical derivative of a given Julia function. Similarly to the GPU case above, much of this functionality already "magically" works, but there is no detailed test suite for it and no validation has been done. This project would involve implementing, validating, and testing the use of Julia autodiff tools in QuantumOptics.jl. ForwardDiff, Enzyme, Zygote, Diffractor, and AbstractDifferentiation are all tools that should have some level of validation and support, both in ODE solving and in simple operator applications.

      Recommended skills: Familiarity with the Julia autodiff stack and the SciML sensitivity analysis tooling. Familiarity with the difficulties to autodiff complex numbers (in general and specifically in Julia). Understanding of the AbstractDifferentiation.jl package.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumOptics.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Easy-to-Medium

      ~~~~~~~~~~

      Closer Integration with the SciML Ecosystem
      SciML is the umbrella organization for much of the base numerical software development in the Julia ecosystem. We already use many of their capabilities, but it would be beneficial to more closely match the interfaces they expect. This project would be heavily on the software engineering side. Formal and informal interfaces we want to support include: better support for DiffEq problem types (currently we wrap DiffEq problems in our own infrastructure and it is difficult to reuse them in SciML); better support for broadcast operations over state objects (so that we can treat them closer to normal arrays and we can simply provide an initial state to a DiffEq solver without having to wrap/unwrap the data); relying more heavily on SciMLOperators which have significant overlap with our lazy operators.

      Recommended skills: Familiarity with the SciML stack.

      Mentors: Stefan Krastanov <stefan@krastanov.org> and QuantumOptics.jl team members

      Expected duration: 175 hours (but applicants can scope it as longer if they plan more extensive work)

      Difficulty: Easy

      ~~~~~~~~~~

      Ab-Initio Quantum Chemistry with Rimu.jl
      Difficulty: Easy to medium (if the recommended skills are available)

      Project size: 175 - 350 hours

      Problem: Rimu.jl provides an interface for defining a custom quantum many-body Hamiltonian and currently implements a selection of model Hamiltonians (e.g. variants of the Hubbard model and the Fröhlich polaron model). The high-level goal of the project is to implement the required functionality to solve ab-initio quantum chemistry problems with Rimu.jl and embed the package into the JuliaMolSim ecosystem, in particular with ElemCo.jl.

      Minimum goal: A minimum goal would be to enable reading in the relevant information about the molecular orbital basis set and integrals that define the molecular Hamiltonian from a file (in the standard FCIDUMP format) and defining an appropriate Hamiltonian type for Rimu.jl that enables its usage for exact diagonalisation and FCIQMC.

      Extended goal: An extended goal would be to make the molecular Hamiltonian efficient for FCIQMC, e.g. by finding and implementing an appropriate strategy for an excitation generator, e.g. a variant of (precomputed) heat-bath sampling. Another worthwhile extension would be to implement variants of the Configuration Interaction (CI) method by filtering the configurations to a relevant subspace (e.g. CI-SD, selctive CI, etc.) for the exact-diagonalisation part of Rimu.jl.

      Recommended skills:

      prior exposure to or strong interest in quantum chemistry

      good to excellent Julia coding skills

      Mentors: Joachim Brand, Daniel Kats, Elke Pahl

      If you are interested please get in touch by email.

      ~~~~~~~~~~

      Load balancing Rimu.jl for multi-node (HPC) calculations
      Difficulty: Medium to hard

      Project size: 175 - 350 hours

      Problem: Rimu.jl parallelises the workload of FCIQMC by making extensive use of native threading for shared-memory parallelism. In high-performance computing environments the primary data structure containing information about the sampled configurations and their amplitudes can further be distributed across nodes, which communicate using the MPI protocol in every time step (making use of MPI.jl). In the current implementation the distribution of configurations to nodes is done passively (in a pseudo-random fashion using a hashing algorithm). While this is fast and easy and usually leads to a fairly even distribution of data and work across the nodes, it does not scale very well when employing hundreds of nodes as every MPI rank has to wait for the slowest one to complete the work done at each time step.

      Minimum goal: Implement an active load-balancing approach where load information of each MPI rank is monitored and work load is shifted between nodes to even out the workload.

      Extended goal: Explore other load-balancing strategies like agent-based approaches, possibly even exploring algorithmic alternatives (e.g. continuous-time Monte Carlo). Design communication protocols that take into account the network topology.

      Recommended skills:

      experience with HPC environments and MPI-style programming

      good to excellent Julia coding skills

      Mentors: Matija Čufar, Joachim Brand

      If you are interested please get in touch with Matija or Joachim.

      ~~~~~~~~~~

      TopOpt Projects – Summer of Code
      TopOpt.jl is a topology optimization package written in pure Julia. Topology optimization is an exciting field at the intersection of shape representation, physics simulations and mathematical optimization, and the Julia language is a great fit for this field. To learn more about TopOpt.jl, check the following JuliaCon talk.

      The following is a tentative list of projects in topology optimization that you could be working on in the coming Julia Season of Contributions or Google Summer of Code. If you are interested in exploring any of these topics or if you have other interests related to topology optimization, please reach out to the main mentor Mohamed Tarek via email.

      ~~~~~~~~~~
      
      Testing and benchmarking of TopOpt.jl
      Project difficulty: Medium

      Work load: 350 hours

      Description: The goal of this project is to improve the unit test coverage and reliability of TopOpt.jl by testing its implementations against other software's outputs. Testing and benchmarking stress and buckling constraints and their derivatives will be the main focus of this project. Matlab scripts from papers may have to be translated to Julia for correctness and performance comparison.

      Knowledge prerequisites: structural mechanics, optimization, Julia programming

      ~~~~~~~~~~
      
      Machine learning in topology optimization
      Project difficulty: Medium

      Work load: 350 hours

      Description: There are numerous ways to use machine learning for design optimization in topology optimization. The following are all recent papers with applications of neural networks and machine learning in topology optimization. There are also exciting research opportunities in this direction.

      DNN-based Topology optimization: Spatial Invariance and Neural Tangent Kernel

      NTopo: Mesh-free Topology Optimization using Implicit Neural Representations

      TONR: An exploration for a novel way combining neural network with topology optimization

      TOuNN: Topology Optimization using Neural Networks

      In this project you will implement one of the algorithms discussed in any of these papers.

      Knowledge prerequisites: neural networks, optimization, Julia programming

      
      ~~~~~~~~~~
      Optimization on a uniform rectilinear grid
      Project difficulty: Medium

      Work load: 350 hours

      Description: Currently in TopOpt.jl, there are only unstructured meshes supported. This is a very flexible type of mesh but it's not as memory efficient as uniform rectilinear grids where all the elements are assumed to have the same shape. This is the most common grid used in topology optimization in practice. Currently in TopOpt.jl, the uniform rectilinear grid will be stored as an unstructured mesh which is unnecessarily inefficient. In this project, you will optimize the finite element analysis and topology optimization codes in TopOpt.jl for uniform rectilinear grids.

      Knowledge prerequisites: knowledge of mesh types, Julia programming

      ~~~~~~~~~~
      
      Adaptive mesh refinement for topology optimization
      Project difficulty: Medium

      Work load: 350 hours

      Description: Topology optimization problems with more mesh elements take longer to simulate and to optimize. In this project, you will explore the use of adaptive mesh refinement starting from a coarse mesh, optimizing and only refining the elements that need further optimization. This is an effective way to accelerate topology optimization algorithms.

      Knowledge prerequisites: adaptive mesh refinement, Julia programming

      
      ~~~~~~~~~~
      Heat transfer design optimization
      Project difficulty: Medium

      Work load: 175 or 350 hours

      Description: All of the examples in TopOpt.jl and problem types are currently of the linear elasticity, quasi-static class of problems. The goal of this project is to implement more problem types and examples from the field of heat transfer. Both steady-state heat transfer problems and linear elasticity problems make use of elliptic partial differential equations so the code from linear elasticity problems should be largely reusable for heat transfer problems with minimum changes.

      Knowledge prerequisites: finite element analysis, heat equation, Julia programming

      ~~~~~~~~~~

      Advanced visualization and in-situ visualization with ParaView
      Difficulty: Medium

      Project size: 175 hours or 350 hours, depending on the chosen subtasks

      Visualizing and documenting results is a crucial part of the scientific process. In Trixi.jl, we rely for visualization on a combination of pure Julia packages (such as Plots.jl and Makie.jl) and the open-source scientific visualization suite ParaView. While the Julia solutions are excellent for visualizing 1D and 2D data, ParaView is the first choice for creating publication-quality figures from 3D data.

      Currently, visualization with ParaView is only possible after a simulation is finished and requires an additional postprocessing step, where the native output files of Trixi.jl are converted to VTK files using Trixi2Vtk.jl. This extra step makes it somewhat inconvenient to use, especially when the current state of a numerical solution is to be checked during a long, multi-hour simulation run.

      The goal of this project is therefore to make such visualizations easier by introducing two significant improvements:

      Add the capability to write out native VTKHDF files directly during a simulation, in serial and parallel.

      Enable parallel in-situ visualization of the results, i.e., to visualize results by connecting ParaView to a currently running, parallel Trixi.jl simulation using the Catalyst API.

      Both tasks are related in that they require the student to familiarize themselves with both the data formats internally used in Trixi.jl as well as the visualization pipelines of VTK/ParaView. However, they can be performed independently and thus this project is suitable for either a 175 hour or a 350 hour commitment, depending on whether one or both tasks are to be tackled.

      This project is good for both software engineers interested in the fields of visualization and scientific data analysis as well as those students who are interested in pursuing graduate research in the field of numerical analysis and high-performance computing.

      Recommended skills: Some knowledge of at least one numerical discretization scheme (e.g., finite volume, discontinuous Galerkin, finite differences) is helpful; initial knowledge about visualization or parallel processing; preferably the ability (or eagerness to learn) to write fast code.

      Expected results: Scalable, production quality visualization of scientific results for Trixi.jl.

      Mentors: Michael Schlottke-Lakemper, Benedict Geihe, Johannes Markert

      
      ~~~~~~~~~~
      
      Asynchronous computing for communication blocking MPI and multi-GPU computing using Trixi.jl
      Difficulty: Medium

      Project size: 175 hours or 350 hours, depending on the chosen subtasks

      The high performance of modern scientific software is built on parallel computing using MPI and GPUs. The communication speed has not kept up with the exponential increase in compute speed and algorithms are often communication bound, leading to underutilization of hardware capabilities. Asynchronous computing avoids communication bottlenecks by performing non-blocking sends and using algorithms that can give reliable results using the currently available data. This approach gives great scalability on parallel computing systems.

      Trixi.jl currently performs distributed memory parallelization using MPI.jl, and has experimental GPU capabilities using CUDA.jl and KernelAbstractions.jl. The goal of this project is to implement a subset of features of Trixi.jl that can perform parallel simulations asynchronously.

      The possible subtasks in this project include:

      Explore and implement a simple code for asynchronous algorithms for solving the 1D advection equation or 1D compressible Euler equations using the API of Trixi.jl.

      Taking the simple code as a prototype, explore and implement an asynchronous algorithm starting with the basic TreeMesh type in Trixi.jl and potentially extending up to P4estMesh.

      Explore and implement asynchronous algorithms for a multi-GPU setup, in the 1D prototype and in Trixi.jl.

      Explore and implement asynchronous algorithms using Remote Memory Access Programming using MPI.jl.

      Optimize and compare the performance of the above implementations across different hardwares.

      This project is good for both software engineers interested in the fields of scientific computing, machine learning and numerical analysis as well as those students who are interested in pursuing graduate research in the field.

      Recommended skills: Some knowledge of GPU or MPI programming. Knowledge of any numerical analysis (e.g., finite differences) will help, but is not strictly required.

      Expected results: Draft of a working subset of the functionality of Trixi.jl efficiently using asynchronous computing.

      Mentors: Arpit Babbar, Hendrik Ranocha, Michael Schlottke-Lakemper

      
      ~~~~~~~~~~
      
      Adaptive mesh refinement on GPUs with CUDA dynamic parallelism
      Difficulty: Hard

      Project size: 175 hours or 350 hours, depending on the chosen subtasks

      Dynamic parallelism is designed for applications with either a variation of work across space or a dynamically varying workload over time. It is perfect for tasks like mesh refinement. When a thread discovers that an area needs to be refined, it can launch a new grid to perform computations on the refined area without the overhead of terminating the current grid, reporting to the host, and launching the new grid from the host.

      Adaptive mesh refinement (AMR) is applied in Trixi.jl to dynamically refine the mesh during simulations, ensuring finer resolution in critical regions for improved accuracy. Currently, the mesh refinement process is performed on CPUs using parallelism with MPI.jl. The goal of this project is to migrate AMR to GPUs using dynamic parallelism for acceleration with CUDA.jl.

      The possible subtasks in this project include:

      Implementing the abstract tree initialization process on GPUs.

      Exploring the TreeMesh initialization processes on GPUs based on the implementation of the first task and combining them.

      Integrating the above into AMRCallback in the simulation using dynamic parallelism (via CUDA.jl).

      Optimizing the code for data transfer, kernel launch overhead, occupancy, etc.

      Starting the above work in 1D and then expanding it to 2D and 3D problems.

      (Optional) Try similar work for P4estMesh in 2D and 3D.

      This project is good for people who are interested in GPU programming, parallel computing, parallel algorithm optimization, and scientific computing.

      Recommended skills: GPU programming, knowledge of CUDA dynamic parallelism, and familiarity with mesh refinement. (For beginners or those unfamiliar with dynamic parallelism, it is recommended to start with the CUDA quadtree example.)

      Expected results: A working example of AMR running on GPUs.

      Mentors: Huiyu Xie, Jesse Chan, Hendrik Ranocha

      

      

      ~~~~~~~~~~
      
      Mooncake.jl Performance Optimization
      Difficulty: Medium

      Duration: 350 hours

      Description: Mooncake.jl is a reverse-mode AD package written entirely in Julia, which addresses many of limitations of the popular ReverseDiff.jl and Zygote.jl libraries. While the library is typically fast, performance is not tested as systematically as it could be, meaning that there are probably a range of performance bugs waiting to be uncovered. Additionally, there are a range of known performance limitations which need to be addressed. This project aims to resolve known performance problems, to find new ones, and fix them too!

      Skills: familiarity with Julia programming, how to make Julia code performant, and a strong desire to make existing Julia code more performant! An understanding of AD is helpful, but not essential.

      
      ~~~~~~~~~~
      
      R and Python Interfaces for JuliaBUGS
      Difficulty: Medium

      Duration: 175 hours or 350 hours

      JuliaBUGS is a Julia implementation of the BUGS probabilistic programming language. It emphasizes interoperability and modularity. JuliaBUGS gives users familiar with BUGS access to Hamiltonian Monte Carlo (HMC), Automatic Differentiation (AD), and Julia’s powerful scientific computing tools. This Google Summer of Code (GSoC) project aims to create easy-to-use R and Python interfaces for JuliaBUGS.

      Project Tasks:

      Interface Design: Develop R and Python packages similar to existing and widely used R packages like R2OpenBUGS and rjags, making it easy for users to adopt.

      Interoperability Development: Use Julia's existing packages (JuliaCall and PythonCall) to create the interfaces. This will allow smooth data transfer and function calls between Julia, R, and Python.

      Integration with Tools (Large Project): Integrate these new interfaces seamlessly with popular Bayesian visualization and diagnostics tools—such as bayesplot, posterior, and coda in R, and ArviZ in Python.

      Documentation and Tutorials (Large Project): Create clear and practical documentation, including tutorials, to support users in understanding and effectively using the interfaces.

      Participants will gain hands-on experience in Bayesian statistics, software engineering, computational methods, and developing software that works across multiple programming languages. This will prepare them well for future academic and professional opportunities.

      
      ~~~~~~~~~~
      Jaxprs in Julia
      Difficulty: Hard

      Duration: TBD

      The Turing.jl team is looking for a student to implement a lightweight Julia library to work with Jaxprs. If this could be you, get in touch and we can discuss the details.

      ~~~~~~~~~~
      VS Code extension
      We are generally looking for folks that want to help with the Julia VS Code extension. We have a long list of open issues, and some of them amount to significant projects.

      Required Skills: TypeScript, Julia, web development.

      Expected Results: Depends on the specific projects we would agree on.

      Mentors: David Anthoff

      ~~~~~~~~~~

      Package installation UI
      The VSCode extension for Julia could provide a simple way to browse available packages and view what's installed on a users system. To start with, this project could simply provide a GUI that reads in package data from a Project.toml/Manifest.toml and show some UI elements to add/remove/manage those packages.

      This could also be extended by having metadata about the package, such as a readme, github stars, activity and so on (somewhat similar to the VSCode-native extension explorer).

      Expected Results: A UI in VSCode for package operations.

      Recommended Skills: Familiarity with TypeScript and Julia development.

      Mentors: Sebastian Pfitzner

      Also take a look at Pluto - VS Code integration!

      ~~~~~~~~~~

      

      Code generation improvements and async ABI
      Because Julia relies on an asynchronous task runtime and WebAssembly currently lacks native support for stack management, Julia needs to explicitly manage task stacks in the wasm heap and perform a compiler transformation to use this stack instead of the native WebAssembly stack. The overhead of this transformation directly impacts the performance of Julia on the wasm platform. Additionally, since all code Julia uses (including arbitrary C/C++ libraries) must be compiled using this transformation, it needs to cover a wide variety of inputs and be coordinated with other users having similar needs (e.g. the Pyodide project to run python on the web). The project would aim to improve the quality, robustness and flexibility of this transformation.

      Recommended Skills: Experience with LLVM.

      
      ~~~~~~~~~~
      Wasm threading
      WebAssembly is in the process of standardizing threads. Simultaneously, work is ongoing to introduce a new threading runtime in Julia (see #22631 and replated PRs). This project would investigate enabling threading support for Julia on the WebAssembly platform, implementing runtime parallel primitives on the web assembly platform and ensuring that high level threading constructs are correctly mapped to the underlying platform. Please note that both the WebAssembly and Julia threading infrastructure is still in active development and may continue to change over the duration of the project. An informed understanding of the state of these projects is a definite prerequisite for this project.

      Recommended Skills: Experience with C and multi-threaded programming.

      ~~~~~~~~~~
      
      High performance, Low-level integration of js objects
      WebAssembly is in the process of adding first class references to native objects to their specification. This capability should allow very high performance integration between julia and javascript objects. Since it is not possible to store references to javascript objects in regular memory, adding this capability will require several changes to the runtime system and code generation (possibly including at the LLVM level) in order to properly track these references and emit them either as direct references to as indirect references to the reference table.

      Recommended Skills: Experience with C.

      ~~~~~~~~~~
      
      DOM Integration
      While Julia now runs on the web platform, it is not yet a language that's suitable for first-class development of web applications. One of the biggest missing features is integration with and abstraction over more complicated javascript objects and APIs, in particular the DOM. Inspiration may be drawn from similar projects in Rust or other languages.

      Recommended Skills: Experience with writing libraries in Julia, experience with JavaScript Web APIs.

      ~~~~~~~~~~
      
      Porting existing web-integration packages to the wasm platform
      Several Julia libraries (e.g. WebIO.jl, Escher.jl) provide input and output capabilities for the web platform. Porting these libraries to run directly on the wasm platform would enable a number of existing UIs to automatically work on the web.

      Recommended Skills: Experience with writing libraries in Julia.

      ~~~~~~~~~~
      
      Native dependencies for the web
      The Julia project uses BinaryBuilder to provide binaries of native dependencies of julia packages. Experimental support exists to extend this support to the wasm platform, but few packages have been ported. This project would consist of attempting to port a significant fraction of the binary dependencies of the julia ecosystem to the web platform by improving the toolchain support in BinaryBuilder or (if necessary), porting upstream packages to fix assumptions not applicable on the wasm platform.

      Recommended Skills: Experience with building native libraries in Unix environments.

      ~~~~~~~~~~
      
      Distributed computing with untrusted parties
      The Distributed computing abstractions in Julia provide convenient abstraction for implementing programs that span many communicating Julia processes on different machines. However, the existing abstractions generally assume that all communicating processes are part of the same trust domain (e.g. they allow messages to execute arbitrary code on the remote). With some of the nodes potentially running in the web browser (or multiple browser nodes being part of the same distributed computing cluster via WebRPC), this assumption no longer holds true and new interfaces need to be designed to support multiple trust domains without overly restricting usability.

      Recommended Skills: Experience with distributed computing and writing libraries in Julia.

      Deployment
      Currently supported use cases for Julia on the web platform are primarily geared towards providing interactive environments to support exploration of the full language. Of course, this leads to significantly larger binaries than would be required for using Julia as part of a production deployment. By disabling dynamic language features (e.g. eval) one could generate small binaries suitable for deployment. Some progress towards this exists in packages like PackageCompiler.jl, though significant work remains to be done.

      Recommended Skills: Interest in or experience with Julia internals.



      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-julia-language/
    idea_list_url: https://julialang.org/jsoc/projects/

  - organization_id: 155
    organization_name: The Linux Foundation
    no_of_ideas: 25
    ideas_content: |

      Qt Print Dialog: Modernize the user interface
      1 contributor full-size (350 hours), Level of difficulty: Hard

      The print dialog of Qt, which is also the print dialog used by KDE applications has still the user interface of 20 years ago, when I told the Qt and KDE developers that a CUPS-supporting print dialog is needed and they made this print dialog in response.

      Now, after the internals of the dialog being up-to-date (Support for the Common Print Dialog Backends added in GSoC 2022) we need to make the user interface of the Qt print dialog cute.

      The modernization should at least be a UI similar to the one of the GTK print dioalog. This should not require any extensions of the API between the print dialog and the applications and so the new dialog can replace the old one without modifications on existing applications needed.

      Optionally, depending on the time left, a dialog with built-in preview (Like in LibreOffice, Chromium, Firefox, Thunderbird) could be created. This requires more UI design work and most probably also additions to the API. The migration of a simple application (like text editor or document viewer) to the new print dialog would demo it and make the developers of other applications switch over.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Qt developers, TBD

      Desired knowledge: C/C++, Qt, UI Design

      Code License: LGPL-3 and GPL-2

      ~~~~~~~~~~

      GTK Print Dialog: Modern dialog with built-in preview in main view
      1 contributor full-size (350 hours), Level of difficulty: Hard

      Are you using LibreOffice, Firefox, Thunderbird, or Chromium with their nice, modern preview-centric print dialogs and got somewhat disappointed with GNOME apps like the Text Editor, Evince, or similar because of their more conventional GTK print dialog? Note that GTK's dialog has also a preview, but it is awkward to use, one has to click a button to get a preview, but there is no button to return to the main dialog to do adjustments.

      Then you should make an end to this problem, by modernizing the user interface (UI) of GTK's print dialog!

      Investigate the workflow of the modern preview-centric print dialogs and also have a look into their code (the mentioned apps are all open source). Also have a look into the code base of GTK's print dialog. Then design a similar UI, with embedded preview for the print dialog and implement it in GTK.

      Try to conserve the API between the application and the print dialog, so that the new print dialog can just replace old one in all applications. If this is not possible, try to keep the API additions a minimum, and for applications which are not (yet) adapted to the new print dialog, try to make as much as possible working in your print dialog (and as last resort display the old dialog).

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), GTK/GNOME developers, TBD

      Desired knowledge: C, GTK/GNOME, UI Design

      Code License: LGPL-2 or later and LGPL-2.1 or later

      ~~~~~~~~~~

      

      KDE Print Manager vs. CUPS 3.x
      1 contributor full-size (350 hours), Level of difficulty: Hard

      As we have made the “Printers” module of the GNOME Control Center supporting CUPS 3.x in several GSoC projects we need to do the same for the KDE Print Manger. And this is what this project is about.

      For the local server of CUPS 3.x the main view does not need to display CUPS queues as defined in `/etc/cups/printers.conf` with PPD files any more but instead, it has to display IPP print destinations (driverless network and IPP-over-USB printers, Printer Applications, shared remote CUPS queues) as on all these we can print, without a CUPS queue needing to be created, as CUPS creates a temporary one when needed. The destinations have to be grouped, when they come from the same device, server, or Printer Application, and the IPP destinations are configured by their admin web interfaces, so we have to add buttons to open these interfaces.

      The “Add Printer” dialog will continue to exist, but to list non-driverless (legacy or specialty) printers and assign Printer Applications instead of PPD files to them.

      Actually we will only add the new functionality and not remove the old one, meaning displaying both IPP destinations and classic CUPS queues, and in the “Add Printer” part allow for assigning both PPD files and Printer Applications (latter preferred), so that once the new Print Manager in place we can make a smooth transition from CUPS 2.x to CUPS 3.x at any time, and also, CUPS 2.x already supports IPP print destinations without permanent CUPS queue, so also for CUPS 2.x users modern, driverless printers will just appear and they do not try to unecessarily create queues for them.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Mike Noe (noeerover at gmail dot com), KDE developers, TBD

      Desired knowledge: C/C++, KDE/Qt, UI Design

      Code License: GPL 2.0 or later and LGPL 2.0 or later

      ~~~~~~~~~~

      Port pyCUPS to CUPS 3.x API + Apply the new pyCUPS to system-config-printer
      1 contributor full-size (350 hours), Level of difficulty: Intermediate

      Most software with print functionality or print administration functionality uses the CUPS library (libcups, 2.x, 3.x) to communicate with CUPS. This is easy when the software is written in C or C++ as the library is written in C.

      If the software is written in other languages, we need some connection between the library and the client code, the so-called bindings. For Python we have bindings for libcups, pyCUPS. This works well with libcups 2.x already for years. system-config-printer is principal user of pyCUPS.

      What we need now is to extend pyCUPS for the use with libcups 3.x of the new CUPS 3.x, so that pyCUPS will live on and continue to allow writing software which interacts with CUPS in Python.

      The contributor's task is to go through the APIs of libcups3 and compare them with libcups2 to see what has to be added. If there is a way to automate the creation of Python bindings, it can be used and old (libcups2) and new (libcups3) has to be merged, so that pyCUPS can be used for any version of libcups.

      It should be also taken into account that libcups2 of CUPS 2.5.x got some functions of libcups3 backported.

      system-config-printer was already updated for CUPS 3.x in last year's GSoC. Here we want system-config-printer use the new pyCUPS now, for optimization and minimization of code duplication.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Zdenek Dohnal, Printing Maintainer at Red Hat (zdohnal at redhat dot com), TBD

      Desired knowledge: Python, C, CUPS

      Code License: GPL-2+ (GPL 2 or any later version)

      ~~~~~~~~~~

      Extend PDFio to be a PDF renderer/displayer
      1 contributor full-size (350 hours), Level of difficulty: Hard

      Like CUPS, libcupsfilters is principally written in regular C and not in C++. We want to avoid C++ as it has often problems with binary compatibility and the mechanism with which the Debian/Ubuntu build services auto-detect dependencies between Debian packages get very awkward with C++.

      In libcupsfilters we now succeeded to eliminate use of C++, by replacing the use of the C++ library QPDF for PDF manipulation by Michael Sweet's PDFio and also by not using libpoppler any more but using Poppler's command line utilities instead. This was done as a GSoC project last year.

      As the call of Poppler via command line utilities and Ghostscript having a license which makes it unsuitable in vertain cases, we are looking into a PDF rasterizer which is written in straight C and has a more friendly (permissive) license. PDFio is written in C and has the same license as CUPS and libcupsfilters themselves, but it is only a PDF manipulation library, not a renderer.

      But as PDFio is able to do the “dirty work” of PDF file reading, especially navigating through the file's object structure we can make use of it to create a PDF renderer, ideally to extend the PDFio library to provide this functionality or to create the renderer library using PDFio.

      This renderer should be aimed for printing, it should be principally called from libcupsfilters, or from Printer Applications, so the goal of this project is to get in this direction and not design a fancy GUI document viewer, but a simple screen display facility would be helpful for development and debugging.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Michael Sweet, author of CUPS and PAPPL (msweet at msweet dot org), Ira McDonald (blueroofmusic at gmail dot com), TBD

      Desired knowledge: C/C++, CUPS

      Code License: Apache 2.0


      ~~~~~~~~~~

      Utilizing OSS-Fuzz-Gen to Improve Fuzz Testing for OpenPrinting Projects
      Security- and AI-related project

      1 contributor full-size (350 hours), Level of difficulty: Hard

      Recent vulnerabilities (including CVE-2024-47175, CVE-2024-47176, CVE-2024-47177) reported in OpenPrinting projects have underscored the critical need for robust security measures. Given that most of the projects of OpenPrinting are developed in C/C++, which are prone to memory violation bugs. To address these challenges, OpenPrinting has engaged with Google's OSS-Fuzz, a service designed to support open-source communities by providing large-scale fuzz testing and bug reporting, and maintains the fuzz harnesses in the separate OpenPrinting fuzzing repository.

      Current Integration with OSS-Fuzz: OpenPrinting has successfully integrated three key projects into the OSS-Fuzz workflow, with two additional projects currently in progress. Although the integration has already yielded significant results, which have reported 21 critical fixed bugs leading to more than 5,000 lines of code fixes, it remains insufficient. The testing coverage for critical components is still lacking, and the severity of potential issues within OpenPrinting projects demands further action.

      For now, OpenPrinting has integrated projects into the OSS-Fuzz workflow:

      cups
      libcups (of CUPS 3.x)
      cups-filters
      The following projects are under construction:

      libcupsfilters
      cups-browsed
      With Google's introduction of OSS-Fuzz-Gen, which leverages Large Language Models (LLMs) to enhance fuzz testing for open-source software, it has demonstrated exceptional potential in facilitating the integration of high-quality fuzz testing (Google Blog). Therefore, we aim to utilize the OSS-Fuzz-Gen framework to further improve the existing quality of OSS-Fuzz harnesses

      Project Goals for GSoC 2025: The primary objective for this Google Summer of Code project is to refine and expand our existing fuzz testing harnesses. Specifically:

      Enhancing Existing Harnesses: Improve the quality of dictionaries, configurations, and seed data for current integrations, adhering to OSS-Fuzz best practices.
      Expanding Harness Integration: Utilize OSS-Fuzz-Gen to develop and implement additional harnesses, targeting high-value, difficult-to-reach code sections with the support of LLMs.
      Contributor Responsibilities:

      Master OSS-Fuzz best practices to provide high-quality seeds and corpus for existing integrations. Employ OSS-Fuzz-Gen to create and integrate new harnesses, adopting diverse strategies to enhance code coverage.
      Collaborate with OpenPrinting developers to identify and patch vulnerabilities uncovered through fuzz testing.
      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Jiongchi Yu, PhD Candidate at Singapore Management University (jiongchiyu at gmail dot com), George-Andrei Iosif, Security Engineer at Snap Inc. (hi at iosifache dot me).

      Desired knowledge: C, Python, fuzz-testing

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      
      
      ~~~~~~~~~~
      
      Integrating OSS-Fuzz for Go-Based and Python-Based OpenPrinting Projects
      Security-related project

      1 contributor medium-size (175 hours), Level of difficulty: Intermediate

      OpenPrinting hosts many polyglot projects, which are developed not limited to languages of C/C++. We also host software written in languages like Python and Golang, which function as crucial printing APIs and often interface with C/C++ libraries to deliver comprehensive printing services. The integration of multiple programming languages into our ecosystem underscores the necessity for a broad and inclusive testing approach. Given the diversity of development environments, it is crucial to extend the testing for these projects, specifically for integration of OSS-Fuzz.

      To this end, we plan to extend the capabilities of the existing OSS-Fuzz frameworks to include projects developed in languages other than C/C++. This initiative will target Python and Golang projects, ensuring that our fuzz testing encompasses the full spectrum of development environments within OpenPrinting.

      Project Goals for GSoC 2025: The primary objective for this Google Summer of Code project is to integrate the polyglot projects in OpenPrinting into OSS-Fuzz framework and refine existing unit tests for these projects. The targeting projects include:

      Golang
      ipp-usb
      goipp
      Python
      pycups
      pyppd
      Contributor Responsibilities:

      Evaluate and Improve Testing Approaches: The contributor needs to understand existing testing strategies within the project and evaluate their effectiveness. Where there are gaps, particularly in areas that are under-tested, the contributor should develop and improve tests to cover these functionalities.
      Integrate Projects into OSS-Fuzz Workflow: The contributor should also integrate these projects into OSS-Fuzz framework, following previous integrations for C/C++ projects in OpenPrinting fuzzing repository with appropriate fuzzing corpus.
      Triage and Report Vulnerabilities: The contributor should work closely with developers from OpenPrinting to identify and report any vulnerabilities that are discovered through the testing process.
      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Jiongchi Yu, PhD Candidate at Singapore Management University (jiongchiyu at gmail dot com), George-Andrei Iosif, Security Engineer at Snap Inc. (hi at iosifache dot me).

      Desired knowledge: Python, Go, fuzz-testing

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      ~~~~~~~~~~
      
      System/Fuzz Testing of Printing Protocols
      Security-related project

      1 contributor full-size (350 hours), Level of difficulty: Hard

      As OpenPrinting advances driverless printing services, the corresponding standardized printing protocols, such as the Internet Printing Protocol (IPP), have become more and more important. The protocol is fundamental to achieving generalized printing services and thus requires rigorous security testing to prevent vulnerabilities.

      Effective testing of printing protocols and Domain-specific languages (DSL) like IPP and PostScript demands precise input pairs and well-regulated testing environments/contexts. Given the complexity and technical specifications of these protocols, creating universal testing suites that can be applied across various platforms and languages is essential. Such suites will support the consistent functionality and specification adherence necessary for secure and efficient printing operations.

      Project Goals for GSoC 2025: The primary objective for this Google Summer of Code project is to develop comprehensive testing suites designed for the printing protocols used in OpenPrinting projects (e.g., IPP). Specifically, the suites encompass: (1) unit tests and differential tests for IPP, detailing test inputs and expected outputs within the appropriate printing contexts, and (2) fuzzing enhanced by a custom validator to verify the correctness of outputs against the specifications. These suites will incorporate unified testing drivers and oracles (validated test input and output pairs) to ensure accurate and reliable results.

      Contributors are expected to achieve:

      Thoroughly understand and summarize the key aspects of printing protocols used in OpenPrinting, such as IPP and PostScript.
      Develop tailored testing strategies for these protocols, referencing standards such as RFC 8011, and OpenPrinting's 17 IPP specifications
      Implement high-quality unit tests, differential tests, and fuzzing drivers along with protocol-tailed testing oracles within OpenPrinting projects. Contributors will also be responsible for identifying any discrepancies or bugs, reporting them, and coordinating with developers to facilitate necessary fixes.
      The outputs of this project will not only serve as a valuable reference for generalizing testing across all OpenPrinting projects but also the documented progress can also lead to potential academic contributions, such as technical reports or research papers.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Jiongchi Yu, PhD Candidate at Singapore Management University (jiongchiyu at gmail dot com), George-Andrei Iosif, Security Engineer at Snap Inc. (hi at iosifache dot me).

      Desired knowledge: C/C++, security/testing

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      
      ~~~~~~~~~~
      
      Security Auditing for OpenPrinting Projects
      Security-related project

      1 contributor full-size (350 hours), Level of difficulty: Intermediate

      OpenPrinting projects play a critical role in the printing infrastructure of countless systems, making their security paramount. Inspired by security auditing reports from other open source communities (CNCF: Security Audit for Karmada, Security Audit for Kubernetes and Security Audit for OpenSSF), we believe a comprehensive security auditing report could significantly enhance the robustness and reliability of these projects. This initiative will leverage advanced software analysis methods to conduct thorough security audits.

      The audit process includes scoring OpenPrinting projects using OpenSSF’s Security Scorecard and examining the projects and their dependencies with respect to testing status, which encompasses adherence to continuous integration (CI) test best practices and test coverage assessments. Furthermore, dynamic testing should also be considered, for example, end-to-end fuzzing techniques such as AFLplusplus, which assists in the successful detection of CVE-2024-47076. Static analysis tools including cppcheck and flawfinder, Valgrind can be employed for checking the implementation flaws. The overall security audit should include dynamic software analysis methodologies to cover more extensive aspects of OpenPrinting projects.

      Project Goals for GSoC 2025: The primary objective of this Google Summer of Code project is to complete a systematic security audit report for OpenPrinting. This comprehensive process includes maximizing the scores provided by the OpenSSF Security Scorecard and scanning dependencies using existing SADT tools. In addition to static analysis, incorporating dynamic testing methodologies will provide an exhaustive overview of security across the entire network of projects. The project aims to identify and mitigate potential vulnerabilities effectively, ensuring that a robust defense mechanism is in place to protect the integrity of the OpenPrinting infrastructure.

      Contributors are expected to: Use or implement dynamic testing/auditing tools for analyzing OpenPrinting projects, which includes examining OpenSSF Scorecard of OpenPrinting projects and preparing detailed security auditing reports outlining discovered vulnerabilities. The contributor should also coordinate with security experts to address these issues effectively.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Jiongchi Yu, PhD Candidate at Singapore Management University (jiongchiyu at gmail dot com), George-Andrei Iosif, Security Engineer at Snap Inc. (hi at iosifache dot me).

      Desired knowledge: C/C++, code auditing

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      ~~~~~~~~~~
      
      Behavior-accurate simulation of multi-function printers (printer + scanner)
      1-3 contributors full-size (350 hours), Level of difficulty: Hard

      Although driverless printing and scanning are governed by standards and specifications, real hardware implementations often have unique details that can deviate from these specifications, impacting the accuracy of our printing and scanning implementations.

      We currently have the “ippeveprinter” tool, which implements an “abstract” IPP 2.x printer. However, we lack a behavior-accurate simulation of real printers and do not have any simulation for eSCL/WSD scanners.

      The goal is to create a behavior-accurate simulator for multi-function printers (MFPs) that supports at least IPP 2.x for printing, eSCL and WSD for scanning, and DNS-SD and WS-Discovery for device discovery. We aim to build a growing collection of models representing various specific devices.

      This simulator will consist of a core simulation engine that provides reference implementations of the aforementioned protocols, along with a customization engine that allows for the expression of implementation details specific to individual devices without the need to reimplement common functionalities repeatedly.

      One of our key objectives is to make the process of creating MFP models semi-automated. For instance, printer attributes and scanner capabilities can be automatically obtained, while accurately simulating behavioral features may require manual testing and analysis to identify these details, along with scripting to express them in the simulator. We anticipate that actual device behavior will not deviate significantly from the “ideal” model implemented by the simulation core, allowing models to remain relatively straightforward. Ideally, the model creation process should be simple enough for mid-level technical personnel and qualified users to undertake independently.

      This initiative opens up several new avenues:

      Remote debugging of printing/scanning issues without needing to connect to the device or engage extensively with the device owner
      The ability to test software changes without physical access to the relevant hardware
      Full-stack automated testing of printing and scanning against simulated hardware
      Initially, our collection of models will be small and may contain inaccuracies. However, as we expand our model collection, we will be able to automatically detect most regression cases during the development of the entire printing and scanning stack.

      The implementation of the simulation core has already started, what we need from the contributor(s) is to develop the initial collection of the printer models. During this phase, we will evaluate and refine the overall concept, establishing and assessing the methodology for creating MFP models.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), TBD

      Desired knowledge: Familiarity with relevant protocols (IPP, eSCL, WSD, DNS-SD), knowledge of the Linux printing and scanning stack, programming in C, and proficiency in Python or JavaScript (for scripting MFP models).

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      
      ~~~~~~~~~~
      
      Image output evaluation for testing of print/scan job processing
      1 contributor full-size (350 hours), Level of difficulty: Hard

      We do a lot of testing for quality assurance and security of our software, especially also tests of the data processing when printing and scanning. For now our only criteria to consider a test failed is a processing error, a crash, an infinite loop, or the output being empty. We do not verify whether the content of the output is actually what we have expected.

      Evaluating the correctness of the content of the output is not easy, as we cannot compare it pixel by pixel, we rather need to determine whether a human being would see the content which they have sent to the printer. This means to recognize text, structures, colors, but with a certain tolerance.

      There is free software work at GNOME for the CI testing of their GUI, which requires to analyse graphical screen content to evaluate whether the response of GUI apps to given user input is as expected, and this should be fully automated. This is the openQA project.

      To compare graphical content they use the free software computer vision library OpenCV and also the universal file comparison tool diffoscope is used to check output.

      With this we could for example take a PDF file, rasterize it in high quality, then “print” it/send it through a filter chain and afterwards compare the images. We can also OCR raster output to check whether the complete text of the input (plain text or PDF file) is conserved in the output, not having anything cut off at the borders and no glyphs missing or replaced by squares/placeholders for missing glyphs.

      See also my report from the GUADEC 2024, the section “Workshop: openQA testing for your GNOME app, module or service”.

      Tests which benefit from this are not only our CI testing in libcupsfilters, but also 2 of our other projects on this list:

      Behavior-accurate simulation of multi-function printers
      Fuzz-based testing of printing protocols
      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), TBD

      Desired knowledge: C, Go, image processing and evaluation, computer vision, OCR

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      ~~~~~~~~~~
      Port CUPS and Printer Applications to Zephyr
      Probably many of you have already thought about that one can take an SBC, install Linux and CUPS or a Printer Application on it, and connect this to an old printer which is still mechanically perfect but needs a driver which is not available any more for some operating systems. Suddenly the printer turns into a modern, driverless IPP printer which can be used with any operating system.

      But it is a little awkward having a little box dangling behind the printer which also occupies a power outlet. Also one can perhaps also make use of much cheaper SBC.

      Imagine you could buy a tiny board for a few dollars and put it somewhere inside the printer and grab its power from the printer's power supply.

      Such tiny boards are often not powerful enough to run Linux, but there is also the much more lightweight Zephyr operating system. This is a system for IoT applications on low-footprint hardware.

      And this scenario does not only serve for cheap DIY solutions to save old printers, it also can be a base for cost-effective printer firmware development.

      This project is about investigating whether one could run the components of the free software printing stack, as CUPS, PAPPL, libcupsfilters, … under the Zephyr operating system, and actually let this tiny print server execute printer drivers and print on legacy printers. Also the handling of print data and the need of resources here needs to be investigated. Can we hold several pages? Can we use Ghostscript? Or do we have to stream raster print data from the client to the printer?

      Most desirable is to do this with PAPPL (Printer APPlication Library), as it is designed to emulate a driverless IPP printer in software, including the so-called “Gadget” mode to appear as an IPP-over-USB device when connecting the power supply USB port of the SBC with the client computer's USB.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Iuliana Prodan (iuliana dot prodan at nxp dot com), Zephyr developers TBD

      Desired knowledge: C, Zephyr, USB, network

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      ~~~~~~~~~~
      Rust bindings for libcups2/3
      1 contributor full-size (350 hours), Level of difficulty: Hard

      Most software with print functionality or print administration functionality uses the CUPS library (libcups, 2.x, 3.x) to communicate with CUPS. This is easy when the software is written in C or C++ as the library is written in C. If the software is written in other languages, we need some connection between the library and the client code, the so-called bindings.

      A programming language which gets more and more used nowadays is Rust, due to its memory-safety, eliminating the number-one source of crashes and vulnerabilities. Unfortunately, we do not have Rust bindings for libcups. And getting them is subject of this project.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), TBD

      Desired knowledge: Python, C, CUPS

      Code License: GPL-2+ (GPL 2 or any later version)

      ~~~~~~~~~~
      Error response pop-up support for CPDB
      1 contributor medium-size (175 hours), Level of difficulty: Intermediate

      It often happens that a print job, sent to a network printer or to a remote CUPS queue does not get printed and a "cups-pki-invalid" error will get logged. This is due to the fact that the locally saved certificate does not match the printer (any more).

      To prevent man-in-the-middle attacks between a client and a network IPP printer with encrypted connection, the first time when a new network printer is accessed, the printer's certificate is loaded from the printer and saved locally. On subsequent accesses the printer's certificate is compared to the locally saved one and on mismatch the error is logged and the printing does not happen.

      often this happens without an attack, just on a change of the printer configuration or a printer firmware update. Then the user screams on internet platforms, when they are lucky finds information about this problem and how to remove the old certificate to make the CUPS replace it by the current one and the printer print again.

      To solve this nasty problem, we came to the conclusion to pop up a dialog which allows to remove the certificate file ("Reset certificte") by clicking a button..

      The contributor's task here is to create such a dialog and make it pop up in the right situation. The pop-up should also be used for other common error scenarios which could be solved by a simple dialog.

      The communication between the pop-up and CUPS should be done by the Common Print Dialog Backends (CPDB), extending the D-Bus interface and implementing the error handling in the CPDB CUPS backend.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Gaurav Guleria (gaurav dot gen3 at gmail dot com), Kushagra Sharma (b20251 at students dot iitmandi dot ac dot in), TBD

      Desired knowledge: C/C++, GTK or Qt, DNS-SD/Avahi, CUPS/IPP

      Code License: MIT, GPL-2+ and LGPL-2+

      ~~~~~~~~~~
      CI Testing programs for libpappl-retrofit and libppd
      1 contributor full-size (350 hours), Level of difficulty: Intermediate

      To protect a free software project worked on by several contributors against regressions caused by a committed change, one needs frequent, automated testing of the code, base, ideally triggered by every commit into the repository. This is called Continuous Integration (CI).

      What is triggered on each commit is usually some static analysis of the code using common, specialized tools and also build and execution tests, usually doing `./configure; make; make test` on different system platforms.

      This naturally requires test scripts/programs which are compiled and run by the `make test` step. For CUPS for example the daemon is started (on an unprivileged port so that it does not need root), queues created and listed, jobs sent, the logs checked whether everything went OK, … For Ghostscript a large collection of input files (gathered from bug reports) is processed and converted into raster formats.

      The contributor's task here is to write test programs for the OpenPrinting projects libppd and pappl-retrofit so that `make test` does something useful, being efficient to catch regressions. They should exercise important functionality of the software with different parameters and analyse logs and output files to check whether the program did the expected work.

      Test programs are also needed for the so-called 'autopkgtest' tests which are added to Debian packages and executed whenever the package is uploaded to Debian or Ubuntu.

      In addition, instruction files and shell scripts are needed to build the software on different platforms/environments, run tests, create GitHub Actions (for the automatic triggering on each commit …).

      This subject got discussed on the OpenPrinting micro-conference on Linux Plumbers 2022: (Summary, Slides, Video)

      Here you can see what we already have in terms of CI, and what is missing …

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Michael Sweet, author of CUPS and PAPPL (msweet at msweet dot org), TBD

      Desired knowledge: C, Shell, PAPPL, CUPS, CI

      Code License: Apache 2.0

      ~~~~~~~~~~
      cups-filters: Create OCR filter to deliver scans as searchable PDFs
      1 contributor medium-size (175 hrs), Level of difficulty: Intermediate

      Scanning with IPP Scan gives the user the possibility to request the scanned image in PDF format. If the IPP Scan server is a Scanner Application, a filter function from cups-filters would convert the the raster image coming from the scanner into PDF.

      Now such PDF files are simply raster images in a PDF frame, not high-level graphics with text and fonts, as PDFs produced by office applications are. Especially one cannot search text in a PDF coming from a scanning process.

      Ghostscript has a new “pdfocr8” device with which Ghostscript takes raster graphics PDFs (or PostScript files) as input, applies OCR (Optical Character Recognition) to the raster image, and creates a PDF which contains the raster image to visually show the scan but adds data about the contained text and where it is located, so that you can find text with the search facility of a PDF viewer.

      Here the contributor's task is to write a filter function (or extend the ghostscript() filter function) to make the “pdfocr8” output device of Ghostscript being used so that a searchable PDF is obtained.

      Mentors: Till Kamppeter, Project Leader OpenPrinting (till at linux dot com), Sahil Arora (sahilarora dot 535 at gmail dot com), Dheeraj Yadav (dhirajyadav135 at gmail dot com), TBD

      Desired knowledge: C/C++, CUPS

      Code License: Apache 2.0



      Task #1 (large/350h): Extend AGL's demo control panel
      The AGL demo control panel is a pyQt (qml) application that is able to control the AGL demo homescreen. It can replay can messages.

      Task: Extend the demo control panel to drive more signals and exercise more advanced features in AGL.

      Level of difficulty: intermediate

      Requirements: QT, pyQT, QML, grpc, kuksa.val

      Contact: jsmoeller (at) linuxfoundation.org

      ~~~~~~~~~~

      Task #2 (large/350h): Extend AGL's speech recognition app (Flutter app) with AI features
      The AGL speech recognition app is a Flutter app that uses a speech recognition engine (vosk/whisper + intent engine) for the audio processing.

      Task: Extend the demo using AI models to allow more complex interactions and reactions. Requirement is to use open-source technologies.

      Level of difficulty: intermediate

      Requirements: python, flutter+dart

      Contact: jsmoeller (at) linuxfoundation.org


      ~~~~~~~~~~

      Task #3 (large/350h): meta-ros
      Task: Work on meta-ros integration. (Robotic framework). Goal is a demo image integrating ROS + AGL .

      Level of difficulty: intermediate/difficult

      Requirements: python, …

      Contact: jsmoeller (at) linuxfoundation.org


      ~~~~~~~~~~

      Create a Linux IIO driver for Analog Devices, Inc.'s ADE9113 Isolated, Sigma-Delta Analog to Digital Converter
      Project Size: 1 contributor medium (175 hours), Level of difficulty: Intermediate

      Desired knowledge: C, Bash, operating systems elementary concepts

      The driver should be tested on the real hardware. The proposed setup is Raspberry Pi 3 Model B and EVAL-ADE9113 evaluation board.

      The goal of the project is to provide support for ADE9113 chips within Linux which will require writing device tree documentation for ADE9113 and developing an IIO device driver. The desired final project state is to have ADE9113 driver and associated device tree documentation merged with upstream IIO tree.

      We are also open to suggestions for different ADI's components. If no suggestions are made, or they are not suitable for a GSoC project, we will choose one component for the accepted student(s).

      Mentors: Marcelo Schmitt, Dragos Bogdan

      Code repository: https://git.kernel.org/pub/scm/linux/kernel/git/jic23/iio.git/

      Code License: GPLv2

 

      ~~~~~~~~~~


      Project 1: Enhancing the SOF Demo GUI for Improved Usability and Functionality
      1 contributor medium-size (175 hours)

      Level of difficulty: Intermediate

      Sound Open Firmware (SOF) is an open source audio digital signal processing (DSP) firmware and an SDK that together provide infrastructure and development tools for developers working on audio or signal processing. More on this, you can find here: https://thesofproject.github.io/latest/introduction/index.html

      SOF has support for NXP, Intel, AMD and Mediatek targets.

      SOF comes with a set of runtime tools - command line applications that can be used to exchange data with running firmware and a demo GUI.

      The current GUI, while functional, lacks some modern usability features and doesn’t fully exploit the potential of SOF’s advanced capabilities.

      This project aims to improve and enhance the SOF Demo GUI, which is used to demonstrate and control SOF components on hardware. The goal is to add new features, improve the user interface, and enhance the overall usability and functionality of the GUI.

      This project will focus on creating a new version of the GUI with the following key improvements:

      Redesign the GUI to make it more intuitive and user-friendly;
      Implement a modern and responsive design using the latest GTK features;
      Display a real-time frequency spectrum to visualize the audio signal's frequency content;
      Provide step-by-step tutorials to guide new users through the features of the GUI.
      This will involve working with the existing codebase, implementing new features, and optimizing the current functionalities.

      This project will provide a more powerful and user-friendly tool for demonstrating and controlling SOF components, benefiting developers and users in the audio processing community. The enhancements will make it easier for new users to get started with SOF, while providing advanced features for experienced users.

      Expected Outcomes:

      A significantly improved SOF Demo GUI with enhanced usability and functionality.
      Comprehensive documentation and tutorials to help users understand and utilize the new features.
      A robust and well-tested codebase that can be easily maintained and extended in the future.
      Submit all enhancements back to SOF
      Skills Required:

      Python programming
      C programming
      GTK and GUI development
      Familiarity with version control systems (e.g., Git)
      Mentors:

      Iuliana Prodan iuliana.prodan@nxp.com
      George Stefan george.stefan@nxp.com


      ~~~~~~~~~~
      Project 2: Add Virtual DAI component to SOF
      1 contributor medium-size (175 hours)

      Level of difficulty: Intermediate

      We want to have a Virtual DAI for two reasons:

      debugging and rapid prototyping. We want to be able to create a quick audio pipeline without using a real DAI device.
      first step in implementing a software loopback pipeline that will help implement a memory to memory processing pipeleline
      The DAI should have two directions:

      playback → just get the data from source and do 'consume' it. Similar with /dev/null.
      capture → generate data (zeroes or some patterns) and send it to sink. Similar with /dev/zero or /dev/urandom
      Expected Outcomes:

      SOF Virtual DAI component implemented and merged upstream
      Simple pipeline with playback and record working
      Virtual DAI will log output frames and throw them out
      Record will generate frames filled with zeroes
      Skills Required:

      C programming
      Familiarity with version control systems (e.g., Git)
      Mentors:

      Daniel Baluta daniel.baluta@nxp.com


      ~~~~~~~~~~

      Project Idea: patch-hub v.1.0.0
      Details
      Project Size: 1 contributor full-size (350 hours)
      Level of Difficulty: Hard
      Helpful Experience: FLOSS development and Rust
      Description
      As mentioned before, in the GSoC 2025 edition, we intend to focus on a single project on the kw sub-project patch-hub. Linux kernel development is done via electronic mail and mailing lists, so instead of submitting pull requests on GitHub through the web, contributions, reviews, and the like are done by sending emails to other developers and mailing lists.

      Software development based on email may seem a little confusing, especially if you have never heard of it, but the important point is that even though there are some arguments in favor of it, there are many inefficiencies and complexities that come with it.

      patch-hub, following the kw spirit of simplifying workflows, aims to simplify the workflows of kernel developers when consuming from the development mailing lists. The tool is constructed as a Terminal UI (TUI), so it is a little less “roots” than a fully CLI system like the rest of kw, but still no graphical interface 8-)

      Below is a video of a simple demo of the tool. From listing the available development lists to consulting the flow of patchsets (a set of related patches, similar to a PR or an MR), their individual contents, and running actions on them, the tool aims to completely cover this part of kernel development.

      patch-hub demo video

      Don't forget to check out the patch-hub GitHub repo.

      Getting to Version 1
      As you can see in the demo video, patch-hub isn't in its initial stages, but there is a lot of work to be done. Currently, the latest released version is v0.1.4, and we are close to v0.2.0, which will be its beta.

      With that being said, between the beta and v1.0.0, there are many tasks to be made, which we can highlight:

      Redesign the architecture, as the technical debt is getting bigger
      Implement custom kernel build
      Implement inline review
      Make patchset reply with git send-email not teardown the UI
      Expand the unit test coverage, which is (being nice) small
      Enhance UI and UX
      And much more…
      The idea is not to strictly get to v1.0.0 by the end of the program but to get as near as possible. At least, we need a solid and robust base that will streamline the rest of the work!

      Interact with the kw/patch-hub community!
      Interacting with kw and patch-hub as a system/tool and a free software project is critical to grasping the dynamics and technical challenges you will face in your GSoC. This means it's nice to use kw and patch-hub to understand its purposes and functionalities while also reporting bugs and suggesting enhancements (take a look at patch-hub reported issues). Don't be afraid to open pull requests addressing them! We really encourage you to do it!

      As this edition focuses on patch-hub, we ask that you also focus the interaction on patch-hub. So, please open PRs, discuss issues, and the like on the [[https://github.com/kworkflow/patch-hub|patch-hub repo]]

      ~~~~~~~~~~


      Project 1: Running Open-Source ML Models on HiFi4 DSP with Zephyr RTOS
      Machine-Learning-related project

      1 contributor medium-size (175 hours)

      Level of difficulty: Intermediate

      Zephyr is an open-source, real-time operating system (RTOS) optimized for resource-constrained devices, making it ideal for IoT and embedded systems. It supports multiple architectures and has a modular design.

      For machine learning (ML) with Zephyr, developers can integrate frameworks like TensorFlow Lite for Microcontrollers (TFLM) or Edge Impulse. These allow small, efficient ML models to run on devices with limited CPU and memory resources.

      The i.MX series from NXP features powerful DSP cores that can offload computational workloads from the main CPU.

      This project will focus on leveraging Zephyr RTOS to manage ML workloads on these DSPs efficiently. It will require porting or optimizing existing ML frameworks for the DSP, designing APIs for seamless integration, and demonstrating an end-to-end ML pipeline running on Zephyr. Potential deliverables include support for TFLM on the DSP, and a sample application showcasing the implementation.

      Expected Outcomes:

      Integration of ML inference frameworks (such as TFLM) on NXP DSPs running Zephyr
      Sample applications demonstrating ML inference (e.g., speech recognition, anomaly detection)
      Documentation and tutorials for deploying ML workloads on NXP DSPs
      Submit pull requests to Zephyr’s upstream repository
      Skills Required:

      C/C++ programming
      Embedded systems and real-time operating systems (Zephyr)
      Familiarity with TensorFlow Lite Micro or similar lightweight ML frameworks
      Familiarity with version control systems (e.g., Git)
      Mentors:

      Iuliana Prodan iuliana.prodan@nxp.com
      George Stefan george.stefan@nxp.com
      Daniel Baluta daniel.baluta@gmail.com
      Laurentiu Mihalcea laurentiu.mihalcea@nxp.com



      ~~~~~~~~~~
      Project 2: Port CUPS and Printer Applications to Zephyr
      1 contributor full-size (350 hours)

      Level of difficulty: Intermediate

      Probably many of you have already thought about that one can take an SBC, install Linux and CUPS or a Printer Application on it, and connect this to an old printer which is still mechanically perfect but needs a driver which is not available any more for some operating systems. Suddenly the printer turns into a modern, driverless IPP printer which can be used with any operating system.

      But it is a little awkward having a little box dangling behind the printer which also occupies a power outlet. Also one can perhaps also make use of much cheaper SBC.

      Imagine you could buy a tiny board for a few dollars and put it somewhere inside the printer and grab its power from the printer's power supply.

      Such tiny boards are often not powerful enough to run Linux, but there is also the much more lightweight Zephyr operating system. This is a system for IoT applications on low-footprint hardware.

      And this scenario does not only serve for cheap DIY solutions to save old printers, it also can be a base for cost-effective printer firmware development.

      This project is about investigating whether one could run the components of the free software printing stack, as CUPS, PAPPL, libcupsfilters, … under the Zephyr operating system, and actually let this tiny print server execute printer drivers and print on legacy printers. Also the handling of print data and the need of resources here needs to be investigated. Can we hold several pages? Can we use Ghostscript? Or do we have to stream raster print data from the client to the printer?

      Most desirable is to do this with PAPPL (Printer APPlication Library), as it is designed to emulate a driverless IPP printer in software, including the so-called “Gadget” mode to appear as an IPP-over-USB device when connecting the power supply USB port of the SBC with the client computer's USB.

      Code License: Apache 2.0, MIT (licenses of the OpenPrinting projects)

      Skills Required:

      C/C++ programming
      Embedded systems and real-time operating systems (Zephyr)
      Familiarity with version control systems (e.g., Git)
      Mentors:

      Till Kamppeter till@linux.com (Project lead OpenPrinting)
      Iuliana Prodan iuliana.prodan@nxp.com
      Zephyr Developes TBD

      ~~~~~~~~~~

      SBOM Conformance Checker

      Create a web accessible tool for validating SPDX 3.0 documents.

      Size: Medium (175 hours)

      Level of Difficulty: Hard

      Skills Needed:

      Software development skills for Web based applications
      Good user interface design skills
      Understanding of SBOM conformance and related standards/regulations such
      has CISA Common Software Bill of Materials or EU AI Act

      Background Information:

      An online form which allows the uploading, parsing, and validation of SPDX 3.0 would provide immediate benefit to the SPDX community. There is no specific programming language requirement, but there is an existing Java and Python libraries which could be used in the project. Some of the technical challenges for this project include having to handle long running operations and implementing a very robust parser implementation able to handle any input.

      Available Mentors: John Speed Meyers, Gary O'Neall (gary at sourceauditor dot com)

      




      
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-linux-foundation/
    idea_list_url: https://wiki.linuxfoundation.org/gsoc/google-summer-code-2025


  - organization_id: 156
    organization_name: The Mifos Initiative
    no_of_ideas: 40 
    ideas_content: |

      Migrate Android Client to Kotlin Multiplatform 
      Mentors
      @Rajan Maurya @Chinmay Kulkarni @Shashank Priyadarshi 
      Length
      Large - 350 hours
      Category
      Mobile - Android SDK | Kotlin Multiplatform
      Overview & Objectives
      The goal of this project is to migrate Android field officer kotlin multi-module application to Kotlin Multiplatform and rewrite network layer by adopting fineract-client-kmp-sdk, make all the network calls are working as expected. The Android client will be the first of the Mifos mobile apps which consume the SDK, reducing repeated network layer code in mobile apps, improving developer experience, and making it easier to migrate to newer versions of Apache Fineract 1.x and Student would work on designing offline sync functionality in background.
      This year we are totally focusing on migrating to Kotlin Multiplatform, writing Unit and Instrumentation test and writing github actions to automate release process using fastlane.
      Description
      In 2025, The student will be working on implementing the following things:
      Update the Android client to latest dependencies
      Rewrite Network layer of Android client to consume fineract SDK using coroutines instead of RxJava implemented code.
      Migrate kotlin multi-module codebase to Kotlin Multiplatform
      Write appropiate unit and integration tests.
      Update CI/CD to build APK and analyses code quality
      Implemented Playstore release github action pipeline
      Integrate google playstore API for better and faster release flow.
      Update corresponding documentation for building the app.
        Helpful Skills
      Android, Kotlin Multiplatform, Kotlin, Jetpack compose, navigation-compose, MVVM, coroutines, Flow, multi-module architecture.
      Impact
      High performance using jetpack compose
      Clean code and easy understandable code because of multi-module and coroutines implementation. 
      Kotlin Multiplatform support to build application for Android, IOS, Desktop, Web.
      Overall stability by increased testing coverage through a more stable and error-free codebase. 
      Improved developer experience through faster build time. 
      More seamless release management and upstream contribution 
      Reduction of time to upgrade 
      Other Resources
      QA & Testing - 
      QA & Testing - Fineract - Apache Software Foundation  
      2024 GSOC Final Report (Aditya Gupta): 
      GSoC'24_Final_Report_Android_client.md 
      Github
      GitHub - openMF/android-client: An android client for the MifosX platform 
      GitHub - apache/fineract: Apache Fineract 
      GitHub - openMF/fineract-client: Mifos Fineract Client is a Java based library that provides a simple interface to interact with the Apache Fineract 1.x Platform APIs 
      GitHub - openMF/fineract-android-sdk: This is architecture repository for mifos-android-sdk 
      
      
      ~~~~~~~~~~

      
      Making Mobile Wallet Deployment-Ready for G2P and Merchant Use Cases
      Mentors
      @Rajan Maurya @Avinash Vijayvargiya 
      Length
      Large - 350 hours
      Category
      Mobile - Mifos X | Core Development
      Overview & Objectives
      2025 development will focus on refining our current Mobile Wallet to be a strong reference implementation of feature-rich and secure mobile wallet application for G2P use cases. While our mobile wallet is a powerful tool for all fintechs and financial institutions, we want to powerfully and simply demonstrate the ability for governments to disburse G2P Payments to highly functional mobile wallet and then be able to transact with that wallet by paying for bills, sending transfers, and paying for goods and services via merchants. We provide a reference mobile wallet application for consumers and merchants that has been developed by our Google Summer of Code interns from 2017 to 2024. The mobile wallet provides an extensible mobile wallet framework to support the basic use cases of a mobile wallet as documented in the Level One Project mobile wallet requirements. This extensible framework should support both merchant and client use cases as well as be capable of integrating with a Fineract back-end 
      Over time, we would like Mifos X to be more generically a wallet management system and this reference application is a powerful tool to support that. 
      In 2025, we will also focus on enabling real-world merchant flows based on requirements from in-country users using the wallets for consumer to merachnt transactions. 
      Description
      The initial mobile wallet framework along with 2 reference apps, PixieCollect and MifosPay, were developed in 2017. Later we decided to continue with MifosPay application only which as mentioned uses the mobile wallet framework.
      In 2019, these functionalities were extended further by Shivansh including improving user experience and redesigning the app, support for Kotlin, integration with two Mojaloop transaction flows via the Paymeht Hub, adding improving Deeplinks, support for standing instructions and more well-rounded support for merchant transactions.
      In 2020, Devansh Aggarwal further added complete support for standing instructions, integrated with Fineract CN for core use cases by mapping Fineract back-office APIs to Fineract CN APIs, added multi-theme support, completed integration with Payment Hub EE, added support for Hover, and converted Java code to Kotlin (in progress). For more details refer this
      In 2021, Kinar Sharma, worked on developing a new multiplatform mobile wallet application using Kotlin multi-platform. This new application consumes FineractCN APIs and is built upon clean architecture. Kinar completed the data, domain and presentation layer (only for Android) for usecases available in FineractCN.
      In 2022, Prashant Singh continued to evolve the app.
      In 2023, Rachit focused on refining the architecture, streamlining the design and implementing some of the G2P use cases.
      In 2024, Pratyush focused on migrating codebase from single module app into kotlin multi-module application by migrating xml to jetpack compose.
      In 2025, we are targeting to make production-ready our cases for G2P, update dependencies, consume more uniformly our SDKs fix pending issues and introduce new features. Functional enhancements include:
      Integrate latest version of Payment Hub EE
      Integrate Mifos' notifications framework to provide support for usecases like merchant request to pay.
      Implemented Apple Store and Desktop apps release github action pipeline
      Update wallet framework to be make use of Mifos' Android SDK
      Improving the security framework to integrate more seamlessly with middlewares, API gateway, and identity management software
      Exploring proof of concept architecture or redesigns to align with movements like the Open Wallet Foundation.
      Write end to end Unit and Instrumentation test suite.
      Helpful Skills
      Android, Kotlin, Kotlin Multiplatform, Jetpack compose, Ktor, Room, Git
      Impact
      By providing an extensible mobile wallet framework, allow partners a complete reference stack of back and front-end applications to offer digital financial services to clients.
      Other Resources
      2024 Mobile Wallet Final Report (Pratyush Singh): 
      GSoC'24_Final_Report_Mobile_Wallet.md | Aditya Kumdale: 
      GSoC'24 Final Report - The Mifos Initiative | Functional Enhancements to Mobile Wallet for G2P Use Cases 
      2023 Mobile Wallet Final Report: 
      GSoC 2023: Final Work Submission 
      2020 Mobile Wallet Progress: https://gist.github.com/devansh-299/e2041c07d9ab55a747391951e9090df4
      Mobile Wallet Framework: Source Code | Issue Tracker  | Slack
      See 
      Mifos Wallet 

      ~~~~~~~~~~
      Integrate Mifos X with Workflow Engine/Process Automation Tool 
      Mentors
      @Aleksandar Vidakovic @Victor Romero 
      Length
      Large - 350 hours
      Category
      Back-end Platform | Modules 
      Overview & Objectives
      Users of Mifos have long had a need to have greater control and flexibility over creating loan and customer onboarding workflows that incorporate internal processes/steps as well processes involving external systems. This project would center around creating an external integration with a workflow engine such as Flowable or jBPM using the Mifos X REST API as the glue. The auto-generated client library from the back-end enforces the contract between the workflow engine and core banking system. The core banking and its REST API act as the glue. The result would be a UI-driven workflow engine to allow non-technical users to define these new custom workflows where they could drag and drop the different steps of the process. 
      Description
      Assumptions:
      BPMN should be adopted as a standard so which can make the workflow engine independent of the technology stack. 
      BPMN editors allow end users to sketch the workflow and generate a machine readable and executable output. 
      Workflow actions or business logic would be written in Java as part of Fineract so adapters will be need to be created on the workflow engine to execute actions on our side. 
      External processes would be sub-flows that could be used like lego bricks and included in the parent workflow context. 
       Steps:
      Intern would select a workflow engine to integrate with and then build adapters to trigger and transfer fm BPMN form data into specific core banking back-office REST API calls. 
      Currently business logic such as creating a customer is triggered by an API call in Fineract. For this project, the intern would define a BPMN form with all the data that is needed which could be defined as a human task. Proceeding through each step triggers an adapter that transforms the generic BPMN form data into specific core banking back-office REST API calls
      Intern would go through the entire REST API building these adapters to trigger transformation of BPMN into core banking back-office REST API callsCurrently when creating a customer, API by API, the intern would define 
      Once all the calls in Mifos X have been transformed, the integration could provide for triggering any external  customer-specific action/workflow/API call/ system integration
      Helpful Skills
      Java, BPMN
      Impact
      UI-Driven interface based on BPMN standard to allow for non-technical users to define customer onboarding and application workflows via a drag and drop interface.
      Other Resources
      Flowable 
      jBPM Business Automation Toolkit 
      BPMN Specification - Business Process Model and Notation 
      Transforming ICT4D: OpenFn's Workflow Automation Platform 
      n8n.io - a powerful workflow automation tool  

      ~~~~~~~~~~ 
      Build new Modern Web UI for Mifos X using ShadCN Reusable Components 
      Mentors
      @Aleksandar Vidakovic 
      Length
      Large - 350 hours
      Category
      Front-End - Web
      Overview & Objectives
      This project would extend up on existing efforts to create a micro front-end approach for our UIs. As the userbase for Mifos/Fineract extends beyond just microfinance and financial inclusion we need to enable developers to easily build front-end user experiences that align with the wide variety of back-end use cases supported by our platform being used by MFIs, credit unions, banks, fintechs and governments. Additionally, many of the flow and screens used by staff as well as customers are common across mobile and web application. 
      Right now the look and feel and the overal UI development experience is very limited by using Angular and Material Design. 
      Description
      This project would aim to build both the micro front-end framework and leverage a set of res-usable UI components that can be deployed as individual flows or end to end applications. Growing in popularity for its flexibility, ease of development, efficient performance, modular design is the ShadCN UI Library which contains unstyle components offering a higher degree of customizability. 
      The current standard UI for Mifos X is still the Web App which is the only one that covers 100% of the feature set. While based on Angular and more modern than our previous Community App, the project hard to maintain and - apart from the occasional color change - hard to customize let alone integrate in other web applications. Developers should be able to pick any number of standalone components and integrate them in custom UI projects (where Fineract is one among multiple backends). All Mifos X UI components should be published for easy consumption by other developers.
      Intern would aim to replicate the current Web UI which is in Angular using the Material Design library using ShadCN components built on ReactJS. 
      This project would use the official typescript API client for Fineract. 
      Tooling should help with consistency and reduce handwritten code as much as possible. Using Monorepos is strongly suggested.
      Helpful Skills
      JavaScript, JSX , React, Tailwind CSS 
      Impact
      Developers can more rapidly build out user interfaces for different financial service use cases with a greater degree of design flexibility in terms of customizability of the look and feel  
      Other Resources
      Build your component library - shadcn/ui 
      What is Shadcn UI and why you should use it? 
      Tailwind CSS - Rapidly build modern websites without ever leaving your HTML. 
      Radix UI 

      ~~~~~~~~~~
      Extend and Evolve UI Library of common components across all Mobile Apps
      Mentors
      @Chinmay Kulkarni  @Devansh Aggarwal @raul.sibaja
      Length
      Large - 350 hours
      Category
      Mobile - Mifos X | Core Development | Infrastructure 
      Overview & Objectives
      For 2025, our efforts this project will focus on delivering components that can be utilized as part of Compose Multiplatform and in conjunction with resuable components like ShadCN. 
       In 2022, Rahul Gill, created and completed the first iteration of our UI library for our mobile apps. Our suite of customer-facing mobile applications include our mobile wallet framework, and mobile banking apps for Fineract 1.x and Fineract CN. These are designed to serve as reference implementations for demonstration purposes but also to act as secure and robust starting dough that can be extended and enhanced and white-labeled.
      With the move towards more digital financial services, these reference solutions are ever more important and critical and must appear highly polished, clean, and professional. We are working with a designer to provide a set of clean, consistent and professional UI designs and workflows to implement across our customer-facing apps. 
      This project would focus on implementing these new designs across the customer-facing apps providing a consistent and familiar look and feel. It will build off of efforts in 2020 and 2021 implementing the UI designs previously proposed during GCI. 
      Across all our mobile apps, there are common screens and workflows  with a lot of redundant and inconsistent design and development from scratch. The creation of a UI library of common shared components and design standards and guidelines would enable the following: 
      Improve developer experience and ease of development
      Consistent look and feel of UIs for all apps
      Defined process for updating apps.
      Develop common UI library to ensure consistency of all apps
      Design guidelines, principles, and standards
      Could potentially be a valuable upstream project in and of itself to create mobile fintech apps
      Description
      In 2025, with leadership of our mentors, this project would focus on extening the initial shared components of the UI library based off of the common screens and workflows identified across the various mobile apps. These common flows will be broken down into their-base-level elements and components.  This components should be built to be compatible with Compose Multiplatform for re-usability across mobile, web, and desktop. 
      Design enhancements to customer-facing apps include: 
      Break down common workflows into base-level components
      Refine and update design standards and guidelines
      Create and set up repository to house elements, components, and designs using jetpack compose.
      Design core ui component for our fintech app using jetpack compose. 
      Develop and create base-level elements and components accoring to UI design standards and guidelines
      Implement screens and workflows to test out on reference open banking fintech app
      Documentation to ensure how to use UI library and update mobile app when UI library is updated. 
      Helpful Skills
      Android Development, Kotlin, Java, Jetpack Compose, XML, Git, Compose Multiplatform
      Impact
      A clean and simple UI is key for our low-tech audience and professional and consistent look and feel enhances credibility of our stack. 
      Other Resources
      Recap on 2022 GSOC Project from Rahul Gill: 
      GSoC '22 Report | The Mifos Initiative | Mifos Android UI library 
      Mobile App UI Library 
      2020 UI Enhancements: https://gist.github.com/ShivangiSingh17/67b6041387c1e281caa7df23347f549e
      Mobile Wallet Framework: Source Code | Issue Tracker | Slack
      Mifos Mobile - Android Mobile Banking App: Source Code | Issue Tracker | Gitter Chatroom
      See https://openmf.github.io/mobileapps.github.io/
      
      ~~~~~~~~~~
      
      Mifos Gazelle: Postman Coverage
      Mentors
      @David Higgins + TBC
      Length
      Large - 350 hours 
      Category
      Platform | DevOps  | Mifos Gazelle
      Overview & Objectives
      Mifos Gazelle brings together multiple components and DPG’s into a single deployment process. A key objective for Gazelle is ease of deployment and ease of use.  To that end Mifos Gazelle needs to maintain good documentation and Postman collections of all its API’s (including those of components).
      Description
      This project would focus on gathering together all the API’s within Gazelle components into a single Postman collection.
      Mifos Gazelle users and PHEE, MifosX and vNext users and learners would benefit greatly from a targeted and well tested postman collection and associated environment.  This would draw heavily from the existing postman tests for MifosX PaymentHub and vNext perhaps a subset from each and would be specifically customised and organised for a Mifos gazelle deployment of all 3 initial components.  This collection would be included in the Mifos Gazelle repository and would also be well documented perhaps with a step by step guide for a number of test scenarios (Mifos Partylookup, vNext PartyLookuop, Bulk Payment etc ) 
      The collection could be very specific for instance hostnames could be set in the environment which are aligned with the Mifos gazelle deployment scripts and well known data (tenants, parties etc) would be utilised. 
      The folder structure of the collection would also be customised to reflect the Mifos Gazelle deployment 
      The design needs to be extendable beyond the initial 3 components as Mifos Gazelle grows.
      Helpful Skills
      Docker, Kubernetes, Jenkins, Bash, REST APIs , Postman.
      Impact
      DevOps and Sys Admins running our projects would experience a more simplified deployment with greater degree of control, improved quality of their builds and greater reliability and ease of testing through a qualified and reliable Postman collection
      Other Resources
      GAZ-13 - create Mifos Gazelle specifc postman collection TO DO

      ~~~~~~~~~~  
      Voice-Driven Banking via Large Acoustic Models (LAMs) (AI)
      Mentors
       @Lalit Mohan S @Akshat sharma 
      Length
      Large - 350 hours 
      Category
      AI | Platform - Modules  | Exploratory
      Overview & Objectives
      The "Voice-Driven Banking via Large Acoustic Models (LAMs)" project develops a voice-based banking platform to enable financial transactions in low-resource languages and dialects. The system will support tasks like balance inquiries, fund transfers, credit applications, and more using voice commands, removing barriers of literacy and technical skills. This initiative targets rural and underserved populations, promoting financial inclusion through innovative AI solutions.
      Objectives
      Technical: Build and deploy LAMs for regional languages and accents, integrated with NLP for intent recognition and voice biometrics for secure authentication.
      Business: Expand access to banking services, improve customer engagement, and reduce service costs via automation.
      Social: Empower non-literate users in underserved areas with seamless access to financial tools.
      Impact and Outcome
      Impact
      Technical: Robust voice recognition for low-resource languages, secure voice authentication, and modular scalability for future enhancements.
      Business: Increased customer base, lower operational costs, and improved satisfaction.
      Social: Enhanced financial access for marginalized groups and improved digital literacy.
      Outcome
      Application: Mobile/web app supporting voice-driven banking in multiple regional languages.
      Capabilities: Voice-initiated transactions (balance checks, payments, loans) with real-time processing.
      Security: Voice biometrics and encrypted transactions for data integrity.
      Analytics: Dashboards to monitor usage and improve language support.
      The final product will simplify banking for rural users, bridging the digital divide and boosting financial inclusion effectively.
      The idea behind this project is to use a LLM to give command/prompts and have those commands fulfilled via selenium
      Description
      The "Voice-Driven Banking via LAMs" project focuses on creating a voice-based banking platform supporting low-resource languages and dialects. The intern will:
      Research: Identify target languages and user needs for voice-based banking tasks.
      Develop Core Features:
      Train/optimize Large Acoustic Models (LAMs) for voice recognition.
      Build NLP pipelines for multilingual intent recognition.
      Integrate voice biometrics for secure authentication.
      System Integration: Design a scalable backend and integrate workflows (e.g., balance checks, payments) with banking systems.
      Testing & Optimization: Conduct accuracy and reliability testing, refine models, and ensure accessibility on low-end devices.
      Documentation: Deliver technical documentation, user guides, and training materials in target languages.
      Expected Deliverables
      A functional voice-based banking app supporting multiple languages.
      Secure voice-enabled workflows for key banking operations
      Documentation and guides for system use and maintenance.
      
      Helpful Skills
      Python, TensorFlow, PyTorch, Natural Language Processing (NLP), Large Acoustic Models (LAMs), speech-to-text systems, voice biometrics, API development
      Impact
      This project will have a significant impact by promoting financial inclusion, especially for underserved and rural populations. By enabling voice-driven banking in multiple low-resource languages, it empowers individuals who may be illiterate or lack digital skills to manage their finances independently. From a business perspective, it opens new customer segments, reduces operational costs through automation, and drives customer loyalty. Technically, the project advances voice recognition, natural language processing, and secure authentication systems, pushing the boundaries of AI in financial services. Ultimately, this initiative fosters social equality, digital literacy, and economic stability, while innovating how banking can be made accessible to all.
      Other Resources
      Documentation on Speech-to-Text and Voice Recognition
      DeepSpeech GitHub(
      GitHub - mozilla/DeepSpeech: DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers. ) – Mozilla’s speech-to-text model that may be useful for voice recognition tasks.
      Kaldi(
      Kaldi ASR ) – An open-source toolkit for speech recognition, widely used in research.
      Large Acoustic Models (LAMs) and NLP Resources
      Speech Recognition with Deep Learning – A tutorial on speech recognition using TensorFlow.
      Transformers by Hugging Face – A popular NLP library that could be adapted for multilingual NLP tasks.
      Voice Biometrics and Security
      Voice Authentication System (API) – Twilio API for implementing voice biometrics in applications.
      General AI and Machine Learning for Banking
      AI in Financial Services – An article detailing AI applications in the financial sector.
      Financial Services AI – A report from Accenture on the future of AI in banking.
      
      ~~~~~~~~~~
      LAM (Large Action Model) for Fineract (AI)
      Mentors
      @jeremy engelbrecht 
      Length
      Large - 350 hours 
      Category
      AI | Platform - Modules  | Exploratory
      Overview & Objectives
      The idea behind this project is to use a LLM to give command/prompts and have those commands fulfilled via selenium
      Description
      Following the similar types of commands/actions that can be executed in Fineract via our chatbot, this project would use LLMs to determine the intent of a user and fulfill those actions in the Mifos/Fineract applications using a tool like Selenium. 
      Helpful Skills
      Python, LLM(Llama2 or similar), Selenium
      Impact
      This would dramatically change the way individuals interact with financial services. It goes well beyond a chatbot by being able to engage with a tool that can apply for and initiate financial transactions via prompts. 
      Other Resources
       XGBoost Documentation — xgboost 2.1.3 documentation 

      ~~~~~~~~~~
      Generative AI to Improve Mifos Documentation 
      Mentors
      @jeremy engelbrecht @Lalit Mohan S @David Higgins 
      Length
      Large - 350 hours 
      Category
      AI | Platform - Modules  | Exploratory
      Overview & Objectives
      Mifos & Apache Fineract provide a suite of core banking applications which are highly complex applications both from a technical and domain knowledge perspective. 
      Maintaining updated documentation around installing, configuring and using the application is challenging and presents a steep learning curve.
      The goal of this project is to use Generative Pretrained Transformer (GPTs) (which is a family of large language models (LLMs) based on a transformer deep learning architecture) for providing answers  to most common questions and for organizing documentation. It is important to ingest data for training this GPT using the manuals, source code repositories, Wiki, ReadMes, mailing list posts, forum posts, slack discussion, and documentation hosted on our project sites, it would greatly simplify the experience for any implementer looking to use the software.
      Description
      In 2025 the Intern would develop/train a GPT using all the sources of technical and user documentation across our project such that implementers could interact with the documentation in a Q&A style format.
      In 2024 in an initial increment of this project an LLM was created that was trained on a specific subset of documentation.
      In 2025 focus needs to be on how this can be scaled across the full documentation set, how to resolve conflicts in answers when you look at large scale documentation.  
      AI tools have changed significantly in the last year that the approach should be changed so then the interaction with them can be implemented using agents.
      An alternative focus of this project could be how to use AI to generate or update documentation at the point of release.
      Helpful Skills
      Hugging Face, LlaMA, Colab, GPT, N8N.
      Impact
      This would greatly simplify the process of configuring, deploying and using our core banking software across various use cases making the software and documentation more maintainable for the project and more usable for the customer base. 
      Other Resources
      What is Generative AI?  | IBM  
      What is a Transformer Model? | IBM  
      Generative AI: Answering Your Frequently Asked Questions | Synechron  
       https://huggingface.co/docs/transformers/model_doc/llama2 
      2024 Mifos Summer Intern Final Showcase -  GSOC - Shubham Pal  - Generative AI for Community Support 
      
      
      ~~~~~~~~~~
      Fraud & Risk Management & Transaction Monitoring POC (Tazama) (AI) 
      Mentors
      @jeremy engelbrecht @Lalit Mohan S @Aleksandar Vidakovic 
      Length
      Large - 350 hours 
      Category
      AI | Platform - Modules  | Exploratory
      Overview & Objectives
      With continually growing adoption of Payment Hub EE to connect fiancial institutions using or not using Fineract into real-time payment systems, the likelihood of fraud is ever-growing. With all of this transactional data flowing into and out of Fineract, there is now also a wealth of data to analyze using rule-based and AI-based methods to detect transactional patterns and identify fraud. A lot of fraud detection and transaction monitoring happens centrally at the level of the payment switch but there’s quite a bit of value in analyzing this at the level of each individual DFSP and sharing this on-us transaction data back to the central payment switch or system
      Goal of this project would be to work on a proof of concept integration between Mifos/Fineract and Payment Hub EE with a FRMS solution for fraud detection and transaction monitoring. Given the power and potential of generative AI for financial services, project shoudl explore the use of generative AI for the following areas as documented by Newron:
       Anomaly Detection: Generative AI models can create synthetic data that mimics legitimate transactions. By training on both genuine and synthetic data, models become adept at detecting unusual patterns indicative of fraud.
      Adaptability: Unlike rule-based systems, Generative AI models can adapt to new fraud patterns. As fraudsters evolve, the model evolves with them, improving detection rates.
      Data Augmentation: Generative AI can augment imbalanced datasets by creating synthetic examples of rare events (fraudulent transactions), making the model more robust.
      Unsupervised Learning: Generative AI models, like Variational Autoencoders (VAEs) or Generative Adversarial Networks (GANs), learn patterns in an unsupervised manner, reducing the need for manual labeling of fraudulent cases.
      Behavioural Analysis: Generative AI can analyze transaction behaviours, such as user interactions or purchasing habits, to identify deviations from the norm
      Project could be integrated with Tazama which although rule-based and not AI-based provides a powerful FRMS solution. 
      Description
      Intern would work on a POC integration to monitor and analyze data from real-time payment system flowing via Payment Hub EE into Fineract. Project could utilize generative AI to improve effectiveness of solutiona and can leverage existing efforts in the community to collaborate with eKuta solution. 
      Helpful Skills
      Hugging Face transformer, Llama2 or similar, Colab
      Impact
      Real-time payments make the challenges and consequences of fraud ever more steep and severe. Using Generative AI to combat it and integrating with FRMS solutions will help the user base using Payment Hub EE and Fineract. 
      Other Resources
       Revolutionising Fraud Detection with Generative AI 
      Open Source Solution FRMS Solution - Tazama - 
      Home 

      ~~~~~~~~~~
      Kotlin Multiplatform App Template Framework 
      Mentors
      @Rajan Maurya 
      Length
      Large - 350 hours
      Category
      Mobile, Kotlin Multiplatform, Compose Multiplatform
      Overview & Objectives
      Throughout 2024, we continued migrating all of our mobile apps to Kotlin Multiplatform and in the processed developed some valuable generic tools and templates to help with building out applications using Kotlin Multiplatform. This project would continue to refine and extend these frameworks. 
      Description
      The focus for 2025 on this project would be the following: 
      Write Material Design3 component layer that can be customizable on top level so anyone forking the repo and creating a project can just add the theme configuration and rest is maintainable in template.
      Write base configuration for Android, Ios, Desktop, Web so whoever is creating project out of template will only adding configuration that will replace the default one.
      Write release github actions for all the platform Android, Ios, Desktop, web using Github Actions.
      Write network, database, datastore etc base layer so it will act like external component can be or can’t be added in the project.
      Write Gradle plugin for dependencies like Room, datastore, ktor, compose etc so it can behave as component and we can have introduce Amper as an alternative for build system.
      Make sync common directories more generic.
      Helpful Skills
      Android, Kotlin, Kotlin Multiplatform, Jetpack compose, Ktor, Room, Git
      Impact
      Streamling the developer experience and reducing the learning curve for building cross-platform apps with native user experiences on top of Kotlin Multiplatform. 
      Other Resources
      Source Code
      GitHub - openMF/kmp-project-template: The Kotlin Multiplatform Multi-module Template generator simplifies cross-platform development by enabling shared business logic and UI components across Android, iOS, Desktop, and Web, while retaining native platform functionality. 
      
      ~~~~~~~~~~
      
      Kotlin Multiplatform App Health Framework 
      Mentors
      @Rajan Maurya 
      Length
      Large - 350 hours
      Category
      Mobile, Kotlin Multiplatform, Compose Multiplatform
      Overview & Objectives
      Throughout 2024, we continued migrating all of our mobile apps to Kotlin Multiplatform and in the processed developed some valuable generic tools and templates to help with building out applications using Kotlin Multiplatform. We realized over past experience that we need a Kotlin Multiplatform tool that checks and take care of app health and give out summary of app breaking points and manage whole thing locally and as well as pushes to firebase logging so we can know where exactly the problem lies instead of walking to crash analytics.
      Description
      The focus for 2025 on this project would be the following: 
      Designing a plan and Product specs.
      Write a local database layer that will store all data required to debug the crash, issue etc.
      Write a sync layer for Kotlin Multiplatform that gives ability to pull issues and debug stream data to fix the issue.
      Design a frame work that will take write in firebase events and manage in such a manner so we can find where issue lies.
      Write a layer that will look for memory leak in the code and analyze and suggest fixes using AI
      Give ability user to expose or keep whole thing locally.
      Write logging layer that will be annotation based and log things for debugging.
      Helpful Skills
      Android, Kotlin, Kotlin Multiplatform, Jetpack compose, Ktor, Room, Git
      Impact
      Streamling the developer experience and reducing the learning curve for building cross-platform apps with native user experiences on top of Kotlin Multiplatform. 
      Other Resources
      Source Code: 
      openMF/app-health-kmp 

      ~~~~~~~~~~
      Open Banking/PISP Fintech App Framework Version 3.0 (GovTech)
      Mentors
      @Shashank Priyadarshi 
      Length
      Large - 350 hours
      Category
      Mobile, Exploratory
      Overview & Objectives
      The 2025 focus for this project would be extending upon the work that was done during Code for GovTech in 2024. Across our ecosystem we're seeing more and more adoption and innovation from fintechs. A huge democratizing force across the financial services sector is the Open Banking movement providing Open Banking APIs to enable third parties to directly interact with customers of financial institutions. We have recently started providing an Open Banking API layer that will allow financial institutions using Mifos and Fineract to offer third parties access to requesting account information and initiating payments via these APIs. Most recently the Mojaloop community, led by Google, has led the development of a centralized PISP API
      To demonstrate these Open Banking APIs and use cases that third parties and fintechs can provide we have developed a cross-platform reference mobile app on Kotlin to showcase a number of these features. It currently connects with the Open Bank Project that adheres to the UK Open Banking API standard. The API Gateway to connect to is still being chosen (WS02, Gravitee, etc.)
      The breadth and variety of apps that could be built leveraging these APIs from region to region is endless. We would like this app to be built in an extensible and modular fashion such that core libraries and components could be re-used across different use cases with this framework as the foundation and multiple reference apps on top. Applications include personal financial management apps aggregating information from multiple bank accounts in one place, wallet apps allowing payments to be made from different banks, lending apps, leveraging data and insight from multiple accounts, savings apps, etc.
      Description
      Intern would work on refining the initial architecture of the framework, the UI and user experience, core use cases including customer authentication and onboarding that was implemented in 2020 and integrating with the Fineract Open Banking APIs and Mojaloop PISP APIs to demonstrate use cases around account information request and payment initiation. 
      This would be a continuation of the project worked on a couple year’s back but essentially the idea is the same to have a stand-alone reference third party fintech app that demonstrates 3rd party initiation/ Open Banking APIs so the app itself would need its own separate user managment, etc but then it would pull in data by authorizing consnet via open banking api to pull in transactional data from a mifos/fineract account (could extend exiting open banking adapter and map additional fineract apis to UK open banking api standard and most importantly we’d want to use this reference fintech app to demonstrate the use of Mojaloop/Google 3PPI PISP APIs whereby a user could authorize and establish consent across any bank participating in a mojaloop switch to the fintech to initiate transactions through mojaloop via their accounts managed in Mifos/Fineract
      Aggregating account information across multiple banks/financial institution
      Initiating payments across multiple financial institutions
      Integrate with additional Fineract Open Banking APIs
      Integrate with Mojaloop PISP APIs. 
      Leverage completed components of UI library 
      Helpful Skills
      Android development, SQL, Java, Javascript, Git, Spring, OpenJPA, Rest, Kotlin, Mojaloop
      Impact
      By providing an extensible open banking fintech app framework, allow partners a complete stack of Open Banking APIs and reference front-end application to rapidly build innovation via Open Banking APIs.   
      Other Resources
      Source code: 
      GitHub - openMF/pisp-app: Repository for app for third party payment initiation use cases (PISP, Open Banking, 3PPI) 
      Figma Design Mockups: 
      Mifos PISP App 
      Previous Development:
      2023 Mifos Summer of Code Final Report - 
      MSoC'23-pisp-app-report.md 
      2020 Google Summer of Code Final Report - 
      Google Summer of Code 2020: Mifos Open Banking App | Report by Ankur Sharma 
      Google Whitepaper on 3PPI: https://static.googleusercontent.com/media/nextbillionusers.google/en//tools/3PPI-2021-whitepaper.pdf
      UK Open Banking API Standard: 
      Standards Home - Open Banking Standards 
      Open Banking Developer Zone: 
      Developer Zone 
      Examples of Open Banking Apps: https://www.ft.com/content/a5f0af78-133e-11e9-a581-4ff78404524e 
      See 
      Mobile Applications


      ~~~~~~~~~~ 
      Micro Front-ends Proof of Concept for Fineract 1.x  & Mifos X 
      Mentors
       @Jose Hernandez @Aleksandar Vidakovic @Ed Cable 
      Category
      Web - Mifos X Web App/Fineract 
      Overview & Objectives
      Originally this idea was sparked by looking at what Moov has around UI drops - 
      Drops: Prebuilt UI components for beautiful payment experiences  and 
      Moov Drops Many different goals, directions, use cases emerge but they would all share in helping make UI more maintainable, more pluggable and having more of a toolkit for builders/developers that would align with Fineract being used for various core banking use cases outside of just financial inclusion as well as the need supporting a variety of fintech use cases with common elementsIn conversation with others, some different directions could emerge:
      @Nayan Ambali and seeing how Finflux has separated out UIs for different personas
      With @Victor Romero  serving the need to help others do custom/specific page view for certain functionality
      Ability to more pluggable components especially for customer-facing operations/use cases
      Have micro-front-ends be brought together to create a monolithic application like the web-app
      @aleksvidakovic suggestion on the real value being in how these components are used in other frameworks/portals and not a full complete application like we currently have.
      For this round of GSOC I’d like us to define a project where we could do a micro front-end around a certain domain/functionality and pick a framework/design/architectural approach that we’d follow. (edited) 
      Our 2022 intern, Ramveer Singh made substantial progress in completing the development of our new web app such that the Web App is now part of the Mifos X release distribution and we’ve fully deprecated our older Community App.  Our Angular Web App is the standard application on the Mifos X distribution that provides all the core functionality for the most common methods of financial inclusion and products and services. It's also the starting point for any partners looking to customize or extend the UI. It's constantly being improved based on user feedback, better performance, and to integrate new design standards.
      The focus for 2025 will be on continuing to optimize the design of key flows, improving app localization, adding in better context-sensitive help, improving dashboards and visualizations, and refactoring of the web app to consume a type-script client for better maintainability. 
      Description
      Given this project is in it infancy, this would really be a proof of concept design the proper archiecture, learn which use cases are best candidates for pluggable and modular UI components and then choosing a framework in which to deploy multiple micro front-end as a single applicaiton with a unified user experience for end users. 
      Propse and design architecture for Micro Front End approach
      Determine best front-end language or javascript framewor to use - leaning towards Angular
      Identify which existing screens or new screens should be implemented as seaprate microservice UIs. 
      Primary efforts center around:
      Fixing remaining issues
      Redesigning customer and account dashboard pages
      Refactor web app to consume typescript client
      Enhance look and feel of app. 
      Implement third party library for proper internationalization. 
      The remaining issues can be found: https://github.com/openMF/web-app/issues 
      The progress is being tracked here: 
      Mifos Web App Task List 
      Some additional work also includes adding in comprehensive keyboard shortcuts to enable power-users of the app and to ensure that the tabs and arrow keys work appropriately for navigating through the app, localization support, additional dashboards, adding of tooltips, etc. 
      Helpful Skills
      Javascript, SCSS, HTML5, Angular 9, Angular Material, Flex Layout
      Impact
      More pluggable, faster to develop, modular UI that better supports variety of use cases of Fineract.
      Reduced dependency on using entire monolithic app. 
      Other Resources
      Usability and Design
      Moov UI Drops - 
      Drops: Prebuilt UI components for beautiful payment experiences  and 
      Moov Drops
      Article on Angular & Micro Front-ends using Module Federation - 
      Micro Frontends with Angular, Module Federation | Auth0 

      ~~~~~~~~~~
      Usability Improvements for Mifos X Web App
      Mentors
        @Bharath Gowda @Pushpendra Kumar @Ramveer 
      Category
      Web - Mifos X Web App
      Overview & Objectives
      Our Angular Web App is the standard application on the Mifos X distribution that provides all the core functionality for the most common methods of financial inclusion and products and services. It's also the starting point for any partners looking to customize or extend the UI. It's constantly being improved based on user feedback, better performance, and to integrate new design standards. Our 2024 interns, Omar Nabil, progress our implementation of translations, redefined styling in the app and implemented a number of usability improvements. This built upon the work of our 2023 intern, Pushpendra who completed the remaining work on the web app to fully deprecate our Community App. 
      2025 focus will be on continuing to optimize the design of key flows, continued improvements to  app localization, adding in better context-sensitive help, improving dashboards and visualizations, and completing the refactoring of the web app to consume a type-script client for better maintainability. 
      Description
      Our legacy community app is now fully deprecated so we must continue to refine the Mifos X web app including updating core dependencies. We must upgrade Angular to its latest stable verison and implement a number of critical design and usability enhancements to the core customer account and dashboard pages. In order to synchronize the UI with the version of each release of the back-end platform we need to complete the refactoring of the interaction layer to consume the auto-generated typescript client, and deepend the integration and seamless user experience with Apache Superset for dashboards and visualizations. 
      Primary efforts center around:
      Update Angular to latest stable version
      Fix identified usability improvements prioritized by community 
      Redesign customer and account dashboard pages
      Implement UI screens for new features contributed by commumity 
      Implement authentication framework to fully integrate Superset for dashboards. 
      Finalize refactoring of web app to consume typescript client
      Enhance look and feel of app. 
      Continued Improvements of  translations 
      Usability Issues and Improvements can be found: 
      https://mifosforge.jira.com/jira/software/c/projects/WEB/boards/62Can't find link
      Some additional work also includes adding in comprehensive keyboard shortcuts to enable power-users of the app and to ensure that the tabs and arrow keys work appropriately for navigating through the app, localization support, additional dashboards, adding of tooltips, etc. 
      Helpful Skills
      Javascript, SCSS, HTML5, Angular, Angular Material, Flex Layout
      Impact
      Enhanced User Experience, Intuitive application design
      Other Resources
      2024 Progress (Omar): 
      GSoC'24 Report - Mifos X Web App Enhancements 
      2023 Progress: 
      Final Report of GSOC'23 
      2022 Progress: 
      GSOC_2022_Ramveer_Final_Submission.md 
      2020 Progress: 
      Final Work Product Submission for Google Summer of Code'20 at The Mifos Initiative - Karan Takalkar(@karantakalkar) 
      Final Work Product Submission for Google Summer of Code'20 at The Mifos Initiative - Muskan Khedia(@muskankhedia) Usability and Design
      ~~~~~~~~~~
      
      Mifos Gazelle: Profile/Demo Creator (NEW!)
      Mentors
      @David Higgins + @Abhinav Kumar 
      Length
      Large
      Category
      Platform - DevOps | Infrastructure
      Overview & Objectives
      Over the past 2 years we have developed a Deployment Tool for DPI infrastructure called Mifos Gazelle.  This aligns to DPI as a packaged Solution (DaaS) toolkit approach.  It currently (as of v1.0.0) deploys 3 DPG components a Payment Orchestration (Mifos Payment Hub EE) a core banking solution (Mifos X including Fineract as a backend) and a payment switch (vNext Beta 1.0).  There is a roadmap to include other DPGs and by the start of this project there may be a 4th DPG included.
      Description
      Currently the Mifos Gazelle deployment does not have an easy way to create demos or profiles although there has been alot of thought and discussion around this see  GAZ-17 - Profile/Demo creator TO DO  .
      This project would look into this area research the options, agree the approach with the mentors and community and develop the first profile/demo creator tool for Mifos Gazelle.
      This project would suit someone who wants to explore and define a new element to a project rather than just follow a set of tasks.
      Helpful Skills
      Docker, Kubernetes, Jenkins, Bash, Java - Spring, PostgreSQL, MariaDB, Cassandra, TDD With JUnit 4, Gradle, CircleCI, Helm, UI , Angular, Research + other soft skills
      Impact
      Provide an easy way for institutions considering DPI to deploy and develop use cases and demos on Mifos Gazelle.
      Other Resources
      Helm Chart for Fineract deployment - 
      fineract-env/helm/fineract at master · fynarfin/fineract-env 
      Helm Charts for Payment Hub EE deployment  - 
      ph-ee-env-labs/helm at master · openMF/ph-ee-env-labs 
      Docker Compose for Mifos - (Fineract Back-End + Web App) - 
      GitHub - openMF/mifos-x-containers: Quick Deployment tool for having a running, non persistent Mifos X environment for demonstration purpose 
      Docker Hub Image of Fineract - https://hub.docker.com/u/openmf 
      https://hub.docker.com/r/apache/fineract 
      Fineract Technical Documentation - 
      Fineract Platform Documentation 
      Miniloop -  
      GitHub - mojaloop/mini-loop: Deployment utilities for Mojaloop 
      Payment Hub EE - 
      Welcome - Mifos Payment Hub EE 
      Lab Environment Overview - 
      Lab environment | Mifos Docs 
      GAZ-17 - Profile/Demo creator TO DO  

      ~~~~~~~~~~



      Mifos Gazelle: Support for ARM
      Mentors
       @tom daly 
      Length
      Large
      Category
      Platform - DevOps | Infrastructure
      Overview & Objectives
      Over the past 2 years we have developed a Deployment Tool for DPI infrastructure called Mifos Gazelle.  This aligns to DPI as a packaged Solution (DaaS) toolkit approach.  It currently (as of v1.0.0) deploys 3 DPG components a Payment Orchestration (Mifos Payment Hub EE) a core banking solution (Mifos X including Fineract as a backend) and a payment switch (vNext Beta 1.0).  There is a roadmap to include other DPGs and by the start of this project their may be a 4th DPG included.
      Description
      Currently the Mifos Gazelle deployment does not support ARM although the vNext already runs and builds docker images for ARM.  This project would primarily focus on updating all the OpenMF pipelines for MifosX and Payment Hub  EE such that it can be built for ARM.  This may included the 4th DPG at that point.
      This would allow for running on Apple devices or Raspberry Pi.
      We would like to be able to run Mifos Gazelle on a couple of Raspberry Pi devices (we call this DPI in a Box).  This project could extend to include this depending on time.
      The Intern must be able to problem solve. We expect during this exercise to hit challenges especially around dependencies that will need to be resolved (especially for Payment Hub EE) and this may result in upstream contributions to these DPGs.
      Helpful Skills
      Docker, Kubernetes, Jenkins, Bash, Java - Spring, PostgreSQL, MariaDB, Cassandra, TDD With JUnit 4, Gradle, CircleCI, Helm
      Impact
      Provide an easy to deploy package to help institutions considering DPI to deploy and develop use cases.
      Other Resources
      Helm Chart for Fineract deployment - 
      fineract-env/helm/fineract at master · fynarfin/fineract-env 
      Helm Charts for Payment Hub EE deployment  - 
      ph-ee-env-labs/helm at master · openMF/ph-ee-env-labs 
      Docker Compose for Mifos - (Fineract Back-End + Web App) - 
      GitHub - openMF/mifos-x-containers: Quick Deployment tool for having a running, non persistent Mifos X environment for demonstration purpose 
      Docker Hub Image of Fineract - https://hub.docker.com/u/openmf 
      https://hub.docker.com/r/apache/fineract 
      Fineract Technical Documentation - 
      Fineract Platform Documentation 
      Miniloop -  
      GitHub - mojaloop/mini-loop: Deployment utilities for Mojaloop 
      Payment Hub EE - 
      Welcome - Mifos Payment Hub EE 
      Lab Environment Overview - 
      Lab environment | Mifos Docs 
      GAZ-10 - ARM support for all Gazelle components TO DO  


      ~~~~~~~~~~



      Self Service Middleware SDK for Mifos X/Apache Fineract (Mifos Mobile, Mobile Wallet, Online Banking App)
      Mentors
      @Victor Romero @Avinash Vijayvargiya 
      Length
      Large - 350 hours
      Category
      Mobile/Platform
      Overview & Objectives
      A powerful and compelling use case of Mifos X is to power any type of customer-facing digital experience (mobile wallet, mobile banking, etc). However we must enable these digital experiences to connect securely to the back-end. We currently have a self-service API layer which is valuable for demonstrating customer-facing actions that can be performed via mobile banking and online banking apps but these APIs were not intended for deployment in live production environment and are being deprecated for a more secure option.
      This project would focus on building out the self-service middleware SDK for Mifos X and Apache Fineract by defining a subset of the APIs to secure expose such that external users can inititate transactions and interact with accounts within Fineract. 
      Victor Romero has created a design for implementation of this middleware layer and would mentoring the intern to implement this design. 
      Some of these effort will also align with previous efforts around Open Banking APIs. Across our ecosystem we're seeing more and more adoption and innovation from fintechs. A huge democratizing force across the financial services sector is the Open Banking movement providing Open Banking APIs to enable third parties to directly interact with customers of financial institutions. We have started providing an Open Banking API layer that will allow financial institutions using Mifos X to offer third parties access to requesting account information and initiating payments via these APIs. This also aligsn with the centralized PISP API introduced within Mojaloop by Google.  
      Tremendous impact can be had at the Base of the Pyramid by enabling third parties to establish consent with customers authorize transactions to be initiated or information to be accessed from accounts at their financial institution. This  Open Banking API layer would enable any instituion using Mifos or Fineract to provide a UK Open Banking API layer  to third parties and fintechs.  
       The API Gateway to connect to is still being chosen (WS02, Gravitee, etc.)
      Description
      In 2025, Intern would need to familiarize with the proposed design and initial codebase contributed by Victor. This design follows the existing architectural patterns of our SDKs and client, exposin the appropriate APIs using coroutines and publishes them in a secure manner. The APIs that are consumed by the mobile banking applications have been documented in the spreadsheet below. The APIs have also been categorized according to whether they are an existing self-service API or back-office API and if they have an equivalent Open Banking API and if so, a link to the corresponding Open Banking API.
      For example: 
      Submit Loan Application (Self-ServiceAPIwith EquivalentOpenBankingAPI)
      https://demo.mifos.io/api-docs/apiLive.htm#loans_create Used by Mifos Mobile
      ImagesAPI(Back-OfficeAPIwith No EquivalentOpenBankingAPI)
      https://demo.mifos.io/api-docs/apiLive.htm#client_images Used by Mifos Mobile and Mobile Wallet 
      Fetch Identification CardAPI(Fineract CNAPIwith no equivalentOpenBankingAPI)
      https://docs.google.com/document/d/15LbxVoQQRoa4uU7QiV7FpJFVjkyyNb9_HJwFvS47O4I/edit?pli=1#heading=h.xfl6jxdpcpy1
      Sample APIs to be Documented
      -------------------------------------------
      Mifos Mobile API Matrix (completed by Ashwin)
      https://docs.google.com/spreadsheets/d/1gR84jZzLF-mM0iRw5JyeMAsHMK6RQPK0vyDmNAY9VhE/edit#gid=0
      MIfos Mobile API Matrix (completed by Shivangi)
      https://docs.google.com/spreadsheets/d/1exTv68v1IW_ygS7mSj0_ySFWGTj06NcxPZeNLjNIy6Y/edit?pli=1#gid=0
      Helpful Skills
      Android development, SQL, Java, Javascript, Git, Spring, OpenJPA, Rest, Kotlin, Gravitee, WSO2
      Impact
      By providing a secure middleware layer we can enable both trusted first party apps to allow customers to autheniticate and access their accounts as well as an API layer for third party fintechs to securely access FIneract and request information or initiate transactions with the consent of customers.
      Other Resources
      Self-Service Middleware Layer/Plugin (Designed Implemented by Victor): 
      GitHub - openMF/selfservice-plugin: Self Service Plugin for Apache Fineract 
      CGAP Research on Open Banking: https://www.cgap.org/research/publication/open-banking-how-design-financial-inclusion
      Docs: https://mifos.gitbook.io/docs/wso2-1/setup-openbanking-apis
      Self-Service APIs: https://demo.mifos.io/api-docs/apiLive.htm#selfbasicauth
      https://cwiki.apache.org/confluence/display/FINERACT/Customer+Self-Service+Phase+2
      Open Banking Adapter: https://github.com/openMF/openbanking-adapte
      Transforms Open Banking API to Fineract API | Can connect to different API gateways and can transform against different API standards.
      Reference Open Banking Fintech App:
      Backend: https://github.com/openMF/openbanking-tpp-server | GUI: https://github.com/openMF/openbanking-tpp-client
      Google Whitepaper on 3PPI: https://static.googleusercontent.com/media/nextbillionusers.google/en//tools/3PPI-2021-whitepaper.pdf
      UK Open Banking API Standard: https://standards.openbanking.org.uk/
      Open Banking Developer Zone: https://openbanking.atlassian.net/wiki/spaces/DZ/overview
      Examples of Open Banking Apps: https://www.ft.com/content/a5f0af78-133e-11e9-a581-4ff78404524e
      See https://openmf.github.io/mobileapps.github.io/
      
      
      ~~~~~~~~~~

      Reactive Loan Risk Assessment Engine for Mifos
      Mentors
      @Ed Cable 
      Length
      Large - 350 hours 
      Category
      Back-end Platform - Modules & Integration (Mifos X)
      Overview & Objectives
      Provides financial institutions with real-time insights into loan risk, helping them make better lending decisions.
      A reactive backend ensures the system can handle a growing number of requests as Mifos deployments expand.
      Improved risk assessment can lead to more responsible lending practices, ultimately benefiting underserved communities.
      Description
      In 2025 the Intern would:
      Create a dedicated microservice in Java that handles loan risk assessment asynchronously.
      Utilize reactive programming paradigms to ensure scalability and high throughput.
      Design and implement a configurable risk scoring model that can incorporate multiple factors such as client financial history, repayment behavior, and external credit ratings.
      Allow for model tuning via configuration, so institutions can adapt the scoring criteria to local requirements.
      Helpful Skills
      Java, Spring Boot, Microservices, Gradle,  testing, SQL
      Impact
      This project will significantly enhance the Mifos X and Apache Fineract platforms by improving the scalability, performance, and reliability of backend services. By transitioning to a reactive microservices architecture using modern Java technologies like Spring
      Other Resources
      [FINERACT-2021] Type-safe REST API layer - ASF JIRA 
      [FINERACT-2022] Type-safe native SQL queries - ASF JIRA 
      Querydsl - Unified Queries for Java 
      
      
      ~~~~~~~~~~
      
      Mobile Check Deposit Proof of Concept Using Moov Image Cash Letter 
      Mentors
      @Victor Romero 
      Length
      Large - 350 hours
      Category
      Mobile | Platform - Integrations
      Overview & Objectives
      As more and more implementers of Mifos X, use the platform for digital and neobank use cases, the ability to remotely capture check (i.e. mobile check deposit) becomes necessary. There are many proprietary solutions to achieve this but this project would aim to create a Proof of Concept that is completely open source to enable a neobank or any financial institution to offer to its members mobile check deposit capability. This would especially be relevant for the credit unions, community banks and smaller financial institutions that are adopting MIfos and Fineract as their core system.
      Description
      This project would be built as a new module that is easily embedded or integrated into our Mifos Mobile self-service mobile banking app. It would consist of an open source tool for actually scanning or capturing the check deposit and use the Moov open source Image Cash Letter library to parse, create, and validating ICL files.
      Image Cash Letter (ICL) specifications provide Check 21 services and are designed to enable banks to handle more checks electronically, which should make check processing faster and more efficient. Traditionally, banks often physically move original paper checks from the bank where the checks are deposited to the bank that pays them. The overall process of translating physical checks to electronic messages is called Check Truncation.
      Helpful Skills
      Java, Android,Kotlin, Compose, Go
      Impact
      Ease of use for end user - enabling small financial institutions like credit unions to offer mobile check deposit at lower cost. 
      Other Resources
      Moov Image Cash Letter Library - 
      Overview 
      Demo of ICL Library - 
      ICL | Moov 
      Github of ICL Library: 
      GitHub - moov-io/imagecashletter: X9’s Specifications for ICL (Image Cash Letter) to provide Check 21 services. The HTTP server is available in a Docker image and the Go package is available. 
      Proprietary Remote Check Capture applications - 
      10 Remote Cheque Deposit Applications in the US from Non-Banks 
      
      ~~~~~~~~~~
      
      POC for Integration with Loan Decisioning (Lokyata, Begini, nTropy)
      Mentors
      @Victor Romero @Aleksandar Vidakovic 
      Length
      Large - 350 hours
      Category
      Platform - Modules
      Overview & Objectives
      Mifos/Fineract is a very robust and highly functional Loan Management System of Record. Typically adopters of the system will build their own or implement a third party tool to score their borrowers, analyze credit risk, and do their loan decisioning as part of their origination processes. Once this decisioning engine has determined eligbiility of the borrower, the customer and loan and ensuing lifecycle can then be managed in Mifos/Fineract. Mifos/Fineract can easily receive information from this decisioning engine and send information to the decisioning/scoring engine to faciilitate this analysis.
      There are a number of different best practice alternative and traditional credit scoring/decisioning tools that Mifos/Fineract could more tightly integrate with. By providing a working integration of plugin framework for integrating with decisioning, our community can have better access to decisioning tools to improve the health of their portfolios.   This project would extend up on existing efforts to create a micro front-end approach for our UIs. As the userbase for Mifos/Fineract extends beyond just microfinance and financial inclusion we need to enable developers to easily build front-end user experiences that align with the wide variety of back-end use cases supported by our platform being used by MFIs, credit unions, banks, fintechs and governments. Additionally, many of the flow and screens used by staff as well as customers are common across mobile and web application. 
      Description
      This project endeavors to create a plugin framework for integration with external decisioning engines. It should identify, design, and build out the points of integration and interaction for inbound and outbound data flows at both the back and front-end for decisioning/scoring tools of both traditional as well as alternative sources of data. This work would include leveraging Fineract data tables for storing and displaying this external data, the respective webhooks, APIs, and events that are called or triggered during the scoring process. Likewise this project would dovetail well with our workflow engine integration as flows would be calling both of these systems. Traditional providers we could potentially build integrations with include Lokyata which provides more out of the box scoring or tools like nTropy which allow data enrichment to build ones one model. On the alternative side, we are exploring integration with Begini which provides pyschometric assesment data as well as behavioral and usage data from the phone to assess credit worthiness. 
      Work would be be on both the back and front-end.
      Helpful Skills
      Java, Spring, Angular, PostgreSQL, MySQL/MariaDB, REST
      Impact
      Cost-effective and modern decisioning to improve the health and creditworthineess of a loan portfolio. More replicable integration points with external systemn that can be followed for other integrations. 
      Other Resources
      Lokyata | Future of underwriting powered by AI. 
      Ntropy | Accurate Data Enrichment API 
      Home 
        
      ~~~~~~~~~~
      
      Digital Bank UI using Compose Multi-Platform Micro Front-End for Web and Mobile Apps 
      Mentors
      @Pushpendra Kumar b20 122 
      Length
      Large - 350 hours
      Category
      UI, Mobile
      Overview & Objectives
      This project would extend up on existing efforts to create a micro front-end approach for our UIs. As the userbase for Mifos/Fineract extends beyond just microfinance and financial inclusion we need to enable developers to easily build front-end user experiences that align with the wide variety of back-end use cases supported by our platform being used by MFIs, credit unions, banks, fintechs and governments. Additionally, many of the flow and screens used by staff as well as customers are common across mobile and web application. 
      Description
      This project would aim build both the micro front-end framework and set of UI components that can be deployed as individual flows or end to end applications across both web and mobile. Recently emerging is the Compose Multiplatform which extends Jetpack Compose to work beyond just mobile devices. 
      The current standard UI for Mifos X is still the Web App which is the only one that covers 100% of the feature set. While based on Angular and more modern than our previous Community App, the project hard to maintain and - apart from the occasional color change - hard to customize let alone integrate in other web applications. Developers should be able to pick any number of standalone components and integrate them in custom UI projects (where Fineract is one among multiple backends). All Fineract UI components should be published for easy consumption by other developers.
      Documentation of the project could follow latest best practices (aka “Storybook”)
      Tooling should help with consistency and reduce handwritten code as much as possible. Using Monorepos is strongly suggested.
      Helpful Skills
      JS, Android, React, CSS 
      Impact
      Developers can more rapidly build out user interfaces for different financial service use cases with a greater degree of design flexibility 
      Other Resources
      Compose Multiplatform UI Framework | JetBrains 
      GitHub - JetBrains/compose-multiplatform: Compose Multiplatform, a modern UI framework for Kotlin that makes building performant and beautiful user interfaces easy and enjoyable. 
      
      ~~~~~~~~~~
      
      OpenG2P  - Digital Identity Proof of Concept with MOSIP (GovTech)
      Mentors
      @Ed Cable @Manoj VM 
      Length
      Large - 350 hours
      Category
      Platform & Modules - Digital ID, Exploratory, Bleeding Edge
      Overview & Objectives
      Digital Identity is a pressing topic and for both generations of Fineract (1.x and CN), we'd like to have integration with emerging KYC and digital identity solutions.
      KYC (Know your customer) is a fundamental banking concept. It refers to the process of identifying a new customer at the time of account opening, in compliance with law and regulation. The identification requirements may be lower for low value accounts ("Tiered KYC"). The term is also used in connection with regulatory requirements for a provider to understand, on an ongoing basis, who their customer is and how they are using their account. Most of the banks are mandated to perform basic/extensive KYC, before they can serve their customers.
      Traditionally KYC is done in a centralised fashion where a central agency has the control over all the data. For example consider each bank like SBI, Deutsche, JP Morgan, etc. when creating a bank account, each of them requires a separate KYC process to be completed and all this data gets stored in their respective databases. Even the systems like Aadhar or social security number, etc. have the data stored in a central manner and maintained by the government. However, in recent times all these centralised identity servers continue to be hacked and the important and private data being stolen regularly.
      Omidyar Network along with Gates Foundation have developed the MOSIP project which provides an open source digital ID platform. Integration between Mifos along with Mojaloop can provide an end to end reference architecture for a digital cash transfer system built on open source digital public goods. 
      Decentralised system means that no one person has control over sensitive data.
      It enables the re-use of KYC, i.e. each financial institution or in our case each customer using Fineract may not have to perform its own complete KYC, but re-use the KYC already performed by others (those who have the power as issuing authority for any kind of claim).
      Cryptographic security is the heart of blockchain technologies enhancing privacy.
      Claim-based system where the end user/customer has the control over his data.
      Description
      Integration between Mifos and digital identity systems and KYC protocols could be deepened. This project would focus on an initial proof of concept integration with MOSIP APIs for digital identity including
      ID Repository
      ID authentication
      Biometric Integration 
      Registration 
      Registering a client with a MOSIP-powered Digital Identity in a Mifos system and verifying that digital identity to perform transactions. 
      
      Helpful Skills
      HTML, Spring, Hibernate, REST, Java, AngularJS, Javascript, SQL, 
      MOSIP 
      Impact
        Other Resources
      MOSIP https://www.mosip.io/
      MOSIP Docs: https://docs.mosip.io/platform/
      
      ~~~~~~~~~~
      
      Machine Learning Scorecard for Credit Risk Assessment Phase 7 (AI)
      Mentors
      @Lalit Mohan S  @Nasser Kaze @Victor Romero 
      Length
      Large - 350 hours
      Category
      AI, Platform - Modules, Bleeding Edge
      Overview & Objectives
      Financial Organizations using Mifos/Fineract are depending on external agencies or their past experiences for evaluating credit scoring and identification of potential NPAs. Though information from external agencies is required, financial organizations can have an internal scorecard for evaluating loans so that preventive/proactive actions can be done along with external agencies reports. In industry, organizations are using rule based, Statistical and Machine learning methods for credit scoring, predicting potential NPAs, fraud detection and other activities. This project aims to implement a scorecard based on statistical and ML methods for credit scoring and identification of potential NPAs.
      Description
      in 2025 the approach should improve last year's GSOC work on Features/Characteristics, Criteria and evaluation. The design and implementation of the screens should follow Mifos Application standards. Should implement statistical and ML methods with explainability on decision making. Should also be extensible for adding other functionalities such as fraud detection, cross-sell and up-sell, etc.
      The system should be able to connect to external sources/providers(e.g. Credit Bureaus) to obtain a credit history that should weigh for the credit worthiness. The scorecard should be able to self update with increase and changes in data. This requires an ML pipeline to continually improve the scorecard models.
      Priorities:
      Further optimize the ML and statistical models.
      Improve the Rule Based scoring system by fine-tuning the features.
      Setup ML pipeline to refresh dataset and models using Federated Learning techniques
      Implement Synthetic Data using SDV or any other open source synthetic data
      Extend the approach beyond Credit Scoring such as Fraud detection
        Helpful Skills
      JAVA, Integrating Backend Service, MIFOS X, Apache Fineract, AngularJS, ORM, ML, Statistical Methods, Django
      Impact
      Streamlined Operations, Better RISK Management, Automated Response Mechanism
      Other Resources
      Source Code: 
      GitHub - apache/fineract-credit-scorecard: Fineract Credit Scorecard - A credit scoring module for Apache Fineract (https://github.com/apache/fineract) 
      Previous GSOC Progress
      2024 Project (Parth Kaushal): 
      GitHub - openMF/scorecard-ai 
      2022: 
      fineract-federatedLearning-research/READEME.md at main · Zavier-opt/fineract-federatedLearning-research Suchit’s Final Report - 
      GSoC '22 for Mifos Submission 
      2021: 
      Google Summer of Code 2021 Final Report.md 
      2020: https://gist.github.com/humbletechy/43e7322913af561fdd7db5d4962d59a7 
      2019: 
      GSoC'19 Final Report 
      Documentation
      Fineract Credit Scorecard - Fineract - Apache Software Foundation 
      lalitsanagavarapu’s gists 
      
      ~~~~~~~~~~
      
      Mifos Mobile 7.0 - Mobile Banking App
      Mentors
      @Ahmad Jawid Muhammadi @Garvit Agarwal @Saksham Handu @Paras Dhama @Rajan Maurya 
      Length
      Large - 350 hours
      Category
      Mobile - Mifos X | Core Development
      Overview & Objectives
      In 2025, we are making a big push around shared infrastructure to provide modern core banking infrastructure the many SACCOs, MFIs and Credit Unions that go the last mile. We are prioritizing providing a more robust and feature-rich self-service mobile banking experience to be offered to their members and customers. Mifos Mobile is a reference mobile banking app which enables clients to authenticate themselves, view and edit their account details. and make repayments or transactions between their own accounts. It is now possible for any financial institution using Mifos to provide an omni-channel banking experience including smartphone-based mobile banking, USSD-based mobile banking, and online banking via a web app.
      Over the years our interns extended our mifos mobile banking app, completing a mix of functional, architectural, and design improvements including improving the outbound notification system by migrating from GCM to FCM, initial integration with RocketChat for direct customer support between staff and clients, a dark theme and better support for skinning, and phase 1 of integration with Mojaloop via the payment hub. In 2020 Shivangi revamped the UI and Ashwin began the migration to Kotlin for mutli-module development and last year Avneet finished the kotlin multi-module migration and whole project get migrated xml to Jetpack compose.
      With the payment hub and API Gateway now in place, next we look to add additional mobile money and payment system integrations into the app as well as having the app connect via the Open Banking API rather than the self-service APIs. This exercise of mapping the Fineract self-service APIs to the Open Banking APIs will be the major focus of this project.
      It was built on top of the Apache Fineract 1.x client-facing APIs to enable self-service channels for clients to interact with their own data and transact in a self-service manner. 
      Description
      In 2025, Work will involve both development of the Mobile application as well as work to connect the app securely via self-service middleware layer. 
      Replace API layer from self-service Fineract APIs to self-service middleware layer 
      Implement new look and feel based on modular UI components. 
      Integration with an external payment system (Mojaloop, mPesa) via  our PH-EE
      Complete migrate Kotlin multi-module to Kotlin Multiplatform.
      Make sure fineract-client-kmp-sdk implemented properly and have no bugs.
      Continue adding unit tests for Data Layer and UI Layer
      Cover all the screens with UI tests
      Implemented Playstore release github action pipeline
      Improve Githhub workflows and add jobs to run Unit and UI tests
      Add CI to build APK and code analysis.
      Helpful Skills
      Android, Kotlin, Kotlin Multiplatform, Jetpack compose, Coroutines, Koin, MVVM, Unit, Instrumentation Testing, Room, Git, OpenJPA, Rest, WS02 API Gateway
      Impact
      By providing an extensible mobile banking app, allow a member/client in having a self-service channel allowing them more direct control and visibility into their financial livelihood.
      Other Resources
      User Stories - https://goo.gl/3xuUko
      Wireframes - https://goo.gl/3xuUko
      Customer Self Service APIs - https://cwiki.apache.org/confluence/display/FINERACT/Customer+Self-Service
      UK Open Banking API Standard: https://standards.openbanking.org.uk/
      Source Code: https://github.com/openMF/mifos-mobile
      See: https://openmf.github.io/mobileapps.github.io/
      Mifos Webinar on Open Banking API: 
      Mifos Open Banking API Documentation: https://app.gitbook.com/@mifos/s/docs/
      GsoC 2020 work progress final report: 
      GSoC'20 - Mifos Mobile - Final Report 
      GSOC 2023 Final Report (Pratyush Singh): 
      GSoC'23 Final Report - Mifos Mobile 
      GSOC 2024 final report (Avneet Singh): 
      Summary of my work in GSoC 2024 
      
      ~~~~~~~~~~
      
      Payment Hub EE - Replicable Mobile Money Connectors for  Mifos Payment Hub EE
      Mentors
       @Subham Pramanik @Paras Dhama @Manoj VM 
      Category
      Platform - Payments Integrations
      Overview & Objectives
      While we didn’t have an intern working on this in 2024 it’s very much a priority to both enable the ecosystem to independently adopt and extend PH-EE as well as to enable PH-EE to be utilized within the regions we’re deploying shared infrastructure to allow members to transaction digitally via mobile money.
      Mobile money is rapidly transforming financial inclusion by providing more immediate, impactful, affordable, and secure financial services to the client. Providers like MFS Africa and Beyonic provide a set of cross-border payment rails to enable remittances across Africa terminating in mobile money wallets. Mobile money platforms like M-Pesa offer the client unparalleled value in terms of convenience, security and the possibility of new services and products that are more in line with real-world financial habits.  For financial institutions and their clients to fully scale mobile money and leverage its potential, it needs to be fully integrated with their core-banking system.
      We designed and implemented Payment Hub EE as a highly flexible integration engine and orchestration layer to allow the ease of connecting to new mobile money APIs by simply building new connectors. Across the ecosystem, PH-EE has been deployed in production for multiple mobile money networks including M-Pesa via Safaricom and other connectors. However it is challenging for others to easily build new connectors. This project would help to make the process for building a new mobile money connector more replicable.  
      Description
      This project would focus on making the process of building a connector more replicable, defining and templating the BMPN flows for inbound and outbound mobile transactions, properly documenting the process, creating a set of helm charts for deployment of Payment Hub EE for the mobile money integration use case. 
      The Payment Hub EE has been built out as an integration layer between Fineract and real-time payment systems like Mojaloop. Built around the Zeebe as an orchestration engine, it's built with an extensible architecture with a set of connectors for additional core banking systems, channels, and payment systems. We have a connector built for Mojaloop and the GSMA mobile money API and would like to build additional ones for the most widely used payment rails across our community. As part of our DIAL-funded project to integrate Mifos with the open source Mojaloop payments platform the team from DPC consulting built out a middleware component called the payment hub to enable the integration with the Mojaloop APIs. This middleware has also served as the point of integration for all other external payment systems - the payment hub is extendable by additional payment connectors. 
      Helpful Skills
      Web Services, Java, SQL , JavaScript , Git, Sprint
      Impact
      Great efficiency, reduced risk for clients, more impactful and relevant products & services.
      Other Resources
      2020 Progress: https://gist.github.com/SubhamPramanik/905ea87b83dd0b6af62af18ca0c0c1ea
      Research & Data on Various Mobile Money Platforms  - http://goo.gl/XkSbdl
      Payment Hub EE Docs: https://mifos.gitbook.io/docs/payment-hub-ee/overview/payment-hub-apis 
      Overview of Payment Hub and How to Configure (See Section 5.6.3): https://docs.google.com/document/d/1XnAuWxmX-Fof7-o69IyU9ilwcmigqQ6dNHc9uNRx1r4/edit?usp=sharing
      Functional and Technical Specification on the Payment Hub: https://docs.google.com/document/d/1iVTgqljj5jW1eczpUcN_qykvWGh9bPKalxDayW8ZGcU/edit?usp=sharing
      Beyonic APIs: https://apidocs.beyonic.com/
      
      ~~~~~~~~~~
      
      Online Banking App 5.0 - Customer Loan Management Portal 
      Mentors
      @Ed Cable  @Victor Romero 
      Length 
      Large - 350 hours
      Category
      Web - Mifos X Online Banking App | Core Development 
      Overview & Objectives
      It’s been a number of years since we have had an intern work on our online banking app but it’s a very high priority given the need for customers to interact with their own loan accounts. The online banking app is overdue for refactoring and could now follow the same Compose Multiplatform architecture as our mobile apps. It is currently an Angular web app powered by self-service APIs so would also follow the progress being made with self-service middleware layer. The app currently allows for account creation, logging in, viewing of account details, transferring between savings accounts, repaying loans via savings accounts, applying for new loans, and more.
      Given the high amount of adoption of Mifos X for loan management use cases, for this year’s project we’d like to create a version of the online banking app which is solely focused lending use cases so Mifos can provide a customer-facing loan management portal. This will be a valuable community resource that others can use for demonstrations or to white-label to provide their customers to log into the self-service portal and view their existing active loans, view transaction details, repayment history, repayment schedules, etc, view details of previous loans, initiate repayments on their loans, calculate the payoff amount of their loans, apply for new loans, view loan account statements, etc. 
      LoanPro provides a valuable resources on what a simple loan management portal could offer at https://help.loanpro.io/article/fcflgkwnxn-customer-website 
      Description
      Focus for 2025 includes:
      Redesign and Refactoring of Online Banking App to Compose Multiplatform
      Align and enhancing overall user experience and design of application 
      Creation of a new repository that contains only the loan management self-service capabilities
      Refine and implement the self-service loan management features listed above: 
      Incorporate better visuals and charts and dashboards around loan history
      View their existing active loans
      View transaction details, repayment history, repayment schedules, etc
      View details of previous loans
      Initiate repayments on their loans
      Calculate the payoff amount of their loans
      Apply for new loans
      View loan account statements, etc. 
      Deploy the APIs (back-office or self-service APIs) securely (i.e. API Gateway)
      Implement capabilities to configure a more customized look and feel of the app (upload logo, etc.)
      Leverage ongoing security enhancements in Fineract to provide better self-service user management
      Ensure the app can easily be embedded or integrated into existing tools of institutions using this.
      Bonus: Enabling self-service external transactions through Payment Hub EE integratio
      Bonus: Adding new support features to make app more user friendly.
      Helpful Skills
      Angular development, SQL, Java, Javascript, Git, HTML, CSS
      Impact
      Allows a member/client in having a self-service channel allowing them more direct control and visibility into their financial livelihood.
      Other Resources
      Previous GSOC Efforts:
      2020 Progress: 
      Online Banking App 4.0 Report 
      2019 Progress: 
      GSOC 2019 Final Work Product Report  
      LoanPro Customer Loan Website: https://help.loanpro.io/article/fcflgkwnxn-customer-website 
      Self Service APIs - https://cwiki.apache.org/confluence/display/FINERACT/Customer+Self-Service
      Source Code - https://github.com/openMF/web-self-service-app and https://github.com/openMF/online-banking-app
      Complete Details can be found here: Self Service Web Application
      UK Open Banking API Standard: https://standards.openbanking.org.uk/
      Mifos Webinar on Open Banking API: 
      Mifos Open Banking API Documentation: https://app.gitbook.com/@mifos/s/docs/
      Further Ideas: https://docs.google.com/document/d/1KXDSrBkuYA9g694-DE4qf1QKFcAhWwA-HNnn9YAucbk/edit?usp=sharing
      
      
      ~~~~~~~~~~
      
      Ad Hoc Reporting Module/Business Analytics (OLAP) 
      Mentors
      @Bharath Gowda @Victor Romero 
      Overview & Objectives
      Business insights are not just raw data; they are the outcome of a thorough analysis that transforms data into valuable information. By examining data from multiple sources, such as sales records, customer feedback, and market research, organizations can gain a comprehensive understanding of their business landscape.
      Through the application of analytical techniques, such as data mining, statistical analysis, and machine learning, organizations can uncover hidden patterns and correlations within their data. These insights provide a deeper understanding of customer behavior, market trends, and operational efficiency.
      During previous GSoC Interms have developed ETL scripts to create OLAP cubes (fact and dimension tables on MySQL). This allowed managers to perform ad hoc slicing and dicing of their data to answer important questions about their operations.
      Created ETL scripts and tests
      Created a Mondrian schema to work with Saiku Analytics
      This previous project would extend off of the work of a previous GSOC intern in building out integration with Saiku.
      The proposed work is looking to use MPP-based real-time data warehouse (like Apache Doris) for ingesting data from Mifos X and the Analytics can be implemented as Dashboards using Apache Superset. 
      
      Description
      The data and information housed in the centralized Mifos database is critical to the operations and management of a financial institution. While Mifos X ships with more than five dozen standard report and has multiple ways to build custom reports, non-technical staff who don’t know SQL queries nor the structure of the database struggle to be able to access new reports on the fly. Integration with Saiku would allow for ad-hoc reporting or more simply a drag and drop interface for management and non-technical staff to easily slice and dice and create reports on the fly.
      Nowadays using near real time data is critical for Decisioning systems and the core banking solutions are a crucial component for any financial institution. And the use of modern open source technologies can give Business Insights on the ever-changing business landscape for taking informed decisions.
      At a later time the data lake could be used for using another AI tools for data analysis.
      Helpful Skills
      Database Management Systems, MDX, SQL,
      Impact
      Data drives a microfinance institution - the more powerful and robust analytical tools management has, the better they can tailor their services and outreach to impact the poor most effectively.
      Other Resources
      Apache Doris - 
      Apache Doris: Open source data warehouse for real time data analytics - Apache Doris 
      Apache SuperSet 
      Welcome | Superset  
      TiDB - HTAP Database - 
      TiDB, Powered by PingCAP  
      Saiku Analytics Demo - demo.analytical-labs.com
      Wikipedia OLAP Article - http://en.wikipedia.org/wiki/Olap
      Introduction to OLAP - http://www.db-class.org/course/video/preview_list
      Gentle Introduction to MDX - http://www.iccube.com/support/documentation/mdx_tutorial/gentle_introduction.html
      Apache Fineract 1.0 Github Repo
      Saiku Github Repo
      https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=73632010
      Ad Hoc Reporting Builder Tool
      GSOC Idea Description
      Demo of Integration from 2014
      Saiku Website - http://community.meteorite.bi/
      Documentation on Work led by Oleg in 2014
      JIRA Issue for Oleg’s Work: https://mifosforge.jira.com/browse/MIFOSX-1448
      Source Code from Oleg’s Work
      Discussion on Saiku and Challenges to Overcome
      Discussion on Saiku
      Demo of Mifos with Salesforce Reporting
      MIFOSX-1448 - 3rd party query builder | SAIKU DEVELOPMENT IN PROGRESS
      


      ~~~~~~~~~~
      Basic CRM Functionality - Inquiries/Complaints Module
      Mentors
      @Ed Cable 
      Category
      Back-end Platform | Modules
      Overview & Objectives
      Right now Mifos X contains core client management functionalities including tracking basic demographic information, know your customer information, document management, and survey collection through data tables. As financial institutions, serving the poor begin to offer a more in-depth and diverse range of financial inclusion products, the need for more robust client management and in-depth client understanding has grown. Their core system needs to provide more and more CRM-type functionality that compliment the portfolio management and financial/social reporting that the Mifos X provides.
      This project will work to deliver the initial set of customer relationship management functionalities including a module for tracking inquiries, complaints. Primarily it will focus around customer support desk type functionality. 
      Description
      This module will have a request management functionality. A request can be of 2 types: Complaints and Service Requests. Each request must be against a customer and optionally against an account of the customer. Each request will go through a simple workflow.
      Actions that can be performed on a request:
      Assign -> will change status to "assigned"
      Start Work --> will change status to "in progress"
      Close --> will change status to "closed" (with a sub-reason code)
      At each step user can enter comments.
      The customer summary screen will have a link to view the requests of the customer - along with a summary and current status - with options to click-through to get the complete history of each request.
      Helpful Skills
      familiarity with Mifos X tech architecture, angular js,node js, java,Spring, Backend Integration
      Impact
      Deepening the client relationship and ensuring fair, responsible, and transparent financial services to the poor is a core piece of the industry's roadmap for financial inclusion. Providing customers the ability to voice their concerns and feedback about the services they're receiving provides a simple yet powerful tool to protect the client. Empowering the financial institution with the ability to track these inquiries and overall maintain a more holistic relationship tracking entire lifecycle of their clients gives them a much better ability to understand their clients and respond to their needs with appropriately designed services and products.
      Other Resources
      Odoo Open Source Business Apps Github Repo
      Odoo Third-party API And Demo
      Wikipedia Article on CRM
      What Is CRM ? 
      CRM
      Medium Projects
      These projects are of a 175 hour duration.


      ~~~~~~~~~~
       AI-Driven Architectural Test for Mifos Payment Hub EE (AI)
      Mentors
      Kerlyn Manyi,   Oreoluwa Oluwasina
        Length
      Medium - 175 hours
        Category 
      Platform | DevOps | PH-EE
        Overview & Objectives
      Mifos Payment Hub EE is a critical financial transaction platform that facilitates seamless payments across different banking and financial services. Given its complexity, ensuring the system's long term resilience, scalability, and security is vital. This project aims to perform AI-driven architectural testing to analyze the system’s performance, identify bottlenecks, predict failures, and enhance its overall robustness. 
        Description
      By leveraging machine learning and automation, the project aims to create an intelligent testing framework that can proactively detect issues before they impact operations. This will result in improved performance, enhanced security, and better fault tolerance for Mifos Payment Hub EE. 
      Intern will;
      Develop machine learning models for anomaly detection, load testing, and vulnerability scanning. 
      Implement AI-driven load and stress testing to identify system bottlenecks and optimize performance. 
      Utilize AI-based security scanning tools to analyze authentication mechanisms, APIs, and transaction flows. Detect potential fraud patterns using machine learning techniques. 
      Design an AI-driven test automation framework to reduce manual testing efforts. Implement predictive analytics to forecast potential system failures. 
      Document testing processes, findings, and recommendations.
        Helpful Skills
      Python, Java, TensorFlow, Scikit-learn, Git
        Impact
      The project will boost Mifos Payment Hub EE's long term reliability and security while enabling scalability, ultimately establishing it as a trusted choice for financial institutions.
        Other Resources

      ~~~~~~~~~~
      Bank Statement Analysis Phase 2 (AI)
      Mentors
      @jeremy engelbrecht @Akshat sharma 
      Length
      Medium - 175 hours
      Category 
      AI | Platform - Modules 
      Overview & Objectives
      Mifos is a powerful loan management system, but it has room to improve its loan origination and decision-making features. Phase 2 of the Bank Statement Analysis project enhances the system by integrating user personalization and expanding cross-platform compatibility. With this, the platform will not only analyze the credit risk of potential borrowers but also provide personalized financial advice based on the user’s spending habits, income, and goals. Additionally, this phase will improve integration with various financial platforms, creating a more comprehensive financial management experience for the user.
      Description
      In this phase,the system will build dynamic, personalized user profiles based on financial data. It will also integrate seamlessly with multiple financial platforms to aggregate data from various sources such as bank accounts, investment portfolios, and payment services. 
      Key features in Phase 2:
      Personalized Financial Advice: Provide tailored recommendations based on historical spending, income, and financial goals. These suggestions will include budgeting tips, savings strategies, and financial goal tracking
      Cross-Platform Integration:
      APIs & Data Standardization: Create robust APIs and standardized data formats for seamless data exchange between multiple financial systems. 
      Real-Time Synchronization: Enable real-time synchronization and data aggregation from various financial sources such as banking accounts, investment portfolios, and payment services.
      Uniform Interface: Provide a uniform interface for consolidating financial records across different platforms, ensuring a unified experience for users. 
      These features will be integrated within MIfos X, allowing users to access a comprehensive overview of their financial data and receive personalized advice, all while improving their loan eligibility assessment.
      Helpful Skills
      Python, XGBoost, NLP, Recommendation Systems, Cross-Platform Data Integration
      Impact
      Phase 2 will significantly improve the loan origination process by offering dynamic, personalized financial recommendations. It will also enhance the user experience by allowing real-time synchronization of financial data across multiple platforms, giving users a comprehensive view of their financial situation. The cross-platform compatibility will foster a more integrated financial management experience, helping users make informed decisions, optimize their finances, and improve their creditworthiness for loan eligibility
      Other Resources
      For similar work that has been worked on previously in the community, see: 
      Powered by Mifos – SoftiDoc 
      2024 GSOC Final Report (Akshat Sharma): 
      Final_Report.md 


      ~~~~~~~~~~
          Credit Bureau Integration Phase 5 
      Mentors
      @Nayan Ambali, @Ed Cable @Rahul Pawar 
      Length
      Medium - 175 hours
      Category 
      Platform - Modules | Core Development
      Overview & Objectives
      Mifos is a very strong loan management system but has room to improve around loan origination features. Credit Bureau integration is one of these key features to build upon. Because of regulatory reasons or to do background check of a client (risk management), MFIs depend on credit bureaus. As part of it, MFI must submit client details to credit bureau and also need to pull client information from credit bureau before approving any new loans to a client. Mifos X can be integrated with a popular CBs in India and from other regions (based on the demand).
      Description
      During the 2016, 2017, and 2020 Google Summer of Codes, Nikhil Pawar and Rahul Pawar completed the credit bureau integration module with integrations for the major credit bureaus in India and Myanmar. This project will continue extending the functionality of the module and work on integrations with the major credit bureaus in Latin America and Sub-Saharan Africa.
      The major functionality will be sending the data to CBs on regular intervals in the format CB expects. And option to pull the client’s information from CB whenever loan officer/branch manager/ user wants to view the information for a particular client.
      During 2025 it is expected to integrate a Credit Scoring standar which is the FICO® (Fair, Isaac, and Company). Although FICO® has many different scoring models, it uses relative percentage weights to help determine how much impact certain factors will have in helping determine a FICO® credit score. The main categories considered are a person’s payment history (35%), amounts owed (30%), length of credit history (15%), new credit accounts (10%), and types of credit used (10%).
      The Credit Burea information can be displayed while creating a new loan application because it will be used only during this process.
      Helpful Skills
       SQL, Java, Javascript, Git, Web Services, Big Data (Hadoop, Hive), API Rest,  
      Impact
      The credit report shows account information such as repayment record, defaults, type of loan, amount of loan, etc. of the customer. This information facilitates prudent decision-making when the credit underwriter processes the loan application. This help MFI to reduce the risk of bad loans and reduces the multiple lendings to same person from different MFIs.
      Other Resources
      For the scope of this project for 2024, see https://jira.apache.org/jira/browse/FINERACT-734
      Detailed requirements https://goo.gl/aZWMZa
      Mifos Credit bureau Integration. (Risk calibration Module -RCM)
      Source Code: 
      creditbureau configuration by nikpawar89 · Pull Request #215 · apache/fineract  
      FICO - 
      Puntuación de FICO® 
      EQUIFAX - 
      What is a FICO® Score, How is It Calculated | Equifax 
      Credit Scores - 
      Credit score in the United States 
      MyFico - 
      What is a Credit Score? | myFICO  
      
      ~~~~~~~~~~
      
      Optimize Payment Hub EE Operations UI with new Micro Front-Ends
      Mentors
      @Ed Cable @Mohit Bajoria @Jose Hernandez 
      Length
      Medium - 175 hours
      Category
      Web 
      Overview & Objectives
      For our Payment Hub EE integration layer and payment orchestration engine, we provide an operational user interface which allow staff of the financial institution participating in a real-time payment scheme to manage view detail of the incoming and outgoing transactions that are flowing through the switch, manually process refunds, complete reconciliations, view and take action on unsuccessful and disputed transactions, and more. 
      Description
      Intern will improve the operations app user interface for the following use cases.
      Transaction Details View
      Transaction Reconciliation
      Refund/Reverse transactions
      Operational Metrics and Dashhboards
      Business metrics and Dashboards Account Details
      Helpful Skills
      Javascript, CSS, HTML5. Angular and Bootstrap (CSS framework) is plus
      Impact
      Reference UI for microfinance institutions on Apache Fineract CN
      Other Resources
      Usability and Design
      Use Cases - 
      Use Cases & Requirements 
      Github
      GitHub - openMF/digital-bank-ui: Digital Bank user interface for staff on top of Fineract CN 
      https://github.com/openMF/digital-bank-ui/issues 
      
      ~~~~~~~~~~
      
      Security Penetration testing for Payment Hub EE 
      Mentors
      Godfrey Kutumela
      Length
      Medium - 175 hours
      Category
      Platform | Infrastructure
      Overview & Objectives
      Mifos Payment Hub EE is continuing to grow in its functional capbailities and breadth of use ceases being adopted for. We must ensure it  is super secure and impenetrable. Your mission, should you choose to accept it, is to prove us wrong, and help close gaps you may find.
      Description
      Beyond a one time exercise, you should integrate (some of) the tools you've used into our build chain so that, even after you've gone, tools flag up future newly introduced potential vulnerabilities.
      Helpful Skills
      Candidates applying for this project would ideally have prior experience in penetration testing, and document this in their application.
      Impact
      Re-assuring the more Entreprise-y type Mifos clients that they can safely bet on Mifos X as an MFI platform.
      Other Resources
      https://www.owasp.org/index.php/Main_Page
      https://code.google.com/p/zaproxy/
      http://wapiti.sourceforge.net
      Run FindBugs & related tools for some serious static code analysis
      http://en.wikipedia.org/wiki/Penetration_test
      
      
      ~~~~~~~~~~
      
      OpenG2P  - Digital Identity Proof of Concept on Sovrin & Hyperledger Indy
      Mentors
      Rachit Kansal
      Length
      Medium - 175 hours (Update)
      Category
      Platform & Modules - ID, Exploratory, Bleeding Edge
      Overview & Objectives
      Digital Identity is a pressing topic and for both generations of Fineract (1.x and CN), we'd like to have integration with emerging KYC and digital identity solutions.
      KYC (Know your customer) is a fundamental banking concept. It refers to the process of identifying a new customer at the time of account opening, in compliance with law and regulation. The identification requirements may be lower for low value accounts ("Tiered KYC"). The term is also used in connection with regulatory requirements for a provider to understand, on an ongoing basis, who their customer is and how they are using their account. Most of the banks are mandated to perform basic/extensive KYC, before they can serve their customers.
      Traditionally KYC is done in a centralised fashion where a central agency has the control over all the data. For example consider each bank like SBI, Deutsche, JP Morgan, etc. when creating a bank account, each of them requires a separate KYC process to be completed and all this data gets stored in their respective databases. Even the systems like Aadhar or social security number, etc. have the data stored in a central manner and maintained by the government. However, in recent times all these centralised identity servers continue to be hacked and the important and private data being stolen regularly.
      With the advent of blockchain concepts and technologies, it is not ideal but imperative that we shift from the traditional identity management to a more secure decentralised claim-based identity management system. This kind of system has multiple benefits:
      Decentralised system means that no one person has control over sensitive data.
      It enables the re-use of KYC, i.e. each financial institution or in our case each customer using Fineract may not have to perform its own complete KYC, but re-use the KYC already performed by others (those who have the power as issuing authority for any kind of claim).
      Cryptographic security is the heart of blockchain technologies enhancing privacy.
      Claim-based system where the end user/customer has the control over his data.
      Description
      See 
      Sovrin/Indy PoC for KYC in Fineract - Fineract - Apache Software Foundation  for details on the proof of concept 
      P0 requirements
      Setup and run an Hyperledger Indy Network with Stewards.
      Opening a bank account scenario.
      Applying for a loan scenario.
      P1 requirements
      Performing money transfer to a merchant online.
      Helpful Skills
      HTML, Spring, Hibernate, REST, Java, AngularJS, Javascript, SQL, Hyperledger Indy
      Impact
        Other Resources
      Sovrin: https://sovrin.org/
      Indy Getting Started: https://github.com/hyperledger/indy-sdk/blob/master/docs/getting-started/indy-walkthrough.md 
      Sovrin Whitepaper: https://sovrin.org/wp-content/uploads/2018/03/Sovrin-Protocol-and-Token-White-Paper.pdf
      Sovrin Stewards: https://sovrin.org/stewards
      
      
      ~~~~~~~~~~
      
      Mifos/Fineract Chatbot & Adapter 4.0 (AI)
      Mentors
      @raul.sibaja @Aleksandar Vidakovic @jeremy engelbrecht 
      Length
      Medium - 175 hours (Update to Large)
      Category
      Platform - Modules | AI | Exploratory
      Overview & Objectives
      For many of our users today, chat is a much more familiar form of user interface for them and it would be valuable to provide an extensible chatbot connected to Mifos/Fineract that could be used to both provide customer support as well as allow clients to directly interact with their accounts. See this post from ThitsaWorks for more: https://medium.com/@thitsaworks/chatbots-the-emergent-and-effective-tool-in-financial-education-f6e63baf9188
      Description
      This project will focus on building on the latest version of the chatbot. In 2019, our GSOC intern, Anshul extended the Mifos Chatbot and Adapter with better authentication, improved Natural Language Processing, and integration with the Slack, Telegram and Facebook messenger platforms. 
      The project will include both leveraging other open source libraries and components to build the chatbot and building the adapter to the chatbot for MIfos/Fineract which will act as the interaction between chatbot and Mifos. It will take the replies from chat and feed them into Mifos. The program will sit in between Mifos and Chat.
      Main components needed are:
      NLU (natural language understanding) /NLP (natural language processing) 
      This componentcomponent is probably a good candidate for integrating a suitable existing OS project. 
      Chat platform and/or protocols
      To establish the communication between user and the bot logic the project could either leverage (at least) one of the major chat platforms (e. g. Facebook messenger etc.) and/or use open source protocols like XMPP or IRC. It's probably best to evaluate existing chat frameworks/client libraries 
      Fineract adapter
      This is the part where most of the student's attention is needed (see use cases below). The student would have to evaluate to which extent a chatbot framework could be integrated or if there are better arguments to develop something Mifos specific.
      Note: only Apache license compatible libraries/frameworks/components can be used.
      It will cover the following use cases: 
      Enquiry of Loan Details
      Mifos/Chat adapter will allow authenticated user to enquiry details of loan based on loan ID.
      Check user/client authentication
      Get MFI name, 9-digits loan ID (xxxxxxxxx), 9-digits clients ID (xxxxxxxxx) if it is an authenticated user/client.
      Allow authenticated user/client to query loan details:
      Status of loan
      Outstanding principal and interest
      Next due date, due principal and interest
      Previous payment date, principal and interest (the last transaction of loan)
      Loan maturity date
      Overdue loan principal and interest (if have)
      Number of days in arrears for loan
      Penalty fees/charges
      Client activation date
      Loan disbursed date/amount/interest
      First repayment date
      Saving balance
      Saving interest (to date amount)
      Next meeting date
      Enquiry of Savings Details
      Saving activated date
      Saving balance
      Saving interest (to date amount)
      Last active transaction date
      Notifications through Chat Adapter
      Notification will be sent thru Mifos/Chat adapter to respective clients on the following events occur on their accounts. 
      Client account activation
      Client account rejection
      Loan disbursal
      Loan close
      Next due principal and interest (1/2 days in advance)
      Payment posted (there may have delay due to data entry)
      Next meeting date
      Saving deposit
      Saving withdrawal
      Saving close
      Update/delete details of clients (address, phone number, NRIC number)
      Update/delete details of group (group name, group leader, loan officer name)
      Upload documents
      Enquiry about Loan Products
      Check user/client authentication
      Get MFI name, 9-digits clients ID (xxxxxxxxx)
      (Provide a list of available loan products of MFI)
      Allow authenticated user/client to query loan product details based on selected product:
      Loan term
      Interest rate
      Max and min allowed amount to borrow
      Number of installments/repayments
      Enquiry about Group Information
      Mifos/Chat adapter will allow authenticated user (group leader) to enquiry on group member details.
      Check user/client authentication.
      Get MFI name, group leader name, group ID, center ID, branch name, (Is a group leader?)
      Allow authenticated client(group leader) to query group details:
      Next meeting date
      Clients who have overdue loan
      Enquiry about Branch Information
      Mifos/Chat adapter will allow authenticated user(branch manager) to enquiry on branch details.
      Check user/client authentication
      Get MFI name, branch manager Name, user id/name, Branch Name, (Is a branch manager?)
      Allow authenticated branch manager to query branch details:
      Number of clients of his/her branch
      Expected disbursement principal (today)
      Outstanding principal and interest
      Saving balance
      Number of clients awaiting for disbursal (today)
      New registered clients (today)
      Prospective clients (as of today)
      Number of clients (dormant) as of today
      Number of village/bloc/ward in a branch
        Helpful Skills
      SQL, Java, Git, Spring, OpenJPA, Rest
      Helpful: technical knowledge of (any) chat protocol (e. g. XMPP, IRC), experience with NPU/NLP
      Impact
        Other Resources
      2019 Progress: https://gist.github.com/iosdev747/2b7de87cd9b028bb97433ee2e26ad18d
      Source Code: https://github.com/openMF/mifos-chatbot
      AI/NLU services
      Google: https://dialogflow.com/
      Facebook: https://wit.ai/
      https://botkit.ai/
      https://www.ambiverse.com/
      https://github.com/ambi-verse/nlu-api-client-java
      Frameworks
      https://github.com/howdyai/botkit
      https://github.com/nitroventures/bot4j
      https://dev.botframework.com/
      Has a lot of information on integration with chat platforms/protocols: https://github.com/BotMill
      NLP/NLU components and tools
      https://opennlp.apache.org/
      https://deeplearning4j.org/java-ai
      https://github.com/AIMLang/aiml-java-interpreter
      https://nlu.rasa.ai/
      Tutorials
      https://dzone.com/articles/building-an-intelligent-chatbot-using-botkit-and-r
      https://dzone.com/articles/beginners-guide-to-creating-chatbots-using-dialogf-1
      https://tutorials.botsfloor.com/
      Other
      Extensive comparison: https://chatbotsjournal.com/25-chatbot-platforms-a-comparative-table-aeefc932eaff
      Seems outdated, maybe helps with some insights/inspiration: http://www.zionsoftware.com/products/jbuddy/botframework/
      
      
      ~~~~~~~~~~
      
      Community support through AI
      Mentors
      @David Higgins @Ed Cable 
      Length
      Medium - 175 hours
      Category
      Platform - Modules | AI | Exploratory
      Overview & Objectives
      The community for Mifos related applications has grown considerably over the past few years.  The applications are highly complex and implementors (especially those new to the projects) require support to be able to implement and develop these applications.
      Current support is via the Slack general channel and dispirate documentation, requests get different treatment depending who reads and responds.  As there is no dedicated resource for monitoring and response which means timescales can be elongated.
      The objectives of this project is to setup an initial AI bot and learning algorithm that can respond to questions and point users to the relevant answers or documentation.
      This would need to be across the range of Mifos/Fineract products that the slack channel currently accomodiates
      it would require some pre-training of the algorithms based on past questions
      Description
      Identify the best AI solution for the task.
      Create the AI PoC and train the algorithms
      Test its responses based on previous questions and answers.
      PoC could be limited to one product initially and have a breakout for additional assistance.
      Web integration e.g. chatbot could be added to websites.
      Helpful Skills
      HTML, Slack, AI
      Impact
        Other Resources


      ~~~~~~~~~~
     
      Small Projects
      These projects are of a 90 hour duration.
      Alignment with emerging Open Wallet Standards
      Integration with Open Banking and Open Payment Standards
      Design and Adoption of new frameworks like Compose Multi-platform
      End to End Demo in Mifos Gazelle 
      Alignment with Emerging Open Wallet Standards 
      Mentors
       @Ed Cable @David Higgins 
        Length
      Small - 90 hours
        Category 
      Mobile Development
        Overview & Objectives
      Mifos and Fineract are valuable Digital Public Goods critical to advancing the Sustainable Development Goal of No Poverty by providing both the core banking system of record to manage the store of value for a functional wallet/transactional account in which to send G2P payments to. Many different financial services can be layered on these accounts within Mifos and Fineract making them a powerful tool for financial inclusion. Apart from providing the back-end to manage these wallets, Mifos also provides a reference mobile wallet which can be extended to one’s local requirements.
      Recently there have been a number of cross-sector movements to establish standards and frameworks upon which any type of wallet could be built. These wallets could be used for financial use cases, identity use cases, health use cases, etc but standards and frameworks initial focus primarily centers around secure sharing of credentials and privacy of user data.  Mifos was a founding member of the Open Wallet Foundation and sits on the GovStack Wallet Building Block Working Group. 
        Description
      This project would consist of researching the different open wallet standards emerging from the Open Wallet Foundation, GovStack wallet building block, and could utilize other digital public goods for identity including Inji from MOSIP and the Gluu Project. 
      Research would include exploring the current status of the specifications, standards and designing a POC architecture for a mobile wallet that aligns with th standards and specifications in their current state. 
        Helpful Skills
      Java, Android, Kotlin, Mobile Development, Enterprise Architecture 
        Impact
      The OWF aims to set best practices for digital wallet technology through collaboration on standards-based OSS components that issuers, wallet providers and relying parties can use to bootstrap implementations that preserve user choice, security and privacy. (mission of Open Wallet Foundation)
        Other Resources
      Open Wallet Standards & Requirements
      OpenWallet Foundation – Linux Foundation Project 
      Why the World Needs an Open Source Digital Wallet Right Now 
      Payments | bb-payments 
      Open Source Tools for Identity & Credential Sharing
      Open Source Identity and Access Management 
      Overview | Inji 


      ~~~~~~~~~~
        Integration with Open Banking and Open Payment Standards 
      Mentors
       @Ed Cable @David Higgins 
        Length
      Small - 90 hours
        Category 
      Payments | Platform - Integrations 
        Overview & Objectives
      A huge democratizing force across the financial services sector is the Open Banking movement providing Open Banking APIs to enable third parties to directly interact with customers of financial institutions. We have recently started providing an Open Banking API layer that will allow financial institutions using Mifos and Fineract to offer third parties access to requesting account information and initiating payments via these APIs. Most recently the Mojaloop community, led by Google, has led the development of a centralized PISP API.  We have chosen to the folow the comprehensive UK Open Banking API standard which is being followed and adopted by a number of countriues through Sub-Saharan Africa and Latin America. The Interledger Foundation now also has an Open Payments Standard.
      All of these standard have great applicability to how our core banking and payment orchestration systems authorize, establish consent, access date, and initaite transactions via these third party APIs and standards for sharing information and initiating transactions 
        Description
      This project would consist of researching the all of the different open banking, open finance and open payment initiatives and their corresponding API specifications. The POC would consiste of designing and implementing ways in which Fineract could generate APIs that are compliant with these specifications and most importantly ways for Fineract and our Payment Hub EE to consume the APIs/standards for these initiatives.
        Helpful Skills
      Java, Android, Kotlin, Mobile Development, Enterprise Architecture 
        Impact
      More innovation, control, and access as they can securely enable third parties to access their data and initiate transactions on their behalf. 
        Other Resources
      Open Banking & Open Finance Standards & APIs
      Mojaloop Third Party API - 
      Third Party API | Mojaloop Documentation 
      Home - Open Banking 
      GitHub - interledger/open-payments: Protocol to setup payments between entities on the Web based on GNAP 
        
        
      ~~~~~~~~~~  
        NEW: End to End Demo within Mifos Gazelle 
      Mentors
        @David Higgins @Abhinav Kumar 
        Length
      Small - 90 hours
        Category 
      DevOps
        Overview & Objectives
      Mifos Gazelle deploys a number of components (DPGs) that can be used in end to end payment flows. The idea of Mifos Gazelle is that these can then have end to end demos run across them potentially linking to other systems external of the environment.
        Description
      This project would consist of researching a potential use-case. Defining the use-case and how it would flow within the environment. Identify any integrations with external components needed and using existing APIs to do this perhaps with the assistance of an external workflow system such as OpenFN. Creating the demo script, configurations for environment, demo data. Ensuring replicability e.g. that it could be repeated on a fresh install with low technical skill.  Documentation, presentation are key for this, this could be an idea webinar or demo/talk at a conference or event.
      Basically this project is limited by your imagination. 
      We can support multiple iterations of this project for different use-cases or it could be scaled up looking at multiple use cases to be a larger project.
        Helpful Skills
      Javascript, DevOps, Enterprise Architecture , soft skills such as research, impact understanding, presentation skills are as important.
        Impact
      This would enable DPI implementors to understand better the use cases within the Payments Ecosystem, accelerate the path to deployment increase adoption and increase financial inclusion
        Other Resources
      Mifos Gazelle : 
      Mifos Gazelle 
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-mifos-initiative/
    idea_list_url: https://mifosforge.jira.com/wiki/spaces/RES/pages/4271669249/Google+Summer+of+Code+2025+Ideas


  - organization_id: 157
    organization_name: The NetBSD Foundation
    no_of_ideas: 40 
    ideas_content: |

      Emulating missing linux syscalls (350h)
      Contact: tech-kern
      Duration estimate: 350h
      NetBSD has the capability to run binaries compiled for Linux under compat_linux. This is a thin in-kernel translation layer that implements the same ABI as the Linux kernel, translating Linux system calls to NetBSD ones.

      Not all Linux syscalls are implemented. This means some programs cannot run.

      This project is about identifying critical missing syscalls and adding support for them.

      In the course of this project, you should find at least one Linux binary that does not yet run on NetBSD using compat_linux to use as a test case (your mentor may have suggestions), trace the program to find the missing features it requires, make note of them, and begin implementing them in NetBSD's Linux compatibility layer.


      ~~~~~~~~~~

      Making a network driver MPSAFE (175h)
      Contact: tech-net
      Duration estimate: 175h
      Access to some hardware registers and other things can only be done by one CPU at a time.
      An easy way to do this is to make the entire network stack runs with a single lock held, so operations only take place on one core.
      This is inefficient, if you ever want to use more than one core, for faster performing cards.

      Adapting old drivers to be able to run with the rest of the network stack not having this lock will improve NetBSD networking.
      A large number of drivers must be adapted, and some of them can be emulated from virtual machines too, some examples:

      Realtek RTL8139 Gigabit Ethernet re(4) (supported by QEMU)
      AMD PCnet pcn(4) (supported by QEMU and VMware)
      Novell NE1000 ne(4) (supported by QEMU)
      Atheros/Killer Gigabit Ethernet alc(4)
      Attansic Gigabit Ethernet ale(4)
      Broadcom NetXtreme bnx(4)
      You may find others listed in pci(4). It is possible you have a computing device with a device for which the driver hasn't been converted yet.

      The file src/doc/TODO.smpnet in the NetBSD source tree contains a list of fully converted drivers that you may use an an example, as well as some general guidelines.

      When applying for this project, please note which driver you would like to work on.


      ~~~~~~~~~~

      Convert a Wi-Fi driver to the new Wi-Fi stack (175h)
      Contact: martin
      Mentors: martin
      Duration estimate: 175h
      The NetBSD Wi-Fi stack is being reworked to support newer protocols, higher speeds, and fine-grained locking using code from FreeBSD. As part of this work, all existing NetBSD Wi-Fi drivers need to be reworked to the new Wi-Fi code base.

      Successful completion of this project requires you to have access to hardware that is already supported by NetBSD but not yet converted. See the ?Driver state matrix for a list of devices to convert. Many older devices can be found cheap on sites like eBay.

      When applying for this project, please note which driver(s) you want to convert.



      ~~~~~~~~~~

      ALTQ Refactoring and NPF Integration (350h)
      Contact: tech-kern
      Mentors: Christos Zoulas
      Duration estimate: 350h
      ALTQ (ALTernate Queueing) is an optional network packet scheduler for BSD systems. It provides various queueing disciplines and other quality of service (QoS) related components required to control resource usage.

      It is currently integrated in pf(4) .

      Unfortunately it was written a long time ago and it suffers from a lot of code duplication, dangerous code practices and can use improvements both in the API and implementation. After these problems have been addressed it should be integrated with npf(4) .


      ~~~~~~~~~~

      RFC 5927 countermeasures against IPv6 ICMP attacks on TCP
      Contact: tech-kern
      Duration estimate: 1 month
      Assess and, if appropriate, implement RFC 5927 countermeasures against IPv6 ICMP attacks on TCP. Write ATF tests for any countermeasures implemented, as well as ATF tests for the existing IPv4 countermeasures.

      This project will close PR kern/35392.

      The IPv4 countermeasures were previously implemented here: https://mail-index.NetBSD.org/source-changes/2005/07/19/msg166102.html


      ~~~~~~~~~~

      auto create swap on memory pressure (175h)
      Contact: tech-kern
      Mentors: tech-kern
      Duration estimate: 175h
      When a system needs more memory but has free disk space it could auto create swap files and then delete them later.

      The ideal solution would be configurable for:

      thresholds for creation
      min/max (don't fill up the disk entirely)
      encryption settings
      The "listener" for the file creation should avoid thrashing, have timeouts, and handle disk space usage sanely.



      ~~~~~~~~~~

      Merge code from two Realtek Wifi Drivers (175h)
      Contact: tech-net
      Mentors: Jason R. Thorpe
      Duration estimate: 175h
      the urtwn and rtwn have a lot of duplicate code.
      Merging them will improve both.

      This project is on hold due to the conversion project needing to be completed first.

      ~~~~~~~~~~

      Userland PCI drivers (350h)
      Contact: tech-kern
      Mentors: Taylor R Campbell
      Duration estimate: 350h
      When developing device drivers inside the kernel, mistakes will usually cause the whole kernel to crash unrecoverably and require a reboot. But device drivers need not run inside the kernel: with rump, device driver code can be run as a process inside userland.

      However, userland code has only limited access to the hardware registers needed to control devices: currently, NetBSD supports only USB device drivers in userland, via ugen(4). NetBSD should additionally support developing PCI drivers in userland with rump -- at least one driver, iwm(4), was developed using rump, but on a Linux host!

      There are several milestones to this project:

      Implement enough of the bus_space(9) and pci_mapreg() (pci(9)) APIs to map device registers from PCI BARs, using a pci(4) device (/dev/pciN). A first approximation can be done using pci(3) and simply mmapping from mem(4) (/dev/mem), but it would be better to cooperate with the kernel so that the kernel can limit the user to mapping ranges listed in PCI BARs without granting privileges to read all physical pages in the system. Cooperation with the kernel will also be necessary to implement port I/O instead of memory-mapped I/O, without raising the I/O privilege level of the userland process, on x86 systems.

      Expose PCI interrupts as events that can be read from a pci(4) (/dev/pciN) device instance, and use that to implement the pci_intr(9) API in userland. For many devices, this may require a small device-specific shim in the kernel to acknowledge interrupts while they are masked -- but that is a small price to pay for rapidly iterating driver development in userland.

      Devise a scheme for userland allocate and map memory for DMA in order to implement bus_dma(9). Again, a first approximation can be done by simply wiring pages with mlock(3) and then asking the kernel for a virtual-to-physical translation to program hardware DMA registers. However, this will not work on any machines with an IOMMU, which would help to prevent certain classes of catastrophic memory corruption in the case of a buggy driver. Cooperation with the kernel, and maintaining a kernel-side mirror of each bus_dmamem allocation and each bus_dmamap.

      Inspiration may be found in the Linux uio framework. This project is not necessarily PCI-specific -- ideally, most of the code to manage bus_space(9), bus_dma(9), and interrupt event delivery should be generic. The focus is PCI because it is widely used and would be applicable to many drivers and devices for which someone has yet to write drivers.


      ~~~~~~~~~~

      VMWare graphical acceleration (350h)
      Contact: port-amd64
      Duration estimate: 350h
      VMWare provides an emulator that could use graphical acceleration, but doesn't on NetBSD.
      A DRM driver exists for linux which could be adapted, like other DRM drivers that were ported.

      ~~~~~~~~~~

      Real asynchronous I/O (350h)
      Contact: tech-kern
      Mentors: Taylor R Campbell
      Duration estimate: 350h
      The current asynchronous I/O (aio) implementation works by forking a background thread inside the kernel to do the I/O synchronously. This is a starting point, but one thread limits the amount of potential parallelism, and adding more threads falls down badly when applications want to have large numbers of requests outstanding at once.

      Furthermore, the existing code doesn't even work in some cases; this is not well documented but there have been scattered reports of problems that nobody had time to look into in detail.

      In order to make asynchronous I/O work well, the I/O path needs to be revised, particularly in the kernel's file system interface, so that all I/O operations are asynchronous requests by default. It is easy for high-level code to wait synchronously for lower-level asynchronous requests to complete; it is much more problematic for an asynchronous request to call into code that expects to be synchronous.

      The ?flow control project, which also requires substantial revisions to the I/O path, naturally combines with this project.



      ~~~~~~~~~~

      NPF user/group filtering
      Contact:
      tech-net
      Mentors: Christos Zoulas
      Duration estimate: 350h
      Add the ability to filter packets by user or group that owns the socket sending or receiving packets. This ability is available in other packet filters for example pf. The project involves modifying the parser to accept the syntax, passing the information to the kernel, and modifying the kernel packet filter code to process the user/group filtering options and allow/drop packets.


      ~~~~~~~~~~

      Tickless NetBSD with high-resolution timers (350h)
      Contact: tech-kern
      Mentors: Taylor R Campbell
      Duration estimate: 350h
      NetBSD configures a timer device to deliver a periodic timer interrupt, usually every 10 ms, in order to count time, wake threads that are sleeping, etc. This made sense when timer devices were expensive to program and CPUs ran at MHz. But today, CPUs run at GHz; timers on modern x86, arm, mips, etc. hardware are cheap to reprogram; programs expect greater than 10 ms resolution for sleep times; and mandatory periodic activity on idle machines wastes power.

      There are four main milestones to this project:

      Choose a data structure for high-resolution timers, and a way to request high-resolution vs low-resolution sleeps, and adapt the various timeout functions (cv_timedwait, etc.) to use it. The current call wheel data structure for callouts provides good performance, but only for low-resolution sleeps. We need another data structure that provides good performance for high-resolution sleeps without hurting the performance of the existing call wheel for existing applications.

      Design a machine-independent high-resolution timer device API, implement it on a couple machines, and develop tests to confirm that it works. This might be done by adapting the struct timecounter interface to arm it for an interrupt, or might be done another way.

      Convert all the functions of the periodic 10 ms timer, hardclock, to schedule activity only when needed.

      Convert the various software subsystems that rely on periodic timer interrupts every tick, or every second, via callout(9), either to avoid periodic work altogether, or to batch it up only when the machine is about to go idle, in order to reduce the number of wakeups and thereby reduce power consumption.

      Add a comment

      ~~~~~~~~~~

      Inetd enhancements -- Add new features to inetd (175h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 175h
      inetd is a classic method for launching network programs on-the-fly and some of its ideas are coming back into vogue. Enhancing this daemon should include investigations into other similar systems in other operating systems.

      Primary milestones:

      Prefork: Support pre-forking multiple children and keeping them alive for multiple invocations.
      Per service configuration file: Add a per-service configuration file similar to xinetd.
      Make the rate-limiting feature configurable on a per-service basis.
      Improve the logging and make logging modes configurable on a per-service basis.
      Nice to have:

      Add include directives to the configuration language to allow service definitions to be installed in /usr/share or /usr/pkg/share.
      Add a separate way to turn services on and off, so they can be defined statically (such as in /usr/share) and turned on and off from /etc.
      Allow non-privileged users to add/remove/change their own services using a separate utility.
      Integrate with the new blocklist daemon.
      Configuration compatibility for systemd socket activations

      ~~~~~~~~~~


      iscsictl(1) enhancement (175h)
      Contact: tech-net
      Mentors: Frédéric Fauberteau
      Duration estimate: 175h
      The iscsictl(1) program manages the iSCSI instances on the local computer. It communicates with the iscsid(8) daemon to send queries using iSCSI protocol.

      Possible enhancements:

      Review of iscsictl(1) manpage. For instance, the command add_target has no description, [target-opts] could be refered to "Target Options".
      Add a mode to iscsictl(1) program to log sessions at boot. It could be a batch command (the name could be discussed) that read a /etc/iscsi.conf file. Some parts of the iscsictl(1) from FreeBSD could be ported.
      Implement the find_isns_servers.
      The iscsi-target(8) server allows to setup iSCSI targets on a NetBSD host and to present block storage to the network. It can be used to test the iscsictl(1) implementation.




      ~~~~~~~~~~

      Test Linux emulation (350h)
      Contact: tech-userlevel
      Mentors: Stephen Borrill
      Duration estimate: 350h
      NetBSD has an extensive test suite that tests native kernel and userland code. NetBSD can run Linux binaries under emulation (notably on x86, but other platforms such as ARM have some support too). The Linux emulation is not covered by the test suite. It should be possible to run an appropriate subset of the tests when compiled as Linux binaries.

      The project could be completed in a number of steps:

      Determine tests that make sense to run under Linux emulation (e.g. syscalls)
      Compile tests on Linux and then run on NetBSD
      Add new/altered tests for Linux-specific APIs or features
      Build cross-compilation environment to build Linux binaries on NetBSD, to make the test-suite self-hosting
      Fix Linux emulation for tests that fail
      Use tests to add Linux emulation for syscalls missing (e.g.timer_*)
      It may also be instructive to look at the Linux Test Project.

      The project would initially be focussed on x86 (amd64 and i386)

      ~~~~~~~~~~

      Modern cryptographic algorithms to netpgp, netpgpverify (350h)
      Contact: Alistair G. Crooks, tech-crypto
      Mentors: Alistair G. Crooks
      Duration estimate: 350h
      Adapt existing ed25519 and salsa20 implementations to netpgp, netpgpverify
      Maintain compatibility and interoperability with gpg2's usage
      Maintain compatibility with openssh's keys
      Extend tests to cover new algorithms
      Extended goals:

      provide a standalone netpgp signing utility, to mirror the netpgpverify verification utility



      ~~~~~~~~~~

      Add UEFI boot options
      Contact: tech-install
      Currently NetBSD can be booted via UEFI firmware, but only offers the default boot loader setup so multi-boot environments are hard to create. This also causes cryptic displays in the firmware boot order menu or boot select menu, like "UEFI OS", instead of "NetBSD 10.0".

      The UEFI spec offers support to configure load options, which include a path to the bootloader and a description of the operating system, see the UEFI spec. This project is to implement setting up proper load option variables at least on x86 machines booting via UEFI.

      Part of the project is to find the best place to set this options up. Some integrations with sysinst might be needed, maybe sysinst is the right place to set this variables. If not, sysinst may simply be changed to use a different sub directory on the ESP for the NetBSD bootloader and the variables setup might happen elsewhere.

      Currently the kernel interface to access the SetVariable() and other EFI runtime callbacks exists, but there is no userland tool to operate it.

      It is not clear what the EFI path set in the variable should be, and mapping NetBSD disks/partitions to EFI path notation is not trivial. 

      ~~~~~~~~~~

      Audio visualizer for the NetBSD base system (350h)
      Contact: nia
      Mentors: nia
      Duration estimate: 350h
      NetBSD includes various simple, command-line audio tools by default, such as audioplay(1), audiorecord(1), mixerctl(1), aiomixer(1), audiocfg(1)...

      These tools are useful because they provide almost everything a user needs to test basic functionality of their audio hardware. They are critically important for basic diagnostics.

      It would be nice to have a tool to easily visualize audio input using a simple Curses interface. Some ideas for its possible functionality:

      Display basic live-updating frequency graph using bars
      Display channels separately
      'Echo' option (play back audio as it is input)
      pad(4) support (NetBSD has support for 'virtual' audio devices. This is useful because you can record the output of an application by having it output to the audio device that opening /dev/pad creates. This can also 'echo' by outputting the data read from the pad device.)
      You need NetBSD installed on physical hardware (older laptops work well and are cheaply available) and a microphone for this project. Applicants should be familiar with the C programming language.




      ~~~~~~~~~~

      Light weight precision user level time reading (350h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 350h
      Design and implement a mechanism that allows for fast user level access to kernel time data structures for NetBSD. For certain types of small data structures the system call overhead is significant. This is especially true for frequently invoked system calls like clock_gettime(2) and gettimeofday(2). With the availability of user level readable high frequency counters it is possible to create fast implementations for precision time reading. Optimizing clock_gettime(2) and alike will reduce the strain from applications frequently calling these system calls and improves timing information quality for applications like NTP. The implementation would be based on a to-be-modified version of the timecounters implementation in NetBSD.

      Milestones:

      Produce optimizations for clock_gettime
      Produce optimizations for gettimeofday
      Show benchmarks before and after
      start evolving timecounters in NetBSD, demonstrating your improvements

      ~~~~~~~~~~

      Query optimizer for find(1) (350h)
      Contact: tech-userlevel
      Mentors: David Holland
      Duration estimate: 350h
      Add a query optimizer to find(1).

      Currently find builds a query plan for its search, and then executes it with little or no optimization. Add an optimizer pass on the plan that makes it run faster.

      Things to concentrate on are transforms that allow skipping I/O: not calling stat(2) on files that will not be matched, for example, or not recursing into subdirectories whose contents cannot ever match. Combining successive string matches into a single match pattern might also be a win; so might precompiling match patterns into an executable match form (like with regcomp(3)).

      To benefit from many of the possible optimizations it may be necessary to extend the fts(3) interface and/or extend the query plan schema or the plan execution logic. For example, currently it doesn't appear to be possible for an fts(3) client to take advantage of file type information returned by readdir(3) to avoid an otherwise unnecessary call to stat(2).

      Step 1 of the project is to choose a number of candidate optimizations, and for each identify the internal changes needed and the expected benefits to be gained.

      Step 2 is to implement a selected subset of these based on available time and cost/benefit analysis.

      It is preferable to concentrate on opportunities that can be found in find invocations likely to actually be typed by users or issued by programs or infrastructure (e.g. in pkgsrc), vs. theoretical opportunities unlikely to appear in practice.

      ~~~~~~~~~~

      IKEv2 daemon for NetBSD (350h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 350h
      racoon(8) is the current IKEv1 implementation used in NetBSD. The racoon code is old and crufty and full of potential security issues. We would like to replace it. There are other implementations available, such as StrongSwan, openiked/isakmpd, racoon2.

      This project has two stages:

      Evaluate all 3 (or more) solutions, describe and document their pros and cons, and then settle into one of them.

      Port it to NetBSD to replace racoon.

      I have started working on that for racoon2 on https://github.com/zoulasc/racoon2/ (see the TODO file), and also have a build glue for NetBSD for it https://github.com/zoulasc/racoon2-glue/ and it works. I've also gotten openiked to compile (but not work).

      ~~~~~~~~~~

      Port launchd (350h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 350h
      Launchd is a MacOS/X utility that is used to start and control daemons similar to init(8), but much more powerful. There was an effort to port launchd to FreeBSD, but it seems to be abandoned. We should first investigate what happened to the FreeBSD effort to avoid duplicating work. The port is not trivial because launchd uses a lot of mach features.

      Milestones:

      report of FreeBSD efforts (past and present)
      launchd port replacing: init
      launchd port replacing: rc
      launchd port compatible with: rc.d scripts
      launchd port replacing: watchdogd
      Nice to have:

      launchd port replacing/integrating: inetd
      launchd port replacing: atd
      launchd port replacing: crond
      launchd port replacing: (the rest)



      ~~~~~~~~~~

      Add support for OpenCL and Vulkan to NetBSD xsrc (175h)
      Contact: nia
      Mentors: nia
      Duration estimate: 175h
      A core component of NetBSD is the 'xsrc' repository, which contains a 'classic' distribution of X11, all related programs, and libraries, as found on Unix systems from times of yore.

      xsrc uses the NetBSD build system and only BSD make to build, which means it builds extremely quickly, with minimal dependencies, and is easy to cross-compile. It currently includes an implementation of the OpenGL graphics API (Mesa), but not an implementation of the next-generation Vulkan graphics API, or OpenCL, the GPU-accelerated compute API, which can also be obtained from Mesa.

      Most of modern X.Org is built with Meson and Python, so some level of translation is required to integrate new components.

      This project involves making modifications to the Mesa Vulkan and OpenCL libraries in order to allow them to work on NetBSD (this part requires basic knowledge of the C programming language and Unix APIs), ideally submitting them upstream, until Vulkan and OpenCL support can be built on NetBSD, and then integrating the relevant components into the NetBSD build system using only BSD Make.

      The candidate should ideally have some knowledge of the C programming language and build systems.

      ~~~~~~~~~~

      Automatic tests for PAM
      Contact: tech-kern
      Mentors: Taylor R Campbell
      Duration estimate: 1-2 months
      Implement automatic tests with ATF for all the PAM modules under src/lib/libpam/modules.

      The modules, such as pam_krb5, are not currently automatically tested, despite being security-critical, which has led to severe regressions.




      ~~~~~~~~~~

      Efficient Package Distribution
      Contact: jkoshy
      Mentors: Joseph Koshy
      Duration estimate: 350h
      Implement efficient binary package updates by patching prior releases instead of downloading large packages afresh - please see: (jkoshy.net) Efficient Package Distribution

      Primary milestones:

      Define the patching protocol between the package manager client (i.e., pkgin) and the Patch server.
      Implement the 'Patch Server', defaulting to current behavior when binary patches are missing.
      Add patch protocol support to the pkgin package management client.
      On the 'Patch Server', implement a pipeline to generate binary patches whenever new package releases are added to it.
      Nice to have:

      Add file-format-specific (i.e., ELF-, JPEG-, PNG- specific) binary patch generation.



      ~~~~~~~~~~

      SASL-C implementation for the OpenLDAP client (350h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 350h
      OpenLDAP already has a SASL back-end for CYRUS-SASL.
      In NetBSD, we have our own SASL-C library which has similar functionality and can be used in OpenLDAP instead of CYRUS.
      Base postfix already does this.

      There is a cyrus.c file where all the work is done.
      We can make a saslc.c one that uses our library.
      This will allow different authentication schemes to be used for the client programs (so we will be able to run ldapsearch against an Active Directory server using GSSAPI.

      ~~~~~~~~~~

      Secure-PLT - supporting RELRO binaries (350h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 350h
      All architectures suffer from code injection issues because the only writable segment is the PLT/GOT. RELRO (RELocation Read Only) is a mitigation technique that is used during dynamic linking to prevent access to the PLT/GOT. There is partial RELRO which protects that GOT but leaves the PLT writable, and full RELRO that protects both at the expense of performing a full symbol resolution at startup time. The project is about making the necessary modifications to the dynamic loader (ld_elf.so) to make RELRO work.

      If that is completed, then we can also add the following improvement: Currently kernels with options PAX_MPROTECT can not execute dynamically linked binaries on most RISC architectures, because the PLT format defined by the ABI of these architectures uses self-modifying code. New binutils versions have introduced a different PLT format (enabled with --secureplt) for alpha and powerpc.

      Milestones:

      For all architectures we can improve security by implementing relro2.
      Once this is done, we can improve security for the RISC architectures by adding support for the new PLT formats introduced in binutils 2.17 and gcc4.1 This will require changes to the dynamic loader (ld.elf_so), various assembly headers, and library files.
      Support for both the old and new formats in the same invocation will be required.
      Status: * Added support to the dynamic loader (ld.elf_so) to handle protecting the GNU relro section. * Enabled partial RELRO by default on x86.



      ~~~~~~~~~~

      Research and integrate the static code analyzers with the NetBSD codebase (350h)
      Contact: tech-userlevel
      Mentors: Christos Zoulas
      Duration estimate: 350h
      The NetBSD sourcecode is verified by a static analyzers like Coverity. Attempt to automate the process, report and if possible fix bugs.

      Milestones:

      Consult and research the available tools.
      Integrate the tools for the purposes of the NetBSD project.
      Scan the sources, report bugs, if possible fix the problems, or file bug reports



      ~~~~~~~~~~

      Sysinst alternative interface (350h)
      Contact: tech-install
      Mentors: Marc Balmer, Martin Husemann
      Duration estimate: 350h
      The goal of this project is to provide an alternative version of the NetBSD system installer with a simple, X based graphical user interface.

      The installer currently uses a "homegrown" (similar to CUA) text based interface, thus being easy to use over serial console as well as on a framebuffer console.

      The current installer code is partly written in plain C, but in big parts uses C fragments embedded into its own definition language, preprocessed by the "menuc" tool into plain C code and linked against libterminfo.

      During this project, the "menuc" tool is modified to optionally generate a different version of the C code, which then is linked against standard X libraries. The C stub fragments sprinkled throughout the menu definitions need to be modified to be reusable for both (text and X) versions. Where needed the fragments can just call C functions, which have different implementations (selected via a new ifdef).

      Since the end result should be able to run off an enhanced install CD, the selection of widgets used for the GUI is limited. Only base X libraries are available. A look & feel similar to current xdm would be a good start.

      Developement can be done on an existing system, testing does not require actuall installation on real hardware.

      An optional extension of the project is to modify the creation of one or more port's install CD to make use of the new xsysinst.

      Milestones include: * modify the "menuc" tool to support X * keep text/serial console installing * demonstrate a GUI install * demonstrate fallback to the text installer

      The candidate must have:

      familiarity with the system installer. You should have used sysinst to install the system.
      familiarity with C and X programming.
      The following would also be useful:

      familiarity with NetBSD.
      familiarity with user interface programming using in-tree X widgets.
      References:
      sysinst source (opengrok)
      vnconfig(8) manual page



      ~~~~~~~~~~

      Verification tool for NetBSD32 (350h)
      Contact: tech-toolchain
      Mentors: Jörg Sonnenberger
      Duration estimate: 350h
      NetBSD supports a number of platforms where both 32bit and 64bit execution is possible. The more well known example is the i386/AMD64 pair and the other important one is SPARC/SPARC64. On this platforms it is highly desirable to allow running all 32bit applications with a 64bit kernel. This is the purpose of the netbsd32 compatibility layer.

      At the moment, the netbsd32 layer consists of a number of system call stubs and structure definitions written and maintained by hand. It is hard to ensure that the stubs and definitions are up-to-date and correct. One complication is the difference in alignment rules. On i386 uint64_t has a 32bit alignment, but on AMD64 it uses natural (64bit) alignment. This and the resulting padding introduced by the compiler can create hard to find bugs.

      goals/milestones:

      replace the manual labour with an automatic tool
      This tool should allow both verification / generation of structure definitions for use in netbsd32 code allow generation of system call stubs and conversion functions. Generated stubs should also ensure that no kernel stack data is leaked in hidden padding without having to resort to unnecessary large memset calls.

      For this purpose, the Clang C parser or the libclang frontend can be used to analyse the C code.

      ~~~~~~~~~~

      Add KNF (NetBSD style) clang-format configuration (175h)
      Contact: tech-toolchain
      Duration estimate: 175h
      clang-format is a tool to format source code according to a set of rules and heuristics. Like most tools, it is not perfect nor covers every single case, but it is good enough to be helpful.

      clang-format can be used for several purposes:

      Quickly reformat a block of code to the NetBSD (KNF) style.
      Spot style mistakes, typos and possible improvements in files.
      Help to follow the coding style rules.
      Milestones:

      Create configuration file .clang-format that approximate the NetBSD coding style
      Patch LibFormat to handle missing coding style rules.
      Integrate .clang-format with the NetBSD distribution.

      ~~~~~~~~~~

      Integrate libFuzzer with the basesystem (350h)
      Contact: tech-userlevel
      Mentors: Kamil Rytarowski
      Duration estimate: 350h
      Integrate the LLVM libFuzzer with the basesystem framework. Build and execute base programs against libFuzzer.

      Milestones:

      Ensure completeness of the toolchain in the basesystem.
      Add a new option for building the basesystem utilities with libFuzzer.
      Finish the integration and report bugs.



      ~~~~~~~~~~

      Integrate LLVM/GCC Sanitizers with pkgsrc (350h)
      Contact: tech-pkg
      Mentors: Kamil Rytarowski
      Duration estimate: 350h
      Add support in the pkgsrc framework for building packages with sanitizers.

      Expected sanitizer options:

      Address (ASan),
      Memory (MSan),
      MemoryWithOrigin (MSan with tracking the origin)
      Undefined (UBSan),
      Thread (TSan),
      Address;Undefined (ASan & UBSan)
      "" (empty string) - the default option
      Milestones:

      Ensure the availability of the toolchain and prebuilt userland with the sanitizers.
      Add new option in pkgsrc to build the packages with a each sanitizer.
      Build the packages and report problems and bugs.

      ~~~~~~~~~~

      Integrate Scudo with the basesystem (350h)
      Contact: tech-userlevel
      Mentors: Kamil Rytarowski
      Duration estimate: 350h
      Integrate the LLVM Scudo with the basesystem framework. Build and execute base programs against Scudo.

      Milestones:

      Ensure completeness of the toolchain in the basesystem.
      Add a new option for building the basesystem utilities with Scudo.
      Finish the integration and report bugs.
      Research Scudo for pkgsrc.



      ~~~~~~~~~~

      Enhance the syzkaller support for NetBSD (350h)
      Contact: tech-userlevel
      Mentors: Kamil Rytarowski
      Duration estimate: 350h
      There is an initial functional support for syzkaller for NetBSD (as guest). Resume the porting effort, execute and report kernel bugs.

      Milestones:

      Ensure completeness of the current support.
      Execute the fuzzer and gather reports, narrow down problems, translate to C reproducers.
      Add missing features, fix bugs in the NetBSD support.

      ~~~~~~~~~~

      Improve UI/UX of pkgsrc MESSAGE (175h)
      Contact: Leonardo Taccari, tech-pkg
      Duration estimate: 175h
      The current UI/UX of pkgsrc MESSAGE has a couple of drawbacks:

      When installing a lot of packages via pkg_add or pkgin it is often get lost
      When updating packages via pkg_add or pkgin - also if the MESSAGE is not changed - it is printed anyway
      For possible inspirations please look at OpenBSD ports' pkg-readmes and/or other package systems.

      ~~~~~~~~~~

      Port the Enlightenment desktop environment to NetBSD (350h)
      Contact: nia
      Mentors: nia
      Duration estimate: 350h
      pkgsrc is NetBSD's native package building system. It's also used on other platforms, such as illumos. It includes numerous graphical environments, including Xfce, MATE, and LXQt, but support for Enlightenment has since bitrotted and been largely removed. Support for its related fork Moksha is missing entirely.

      Enlightenment is partiuclarly interesting for NetBSD because it's lightweight, BSD licensed, and suitable for mobile applications. We're not sure about the benefits of Moksha over Enlightenment proper, but it's worth investigating.

      Since Enlightenment is written in C, the applicant should ideally have a basic understanding of C and Unix system APIs. In order for the port not to bit-rot in the future, it should be done well, with patches integrated upstream where possible. They should have a laptop with NetBSD installed (older laptops are likely more representative of typical NetBSD uses and can be picked up cheap from local auctions sites).

      Integrating Enlightenment into pkgsrc will require a knowledge of build systems and make (pkgsrc in particuar is built on top of BSD make).

      Milestones:

      A basic port enables basic Enlightenment installation on NetBSD when installed from pkgsrc.
      A more advanced and ideal port has tight integration with NetBSD system APIs, supporting features like native audio mixing and reading from sensors.
      For extra brownie points, the pkgsrc package should work on illumos too.

      ~~~~~~~~~~

      pkgin improvements (350h)
      Contact: tech-pkg
      Mentors: Emile 'iMil' Heitor, Jonathan Perkin
      Duration estimate: 350h
      pkgin is aimed at being an apt-/yum-like tool for managing pkgsrc binary packages. It relies on pkg_summary(5) for installation, removal and upgrade of packages and associated dependencies, using a remote repository.

      While pkgin is now widely used and seems to handle packages installation, upgrade and removal correctly, there's room for improvement. In particular:

      Main quest

      Support for multi-repository
      Speed-up installed packages database calculation
      Speed-up local vs remote packages matching
      Implement an automated-test system
      Handle conflicting situations (MySQL conflicting with MySQL...)
      Better logging for installed / removed / warnings / errors
      To be confirmed / discussed:

      Make pkgin independent from pkg_install binaries, use pkg_install libraries or abstract them
      Bonus I

      In order to ease pkgin's integration with third party tools, it would be useful to split it into a library (libpkgin) providing all methods needed to manipulate packages, i.e., all pkgin's runtime capabilities and flags.

      Bonus II (operation "burn the troll")

      It would be a very nice addition to abstract SQLite backend so pkgin could be plugged to any database system. A proof of concept using bdb or cdb would fulfill the task.

      Useful steps:

      Understand pkgsrc
      Understand pkg_summary(5)'s logic
      Understand SQLite integration
      Understand pkgin's `impact.c' logic


      ~~~~~~~~~~

      Improve support for NetBSD sensors and audio APIs in third-party software (350h)
      Contact: nia
      Mentors: nia
      Duration estimate: 350h
      pkgsrc is NetBSD's native package building system It includes numerous graphical environments, including Xfce, MATE, and LXQt, but many have limited support for native NetBSD system APIs, e.g. support for reading battery levels, and audio volume.

      We really would like better desktop environment integeration, and this requires some work on the upstream projects in C and in some cases C++.

      An applicant should have basic familiarity with build systems, make, and C. They should be good at carefully reading documentation, as much of this stuff is documented in manual pages like audio(4) and envsys(4). They should have a laptop with NetBSD installed (older laptops are likely more representative of typical NetBSD uses and can be picked up cheap from local auctions sites).

      They should be able to investigate the current level of support in various third-party projects and identify priority targets where native code for NetBSD can be written.

      Nia is very experienced in writing native code for NetBSD audio and sensors and would be happy to answer questions.

      As the project continues, we might even be able to start porting more applications and applets.



      ~~~~~~~~~~

      Add dependency information to binary packages (350h)
      Contact: tech-pkg
      Mentors: Thomas Klausner
      Duration estimate: 350h
      Change infrastructure so that dependency information (currently in buildlink3.mk files) is installed with a binary package and is used from there

      This is not an easy project.

      pkgsrc currently handles dependencies by including buildlink3.mk files spread over pkgsrc. The problem is that these files describe the current state of pkgsrc, not the current state of the installed packages.

      For this reason and because most of the information in the files is templated, the buildlink3.mk files should be replaced by the relevant information in an easily parsable manner (not necessarily make syntax) that can be installed with the package. Here the task is to come up with a definitive list of information necessary to replace all the stuff that's currently done in buildlink3.mk files (including: dependency information, lists of headers to pass through or replace by buildlink magic, conditional dependencies, ...)

      The next step is to come up with a proposal how to store this information with installed packages and how to make pkgsrc use it.

      Then the coding starts to adapt the pkgsrc infrastructure to do it and show with a number of trivial and non-trivial packages that this proposal works.

      It would be good to provide scripts that convert from the current state to the new one, and test it with a bulk build.

      Of course it's not expected that all packages be converted to the new framework in the course of this project, but the further steps should be made clear.

      goals/milestones:

      invent a replacement for buildlink3.mk files, keeping current features
      demonstrate your new tool as a buildlink3.mk replacement including new features
      execute a bulk build with as many packages as possible using the new buildlink





    
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-netbsd-foundation/
    idea_list_url: https://wiki.netbsd.org/projects/gsoc/

  - organization_id: 158
    organization_name: The P4 Language Consortium
    no_of_ideas:
    ideas_content: |
     
      Project 1: Integrate p4-constraints frontend into P4C ⤴️
      Basic info
      Potential mentors
      Primary: Matthew Lam
      Support: Jonathan DiLorenzo, Fabian Ruffy
      Skills
      Required: Git, C++
      Preferred: CMake, Bazel, P4C
      Discussion thread: TBD
      Alternative qualification task
      Currently, the type checking function, InferAndCheckTypes, explicitly fails when called on an already type-checked expression. Ideally, this behavior should be idempotent; causing no change to an already type-checked expression, but also not causing an error. This would allow us to use it to ensure that expression were properly typed and had certain types.
      Create a PR under https://github.com/p4lang/p4-constraints with the fix.
      Project description
      p4-constraints is a useful extension of the P4 programming language that is currently architected as a standalone library separate from the P4 compiler, P4C.
      The goal of this project is to integrate the p4-constraints frontend, which parses and type checks the constraint annotations, into the P4C frontend. This architecture change provides the following benefits:
      For P4 programmers: Immediate feedback about syntax or type errors in constraints during P4 compilation.
      For P4C backend developers: Easy consumption of the parsed & type-checked constraints.
      P4TestGen is a concrete example of a P4C backend that needs to consume p4-constraints to work correctly, and it currently does this by implementing its own p4-constraints frontend, which is brittle and requires duplication of work for new p4-constraint features.
      Expected outcomes
      The p4-constraints frontend becomes part of P4C.
      Resources
      https://github.com/p4lang/p4-constraints
      https://github.com/p4lang/p4c
      p4lang/p4c#4387


      ~~~~~~~~~~

      Project 2: BMv2 packet trace support ⤴️
      Basic info
      Potential mentors
      Primary: Matthew Lam
      Support: Jonathan DiLorenzo, Bili Dong, Antonin Bas
      Skills
      Required: Git, C++
      Preferred: P4
      Discussion thread: TBD
      Alternative qualification task
      Currently, BMv2 uses some legacy code written in C with bf_lpm_trie.c being one of the instances.
      Create a PR under https://github.com/p4lang/behavioral-model that converts the C code to C++. Note that style and readability are key.
      Project description
      Having programmatic access to the trace of a packet going through a P4 pipeline (e.g. applied tables, actions, entries hit, etc) has many use cases from human comprehension to use by automated tools for test coverage measurement, automated test generation, automated root causing, etc.
      BMv2 currently does provide textual logs that can be used to manually track the packet as it goes through the pipeline. However there is no API to access the trace in a more structured and programmatic form (i.e. in a way that can potentially be digested by other tools).
      The goal of this project is to provide a mechanism for BMv2 to record the trace and provide it to the user in a structured format.
      Expected outcomes
      Structured packet trace outputs supported in BMv2.
      Resources
      BMv2: https://github.com/p4lang/behavioral-model

      ~~~~~~~~~~


      Project 3: BMv2 with all possible output packets ⤴️
      Basic info
      Potential mentors
      Primary: Matthew Lam
      Support: Jonathan DiLorenzo, Bili Dong, Antonin Bas
      Skills
      Required: Git, C++
      Preferred: P4
      Discussion thread: TBD
      Alternative qualification task
      Currently, BMv2 uses some legacy code written in C with bf_lpm_trie.c being one of the instances.
      Create a PR under https://github.com/p4lang/behavioral-model that converts the C code to C++. Note that style and readability are key.
      Project description
      There are many situations where it is more useful to have all possible outputs from a P4 simulation rather than only a single one. For example, we use this for diff testing, to determine whether the switch is doing something correct or something incorrect.
      Multiple allowed behaviors usually arise from various multi-path constructs (e.g. ECMP, WCMP, or perhaps LAGs) usually modeled as action profiles in P4. BMv2 currently allows users to set a mode determining action profile behavior, like round robin which means that every time you send in the same packet, it should result in the next possible outcome (eventually wrapping around).
      The goal of this project is to provide a new mode for BMv2 to instead output ALL possible behaviors. This will both require extending the action profile modes, and likely extending the notion of output from a set of packets to a set of sets of packets.
      Expected outcomes
      BMv2 has a modality where every possible outcome is generated instead of one possible outcome.
      Must interact correctly with multicast and punting.
      Resources
      BMv2: https://github.com/p4lang/behavioral-model

      ~~~~~~~~~~
      Project 4: Finalize Katran P4 and improve the eBPF backend! ⤴️
      Basic info
      Potential mentors
      Primary: Davide Scano
      Support: Fabian Ruffy
      Skills
      Required: eBPF
      Preferred: P4C, P4
      Discussion thread: TBD
      Alternative qualification task
      Please demonstrate your XDP eBPF skills through contributions to any of the following projects:
      Any existing XDP eBPF project.
      Any personal project that has used XDP eBPF.
      Please demonstrate your basic P4 knowledge through contributions to any of the following projects:
      Any existing P4 project, preferably P4 tutorials or P4C.
      Any personal project that incorporates P4.
      Project description
      Katran is designed to build a high-performance load balancer based on C and eBPF. The P4 open-source compiler, P4C, supports eBPF as one of its possible targets. This allows a P4 program to be converted into an eBPF program for packet processing. The maintenance of the eBPF backend relies on simple examples that are used to test the backend. The lack of complex programs makes developing and evaluating new features, as well as identifying regressions, more challenging.
      Finalize the implementation of Katran in P4 helps provide a complex program example imporve the test coverage of eBPF backend. Due to that possible bugs can be identifed and fixd together with new features can be implemented.
      Expected outcomes
      Document and complete the P4 implementation of Katran.
      Identify and/or resolve bugs in the P4C eBPF backend.
      If needed, update the P4C eBPF backend documentation.
      Resources
      Katran: https://github.com/facebookincubator/katran
      Katran P4: https://github.com/Dscano//P4-Katran
      P4C eBPF backend: https://github.com/p4lang/p4c/tree/main/backends/ebpf
      NIKSS: https://github.com/NIKSS-vSwitch/nikss

      ~~~~~~~~~~
      Project 5: P4Simulator: Enabling P4 Simulations in ns-3 ⤴️
      Basic info
      Potential mentors
      Primary: Mingyu Ma
      Support: Tommaso Pecorella, Davide Scano
      Skills
      Required: P4, C++
      Preferred: ns-3, BMv2
      Discussion thread: TBD
      Project description
      P4Simulator is a P4-driven network simulator that aims to combine P4—the state-of-the-art programmable data plane language—with ns-3, one of the most popular and versatile network simulators. While the current module already supports basic P4 functionality in ns-3, there remain numerous areas that require further development, as outlined in the Alternative qualification task. We also welcome discussions on any other ideas or improvements you may wish to propose for P4Simulator.
      To advance the development of P4Simulator, we invite contributions in several key areas, including but not limited to:
      Control Plane Enhancement: Improving control plane support for seamless interaction between P4 programs and ns-3.
      PSA Architecture Completion: Implementing full support for the Portable Switch Architecture (PSA) within P4Simulator.
      High-Speed Ethernet Link Module: Developing a high-performance Ethernet link model to simulate real-world network conditions.
      Other Enhancements & Extensions: Exploring additional improvements to expand the functionality and efficiency of P4Simulator.
      Furthermore, we encourage discussions on novel ideas and enhancements that could contribute to the evolution of P4Simulator, making it a more powerful and flexible tool for network simulation research.
      Expected outcomes
      Complete the development and submission of the corresponding project.
      Resources
      p4simulator
      p4sim
      Currently, the p4sim repository is private (Prepare the paper for ICNS3), but it will be made open-source on March 21, 2025, at 17:00 EST. This delay allows for ongoing research, refinement, and the preparation of related publications before public release.
      
      ~~~~~~~~~~
      
      Project 6: P4MLIR: MLIR-based high-level IR for P4 compilers ⤴️
      Basic info
      Potential mentors
      Primary: Anton Korobeynikov
      Support: Bili Dong, Fabian Ruffy
      Skills
      Required: MLIR
      Preferred: P4, P4C
      Discussion thread: TBD
      A bit more information: slides
      Alternative qualification task
      Please demonstrate your MLIR skills through contributions to any of the following projects:
      P4MLIR itself.
      Any other MLIR-based compiler project.
      Your personal project is also fine.
      Make sure your contributions could demonstrate your knowledge of MLIR concepts & internals.
      Project description
      P4C, being a reference compiler for the P4 language, struggles with some fundamental shortcomings of its internal code representation (IR). These issues result in increased running time of the compiler itself as well as unacceptable memory consumption of certain compiler passes.
      Since these problems lie at the foundation of the present IR, as an alternative to just fixing them (that would require some redesign of the IR and would require some invasive changes in the compiler codebase) we are aiming to explore alternative solutions that might at the same time open more opportunities for future growth and expansion of the compiler. One of such possibilities is to explore the adoption of the results of MLIR project to be used within P4C.
      In particular, we aim to develop a P4-specific MLIR dialect (P4HIR) that would allow reuse the infrastructure, code analysis, and transformation passes that have recently been developed within MLIR framework.
      Since P4MLIR is a moving target, the precise set of tasks within this project is TBD at the time of project proposal submission. This might include (but not limited to):
      Implementation of certain dialect operations corresponding to P4 constructs
      Implementation of some dialect interfaces allowing high-level transformations (e.g. Mem2Reg, SROA, data flow analyses)
      Reimplementation of P4C frontend / midend passes in MLIR
      Lowering to P4 high-level dialect to lower-level constructs:
      Perform CFG flattening
      Lowering to llvm and / or emitc dialects
      ...
      Implementing control plane metadata emission out of P4HIR
      The exact list of tasks is to be determined with mentors.
      Expected outcomes
      Implementation of the mentioned P4HIR advancements
      Document the changes made
      Resources
      P4MLIR: https://github.com/p4lang/p4mlir
      P4C: https://github.com/p4lang/p4c
      MLIR: https://mlir.llvm.org/

      ~~~~~~~~~~
      Project 7: P4MLIR BMv2 Dialect Prototype ⤴️
      Basic info
      Potential mentors
      Primary: Bili Dong
      Support: Anton Korobeynikov, Fabian Ruffy
      Skills
      Required: MLIR
      Preferred: BMv2, P4
      Discussion thread: TBD
      Alternative qualification task
      Please demonstrate your MLIR skills through contributions to any of the following projects:
      P4MLIR itself.
      Any other MLIR-based compiler project.
      Your personal project is also fine.
      Make sure your contributions could demonstrate your knowledge of MLIR concepts & internals.
      Project description
      BMv2 is a popular software simulator target for P4. In our current open source P4 compiler P4C, when targeting BMv2, a P4 program is converted to a JSON file, which BMv2 uses as a specification for processing packets. In P4MLIR, we plan to add a dialect specifically for modeling BMv2 JSON primitives, so that the BMv2 dialect -> BMv2 JSON transformation could be straightforward.
      In the longer term, we expect a compilation path like P4C frontend -> P4HIR dialect -> BMv2 dialect -> BMv2 JSON. For this GSoC project, we will concentrate on implementing a subset of BMv2 JSON primitives in the BMv2 dialect, and implementing the corresponding BMv2 dialect -> BMv2 JSON transformation.
      Expected outcomes
      A subset of BMv2 JSON primitives are defined in the BMv2 dialect.
      The BMv2 dialect -> BMv2 JSON transformation works for this subset of primitives.
      Resources
      P4MLIR: https://github.com/p4lang/p4mlir
      BMv2 JSON format: https://github.com/p4lang/behavioral-model/blob/main/docs/JSON_format.md
      P4C BMv2 backend: https://github.com/p4lang/p4c/tree/main/backends/bmv2
      
      ~~~~~~~~~~
      
      Project 8: Gigaflow: A Smart Cache for a SmartNIC! ⤴️
      Basic info
      Potential mentors
      Primary: Annus Zulfiqar, Ali Imran
      Support: Davide Scano, Ben Pfaff, Muhammad Shahbaz
      Skills
      Required: Xilinx Vivado SDK/FPGA Development
      Preferred: OVS, P4, DPDK
      Discussion thread: TBD
      Alternative qualification task
      Please demonstrate your FPGA skills through contributions to any of the following projects:
      Any existing Xilinx Open NIC or NetFPGA projects.
      Any personal project that has used Xilinx Vivao tools.
      Please demonstrate your basic P4 knowledge through contributions to any of the following projects:
      Any existing P4 project.
      Any personal project that incorporates P4.
      Please demonstrate your basic Virtual Networking knowledge through contributions to any of the following projects:
      Any existing OVS project.
      Any personal project that incorporates OVS.
      Project description
      Open vSwitch (OVS) is a widely-adopted virtual switch (vSwitch) in cloud deployments and data centers. Gigaflow (appearing at ASPLOS'25) is a recent advancement that massively improves OVS forwarding performance by offloading a novel multi-table cache architecture to SmartNICs, thereby reducing the CPU-bound cache misses and improving the end-to-end forwarding latency. This project aims to develop a P4-based SmartNIC backend for Gigaflow cache in OVS for P4-programmable FPGA SmartNICs, e.g., the Xilinx Alveo U55/U250 Data Center Accelerator, and modern off-the-shelf SmartNICs, such as AMD Pensando DPU.
      Expected outcomes
      OVS-to-P4 Compilation Pipeline: Improve the existing OVS → P4-SDNet → FPGA codebase to enable seamless compilation to FPGA-based SmartNICs.
      SmartNIC Backend Development: Extend support beyond FPGA-based SmartNICs to include Pensando DPUs as a backend target.
      Upstream Integration: Work towards making Gigaflow a mainstream OVS backend, ensuring maintainability and adoption.
      Resources
      Gigaflow ASPLOS-25 Artifact: https://github.com/gigaflow-vswitch
      Open vSwitch: https://github.com/openvswitch/ovs
      P4 Language: Tutorial-1, Tutorial-2
      
      ~~~~~~~~~~
      
      Project 9: SpliDT: Scaling Stateful Decision Tree Algorithms in P4! ⤴️
      Basic info
      Potential mentors
      Primary: Annus Zulfiqar, Ali Imran
      Support: Davide Scano, Walter Willinger, Muhammad Shahbaz, Murayyiam-Parvez
      Skills
      Required: P4, HyperMapper
      Preferred: Scikit-Learn, PyTorch, Tensorflow, P4Studio
      Discussion thread: TBD
      Alternative qualification task
      Please demonstrate your basic P4 knowledge through contributions to any of the following projects:
      Any existing P4 project.
      Any personal project that incorporates P4.
      Please demonstrate your basic ML and Decision Tree knowledge through contributions to any of the following projects:
      Any personal project that incorporates Scikit-Learn or PyTorch/Tensorflow.
      Project description
      Machine learning is increasingly deployed in programmable network switches for real-time traffic analysis and security monitoring. SpliDT is a scalable framework that removes traditional feature constraints in decision tree (DT) inference by dynamically selecting relevant features at runtime rather than requiring a fixed set per flow. The goal is to enhance accuracy and scalability in high-speed network environments. This project aims to implement and optimize SpliDT using P4, TensorFlow, scikit-learn, and HyperMapper.
      Expected outcomes
      Develop a P4-based implementation of the partitioned DT inference model for P4-programmable switches, leveraging recirculation to efficiently manage resources.
      Use TensorFlow and scikit-learn to enhance DT training and feature selection through a custom optimization framework based on HyperMapper and Bayesian Optimization.
      Evaluate performance across programmable data planes, optimizing the balance between accuracy, scalability, and switch resource efficiency.
      The project will target deployment on Tofino-based switches and other programmable switch architectures, ensuring practical applicability in real-world network monitoring and security scenarios.
      Resources
      P4 Language: Tutorial-1, Tutorial-2
      In-Network ML: Taurus Tutorial at SIGCOMM
      HyperMapper: https://github.com/luinardi/hypermapper
      Tensorflow: https://www.tensorflow.org/
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-p4-language-consortium/
    idea_list_url: https://github.com/p4lang/gsoc/blob/main/2025/ideas_list.md

  - organization_id: 159
    organization_name: The Palisadoes Foundation
    no_of_ideas: 8
    ideas_content: |
      
      Talawa Admin Plugins
      Description:
      Fix and enhance the Talawa plugin system for improved extensibility, usability, and support for additional functionalities such as payment system integration. The current plugin system does not allow for the upload of source code into a predefined directory structure, limiting external contributions. This needs to be refactored and standardized.
      Expected Outcomes:
      Plugin System:
      Replace the existing plugin system with a more robust architecture allowing contributors to upload source code into a predefined directory structure.
      Support multiple external contributors to the Talawa code base.
      Operate similarly to WordPress plugins, enabling flexible and modular integrations.
      (Plugin) Payment System Integration:
      Refactor the plugin system to allow selective uploads of code for integrating payment systems, on a per-provider basis.
      Examples:
      PayPal integration as one plugin.
      Razorpay integration as another plugin.
      Use the WordPress plugin methodology as a guide.
      Maintain separate repositories (e.g., Talawa-plugin-*) for different plugins to support this functionality.
      This plugin would be used to accept single, recurring or fundraising campaign donations. Think of other feature areas where payments could be applicable.
      (Plugin) AI for Usability:
      Primary Features:
      Implement AI-driven SPAM filtering.
      Use AI for fact-checking comments.
      Secondary Features:
      Suggest improvements to event attendance.
      Propose volunteers for events.
      Generate announcements that yield better response rates.
      Integrate AI functionality into a separate repository for scalability.
      Refactoring:
      Reduce technical debt in the API, Talawa Mobile and Talawa Admin codebases related to this feature. Other refactoring is out of scope.
      Improve security to meet modern standards.
      References:
      https://docs-admin.talawa.io/docs/docs/plugins/plugin-architecture
      Repos to update:
      Talawa
      Talawa-API
      Talawa-Admin
      Depends on Project: N/A
      Project Size: 350 hours (Large)
      Possible Mentors:
      Tasneem Koushar (Primary)
      Meetul Rathore (Secondary)
      Difficulty: Medium
      Impact Definition: Core development


      ~~~~~~~~~~

      Improved Usability & Hardening - Talawa Mobile
      Description:
      Refactor and enhance the security features of the Talawa Mobile code base to reduce technical debt, enhance performance, improve security, and optimize usability. Address specific issues related to notifications, event management, and UX improvements.
      Expected Outcomes: We require the following:
      Security Enhancements:
      Strengthen security, especially for file uploads, and implement measures to combat malicious content.
      This is external to the XSS and encryption improvement projects that are currently underway.
      Notifications:
      Build a robust notification system for Talawa Mobile.
      Event Guest Invitations:
      Introduce functionality to invite guests to events through the app.
      Semiotics for UX Improvement:
      Augment text with symbols to improve accessibility and usability for users with limited literacy.
      General:
      Refactor the Talawa Mobile codebase accordingly to reduce technical debt, enhance performance, improve security, and optimize usability related to these features.
      Maximize the use of reusable code.
      Optimize GraphQL queries to minimize the volume and type of unnecessary results
      Related Improvements:
      Consider any other improvements related to the overall goal
      Repos to update:
      Talawa
      Talawa-Mobile
      Depends on Project: N/A
      Project Size: 350 hours (Large)
      Possible Mentors:
      Parag Gupta (Primary / TBD)
      Md. Noman Khan (Secondary)
      Difficulty: Medium
      Impact Definition: Core development


      ~~~~~~~~~~
      Notification Improvements - Talawa Admin
      Description:
      Refactor the messaging and notifcation features of the Talawa Admin code base to reduce technical debt, enhance security, and introduce new features related to notifications. Focus on improving the features and related UI/UX while ensuring the code meets modern best practices.
      Expected Outcomes: These are the expected outcomes:
      Notifications: We need to implement a notification system to make the applications more usable.
      Notification Template:
      Admin created, stored in the DB
      Blueprint for creating notifications.
      Defines the content, type, title, and channel (e.g., email, SMS, or in-app notification).
      The possibility of dynamic variables being injected into the template for personalization.
      Notification Log:
      Maintains a structured DB log of all notifications sent to users or organizations.
      Includes details about the sender, recipient, status, and any dynamic data (variables)
      The ability to be queried for delivery statistics, status tracking, usage patterns.
      Delivery:
      Notifications routed to the appropriate channel (email, in-app, or SMS) based on the template.
      Additional features for possible frontend deep linking.
      Engines & Services:
      Sound scalable methodologies must be found to implement the feature.
      Example:
      A new event is created.
      An administrator creates a template: "Hello {{userName}}, a new event {{eventName}} is live!"
      The backend triggers notifications:
      Template: Event Update.
      Variables: { userName: "Alice", eventName: "Hackathon"}.
      The Notification Engine sends personalized messages to all users.
      Other: Other non notification features include
      Event Guest Invitations:
      Add functionality to invite guests to events from the admin panel.
      Chat Feature:
      Refactor the chat system for better performance and integration with other features.
      Code Quality
      Maximize the use of reusable code
      Optimize GraphQL queries to minimize the volume and type of unnecessary results
      Related Improvements:
      Consider any other improvements related to the overall goal
      Repos to update:
      Talawa
      Talawa-Admin
      Depends on Project: N/A
      Project Size: 350 hours (Large)
      Possible Mentors:
      Disha Talreja (Primary)
      Rishav Jha (Secondary)
      Difficulty: Medium
      Impact Definition: Core development

      ~~~~~~~~~~
      Talawa Accessibility for Blind Users (Mobile)
      Description:
      Enhance Talawa’s accessibility features to support blind and visually impaired users. This includes transcription for voice messages, text-to-speech functionality, screen reader integration, and voice-activated commands.
      Expected Outcomes:
      Transcription for Voice Messages:
      Convert voice messages to text using the Google Speech-to-Text API.
      Display transcriptions below voice messages.
      Implement optional language detection for user-preferred language transcription.
      Text-to-Speech for Transcription:
      Provide TTS functionality using the Flutter TTS plugin to read transcribed text aloud.
      Screen Reader Integration:
      Ensure all voice messages and transcriptions are properly read by screen readers (e.g., TalkBack for Android, VoiceOver for iOS).
      Ensure navigation compatibility with assistive technologies for seamless interactions.
      Voice-Activated Commands:
      Add support for voice commands to play recent messages, start recording, or access transcriptions without touch gestures.
      Media Playback:
      Implement a media player for seamless voice message playback with accessibility features.
      Repos to update:
      Talawa
      Talawa-Mobile
      Depends on Project: N/A
      Project Size: 350 hours (Large)
      Possible Mentors:
      Md. Noman Khan (Primary)
      Shekhar Patel (Secondary / TBD)
      Difficulty: Medium
      Impact Definition: Inclusive development

      ~~~~~~~~~~
      Talawa Enhanced Testing
      Description:
      Improve the testing strategy across all Talawa codebases to ensure high-quality, secure, and maintainable code. Address issues like memory leaks, poor business logic, and lack of comprehensive test coverage. Integrate AI-driven tools for testing automation and efficiency.
      Expected Outcomes:
      Unit Testing with AI:
      Use AI tools like CodeRabbit.ai to create unit tests for all modules in the Talawa application.
      Memory Management Improvements:
      Utilize tools like Keploy or Tramline to optimize memory usage and reduce application bloat.
      End-to-End Testing:
      Perform E2E tests for the Talawa Admin and Mobile codebases using tools like Puppeteer and Jest.
      Reference: Talawa Admin Pull Request #580.
      Prevent Bad Practices:
      Implement mechanisms to catch and prevent poor coding practices, improving the codebase’s robustness and maintainability.
      Repos to update:
      Talawa
      Talawa-Admin
      Talawa-Mobile
      Depends on Project: N/A
      Project Size: 350 hours (Large)
      Possible Mentors:
      Kevonia Tomlinson (Primary)
      Tasneem Koushar (Secondary)
      Md. Noman Khan (Secondary)
      Difficulty: Medium
      Impact Definition: Core development


      ~~~~~~~~~~
      Enhanced SwitchMap-NG Web Features
      Description: The current web UI/UX needs to be improved to increase the usage of SwitchMap-NG by the wider community.
      Expected Outcomes:
      Web UI/UX (Priority)
      The code uses deprecated python packages that prevent upgrading the rest to current versions. The flask-table package is the most notable one
      The UI looks dated because it uses the flask-table package for HTML tables. A more modern alternative is needed. This may or may not be written in Python.
      The latest version offers many new features. We are eager to add new web based capabilities based on these additions that will increase the usage of SwitchMap-NG by the wider community. For example:
      Using LLDP data to create network topology charts
      Showing the historical movement of devices across the network
      Bandwidth charting
      Repository Strategy
      We want to migrate from a monorepo to a polyrepo strategy. We feel this will:
      Allow optimization of each subsystem's code using the appropriate best practices.
      Reduce the learning curve to contribute.
      Your plan must include approaches to do this
      Installation (Priority)
      Use the containerized solution in the switchmap-ng repo as a guide to containerizing your work
      Interaction between the equivalent replacements for the daemons must only communicate via existing GraphQL API calls for data.
      We need an easy to use installation and configuration script for the web UI.
      The structure of the configuration files could be improved.
      Documentation (Priority)
      Create autogenerated markdown documentation for developers from the code base based on code comments.
      This is already done in our Talawa* repositories.
      GitHub actions must be created to ensure that the auto-generated documentation is formatted according to our standards.
      The site must be autoupdated whenever the markdown mentioned in this section is changed.
      Testing (Priority)
      We want to achieve 100% test code coverage for the repository using GitHub actions
      We also want GitHub actions to fail if codecov.io code coverage criteria are not met and coderabbit.io does not approve the PR.
      Repos to Update: SwitchMap-NG
      Skills Required: Proficiency in the code stacks related to the repository. Refer to the introduction section for more details.
      Depends on Project: Enhanced SwitchMap-NG Scalability
      Project Size: 350 hours (Large)
      Possible Mentors:
      Aashima Wadhwa (Primary)
      TBD (Secondary)
      Difficulty: Medium
      Impact Definition: Risky/Exploratory


      ~~~~~~~~~~
      Enhanced SwitchMap-NG Scalability
      For the purposes of this section, the term polling should be interpreted as periodic data gathering.
      Description: SwitchMap-NG has multi-site capabilities, but we need more functionality for it to scale from a few to thousands of pollers.
      Expected Outcomes:
      Operation (Priority)
      The app isn’t suitable for a distributed deployment with groups of pollers that may not have access to the central API server. There needs to be an intuitive way for:
      pollers to reliably store and forward data to an aggregator in their region.
      each regional aggregator to send data to the central API server
      configuring this.
      The solution must tolerate poor connectivity between the pollers, aggregators and the API though a store and forward mechanism without the loss of data for a configurable amount of time.
      For the sake of simplicity, the pollers must get their configurations from the API either directly or through intermediate aggregators.
      Asynchronous Polling (Priority)
      The current python EasySNMP package is very resource intensive and must be replaced.
      Consider replacing multiprocessing / threaded polling with a faster asynchronous polling mechanism using Python’s asyncio or aiohttp for better scalability. This would allow polling of larger networks without blocking and improve the overall speed and resource usage. This would facilitate faster data collection, more efficient resource utilization, and the ability to scale to large networks.
      Another option would be to use a purpose built high performance SNMP application like MRTG/RRDTool to poll and/or evaluate the available SNMP parameters on the target devices.
      Realtime data updates by zone
      The current approach stores posted data to disk with periodic database updates.
      The speed of processing the data may have optimization potential.
      Different data types may require different polling intervals, for example device performance data versus device status data.
      This may require optimized, separate, purpose specific data gathering approaches.
      Historical Data Storage
      Use the current state database to more effectively store and analyze historical network data, such as port utilization, interface bandwidth rates, device status, and ARP data over time. This would allow users to analyze trends and detect issues that may have developed gradually.
      Additional Data Collection
      Extend SNMP support by parsing additional OIDs (MIB translations can be slower) for more detailed device information, such as CPU usage, memory stats, or interface statistics. This would make the inventory system more comprehensive.
      Repository Strategy
      We want to migrate from a monorepo to a polyrepo strategy. We feel this will:
      Allow optimization of each subsystem's code using the appropriate best practices.
      Reduce the learning curve to contribute.
      Your plan must include approaches to do this
      Installation (Priority)
      Use the containerized solution in the switchmap-ng repo as a guide to containerizing your work
      Interaction between the equivalent replacements for the daemons must only communicate via existing API calls. The RESTful posting of data to the DB API server’s file system should remain to reduce the potential overload unless a suitable alternative can be found.
      We need an easy to use installation and configuration script for the web UI.
      The structure of the configuration files could be improved.
      Documentation (Priority)
      Create autogenerated markdown documentation for developers from the code base based on code comments.
      This is already done in our Talawa* repositories.
      GitHub actions must be created to ensure that the auto-generated documentation is formatted according to our standards.
      The site must be autoupdated whenever the markdown mentioned in this section is changed.
      Testing (Priority)
      We want to achieve 100% test code coverage for the repository using GitHub actions
      We also want GitHub actions to fail if codecov.io code coverage criteria are not met and coderabbit.io does not approve the PR.
      Repos to Update: SwitchMap-NG
      Skills Required: Proficiency in the code stacks related to the repository. Refer to the introduction section for more details.
      Depends on Project: Enhanced SwitchMap-NG Web Features
      Project Size: 350 hours (Large)
      Possible Mentors:
      Dominic Mills (Primary)
      TBD (Secondary)
      Difficulty: Medium
      Impact Definition: Risky/Exploratory


      ~~~~~~~~~~
     
      Hybrid
      Note: It's important that you append a brief 3-4 word description to the name of your Hybrid idea. This will make it uniquely identifiable. It could assist us in selecting one or more hybrid ideas. For example if your hybrid idea is to improve the deployment of foo, you could name your project Hybrid - Foo Deployment. The title must have the word Hybrid in it.
      Description: Do the ideas need something more? What completely new thoughts could be applied to the existing ideas? If you have answers to these questions then this section is for you.
      Expected Outcomes: Your proposal must meet the guidelines below. It must:
      Not depend on other participants. There should be minimal impact by other participants disappearing or doing a very bad or very good job.
      Add completely new features not previously stated in ideas.
      Create features that users will want or facilitate new features that will be the groundwork for features that they would want.
      Be suitable for use by most non-profit organization.
      We are not interested in membership subscriptions and any related financial management at this time.
      Justify 350 hours of work.
      Repos to update: Talawa, Talawa-API, Talawa-Admin
      Skills Required: Code stacks related to repos above. See introduction section.
      Depends on Project: N/A
      Project Size: 350 hours (Large)
      Possible Mentors:
      Shannika Jackson (Primary)
      Tyrone Taylor
      Difficulty: Medium
      Impact Definition: Risky/Exploratory
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-palisadoes-foundation/
    idea_list_url: https://developer.palisadoes.org/docs/internships/gsoc/gsoc-ideas


  - organization_id: 160
    organization_name: The Rust Foundation
    no_of_ideas: 21
    ideas_content: |

      Extend annotate-snippets with features required by rustc
      Description
      rustc currently has incomplete support for using annotate-snippets to emit errors, but it doesn't support all the features that rustc's built-in diagnostic rendering does. The goal of this project is to execute the rustc test suite using annotate-snippets, identify missing features or bugs, fix those, and repeat until at feature-parity.
      Expected result
      More of the rustc test suite passes with annotate-snippets.
      Desirable skills
      Knowledge of Rust.
      Project size
      Medium.
      Difficulty
      Medium or hard.
      Mentor
      David Wood (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Compiler team

      ~~~~~~~~~~
      Reproducible builds
      Description
      Recent OSS attacks such as the XZ backdoor have shown the importance of having reproducible builds.
      Currently, the Rust toolchain distributed to Rust developers is not very reproducible. Our source code archives should be reproducible as of this pull request, however making the actual binary artifacts reproducible is a much more difficult effort.
      The goal of this project is to investigate what exactly makes Rust builds not reproducible, and try to resolve as many such issues as possible.
      While the main motivation is to make the Rust toolchain (compiler, standard library, etc.) releases reproducible, any improvements on this front should benefit the reproducibility of all Rust programs.
      See Tracking Issue for Reproducible Build bugs and challenges for a non-exhaustive list of reproducibility challenges.
      Expected result
      Rust builds are more reproducible, ideally the Rust toolchain can be compiled in a reproducible manner.
      Desirable skills
      Knowledge of Rust and ideally also build systems.
      Project size
      Medium.
      Difficulty
      Hard.
      Mentor
      Jakub Beránek (GitHub, Zulip)
      Related links
      Idea discussion
      Prior art in Go

      ~~~~~~~~~~
      Bootstrap of rustc with rustc_codegen_gcc
      Description
      rustc_codegen_gcc used to be able to compile rustc and use the resulting compiler to successfully compile a Hello, World! program. While it can still compile a stage 2 rustc, the resulting compiler cannot compile the standard library anymore.
      The goal of this project would be to fix in rustc_codegen_gcc any issue preventing the resulting compiler to compile a Hello, World! program and the standard library. Those issues are not known, so the participant would need to attempt to do a bootstrap and investigate the issues that arises.
      If time allows, an optional additional goal could be to be able to do a full bootstrap of rustc with rustc_codegen_gcc, meaning fixing even more issues to achieve this result.
      Expected result
      A rustc_codegen_gcc that can compile a stage 2 rustc where the resulting compiler can compile a Hello, World! program using the standard library (also compiled by that resulting compiler).
      An optional additional goal would be: a rustc_codegen_gcc that can do a full bootstrap of the Rust compiler. This means getting a stage 3 rustc that is identical to stage 2.
      Desirable skills
      Good debugging ability. Basic knowledge of:
      Intel x86-64 assembly (for debugging purposes).
      rustc internals, especially the codegen part.
      libgccjit and GCC internals.
      Project size
      Medium-Large depending on the chosen scope.
      Difficulty
      Hard.
      Mentor
      Antoni Boucher (GitHub, Zulip)
      Zulip streams
      Idea discussion
      rustc_codegen_gcc

      ~~~~~~~~~~
      Refactoring of rustc_codegen_ssa to make it more convenient for the GCC codegen
      Description
      rustc_codegen_gcc uses rustc_codegen_ssa and implements the traits in this crate in order to have a codegen that plugs in rustc seamlessly. Since rustc_codegen_ssa was created based on rustc_codegen_llvm, they are somewhat similar, which sometimes makes it awkward for the GCC codegen. Indeed, some hacks were needed to be able to implement the GCC codegen with this API:
      Usage of unsafe transmute: for instance, this or this. Fixing this might require separating Value into RValue and LValue or using Function in place of Value in some places to better fit the GCC API.
      Usage of mappings to workaround the API: for instance, this or this.
      Some other improvement ideas include:
      Separate the aggregate operations (structs, arrays): methods like extract_value are generic over structures and arrays because it's the same operation in LLVM, but it is different operations in GCC, so it might make sense to have multiple methods like extract_field and extract_array_element.
      Remove duplications between rustc_codegen_gcc and rustc_codegen_llvm by moving more stuff into rustc_codegen_ssa. For instance:
      some debuginfo code is exactly the same
      ABI code
      the allocator code
      the dummy output type for inline assembly
      perhaps we could add a set_alignment method in rustc_codegen_ssa that asks the backend to set the alignment and is called in rustc_codegen_ssa in strategic places so that we don't have to worry as much about alignment in the codegens (not sure if this is possible).
      The goal of this project is to improve rustc_codegen_gcc by removing hacks, unnecessary unsafe code and/or code duplication with rustc_codegen_llvm by refactoring rustc_codegen_ssa. It would be important that this refactoring does not result in a performance degradation for rustc_codegen_llvm.
      Expected result
      A rustc_codegen_gcc that contains less hacks, unsafe code and/or code duplication with rustc_codegen_llvm.
      Desirable skills
      Knowledge of Rust and basic knowledge of rustc internals, especially the codegen part.
      Project size
      Small-Medium depending on the chosen scope.
      Difficulty
      Medium.
      Mentor
      Antoni Boucher (GitHub, Zulip)
      Zulip streams
      Idea discussion
      rustc_codegen_gcc

      ~~~~~~~~~~
      ABI/Layout handling for the automatic differentiation feature
      Description
      Over the last year, support for automatic differentiation ('autodiff') was added to the Rust compiler. The autodiff tool which we are using (Enzyme) operates on LLVM-IR, which is the intermediate representation of code, used by LLVM. LLVM is the default backend of the Rust compiler. Unfortunately, two layout related problems limit its usability.
      A) The Rust compiler has a set of ABI optimizations which can improve performance, but make it harder for autodiff to work. An example is the function fn foo(a: f32, b: f32) -> f32, which the compiler might optimize to fn foo(x: i64) -> f32. While this is fine from an LLVM perspective, it makes it hard for Enzyme, the LLVM based autodiff tool. More information about such optimizations can be found here. If a function has a #[rustc_autodiff] attribute, the Rust compiler should simply not perform such optimizations. We don't want to disable these optimizations for all functions, as they are generally beneficial. Multiple examples of function headers which will get handled incorrectly at the moment are listed here.
      B) Enzyme requires good information about the memory layout of types, both to be able to differentiate the code, and to do so efficiently. In order to help Enzyme, we want to lower more Type Information from MIR or even THIR into LLVM-IR metadata, or make better usage of existing debug info. If you are interested in this part and also have some LLVM experience, please have a look at the LLVM website for the related proposal.
      For both A) and B), the online compiler explorer here can be used to trigger both types of bugs, to get a feeling for existing problems.
      Expected result
      The Rust compiler should not perform ABI optimizations on functions with the #[rustc_autodiff] attribute. As a result, #[autodiff(..)] should be able to handle functions with almost arbitrary headers. If a general solution turns out tricky, it is ok to focus on the most common types like those listed in the issue above (e.g. combinations of floats, small arrays/structs/tuples, etc.). We care less about advanced types like those listed here. These changes can't have a performance impact on functions without the #[rustc_autodiff] attribute.
      Newly working testcases should be added to the rust test suite. The rustc_autodiff parsing in the autodiff frontend might need small bugfixes if the new testcases discover additional bugs, but those can also be solved by other contributors.
      Examples for code that currently is not handled correctly can be discussed in the project proposal phase.
      Desirable skills
      Intermediate knowledge of Rust. Familiarity with ABIs is a bonus, but not required.
      Project size
      Medium
      Difficulty
      Medium to hard.
      Mentor
      Manuel Drehwald (GitHub, Zulip)
      Oli (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Automatic differentiation working group


      ~~~~~~~~~~
      Improving parallel frontend
      Description
      Improving compiler performance has always been a focus of the Rust community and one of the main tasks of the compiler team. Parallelization of rust compiler is an important and effective approach. Currently, the backend end (codegen part) of the compiler has been parallelized, which has brought a huge improvement in the performance of the compiler. However, there is still much room for improvement in the parallelization of the rust frontend.
      The most important and valuable work in this area are two aspects:
      A) Diagnosing and fixing deadlock issues caused by the execution order of compiler queries in a multithreaded environment. Queries is a unique design of the Rust compiler, which is used to achieve incremental compilation process. It divides the compiler process into various parts and caches the execution results of each part. However, queries caching dependencies between multiple threads may cause deadlock. Work-stealing, a method used to improve parallelization performance, is the core reason.
      To solve these problems, we need to find the part of the compiler process that causes deadlock through diagnosing coredumps in issues, and adjusting the execution order of this part of code so that there will be no circular dependencies on the query caches between multiple threads. This PR is a good example of solving a deadlock problem.
      B) Improving the performance of the parallel frontend The parallel frontend has implemented parallelization in type checking, MIR borrow checking and other parts of the compiler. However, there is still a lot of room for improvement:
      HIR lowering. Modifying the array structure of tcx.untracked.definitions so that it can be accessed efficiently in multiple threads is likely to be the key.
      Macro expansion. How to deal with the order problem of name resolution during macro expansion is a difficult problem.
      Lexing and/or parsing.
      Achieving the above goals is of big significance to improving the performance of the Rust compiler.
      The project could choose either one of these two areas, or try to tackle both of them together.
      Expected result
      Parallel frontend will not cause deadlock issues. We can ensure usability through UI testing.
      The performance of the compiler will be improved, ideally at least by a couple of percentage points.
      Desirable skills
      Intermediate knowledge of Rust. A basic understanding of the implementation of the compiler process (such as typeck, hir_lowering, macro expansion) would be ideal.
      Project size
      Medium to hard (depending on the chosen scope).
      Difficulty
      Medium to hard.
      Mentor
      Sparrow Li (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Parallel frontend working group
      Parallel frontend project goal

      ~~~~~~~~~~
      C codegen backend for rustc
      Description
      rustc currently has three in-tree codegen backends: LLVM (the default), Cranelift, and GCC. These live at https://github.com/rust-lang/rust/tree/master/compiler, as rustc_codegen_* crates.
      The goal of this project is to add a new experimental rustc_codegen_c backend that could turn Rust's internal representations into C code (i.e. transpile) and optionally invoke a C compiler to build it. This will allow Rust to use benefits of existing C compilers (better platform support, optimizations) in situations where the existing backends cannot be used.
      Expected result
      The minimum viable product is to turn rustc data structures that represent a Rust program into C code, and write the output to the location specified by --out-dir. This involves figuring out how to produce buildable C code from the inputs provided by rustc_codegen_ssa::traits::CodegenBackend.
      A second step is to have rustc invoke a C compiler on these produced files. This should be designed in a pluggable way, such that any C compiler can be dropped in.
      Desirable skills
      Knowledge of Rust and C, basic familiarity with compiler functionality.
      Project size
      Large.
      Difficulty
      Hard.
      Mentor
      Trevor Gross (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Compiler team
      Previous discussion about this topic
      Rust standard library


      ~~~~~~~~~~
      Extend testing of std::arch intrinsics
      Description
      The std::arch module in the standard library provides architecture-specific intrinsic functions, which typically directly map to a single machine instruction.
      These intrinsics are based on the architecture-specific intrinsics in C, which are usually based on a vendor specification and then implemented by C compilers such as Clang or GCC.
      Rust supports thousands of intrinsics and we need to verify that they match the behavior of the equivalent intrinsics in C. A first step towards this has been the intrinsic-test which fuzz tests the ARM (AArch32 and AArch64) intrinsics by generating C and Rust programs which call the intrinsics with random data and then verifying that the output is the same in both programs.
      While this covers the ARM architectures, we have thousands of intrinsics for other architectures (notably x86) which are only lightly tested with manual tests. The goal of this project is to extend intrinsic-test to other architectures: x86, PowerPC, LoongArch, etc.
      Expected result
      By the end of this project intrinsic-test should be able to validate the behavior of intrinsics on multiple architectures. The primary goal is to support x86 since this is the most widely used architecture, but stretch goals could include support for other architectures such as PowerPC, LoongArch, WebAssembly, etc.
      Desirable skills
      Intermediate knowledge of Rust and C. Knowledge of intrinsics or assembly is useful but not required.
      Project size
      Small to Medium.
      Difficulty
      Medium.
      Mentors
      Amanieu d'Antras (GitHub, Zulip)
      Zulip streams
      Idea discussion
      t-libs/stdarch


      ~~~~~~~~~~
      Infrastructure
      Implement merge functionality in bors
      Description
      Various Rust repositories under the rust-lang organization use a merge queue bot (bors) for testing and merging pull requests. Currently, we use a legacy implementation called homu, which is quite buggy and very difficult to maintain, so we would like to get rid of it. We have started the implementation of a new bot called simply bors, which should eventually become the primary method for merging pull requests in the rust-lang/rust repository.
      The bors bot is a GitHub app that responds to user commands and performs various operations on a GitHub repository. Primarily, it creates merge commits and reports test workflow results for them. It can currently perform so-called "try builds", which can be started manually by users on a given PR to check if a subset of CI passed on the PR. However, the most important functionality, actually merging pull requests into the main branch, has not been implemented yet.
      Expected result
      bors can be used to perform pull request merges, including "rollups". In an ideal case, bors will be already usable on the rust-lang/rust repository.
      Desirable skills
      Intermediate knowledge of Rust. Familiarity with GitHub APIs is a bonus.
      Project size
      Medium.
      Difficulty
      Medium.
      Mentors
      Jakub Beránek (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Infra team

      ~~~~~~~~~~
      Improve bootstrap
      Description
      The Rust compiler it bootstrapped using a complex set of scripts and programs generally called just bootstrap. This tooling is constantly changing, and it has accrued a lot of technical debt. It could be improved in many areas, for example:
      Design a new testing infrastructure and write more tests.
      Write documentation.
      Remove unnecessary hacks.
      Expected result
      The bootstrap tooling will have less technical debt, more tests, and better documentation.
      Desirable skills
      Intermediate knowledge of Rust. Knowledge of the Rust compiler bootstrap process is welcome, but not required.
      Project size
      Medium or large.
      Difficulty
      Medium.
      Mentor
      AlbertLarsan68 (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Bootstrap team


      ~~~~~~~~~~
      Port std::arch test suite to rust-lang/rust
      Description
      The std::arch module in the standard library provides architecture-specific intrinsic functions, which typically directly map to a single machine instruction.
      Currently, it lives in its own repository outside the main Rust compiler repository (rustc). The rustc repository includes stdarch only as a submodule, and does not execute its testsuite on the compiler's CI. This sometimes causes contributor friction, because updates to the compiler can break stdarch (and vice versa) and it is not possible to change both the compiler and stdarch at once (in the same pull request).
      stdarch has a comprehensive test suite that tests the intrinsics on several hardware architectures and operating system platforms, and it also includes fuzz tests. It cannot be simply copied over to rustc, because that has its own (much more complex) set of CI workflows. The stdarch testsuite thus has to be adapted to the way workflows are executed in the compiler repository.
      The ultimate goal is to inline stdarch into rustc completely, and archive the stdarch repository. This can be incrementally achieved by the following two steps:
      Investigate the CI (continuous integration) test suite of stdarch, and port as much of it into rustc. This will involve implementing new testing and documentation steps for working with stdarch in the compiler's build system, bootstrap.
      Once a sufficient portion of the test suite has been ported, stdarch should be changed from a submodule to either a git or Josh subtree, so that compiler contributors are able to make changes to stdarch when they modify the compiler. This might involve creating some automation tooling to help with performing regular synchronizations from/to stdarch. See this page for more details.
      Expected result
      The most important parts of the stdarch test suite should be running in the CI of the Rust compiler. Ideally, stdarch should be included as a git/Josh subtree instead of a submodule, or in the best possible scenario moved completely into rust-lang/rust.
      Desirable skills
      Intermediate knowledge of Rust. Experience with GitHub Actions or CI workflows is a benefit.
      Project size
      Small to Medium.
      Difficulty
      Medium.
      Mentors
      Jakub Beránek (GitHub, Zulip)
      Zulip streams
      Idea discussion
      t-libs/stdarch

      ~~~~~~~~~~
      Cargo
      Prototype an alternative architecture for cargo fix
      Description
      Some compiler errors know how to fix the problem and cargo fix is the command for applying those fixes. Currently, cargo fix calls into the APIs that implement cargo check with cargo in a way that allows getting the json messages from rustc and apply them to workspace members. To avoid problems with conflicting or redundant fixes, cargo fix runs rustc for workspace members in serial. As one fix might lead to another, cargo fix runs rustc for each workspace member in a loop until a fixed point is reached. This can be very slow for large workspaces.
      We want to explore an alternative architecture where cargo fix runs the cargo check command in a loop, processing the json messages, until a fixed point is reached.
      Benefits
      Always runs in parallel
      May make it easier to extend the behavior, like with an interactive mode
      Downsides
      Might have issues with files owned by multiple packages or even multiple build targets
      This can leverage existing CLI and crate APIs of Cargo and can be developed as a third-party command.
      See cargo#13214 for more details.
      Expected result
      A third-party command as described above
      A comparison of performance across representative crates
      An analysis of corner the behavior with the described corner cases
      Desirable skills
      Intermediate knowledge of Rust.
      Project size
      Medium
      Difficulty
      Medium.
      Mentor
      Ed Page (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Cargo team

      ~~~~~~~~~~
      Prototype Cargo plumbing commands
      Description
      Cargo is a high-level, opinionated command. Instead of trying to directly support every use case, we want to explore exposing the building blocks of the high-level commands as "plumbing" commands that people can use programmatically to compose together to create custom Cargo behavior.
      This can be prototyped outside of the Cargo code base, using the Cargo API.
      See the Project Goal for more details.
      Expected result
      Ideal: a performant cargo porcelain check command that calls out to individual cargo plumbing <name> commands to implement its functionality.
      Depending on the size the participant takes on and their experience, this may be out of reach. The priorities are:
      A shell of cargo porcelain check
      Individual commands until cargo porcelain check is functional
      Performance
      Desirable skills
      Intermediate knowledge of Rust.
      Project size
      Scaleable
      Difficulty
      Medium.
      Mentor
      Ed Page (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Cargo team

      ~~~~~~~~~~
      Move cargo shell completions to Rust
      Description
      Cargo maintains Bash and Zsh completions, but they are duplicated and limited in features.
      A previous GSoC participant added unstable support for completions in Cargo itself, so we can have a single implementation with per-shell skins (rust-lang/cargo#6645).
      Final project report
      GSoC project annotation
      Project discussion on Zulip
      There are many more arguments that need custom completers as well as polish in the completion system itself before this can be stabilized.
      See
      Clap's tracking issue
      Cargo's tracking issue
      Expected result
      Ideal:
      A report to clap maintainers on the state of the unstable completions and why its ready for stabilization
      A report to cargo maintainers on the state of the unstable completions and why its ready for stabilization
      Desirable skills
      Intermediate knowledge of Rust. Shell familiarity is a bonus.
      Project size
      Medium.
      Difficulty
      Medium.
      Mentor
      Idea discussion
      Ed Page (GitHub, Zulip)

      ~~~~~~~~~~
      Build script delegation
      Description
      When developers need to extend how Cargo builds their package, they can write a build script. This gives users quite a bit of flexibility but
      Allows running arbitrary code on the users system, requiring extra auditing
      Needs to be compiled and run before the relevant package can be built
      They are all-or-nothing, requiring users to do extra checks to avoid running expensive logic
      They run counter to the principles of third-party build tools that try to mimic Cargo
      A developer could make their build script a thin wrapper around a library (e.g. shadow-rs) but a build script still exists to be audited (even if its small) and each individual wrapper build script must be compiled and linked. This is still opaque to third-party build tools.
      Leveraging an unstable feature, artifact dependencies, we could allow a developer to say that one or more dependencies should be run as build scripts, passing parameters to them.
      This project would add unstable support for build script delegation that can then be evaluated for proposing as an RFC for approval.
      See the proposal for more details.
      Expected result
      Milestones
      An unstable feature for multiple build scripts
      An unstable feature for passing parameters to build scripts from Cargo.toml, built on the above
      An unstable feature for build script delegation, built on the above two
      Bonus: preparation work to stabilize a subset of artifact dependencies.
      Desirable skills
      Intermediate knowledge of Rust, especially experience with writing build scripts.
      Project size
      Large.
      Difficulty
      Medium.
      Mentor
      Idea discussion
      Ed Page (GitHub, Zulip)


      ~~~~~~~~~~
      rust-analyzer
      Implement a new proc-macro server RPC API
      Description
      Today, rust-analyzer (and RustRover) expands proc-macros by spawning a separate proc-macro server process that loads and executes the proc-macro dynamic libraries. They communicate to this process via a JSON RPC interface that has not been given much thought when it was implemented, now starting to show its limitations.
      The goal is to replace this current implementation entirely in favor of a more performant format that also supports the more complicated needs of the proc-macro API, outlined in rust-lang/rust-analyzer#19205.
      Expected result
      There exists a new proc-macro server that is more efficient and allows for implementing the remaining proc-macro API. Ideally, it should be integrated within rust-analyzer.
      Desirable skills
      Intermediate knowledge of Rust.
      Project size
      Medium.
      Difficulty
      Medium.
      Mentor
      Lukas Wirth (GitHub, Zulip)
      Zulip streams
      Idea discussion
      rust-analyzer team
      Crate ecosystem

      ~~~~~~~~~~
      Modernize the libc crate
      Description
      The libc crate is one of the oldest crates of the Rust ecosystem, long predating Rust 1.0. Additionally, it is one of the most widely used crates in the ecosystem (#4 most downloaded on crates.io). This combinations means that the current version of the libc crate (v0.2) is very conservative with breaking changes has accumulated a list of things to do in a 1.0 release. Additionally, some of the infrastructure for lib is rather outdated.
      Most of the changes required for 1.0 are under the 1.0 milestone. Some of these come from the evolution of the underlying platforms, some come from a desire to use newer language features, while others are simple mistakes that we cannot correct without breaking existing code.
      The crate used for testing libc (ctest) uses an old syntax parser that cannot support modern Rust, so some of the changes will require rewriting ctest to use a newer parser (e.g. syn). This upgrade is tracked at rust-lang/libc#4289.
      The goal of this project is to prepare and release the next major version of the libc crate.
      Expected result
      The libc crate is cleaned up and modernized, and released as version 0.3.
      Desirable skills
      Intermediate knowledge of Rust.
      Project size
      Medium.
      Difficulty
      Medium.
      Mentor
      Trevor Gross (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Library team

      ~~~~~~~~~~
      Add more lints to cargo-semver-checks
      Description
      cargo-semver-checks is a linter for semantic versioning. It ensures that Rust crates adhere to semantic versioning by looking for breaking changes in APIs.
      It can currently catch ~120 different kinds of breaking changes, meaning there are hundreds of kinds of breaking changes it still cannot catch! The goal of this project is to extend its abilities, so that it can catch and prevent more breaking changes, by:
      adding more lints, which are expressed as queries over a database-like schema (playground)
      extending the schema, so more Rust functionality is made available for linting
      Expected result
      cargo-semver-checks will contain new lints, together with test cases that both ensure the lint triggers when expected and does not trigger in situations where it shouldn't (AKA false-positives).
      Desirable skills
      Intermediate knowledge of Rust. Familiarity with databases, query engines, or query language design is welcome but not required.
      Project size
      Medium or large, depends on how many lints will be implemented. The more lints, the better!
      Difficulty
      Medium to high, depends on the choice of implemented lints or schema extensions.
      Mentor
      Predrag Gruevski (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Related Links
      Playground where you can try querying Rust data
      GitHub issues describing not-yet-implemented lints
      Opportunities to add new schema, enabling new lints
      Query engine adapter


      ~~~~~~~~~~
      Make cargo-semver-checks run faster
      Description
      As more lints get added to cargo-semver-checks, its runtime grows longer. As a result, users' iteration loops and CI pipelines take longer as well, degrading the overall experience of using the tool.
      Figure out ways to speed up cargo-semver-checks, and find good ways to deploy them without degrading the maintainability of the codebase!
      Expected result
      The wall-clock runtime of running cargo-semver-checks on a large Rust crate gets cut by 50-80%, while still running the same lints as before.
      Desirable skills
      Interest in and at least a bit of experience with performance engineering. Understanding of how to apply techniques like:
      profiling and benchmarking
      parallel programming (e.g. with rayon)
      building and applying indexes (in the database sense)
      Strong attention to detail. Willingness to learn quickly and perform lots of experiments, even though many of them may prove to be dead ends. Discipline and thoughtfulness when writing and testing code, to ensure that code changes are not merely fast but also maintainable.
      Project size
      Ideally large, to have the biggest possible positive performance impact.
      Difficulty
      Medium to high. See the "desirable skills" section above.
      Mentor
      Predrag Gruevski (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Related Links
      Playground where you can try querying Rust data
      Past optimization work: Speeding up Rust semver-checking by over 2000x
      Conference talk: How Database Tricks Sped up Rust Linting Over 2000x
      Query engine adapter, where many of the optimizations may be deployed
      
      ~~~~~~~~~~
      
      Enable witness generation in cargo-semver-checks
      Description
      When cargo-semver-checks reports a breaking change, it in principle has seen enough information for the breakage to be reproduced with an example program: a witness program. Witness programs are valuable as they confirm that the suspected breakage did indeed happen, and is not a false-positive.
      Expected result
      Automatic witness generation is something we've explored, but we've only scratched the surface at implementing it so far. The goal of this project would be to take it the rest of the way: enable cargo-semver-checks to (with the user's opt-in) generate witness programs for each lint, verify that they indeed demonstrate the detected breakage, and inform the user appropriately of the breakage and the manner in which it was confirmed. If a witness program fails to reproduce breakage flagged by one of our lints, we've found a bug — the tool should then prepare a diagnostic info packet and offer to help the user open an auto-populated GitHub issue.
      Stretch goal: having implemented witness generation, run another study of SemVer compliance in the Rust ecosystem, similar to the study we completed in 2023. The new study would cover many more kinds of breaking changes, since cargo-semver-checks today has 2.5x times more lints than it did back then. It would also reveal any new false-positive issues, crashes, or other regressions that may have snuck into the tool in the intervening years.
      Desirable skills
      Intermediate knowledge of Rust. Interest in building dev tools, and empathy for user needs so we can design the best possible user experience. Familiarity with databases, query engines, or programming language design is welcome but not required.
      Project size
      Large
      Difficulty
      Medium
      Mentor
      Predrag Gruevski (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Related Links
      Playground where you can try querying Rust data
      Use of witness programs to verify breaking change lints
      
      ~~~~~~~~~~
      
      Wild linker with test suites from other linkers
      Description
      The Wild linker is a project to build a very fast linker in Rust that has incremental linking and hot reload capabilities.
      It currently works well enough to link itself, the Rust compiler, clang (provided you use the right compiler flags) and a few other things. However, there are various features and combinations of flags that don’t yet work correctly. Furthermore, we have a pretty incomplete picture of what we don’t support.
      The proposed project is to run the test suite of other linkers with Wild as the linker being tested, then for each failure, determine what the problem is. It’s expected that many failures will have the same root cause.
      Expected result
      Write a program, ideally in Rust, that runs the test suite of some other linker. Mold’s test suite is pretty easy to run with Wild, so that’s probably a good default choice. The Rust program should emit a CSV file with one row per test, whether the test passes or fails and if it fails, an attempt to identify the cause based on errors / warnings emitted by Wild.
      For tests where Wild doesn’t currently emit any error or warning that is related to the cause of the test failure, attempt to make it do so. Some of the tests might fail for reasons that are hard to identify. It’s OK to just leave these as uncategorised. Where tests fail due to bugs or differences in behaviour of Wild, automatic classification likely isn’t practical. A one-off classification of these would be beneficial.
      If time permits, pick something achievable that seems like an important feature / bug to support / fix and implement / fix it.
      Desirable skills
      Knowledge of Rust. Any existing knowledge of low-level details like assembly or the ELF binary format is useful, but can potentially be learned as we go.
      Project size
      Small to large depending on chosen scope.
      Difficulty
      Some of the work is medium. Diagnosing and / or fixing failures is often pretty hard.
      Mentor
      David Lattimore (GitHub, Zulip)
      Zulip streams
      Idea discussion
      Further resources
      Wild linker
      Blog posts, most of which are about Wild
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-rust-foundation/
    idea_list_url: https://github.com/rust-lang/google-summer-of-code
  

  - organization_id: 161
    organization_name: The Tor Project
    no_of_ideas: 3
    ideas_content: |
   
      1. Project "Rewrite metrics-lib in Rust"
      Mentors:
      Hiro
      Sarthik
      Hours required: 350 hours
      Skills required: Rust + some Java
      Expected outcome: A library to process Tor network documents in Rust is available.
      Difficulty: medium
      Background
      Tor Metrics Library is a Java library that fetches and parses Tor descriptors.
      Metrics lib provides a Java API for processing Tor network data from the CollecTor service for statistical analysis and for building services and applications.
      Proposal
      The metrics pipeline is being restructured and is slowly moving away from a mostly JAVA codebase to a rust and python tool belt.
      This project would involve a complete re-implementation of the Tor metrics library in Rust.
      Metrics-lib is a JAVA based API that is used to parse and validate Tor network documents. The rust rewrite should provide the same parsing and validation functionalities provided by metrics-lib and in addition allow exporting of the documents in some external storage, like parquet files to be saved into object storage or a table on a postgresql database.
      Resources:
      https://gitlab.torproject.org/tpo/network-health/metrics/library
      https://metrics.torproject.org/metrics-lib.html
      https://gitlab.torproject.org/tpo/network-health/metrics/descriptorParser/
      https://gitlab.torproject.org/tpo/network-health/team/-/wikis/metrics/development/home
      
      
      ~~~~~~~~~~
      2. Project "Onion Service Support Tooling for Arti"
      Mentors:
      Gabi
      Wesley
      Hours required: 175 hours
      Skills required: Knowledge of Rust (experience with async programming is a plus); ability to use Git
      Expected outcome: the arti CLI is extended with more commands for key and state management; constructive discussions leading to changes to, or recommendations for, Arti's APIs and documentation.
      Difficulty: Medium
      Problem
      Arti has two state management subcommands, arti hss and arti hsc, for managing the state of onion services and onion service clients, respectively. These commands are currently very limited in functionality, and do not support many of the features onion service clients and operators will require.
      Proposal
      This project is about contributing to the tooling onion service clients and operators will need for managing the on-disk state and keys of their Arti onion services. It will involve extending the existing state management commands, as well as potentially adding new ones, and contributing to Arti's APIs and documentation.
      For example, the extra functionality we need includes but is not limited to:
      a subcommand for listing keys and certificates from the configured keystores
      a subcommand for performing consistency, validity, and integrity checks on the specified stores (this might also take an optional --fix flag, to fix the detected issues, if possible)
      an arti hss destroy-and-recreate subcommand, for generating a new identity (set of keys) for an existing onion service (this command will replace all the keys and state of the service)
      an arti hss destroy subcommand, for removing the persistent state and all the keys of a onion service.
      miscellaneous low-level "plumbing" subcommands, which deal with individual files from the keystore and state directories (for example. arti keys-raw remove-by-path)
      a C Tor to Arti key migration tool, which will enable onion service operators to seamlessly migrate from C Tor to Arti
      field-formatted output to be easily parseable by other programs (maybe enabled by a special flag) (when/if makes sense). Similar (but maybe better) functionality as gpg(1) --with-colons and many other CLI tools
      man pages for each CLI or subcommand
      A successful project will involve implementing some, or all, of the functionality described above.
      Resources
      The Arti repository: https://gitlab.torproject.org/tpo/core/arti
      About onion services: https://onionservices.torproject.org/technology/
      Table comparing the C Tor and Arti onion service implementations: https://onionservices.torproject.org/dev/implementations/
      The original state management CLI implementation plan: https://gitlab.torproject.org/tpo/core/arti/-/blob/main/doc/dev/notes/state-management-cli.md
      
      
      ~~~~~~~~~~
      
      3. Relay to relay connectivity in the Tor network
      mentors:
      juga
      gk
      hours: 175h
      skills:
      rust
      data analysis
      graph theory
      graph databases
      expected outcome:
      updated and streamlined partitioning detection tool (erpc)
      have a module to analyze the partitions in the Tor network and visualize it
      difficulty: medium
      Problem
      In an ideal world, any Tor relay would be able to reach any other Tor relay when trying to build paths through the network, as partitioning in the Tor network is bad for Tor's anonymity guarantees. During GSoC 2023 erpc got built, which is a tool implemented in Rust to check for partitions in the Tor network by building two hop circuits between all the relays.
      It stores the results in a graph database (neo4j). The graph vertices are the fingerprints of the relay and the edges are the relay pairs involved in the circuit. Also stored is the message obtained building the circuit and the timestamp.
      This data needs to be analyzed to find partitions in the Tor network and present them in a meaningful way.
      Proposal
      This project would involve updating and optimizing erpc to keep our dataset manageable. Additionally, it needs research into which algorithms are most suitable to find the partitions in the Tor network. Since the network is currently stored as a directed graph, we can apply community detection and clustering algorithms. Neo4j already offers several clustering algorithms within its Graph Data Science (GDS) library.
      The project would also involve writing the code to apply the partitioning algorithms and present the results. For example, a first approach could be listing the relay fingerprints and the number of other relays they're able to build a circuit to. This can be further improved in several ways, for instance by adding properties to the vertices like country, ASN, flags, family, etc. This would allow it to analyze separately the cyclic non-exits subgraphs and the acyclic exits subgraphs. It'd also be possible to detect whether some subgraphs are not connected because of families, ASN or other reasons.
      During the analysis and implementation it would be helpful to visualize parts of the graph, therefore the project would also involve to select some open source graph visualization tool and also implement the code to automaticaly analyze and visualize subgraphs.
      Resources:
      https://gitlab.torproject.org/tpo/team/-/wikis/gsoc-previous-years#1-relay-to-relay-connectivity-in-the-tor-network
      https://en.wikipedia.org/wiki/Graph_partition
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-tor-project/
    idea_list_url: https://gitlab.torproject.org/tpo/team/-/wikis/GSoC

  - organization_id: 162
    organization_name: The ns-3 Network Simulator Project
    no_of_ideas: 16
    ideas_content: |
     
      Small sized projects (90 hours)
      NTN example for 5G NR
      Mentors: Gabriel Ferreira, Amir Ashtari Gargari, Biljana Bojovic and Katerina Koutlia
      The objective of this project is the creation of a 5G NR example for the NTN use case. The example should provide a typical NTN topology, with a set of cells served by Low-Earth Orbit (LEO) satellites (e.g. Starlink, Kuiper), hence maybe an NTN topology helper could be created as a part of this project. The example should use the ns-3 3GPP NTN channel model. If handover is already functional, satellites should move at orbital speeds in their orbital planes, handing off users to the upcoming cell with LOS. We could explore scenarios (dense urban and urban).
      For starters, we would suggest adding the CTTC 5G-LENA (nr module) to ns-3, in the typical way (as a module in the contrib/ directory), and building and running the examples. Documentation is available from here: https://5g-lena.cttc.es/. There is an overview tutorial video available here: https://acmse.net/2021/tutorials-offered/#tut-work03. That is the background information.
      Required Experience: C++ programming, understanding of 5G NR, LTE, and wireless networks
      Interests: 5G NR simulations
      Difficulty: Medium.
      Patch requirement: See the description. You can also consider some of the nr good to start issues. Or, you can start writing some APIs for the selected project proposal. Also, if you have some previous MRs to ns-3 or the nr module, you can contact us to check whether it is enough for the patch requirement.
      
      

      ~~~~~~~~~~
      
      Upgrade the AQM Evaluation Suite for ns-3
      Mentors: Mohit P. Tahiliani
      AQM (Active Queue Management) evaluation suite for ns-3 helps to quickly study the performance of AQM algorithms based on the guidelines mentioned in RFC 7928. This suite automates simulation setup, topology creation, traffic generation, program execution, results collection and their graphical representation using ns-3 based on the scenarios mentioned in RFC 7928. It was designed and developed in 2017 and actively maintained till 2019. In the past few years, the traffic control model in ns-3 has grown significantly in terms of supporting state-of-the-art packet scheduling and AQM algorithms, and the ns-3 build system has changed from waf to cmake. This project has four main goals: (1) upgrade the AQM Evaluation Suite according to the latest ns-3-dev, (2) enable support for latest packet scheduling, AQM algorithms and ECN functionality (3) update the examples in AQM Evaluation Suite to better suit the needs of researchers working in this area, and (4) make AQM Evaluation Suite available on the ns-3 app store.
      Required Experience: Familiarity with AQM and C++ programming.
      Bonus Experience: Familiarity with traffic control model in ns-3.
      Interests: Packet Scheduling algorithms, AQM algorithms and ECN.
      Difficulty: Medium.
      Recommended Reading:
      AQM Evaluation Suite [Paper] [Implementation]
      RFC 7928
      Traffic Control Model in ns-3
      Patch requirement: Create a pull request to handle the case when an incorrect Scenario name or number is passed via command line.
      
      small size : 90 hours
      ~~~~~~~~~~
      Implementation of Alternative Backoff with ECN (ABE)
      Mentors: Mohit P. Tahiliani
      Alternative Backoff with ECN (ABE) is a newly proposed feature to enhance the performance of TCP when ECN is deployed. The main idea of ABE is to make the TCP sender respond differently to an ECN signal than it does for a packet loss. This project intends to implement, test and document this feature in ns-3. Additonally, an example program must be developed to demonstrate the usage of ABE in ns-3.
      Required Experience: Familiarity with ECN and C++ programming.
      Bonus Experience: Familiarity with traffic control model in ns-3.
      Interests: Packet Scheduling algorithms, AQM algorithms and ECN.
      Difficulty: Medium.
      Recommended Reading:
      Alternative Backoff with ECN [RFC 8511] [Paper]
      ECN support in ns-3
      Traffic Control Model in ns-3

      ~~~~~~~~~~



      Medium sized projects (175 hours)
      ICMP socket and generate/handle ICMP messages (host/net unreachable)
      Mentors: Tommaso Pecorella, Manoj K. Rana.
      The current IP stack in ns-3 does not provide an ICMP socket, and in order to send or receive ICMP packets (either IPV4 or IPv6) it is necessary to use a "RAW" socket. This approach works, but has a severe limitation: it does not work if the packet has been fragmented. Moreover, using a RAW socket is far more complex than a normal socket, as the receiver application must filter the incoming packets according to specific rules.
      The goal of the idea is to create, test, and document an ICMP socket that works both for IPv4 and IPv6, mimicking the Linux sockets socket(AF_INET, SOCK_DGRAM, IPPROTO_ICMP) and socket(AF_INET6, SOCK_DGRAM, IPPROTO_ICMPV6). Note that the choice of SOCK_DGRAM or SOCK_RAW (i.e., with or without the IP header) is totally left to the proposal.
      The most important point of the implementation should be code duplicate minimization, in order to have the minimize maintenance efforts.
      Once the sockets are in place, beside the "normal" tests, it will be necessary to modify the code that is actually made obsolete by the new sockets, e.g.:
      IPv6 ICMP messages (RA, RS, NA, NS, etc.),
      IPv4 ICMP messages,
      ICMP Echo and ICMPv6 Echo messages.
      and to handle properly ICMP error messages like Destination Unreachable in the Ping application.
      Required Experience: Fundamentals of IPv4 and IPv6 sockets, C++ programming.
      Interests: Sockets and API interface implementation.
      Difficulty: Medium.
      Recommended reading:
      Linux socket
      Raw Sockets and ICMP, Srinidhi Varadarajan
      Issue #810
      Possible tasks to fulfill the patch requirement:
      Submit a patch to fix Issue #809

      ~~~~~~~~~~
      6LoWPAN mesh-under routing enhancements
      Mentors: Tommaso Pecorella, [TBD].
      The 6LoWPAN module offers a simple option to implement a multi-hop topology by using a contolled flooding. However, the implemented controlled flooding is very simple, and is not efficient in complex networks. This is mainly due to the lack of congestion control, or rather its naive implementation. A better approach would be to borrow some concepts and ideas from RFC 7731 Multicast Protocol for Low-Power and Lossy Networks (MPL), so that messages do not generate network congestions when the network is large.
      The candidate should outline what parts of code are going to be affected, and how they can be enhanced thanks to RFC 7731.
      Required Experience: Fundamentals of IPv6 addressing, C++ programming.
      Bonus Experience: Familiarity with mesh routing and 6LoWPAN ns-3
      Interests: IPv6 mesh routing
      Difficulty: Easy.
      Recommended reading:
      Mesh-under in ns-3 6LoWPAN
      RFC 7731
      Possible tasks to fulfill the patch requirement:
      TBD

      medium size : 175 hours

      ~~~~~~~~~~
      6LoWPAN neighbor discovery protocol
      Mentors: Tommaso Pecorella, [TBD].
      The 6LoWPAN-ND (RFCs 4944, 6775, and 8505) is a replacement for IPv6 DAD and NDP for 6LoWPAN networks, and it is important to ensure address uniquness across a network that can potentially use different MAC/PHY layers.
      There is a model for 6LoWPAN-ND, but it still not merged in the main ns-3 branch. The goal is to cleanup the implementation, remove an actual limitation due to a questionble assumption, and to add the support for multi-hop operations (EDAR and EDAC messages).
      The candidate should outline in the proposal the parts of the code should be modified, and how. The repository for 6LoWPAN-ND is necessary, and the link will be shared upon request.
      Required Experience: Fundamentals of IPv6 addressing, C++ programming.
      Bonus Experience: Familiarity with 6LoWPAN and 6LoWPAN-ND
      Interests: IPv6 and IoT networks
      Difficulty: Easy.
      Recommended reading:
      RFC 8505
      RFC 6775
      RFC 4944
      Possible tasks to fulfil the patch requirement:
      Patch the actual 6LoWPAN-ND to remove the limitation about concurrent address registrations.
      
      medium size : 175 hours

      ~~~~~~~~~~
      
      Improving 5G NR module usability through helpers
      Mentors: Biljana Bojovic,Gabriel Ferreira, Katerina Koutlia and Amir Ashtari Gargari
      This project would be focused on improving the usability of the 5G nr module by enabling new helper support. The new helpers should allow for simplifying the setup of NR applications, XR applications, scenarios, the management of the configuration of many parameters of the scenario, etc. All the NR examples should be updated to make use of these new helpers. The use of such helpers would help reduce significantly the code duplication in 5G NR examples.
      For starters, we would suggest adding the CTTC 5G-LENA (nr module) to ns-3, in the typical way (as a module in the contrib/ directory), and building and running the examples. Documentation is available from here: https://5g-lena.cttc.es/. There is an overview tutorial video available here: https://acmse.net/2021/tutorials-offered/#tut-work03. That is the background information.
      Required Experience: C++ programming, understanding of 5G NR, LTE, and wireless networks
      Interests: 5G NR simulations
      Difficulty: Medium.
      Patch requirement: See the description. You can also consider some of the nr good to start issues. Or, you can start writing some APIs for the selected project proposal. Also, if you have some previous MRs to ns-3 or the nr module, you can contact us to check whether it is enough for the patch requirement.
      medium size : 175 hours

      ~~~~~~~~~~
      
      Enabling 5G NR examples visualization
      Mentors: Amir Ashtari Gargari, Gabriel Ferreira, Biljana Bojovic and Katerina Koutlia
      The main idea of this project is to allow easier visualization of 5G NR examples by integrating the NR module with some ns-3 visualization tools like NetAnim, or by implementing a kind of web-based visualization, e.g., through Jupyter notebook. The new feature should allow the visualization of already existing traces, visualization of topology, or even some new relevant simulation aspects could be considered. The idea is that users better understand how the metrics collection works, and how changing parameters can affect simulation results. In this project, we are open to other ideas on how to implement visualizations.
      For starters, we would suggest adding the CTTC 5G-LENA (nr module) to ns-3, in the typical way (as a module in the contrib/ directory), then building and running the examples. After getting used to C++, then proceed to use the Python bindings, as described by the documentation: https://www.nsnam.org/docs/manual/html/python.html#using-the-bindings-from-the-ns-3-source. Documentation is available here: https://5g-lena.cttc.es/. There is an overview tutorial video available here: https://acmse.net/2021/tutorials-offered/#tut-work03. That is the background information. For more specific guidelines, please view this Google document.
      Required Experience: C++ and Python programming, understanding of 5G NR, LTE, and wireless networks
      Interests: 5G NR simulations
      Difficulty: Medium.
      Patch requirement: See the description. You can also consider some of the nr good to start issues. Or, you can start writing some APIs for the selected project proposal. Also, if you have some previous MRs to ns-3 or the nr module, you can contact us to check whether it is enough for the patch requirement.
      
      medium size : 175 hours

      ~~~~~~~~~~
      Linux-like Loss Detection Techniques for ns-3 TCP
      Mentors: Mohit P. Tahiliani
      Forward Acknowledgement (FACK), Duplicate Selective Acknowledgement (DSACK), and Recent Acknowledgement (RACK) Tail Loss Probe (TLP) are the loss detection techniques implemented in the Linux kernel. These techniques have been already implemented for ns-3 TCP but their code is not yet merged into the mainline. This project has four main goals: (1) update the implementation of these techniques according to the latest ns-3-dev, (2) develop a framework to test the functionality of these techniques, (3) develop example program(s) to demonstrate the usage of these techniques in ns-3 and (4) merge these techniques in the mainline of ns-3.
      Required Experience: Familiarity with TCP and C++ programming.
      Bonus Experience: Familiarity with TCP implementation in Linux kernel.
      Interests: TCP packet loss detection techniques.
      Difficulty: Medium to Hard.
      Recommended Reading:
      Forward Acknowledgement (FACK) [Paper] [Implementation]
      Duplicate Selective Acknowledgment (DSACK) [RFC 2883] [Implementation]
      RACK-TLP [RFC 8985] [Implementation]

      medium size : 175 hours

      ~~~~~~~~~~
      AODVv2 Protocol enhancements
      Mentors: Tommaso Pecorella, [TBD].
      ns-3 contains models for proactive (DSDV and OLSR) and reactive (AODV and DSR) ad hoc routing protocols. AODVv2 is currently an IETF draft, and its implementation in ns-3 is ongoing. This project aims at enhancing the AODVv2 model for ns-3.
      In particular the project should address the following points: 1) AODVv2 performances, 2) AODV address compression, 3) "external" network routing support, 4) general model validation against the latest draft. Collaboration with the draft authors is also highly suggested.
      Required Experience: Fundamentals of IPv6 addressing, C++ programming.
      Bonus Experience: Familiarity with AODV implementations in ns-3 and AODVv2
      Interests: Ad hoc routing
      Difficulty: Medium.
      Recommended reading:
      IPv6 model in ns-3
      AODV model in ns-3
      Ad Hoc On-demand Distance Vector Version 2 (AODVv2) Routing
      Possible tasks to fulfill the patch requirement:
      Issue #368 - aodv: aodv parameters can be set to "impossible" values
      
      
      ~~~~~~~~~~
      Large projects (350 hours)
      IPv6 global routing
      Mentors: Tommaso Pecorella, [TBD].
      Creating a complex topology can be a problem, and sometimes the user do not want to be (also) concerned about setting up dynamic routing protocols (e.g., RIP, RIPng). For IPv4, ns-3 provides two alternatives: GlobalRouting, and NixRouting, which just "do the trick" - they simply fill the routing tables in intermediate nodes, GlobalRouting using an approach similar to OSPF, NixRouting by leveraging the "abstract" knowledge of the network. Neither actually use any message between the nodes, so they also reduce the network overhead - something that is useful in many cases.
      The problem is that GlobalRouting don't work for IPv6 (NixRouting was migrated to IPv6 recently), and that's a huge limitation. The goal of the project is to fix that limitation. Note that the project must cope with different IPv6 address kinds (link-local, global, scoped multicast, etc.).
      The most important point of the implementation should be code duplicate minimization, in order to have the minimize maintenance efforts. The proposer is advised to check the approach used for NixRouting, as it might be a starting point.
      Required Experience: Fundamentals of IPv6 addressing, C++ programming.
      Bonus Experience: Familiarity with GlobalRouting implementations in ns-3
      Interests: IPv6 routing
      Difficulty: Medium.
      Recommended reading:
      IPv6 model in ns-3
      GlobalRouting model in ns-3
      Possible tasks to fulfill the patch requirement:
      Add a function to print the path that a packet will use (according to Ipv4GlobalRouting), i.e., given source and destination IP print the IP addresses of the nodes that Ipv4GlobalRouting will use.
      
      ~~~~~~~~~~
      Mesh Link Establishment (MLE) protocol
      Mentors: Tommaso Pecorella, TBD.
      The Mesh Link Establishment (MLE) is a proposed IETF protocol for establishing and configuring secure radio links in IoT networks. It was originally proposed for IEEE 802.15.4, and the IETF draft seems to be not progressing. However, MLE is being used in Thread, and it can be useful to implement it.
      The goal of the project is to study the differences between the IETF version of MLE and the one being used in Thread, and propose an implementation that complies with either, or both.
      Required Experience: Fundamentals of IPv4 and IPv6 sockets, C++ programming.
      Interests: Sockets and API interface implementation.
      Difficulty: Hard.
      Recommended reading:
      MLE draft
      Thread primer
      Thread specifications
      Possible tasks to fulfill the patch requirement:
      TBD, contact the mentors if interested.

      large size : 350 hours


      ~~~~~~~~~~
      Lr-WPAN (IEEE 802.15.4) preamble detection support
      Mentors: Tommaso Pecorella, Alberto Gallegos Ramonet.
      A preamble is a series of defined bits that signal the data transmission between two or more devices. The current Lr-WPAN module takes into consideration the preamble transmission time but it does not support preamble detection (hence there is no chance of detection failure). Implementing preamble detection would have the added benefit of adding RSSI support to the Lr-WPAN module which itself has many added benefits.
      This project touches on some core PHY functions of the Lr-WPAN module (the detection of packets). Unlike similar ns-3 modules, Lr-WPAN is relatively simple, therefore, it is a good opportunity to learn about Lr-WPAN and how PHYs are handled in ns-3.
      As usual, reduction of code duplicity and a flexible scalable design is desired (e.g. Allow the inclusion of different preambles in the future).
      Required Experience: Basic understanding of IEEE 802.15.4, C++ programming.
      Bonus Experience: PHY process familiarity, Familiarity with ns-3's Lr-WPAN
      Interests: Lr-WPAN, MAC and PHY designs
      Difficulty: Medium.
      Recommended reading:
      IEEE 802.15.4-2006
      IEEE 802.15.4-2015
      ns-3 lr-wpan module
      Possible tasks to fulfill the patch requirement:
      TBD, contact the mentors if interested.


      large size : 350 hours


      ~~~~~~~~~~
      5G NR module integration with ns-3-ai
      Mentors: Katerina Koutlia, Gabriel Ferreira, Amir Ashtari Gargari and Biljana Bojovic
      The objective of this project is to integrate the ns-3 5G NR module with ns-3-ai. In GSoC 2024 we had a project in which 5G NR was integrated with ns-3 gym. While ns-3 gym is a popular ns-3 module for AI, it is limited to the application of reinforcement learning techniques in networking research. On the other hand, ns-3-ai module provides a more general solution that enables the data interaction between ns-3 and other Python-based AI frameworks, like Tensorflow C++ APIs and PyTorch C++ APIs, which opens the door to use different machine learning-based techniques in 5G NR models. The correct functioning of the integration should be tested, and documented, and a fully working example using ns-3-ai should be provided. The contributor can propose a use-case scenario for matching learning. One option is to use it for MAC scheduling, but it could be used for other 5G related research problems, and the contributor is encouraged to propose the use case of his/her interest.
      For starters, we would suggest adding the CTTC 5G-LENA (nr module) to ns-3, in the typical way (as a module in the contrib/ directory), and building and running the examples. Documentation is available from here: https://5g-lena.cttc.es/. There is an overview tutorial video available here: https://acmse.net/2021/tutorials-offered/#tut-work03. That is the background information. For more specific guidelines, please view this Google document.
      Required Experience: C++ programming, understanding of 5G NR, LTE, and wireless networks
      Interests: 5G NR simulations
      Difficulty: Medium.
      Patch requirement: See the description. You can also consider some of the nr good to start issues. Or, you can start writing some APIs for the selected project proposal. Also, if you have some previous MRs to ns-3 or the nr module, you can contact us to check whether it is enough for the patch requirement.
      
      
      large size : 350 hours


      ~~~~~~~~~~
      Linux-like CAKE queue discipline for ns-3
      Mentors: Mohit P. Tahiliani
      Common Applications Kept Enhanced (CAKE) is the most recent queue discipline added in Linux 4.19. It is a comprehensive queue management framework targeted for home Internet gateways, and integrates the following four components: bandwidth shaping, a new Active Queue Management (AQM) algorithm called COBALT (CoDel BLUE Alternate), handling Differentiated Services (DiffServ) and TCP ACK filtering. The main tasks in this project include: implementation, testing and documentation of individual components of CAKE in ns-3, followed by the integration of these components to form CAKE queue discipline in ns-3.
      Required Experience: Familiarity with queue disciplines, TCP and C++ programming.
      Bonus Experience: Familiarity with CAKE framework in Linux 4.19
      Interests: Active Queue Management, Packet scheduling and TCP.
      Difficulty: Medium to Hard
      Recommended reading:
      Piece of CAKE: A Comprehensive Queue Management Solution for Home Gateways
      Let them run CAKE
      Queue disciplines in ns-3
      
      
      large size : 350 hours


      ~~~~~~~~~~
      Switched Ethernet
      Mentors: Tommaso Pecorella, TBD.
      The current ns-3 models for wired connections are fine for simple networks, but the lack of a switched Ethernet model is a limitation in some cases.
      The goal of the idea is to create, test, and document a Switched Ethernet model, able to simulate (at least) 1, 10, and 40 GbE links and model for a switch.
      The model of the NetDevice and Channel shall take into account the link delays and errors, similarly to what is done by the point-to-point model. Futhermore, it should be able to set the link speed and if it is full-duplex or half-duplex. Additional support for flow control is a bonus, but not strictly required. Link speed auto-negotiation is not considered to be interesting.
      The model for the switch should be modular (i.e., allowing the development of different switch types), and include auto-learning of I/O ports based on the MAC address, i.e., have a MAC/port table, and a basic store-and-forward operation. Features like advanced I/O buffer handling and ARP/NDP spoofing detection are not a priority and shall be left for future implementations.
      The model should consider the future implementaion of algorithms like VLANs (IEEE 802.1Q, 802.1ad), and the Spanning Tree Protocol (IEEE 802.1D, 802.1w, and 802.1s). Their implementaion is not required, but the model design should allow their development.
      Required Experience: Fundamentals of Ethernet sitched networking, C++ programming.
      Interests: Ethernet networks and switched data networks.
      Difficulty: Medium.
      Recommended reading:
      Basic implementation (very old)
      Full-duplex CSMA, somehow related
      Paper on gigabit Ethernet switch models for simulation
      Possible tasks to fulfill the patch requirement:
      TBD, contact the mentors if interested.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/the-ns-3-network-simulator-project/
    idea_list_url: https://www.nsnam.org/wiki/GSOC2025Projects

  - organization_id: 163
    organization_name: Typelevel
    no_of_ideas: 12
    ideas_content: |
 
      MACHINE LEARNING INFERENCE IN CATS EFFECT
      We want to make it possible to deploy machine learning inference as part of a larger web service without compromising the latency of other on-going requests. The goal of this project is to create a compiler to transform a pre-trained ML model into a sequence of Cats Effect IO steps that perform inference on some input.
      PREREQUISITES
      Scala, ideally some experience with ML
      EXPECTED DIFFICULTY
      Hard but doable. Will draw on knowledge of ML and compilers.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @armanbilge @djspiewak @ekrich @valencik
      RELATED REPOS
      cats-effect
      AI WEB PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      SERVERLESS INTEGRATIONS FOR FERAL
      Feral is a Typelevel library for building serverless functions that currently supports AWS Lambda and Google Cloud Run Functions. We want to add support for more types of serverless events and more cloud providers.
      PREREQUISITES
      Scala, ideally experience with serverless
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Medium (~ 175 hours)
      MENTORS
      @armanbilge @bpholt @Chingles2404
      RELATED REPOS
      feral
      CLOUD PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      NATIVE I/O BACKEND FOR FS2 JVM
      FS2 on the JVM currently implements its networking API using JDK NIO. Unfortunately this indirection incurs a non-trivial performance penalty. We want to replace the use of JDK NIO with direct calls to system I/O APIs such as epoll and kqueue.
      PREREQUISITES
      Scala, ability to read C
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @antoniojimeneznieto @djspiewak @mpilquist @armanbilge
      RELATED REPOS
      fs2
      OPERATING SYSTEMS PROGRAMMING LANGUAGES


      ~~~~~~~~~~
      POLLING-BASED I/O IN FS2
      Cats Effect v3.6.0 introduced the ability to poll for I/O readiness. We want to use polling to reimplement several I/O APIs in FS2, including datagrams, unix sockets, and processes, on the JVM and Native platforms.
      PREREQUISITES
      Scala, ability to read C
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @armanbilge @mpilquist @antoniojimeneznieto
      RELATED REPOS
      fs2
      OPERATING SYSTEMS PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      FS2 CONNECTION API
      TCP-based protocols are common (e.g. HTTP, Postgres, Redis) and are implemented by clients to interface with these services (e.g. Ember, Skunk, Rediculous). The goal of this project is to create a “connection” API that supports pooling, error conditions, and metrics and can be shared by all of our client libraries.
      PREREQUISITES
      Scala, ideally some knowledge of networking
      EXPECTED DIFFICULTY
      Hard.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @mpilquist @armanbilge
      RELATED REPOS
      fs2
      OPERATING SYSTEMS PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      WEB COMPONENTS FOR CALICO
      Calico is a reactive UI library built with Cats Effect and FS2. Web Components are a standard for creating framework-agnostic, reusable UI elements. The goal of this project is to enable Calico users to access the vast array of web components available by improving its DSL and code-generation.
      PREREQUISITES
      Scala, ideally experience with Web APIs
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @armanbilge
      RELATED REPOS
      calico
      WEB PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      UPGRADE SBT-TYPELEVEL TO SBT 2
      sbt-typelevel is a plugin for sbt, the Scala build tool, used by hundreds of open source and enterprise projects. sbt 2 is in the final stages of development. We want to upgrade sbt-typelevel to sbt 2 and adopt its new features, such as “project matrix” for cross-building.
      PREREQUISITES
      Scala
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @mzuehlke @armanbilge
      RELATED REPOS
      sbt-typelevel
      DEVELOPMENT TOOLS

      ~~~~~~~~~~
      REFRESH DAVENVERSE PROJECTS
      The Davenverse is a collection of several popular Typelevel libraries, including Mules and cats-scalacheck. Unfortunately, we have fallen behind on their maintenance. We want to move these libraries under the Typelevel org, refresh their build tooling, and bring them up-to-date to ensure their longevity.
      PREREQUISITES
      Scala
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Medium (~ 175 hours)
      MENTORS
      @samspills @valencik
      RELATED REPOS
      davenverse
      DEVELOPMENT TOOLS PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      CATS EFFECT & FS2 ON WASM/WASI
      Web Assembly and its System Interface are emerging technologies for deploying secure, modular applications. The goal of this project is to prototype porting the Cats Effect runtime and FS2 streaming I/O to the Wasm/WASI platform, also possibly generating feedback for the Scala WASM and WASI teams.
      PREREQUISITES
      Scala, ideally some experience with Wasm/WASI
      EXPECTED DIFFICULTY
      Hard. Wasm/WASI support in Scala is experimental.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @armanbilge @tanishiking @valencik
      RELATED REPOS
      cats-effect fs2
      WEB CLOUD OPERATING SYSTEMS PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      EXTENSIBLE LOG4CATS INTERFACE
      log4cats is the de facto logging library for the Typelevel stack. Recently, a new API was proposed that overcomes current limitations of log4cats. The goal of this project is to adopt the new API in log4cats, migrate existing integrations to the new API, and create a compatibility layer with the old API.
      PREREQUISITES
      Scala
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Long (~ 350 hours)
      MENTORS
      @morgen-peschke @kubukoz @irevive
      RELATED REPOS
      log4cats
      CLOUD PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      HTTP4S-FS2-DATA
      fs2-data is a streaming data library that supports a plethora of formats. http4s is a library for creating and consuming web services. http4s-fs2-data is a project to integrate the two libraries. We want to integrate more fs2-data modules as well as enhance the existing integrations.
      PREREQUISITES
      Scala
      EXPECTED DIFFICULTY
      Medium.
      EXPECTED LENGTH
      Short (~ 90 hours)
      MENTORS
      @satabin @ybasket
      RELATED REPOS
      http4s-fs2-data fs2-data http4s
      CLOUD WEB PROGRAMMING LANGUAGES

      ~~~~~~~~~~
      CONVERT DOOBIE TEST SUITE TO USE MUNIT-CATS-EFFECT
      Doobie is a purely functional library for database access. Our test suites are written before there is good integration between MUnit (the test framework) and Cats-Effect (the effect system we depend on). We want to convert to use munit-cats-effect to make them less verbose and error prone.
      PREREQUISITES
      Scala
      EXPECTED DIFFICULTY
      Easy.
      EXPECTED LENGTH
      Medium (~ 175 hours)
      MENTORS
      @jatcwang
      RELATED REPOS
      doobie munit-cats-effect
      CLOUD PROGRAMMING LANGUAGES
     
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/typelevel/
    idea_list_url: https://typelevel.org/gsoc/ideas

  - organization_id: 164
    organization_name: UC OSPO
    no_of_ideas: 55
    ideas_content: |
      
      

      
      AI Data Readiness Inspector (AIDRIN)
      Jean Luca Bez, Suren Byna
      Feb 11, 2025

      Garbage In Garbage Out (GIGO) is a universally agreed quote by computer scientists from various domains, including Artificial Intelligence (AI). As data is the fuel for AI, models trained on low-quality, biased data are often ineffective. Computer scientists who use AI invest considerable time and effort in preparing the data for AI.

      AIDRIN (AI Data Readiness INspector) is a framework that provides a quantifiable assessment of the readiness of data for AI processes, covering a broad range of readiness dimensions available in the literature. AIDRIN uses metrics in traditional data quality assessment, such as completeness, outliers, and duplicates, for data evaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI, such as feature importance, feature correlations, class imbalance, fairness, privacy, and FAIR (Findability, Accessibility, Interoperability, and Reusability) principle compliance. AIDRIN provides visualizations and reports to assist data scientists in further investigating the readiness of data.

      AIDRIN Visualizations and Science Gateway
      The proposed work will include improvements in the AIDRIN framework to (1) enhance, extend, and optimize the visualizations of metrics related to all six pillars of AI data readiness and (2) set up a science gateway on NERSC or AWS cloud service.

      Topics: data readiness AI
      Skills: Python, C/C++, good communicator
      Difficulty: Moderate
      Size: Large (350 hours)
      Mentors: Jean Luca Bez and Suren Byna

      ~~~~~~~~~~

      AI for Science: Automating Domain Specific Tasks with Large Language Models
      Daniel Wong, Luanzheng "Lenny" Guo
      Feb 23, 2025

      Recent advancements in Large Language Models (LLMs) have transformed various fields by demonstrating remarkable capabilities in processing and generating human-like text. This project aims to explore the development of an open-source framework that leverages LLMs to enhance discovery across specialized domains.

      The proposed framework will enable LLMs to analyze and interpret complex datasets, automate routine tasks, and uncover novel insights. A key focus will be on equipping LLMs with domain-specific expertise, particularly in areas where specialized tools – such as ANDES – are not widely integrated with LLM-based solutions. By bridging this gap, the framework will empower researchers and professionals to harness LLMs as intelligent assistants capable of navigating and utilizing niche computational tools effectively.

      AI for Science: Automating Domain Specific Tasks with Large Language Models
      Topics: Large Language Models AI for Science
      Skills: Python, Experience with LLMs, Prompt Engineering, Fine-Tuning, LLM Frameworks
      Difficulty: Medium-Difficult
      Size: Large (350 hours)
      Mentor: [Daniel Wong]Daniel Wong, [Luanzheng “Lenny” Guo]Luanzheng "Lenny" Guo
      Project Tasks and Milestones
      Designing an extensible framework that facilitates the integration of LLMs with specialized software and datasets.
      Developing methodologies for fine-tuning LLMs to act as domain experts.
      Implementing strategies for improving tool interoperability, allowing LLMs to interact seamlessly with less commonly used but critical analytical platforms.


      ~~~~~~~~~~

      AR4VIP
      alex pang
      Feb 18, 2025
      We are interested in developing navigation aids for visually impaired people (VIP) using AR/VR technologies. Our intended use is primarily indoors or outdoors but within private confines e.g. person’s backyard. Using AR/VR headsets or smart glasses allows navigation without using a cane and frees the users’ hands for other tasks.

      Continue Development on Meta Quest 3 Headset
      Topics: Dynamic scenes Spatial audio Proximity detection
      Skills: AR/VR familiarity, WebXR, Unity, SLAM, good communicator, good documentation skills
      Difficulty: Moderate
      Size: Medium or large (175 or 350 hours)
      Mentors: Alex Pang, James Davis
      Continue development and field testing with the Meta Quest 3 headset. See this repository page for current status.

      Specific tasks:

      Improve spatial audio mapping
      Improve obstacle detection, at different heights, with pre-scanned geometry as well as dynamic objects e.g. other people, pets, doors
      Special handling of hazards e.g. stairs, uneven floors, etc.
      Explore/incorporate AI to help identify objects in the scene when requested by user
      New Development on Smart Glasses
      Topics: Dynamic scenes Spatial audio Proximity detection
      Skills: AR/VR familiarity, WebXR, Unity, SLAM, good communicator, good documentation skills
      Difficulty: Moderate
      Size: Large (350 hours)
      Mentors: Alex Pang, James Davis
      VR headsets are bulky and awkward, but currently is more advanced than AR glasses in terms of programmability. Ultimately, the form factor of smart glasses is more practical for extended use by our target users. There are many vendors working on pushing out their version of smart glasses targetting various applications e.g. alternative for watching TV, etc. We are interested in those that provide capabilities to support spatial computing. Most of these will likely have their own brand specific APIs. This project has 2 goals: (a) develop generic brand-independent API, perhaps extensions to WebXR, to support overarching goal of navigation aid for VIP, and (b) port functionality of VR version to smart glasses while taking advantage of smart glass functionalities and sensors.

      Specific tasks:

      Explore current and soon-to-be-available smart glass options e.g. Snap Spectacles, Xreal Air 2 ultra, etc. and select a platform to work on (subject to cost and availability of SDK). At a minimum, glass should be microphones and speakers, and cameras. Infrared cameras or other low light capability is a plus. Sufficient battery life or option for quick exchange.
      Identify support provided by SDK e.g. does it do realtime scene reconstruction? does it support spatial audio? etc. If it supports features outside of WebXR, provide generic hooks to improve portability of code to other smart glasses.
      Port and extend functionalities from the Meta Quest 3 VR headsets to smart glass platform.
      Add AI support if glasses support them.
      Provide documentation of work.

      ~~~~~~~~~~

      Autograder
      Eriq Augustine
      Feb 6, 2025

      The EduLinq Autograder is an open source tool used by several courses at UCSC to safely and quickly grade programming assignments. Grading student code is something that may seem simple at first (you just need to run their code!), but quickly becomes exceeding complex as you get more into the details. Specifically, grading a student’s code securely while providing the “last mile” service of getting code from students and sending results to instructors/TAs and the course’s LMS (e.g., Canvas) can be very difficult. The Autograder provides all of this in a free and open source project. The LINQS Lab has made many contributions to the maintain and improve the Autograder.

      As an open source project, there are endless opportunities for development, improvements, and collaboration. Here, we highlight some specific projects that will work well in the summer mentorship setting.

      All students interested in LINQS projects for OSRE/GSoC 2025 should fill out this form. Towards the end of the application window, we will contact those who we believe to be a good fit for a LINQS project. The form will stop accepting responses once the application window closes. Do not post on any of the project repositories about OSRE/GSoC (e.g., comment on an issue that you want to tackle it as a part of OSRE/GSoC 2025). Remember, these are active repositories that were not created for OSRE/GSoC.

      LLM Detection
      Topics: AI/ML LLM Research Backend
      Skills: software development, backend, systems, data munging, go, docker
      Difficulty: Challenging
      Size: Large (350 hours)
      Mentors: Eriq Augustine, Fabrice Kurmann, Lise Getoor
      As Large Language Model (LLM) tools like ChatGPT become more common and powerful, instructors need tools to help determine if students are the actual authors of the code they submit. More classical instances of plagiarism are often discovered by code similarity tools like MOSS. However these tools are not sufficient for detecting code written not by a student, but by an AI model like ChatGPT or GitHub Copilot.

      The task for this project is to create a system that provides a score indicating the system’s confidence that a given piece of code was written by an AI tool and not a student. This will supplement the existing code analysis tools in the Autograder. There are many approaches to completing this task that will be considered. A more software development approach can consist of levering exiting systems to create a production-ready system, whereas a more research approach can consist of creating a novel approach complete with a paper and experiments.

      See Also:

      Repository for Autograder Server
      GitHub Issue
      
      ~~~~~~~~~~
      
      Code Analysis GUI
      Topics: Frontend
      Skills: software development, frontend, data munging, js, css, go
      Difficulty: Easy
      Size: Medium or Large (175 or 350 hours)
      Mentors: Eriq Augustine, Fabrice Kurmann, Lise Getoor
      The Autograder has existing functionality to analyze the code in a student’s submission for malicious content. Relevant to this project is that the Autograder can run a pairwise similarity analysis against all submitted code. This is how most existing software plagiarism systems detect offending code. The existing infrastructure provides detailed statistics on code similarity, but does not currently have a visual way to display this data.

      The task for this project is to create a web GUI using the Autograder REST API to display the results of a code analysis. The size of this project depends on how many of the existing features are going to be supported by the web GUI.

      See Also:

      Repository for Autograder Web GUI
      GitHub Issue
      Pairwise Code Analysis Type
      Sample API Data

      ~~~~~~~~~~
      Web GUI
      Topics: Frontend
      Skills: software development, frontend, js, css
      Difficulty: Easy
      Size: Medium or Large (175 or 350 hours)
      Mentors: Eriq Augustine, Fabrice Kurmann, Lise Getoor
      The Autograder contains dozens of API endpoints, most directly representing a piece of functionality exposed to the user. All of these features are exposed in the Autograder’s Python Interface. However, the Python interface is a purely command-line interface. And although command-line interface are objectively (read: subjectively) the best, a web GUI would be more accessible to a wider audience. The autograder already has a web GUI, but it does not cover all the features available in the Autograder.

      The task for this project is to augment the Autograder’s web GUI with more features. Specifically, add support for more tools used to create and administer courses.

      See Also:

      Repository for Autograder Web GUI
      GitHub Issue
      Autograder API Endpoints
      Autograder’s Python Interface

      ~~~~~~~~~~

      Brahma / Protoocol Release and Validation
      Topics: Web Development Software Architecture VR Development Computer Graphics Cloud Platforms
      Skills: Node.js, Three.js
      Difficulty: Moderate-Challenging
      Size: Large (350 hours)
      Mentors: Samir Ghosh
      The proposed work includes three phases, primarily working on backend code, and API design. In the first phase, to gain familiarity, the mentee will be running and testing the Brahma backend on a variety of cloud platforms such as AWS, Google Cloud, and Azure– and learning best methods for documentation in the process. Then, in the second phase, the mentee will work on formalizing the protocol for avatar embodiment and other multi-user interfaces, testing the application with a simple pong game. In the third phase, the mentee will address telemetry, logging, and analysis considerations.

      This project is well suited for someone who has interest in virtual reality, especially social VR, multi-user, or collaborative applications

      ~~~~~~~~~~
      
      Brahma / Allocentric WebXR Interfaces
      Topics: Web Development VR Development Computer Graphics UX/UI
      Skills: Three.js, GLSL, WebSocket
      Difficulty: Moderate-Challenging
      Size: Medium or large (175 or 350 hours)
      Mentors: Samir Ghosh
      The proposed work primarily involves front-end code and VR interface design. In the first phase, the mentee will gain familiarity with best practices for WebXR development through the implementation and documentation of simple interaction patterns. Then, the mentee will implement a simple multi-user pong game to learn about allocentric interfaces. In the final phase of the project, the mentee will design and implement one or more allocentric interface of their choosing.

      This project is well suited for someone who has interest in virtual reality, especially aspects of graphics and interaction design.



      ~~~~~~~~~~

      CarbonCast: Building an end-to-end consumption-based Carbon Intensity Forecasting service
      Abel Souza
      Feb 18, 2025

      CarbonCast is a machine-learning-based approach to provide multi-day forecasts of the electrical grid’s carbon intensity. Developed in Python, the current version of CarbonCast delivers accurate forecasts in numerous regions by using historical source production data of a particular geographical region, time of day/year, and weather forecasts as features. However, there is no easy way to access and visualize the data through a standard interface. In addition, much important information is left out and is not available to users. For instance, electricity grids often import electricity from neighboring regions and so electricity consumption depends on both electricity generation and imports. Moreover, it is imperative for each energy source to utilize a tailored predictive mechanism. Consequently, any carbon optimization solution trying to reduce carbon emissions due to its electricity consumption will benefit more from following a consumption-based CI signal.

      The plan for this project is to develop both the frontend and the backend API services for CarbonCast. We also intend to enhance CarbonCast by implementing an architecture wherein each region can employ a distinct interface for their predictive modeling. In scenarios where these new models do not yield superior outcomes within a region, the current architecture will serve as a fallback solution.

      Building an end-to-end consumption-based Carbon Intensity Forecasting service
      Topics: Databases Machine Learning
      Skills: Python, command line (bash), MySQL, Django, machine learning, cronjob
      Difficulty: Moderate
      Size: Medium (175 hours)
      Mentors: Abel Souza
      Develop a containerized end-to-end backend, API, and frontend for collecting, estimating, and visualizing real-time and forecast electrical grid’s carbon intensity data in a scalable manner.

      Tasks:

      Research web technologies and frameworks relevant to CarbonCast development.
      Run and collect CarbonCast’s data (CSV)
      Ingest CSV into a MySQL or SQLite database
      Develop an Application Programming Interface (API) and a Web User Interface (UI) to provide real-time data access and visualization.
      Deploy the CarbonCast API as a service and dockerize it so that other users and applications can locally deploy and use it easily.
      Implement a choropleth web map to visualize the carbon intensity data across the different geographical regions supported by CarbonCast.
      Enhance CarbonCast by implementing an extensible architecture wherein every region can employ distinct models for their predictive modeling.



      ~~~~~~~~~~

      
      Causeway / Improving the Core Infrastructure
      The proposed work includes adding logging, analytics, and a production-level CI/CD pipeline, adding a robust testing framework, and refactoring some of our code into seperate modules. Both roles will also contribute to running usability studies and documenting the platform.

      Topics: Web Development, Educational Technologies, Angular
      Skills: Web development experience, HTML, CSS, Javascript, Angular, RxJS, NgRx, Firebase
      Difficulty: Medium to Hard
      Size: Large (350 hours)
      Mentors: David Lee
      
      ~~~~~~~~~~
      
      Causeway / Quizzes and Generative AI
      The proposed work includes extending the application to support quizzes, adding quizzes for the existing tasks, and exploring the use of generative AI to support the quizzes feature. Both roles will also contribute to running usability studies and documenting the platform.

      Topics: Web Development, Educational Technologies, Angular
      Skills: Web development experience, HTML, CSS, Javascript, Angular, RxJS, NgRx, Firebase, Generative AI
      Difficulty: Medium to Hard
      Size: Large (350 hours)
      Mentors: David Lee

      ~~~~~~~~~~

      Disentangled Generation and Editing of Pathology Images
      Xi Li
      Feb 7, 2025

      Topics: computational pathology, image generation, disentangled representations, latent space manipulation, deep learning
      Skills:
      Programming Languages:
      Proficient in Python, with experience in machine learning libraries such as PyTorch or TensorFlow.
      Generative Models:
      Familiarity with Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and contrastive learning methods.
      Data Analysis:
      Image processing techniques, statistical analysis, and working with histopathology datasets.
      Biomedical Knowledge (preferred):
      Basic understanding of histology, cancer pathology, and biological image annotation.
      Difficulty: Advanced
      Size: Large (350 hours). The project involves substantial computational work, model development, and evaluation of generated pathology images.
      Mentors: Xi Li (contact person), Mentor Name
      Project Idea Description
      The project aims to advance the generation and disentanglement of pathology images, focusing on precise control over key histological features. By leveraging generative models, we seek to create synthetic histological images where specific pathological characteristics can be independently controlled.

      Challenges in Current Approaches
      Current methods in histopathology image generation often struggle with:

      Feature Entanglement: Difficulty in isolating individual factors such as cancer presence, severity, or staining variations.
      Lack of Control: Limited capability to manipulate specific pathological attributes without affecting unrelated features.
      Consistency Issues: Generated images often fail to maintain realistic cellular distributions, affecting biological validity.
      Project Motivation
      This project proposes a disentangled representation framework to address these limitations. By separating key features within the latent space, we aim to:

      Control Histological Features: Adjust factors such as cancer presence, tumor grade, number of malignant cells, and staining methods.
      Ensure Spatial Consistency: Maintain the natural distribution of cells during image reconstruction and editing.
      Enable Latent Space Manipulation: Provide interpretable controls for editing and generating realistic histopathology images.
      Project Objectives
      Disentangled Representation Learning:
      Develop generative models (e.g., VAEs, GANs) to separate and control histological features.
      Latent Space Manipulation:
      Design mechanisms for intuitive editing of pathology images through latent space adjustments.
      Spatial Consistency Validation:
      Implement evaluation metrics to ensure that cell distribution remains biologically consistent during image generation.
      Project Deliverables
      Generative Model Framework:
      An open-source Python implementation for pathology image generation and editing.
      Disentangled Latent Space Tools:
      Tools for visualizing and manipulating latent spaces to control specific pathological features.
      Evaluation Metrics:
      Comprehensive benchmarks assessing image quality, feature disentanglement, and biological realism.
      Documentation and Tutorials:
      Clear guidelines and code examples for the research community to adopt and build upon this work.
      Impact
      By enabling precise control over generated histology images, this project will contribute to data augmentation, model interpretability, and biological insight in computational pathology. The disentangled approach offers new opportunities for researchers to explore disease mechanisms, develop robust diagnostic models, and improve our understanding of cancer progression and tissue morphology.


      ~~~~~~~~~~

      Environmental NeTworked Sensor (ENTS)
      Colleen Josephson
      Last updated on Feb 10, 2025

      ENTS I: Web portal for large-scale sensor networks
      Data Visualization Dashboard
      Topics: Data Visualization, Backend, Frontend, UI/UX, Analytics
      Skills:
      Required: React, Javascript, Python, SQL, Git
      Nice to have: Flask, Docker, CI/CD, AWS, Authentication
      Difficulty: Medium
      Size: Large (350 hours)
      Mentors: Colleen Josephson, John Madden, Alec Levy
      The Environmental NeTworked Sensor (ENTS) platform, formally Open Sensing Platform (OSP), implements data visualization website for monitoring microbial fuel cell sensors (see GitHub). The mission is to scale up the current platform to support other researchers or citizen scientists in integrating their novel sensing hardware or microbial fuel cell sensors for monitoring and data analysis. Examples of the types of sensors currently deployed are sensors measuring soil moisture, temperature, current, and voltage in outdoor settings. The focus of the software half of the project involves building upon our existing visualization web platform, and adding additional features to support the mission. A live version of the website is available here.

      Below is a list of project ideas that would be beneficial to the ENTS project. You are not limited to the following projects, and encourage new ideas that enhance the platform:

      Improve streaming functionality
      Generic interface for sensor measurements
      Logger registration
      Over the air (OTA) configuration updates
      Implement unit tests and API documentation

      ~~~~~~~~~~

      ENTS II: Hardware to for large-scale field sensor networks
      Hardware
      Topics: Embedded system, wireless communication, low-power remote sensing
      Skills:
      Required: C/C++, Git, Github, PlatformIO
      Nice to have: STM32 HAL, ESP32 Arduino, protobuf, python, knowledge of standard communication protocols (I2C, SPI, and UART)
      Difficulty: Hard
      Size: Large (350 hours)
      Mentors: Colleen Josephson, John Madden, Jack Lin
      The Environmental NeTworked Sensor (ENTS) node aims to be a general purpose hardware platform for outdoor sensing (e.g. agriculture, ecological monitoring, etc.). The typical use case involves a sensor deployment in an agricultural field, remotely uploading measurements without interfering with farming operations. The current hardware revision (Soil Power Sensor was originally designed for monitoring power output of microbial fuel cells using high fidelity voltage and current measurement channels, as well as auxiliary sensors such as the SDI-12 TEROS-21 soil moisture sensor. The primary activities of this project will involve low-level firmware design and implementation, but may also incorporate hardware design revisions if necessary. We are looking to expand functionality to other external sensors, as well as optimize for power consumption, via significant firmware design activities.

      Long-range, low-power wireless communication is achieved through a LoRa capable STM32 microcontroller with in-lab experiments using an ESP32 microcontroller to enable the simpler WiFi interface. Both wireless interfaces communicate upload measurements to our data visualization dashboard, ENTS I. The combined goal across both of these projects is to create a system that enables researchers to test and evaluate novel sensing solutions. We are looking to make the device usable to a wide range of researchers which may not have a background in electronics, so are interested in design activities that enhance user friendliness.

      In total there will be 2-4 people working on the hardware with progress being tracked on GitHub. Broader project planning is tracked through a Jira board. We intend to have weekly meetings to provide updates on current issue progress along with assigning tasks. Please reach out to John Madden if there are any questions or specific ideas for the project.

      Below is a list of project ideas that would be beneficial to the ENTS project. You are not limited to the following projects, and encourage new ideas that enhance the platform:

      Backup logging via SD card
      I2C multiplexing for multiple of the same sensors
      Batch sensor measurement uploading


      ~~~~~~~~~~

      Exploration of I/O Reproducibility with HDF5
      Luanzheng "Lenny" Guo, Wei Zhang
      Last updated on Feb 20, 2025

      Parallel I/O is a critical component in high-performance computing (HPC), allowing multiple processes to read and write data concurrently from a shared storage system. HDF5—a widely adopted data model and library for managing complex scientific data—supports parallel I/O but introduces challenges in I/O reproducibility, where repeated executions do not always produce identical results. This lack of reproducibility can stem from non-deterministic execution orders, variations in collective buffering strategies, and race conditions in metadata and dataset chunking operations within HDF5’s parallel I/O hierarchy. Moreover, many HDF5 operations that leverage MPI I/O require collective communication; that is, all processes within a communicator must participate in operations such as metadata creation, chunk allocation, and data aggregation. These collective calls ensure that the file structure and data layout remain consistent across processes, but they also introduce additional synchronization complexity that can impact reproducibility if not properly managed. In HPC scientific workflows, consistent I/O reproducibility is essential for accurate debugging, validation, and benchmarking, ensuring that scientific results are both verifiable and trustworthy. Tools such as h5bench—a suite of I/O kernels designed to exercise HDF5 I/O on parallel file systems—play an important role in identifying these reproducibility challenges, tuning performance, and ultimately supporting the overall robustness of large-scale scientific applications.

      Workplan
      The proposed work will include (1) analyzing and characterizing parallel I/O operations in HDF5 with h5bench miniapps, (2) exploring and validating potential reproducibility challenges within the parallel I/O hierarchy (e.g., MPI I/O), and (3) implementing solutions to address parallel I/O reproducibility.

      Topics: Parallel I/O MPI-I/O Reproducibility HPC HDF5
      Skills: C/C++, Python
      Difficulty: Medium
      Size: Large (350 hours)
      Mentors: Luanzheng "Lenny" Guo and [Wei Zhang]Wei Zhang

      ~~~~~~~~~~

      FairFace: Reproducible Bias Evaluation in Facial AI Models via Controlled Skin Tone Manipulation
      Bias in facial AI models remains a persistent issue, particularly concerning skin tone disparities. Many studies report that AI models perform differently on lighter vs. darker skin tones, but these findings are often difficult to reproduce due to variations in datasets, model architectures, and evaluation settings. The goal of this project is to investigate bias in facial AI models by manipulating skin tone and related properties in a controlled, reproducible manner. By leveraging BioSkin, we will adjust melanin levels and other skin properties on existing human datasets to assess whether face-based AI models (e.g., classification and vision-language models) exhibit biased behavior toward specific skin tones.

      Topics: Fairness & Bias in AI, Face Recognition & Vision-Language Models, Dataset Augmentation for Reproducibility
      Skills: Machine Learning & Computer Vision, Deep Learning (PyTorch/TensorFlow), Data Augmentation & Image Processing, Reproducibility & Documentation (GitHub, Jupyter Notebooks).
      Difficulty: Moderate
      Size: Medium or Large ( Can be completed in either 175 or 350 hours, depending on the depth of analysis and number of models tested.)
      Mentors: James Davis, Alex Pang
      Key Research Questions
      Do AI models perform differently based on skin tone?
      How do classification accuracy, confidence scores, and error rates change when skin tone is altered systematically?
      What are the underlying causes of bias?
      Is bias solely dependent on skin tone, or do other skin-related properties (e.g., texture, reflectance) contribute to model predictions?
      Is bias driven by dataset imbalances (e.g., underrepresentation of certain skin tones)?
      Do facial features beyond skin tone (e.g., structure, expression, pose) contribute to biased predictions?
      Are bias trends reproducible?
      Can we replicate bias patterns across different datasets, model architectures, and experimental setups?
      How consistent are the findings when varying image sources and preprocessing methods?
      Specific Tasks:
      Dataset Selection & Preprocessing
      Choose appropriate face/human datasets (e.g., FairFace, CelebA, COCO-Human).
      Preprocess images to ensure consistent lighting, pose, and resolution before applying transformations.
      Skin Tone Manipulation with BioSkin
      Systematically modify melanin levels while keeping facial features unchanged.
      Generate multiple variations per image (lighter to darker skin tones).
      Model Evaluation & Bias Analysis
      Test face classification models (e.g., ResNet, FaceNet) and vision-language models (e.g., BLIP, LLaVA) on the modified images.
      Compute fairness metrics (e.g., demographic parity, equalized odds).
      Investigate Underlying Causes of Bias
      Compare model behavior across different feature sets.
      Test whether bias persists across multiple datasets and model architectures.
      Ensure Reproducibility
      Develop an open-source pipeline for others to replicate bias evaluations.
      Provide codebase and detailed documentation for reproducibility.


      ~~~~~~~~~~

      h5bench with AI workloads
      Jean Luca Bez, Suren Byna
      Feb 11, 2025

      h5bench is a suite of parallel I/O benchmarks or kernels representing I/O patterns that are commonly used in HDF5 applications on high performance computing systems. h5bench measures I/O performance from various aspects, including the I/O overhead, and observed I/O rate.

      Parallel I/O is a critical technique for moving data between compute and storage subsystems of supercomputers. With massive amounts of data produced or consumed by compute nodes, high-performant parallel I/O is essential. I/O benchmarks play an important role in this process; however, there is a scarcity of I/O benchmarks representative of current workloads on HPC systems. Toward creating representative I/O kernels from real-world applications, we have created h5bench, a set of I/O kernels that exercise HDF5 I/O on parallel file systems in numerous dimensions. Our focus on HDF5 is due to the parallel I/O library’s heavy usage in various scientific applications running on supercomputing systems. The various tests benchmarked in the h5bench suite include I/O operations (read and write), data locality (arrays of basic data types and arrays of structures), array dimensionality (1D arrays, 2D meshes, 3D cubes), I/O modes (synchronous and asynchronous). h5bench measurements can be used to identify performance bottlenecks and their root causes and evaluate I/O optimizations. As the I/O patterns of h5bench are diverse and capture the I/O behaviors of various HPC applications, this study will be helpful to the broader supercomputing and I/O community.

      h5bench with AI workloads
      The proposed work will include (1) analyzing and characterizing AI workloads that rely on HDF5 datasets, (2) extracting a kernel of their I/O operations, and (3) implementing and validating the kernel in h5bench.

      Topics: I/O HPC benchmarking
      Skills: Python, C/C++, good communicator
      Difficulty: Moderate
      Size: Large (350 hours)
      Mentors: Jean Luca Bez and Suren Byna


      ~~~~~~~~~~

      HAgent is a platform to build AI hardware agent engine to support multiple components in chip design, such as code generation, verification, debugging, and tapeout.

      HAgent is build as a compiler for for Hardware Agents, it interfaces with typical EDA tools like compilers, synthesis, and verification. There are several projects around enhancing HAgent.

      BugFarm hagent step
      Objective: Develop a HAgent step (pass) to create bugs in a given design.

      Description: Using LLMs (Hagent APIs), the goal is to add “bugs” to input Verilog design. The goal is for other tools passes that need to fix bugs, to use this infrastructure as a bug generator. There is a MCY (https://github.com/YosysHQ/mcy) that does something similar but it does not use verilog and create a very different Verilog output. The BugFarm is supposed to have somewhat similar functionality but edit the Verilog directly which results in a code with just a few edits. Like MCY, there has to be a step to confirm that the change affects results. The project should benchmarks and compare with MCY.

      Skills Needed: Python, Verilog, and understand agents
      Difficulty: Medium
      Size: Medium
      Mentors: Jose Renau, Farzaneh Rabiei Kashanaki


      ~~~~~~~~~~
      HDEval Competition Repository
      Objective: Create a platform for HDL programming challenges and community engagement.

      Description: Develop a repository where users can solve HDL problems in Verilog, Chisel, PyRTL, etc. Implement a points system for successful solutions. Allow users to submit new problems (code, specifications, verification, and tests) that are not easily solvable by LLMs. Automate solution testing and provide feedback on submissions.

      The submissions consist of 4 components: code, specification, verification, and tests. It should be possible to submit also examples of bugs in code/specification/verification/tests during the design.

      If the code is different from Verilog, it should include the HDL (chisel, PyRTL,…) and also the Verilog.

      The specification is free form. For any given specification, an expert on the area should be able to generate code, verification, and tests. Similarly, from any pair. Any expert should be able to generate the rest. For example, from verification and tests, it should be able to generate the code and specification.

      Typical specifications consist of a plan, API, and a sample usage.

      Skills Needed: Web design, some hardware understanding
      Difficulty: Medium
      Size: Medium
      Mentors: Jose Renau, Farzaneh Rabiei Kashanaki

      ~~~~~~~~~~
      Integrate Silicon Compiler
      Objective: Silicon Compiler is an open-source Python library that allows to interface with many EDA tools. The idea is to integrate it with HAgent to allow prompts/queries to interface with it.

      Description: The agentic component requires to check with silicon compiler that the generated Python compiles but also that has reasonable parameters. This will require a react loop for compiler errors, and likely a judge loop for testing for reasonable options/flow with feedback from execution. Since there is not much training examples, it will require a few shot with a database to populate context accordingly.

      The end result should allow to select different tools and options trhough silicon compiler.

      Skills Needed: Backend chip design
      Difficulty: High
      Size: Medium
      Mentors: Jose Renau

      ~~~~~~~~~~
      Comodore 64 or MSX or Gameboy
      Objective: Create a prompt-only specification to build a hardware accelerated for the target platform (Comodore 64, MSX or Gameboy). The generated code should focus on Verilog, but it is fine to also target some other HDL. In all the cases, the project should include a generated Verilog integrated with some emulator for verification.

      Description: Using Hagent, create an HDLEval benchmark (set of prompts) that provide the necessary information to create the Verilog implementation. HDLEval prompts usually consists of a high-level PLAN or specification, an API to implement, and a few examples of usage for the given API.

      The result of running the bencharmk, a generated Verilog runs program in the emulator and the Verilog to compare correctness. The platform should have an already existing emulator vice-emu or mGBA to perform cosimulation against the generated specification.

      Skills Needed: Verilog for front-end design
      Difficulty: High
      Size: Large (175 or 350 hours)
      Mentors: Jose Renau

      ~~~~~~~~~~
      LLMSeqRec: LLM Enhanced Contextual Sequential Recommender
      Linsey Pang, Bin Dong
      Feb 6, 2025

      Project Description
      Sequential Recommender Systems are widely used in scientific and business applications to analyze and predict patterns over time. In biology and ecology, they help track species behavior by suggesting related research on migration patterns and environmental changes. Medical applications include personalized treatment recommendations based on patient history and predicting disease progression. In physics and engineering, these systems optimize experimental setups by suggesting relevant past experiments or simulations. Environmental and climate science applications include forecasting climate trends and recommending datasets for monitoring deforestation or pollution. In business and e-commerce, sequential recommenders enhance user experiences by predicting consumer behavior, suggesting personalized products, and optimizing marketing strategies based on browsing and purchase history. By leveraging sequential dependencies, these recommender systems enhance research efficiency, knowledge discovery, and business decision-making across various domains. Traditional sequential recommendation systems rely on historical user interactions to predict future preferences, but they often struggle with capturing complex contextual dependencies and adapting to dynamic user behaviors. Existing models primarily use predefined embeddings and handcrafted features, limiting their ability to generalize across diverse recommendation scenarios. To address these challenges, we propose LLM Enhanced Contextual Sequential Recommender (LLMSeqRec), which leverages Large Language Models (LLMs) to enrich sequential recommendations with deep contextual understanding and adaptive reasoning. By integrating LLM-generated embeddings and contextual representations, LLMSeqRec enhances user intent modeling, cold-start recommendations, and long-range dependencies in sequential data. Unlike traditional models that rely solely on structured interaction logs, LLMSeqRec dynamically interprets and augments sequences with semantic context, leading to more accurate and personalized recommendations. This fusion of LLM intelligence with sequential modeling enables a more scalable, adaptable, and explainable recommender system, bridging the gap between traditional sequence-based approaches and advanced AI-driven recommendations.

      Project Objectives
      Aligned with the vision of the 2025 Open Source Research Experience (OSRE), this project aims to develop an LLM-Enhanced Contextual Sequential Recommender (LLMSeqRec) to improve sequential recommendation accuracy across various scientific and business applications. Sequential recommender systems are widely used to analyze and predict patterns over time, assisting in fields such as biology, ecology, medicine, physics, engineering, environmental science, and e-commerce. However, traditional models often struggle with capturing complex contextual dependencies and adapting to dynamic user behaviors, as they primarily rely on vanilla sequential Id orders. To address these limitations, this project will leverage Large Language Models (LLMs) to enhance context-aware sequential recommendations by dynamically integrating LLM-generated embeddings and contextual representations. The core challenge lies in designing LLMSeqRec, a unified and scalable model capable of enriching user intent modeling, mitigating cold-start issues, and capturing long-range dependencies within sequential data. Unlike conventional systems that rely solely on structured interaction logs, LLMSeqRec will interpret and augment sequences with semantic context, resulting in more accurate, adaptable, and explainable recommendations. Below is an outline of the methodologies and models that will be developed in this project:

      Step 1: Data Preprocessing & Feature Creation: Develop a data processing pipeline to parse user’s sequential interaction behaviors into sequential data points for LLM-based embeddings and contextual sequential transformer modeling; Extract user behavior sequences, items’ metadata, and temporal patterns to create context-aware sequential representations for training, validation and testing; The data source can be from Amazon open public data or Movie Lense data set. The data points creation can follow SASRec (in the reference 1).

      Step 2: Model Development: Design and implement LLM-enhanced sequential recommendation models, integrating pretrained language models to augment user-item interactions with semantic context; Develop an adaptive mechanism to incorporate external contextual signals, such as product descriptions, reviews into the sequential recommendation process; The baseline model can be SASRec pytorch implementation.

      Step 3: Evaluation: : Benchmark LLMSeqRec against state-of-the-art sequential recommenders, evaluating on accuracy, NDCG and cold-start performance; Conduct ablation studies to analyze the impact of LLM-generated embeddings on recommendation quality; Optimize model inference speed and efficiency for real-time recommendation scenarios.

      Project Deliverables
      This project will deliver three components, software, model training, validation and performance evaluation and demo. The software which implements the above LLMSeqRec model will be hosted on the github repo as open-access repositories. The evaluation results and demo will be published along the github repo .

      LLMSeqRec
      Topics: LLM Enhanced Contextual Sequential Recommender
      Skills: Proficiency in Python, Pytorch, Github, Self-attention, Transformer
      Difficulty: Difficult
      Size: Large (350 hours)
      Mentor: Linsey Pang, Bin Dong
      References:
      Self-Attentive Sequential Recommendation (SASRec)
      BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer
      VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks
      Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
      Amazon Dataset: https://cseweb.ucsd.edu/~jmcauley/datasets.html#amazon_reviews
      Movie Lense Data: https://grouplens.org/datasets/movielens/


      ~~~~~~~~~~

      Advanced Canvas Support
      Topics: Backend Teaching Tools API
      Skills: software development, backend, rest api, data munging, http request inspection, python
      Difficulty: Moderate
      Size: Medium or Large (175 or 350 hours)
      Mentors: Eriq Augustine, Batuhan Salih, Lise Getoor
      The LMS Toolkit already has basic read-write support for core Canvas functionality (working with grades and assignments). However, there are still many more features that can be supported such as group management, quiz management, quiz statistics, and assignment statuses.

      The task for this project is to implement chose of set of advanced Canvas features to support (not limited to those features mentioned above), design an LMS-agnostic way to support those features, and implement those features. The flexibility in the features chosen to implement account for the variable size of this project.

      See Also:

      Repository for LMS Toolkit
      GitHub Issues
      Group Management,
      Quiz Management,
      Quiz Statistics,
      Assignment Statuses.

      ~~~~~~~~~~
      New LMS Support: Moodle
      Topics: Backend Teaching Tools API
      Skills: software development, backend, rest api, data munging, http request inspection, python
      Difficulty: Moderate
      Size: Large (350 hours)
      Mentors: Eriq Augustine, Batuhan Salih, Lise Getoor
      The goal of the LMS toolkit is to provide a single interface for all LMSs. It is a lofty goal, however there is currently only support for Canvas. Moodle is one of the more popular LMSs. Naturally, the LMS Toolkit wants to support Moodle as well. Moodle is open source, so adding support in the LMS Toolkit should not be too challenging.

      The task for this project is to add basic support for the Moodle LMS. It is not necessary to support all the same features that are supported for Canvas, but at least the core features of score and assignment management should be implemented.

      See Also:

      Repository for LMS Toolkit
      Moodle Wiki Page
      GitHub Issue

      ~~~~~~~~~~
      New LMS Support: Blackboard
      Topics: Backend Teaching Tools API
      Skills: software development, backend, rest api, data munging, http request inspection, python
      Difficulty: Challenging
      Size: Large (350 hours)
      Mentors: Eriq Augustine, Batuhan Salih, Lise Getoor
      The goal of the LMS toolkit is to provide a single interface for all LMSs. It is a lofty goal, however there is currently only support for Canvas. Blackboard (also called “Blackboard Learn”) is one of the more popular LMSs. Naturally, the LMS Toolkit wants to support Blackboard as well. However, a challenge in supporting Blackboard is that it is not open source (unlike Canvas). Therefore, support and testing on Blackboard may be very challenging.

      The task for this project is to add basic support for the Blackboard LMS. It is not necessary to support all the same features that are supported for Canvas, but at least the core features of score and assignment management should be implemented. The closed nature of Blackboard makes this a challenging and uncertain project.

      See Also:

      Repository for LMS Toolkit
      Blackboard Wiki Page
      GitHub Issue

      ~~~~~~~~~~
      New LMS Support: Brightspace
      Topics: Backend Teaching Tools API
      Skills: software development, backend, rest api, data munging, http request inspection, python
      Difficulty: Challenging
      Size: Large (350 hours)
      Mentors: Eriq Augustine, Batuhan Salih, Lise Getoor
      The goal of the LMS toolkit is to provide a single interface for all LMSs. It is a lofty goal, however there is currently only support for Canvas. D2L Brightspace is one of the more popular LMSs. Naturally, the LMS Toolkit wants to support Brightspace as well. However, a challenge in supporting Brightspace is that it is not open source (unlike Canvas). Therefore, support and testing on Brightspace may be very challenging.

      The task for this project is to add basic support for the Brightspace LMS. It is not necessary to support all the same features that are supported for Canvas, but at least the core features of score and assignment management should be implemented. The closed nature of Brightspace makes this a challenging and uncertain project.

      See Also:

      Repository for LMS Toolkit
      Brightspace Wiki Page
      GitHub Issue

      ~~~~~~~~~~
      Testing / CI Infrastructure
      Topics: Backend Teaching Tools Testing CI
      Skills: software development, backend, testing, ci, docker
      Difficulty: Challenging
      Size: Large (350 hours)
      Mentors: Eriq Augustine, Batuhan Salih, Lise Getoor
      The goal of the LMS toolkit is to provide a single interface for all LMSs. This means that our system must communicate with several different (the LMSs), each with their own systems, data patterns, versions, and quirks. Testing will be essential to ensure that our tools keep working as the different LMSs evolve and update. The LMS Toolkit currently tests with Canvas by mocking API responses. However, this tactic does not scale well with multiple LMSs (and multiple versions of each system). A more scalable approach would be to have test instances of the different LMSs that our testing infrastructure can interact with both interactively and in continuous integration (CI).

      The task for this project is to create testing infrastructure that connects to test instances of different LMS systems (e.g., Canvas). This task does not require that all the LMSs in this document are used, but the testing infrastructure should be robust enough to support them all. The open source LMSs (Canvas and Moodle) will likely be much easier to setup than the others, and should be targeted first. We should be able to run tests locally as well as in CI, and will likely heavily use Docker containers.

      See Also:

      Repository for LMS Toolkit
      GitHub Issue
      Mocked API Responses.

      ~~~~~~~~~~

      Medicinal Language Embeddings
      Topics: Large Language Models NLP Embeddings Medicine
      Skills: Python, JavaScript, Data Science, Technical Communication
      Difficulty: Challenging
      Size: Large (350 hours)
      Mentors: Oskar Elek, Kiran Deol
      This project aims to refine and enhance Mediglot, a web application for visualizing 3D medicinal embeddings, which extends the Polyglot app and leverages the PolyPhy toolkit for network-inspired data science. Mediglot currently enables users to explore high-dimensional vector representations of medicines (derived from their salt compositions) in a 3D space using UMAP, as well as analyze similarity through the innovative Monte-Carlo Physarum Machine (MCPM) metric. Unlike traditional language data, medicinal embeddings do not have an inherent sequential structure. Instead, we must work with the salt compositions of each medicine to create embeddings that are faithful to the intended purpose of each medicine.

      This year, we would like to focus on exploring and integrating state-of-the-art AI techniques and algorithms to improve Mediglot’s clustering capabilities and its representation of medicinal data in 3D. The contributor will experiment with advanced large language models (LLMs) and cutting-edge AI methods to develop innovative approaches for refining clustering and extracting deeper insights from medicinal embeddings. Beyond LLMs, we would like to experiment with more traditional language processing methods to design novel embedding procedures. Additionally, we would like to experiment with other similarity metrics. While the similarity of two medicines depends on the initial embedding, we would like to examine the effects of different metrics on the kinds of insights a user can extract. Finally, the contributor is expected to evaluate and compare different algorithms for dimensionality reduction to enhance the faithfulness of the visualization and its interpretability.

      The ideal contributor for this project has experience with Python (and common scientific toolkits such as NumPy, Pandas, SciPy). They will also need some experience with JavaScript and web development (MediGlot is distributed as a vanilla JS web app). Knowledge of embedding techniques for language processing is highly recommended.

      Specific tasks:

      Closely work with the mentors to understand the context of the project and its detailed requirements in preparation for the proposal.
      Become acquainted with the tooling (PolyPhy, PolyGlot, Mediglot) prior to the start of the project period.
      Explore different embedding techniques for medicinal data (including implementing novel embedding procedures).
      Explore different dimensionality reduction techniques, with a focus on faithful visualizations.
      Document the process and resulting findings in a publicly available report.
      
      ~~~~~~~~~~
      
      Enhancing PolyPhy Web Application
      Topics: Web Development UI/UX Design Full Stack Development JavaScript Next.js Node.js
      Skills: Full Stack Web Development, UI/UX Design, JavaScript, Next.js, Node.js, Technical Communication
      Difficulty: Challenging
      Size: Medium (175 hours)
      Mentors: Oskar Elek, Kiran Deol
      This project aims to revamp and enhance the PolyPhy web platform to better support contributors, users, and researchers. The goal is to optimize the website’s UI/UX, improve its performance, and integrate Mediglot to provide users with a seamless experience in visualizing both general network structures and 3D medicinal embeddings.

      The contributor will be responsible for improving the website’s overall look, feel, and functionality, ensuring a smooth and engaging experience for both contributors and end-users. This includes addressing front-end and back-end challenges, optimizing the platform for better accessibility, and ensuring seamless integration with Mediglot.

      The ideal candidate should have experience in full-stack web development, particularly with Next.js, JavaScript, and Node.js, and should be familiar with UI/UX design principles. A strong ability to communicate effectively, both in writing and through code, is essential for this role.

      Specific tasks:

      Collaborate with mentors to understand the project’s goals and the specific requirements for the website improvements.
      UI/UX Redesign:
      Redesign and enhance the website’s navigation, layout, and visual elements to create an intuitive and visually engaging experience.
      Improve mobile responsiveness for broader accessibility across devices.
      Website Performance & Stability:
      Identify and resolve performance bottlenecks, bugs, or issues affecting speed, stability, and usability.
      Mediglot Integration:
      Integrate the Mediglot web application with PolyPhy, ensuring seamless functionality and a unified user experience for visualizing medicinal data alongside general network reconstructions.
      Documentation:
      Document the development process, challenges, and solutions in a clear and organized manner, ensuring transparent collaboration with mentors and the community.


      ~~~~~~~~~~

      Improving Code Quality in OpenROAD
      Topics: Coding Best Practices in C++, Code Quality Tooling, Continuous Integration
      Skills: C++
      Difficulty: Medium
      Size: Medium (175 hours)
      Mentors: Matt Liberty & Arthur Koucher
      OpenROAD is a large and complex program. This project is to improve the code quality through resolving issues flagged by tools like Coverity and clang-tidy. New tools like the clang sanitizers ASAN/TSAN/UBSAN should also be set up and integrated with the Jenkins CI.

      ~~~~~~~~~~
      
      GUI Testing in OpenROAD
      Topics: Testing, Continuous Integration
      Skills: C++, Qt
      Difficulty: Medium
      Size: Large (350 hours)
      Mentors: Matt Liberty & Peter Gadfort
      The OpenROAD GUI is a crucial set of functionality for users to see and investigate their design. GUI testing is specialized and rather different from standard unit testing. The GUI therefore needs improvements to its testing to cover both interaction and rendering. The GUI uses the Qt framework. An open-source testing tool like https://github.com/faaxm/spix will be set up and key tests developed. This will provide the framework for all future testing.

      ~~~~~~~~~~
      
      Rectilinear Floorplans in OpenROAD
      Topics: Electronic Design Automation, Algorithms
      Skills: C++, data structures and algorithms
      Difficulty: Medium
      Size: Large (350 hours)
      Mentors: Eder Monteiro & Augusto Berndt
      OpenROAD supports block floorplans that are rectangular in shape. Some designs may require more complex shapes to fit. This project extends the tool to support rectilinear polygon shapes as floorplans. This will require upgrading data structures and algorithms in various parts of OpenROAD including floor plan generation, pin placement, and global placement.

      ~~~~~~~~~~
      
      LEF Reader and Database Enhancements in OpenROAD
      Topics: Electronic Design Automation, Database, Parsing
      Skills: Boost Spirit parsers, Database, C++
      Difficulty: Medium
      Size: Medium (175 hours)
      Mentors: Osama Hammad & Ethan Mahintorabi
      LEF (Library Exchange Format) is a standard format for describing physical design rules for integrated circuits. OpenROAD has support for many constructs but some newer ones for advanced process nodes are not supported. This project is to support parsing such information and storing in the OpenDB for use by the rest of the tool.

      ~~~~~~~~~~
      
      ORAssistant - LLM Data Engineering and Testing
      Topics: Large Language Model, Machine Learning, Data Engineering, Model Deployment, Testing, Full-Stack Development
      Skills: large language model engineering, database, evaluation, CI/CD, open-source or related software development, full-stack
      Difficulty: Medium
      Size: Medium (175 hours)
      Mentor: Jack Luar & Palaniappan R
      This project is aimed at enhancing robustness and accuracy for OR Assistant, the conversational assistant for OpenROAD through comprehensive testing and evaluation. You will work with members of the OpenROAD team and other researchers to enhance the existing dataset to cover a wide range of use cases to deliver accurate responses more efficiently. This project will focus on data engineering and benchmarking and you will collaborate on a project on the LLM model engineering. Tasks include: creating evaluation pipelines, building databases to gather feedback, improving CI/CD, writing documentation, and improving the backend and frontend services as needed (non-exhaustive). You will gain valuable experience and skills in understanding chip design flows and applications. Open to proposals from all levels of ML practitioners.

      ~~~~~~~~~~
      
      ORAssistant - LLM Model Engineering
      Topics: Large Language Model, Machine Learning, Model Architecture, Model Deployment
      Skills: large language model engineering, prompt engineering, fine-tuning
      Difficulty: Medium
      Size: Medium (175 hours)
      Mentor: Jack Luar & Palaniappan R
      This project is aimed at enhancing robustness and accuracy for OR Assistant, the conversational assistant for OpenROAD through enhanced model architectures. You will work with members of the OpenROAD team and other researchers to explore alternate architectures beyond the existing RAG-based implementation. This project will focus on improving reliability and accuracy of the existing model architecture. You will collaborate on a tandem project on data engineering for OR assistant. Tasks include: reviewing and understanding the state-of-the-art in retrieval augmented generation, implementing best practices, caching prompts, improving relevance and accuracy metrics, writing documentation and improving the backend and frontend services as needed (non-exhaustive). You will gain valuable experience and skills in understanding chip design flows and applications. Open to proposals from all levels of ML practitioners.

      ~~~~~~~~~~

      Canvas Import
      Topics: Backend Teaching Tools API
      Skills: software development, backend, rest api, data munging, http request inspection, python
      Difficulty: Moderate
      Size: Medium (175 hours)
      Mentors: Eriq Augustine, Lucas Ellenberger, Lise Getoor
      The Quiz Composer houses quizzes and quiz questions in a simple and unambiguous format based on JSON and Markdown (specifically, the CommonMark specification). This allows the Quiz Composer to unambiguously create versions of the same quiz in many different formats. However, creating a quiz in the Quiz Composer format can be a daunting task for those not familiar with JSON or Markdown. Instead, it would be easier for people to import quizzes from another format into the Quiz Composer format, and then edit it as they see fit. Unfortunately not all other quiz formats, namely Canvas in this case, are unambiguous.

      The task for this project is to implement the functionality of importing quizzes from Canvas to the standard Quiz Composer format. The unambiguous nature of Canvas quizzes makes this task non-trivial, and adds an additional element of design decisions to this task. It will be impossible to import quizzes 100% correctly, but we want to be able to get close enough that most people can import their quizzes without issue.

      See Also:

      Repository for Quiz Composer
      GitHub Issue

      ~~~~~~~~~~
      Google Forms Export
      Topics: Backend Teaching Tools API
      Skills: software development, backend, rest api, data munging, python
      Difficulty: Moderate
      Size: Medium (175 hours)
      Mentors: Eriq Augustine, Lucas Ellenberger, Lise Getoor
      The Quiz Composer can export quizzes to many different formats, each with a varying level of interactivity and feature support. For example, quizzes can be exported to PDFs which will be printed and the students will just write down their answers to be checked in the future. Quizzes can also be exported to interactive platforms like Canvas where students can enter answers that may be automatically checked with feedback immediately provided to the student. On potential platform with functionality somewhere between the above two examples is Google Forms. “Forms” (an entity on Google Forms) can be something like a survey or (as of more recently) a quiz.

      The task for this project is to add support for exporting quizzes from the Quiz Composer to Google Forms. There is a large overlap in the quiz features supported in Canvas (which the Quiz Composer already supports) and Google Forms, so most settings should be fairly straightforward. There may be some design work around deciding what features are specific to one quiz platform and what features can be abstracted to work across several platforms.

      See Also:

      Repository for Quiz Composer
      GitHub Issue

      ~~~~~~~~~~
      Template Questions
      Topics: Backend Teaching Tools API
      Skills: software development, backend, data munging, python
      Difficulty: Moderate-Challenging
      Size: Large (350 hours)
      Mentors: Eriq Augustine, Lucas Ellenberger, Lise Getoor
      Questions in the Quiz Composer are described using JSON and Markdown files which contain the question prompt, possible answers, and the correct answer. (Of course there are many differ question types, each with different semantics and requirements.) However, a limitation of this is that each question is always the same. You can have multiple copies of a question with slightly different prompts, numbers, and answers; but you are still limited to each question being static and unchanging. It would be useful to have “template questions” that can dynamically create static questions from a template and collection of replacement data.

      The task for this project is to add support for the “template questions” discussed above. Much of the high-level design work for this issue has already been completed. But there is still the implementation and low-level design decision left to do.

      See Also:

      Repository for Quiz Composer
      GitHub Issue


      ~~~~~~~~~~


      RAG-ST: Retrieval-Augmented Generation for Spatial Transcriptomics
      Ziheng Duan
      Jan 15, 2025

      Topics: bioinformatics, spatial transcriptomics, gene expression generation, retrieval-augmented generation, large models
      Skills:
      Programming Languages:
      Proficient in Python, and familiarity with machine learning libraries such as PyTorch.
      Data Analysis:
      Experience with spatial transcriptomics datasets and statistical modeling.
      Machine Learning:
      Understanding of vision models, retrieval-based systems, and MLP architectures.
      Bioinformatics Knowledge (preferred):
      Familiarity with scRNA-seq data integration and computational biology tools.
      Difficulty: Advanced
      Size: Large (350 hours). Given the scope of integrating RAG models, building a robust database, and ensuring interpretable predictions, this project involves substantial computational and data preparation work.
      Mentors: Ziheng Duan (contact person)
      Project Idea Description
      Spatial transcriptomics (ST) is a revolutionary technology that provides spatially resolved gene expression measurements, enabling researchers to study cellular behaviour within tissues with unprecedented detail. This technology has transformed our understanding of complex biological systems, such as disease progression, tissue development, and cellular heterogeneity. However, the widespread adoption of ST is limited by its high cost and technical requirements.

      Histology imaging, on the other hand, is far more accessible and cost-effective. If gene expression could be accurately predicted from histology images, it would enable researchers to leverage these abundant images for high-resolution biological insights without the need for expensive spatial transcriptomics experiments. This task has immense potential to democratize spatial transcriptomics research and significantly reduce costs.

      Challenges in Current Approaches
      Current methods for predicting gene expression from histology images typically involve:

      Using large vision models to encode histology image patches into embeddings.
      Employing Multi-Layer Perceptrons (MLPs) to map these embeddings to gene expression profiles.
      While these approaches have shown promise, they suffer from two critical limitations:

      Accuracy: The MLP-based mappings often fail to fully capture the biological complexity encoded in the histology images, leading to suboptimal predictions.
      Interpretability: These models act as black boxes, providing no insight into the underlying biological rationale for the predictions. Researchers cannot determine why a specific gene expression profile was generated, limiting trust and utility in biological contexts.
      Project Motivation
      To overcome these limitations, this project proposes a novel Retrieval-Augmented Generation (RAG) framework for spatial transcriptomics. Instead of relying solely on black-box MLPs, RAG-ST will:

      Retrieve relevant examples from a curated database of paired histology images, scRNA-seq data, and gene expression profiles.
      Use these retrieved examples to inform and enhance the generation process, resulting in predictions that are both more accurate and biologically interpretable.
      This approach not only grounds predictions in biologically meaningful data but also provides transparency by revealing which database entries influenced the results.

      Project Objectives
      Database Construction:
      Curate a large and diverse database of histology images paired with scRNA-seq and gene expression data.
      Model Development:
      Develop a RAG framework combining vision-based encoders and retrieval-enhanced generation techniques.
      Incorporate interpretability mechanisms to link predicted gene expressions to retrieved examples.
      Evaluation and Benchmarking:
      Assess RAG-ST against state-of-the-art methods, focusing on accuracy, interpretability, and biological validity.
      Project Deliverables
      Curated Database:
      A publicly available, well-documented database of histology images and gene expression profiles.
      RAG-ST Framework:
      An open-source Python implementation of the RAG-ST model, with retrieval, generation, and visualization tools.
      Benchmark Results:
      Comprehensive evaluations demonstrating the benefits of RAG-ST over conventional pipelines.
      Documentation and Tutorials:
      User-friendly guides to facilitate adoption by the spatial transcriptomics research community.
      Impact
      By integrating retrieval-augmented generation with large models, RAG-ST represents a paradigm shift in spatial transcriptomics. It offers a cost-effective, accurate, and interpretable solution for gene expression prediction, democratizing access to high-quality spatial transcriptomic insights and fostering advancements in biological research.



      
      ~~~~~~~~~~
      ReasonWorld: Real-World Reasoning with a Long-Term World Model
      A world model is essentially an internal representation of an environment that an AI system would construct based on external information to plan, reason, and interpret its surroundings. It stores the system’s understanding of relevant objects, spatial relationships, and/or states in the environment. Recent augmented reality (AR) and wearable technologies like Meta Aria glasses provide an opportunity to gather rich information from the real world in the form of vision, audio, and spatial data. Along with this, large language (LLM), vision language models (VLMs), and general machine learning algorithms have enabled nuanced understanding and processing of multimodal inputs that can label, summarize, and analyze experiences.

      With ReasonWorld, we aim to utilize these technologies to enable advanced reasoning about important objects/events/spaces in real-world environments in a structured manner. With the help of wearable AR technology, the system would be able to capture real-world multimodal data. We aim to utilize this information to create a long-memory modeling toolkit that would support features like:

      Longitudinal and structured data logging: Capture and storing of multimodal data (image, video, audio, location coordinates etc.)
      Semantic summarization: Automatic scene labeling via LLMs/VLMs to identify key elements in the surroundings
      Efficient retrieval: For querying and revisiting past experiences and answering questions like “Where have I seen this painting before?”
      Adaptability: Continuously refining and understanding the environment and/or relationships between objects/locations.
      Adaptive memory prioritization: Where the pipeline can assess the contextual significance of the captured data and retrieve those that are the most significant. The model retains meaningful, structured representations rather than raw, unfiltered data.
      This real-world reasoning framework with a long-term world model can function as a structured search engine for important objects and spaces, enabling:

      Recognizing and tracking significant objects, locations, and events
      Supporting spatial understanding and contextual analysis
      Facilitating structured documentation of environments and changes over time
      Alignment with Summer of Reproducibility:
      Core pipeline for AR data ingestion, event segmentation, summarization, and indexing (knowledge graph or vector database) would be made open-source.
      Clear documentation of each module and how they collaborate with one another
      The project could be tested with standardized datasets, simulated environments as well as controlled real-world scenarios, promoting reproducibility
      Opportunities for Innovation - A transparent, modular approach invites a broad community to propose novel expansions
      Specific Tasks:
      A pipeline for real-time/batch ingestion of data with the wearable AR device and cleaning
      Have an event segmentation module to classify whether the current object/event is contextually significant, filtering out the less relevant observations.
      Have VLMs/LLMs summarize the events with the vision/audio/location data to be stored and retrieved later by structured data structures like knowledge graph, vector databases etc.
      Storage optimization with prioritizing important objects and spaces, optimizing storage based on contextual significance and frequency of access.
      Implement key information retrieval mechanisms
      Ensure reproducibility by providing datasets and scripts
      ReasonWorld
      Topics: Augmented reality Multimodal learning Computer vision for AR LLM/VLM Efficient data indexing
      Skills: Machine Learning and AI, Augmented Reality and Hardware integration, Data Engineering & Storage Optimization
      Difficulty: Hard
      Size: Large (350 hours)
      Mentors: James Davis, Alex Pang


      ~~~~~~~~~~



      ReIDMM: Re-identifying Multiple Objects across Multiple Streams
      Bin Dong, Linsey Pang
      Feb 6, 2025

      Project Description
      Re-identifying multiple objects across multiple streams (ReIDMM) is essential in scientific research and various industries. It involves tracking and analyzing entities across different viewpoints or time frames. In astronomy, ReIDMM helps track celestial objects like asteroids and space debris using multiple observatories. In biology and ecology, it enables the identification of animals across different camera traps and aids in tracking microscopic organisms in laboratory studies. In physics and engineering, it is used for tracking particles in high-energy physics experiments, monitoring structural changes in materials, and identifying robots or drones in lab automation. Beyond scientific applications, ReIDMM plays a critical role in industries such as retail, where it tracks customer behavior across multiple stores and improves sales and prevents theft. In smart cities, it supports traffic monitoring by identifying vehicles across intersections for improved traffic flow management. In manufacturing, it enables supply chain tracking by locating packages across conveyor belts and warehouse cameras. In autonomous systems, ReIDMM enhances multi-camera sensor fusion and warehouse robotics by identifying pedestrians, obstacles, and objects across different camera views.

      Project Objectives
      Aligned with the vision of the 2025 Open Source Research Experience (OSRE), this project aims to develop an open-source algorithm for multiple-object re-identification across diverse open-source data streams. As highlighted earlier, this method is expected to have wide-ranging applications in both scientific research and industry. Utilizing an open-source dataset, our focus will be on re-identifying common objects such as vehicles and pedestrians. The primary challenge lies in designing a unified algorithm, ReIDMM, capable of performing robust multi-object re-identification across multiple streams. Users will be able to tag any object as a target in a video or image for tracking across streams. Below is an outline of the algorithms to be developed in this project:

      Step 1: Target Object Identification: Randomly select a target object from an image or video using object detection models such as YOLOv7. These models detect objects by generating bounding boxes around them. Target objects could include vehicles, pedestrians, animals, or other recognizable entities. This step ensures an initial object of interest is chosen for re-identification.

      Step 2: Feature Extraction and Embedding: Once the target object is identified, extract relevant features such as bounding box coordinates, timestamp, location metadata (if available), and visual characteristics. A multimodal embedding approach is used, where these features are transformed into a numerical representation (embedding vector) that captures the object’s unique identity. This allows for efficient comparison across different images or videos.

      Step 3: Searching and Matching: To find the target object in other images or videos: (1) Extract embeddings of all objects detected in the other images/videos; (2) Compute similarity between the target object’s embedding and those of all detected objects using metrics like cosine similarity or Euclidean distance. (3) Rank objects by similarity, returning the most probable matches. The highest-ranked results are likely to be the same object observed from different angles, lighting conditions, or time frames.

      Project Deliverables
      This project will deliver three things, software, evaluation results and demo. The software which implements the above ReIDMM algorithm will be hosted on the github repo as open-access repositories. The evaluation results and demo will be published along the github repo.

      ReIDMM
      Topics: ReIDMM: Re-identifying Multiple Objects across Multiple Streams`
      Skills: Proficient in Python, Experience with images processing, machine learning
      Difficulty: Difficult
      Size: Large (350 hours)
      Mentor: Bin Dong, Linsey Pang
      Reference:
      multiple-object-tracking-using-person
      Dataset: Vehicle re-identification dataset and paper and Person re-identification data and paper


      ~~~~~~~~~~



      3D Driving Scenarios
      Topics: Autonomous Driving 3D modeling
      Skills: Python; basic vector geometry
      Difficulty: Moderate
      Size: Medium or Large (175 or 350 hours)
      Mentors: Daniel Fremont, Eric Vin
      Scenic scenarios written to test autonomous vehicles use the driving domain, a Scenic library defining driving-specific concepts including cars, pedestrians, roads, lanes, and intersections. The library extracts information about road networks, such as the shapes of lanes, from files in the standard OpenDRIVE format. Currently, we only generate 2D polygons for lanes, throwing away 3D information. While this suffices for many driving scenarios, it means we cannot properly model overpasses (the roads appear to overlap) or test driving scenarios where 3D geometry is important, such as hilly terrain.

      The goals of this project are to extend our road network library to generate 3D meshes (instead of 2D polygons) for roads, write new Scenic scenarios which use this new capability, and (if time allows) test autonomous driving software using them.

      ~~~~~~~~~~
      
      A Library for Aviation Scenarios
      Topics: Autonomous Aircraft
      Skills: Python; ideally some aviation experience
      Difficulty: Moderate
      Size: Medium or Large (175 or 350 hours)
      Mentors: Daniel Fremont, Eric Vin
      We have used Scenic to find, diagnose, and fix bugs in software for autonomous aircraft: in particular, this paper studied a neural network-based automated taxiing system using the X-Plane flight simulator. We also have prototype interfaces to AirSim and Microsoft Flight Simulator. However, our experiments so far have mainly focused on simple scenarios involving a single aircraft.

      The goal of this project is to develop an aviation library for Scenic (like the driving domain mentioned in the previous project) which will allow users to create complex aviation scenarios in a simulator-agnostic way. The library would define concepts for aircraft, flight paths, weather, etc. and allow importing real-world data about these. The student would demonstrate the library’s functionality by writing some example scenarios and testing either simple aircraft controllers or (if time allows) ML-based flight software.

      ~~~~~~~~~~
      
      Interfacing Scenic to New Simulators
      Topics: Simulation Autonomous Driving Robotics LLMs
      Skills: Python
      Difficulty: Moderate
      Size: Medium or Large (175 or 350 hours)
      Mentors: Daniel Fremont, Eric Vin
      Scenic is designed to be easily-interfaced to new simulators. Depending on student interest, we could pick a simulator which would open up new kinds of applications for Scenic and write an interface for it. Some possibilities include:

      The AWSIM driving simulator (to allow testing the Autoware open-source autonomous driving software stack)
      The CoppeliaSim robotics simulator
      NVIDIA’s Cosmos, an LLM which generates videos from text prompts
      NVIDIA’s Omniverse (various applications, e.g. simulating virtual factories)
      Various simulators for which we have prototype interfaces that could be generalized and made more usable, including MuJoCo and Isaac Sim
      The goal of the project would be to create an interface between Scenic and the new simulator and write scenarios demonstrating it. If time allows, we could do a case study on a realistic system for publication at an academic conference.

      ~~~~~~~~~~
      
      Optimizing and Parallelizing Scenic
      Topics: Optimization Parallelization
      Skills: Python
      Difficulty: Moderate
      Size: Medium or Large (175 or 350 hours)
      Mentors: Daniel Fremont, Eric Vin
      Large-scale testing with Scenic, when one wants to generate thousands of simulations, can be very computationally-expensive. In some cases, the bottleneck is the simulator, and being able to easily run multiple simulations in parallel would greatly increase scalability. In others, Scenic itself spends substantial time trying to sample scenarios satisfying all the given constraints.

      This project would explore a variety of approaches to speeding up scene and simulation generation in Scenic. Some possibilities include:

      Parallelizing scene generation and simulation (e.g. using Ray)
      Systematically profiling real-world Scenic programs to characterize the main bottlenecks and propose optimizations
      JIT compiling Scenic’s internal sampling code (e.g. using Numba)
      
      ~~~~~~~~~~
      Improvements and Infrastructure for the VerifAI Toolkit
      Topics: DevOps Documentation APIs
      Skills: Python
      Difficulty: Easy
      Size: Medium or Large (175 or 350 hours)
      Mentors: Daniel Fremont, Eric Vin
      VerifAI is a toolkit for design and analysis of AI-based systems that builds on top of Scenic. It adds among other features the ability to perform falsification, intelligently searching for scenarios that will cause a system to behave in an undesirable way.

      The goal of this project is to improve VerifAI’s development infrastructure, documentation, and ease of use, which are currently relatively poor compared to Scenic. Specific tasks could include:

      Setting up continuous integration (CI) on GitHub
      Creating processes to help users/developers submit issues and PRs and deal with them in a timely manner
      Writing more documentation, including tutorials and examples (not only for end users of VerifAI but those wanting to develop custom falsification components, for example)
      Refactoring VerifAI’s API to make it easier to use and extend


      ~~~~~~~~~~

      Seam / Kubernetes Resource Provisioning and Management
      The proposed work includes expanding the Python library to support comprehensive Kubernetes resource provisioning, network management, and virtual machine provisioning using KubeVirt. Students will enhance the current implementation to allow users to define resource limits, CPU/GPU quotas, and network policies. They will also integrate with ESnet SENSE to facilitate L2 networking, and explore the use of Prometheus and Grafana for real-time performance monitoring and metrics collection.

      Topics: Kubernetes, Python, Cloud Computing, Networking, Programmable Networking, Monitoring, CI/CD
      Skills: Python, Kubernetes, P4 programming, KubeVirt, ESnet SENSE, Docker, GitLab CI/CD, Prometheus, Grafana, PostgreSQL, Flask
      Difficulty: Hard
      Size: Large (350 hours)
      Mentors: Mohammad Firas Sada

      ~~~~~~~~~~
      Seam / Full-Stack Web Development and Dashboard
      The proposed work includes building a Flask-based web dashboard using Bootstrap for UI, integrating it with the Python library to enable users to easily provision resources, monitor network performance, and track resource usage in real-time. The dashboard will support role-based access control (RBAC), allowing for secure multi-user management. Students will also integrate PostgreSQL for managing and storing configurations, logs, and performance metrics.

      Topics: Full-Stack Web Development, Flask, Bootstrap, PostgreSQL, Kubernetes, Monitoring, DevOps
      Skills: Web Development, Flask, Bootstrap, PostgreSQL, API Development, Kubernetes
      Difficulty: Medium to Hard
      Size: Large (350 hours)
      Mentors: Mohammad Firas Sada

      ~~~~~~~~~~
      Seam / CI/CD and GitLab Integration
      The proposed work includes setting up GitLab CI/CD pipelines for automated testing, deployment, and maintenance of the Python library, Kubernetes resources, and web dashboard. Students will automate the deployment of P4 programs, Kubernetes deployments, and networking configurations. They will also focus on unit testing, integration testing, and the automation of benchmarking experiments to ensure reproducibility of results.

      Topics: CI/CD, GitLab, Python, Kubernetes, DevOps, Testing, Automation
      Skills: GitLab CI/CD, Python, Kubernetes, Docker, Automation, Testing, Benchmarking
      Difficulty: Medium to Hard
      Size: Large (350 hours)
      Mentors: Mohammad Firas Sada

      ~~~~~~~~~~
      Seam / Networking & SmartNIC Programming
      The proposed work includes writing P4 programs to control network traffic flow, enforce network security policies, and optimize data transfer across the Kubernetes cluster. Students will gain experience with SmartNICs (Xilinx Alveo U55C, SN1000, NVIDIA Bluefield 2) and Tofino switches, using P4 to write network policies and integrate with the Kubernetes network layer (Multus, Calico). Students will also explore gRPC APIs for dynamically adjusting network policies and provisioning virtual network interfaces in real time.

      Topics: Networking, P4 Programming, SmartNICs, Kubernetes Networking, Cloud Computing
      Skills: P4, Networking, SmartNICs, Kubernetes Networking, Multus, Calico, gRPC
      Difficulty: Hard
      Size: Large (350 hours)
      Mentors: Mohammad Firas Sada

      ~~~~~~~~~~

      Smart Batching for Large Language Models
      Daniel Wong, Luanzheng "Lenny" Guo
      Feb 9, 2025

      Sequence tokenization is a crucial step during Large Language Model training, fine-tuning, and inference. User prompts and training data are tokenized and zero-padded before being fed to the model in batches. This process allows models to interpret human language by breaking down complex sentences into simple token units that are numerically represented in a token set. However, the process of sequence padding for maintaining batch dimensions can introduce unnecessary overhead if batching is not properly done.

      In this project, we introduce Smart Batching, where we dynamically batch sequences in a fine-tuning dataset by their respective lengths. With this method, we aim to minimize the amount of zero padding required during sequence batching, which can result in improved and efficient fine-tuning and inference speeds. We also analyze this method with other commonly used batching practices (Longest Sequence, Random Shuffling) on valuable metrics such as runtime and model accuracy.

      Project Title
      Topics: Large Language Models Fine-Tuning AI Transformers
      Skills: Python, Pytorch, Large Language Models
      Difficulty: Moderate
      Size: Large (350 hours)
      Mentor: [Daniel Wong]Daniel Wong, [Luanzheng “Lenny” Guo]Luanzheng "Lenny" Guo
      Project Tasks and Milestones
      Implement an open source smart batching framework based on HuggingFace to allow for dynamically grouping sequences of similar token lengths into batches
      Analyze runtime, padding, and model accuracy with smart batching and other commonly used batching practices
      Apply smart batching with distributed fine-tuning and observe large language model outputs


      ~~~~~~~~~~

      UC Open Source Repository Browser
      Juanita Gomez
      Mar 3, 2025

      The University of California Open Source Repository Browser (UC ORB) is a discovery tool designed to map and classify open source projects across the UC system. This project is a collaboration with the UC Network of Open Source Program Offices (OSPOs), which brings together six UC campuses (Santa Cruz, Berkeley, Davis, Los Angeles, Santa Barbara, and San Diego) to support open source research, promote sustainability, and establish best practices within academic environments.

      By providing a centralized platform, UC ORB enhances the visibility of UC’s open source contributions, fosters collaboration among researchers and developers, and serves as a model for other institutions aiming to improve open source discovery and sustainability.

      This project focuses on building the web application for UC ORB, which will serve as the primary interface for users to explore and interact with UC’s open source projects. The student will work on developing a clean, user-friendly, and scalable web application.

      Develop the UC ORB Application
      Topics: Web development
      Skills: Experience in Python and at least one Python-based web framework (e.g., Flask, Django, FastAPI), experience with front-end technologies (React, HTML, CSS, JavaScript), familiarity with Git and collaborative development workflows, familiarity with database interaction (SQL).
      Difficulty: Moderate
      Size: Large (350 hours)
      Mentors: Juanita Gomez
      Develop a web application that serves as the front-end interface for the UC ORB. The application will allow users to browse, search, and explore open source projects across the UC system. The project will involve integrating with the repository database to fetch and display repository data, designing an intuitive user interface, and ensuring the application is scalable and maintainable.

      Specific Tasks:

      Choose an appropriate Python-based web framework (e.g., Flask, Django, or FastAPI) for the backend and set up the basic structure of the application.
      Develop a responsive and user-friendly front-end interface ensuring that it is accessible and works well on both desktop and mobile devices.
      Add search functionality to allow users to find projects by keywords, tags, or other metadata.
      Implement filtering options to narrow down search results (e.g., by campus, topic, or programming language).
      Deploy the application to a cloud platform (e.g., AWS, or Google Cloud) or GitHub Pages (GitHub.io) for public access.
      Create developer documentation that explains the application’s architecture, setup instructions, and contribution guidelines.
      Write a short user manual to help end-users browse and use the web application effectively.


      ~~~~~~~~~~


      Vector Embeddings Dataset
      jayjeetc
      Feb 11, 2025
      Vector Embeddings Dataset
      Topics: Vector Embeddings LLMs Transformers
      Skills: software development, apis, scripting, python
      Difficulty: Moderate
      Size: Medium or Large (175 or 350 hours)
      Mentors: Jayjeet Chakraborty
      To benchmark vector search algorithms (aka ANN algorithms), there are several datasets available but none of them represent actual real world workloads. This is because they usually have small vectors of only a few hundred dimensions. For vector search experiments to represent real world workloads, we want to have datasets with several thousand dimensions like what is generated by OpenAIs text-embedding models. This project aims to create a dataset with 1B embeddings from a wikipedia dataset using open source models. Ideally, we will have 3 versions of this dataset, with 1024, 4096, and 8192 sized embeddings to start with.


      ~~~~~~~~~~

      Improving and Optimizing Data Processing Pipeline for More Accurate Soil Moisture Measurements
      Topics: Digital Signal Processing Machine Learning
      Skills: C/embedded, signal processing, machine learning, MATLAB (optional)
      Difficulty: Moderate
      Size: Medium (175 hours)
      Mentors: Colleen Josephson, Eric Vetha
      Enhance the accuracy of soil moisture measurements by refining the data processing pipeline.

      Tasks:

      Develop and test algorithms for noise reduction and signal improvement.
      Implement advanced filtering and statistical techniques to improve measurement precision.
      Validate improvements using real-world field data.
      Translate algorithms into embedded to be implemented in real-time embedded hardware.
      
      ~~~~~~~~~~
      
      Improving Backscatter Tag PCB
      Topics: Hardware Design Signal Processing
      Skills: PCB design, RF knowledge
      Difficulty: Moderate
      Size: Medium (175 hours)
      Mentors: Colleen Josephson, Eric Vetha
      Enhance the performance of WaDAR’s backscatter tags by optimizing PCB design for improved signal-to-noise ratio (SNR) and implementing a communication protocol for tag identification.

      Tasks:

      Redesign PCB for improved readings.
      Implement and test a communication protocol to distinguish between multiple tags.
      Evaluate hardware changes in real-world field conditions.
      Optimize power consumption and scalability for practical deployment.


      ~~~~~~~~~~

      WildBerryEye
      Carlos Isaac Espinosa Ramirez
      Last updated on Feb 12, 2025

      WildBerryEye leverages Raspberry Pi and YOLO object detection models to monitor pollinizers like bees and hummingbirds visiting flowers. This initiative aims to enhance environmental research by automating data collection and analysis of pollinator activities, which are crucial for ecological assessments and conservation efforts. The project utilizes video data provided by Dr. Rossana Maguiña, processed through advanced machine learning techniques to accurately identify and track pollinator interactions in natural habitats.

      Develop web-based user interface
      Topics: Full Stack Development React Flask
      Skills: Experience with full stack development and real time processing
      Difficulty: Moderate to Challenging
      Size: Medium or large (175 or 350 hrs)
      Mentors: Carlos Isaac Espinosa Ramirez
      Develop a clean and intuitive web-based interface for WildBerryEye, ensuring ease of use for researchers and contributors. The platform should present real-time pollinator detection results, facilitate data visualization, and allow users to interact with system settings efficiently. The website must be accessible, visually appealing, and optimized for both desktop and mobile users, avoiding unnecessary complexity or intrusive elements.

      Specific tasks:

      Frontend Development: Continue development to enhance the user interface using React and CSS, ensuring a responsive and user-friendly design.
      Backend Development: Expand functionality using Flask, focusing on efficient API endpoints and seamless interaction with the frontend (excluding database implementation).
      Real-Time Communication: Implement and refine real-time updates between the frontend and backend to enhance system responsiveness.
      Usability & Design Optimization: Research and propose improvements to the system’s usability, design, and overall user experience.















       

























      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/unicode-inc./
    idea_list_url: https://docs.google.com/document/u/2/d/e/2PACX-1vQbj0-VFkRjYdnivuPPXuHM3IW4LuHxK6E0LVO3O8ZU_-k8CYH_eFMZ_IwFg_r-oBw3FCEOmHCb5jrn/pub


  - organization_id: 166
    organization_name: Unikraft
    no_of_ideas: 10
    ideas_content: |
      Expanding the Unikraft Software Support Ecosystem
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 2
      Constraints/requirements Basic OS concepts, familiarity with POSIX and system calls, build systems and tool stacks.
      Description
      One of the weak points of most unikernel projects has always been application support, often requiring that applications be ported to the target unikernel OS. With Unikraft we have been making a strong push towards POSIX compatibility so that applications can run unmodified on Unikraft. We have been doing this in two different ways:
      by adding support for the Musl libc library such that applications can be compiled against it, using their native build systems, and then linked into Unikraft
      through binary-compatibility mode, where unmodified ELFs are directly executed in Unikraft and the resulting syscalls trapped and redirected to the Unikraft core, via the app-elfloader.
      This has lead to the creation of the application catalog repository where running applications and examples are brought together.
      This project focuses on expanding Unikraft's software support ecosystem by adding new applications to the application catalog repository, primarily in binary-compatibility mode. While doing this, you will also:
      implement and extend system calls
      add extensive testing for the application or framework that is to be included in the catalog
      add benchmarking scripts to measure the performance and resource consumption of the application running with Unikraft
      conduct synthetic tests using tools such as the Linux Test Project
      The success of this project will directly impact Unikraft adoption. The project length can be varied depending on which of these items are covered by the project.
      Reading & Related Material
      https://www.musl-libc.org/
      https://unikraft.org/guides/using-the-app-catalog
      https://github.com/unikraft/catalog
      https://unikraft.org/docs/contributing/adding-to-the-app-catalog

      ~~~~~~~~~~
      Software Quality Assurance of Unikraft Codebase
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 2
      Constraints/requirements C programming skills, Linux command-line experience, build tools
      Description
      During its 6 years of existence, Unikraft, now at version 0.16.1, has grown in features, application support and codebase. As it matures, a high quality of the code and robust behavior are a must to provide a stable solution for its user base.
      The aim of this project is to assist in the software quality assurance of the Unikraft codebase, by tackling one of the following ideas:
      The use of the uktest framework to create unit tests for internal libraries and external libraries. Not many libraries have unit tests, those that do are mostly exceptions. This will directly impact the stability of the code base and allow quick validation of new features that may break existing functionality.
      Inclusion of static and dynamic analysis tools that highlight potential spots of faulty or undefined behavior.
      The use of compiler builtins and compiler flags providing constraints on the code to increase its resilience to faulty behavior.
      Augmenting the CI/CD system used by Unikraft (based on GitHub Actions) to feature automatic testing, validation and vetting of contributions to Unikraft repositories: core, libraries, applications. Potential items are:
      handling running of unikernels instead of simple builds
      static analysis of images to be delivered as reports to GitHub pull requests
      regression checks on performance (delivered as % change from the current upstream version)
      Any other project that is targeted towards increasing the robustness of Unikraft source code is welcome. These will both increase the viability of Unikraft as a stable solution and increase the quality of future contributions, by enforcing good practices on submitted code.
      Reading & Related Material
      Writing Tests in Unikraft
      https://www.guru99.com/unit-testing-guide.html
      https://docs.kernel.org/dev-tools/kunit/index.html
      https://github.com/features/actions
      https://unikraft.org/docs/contributing/review-process/

      ~~~~~~~~~~
      Supporting macOS networking (medium-large, 175-350hrs)
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 1
      Constraints/requirements Good Go skills, familiarity with virtualization, macOS and networking, good OS knowledge
      Description
      KraftKit, the supporting codebase for the modular library operating system Unikraft designed for cloud native applications, provides users with the ability to build, package and run unikernels. As a Swiss-army-knife of unikernel development, it eases both the construction and deployment of unikernels. To this end, supporting diverse user environments and their ability to run unikernels locally supports the ultimate goal of the project. One such environment which requires more attention is macOS.
      Towards better facilitating the execution of unikernel virtual machine images on macOS, this project aims to introduce new packages which interface directly with macOS environments by interfacing natively with the local networking environment such that the execution of unikernels is accessible through a more direct communication mechanisms of the host. Until now, the project only supports Linux bridge networking with accommodation (albeit "stubs") in the codebase for Darwin.
      Reading & Related Material
      unikraft/kraftkit#841

      ~~~~~~~~~~
      Converting the eroFS library to Golang and testing it
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 1
      Constraints/requirements Good Go skills, decent C skills, familiarity with file systems, basic testing knowledge
      Description
      EROFS (Enhanced Read-Only File System) is a lightweight, high-performance read-only filesystem tailored for Linux environments. It is designed to provide fast and efficient access to data while supporting built-in transparent compression, which helps reduce storage overhead. Currently, Golang has support through libraries only for reading EROFS files and no support for creating them.
      Towards better support in KraftKit, this project aims to introduce a new library that reimplements the mkfs.erofs command with all its functionality. This is currently implemented in C which can only be imported into Golang with C to Go bindings. Some attempts have been made to implement this, but are incomplete and do not offer all arguments, of which some we need. Finally, at all steps tests should be implemented that compare original functionality to the ported library functionality.
      Reading & Related Material
      https://docs.kernel.org/filesystems/erofs.html
      https://github.com/erofs/erofs-utils/blob/dev/mkfs/main.c
      unikraft/kraftkit#2007
      https://pkg.go.dev/gvisor.dev/gvisor/pkg/erofs
      https://github.com/dpeckett/archivefs/tree/main/erofs

      ~~~~~~~~~~
      Fine-Tuning Unikraft's Performance
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 1
      Constraints/requirements Good C skills, familiarity with general operating system concepts, good testing knowledge
      Description
      Over the past releases the development focus of Unikraft has been set on improving its compatibility with existing code bases and adding missing operating system features. This means that less efforts were dedicated to performance-testing Unikraft, resulting in a potential loss of performance in recent releases. Now that Unikraft is reaching the desired level of maturity and compatibility, it is time to go back to evaluating and fine-tuning its performance.
      The aim of this project is to 1) evaluate the current performance of Unikraft, 2) identify potential performance bottlenecks, and 3) address these bottlenecks through targeted patches.
      To evaluate the performance of Unikraft, this project will base on the evaluation of the Unikraft EuroSys paper, re-running experiments with the latest release of Unikraft. The first phase of the project will be to create a new repository with updated experiments that can easily be run in a push-button manner (deliverable 1).
      Following this, bottlenecks will be identified. Performance bottlenecks may lie in any Unikraft component: this will be a unique opportunity to touch on many operating system concepts. Performance bottlenecks will be reported in the form of GitHub issues (deliverable 2).
      Finally, the project will aim to provide self-contained, targeted fixes for these bottlenecks in the form of GitHub Pull-Requests (deliverable 3).
      This project is a unique opportunity to learn about performance evaluation and optimization in a production-grade operating system. It is also an opportunity to participate in a potential academic journal submission of Unikraft by refreshing its evaluation.
      Reading & Related Material
      The Unikraft EuroSys 2021 paper (see the Evaluation, Section 5): https://dl.acm.org/doi/10.1145/3447786.3456248
      The EuroSys 2021 evaluation repository: https://github.com/unikraft/eurosys21-artifacts
      
      ~~~~~~~~~~
      
      Testing Framework for Unikraft Builds
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 1
      Constraints/requirements Python knowledge, Linux CLI
      Description
      We are currently developing a testing framework that is able to multiplex the variety of configuration options, VMMs, hypervisors, architectures, boot protocols, to validate the successful building and running of unikernel images. This framework is able to configure, build, run and test the variety of Unikraft builds. It is written in Python and is subject to improvements and refactoring.
      We are looking to augment the testing infrastructure to make it seamless to be used by Unikraft developers and users. To this end we aim to:
      Consolidate the testing framework as a separate project inside its own repository.
      Have the testing framework work out-of-the-box with the catalog and catalog-core repositories.
      Integrate the testing framework with the CI/CD system used in the Unikraft organization repositories to automatically validate builds for contributions. Tests are to be triggered each time a pull request is open in the unikraft and in core library repositories.
      Reading & Related Material
      https://github.com/unikraft/catalog
      https://github.com/unikraft/catalog-core
      https://github.com/unikraft-upb/catalog/tree/razvand/generator/new-design/utils/new-design


      ~~~~~~~~~~
      Update Newlib and Pthread-embedded Libraries
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 1
      Constraints/requirements C, assembly, Linux CLI, GNU build tools
      Description
      The default Unikraft standard C library (libc) is Musl, a lightweight libc providing a POSIX interface. Up until 2022, the default libc was Newlib. Starting with release 0.11.0 the default libc switched to Musl.
      Ever since that point, Newlib supported hasn't been updated to keep up with the recent version of Unikraft.
      The goal of this project is to update Newlib and pthread-embedded support to the recent Unikraft versions. Such as current builds would work out-of-the-box with Newlib and pthread-embedded as well as Musl.
      The steps to be done are:
      Update Newlib and pthread-embedded to build with the most recent Unikraft version.
      Update Newlib version to the most recent upstream version.
      Build and run applications on the catalog-core and catalog repositories.
      (Optionally) Add CI pipelines to work with Newlib and pthread-embedded.
      Reading & Related Material
      https://github.com/unikraft/lib-newlib
      https://github.com/unikraft/lib-pthread-embedded
      https://github.com/RWTH-OS/pthread-embedded
      https://sourceware.org/newlib/


      ~~~~~~~~~~
      Update Unikraft Core External Libraries
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 2
      Constraints/requirements C, assembly, Linux CLI, GNU build tools
      Description
      The Unikraft core external libraries haven't been updated in the past 2 years. We aim to update them to their latest version. That means:
      Update lib-musl from 1.2.3 to 1.2.5 (the most recent upstream Musl version).
      Update lib-lwip from 2.1.2 to 2.2.1 (the most recent upstream LWIP version).
      Update lib-gcc from 7.3.0 to 14.2.0 (the most recent upstream GCC version).
      Update lib-libcxx from 14.0.6 to 19.1.7 (the most recent upstream LLVM version).
      Update lib-libcxxabi from 14.0.6 to 19.1.7 (the most recent upstream LLVM version).
      Update lib-compiler-rt from 14.0.6 to 19.1.7 (the most recent upstream LLVM version).
      Update lib-libunwind from 14.0.6 to 19.1.7 (the most recent upstream LLVM version).
      The update is aimed to use the workflow for Unikraft microlibrary version. As part of the update effort, we aim to also test and validate builds for the catalog-core and catalog repositories.
      Reading & Related Material
      RFC: Unikraft Microlibrary Versioning

      ~~~~~~~~~~
      Update Unikraft Application Libraries
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 2
      Constraints/requirements C, assembly, Linux CLI, GNU build tools
      Description
      The Unikraft application libraries haven't been updated in the past 2 years. We aim to update them to their latest upstream version. Target libraries / applications are:
      lib-nginx
      lib-redis
      lib-sqlite
      lib-python3
      lib-libgo
      lib-lua
      The update is aimed to use the workflow for Unikraft microlibrary version. As part of the update effort, we aim to also test and validate builds for the catalog-core and catalog repositories.
      Reading & Related Material
      RFC: Unikraft Microlibrary Versioning


      ~~~~~~~~~~
      Add FreeBSD Libc as Unikraft External Library
      Difficulty 3/5
      Project Size Variable (175 or 350 hours)
      Maximum instances 1
      Constraints/requirements C, assembly, Linux CLI, GNU build tools
      Description
      The default Unikraft standard C library (libc) is Musl, a lightweight libc providing a POSIX interface. FreeBSD Libc is the default libc used by default by FreeBSD, with a compatible license with Unikraft.
      The goal of this project is have a FreeBSD libc build repository for Unikraft and build existing applications against it. In the end, you would be able to build and run applications on the catalog-core and catalog repositories using the FreeBSD libc variant.
      Reading & Related Material
      https://github.com/freebsd/freebsd-src/tree/main/lib/libc
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/unikraft/
    idea_list_url: https://github.com/unikraft/gsoc/blob/staging/gsoc-2025/ideas.md


  - organization_id: 167
    organization_name: Uramaki LAB
    no_of_ideas:
    ideas_content: |
      GSoC 2025 Ideas for RUXAILAB
      All the current ideas for GSoC2025 are listed bellow:
      Big size projects (~350h)
      AI-Powered Accessibility Evaluation in RUXAILAB (350h)
      This project aims to develop a comprehensive AI-powered accessibility evaluation system within RUXAILAB, focusing on automating and enhancing WCAG compliance testing. By integrating artificial intelligence with semi-automated evaluation techniques, this system will assist developers and usability experts in identifying and addressing accessibility barriers in digital content, including websites, documents, and mobile applications. The system will provide detailed, multi-dimensional reports, offering both quantitative compliance scores and qualitative insights in plain language.
      Key Features:
      Automated WCAG Compliance Testing: Utilize AI-enhanced evaluation tools and integrate existing APIs (e.g., WAVE API) to generate automated accessibility assessments.
      AI-Powered Accessibility Insights: Implement machine learning models to detect complex accessibility issues that may not be captured by traditional automated tools, such as color contrast issues, ARIA misconfigurations, and screen reader compatibility problems.
      Data Integration and Analysis: Merge results from automated tools and AI-generated insights, creating a comprehensive accessibility evaluation framework.
      Semi-Automated Expert Evaluation: Enable expert evaluators to refine AI-generated reports, ensuring higher evaluation accuracy and adaptability.
      Quantitative Compliance Scoring: Establish a numerical accessibility index based on WCAG success criteria, enabling users to track and compare improvements over time.
      Natural Language Summaries: Use AI-driven text generation to translate technical accessibility reports into readable, actionable insights for designers, developers, and content creators.
      Continuous Learning Mechanism: Implement an AI model that improves over time by learning from expert evaluations and new accessibility guidelines.
      Keywords: Artificial Intelligence (AI), Accessibility Testing, WCAG Compliance, Data Analysis, Machine Learning, Usability Evaluation
      Expected Outcome: A fully integrated AI-driven accessibility evaluation system that enhances and automates WCAG compliance testing, making accessibility validation more efficient and insightful within RUXAILAB.
      Skills Required: Python, JavaScript, AI for Data Analysis, Machine Learning, Accessibility Standards (WCAG), NLP for Report Generation
      Mentor: Marc
      Difficulty: Hard
      AI Tool for Heuristic Evaluation (350h)
      This project aims to develop an AI-based heuristic evaluation tool capable of automatically assessing usability issues in digital interfaces, mimicking the analysis of an expert usability evaluator. The system will apply well-established usability heuristics, such as Nielsen’s Heuristics, to evaluate web pages and identify usability problems based on structured guidelines. The tool will generate detailed reports with quantitative scores and qualitative insights, helping designers and developers improve their interfaces.
      Key Features:
      Automated Heuristic Evaluation: Utilize AI to systematically analyze web pages based on usability heuristics.
      Expert-Level Analysis: Develop machine learning models trained on usability best practices to identify common usability problems such as poor feedback, inconsistent navigation, and inefficient workflows.
      Multi-Dimensional Reporting: Generate both quantitative usability scores and qualitative insights that explain detected usability issues similarly as RUXAILAB is doing right now.
      Continuous Learning Mechanism: Enhance evaluation accuracy by refining AI models based on expert reviews and user feedback.
      Integration with RUXAILAB: Seamlessly integrate with the existing usability evaluation tools within RUXAILAB.
      Keywords: Artificial Intelligence (AI), Usability Testing, Heuristic Evaluation, Data Analysis, Machine Learning, UI/UX Optimization
      Expected Outcome: A fully automated heuristic evaluation tool that functions as an AI-based usability expert, identifying and reporting usability issues based on standard heuristic guidelines.
      Skills Required: Python, JavaScript, NLP for Report Generation
      Mentor: Marc González
      Difficulty: Hard
      Integration of Heat Maps into Remote Usability LAB (350h)
      Heat maps encompass a variety of tracking tools, including scroll maps, click maps, and move maps, each providing distinct insights into user behavior. This project aims to develop and integrate a comprehensive heatmap recording tool for usability testing inside the RUXAILAB framework. The system will optimize mouse tracking and generate detailed reports on user interactions.
      Key Features:
      Comprehensive Heatmap Tracking: Implementation of scroll maps, click maps, and move maps for a thorough performance analysis
      Real-Time Data Collection: AI-powered tracking to capture and visualize user interaction patterns
      Optimized Mouse Tracking System: Enhancing usability testing with advanced cursor movement analytics
      Automated Report Generation: AI-driven insights into user behavior for usability evaluation
      Seamless RUXAILAB Integration: Full compatibility with existing usability testing tools
      Keywords: Artificial Intelligence (AI), Algorithm Optimization, JavaScript, Usability Testing, Front-end Development
      Expected Outcome: A fully integrated heatmap tracking system that enhances usability testing in RUXAILAB by analyzing user behavior and generating reports
      Skills Required: Python, JavaScript, AI for Data Analysis
      Mentor: Murilo
      Difficulty: Hard
      Integration of User Testing into RUXAILAB with Eye Tracking, Sentiment Analysis and Pre-Post Form Tasks (350h)
      This project aims to integrate advanced user testing capabilities into RUXAILAB, incorporating eye tracking, sentiment analysis, and structured pre/post-test forms. By combining these elements, the system will provide a comprehensive framework for usability testing, offering insights into user behavior, emotional response, and engagement levels.
      Key Features:
      Eye Tracking Integration: Analyze user gaze patterns to identify usability issues and areas of focus
      Sentiment Analysis: Utilize AI-driven sentiment detection to assess user emotions during interactions
      Pre and Post-Test Forms: Structured questionnaires to collect user expectations and post-experience feedback
      Automated Data Analysis: Generate real-time reports with actionable insights for improving usability
      Seamless RUXAILAB Integration: Ensure compatibility with existing usability testing workflows
      Keywords: User Testing, Eye Tracking, Sentiment Analysis, AI, Usability Testing
      Expected Outcome: A fully integrated user testing framework that enhances RUXAILAB by capturing and analyzing user behavior, emotional responses, and structured feedback
      Skills Required: Python, JavaScript, AI/ML for Sentiment Analysis, Eye Tracking APIs
      Mentor: Marc and Karine Difficulty: Hard
      Medium size projects (~175h)
      UI Layout Optimization for RUXAILAB (175h)
      This project aims to redesign the RUXAILAB user interface (UI) to improve usability, accessibility, and responsiveness.
      Key Improvements:
      Simplified Navigation: Improved menu structure for seamless interaction
      Responsive Design: Optimized for mobile, tablet, and desktop
      Accessibility Features: WCAG-compliant color contrast, keyboard navigation, screen reader support
      Dark Mode & Custom Themes: Enhancing user comfort for different environments
      Keywords: UI/UX Design, Accessibility, Front-end Development, , Usability Testing
      Expected Outcome: A fully redesigned and accessible RUXAILAB interface Skills Required: JavaScript, Vue.js, CSS, Figma, AI for UI Optimization
      Mentor: Leticia
      Difficulty: Medium
      Comparative Analysis and Fine-Tuning of Sentiment Models for Improved System Integration (175h)
      This project focuses on comparing and fine-tuning sentiment analysis models to enhance integration efficiency and scalability within RUXAILAB. The goal is to analyze both traditional performance metrics and operational scalability factors to determine the most efficient sentiment models for real-time and batch processing scenarios.
      Key Features:
      Resource Efficiency Analysis: Evaluate computation time, response latency, and initialization speed
      Performance Comparison: Assess accuracy, F1-score, and contextual processing capabilities
      Scalability and Memory Management: Optimize model performance under varying data loads
      Batch vs. Real-Time Processing: Analyze trade-offs between batch processing and real-time sentiment detection
      Storage and Memory Optimization: Identify strategies to minimize memory footprint while maintaining performance
      Monitoring and Observability: Implement tracking mechanisms for efficient model oversight
      Keywords: Sentiment Analysis, Machine Learning, AI Optimization, Scalability, Performance Metrics
      Expected Outcome: A comparative study and fine-tuned sentiment models optimized for scalability, resource efficiency, and real-time usability in RUXAILAB
      Skills Required: Python, NLP, AI/ML, Model Optimization
      Mentor: Karine
      Difficulty: Medium
      Transcription Tool for Usability Testing (175h)
      This project aims to create a transcription service designed to streamline usability testing processes within RUXAILAB. The service will allow testers to activate transcription during specific tasks of a test and provide an interface to review and analyze transcriptions afterward. By integrating real-time speech-to-text capabilities, usability researchers can better capture verbal feedback from users.
      Key Features:
      Task-Specific Transcription: Testers can activate transcription for specific tasks during usability tests
      Post-Test Review and Editing: An interface for reviewing, organizing, and editing transcriptions task by task
      Automated Report Generation: Generate comprehensive task-specific transcription reports exportable in multiple formats (e.g., PDF, CSV)
      Seamless RUXAILAB Integration: Ensuring compatibility with existing usability testing workflows
      Real-Time Speech-to-Text Processing: Enable accurate transcription of verbal feedback during user testing
      Keywords: Speech-to-Text, Transcription, Usability Testing, AI, Automation
      Expected Outcome: A task-based transcription system integrated into RUXAILAB, allowing testers to capture, analyze, and report usability test transcriptions efficiently
      Skills Required: Python, NLP, Speech-to-Text APIs, Front-End Development
      Mentor: Anna
      Difficulty: Medium
      Implementation of A/B Testing Capability in RUXAILAB (175h)
      This project focuses on implementing A/B testing functionality within RUXAILAB to enhance usability evaluation and data-driven decision-making. The goal is to provide an integrated system for running controlled experiments, comparing different UI designs, and gathering insights on user preferences.
      Key Features:
      Automated A/B Test Setup: Allow testers to configure and manage A/B tests within RUXAILAB
      Real-Time Performance Tracking: Collect user interaction data for different variations
      Statistical Analysis Module: Provide insights on test results using key performance indicators
      User Segmentation: Enable tests based on demographic, behavior, or experience level
      Seamless UI Integration: Ensure compatibility with existing usability testing workflows
      Keywords: A/B Testing, User Experience, Usability Testing, Data Analysis, Front-End Development
      Expected Outcome: A fully integrated A/B testing module that allows usability researchers to conduct controlled experiments and make data-driven design decisions in RUXAILAB
      Skills Required: JavaScript, Python, Data Analysis, UI/UX Testing
      Mentor: Igor
      Difficulty: Medium
      Small size projects (~90h)
      Integration of GitHub Actions with Discord Role Management (90h)
      This project aims to integrate GitHub Actions with Discord to automate role creation, pull request (PR) management, and collaboration analytics. The system will enable seamless automation between GitHub repositories and Discord servers, ensuring that users receive appropriate roles based on their contributions and project interactions.
      Key Features:
      Automated Role Assignment: Assign Discord roles based on GitHub contributions, such as merged PRs, issues opened, and commits
      Pull Request Management: Automate PR reviews, label assignments, and notifications to Discord channels
      Collaborator Analytics: Generate visual charts of contributors' activities and display them in Discord
      Customizable GitHub Actions: Enable project maintainers to define rules for PR handling, auto-merging, and CI/CD notifications
      Seamless RUXAILAB Integration: Extend usability for research and open-source projects
      Keywords: GitHub Actions, Discord API, Automation, Open Source Collaboration, Workflow Management
      Expected Outcome: A GitHub Actions-powered integration that automates role management, PR handling, and contributor analytics for Discord communities
      Skills Required: JavaScript, Python, GitHub Actions, Discord API
      Mentor: Leticia
      Difficulty: Easy
      Automating Issue Creation from SonarQube in CI/CD Pipelines (90h)
      This project focuses on automating the creation of GitHub issues based on SonarQube analysis in a CI/CD pipeline. By integrating SonarQube results into the development workflow, the system will automatically detect code quality issues, create GitHub issues, and notify maintainers for quick action.
      Key Features:
      Automated Issue Creation: Detect new issues from SonarQube scans and create corresponding GitHub issues
      Severity-Based Issue Prioritization: Categorize issues based on severity (Critical, Major, Minor)
      Pipeline Integration: Ensure smooth integration with CI/CD workflows for real-time analysis
      Developer Notifications: Automatically notify responsible developers about newly created issues
      Customizable Rules: Allow maintainers to define which issues should trigger automatic creation
      Keywords: SonarQube, Software Quality, CI/CD, GitHub Actions, Automation
      Expected Outcome: A fully automated issue tracking system that integrates SonarQube with GitHub for better software quality management
      Skills Required: Python, JavaScript, GitHub Actions, SonarQube API
      Mentor: Leticia
      Difficulty: Easy
      Enhancing Playwright Testing in RUXAILAB (90h)
      This project aims to refine and optimize Playwright-based automated testing in RUXAILAB, improving test efficiency and documentation to enhance maintainability and ease of use. The focus will be on ensuring robust test coverage, optimizing test workflows, and developing comprehensive documentation to support contributors.
      Key Features:
      Improving Test Maintainability: Refactor test scripts for better reusability and efficiency
      Cross-Browser and Device Compatibility: Ensure consistent behavior across different browsers and devices
      Accessibility Testing Enhancements: Strengthen WCAG compliance validation for UI components
      Comprehensive Documentation: Develop detailed guides on test creation, execution, and maintenance
      Integration with CI/CD Pipelines: Enhance GitHub Actions workflows for streamlined automated testing
      Keywords: Playwright, Automated Testing, UI Testing, Accessibility, Documentation
      Expected Outcome: A more maintainable and well-documented Playwright testing framework, ensuring long-term usability and ease of contribution in RUXAILAB
      Skills Required: JavaScript, Playwright, Automated Testing, CI/CD, GitHub Actions, Technical Writing
      Mentor: Eric
      Difficulty: Easy
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/uramaki-lab/
    idea_list_url: https://github.com/ruxailab/gsoc/blob/main/ideas2025.md

  - organization_id: 168
    organization_name: VideoLAN
    no_of_ideas: 28
    ideas_content: |
      
      
      Advanced Audio Filters
      Project Description: We are looking for a skilled audiophile that knows a lot about audio theory and practice to work on new audio filters for VLC.
      Duration: 350h
      Tasks to do:
      SRS WoW like or other 3D effects;
      channels mixing, notably upmixing, like Prologic-II;
      tracks mixing, and transitions;
      scriptable new audio filters in lua and enable users to create whatever audio filtering function they want in a Lua script;
      LADSPA or other libraries integration.
      Requirements: This project needs some good audio knowledge and good C experience.
      Qualification task: Port any audio filter from MPlayer
      Proposed mentor: unidan

      ~~~~~~~~~~
      VLC Qt interface redesign
      Project Description: The VLC interface is quite outdated on Linux and Windows. It has a lot of features, but some are not properly exposed.
      We are currently reworking the interface, but we need help.
      Duration: 350h
      Scope of the tasks to do:
      Use the new designs shared on the mailing list, and help developping part of those, using Qml.
      This new interface is simpler, more user friendly, and has a better "media center" feel into it.
      It requires integration with the media library and with the current interface.
      Qml is the technology needed to improve the current UI.
      Requirements: This project requires Qt/C++ knowledge, and qml would be a nice plus.
      Proposed mentor: Pierre

      ~~~~~~~~~~
      VLC Skins2 interface update
      Project Description: The VLC Skins2 interface was not updated for the latest interface and core changes for the media player and playlist engine yet.
      We are currently reworking the interface, but we need help.
      Duration: 350h
      Scope of the tasks to do:
      wayland integration
      video integration rework (like Qt interface)
      medialibrary integration
      Requirements: This project requires Qt/C++ knowledge, and qml would be a nice plus.
      Proposed mentor: Pierre

      ~~~~~~~~~~
      VLC macOS interface redesign
      Project Description: The VLC interface is quite outdated on macOS and we are currently in the process of re-writing it to give it a modern feel, but also to integrate recent additions to libvlc regarding playback control and library management.
      This project for the summer is to rework heavily this interface to make it beautiful and useful again.
      Duration: 350h or 175h
      Scope of the tasks to do:
      There is a full design already done and tested. The major hurdle is to actually implement it the way we want it to be. The iOS/tvOS interface is simpler, more user friendly, and has a better "media center" feel into it, which influenced what we want to achieve on the Mac. Note that the objective is to use AppKit. UIKit will not be part of this project.
      Iterating from the current UI and closely collaborating with the team currently working on it is a requirement.
      Requirements: This project requires Obj-C knowledge, a thorough understanding of OOP and proven previous Mac development experience. You cannot use swift for this project.
      Proposed mentor: David Fuhrmann, Felix Paul Kühne

      ~~~~~~~~~~
      VLC watchOS port
      Project Description: VLCKit recently added support for playback of audio files on watchOS with support for http streams coming in a future update. The idea is to create a new, standalone app for watchOS that can play local files on device with a good way to synchronize those either from a computer or the app on the companion iPhone. The UI development needs to be done in SwiftUI following the restrictions of the platform.
      Duration: 350h
      Proposed mentor: Diogo Simao Marques, Felix Paul Kühne

      ~~~~~~~~~~
      iced ui for VLC
      iced is a cross-platform UI library for Rust. The project aims to provide a VLC iced Widget as first step and then a full UI as complete as possible within the time available.
      Tasks
      Revamp and publish the VLC-rs bindings
      Create an iced Widget similar to what exists already forGStreamer
      Increase the richness of the UI gradually
      First normal direct playback (play pause seek)
      Add volume controls
      Add support to manage subtitles
      Expose the VLC configuration knobs (one subset at time)
      Duration: 175h
      Proposed mentor: Luca Barbato

      ~~~~~~~~~~
      Improve Android MediaCodec support
      Project Description: The goal is to fix few bugs (black screen with some device/video, HDR issues), and to improve the download of MediaCodec surfaces to the CPU
      Duration: 175h
      Scope of the tasks to do:
      Fix MediaCodec bugs https://code.videolan.org/videolan/vlc/-/issues/?sort=updated_desc&state=opened&label_name%5B%5D=Component%3A%3AVideo%3A%20Android&first_page_size=20
      Fix download for all kind of chromas/size/offset/crop (Decoding Acceleration in the vlc-android app)Duration: 350hRequirements: Those will be done in C, and it requires familiarity with the android dev environment and hardware decoders.
      Proposed mentor: Thomas Guillem

      ~~~~~~~~~~
      Add back netsync module
      Project Description: Use the new vlc clock to add back the netsync module
      Duration: 350h
      Scope of the tasks to do:
      Use a new network protocol: RTP Midi
      Expose some vlc_clock APIs to be used by "control" module
      Plug the vlc_clock API inside the new module
      Requirements: Very good C knowledge
      Proposed mentor: Thomas Guillem

      ~~~~~~~~~~
      VLC iOS UI update
      Project Description: We're currently in the process of rewriting and updating the entire UI for VLC iOS
      There is a lot of components that need refactoring and need to get an updated UI.
      The Android port of VLC has done most of that and was successful. We need the same level of features.
      Duration: 350h or 175h
      Tasks to do:
      Get an overview of the current App and components that need an update
      Refactor and give the appropriate components a new look
      See what is missing compared to the Android version
      Code it :
      Requirements: This project requires Obj-C and Swift knowledge and ideally knowledge of writing tests for iOS but this can be learned.
      Proposed mentor: Felix Paul Kühne, Diogo Simao Marques

      ~~~~~~~~~~
      Qt integration tests
      Project Description: In order to improve the robustness of our application, we would like to develop integration tests for the Qt interfac.e The goal being to ensure that new features and refactors won't break other parts of the UI.
      Duration: 350h or 175h
      Scope of the Tasks to do:
      study existing solutions used in other open-source projects (https://invent.kde.org/sdk/selenium-webdriver-at-spi)
      adapt test framework to our environment
      write sample test cases
      study CI integration feasibility (Linux and/or Windows tests)
      Requirements: This project requires Qt/C++ and some scripting language (pyhton?) knowledge, Qml would be a nice plus.
      Proposed mentor: Pierre

      ~~~~~~~~~~
      
      Cloud integration for desktop
      Project Description: We want to be able to access Cloud Storage services (Dropbox, Google Drive and so on) in the VLC application.
      Duration: 350h or 175h
      Scope of the Tasks to do:
      revive libcloudstorage
      integrate libcloudstorage inside VLC
      write sample test cases
      Requirements: This project requires C++ knowledge.
      Proposed mentor: Pierre

      ~~~~~~~~~~
      
      Improve libNDI and integrate in VLC
      Project description: Improve the libNDI project supporting the NDI protocol to support more formats.
      Duration: 350h
      Tasks to do:
      Study the NDI protocol, implement and test and integrate inside VLC.
      Requirements:
      NDI understanding
      C knowledge.
      Proposed mentor: j-b

      ~~~~~~~~~~
      Update the Lua integration
      Project description: The current extension implementation in Lua needs more love to make them first class citizen (they are currently loaded by GUI instead of the core).
      Duration: 350h
      Tasks to do:
      update libvlccore to load Lua extensions instead of the GUI
      work on a better descriptive abstraction for lua stream parsers extensions which needs to extract data from the webpage. (currently done by manual read())
      more testing infrastructure for the scripts
      Requirements:
      Lua and C knowledge, c++ is a plus
      Proposed mentor: Alexandre Janniaux

      ~~~~~~~~~~
      Implement DVD-Audio deciphering
      Project description: Support DVD-Audio deciphering using dvdcpxm
      https://offog.org/git/dvdaexplorer/
      http://www.thescrapyard.org/software/libdvdcpxm.html
      http://forum.doom9.org/showthread.php?t=167537
      https://sourceforge.net/projects/dvdadecoder/
      Duration: 350h
      Tasks to do:
      Understand DVD-Audio
      Implement VLC module based on those modules
      Requirements:
      Audio likeness
      C knowledge.
      Proposed mentor: j-b

      ~~~~~~~~~~
      Radio-Browser integation
      Project Description: Integrate the Radio-Browser.info API in a service discovery module so it is available on all of VLC's platforms.
      Duration: 175h
      Tasks to do:
      Study and understand the REST API
      Implement a VLC module based on the API
      Add a way to favorite channels
      Requirements:
      previous experience with REST APIs
      C knowledge
      Proposed mentor: Felix

      ~~~~~~~~~~
      Port the remote access webserver to VLC Desktop
      Description: To remotely access and control a VLC instance, a webserver has been developped for VLC Android. The goal is to port it to VLC desktop.
      Duration: 350h
      Tasks to do:
      Extract the web client code from the VLC for Android reprository to a dedicated one
      Write the server part in VLC desktop using lua scripts
      Adapt the client to be compatible with the new VLC desktop web server
      Requirements:
      js, Vue, lua, websockets
      Proposed mentor Nicolas

      ~~~~~~~~~~
      demux Rust bindings and AVI module for VLC
      VLC has already its first Rust (logger) module: https://code.videolan.org/videolan/vlc/-/commit/e8e46b0d915d153a58d002c9d6f19a7dbdfeeca9 There was a proposal to add several Rust bindings and example: https://code.videolan.org/videolan/vlc/-/merge_requests/2738
      Tasks
      Adapt demux API Rust bindings to upstream VLC
      Add a new AVI demux module to test the new bindings (Using the nom crate: https://crates.io/crates/nom/)
      Duration: 350h
      Requirements: Good C knowledge and very good Rust knowledge
      Proposed mentors: Thomas Guillem and Alexandre Janniaux

      ~~~~~~~~~~
      integrate checkasm tooling and improve existing asm coverage
      VLC has some amount of existing assembly (yadif, video chroma) but we lack test coverage for it and also could use more for newer architectures
      Tasks
      Integrate checkasm for validation (against a C baseline) and benchmarking (similarly to what's done in dav1d)
      Convert the existing assembly to use it
      Add new optimizations for things like audio/video format conversions, filters and also for newer arch's (riscv etc.)
      Duration: 175h or 350h
      Proposed mentors: Marvin Scholz, Nathan Egge, Tristan Matthews
      
      ~~~~~~~~~~
      libvlc Wayland API
      In order to allow easy integration of VLC video rendering into application that uses Wayland, similarly to what we provide for X11 or HWND.
      Duration: 175h
      Scope of the Tasks to do:
      Provide a method to expose external Wayland surface and additional mechanisms to libvlc.
      Write a sample application to illustrate how to use the API
      Requirements: This project requires some good C experience
      Proposed mentor: Pierre Lamot

      ~~~~~~~~~~
      Other short ideas for VLC & libVLC
      Those ideas are not detailed, but they are ideas that we could help to spring new ideas. We can help work with you to make those more detailed.
      Those ideas should be 175h long
      Improve Vulkan output for VLC, including HDR support
      Improve id3 tag and metadata handling in VLC
      Bridge module for GMI'C or other video filters
      Automated Testing Environment like ffmpeg Fate (port ?) for demuxing, non-hw decoding
      Integrate libavfilter in VLC
      Improve the libVLCSharp bindings for VLC in C#
      Provide setups for popular streaming services / sout templates (ui ?)
      Improve cue support in VLC

      ~~~~~~~~~~
      Ideas for VideoLAN infrastructure
      Improve the VideoLAN crash reporter in Go and Vue.js
      The idea is to improve the current crash reporter of VLC, called CrashDragon.
      The tasks are the following:
      Review the current code
      Improve the API in Go
      Write a new Vue.js frontend
      Those will be done in Go and JS
      Duration: 350h
      Proposed mentor: David and j-b

      ~~~~~~~~~~
      Ideas for dav1d
      dav1d RISC-V optimizations
      Improving the performance of the AV1 decoder is very important for VLC and the whole ecosystem.
      It requires to:
      Understand of RISC-V assembly
      Understand a bit what a video decoder is
      Write RISC-V functions
      Requirements: This project requires C and ASM knowledge, as well as system programming skills
      Duration: 175h
      Contact 'j-b'

      ~~~~~~~~~~
      dav1d GPU Compute Shaders
      Improving the performance of the AV1 decoder is very important for VLC and the whole ecosystem.
      This project requires to port one of the filter, like SGR or Wiener to one of the Shader languages. iPhones or Xbox One would be a good target.
      This is a tricky project, but is doable during the summer
      Duration: 350h
      Requirements: This project requires C and GPU Shaders knowledge, as well as system programming skills
      Contact 'j-b'

      ~~~~~~~~~~
      dav1d statistics extractions
      The dav1d AV1 decoder is a new high performance AV1 decoder by VideoLAN.
      Current open source tools for AV1 analysis use instrumentation in the reference decoder libaom to extract decode-time metadata for display and reporting, but support for sophisticated analysis is lacking.
      To speed development of AV1 tools like the rav1e, it would be helpful to add similar decoder metadata extraction APIs to the dav1d decoder so that rapid testing of encoder algorithms is easier. This includes the ability to quickly produce statistics, visualizations and other reporting that can be used for tuning encoder parameters or guiding development. Advanced ideas include adding similar encoder metadata API to rav1e that add encode-time visualizations.
      Requirements: This project requires C knowledge.
      Duration: 175h
      Contact 'unlord'

      ~~~~~~~~~~
      Ideas for libplacebo
      Direct3D 11 backend
      Project Description:
      libplacebo uses a GPU abstraction with a number of backends. The goal would be to add a new backend based on Direct3D 11, since Vulkan and OpenGL support on Windows are often of limited quality, especially for older hardware.
      Lots of example code for how this implementation would look can be found as part of the mpv project .
      Large parts can be copy/pasted and adapted to the libplacebo API.
      Tasks to do:
      Add a new `pl_gpu` backend based on Direct3D 11
      Integration into the build system, test framework and CI infrastructure
      Requirements:
      Knowledge of C as well as, ideally, graphics API fundamentals. (But the latter can be learned as part of the project)
      Ability to develop and test on Windows
      Duration: 175h
      Contact 'haasn'

      ~~~~~~~~~~
      Dolby Vision Profile 5 (IPT-PQ)
      Project Description:
      Dolby IPT-PQ is a HDR color space similar to ITU-R ICtCp, but with proprietary Dolby modifications (reshaping algorithm). Your goal is to implement this reshaper in the form of a GLSL shader, using knowledge from known Dolby patents and dumped headers.
      Tasks to do:
      Figure out, and (if necessary) reverse engineer the stream format for the Dolby reshaping algorithm described in several of their patents.
      Implement this algorithm in GLSL
      Integration into libplacebo (optional)
      Test against reference implementations of Dolby Vision profile 5
      Requirements:
      Knowledge of GLSL and C. Knowledge of colorspaces in general is an obvious plus, but the theory here is not important - only the implementation.
      (Possibly) Ability to reverse engineer any still-unknown or differing-from-patents parts of the stream headers.
      Knowledge of libplacebo internals is not required, since the skeleton code for this already exists - what's missing is the reshaping algorithm.
      Duration: 350h
      Contact 'haasn'

      ~~~~~~~~~~
      GPU motion interpolation (mvtools)
      Project Description
      Your goal is to develop GPU shaders for motion-adaptive frame interpolation in the style of [mvtools](https://github.com/dubhater/vapoursynth-mvtools).
      This is an open-ended project. If not completed, any progress towards this goal is good enough.
      Sub-goals:
      Recreate the motion vector search algorithms from MAnalyze
      Implement the pixel masking and pixel flow algorithms from MFlowFps
      These can be tackled and complete out-of-order.
      Requirements:
      Good knowledge of both C and GLSL, especially compute shaders and other GPGPU techniques. (CUDA or OpenCL skills also transfer, though the shader will have to be GLSL)
      Ideally, general knowledge of video processing techniques (e.g. motion vector search) - at least enough to be able to understand what mvtools code is doing.
      Duration: 350h
      Contact 'haasn'

      ~~~~~~~~~~
      Ideas for VLC dependencies
      libmicrodns refactoring
      Our current mDNS discoverer is working, but is not so respectful of the RFC. Possible improvements include:
      Device TTL support
      Device removal detection
      Better request pacing
      Delegate socket interactions to the caller
      Unit testing
      Fuzzing
      Requirements: This project require C knowledge, as well as system programming skills
      Duration: 175h
      Proposed mentor: tguillem

    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/videolan/
    idea_list_url: https://wiki.videolan.org/SoC_2025/


  - organization_id: 169
    organization_name: Wagtail
    no_of_ideas: 2
    ideas_content: |
  
      Content Security Policy compatibility
      Summary
      Wagtail is close to being compatible with strict Content Security Policies (CSP). With one final push, we can get fundamental features all compatible with CSPs, document support, and treat any gaps as bugs.
      For more information, see:
      CSP compatibility issues #1288
      A list of widgets breaking strict Content-Security-Policy (CSP) directives #7053
      Wagtail Stimulus Adoption Schedule (2022-25) 🎛️.
      Expected outcomes
      Addressing any remaining CSP issues in Wagtail.
      Providing official recommendations for compatible CSP settings.
      Ensuring essential functionality works with a strict CSP.
      Documenting or backlogging all CSP-related issues.
      Adding a strict CSP to wagtail.org.
      Implementation
      This will require reviewing existing issues and technical discovery work to device a plan for addressing them. Understanding options in django-csp, and possibly trialing any changes with core Django CSP support.
      The changes required will be a mix of front-end and backend work, and require expertise with security fundamentals to understand what is needed.
      Skills
      Django
      JavaScript
      Security headers
      CSP
      Cross-site scripting
      Technical writing
      Mentors
      Lead: TBC - Sage Abdullah
      Support: TBC
      Support: TBC
      Size
      Expected size of project approximately 350 hours.
      Difficulty rating
      High

      ~~~~~~~~~~
      Grid-aware websites
      Summary
      We want to trial the grid-aware websites concept on a real Wagtail project: the wagtail.org website. This will involve understanding what grid awareness means for websites, how to implement it with Wagtail, and how to measure the website’s energy use depending on different adaptations.
      Expected outcomes
      A grid-aware version of the wagtail.org website.
      A blog post explaining the process and outcomes.
      A report on energy use of different website front-end and back-end components.
      A set of recommendations for other Wagtail websites to become grid-aware.
      Implementation
      This is highly dependent on the outcome of the ongoing grid-aware websites project, which is currently under way. More information will be available in March 2025.
      Skills
      JavaScript
      Django
      Cloudflare workers
      Digital sustainability
      Performance auditing
      Mentors
      Lead: Thibaud Colas
      Support: TBC
      Support: TBC
      Size
      Expected size of project approximately 350 hours.
      Difficulty rating
      High

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/wagtail/
    idea_list_url: https://github.com/wagtail/gsoc/blob/main/project-ideas.md


  - organization_id: 170
    organization_name: Waycrate
    no_of_ideas: 3
    ideas_content: |
 
      Idea 1: Introduce ext_image_capture_source_v1 protocol support in Wayshot and improve security features
      Possible Mentors:
      Rachancheet Singh Kohli (rachancheet37 [at] gmail.com)
      Aakash Sen Sharma (aakashsensharma [at] gmail.com)
      Ishan Joshi (joshiishan246890 [at] gmail.com)
      Difficulty: Hard
      Project Size: Large (350 Hours)
      Pre-requisite Skills: Rust, Wayland Protocols ( Optional )
      Description:
      The ext_image_capture_source_v1 protocol has recently been introduced to Wayland, providing a standardized method for display and top-level window capture. Wayshot currently supports CPU-based and GPU-based capture over wlr-screencopy protocol which is non-standard. Adopting the official protocol offers toplevel capture capabilities natively and improves the user experience.
      This idea aims to introduce a new backend and turn the wlr backend into a legacy codebase for backwards compatibility. Due to the existence of this standardized protocol, we can now also provide extra security to users and denote over dbus notifications when a particular app-id is being recorded by wayshot clients.
      Expected Outcomes:
      Introduction of new standardized protocol and security features to denote when toplevels are recorded by clients.
      Integration of the same protocol to xdg-desktop-portal-luminous to enable standardized WebRTC streaming.
      ~~~~~~~~~~
      
      Idea 2: Introduce libinput backend to SWHKD to improve keyboard detection and security heuristics
      Possible Mentors:
      Ishan Joshi (joshiishan246890 [at] gmail.com)
      Aakash Sen Sharma (aakashsensharma [at] gmail.com)
      Difficulty: Medium
      Project Size: Medium (175 Hours)
      Skills: Rust
      Description:
      Currently SWHKD uses the linux kernel evdev module to read keyboards and has very simplistic heuristics for device detection that is not ideal and prone to errors. Due to these heuristics SWHKD in some scenarios may capture kernel events from devices that are NOT meant to be grabbed.
      Evdev also requires a very complex security model to work with to ensure proper execution and we hope libinput helps us resolve some of that.
      This can be avoided by a more restricted libinput API and can significantly reduce code complexity. This would also vastly enhance the UX of the project at the cost of reduced capabilities but that can be avoided by a feature flag during build time.
      PS: Due to space constraints we are unable to list out all the advantages & disadvantages of evdev. If you’d be interested in those details, feel free to contact the listed possible mentors.
      Expected Outcomes:
      Introduction of new libinput API for improved UX
      
      ~~~~~~~~~~
      Idea 3: Introduce RDP support into xdg-desktop-portal-luminous
      Possible Mentors:
      Decodetalkers (chenhongtao12345678 [at] gmail.com)
      Aakash Sen Sharma (aakashsensharma [at] gmail.com)
      Difficulty: Medium-ish (leaning towards hard)
      Project Size: Medium (175 Hours)
      Skills: Rust
      Description:
      Xdg-desktop-portal-luminous is a high performance capture portal for wayland compositors that supports frame capture and gpu-copy based frame streaming. The goal of this idea is to introduce support for remote-desktop protocol to enable applications like teamviewer and anydesk to work seamlessly on wayland compositors using our custom portal backends.
      This will improve adoption and UX, users will no longer need to depend on other portals for this particular usecase and all usecases can be consolidated into 1 portal.
      Expected Outcomes:
      Introduction of RDP support to luminous portal.
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/waycrate/
    idea_list_url: https://waycrate.github.io/outreach/gsoc/2025/idea-list/
  

  - organization_id: 171
    organization_name: Wellcome Sanger Tree of Life
    no_of_ideas: 5
    ideas_content: |

        Finding the impact of biodiversity genomics datasets in scientific publications

        Mentors

        TBC (Sanger Tree of Life and Europe PMC at EMBL-EBI)

        Size

        LARGE (350 hours)

        Difficulty

        HARD

        Technologies

        Python, Machine-learning, Text processing

        THIS project aims to develop an advanced literature retrieval method tailored for research within biodiversity projects such as the Darwin Tree of Life (DToL) initiative. By integrating the Europe PubMed Central (Europe PMC) literature search functionality, the tool will provide researchers with a powerful platform to efficiently identify, access, and analyse cutting-edge scientific information. Beyond enhancing literature accessibility, this project will offer valuable insights into the outcomes of Tree of Life research, deepening our understanding of the impact of biodiversity genomics and its applications. It will also inform future resource management strategies by identifying key trends, gaps, and opportunities in the field. Ultimately, this initiative aims to equip researchers with the tools and knowledge needed to drive advancements in biodiversity genomics while supporting sustainable and informed decision-making for the management of biological resources.

        MORE technically, the project focuses on co-developing an NLP-based tool that can find relevant biodiversity genomics articles in Europe PMC. Key steps in the project may include:

        Building a specialized dictionary of biodiversity genomics-related keywords, phrases, and domain-specific terms from relevant documents, publications, and biological terminology databases.
        Data collection from the Europe PMC database and preprocessing.
        Annotation using the dictionary and filtering.
        Language pattern recognition.
        Machine learning based classification method development.
        It is an extremely challenging project. We will be working with the Europe PMC team at EMBL-EBI to develop this methodology and may have to align with some of their existing text mining initiatives and frameworks already used in production. Flexibility will be key to design and implement this right.

        Further reading:

        Darwin Tree of Life website and example scientific output
        Europe PMC web portal, Annotation service / API, and download page.

        ~~~~~~~~~~

        Building a machine-learning taxon classifier to inform genomic classification in malaria mosquitoes

        Mentors

        Chris Clarkson, Anastasia Hernandez-Koutoucheva, Alistair Miles

        Size

        Medium (175 hours)

        Difficulty

        Medium

        Technologies

        Python, Machine-learning, Google Cloud Storage

        Identifying Anopheles mosquitoes species with precision is critical for malaria control. The Anopheles gambiae sensu lato (An. gambiae s.l.) complex, the primary malaria vector in sub-Saharan Africa, consists of multiple species, including An. arabiensis, An. coluzzii, and An. gambiae s.s. Each of these species has unique ecological roles and varying susceptibility to vector control strategies, leading to heterogeneity in their contribution to malaria transmission.

        Taxonomic identification of Anopheles mosquitoes is challenging as they are morphologically identical, and genomic data is key to correctly classify individuals. Misclassification can lead to suboptimal interventions and flawed epidemiological insights, underscoring the need for robust, scalable and accessible classification frameworks.

        This project aims to optimise, enhance, and package a cloud-native genomic taxon classifier for Anopheles mosquitoes. The starting point will be to optimise an existing random-forest classifier to improve accuracy and computational efficiency while validating the predictions against expertly curated taxonomic datasets.

        As the current implementation is trained on high-resolution genomic data from the Vector Observatory, which integrates whole-genome sequence data for over 25,000 mosquitoes, a key aspect of the project will be to package the classifier in an accessible manner, ensuring any research group can use this tool.

        Further reading:

        Malaria Genome Vector Observatory: https://www.malariagen.net/vobs
        Article on the distribution of African mosquitoes belonging to the Anopheles gambiae complex: https://www.cell.com/partod/fulltext/S0169-4758(09)01563-X

        ~~~~~~~~~~

        Building cloud-native analytical tools to detect and track outbreaks of insecticide resistance in African malaria mosquitoes

        Mentors

        Alistair Miles, Anastasia Hernandez-Koutoucheva, Chris Clarkson

        Size

        Large (350 hours)

        Difficulty

        Medium

        Technologies

        Python, Statistical Analysis, Google Cloud Storage

        Description

        The Malaria Vector Genome Observatory is an open and collaborative ecosystem that supports researchers and public health authorities to access, analyse and visualise data from Anopheles mosquitoes collected from affected countries. Integrating high-quality whole-genome sequence data from over 25,000 mosquitoes contributed by partners across 30 countries, this resource represents the largest natural genetic variation dataset for any multicellular organism, second only to humans.

        At the core of this resource, is the malariagen_data API - a cloud-native, open-source Python software package that enables scalable population genomics and genomic surveillance by providing robust statistical and visualisation tools designed for rapid and reproducible analysis.

        For this project, we are looking for contributors who have an interest in expanding and enhancing this ecosystem to identify and track new insecticide resistance outbreaks in response to new vector control interventions. A suggested starting point will be to look into methods to improve the detection of genes and variants under recent positive selection, to identify variants associated with insecticide resistance, and to track the spread of resistance variants over space and time. We would also encourage contributors to develop their own ideas for potential improvements and new features, after building an understanding of the capabilities that would have the most impact for researchers working on malaria vector surveillance and control in Africa.

        Further reading:

        Source code: https://github.com/malariagen/malariagen-data-python
        Malaria Vector Genome Observatory: https://www.malariagen.net/vobs
        Training course showcasing data analysis with the malariagen_data API: https://anopheles-genomic-surveillance.github.io/home.html

        ~~~~~~~~~~

        Implementing a user interface to KinFin for interactive exploration of protein clustering data

        Mentors

        Rich Challis & Cibele Sotero-Caio

        Size

        Large (350 hours)

        Difficulty

        Medium

        Technologies

        Javascript (React) & Python

        Analysing how gene families evolve is key to many large scale projects in phylogenetics and genomics. Most eukaryotic species have between 15,000 and 25,000 protein coding genes and toolkits exist to cluster these into protein families based on sequence similarity. KinFin is a command line tool that takes protein clustering derived from variants of the MCL algorithm and facilitates intensive interrogation of protein families across hundreds of species (and many million proteins) for patterns that reveal biological processes. A GSoC 2024 project updated the codebase and built an API layer to deliver an analysis interface to web-available genome browsing or analysis systems such as Ensembl and GenomeHubs. This project will build the functionality to extend the API and add interactive UI components to provide a standalone UI and allow integration into GenomeHubs sites such as MolluscDB. Much of the power of KinFin lies in its innovative visualisation approaches, and development of additional visualisations and analytic outputs will be part of the project.

        KinFin plot of frequencies of protein clusters from 19 species. The peak at a cluster size of ~19 identifies the likely set of one-to-one orthologues in the analysed data.


        Further reading:

        KinFin publication: OrthoFinder publication
        Modified KinFin code at GitHub
        GenomeHubs
        MolluscDB

        ~~~~~~~~~~

        Genome After-Party: a global database of ready-made genome analyses

        Mentors

        Matthieu Muffato and another bioinformatician (TBC)

        Size

        Large (350 hours)

        Difficulty

        Medium

        Technologies

        Nextflow (nf-core), Python/Shell for glue/wrapper scripts. Bioinformatics tools

        The Tree of Life department of the Wellcome Sanger Institute is largely devoted to generating and analysing high-quality reference genomes from biodiversity projects. Our flagship project is Darwin Tree of Life (DToL), for which we have generated more than 1,500 reference genome assemblies. All those assemblies are then released to INSDC without embargo and a short paper, called a Genome Note, is published at Wellcome Open Research. Genome Notes require certain genome analyses, such as quality scores (QV, BUSCO) or plots (Hi-C contact maps, BlobTools). These represent the core of the Genome After-Party, a new public data repository (https://gap.cog.sanger.ac.uk/) for common genome analyses. that we are now expanding with sequence-composition tracks, variant-calls, variant analysis, etc.

        All Genome After-Party data come from a suite of production-grade pipelines written in Nextflow using the nf-core standards, and made public on GitHub https://github.com/sanger-tol. Complete documentation and examples of the pipelines are on the website https://pipelines.tol.sanger.ac.uk/.

        Several pipelines are used in production to generate analysis data for many genomes and we're now looking to expand the range of analyses being performed, with guidance from the researcher community. In this project, we are looking for people interested in contributing to our vision and implementing new analyses in Nextflow. We already have a list of analyses and tools in mind, requested or advised by Faculty partners, on our Project board on GitHub. We're particularly interested in expanding the sequence composition pipeline (e.g. to annotate all sorts of repeat elements) and the variant calling & analysis pipelines.

        Further reading:

        Overview of pipelines: https://pipelines.tol.sanger.ac.uk/genome_after_party
        Project board: https://github.com/orgs/sanger-tol/projects/3
        Nf-core documentation: https://nf-co.re/docs/









       
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/wellcome-sanger-tree-of-life/
    idea_list_url: https://docs.google.com/document/d/1dRHwnHAXlwQbRDstnd0OZTDJYA9cTsl1jG_hOempqII/edit?usp=sharing

  - organization_id: 172
    organization_name: Zendalona
    no_of_ideas: 10
    ideas_content: |
      Project Title: Accessible-Bluff Bot - Enhancing AI Opponents for Inclusive Card Gaming


      What is Accessible-Bluff


      Accessible-Bluff is a web-based card game designed with accessibility in mind, ensuring that all actions and information are conveyed audibly using a screen reader. It mimics a physical card game with real-life experiences by enabling teams to establish private rooms for remote collaboration and gaming.


      How to play the Bluff game?
      Like a regular card game, a group of players join a virtual room and shuffle the cards. The game begins with the first player placing one or more cards by either telling the truth or lying. For instance, if the player places “the king”, he/she can claim it as “a queen”, “a jack”, or “any other card”, or truthfully state it as “a king” itself. Other players can challenge if they suspect deception/cheat. If a player falsely claims “a queen” as “a king” and is challenged, the player receives a penalty, while the challenger earns an extra chance. However, if the challenger is wrong, he/she receives the penalty. Players can choose to “Pass” if they don’t want to participate in the round, but they can still “Raise” a challenge. A round concludes only when all players “Pass”, or someone “Raise” the challenge.  The winner is the player who clears his/her cards first. 


      Project Details
      Project page: https://zendalona.com/accessible-bluff/
      Game URL (Project): bluff.zendalona.com
      Bluff GitHub repository: https://github.com/zendalona/accessible-bluff
      This project is to develop an AI bot for the Accessible-Bluff card game, ensuring it is fully accessible to visually impaired players. The bot should be one of the players. The bot should support multiple difficulty levels, allowing players of different skill levels to enjoy the game. The design should be modular, enabling future improvements and enhancements. The bot should be seamlessly integrated with the existing Accessible-Bluff game environment and its actions must be fully conveyed via screen readers.
      Expected Output
      AI Bot for Accessible-Bluff  
      On the homepage, players can select the number of bots and their difficulty level while creating a game room. Once the game starts, bots will be displayed with names like Bot1, Bot2, etc., alongside human players, according to the user's selection on the game page. 


      A fully functional AI bot capable of playing the Accessible-Bluff card game, mimicking a real human player throughout the game.  
      
      Multiple difficulty levels cater to different player skill levels, including the following. 


      Beginner (Easy Mode) – The AI plays with basic strategies, making   predictable moves and occasionally bluffing. This level helps new players understand   the game mechanics.  
         
      Intermediate (Normal Mode) – The AI uses a mix of strategy and deception, analyzing previous moves to make more competitive decisions. It bluffs more effectively and detects bluffs with moderate accuracy.  


      Advanced (Hard Mode) – The AI employs complex strategies, adaptive learning, and advanced bluff detection. It bluffs unpredictably and adjusts its playstyle based on opponents' behaviour, making it challenging for experienced players.  
            
      2. Accessibility Features
      Seamless integration with screen readers, ensuring all bot actions (bluffing with selected cards and bluff text, challenging opponents' actions) are audibly conveyed.  
      3. Modular Design & Integration
      A flexible and expandable bot architecture for future improvements.  
      Seamless integration with the Accessible-Bluff game environment, preserving existing accessibility and gaming logic.   
      4. Comprehensive Documentation  
      Detailed documentation covering the bot's architecture, algorithms, and usage.


      Skills required/preferred Bot, NodeJs, Javascript,  
      Expected size of the project: 175 hours
      Difficulty: High
      Possible mentors: Nalin Sathyan

      ~~~~~~~~~~





      Project Title: AI-Powered Agent to provide support for Zendalona products
      Project Description:
      Develop an AI-powered Agent that provides information and support related to Zendalona products and assistive technologies for visually impaired individuals. This project aims to enhance the agent’s capabilities by integrating advanced Natural Language Processing (NLP) techniques, improving accessibility features, and expanding its knowledge base to better serve users with visual impairments.
      Project Goals:
      Advanced NLP Integration:
      Implement state-of-the-art NLP models (e.g., BERT, GPT) to improve the AI Agents understanding of user queries.
      Enhance the Agents ability to handle complex, multi-turn conversations and provide contextually relevant responses.
      Accessibility Enhancements:
      Ensure the Agent is compatible with screen readers and other assistive technologies commonly used by visually impaired individuals.
      Implement text-to-speech (TTS) and speech-to-text (STT) functionalities to facilitate seamless communication.
      Knowledge Base Expansion:
      Curate and integrate a comprehensive database of Zendalona, including detailed descriptions, usage instructions, and user reviews.
      Enable the chatbot to provide personalized recommendations based on user preferences and needs.
      User Experience Improvements:
      Conduct user testing with visually impaired individuals to gather feedback and identify areas for improvement.
      An intuitive and user-friendly user experience for all types of queries.
      Expected Outcomes:
      An intelligent and responsive AI Agent capable of understanding and addressing a wider range of user queries.
      Enhanced accessibility features that make the Agent accessible for visually impaired individuals.
      A richer knowledge base that provides users with detailed and accurate information about assistive technologies.
      A user-friendly interface that improves overall satisfaction and engagement.


      Skills required/preferred : AI, NLP, Python
      Expected size of project: 175 hours
      Difficulty: High
      Possible mentors: Sivasailam vellaisamy, Mukundhan

      ~~~~~~~~~~


      





      Project Title: Accessible World-Map-Explorer V2
      Description: World-Map-Explorer is an inclusive and educational mapping tool designed for both visually impaired and sighted users. Powered by OpenStreetMap, it provides a seamless way to explore the world using keyboard navigation, audio feedback, and interactive features. Users can search for places, move through locations using arrow keys, get real-time border alerts, measure distances, and access detailed geographic information. Additional features include an adjustable pointer for exploring surroundings, inbound navigation to limit movement within a selected region, and a road distance calculator. 
      The Application is live at map.zendalona.com 
      User guide - https://map.zendalona.com/src/pages/user-guide/index.html 
      GitHub repository: https://github.com/zendalona/world-map-explorer-v2
      
      Outcome: Migrate the project to Next.js for better performance, implement server-side functionalities, and add the following features. 
      User Login – Log in to save your preferences and create a personalized experience. 
      Search History and Undo/Redo – Access a history of your previous actions to revisit locations easily. 
      Dynamic Routing – Navigate to places directly using external URLs when applicable 
      Bookmarks – Add and manage bookmarks, saving them in the database for future reference. 
      Settings Management – Save and manage your preferences for a customized experience: 
      Profile – Edit your email and personal data.  
      Key binding – Customize keyboard shortcuts for efficient navigation.  
      Bookmark Management – Edit and organize your bookmarks.  
      Other Settings – Adjust cursor pointer size, angle, and related features. 
      Path Navigation – Navigate through roads, railways, rivers, and other paths using the cursor to inform the user about the places passing through. 
      Water Sound Alerts – Receive auditory cues when cursor enters water bodies for enhanced interaction. 
      


      Skills required/preferred : JavaScript, TypeScript, Next.js, Leaflet.js, and PostgreSQL.
      Expected size of project: 175 hours
      Difficulty: High
      Possible mentors: K Sathyaseelan, Nalin Sathyan

















      ~~~~~~~~~~

      Project Title: Accessible TuxType and TuxMath Enhancement
      Description
      During Google Summer of Code (GSoC) 2013, we made TuxType and TuxMath accessible for visually impaired users. However, the current official versions lack these accessibility features. It's crucial to release a new official version of TuxType and TuxMath on all platforms.


      TuxType


      The keyboard is the primary input device for visually impaired users, making keyboard practice essential for effective computer use.


      TuxType is an educational typing game designed to improve users' typing skills in an engaging way. It consists of multiple game modes: 


      Fish Cascade: Tux must eat fish while avoiding those with letters by typing them to make them disappear. 


      Comet Zap: Tux defends cities from falling comets by typing the letters on them, inspired by the classic math game "Tux, of Math Command." 


      Lessons and Phrase Typing: Players practice typing through structured lessons and phrases, tracking accuracy and speed. Future improvements aim to make it easier for educators to customize content. 


      GitHub Repository:  https://github.com/tux4kids/tuxtype


      TuxMath 
      TuxMath transforms math practice into an exciting game where players help Tux defend planets from asteroids by solving arithmetic problems. It fosters quick thinking, hand-eye coordination, and strategic planning while reinforcing mathematical skills. 


      GitHub Repository: https://github.com/tux4kids/tuxmath/


      t4common library
      Tuxmath and Tuxtype are coded in C and utilize the SDL library for graphics. They share the t4common library. Accessibility features can be activated via a new menu or keyboard shortcuts.


      GitHub Repository: https://github.com/tux4kids/t4kcommon




      Expected Output: 
      Improve documentation around the build
      Fix Mac build for m-X chips
      Check and update dependencies, this will include updating the SDL library to version 2
      Expose accessibility features in Tuxmath and Tuxtype
      Fix existing bugs that include supporting it over other Linux distros like Fedora, Arch Linux
      Make an official release for GNU/Linux
      Make an official release for Microsoft Windows
      Make an official release for MacOS
      Prepare and release official packages or installers for all platforms.
      Releasing snap packages for the Ubuntu store
      Add Ukrainian translation
      Add fractions question support: There is an issue around it: https://github.com/tux4kids/tuxmath/issues/38


      Release TuxType and TuxMath with accessibility features for visually impaired users on all platforms without compromising the comfort of regular users.


      Skills preferred: C, SDL
      Expected time of project: 175 hours 
      Difficulty: Intermediate 
      Possible mentors: Deepak Agarwal, Mukundhan Annamalai














      ~~~~~~~~~~

      Project Title: Liblouis table editor - Enhancement
      
      Description: “The Liblouis software suite provides an open-source braille translator, back-translator, and formatter for many languages and braille codes. It is a set of libraries designed for use in several applications, both free and commercial.”   - https://liblouis.io/ 
      
      Numerous software applications like NVDA, JAWS, BrlTTY, TalkBack, make use of liblouis. 
      The total global user count is in millions. Many projects developed in Zendalona utilize liblouis, including IBus-Braille, Sharada-Braille-Writer, Braille-Translator-GUI, and the Braille-Translator Web version.  


      Outcome: Creating Liblouis translation tables is a laborious and time-consuming task. Both software developers and end users at the Braille printing press require a more convenient method for editing the liblouis table. Furthermore, in numerous languages, the editing process involves inputting Unicode code points instead of directly writing the letters, adding an extra layer of complexity to the table editing process. 
      
      Liblouis manual: https://liblouis.io/documentation/liblouis.html#How-to-Write-Translation-Tables 
      
      As part GSoC 2024, We have created a free and open-source Liblouis table editor compatible with GNU/Linux, Microsoft Windows, and macOS, fulfilling the following criteria: 
      Display characters as they are alongside their Unicode code points. 
      Provide a drop-down list for selecting opcodes. 
      Enable the insertion of operands through entries with validity checks. 
      Include an option to test forward and back-translation on the fly. 
      Allow users to view and modify the Unicode character equivalent corresponding to the written Unicode code point. 
      Indicators to ensure the user is aware of duplicate entries. 
      Should be accessible to visually challenged people 

      GitHub repository: https://github.com/zendalona/liblouis-table-editor



      Here is the list of tasks we need to complete to release the project

      Implement the Forward/Backward table testing feature 
      Fix bugs related to the toolbar
      Fix bugs
      Showcase the project internally within the organization
      Do internal testing and fix bugs
      Create a package for GNU/Linux
      Develop an installer for Windows
      Present the project to potential users
      Facilitate testing with end users
      Perform accessibility testing with blind users
      Fix bugs and release the final version




      Skills required/preferred Python, Qt, Liblouis.
      Expected size of project: 175 hours
      Difficulty: Intermediate
      Possible mentors: Samuel Thibault, Nalin Sathyan








      ~~~~~~~~~~


      Project Title: Enhancing Accessibility in the Ubuntu Installer for Visually Impaired Users to Support Accessible-Coconut 24.04
      Description:
      The Ubuntu installer is a critical tool for users to set up their systems, but it currently lacks sufficient accessibility features for visually impaired users. This issue directly impacts projects like Accessible-Coconut, a specialized Linux distribution developed by Zendalona over the past decade. Zendalona has been releasing Accessible-Coconut every two years, with the upcoming Accessible-Coconut 24.04 planned to be based on Ubuntu MATE 24.04. Improving the accessibility of the Ubuntu installer is essential to ensure a smooth and inclusive experience for users of Accessible-Coconut.
      This project aims to address the accessibility shortcomings of the Ubuntu installer(Ubuntu Desktop Provision) by improving compatibility with screen readers like Orca, enhancing keyboard navigation, and providing clear audio feedback. These improvements will not only benefit Ubuntu users but also directly support the efforts of Zendalona, the developer behind Accessible-Coconut, in releasing a fully accessible 24.04 version.
      Ubuntu-Desktop-Provision GitHub repository: https://github.com/canonical/ubuntu-desktop-provision
      Objectives:
      Improve Orca Screen Reader Integration:
      Investigate and fix issues with Orca compatibility in the Ubuntu installer, ensuring that all installer components are properly labelled and navigable using the screen reader.
      Collaborate with the Orca development team to address any upstream issues affecting the installer.
      Enhance Keyboard Navigation:
      Ensure that all installer elements can be accessed and interacted with using only the keyboard, as many visually impaired users rely on keyboard navigation instead of a mouse.
      Provide Clear Audio Feedback:
      Implement audio cues and feedback for critical actions (e.g., selecting a disk, confirming installation) to guide visually impaired users through the installation process.
      Simplify and Streamline the User Interface:
      Work with the Ubuntu design team to simplify the installer interface, making it easier for screen readers to interpret and for users to understand.
      Support Accessible-Coconut 24.04:
      Collaborate with Zendalona, who has been releasing Accessible-Coconut every two years for the past decade, to ensure that the improvements align with the needs of Accessible-Coconut users.
      Test the installer changes in the context of Ubuntu MATE 24.04, which is the base for Accessible-Coconut 24.04.
      Documentation and Testing:
      Create detailed documentation for visually impaired users on how to use the improved installer.
      Conduct usability testing with visually impaired users, including those from the Accessible-Coconut community, to gather feedback and ensure the changes meet their needs.
      Expected Outcomes:
      A more accessible Ubuntu installer that provides a seamless experience for visually impaired users, including those using Accessible-Coconut.
      Improved compatibility with Orca and other screen readers.
      Clearer navigation and feedback mechanisms for users relying on assistive technologies.
      Comprehensive documentation and testing reports to guide future accessibility improvements.
      Direct support for Zendalona's efforts to release Accessible-Coconut 24.04 based on Ubuntu MATE 24.04, continuing a decade-long tradition of providing accessible Linux solutions.
      Skills Required:
      Familiarity with Linux systems and Ubuntu.
      Experience with accessibility tools like Orca and knowledge of accessibility standards (e.g., WCAG).
      Proficiency in Python (used in the Ubuntu desktop provisioner) and GTK (for UI improvements).
      Strong communication skills to collaborate with the Ubuntu community, Zendalona, and visually impaired users.
      Related Links:
      Ubuntu Discourse Thread on Installer Accessibility
      Launchpad Bug Report on Accessibility Issues
      GitHub Issue on Installer Accessibility
      Ubuntu MATE Community Discussion on Orca Improvements
      Impact:
      This project will significantly improve the inclusivity of the Ubuntu installer, making it easier for visually impaired users to install and use Ubuntu. It will also directly support Zendalona's efforts to release Accessible-Coconut 24.04, ensuring that the distribution remains a leading choice for visually impaired users. Additionally, the improvements will set a precedent for future accessibility enhancements across Ubuntu and other Linux distributions. By supporting Zendalona's decade-long commitment to accessibility, this project will contribute to a more inclusive open-source ecosystem.
      Skills preferred: Flutter, Dart, Python
      Expected time of project: 175 hours 
      Difficulty: High 
      Possible mentors: K Sathyaseelan, Akshay S Dinesh


      ~~~~~~~~~~




      Project Title: Linux-Intelligence-OCR-Solution(LIOS) - Enhancement 
      
      Description: LIOS is a free and open-source software designed for converting printed text into digital format using scanners or cameras. It is also capable of generating text from scanned images sourced from various formats, including PDFs, images, image folders, or screenshots. The program ensures complete accessibility for visually impaired users through a graphical user interface (GUI). Leveraging OCR engines like Tesseract and Cuneiform, LIOS facilitates the conversion of images to text. 
      
      Significantly, LIOS is included in the Debian repository and distinguishes itself as the exclusively accessible OCR user interface within the GNU/Linux environment. Furthermore, it has been developed inclusively, allowing many sighted individuals to also benefit from its features. 
      
      Github page: https://github.com/zendalona/lios 
      Debian repository: https://packages.debian.org/bookworm/lios


      Outcome:  We need the following  
      Make the UI simpler more easier by moving/removing many UI components  
      Make the UI more readable for Low vision by providing easy switchable themes 
      Make items in preferences more reasonably categorized 
      Fix scanner driver issues  
      Refine the code  
      Fix all reported bugs 
      Enhance detection of Tesseract data paths
      Make dialog boxes foolproof
      Release the new version as RPM package  
      
      
      Skills required/preferred Python, Gtk, Cairo 
      Expected size of project: 175 hours
      Difficulty: Intermediate
      Possible mentors: Samuel Thibault, Nalin Sathyan

      ~~~~~~~~~~


      Project Title: Accessible World-Map-Explorer Android version - zMap
      Description: Discover the world with world map explorer, a web app made with inclusivity in mind. Navigate through keyboard or via search and explore the world with real time voice over. Search for countries, states, places, rivers or even historic monuments. Control the exploration area to stay within a region or make sure you don’t get lost in the map with real time border crossing alert. Explore the surroundings with the adjustable pointer by changing its distance and angle. Start your adventure with World Map Explorer today and navigate the world with ease and confidence!  
      The web version is currently availablemap.zendalona.com	


      The Application is live at map.zendalona.com 
      User guide - https://map.zendalona.com/src/pages/user-guide/index.html 
      GitHub repository (Web version): https://github.com/zendalona/world-map-explorer-v2
      
      Expected Outcome:
      The android version can be a webview which should achieve the same experience as the web version by using gestures instead of keys of the keyboard. The features of the app are: 
      Gesture-Assisted navigation: The user should be able to use the app by using the gestures and no gesture should overlap with other gestures. 
      Capturing User Location: User should be able to start navigation from a place near user’s actual location. 
      Navigation Using Search: User should be able to	
      discover and navigate to any places, rivers and historic monuments by using the search feature. 
      Boundary setting for search and navigation: The user should be able to select to select a place to learn more about it and restrict the navigation within it’s boundaries. 
      Adjustable pointer: The user should be able to customize the distance and angle of a pointer to explore nearby locations with precision. 
      Distance to Borders: The user should instantly know the distance to the borders in the north, south, east and west direction. 
      Zoom in: The user should be able to zoom in zoom out. 
      Distance Finder: The user should be able to find the distance between any two places with ease. 
      Map layout options: The user should be able to switch between political and geographical views. 
      Altitude awareness: The user should instantly know the altitude of the current place. 
      Managing notifications and calls: Managing many activities that can occur while using the apps such as notifications, calls etc. 


      Skills preferred: Android, Java 
      Expected time of project: 350 hours 
      Difficulty: Intermediate 
      Possible mentors: Nalin Sathyan, Mukundhan Annamalai  


      ~~~~~~~~~~
      

















      Project Title: Maths-Tutor QT Version and Enhancement 
      
      Description: Accessible Maths-Tutor is a software tool that combines the enjoyment of gaming with the essential skill of mathematics. Imagine having a friendly mentor right on your computer screen, guiding you through math problems in a fun and interactive way. This is precisely what Maths Tutor offers a unique and engaging learning experience. 
      
      Information about the previous version(1): https://zendalona.com/accessible-maths-tutor/ 


      In the previous year's GSoC, we migrated the project from GTK to Qt to address accessibility issues on Windows and macOS. 


      Repository link: https://github.com/zendalona/maths-tutor-v2/tree/development 


      Here is the list of tasks to be completed:


      Bugs in Maths-Tutor V2: 
      Upload option not implemented in Home 
      Settings Option not implemented 
      Even though we answered correctly, the animation for the wrong answer appears and announces the wrong answer and moves to the next question. 
      In Subject Time the Questions are not fully visible 
      Only for the first right answer the clap audio is heard but for the second right answer  
      Note overrides over the subject menu 
      The Bell Ringing option was not implemented 
      The difficulty level not working as intended same questions are repeated in every level 
      
      
      Things Remaining to be implemented: 
      Provide Speech Sound using Human Voice instead of Text-To-Speech Engine  
      Intermediate score announcement for Appreciation 
      Provide Answer clues in situations like the User taking too much time  
      User Interface for creating Question File  
      Clock Tick Sound for indicating Time consumption  
      Introduce the "Assessment Mode" Checkbox to Enable/Disable exposing Score, Clock, etc.  
      User Guide  
      Themes for Low Vision - High Contrast, Low Contrast  
      Lessen the Lock to make the User finish for the Next Lesson  
      Increase sound playing Speed to Speech Rate  
      Profile Preferences for Each Kid and Use their Name While Appreciating  
      Pair Question in Percentage  
      Dataset - Add number typing of Lakhs / Millions  
      Dataset for teaching multiple ways to make the same Digit  
      Fix announcement of Lakhs / Millions  




      


      
      Skills required/preferred: Python, QT
      Expected size of project: 175 hours
      Difficulty: Intermediate
      Possible mentors: Sai Saravan, K Sathyaseelan
      
      












      ~~~~~~~~~~
      Project Title: Maths-Mantra Enhancement
      
      Description: In GSoC 2024, we developed a comprehensive smartphone application incorporating all the features of the Math-Tutor computer version. Additionally, we integrated the functionalities outlined in the 'What We Need' section. The app utilizes various input methods, including touch screen, accelerometer, microphone, GPS, clock, and magnetometer, to create an immersive and interactive learning experience. To enhance user engagement and effectiveness, we implemented feedback mechanisms such as stereo sound, vibrations, and other sensory cues.


      This year, we need to fix existing bugs and add the remaining features to complete the project.


      GithHub repository: https://github.com/zendalona/Math-Mantra 


      Outcome: Include the following concepts in the application: 
      
      1. Utilize phone sensors and stereo sound to teach cardinal directions (North, East, West, South) through interactive methods. 
      2. Integrate lessons on Angle X, Y, Z, and incorporate simple distance/height calculations using trigonometric functions. 
      3. Enable user engagement by allowing kids to input answers through sound or clapping using the device's microphone. 
      4. Leverage GPS functionality to teach distance-related concepts, providing a real-world context for understanding spatial relationships. 
      5. Implement multi-touch functionality on the screen to teach number concepts and facilitate the drawing of various shapes such as triangles, rectangles, rounds, ovals, etc. 




      Skills required/preferred: Android, Java, UI development
      Expected size of project: 350 hours
      Difficulty: Intermediate
      Possible mentors: Nalin Sathyan, Mukundhan
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/zendalona/
    idea_list_url: https://docs.google.com/document/d/1HshVGE-oQq_xx09zG2LfqfVYWRhyrASteXzabCV9eIQ/edit?usp=sharing

  - organization_id: 173
    organization_name: Zulip
    no_of_ideas: 17
    ideas_content: |
      Full stack and web frontend focused projects
      Code: github.com/zulip/zulip – Python, Django, TypeScript/JavaScript, and CSS.
      Cluster of priority features. Implement a cluster of new full stack features for Zulip. The high priority label documents hundreds of issues that we’ve identified as important to the project. A great project can be 3-5 significant features around a theme (often, but not necessarily, an area label); the goal will be to implement and get fully merged a cluster of features with a meaningful impact on the project. Zulip has a lot of half-finished PRs, so some features might be completed by reading, understanding, rebasing, and reviving an existing pull request. 175 or 350 hours; difficulty will vary. Skills required: Depends on the features; Tim Abbott will help you select an appropriate cluster once we’ve gotten to know you and your strengths through your getting involved in the project.
      Experts: Tim Abbott and various others depending on project area

      ~~~~~~~~~~
      Complete some unfinished projects. This is a variant of the previous project idea category, but focused on projects with significant existing work to start from and polish, rather than projects that have not been seriously attempted previously.
      We maintain a completion candidate label for pull requests where a previous contributor (sometimes via GSoC!) did significant work towards something valuable, and there’s significant feedback from maintainers, but the project was never finished, and requires significant further effort from a new contributor in order to progress. One of our goals for this summer’s GSoC is to complete many of these issues. Start by picking something that’s interesting to you, and you feel you have the skills required to complete. Read the code and the feedback, and then create your own PR for the issue. See the guide on continuing unfinished work for details. 175 or 350 hours; difficulty will vary. Skills required: Varies with project; a common skill will be good reading comprehension and organization/communication skills, to walk maintainers through how you resolved problems, addressed any pending feedback on the previous PR, and your understanding of the outstanding questions for a given project. Taking the time to get really good at resolving merge conflicts is likely to be valuable here as well.

      Experts: Tim Abbott and various others depending on project area

      ~~~~~~~~~~
      Migrate Zulip’s direct message recipient data structures to a new model that enables personal settings associated with a direct message conversation, and add several settings (see the linked issues) enabled by that infrastructure work. 175 or 350 hours; fairly difficult. Skills required: This project will be deep Python 3/PostgreSQL work. Concretely, challenging parts of this project include thinking about races and database transactions, writing database migrations intended to be run live at scale, complex internal refactors, and carefully verifying the indexes used by migrated database queries.
      Experts: Tim Abbott, Mateusz Mandera, Prakhar Pratyush

      ~~~~~~~~~~
      Implement channel groups that simplify administration of collections of related channels in Zulip. Contributors interested in working on this should start with studying Zulip’s existing channel and group-based permissions system, both UX and implementation, and doing some starter issues in the settings area. 175 or 350 hours; medium difficulty. Skills required: Ability to read and understand a lot of code, as well web frontend work in TypeScript/HTML/CSS, with a bit of Python server programming. We’ll be particularly interested in the ability to explain and reason about complex logic and follow the existing UI patterns for group settings and channel settings.
      Experts: Sahil Batra, Shubham Padia
      ~~~~~~~~~~
      Add the core infrastructure for topic-based permissions and settings like pinned topics and read-only topics, and then build some of those settings. This project will be a mixture of Python 3/PostgreSQL work, including thinking about database transactions and races, writing database migrations intended to be run live at scale, and complex logic to handle moving messages correctly in the context of these settings, including significant changes to the Zulip API and API documentation. 175 or 350 hours; fairly difficult. Skills required: A high level of fluency with writing readable Python 3 and thinking about corner cases.
      Experts: Tim Abbott, Prakhar Pratyush

      ~~~~~~~~~~
      Zulip’s REST API documentation, which is an important resource for any organization integrating with Zulip, as well as the developers of our API clients. Zulip has a nice framework for writing API documentation built by past GSoC students based on the OpenAPI standard with built-in automated tests of the data both the Python and curl examples. However, the documentation isn’t yet what we’re hoping for: there are a few dozen endpoints that are missing, several of which are quite important, the visual design isn’t perfect (especially for, e.g., GET /events), many templates could be deleted with a bit of framework effort, etc. See the API docs area label for some specific projects in the area; and git grep pending_endpoints to find the list of endpoints that need documentation and their priorities. Our goal for the summer is for 1-2 students to resolve all open issues related to the REST API documentation. 175 or 350 hours; difficulty easy or medium. Skills required: Python programming. Expertise with reading documentation and English writing are valuable, and product thinking about the experience of using third-party APIs is very helpful.
      Expert: Lauryn Menard

      ~~~~~~~~~~
      Improve the UI and visual design of the Zulip web app. We are working on a major redesign for the core surfaces of the Zulip web app – see the redesign label for specced out work, with more to come. We’re particularly excited about students who are interested in making our CSS clean and readable as part of working on the UI. 175 or 350 hours; medium to difficult. Skills required: Design, HTML and CSS skills; most important is the ability to carefully verify that one’s changes are correct and will not break other parts of the app; design changes are very rewarding since they are highly user-facing, but that also means there is a higher bar for correctness and reviewability for one’s work. A great application would include PRs making small, clean improvements to the Zulip UI (whether logged-in or logged-out pages).
      Experts: Aman Agrawal, Karl Stolley, Alya Abbott

      ~~~~~~~~~~
      Improve type safety of node tests. Rework Zulip’s automated node tests to use objects that consistently have the correct type. Currently, many tests use fake message, user, or channel objects with only a handful of fields relevant to the test. We’ve been working towards web/tests/lib/example_*. A good starter project would be to try to convert a small test module that currently does not use the make_user type functions to do so. The main TypeScript migration thread is useful background reading, and #frontend channel is a good place to start new topics while working on this project. 175 or 350 hours; medium difficulty. Skills required: TypeScript fluency, and the discipline to write easily reviewed pull requests that often will include a series of changes to clean up an individual test while you’re working on it.
      Experts: Afeefuddin, Lalit

      ~~~~~~~~~~
      Replace hundreds of dict[str, Any] types with modern dataclasses. While functionally efficient, dataclasses are more readable, safe against typos, and have nice support for optimizing them further using __slots__. A lot of Zulip server code was written before dataclasses existed, and while a lot has been converted naturally as part of other projects, we’d like to make a focused push to replace the remaining ones. This project will involve making dozens of small commits and PRs, each a clean refactor converting a single type. Use this conversation for discussion and coordination. Skills required. Solid understanding of statically typed Python, and the discipline to learn to write refactoring commits that are easy to integrate, following our standard guidelines, because they convincingly don’t change any product behavior while improving type-safety.
      Experts: Tim Abbott, Anders Kaseorg

      ~~~~~~~~~~
      Optimize performance and scalability, either for the web frontend or the server. Zulip is already one of the faster web apps out there, but we have a number of ideas for how to make it substantially faster yet. This is likely a particularly challenging project to do well, since there are a lot of subtle interactions to understand. 175 or 350 hours; difficult. Skill recommended: Strong debugging, communication, and code reading skills are most important here. JavaScript experience; some Python/Django experience, some skill with CSS, ideally experience using the Chrome Performance profiling tools (but you can pick this up as you go) can be useful depending on what profiling shows. Our backend scalability design doc and the performance label may be helpful reading for the backend part of this.
      Experts: Tim Abbott
      ~~~~~~~~~~
      Fill in gaps, fix bugs, and improve the framework for Zulip’s library of native integrations. We have about 120 native integrations, but there are a number of others we would like to add. Also, several extensions to the framework that would dramatically improve the user experience of using integrations, e.g., being able to do callbacks to third-party services like Stripe to display more user-friendly notifications. The the integrations label on GitHub lists some of the priorities here (many of which are great preparatory projects). 175 or 350 hours; medium difficulty with various possible difficult extensions. Skills required: Strong Python experience, will to install and do careful manual testing of third-party products. Fluent English, usability sense and/or technical writing skills are all pluses.
      Experts: Niloth, Lauryn Menard
      ~~~~~~~~~~
      Make Zulip integrations easier for nontechnical users to set up. This includes adding a backend permissions system for managing bot permissions (and implementing the enforcement logic), adding an OAuth system for presenting those controls to users, as well as making the /integrations page UI have buttons to create a bot, rather than sending users to the administration page. 175 or 350 hours; easy to difficult depending on scope. Skills recommended: Strong Python/Django; JavaScript, CSS, and design sense helpful. Understanding of implementing OAuth providers, e.g., having built a prototype with the Django OAuth toolkit would be great to demonstrate as part of an application. The Zulip integration writing guide and integration documentation are useful materials for learning about how things currently work, and the integrations label on GitHub has a bunch of good starter issues to demonstrate your skills if you’re interested in this area.
      Experts: Niloth, Lauryn Menard

      ~~~~~~~~~~
      Work on Zulip’s development and testing infrastructure. Zulip is a project that takes great pride in building great tools for development, but there’s always more to do to make the experience delightful. Significantly, about 10% of Zulip’s open issues are ideas for how to improve the project’s contributor experience, and are in these four labels for tooling improvements.
      This is a somewhat unusual project, in that it would likely consist of dozens of small improvements to the overall codebase, but this sort of work has a huge impact on the experience of other Zulip developers and thus the community as a whole (project leader Tim Abbott spends more time on the development experience than any other single area). 175 or 350 hours; difficult. Skills required: Python, some DevOps, and a passion for checking your work carefully. A strong applicant for this will have completed several projects in these areas.
      Expert: Tim Abbott

      ~~~~~~~~~~
      Terminal app
      Code: Zulip Terminal
      Experts: Neil Pilgrim, Aman Agrawal
      
      Work on Zulip Terminal, the official terminal client for Zulip. zulip-terminal is out in beta, but there’s still a lot to do for it to approach parity with the web app. We would be happy to accept multiple strong students to work on this project. 175 or 350 hours; medium difficulty. Skills required: Python 3 development skills, good communication and project management skills, good at reading code and testing.
      
      ~~~~~~~~~~
      Desktop app
      Code: Our cross-platform desktop app written in JavaScript on Electron.
      Expert: Anders Kaseorg
      Contribute to our Electron-based desktop client application. There’s plenty of feature/UI work to do, but focus areas for us include things to (1) improve the release process for the app, using automated testing, TypeScript, etc., and (2) polishing the UI. Browse the open issues and get involved! 175 or 350 hours. This is a difficult project because it is important user-facing code without good automated testing, so the bar for writing high quality, reviewable PRs that convince others your work is correct is high. Skills required: JavaScript, Electron; you can learn Electron as part of your application.
      
      ~~~~~~~~~~
      Prototype a next generation Zulip desktop app implemented using the Tauri Rust-based framework. Tauri is a promising new project that we believe is likely a better technical direction for client applications than Electron for desktop apps, for security and resource consumption reasons. The goal of this project would be to build a working prototype to evaluate to what extent Tauri is a viable platform for us to migrate the Zulip desktop app to. 350 hours only; difficult. Skills required: Ability to learn quickly. Experience with Rust and secure software design may be helpful.
      Expert: Anders Kaseorg

      ~~~~~~~~~~
      Mobile app
      Code: The next-generation Zulip mobile app, written with Flutter (now in beta)
      Experts: Greg Price, Chris Bobbe, Zixuan James Li
      Work on the upcoming Flutter-based Zulip client. Zulip has a freshly-written new mobile app built on Flutter, which we’re nearing the point of rolling out to replace the legacy React Native-based app. We’ll be using this foundation to build much-anticipated features that the Zulip mobile apps have never had before, as well as some that the legacy app had but were skipped for the initial rollout.
      This project will involve building features for the Flutter app, including code for UI, data structures, and interacting with the Zulip server and the Android and/or iOS platforms. For a sense of the features we’re working on, see our project board for the new app; the tasks we’ll be working on during GSoC will come mostly from the [“M6: Post-launch” milestone][flutter-milestone-post-launch]. For some features, we may find ourselves contributing changes upstream to the Flutter project itself. 175 or 350 hours; difficult.
      Skills required: Ability to learn quickly, check your work carefully, and communicate clearly and accurately. The code for this project will be written primarily in Dart atop Flutter; previous experience may be helpful, but you can learn both during the contributions leading up to your application. Previous experience with Android or iOS may also be helpful but is not necessary.
      Previous
      Next
      © Copyright 2012–2015 Dropbox, Inc., 2015–2021 Kandra Labs, Inc., and contributors.
      Built with Sphinx using a theme provided by Read the Docs.
      latest
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/zulip/
    idea_list_url: https://zulip.readthedocs.io/en/latest/outreach/gsoc.html

  - organization_id: 174
    organization_name: cBioPortal for Cancer Genomics
    no_of_ideas: 10
    ideas_content: |
      
      Add in Chromoscope component for Strctural Variants visualization
      cBioPortal
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Java
      Javascript
      Size: Large (350h)
      Size: Medium (175h)


      Background
      cBioPortal:
      The cBioPortal for Cancer Genomics is an open-access, open-source resource for interactive exploration of multidimensional cancer genomics data sets. The goal of cBioPortal is to significantly lower the barriers between complex genomic data and cancer researchers by providing rapid, intuitive, and high-quality access to molecular profiles and clinical attributes from large-scale cancer genomics projects, and therefore to empower researchers to translate these rich data sets into biologic insights and clinical applications.
      cBioPortal's Strctural Variants tab:
      In the cBioPortal results view page, we have a Structural Variants tab displaying all strcutural variants regarding queried genes in selected study (see example here). This helps cancer researchers dive deep into detailed strctural variants information on every sample in this study cohort.
      Image
      Chromoscope
      The Chromoscope is an interactive multiscale visualization for structural variation in human genomes. It enables a user to analyze structural variants at multiple scales, using four main views. Each view uses different visual representations that can facilitate the interpretation for a given level of scale. All views in Chromoscope are interactive, allowing a user to explore data effectively.
      Image

      Goal
      Implement backend logic to transform cBioPortal's structural variants data into Chromoscope's data format
      Integrate Chromoscope as a React component into the Structural Variants tab
      To have a sense of what it looks like, we have a patient view page hosting Chromoscope on external server here.

      Approach
      For data format transformation:

      Get familiar with cBioPortal backend codebase
      Compare cBioPortal data format with Chromoscope's, find the mapping relationships between them
      Implement backend transformation solutions and verify the format is correct
      Up to this point can be taken as a medium project.

      For Chromoscope component integration:

      Get familiar with cBioPortal frontend codebase
      Sketch out a frontend design balancing functionality and visual appearace
      Integreat React version of Chromoscope into our Structural Variants tab
      Everything above as a whole can be taken as a large project.

      Needed skills
      Backend: Java, Spring Boot, SQL. Frontend: Typescript, React
      Willingness and ability to gather relavant information (search, docs, etc) and attention to details.
      Maybe some starting point
      Help on some of our backend and frontend issues to demonstrate (show off :0) your understanding of our codebase and your programming skills
      Some hints to think of and can be included in your proposal, among other things:
      Where to find data format specifications?
      How to return transformed results (and communicate to the frontend)?
      The table is displaying multiple samples but can Chromoscope summarize them? Any examples?
      Possible mentors
      Ryan (@fuzhaoyuan)
      
      ~~~~~~~~~~
      Create an automated metadata harmonization/curation tool
      cBioPortal
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Python
      Size: Large (350h)

      Background:
      Though many omics data repositories host large volumes of datasets from diverse studies, cross-study analysis within these repositories is still somewhat limited due to the heterogeneity in their metadata structures. This lack of metadata harmonization especially impedes the application and development of machine learning tools around high-throughput biological data, which is in high demand due to the complexity and high dimensionality of multi-omics datasets. To facilitate comparable analysis across data sources through machine learning, we initiated OmicsMLRepo projects harmonizing metadata from diverse omics data repositories. Under this project, we manually reviewed metadata schema, consolidated similar or identical information spread across schema, and incorporated ontologies where possible. One of our target data repositories is cBioPortal and we have harmonized cBioPortal’s key clinical metadata across the whole data repository, not just at the study level, and incorporated ontology terms to improve the AI/ML-readiness of the cBioPortal data.

      We performed a manual inspection of clinical metadata from 375 studies in cBioPortal (available on 5/13/2023) and harmonized major attributes, such as treatment, demographic information (e.g., age, sex, etc.), and disease. For example, 24 different values (e.g., RADIO_THERAPY, Rad, XRT, etc.) categorized as ‘treatment_type’ were harmonized into a single ontology term, “Radiation Therapy” (NCIT:C15313). While the comparability of the 375 datasets has been improved a lot, cBioPortal is continuously growing and we want to harmonize/digest new data to follow the data dictionary established under the OmicsMLRepo project. To reduce this maintenance effort, we would like to create an automated data harmonization tool.

      The main approach we are currently considering is using semantic similarity. Understanding the meaning of a set of terms is often not straightforward because words might be different but meanings might be the same (e.g., leukemia and blood cancer). “Semantic similarity search” is searching by meaning rather than by word through “encoding”. Encoding is a way of transforming words or sentences into vectors of numbers, such that the points in N-dimensional space (usually 700~2,000), where points near each other have similar meanings. We want to encode both curated terms (from our data dictionary) and uncurated terms (from new incoming data), compare them, and map uncurated terms into curated terms.

      Goal:

      Create an automated data harmonization/digestion tool based on semantic similarity search.
      Create an interactive dashboard showing (and potentially allowing edits on) the automated harmonization results.
      Approach:

      We will use sentence transformers, a type of natural language processing (NLP) model designed specifically for transforming sentences or text snippets into fixed-dimensional vectors to capture the semantic similarity (e.g., txt2onto).
      Commonly used architectures for sentence transformers include BERT (Bidirectional Encoder Representations from Transformers), RoBERTa (Robustly optimized BERT approach), and DistilBERT, among others. Pre-trained transformer models can be fine-tuned on specific tasks or datasets to create sentence embeddings tailored to a particular application.
      Semantic similarity search can be done at two stages - column/attribute names and actual values for a given column/attribute.
      Need skills:
      Python
      R

      Possible mentors:
      Sehyun Oh (@shbrief), Sean Davis (@seandavi)

      If you are interested:
      Anyone interested in this project, please try the EDA below and email your EDA work to Sehyun.Oh@sph.cuny.edu. Looking forward to hearing your idea. Thanks!

      [Required] How can you harmonize new_meta to follow the curated_meta schema with minimum manual curation? You can sketch the overall process or select a specific attribute to demonstrate your idea. (metadata_samples.zip)
      [Optional] Design the curator supporting tool that shows which attribute a new value belongs to.
      [Optional] automated_metadata_curation.ipynb (curated_bodysite.csv)
            

      ~~~~~~~~~~
      Streamline cBioPortal Docker Compose Initialization Setup
      cBioPortal
      devops
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Size: Medium (175h)

      Background:

      cBioPortal: cBioPortal is an open-source platform for cancer genomics data analysis and visualization. It provides a centralized resource for exploring and analyzing large-scale cancer genomic data sets, including genomic alterations, gene expression, and clinical information. The platform integrates data from multiple sources, including The Cancer Genome Atlas (TCGA) and the International Cancer Genome Consortium (ICGC), and makes it available through a web interface for researchers, clinicians, and the general public. Please refer to the cBioPortal home page for an overview.
      Docker Compose: We also provide a Docker Compose Setup to allow users to spin up their own local instances of cBioPortal. This approach involves a lot of bash scripts that need to be run as part of the initialization setup, leading to incompatibility issues and silent errors when these scripts are run on varying operating systems.
      Goal:

      Streamline the cBioPortal docker compose initialization setup by ensuring consistency across operating systems and eliminating silent errors.
      Approach:

      Detect points of failure in the init scripts and eliminate them. Dockerize the init scripts to eliminate dependency on the operating system.
      Ensure the changes are backwards compatible.
      Test changes with other scripts in cbioportal-test repo and localdb tests
      Need skills:
      Familiarity with the command line, bash, docker/docker compose.

      Possible mentors:
      @zainasir


      ~~~~~~~~~~
    
      Show Variant Allele Frequency on the Plots Tab and OncoPrint
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Javascript
      Size: Large (350h)
      Size: Medium (175h)

      Background:

      The cBioPortal is an open-access, open-source resource for interactive exploration of multidimensional cancer genomics data sets, which are collected from a multitude of sources such as published research papers, publicly available data repositories, and private data sets. Please refer to the cBioPortal home page for an overview.

      The cBioPortal can show mutations in a cohort of patients on various pages, but in most places it only shows the mutation type (missense, truncating, etc). Another attribute of a mutation is the "variant allele frequency (VAF)", in how many reads of sequenced DNA a mutation occurs in all of the sequenced DNA at that position in the genome.

      Plots Tab
      One can currently plot e.g. the cancer type vs the number of mutations in a sample (see here):

      Image

      It is, however, not possible to plot e.g. the VAF of a particular gene across the different cancer types (or stages of the tumor), one can only choose categorical values:

      Image

      OncoPrint
      The OncoPrint currently only shows the type of mutations on the Results View. See e.g. here:

      Image

      We can add a new feature to allow users to plot the VAF of each individual mutation in a separate track. Similar to what's possible on the patient view:

      Image

      Goal:

      Add Variant Allele Frequency in the Plots Tab

      Add Variant Allele Frequency in the OncoPrint on the Restuls View

      Approach:

      Add VAF to the Plots Tab:

      Get familiar with the plots tab codebase
      Update the axis selection interface to allow a user to select the VAF of a specific Gene
      Implement and collaborate with other devs
      For OncoPrint:

      Get familiar with the oncoprint codebase
      Update the toolbox interface to allow a user to select the VAF
      Implement and collaborate with other devs
      For a medium project (175h), one could do only the Plots Tab. For a large project (350h), one could implement both. An additional way to expand scope would be to add the cancer cell fraction of a mutation, which is available for a subset of studies.

      Needed skills:

      Javascript, TypeScript, React
      General good programming skills and willingness to learn.
      Possible mentors:

      @onursumer
      @mlizchap
      @gblaih
      @fuzhaoyuan
      
      ~~~~~~~~~~
      LLM Copilot for cBioPortal
      cBioPortal
      Difficulty: Hard
      GSoC-2025
      GSoC 2025 Candidate Projects
      Java
      LLM
      Size: Large (350h)


      Background
      cBioPortal is a powerful platform for exploring cancer genomics data, but its rich interface can be challenging for new users to navigate and interpret. An integrated Copilot (AI assistant powered by LLMs) could guide users through key pages of cBioPortal, answering questions and providing contextual help in real-time. This Copilot concept can be applied to multiple parts of the portal, including:

      Query Page: Assists users in selecting relevant studies and genomic profiles for their analysis through natural language suggestions or explanations of available options.
      Study View Page: Helps users navigate study-level data (genomic alterations, clinical summaries, etc.), highlighting important findings and answering questions about the cohort’s genomic and clinical landscape.
      Results Page: Guides users through complex visualizations (Oncoprint, Plots, Mutations, Mutual Exclusivity, etc.), explaining charts and results, and helping interpret findings (e.g. what a mutual exclusivity plot means or how to download data).
      Comparison Page: Assists in comparing patient groups (e.g. mutated vs. wild-type cases) by explaining differences in genomic or clinical characteristics and helping users set up or interpret group comparisons.
      Patient View Page: Helps users understand a single patient’s data by summarizing the patient’s “journey” (diagnosis, treatments, outcomes) and explaining specific mutations or treatment history in context.
      While the Copilot could eventually span all five pages above, the primary goal for GSoC 2025 is to achieve deep integration on at least one page rather than superficial support across all pages. We would recommend that the proposed project focus on one page. By narrowing the scope to one page, we aim to deliver a fully functional and insightful assistant experience that can later be extended to other parts of cBioPortal. The goal is to fully understand the technical feasibility and showcases the Copilot’s capabilities.

      Benefits to the Community
      Improved User Experience: This project will make cBioPortal more intuitive and user-friendly, especially for novices. An AI Copilot can lower the learning curve by providing on-demand explanations and guidance, allowing researchers and clinicians to focus on insights rather than figuring out the tool.
      Innovation in Bioinformatics Tools: Implementing an LLM-driven assistant in cBioPortal will be a novel proof-of-concept for how AI can enhance bioinformatics software. It could inspire similar features in other scientific platforms and spark further development of intelligent user assistance in open-source tools.
      Efficiency in Data Analysis: Researchers and clinicians will be able to navigate large genomic datasets more efficiently with the Copilot’s help. For example, instead of manually searching documentation, a user could ask the Copilot questions like “How many patients have this alteration?” or “What does this clinical term mean?” and get quick answers. This accelerates data interpretation and could lead to faster hypotheses generation or insights.
      Community and Educational Value: A well-documented Copilot feature can also serve as an educational resource. New contributors can learn from the implementation about integrating AI into web applications. Users of cBioPortal will indirectly learn more about genomics as the Copilot explains concepts to them. Plus, the feature shows the community that cBioPortal is staying at the forefront by adopting modern AI assistance capabilities.
      Overall, the Copilot integration aims to enhance cBioPortal’s functionality and accessibility, ensuring that the research community can leverage the portal’s full potential with greater ease and understanding. The project’s outcome will not only benefit current users but also lay the groundwork for future expansions of AI-driven assistance across the platform.

      Approach
      We will develop an interactive Copilot panel or chatbot UI within the chosen cBioPortal page. The Copilot will leverage a Large Language Model (LLM) to understand user questions or actions and provide helpful, context-specific responses. Key steps include:

      Backend Integration (Java): Extend cBioPortal’s Java backend if necessary to gather the relevant context from the portal (such as current study details, selected patient data, or query parameters) and make it available to the Copilot. This may involve utilizing data fetched by the current page, creating new API endpoints or services to retrieve metadata (e.g. study descriptions, gene annotations, patient clinical data) on the fly.
      API Development: Ensure that all information the Copilot needs (e.g. definitions of genomic terms, interpretation of plots, data summaries) is either already fetched by the page, or can be retrieved through cBioPortal’s APIs. We might enhance existing APIs or add new ones to provide richer context. This will enable the LLM to ground its answers in real cBioPortal data.
      LLM Integration: Use an LLM to power the Copilot’s natural language understanding and generation. The Copilot will be prompted with the context from the current page and the user’s query. We will likely use a hosted LLM service or an open-source model, depending on what’s feasible within the project (ensuring compliance with any data privacy or hosting constraints).
      Prompt Engineering: Craft effective prompts and conversation flows so that the LLM provides accurate and relevant assistance. This involves instructing the LLM on cBioPortal-specific roles (e.g. “You are an expert assistant for a cancer genomics portal…”) and feeding it context like “the user is looking at Oncoprint for Study X” or “the user selected patient Y with these mutations”. Iterative refinement of prompts will be done to handle different user questions (from basic “what is shown in this plot?” to complex “how do I find patients with KRAS mutations and treated with sotorasib?”) and to ensure the responses are correct, concise, and helpful.
      UI/UX Integration: Design a user-friendly interface element on the page (such as a chat window or help sidebar) where users can interact with the Copilot. The UI will display the Copilot’s guidance and allow the user to ask follow-up questions. It should feel like a seamless part of cBioPortal, with context-aware behavior (for example, suggesting what to do next or providing explanations without the user always needing to ask).
      Throughout development, we will test the Copilot’s responses for accuracy and helpfulness. We will also document how the context is gathered and used, to make it easier to expand the Copilot to the other pages in the future. If time permits after achieving a solid integration on the primary page, we can create a minimal prototype on one of the other pages to demonstrate scalability.

      Technologies
      Java: Used for back-end development in cBioPortal. We will use Java to integrate the Copilot with server-side logic, ensuring the LLM has access to necessary data through cBioPortal’s backend.
      REST APIs: Developing and extending APIs will be crucial for retrieving page-specific metadata and context. This project will likely involve creating new API calls or augmenting existing ones.
      LLM (Large Language Model): The core of the Copilot’s intelligence. We will utilize an LLM (such as GPT-based models or similar) to interpret user queries and generate helpful responses. The model could be accessed via an API (e.g. OpenAI, Anthropic, or a local model) depending on feasibility and permissions.
      Prompt Engineering: Techniques for constructing effective prompts and handling the conversation with the LLM. This includes providing context, controlling the tone and detail of responses, and guiding the model to stay on topic (for instance, focusing on genomic data interpretation rather than general knowledge).
      Expected Outcome
      By the end of the project we expect to deliver:

      Copilot on One Key Page: A fully functional, context-aware Copilot integrated into one of the major cBioPortal pages (as identified in the scope). Users should be able to interact with it to get assistance specific to that page (e.g. asking “What does this chart mean?” on the Results page and receiving a useful explanation).
      Enhanced Metadata Access: Any necessary enhancements to cBioPortal’s data retrieval (such as new API endpoints or backend methods) to support the Copilot’s functionality will be implemented. This ensures the Copilot has the data it needs.
      Documentation and Guides: Clear documentation of the Copilot’s implementation and usage. This will include how to configure or extend it to other pages, instructions for developers to maintain or improve it, and maybe a short user guide section on how to use the Copilot feature.
      Proof-of-Concept for Expansion: Although we focus on one page, the project will serve as a template for future Copilot integrations in cBioPortal. The outcome will include insights or even a demo on how the Copilot could be rolled out to the other pages (for instance, noting what additional data would be needed for those pages), providing a foundation for continued development after GSoC.
      Difficulty
      Difficulty Level: Advanced – This project is challenging because it involves cutting-edge integration of AI (LLMs) with a complex bioinformatics platform. The student will need to be comfortable working across the full stack (front-end UI, back-end Java, and external AI services) and handling the uncertainties of LLM interactions. Experience with both software engineering and some understanding of the biological context will be helpful to navigate this project’s complexity.

      Skills Required
      LLM Integration: Experience or willingness to learn how to integrate large language model APIs or libraries. This includes handling API calls, parsing model responses, and possibly fine-tuning prompts or using libraries for better context management.
      Prompt Engineering: Skill in crafting and refining prompts to get useful outputs from the LLM. The student should be prepared to experiment with prompt phrasing and conversation structure to improve the Copilot’s accuracy and usefulness.
      Java Development: Strong skills in Java for modifying cBioPortal’s backend, adding new endpoints, and ensuring the application remains robust and efficient with the new features.
      API Design & Development: Ability to design clear and efficient APIs. The student should be able to extend cBioPortal’s REST API or backend services to provide the data the Copilot needs.
      Web Integration (Frontend): Familiarity with web development (JavaScript/React) to embed the Copilot interface seamlessly into the cBioPortal UI. While the project description emphasizes backend and LLM, some frontend work will be needed for the user interface.
      Bioinformatics Domain Knowledge (Preferred): While not strictly required, familiarity with cancer genomics concepts and portals like cBioPortal will be very beneficial. Understanding terms like “oncoprint”, “mutation frequency”, or clinical data will help in guiding the LLM and interpreting what users might ask.
      Potential Mentors
      @pieterlukasse, @forus, @jjgao, Michele Water, Mitchell Parker

      ~~~~~~~~~~
     
      Re-implement Study View's data binning algorithm using SQL (instead of Java)
      cBioPortal
      Difficulty: Medium
      enhancement
      GSoC-2025
      GSoC 2025 Candidate Projects
      Java
      Size: Medium (175h)
      SQL


      Background:
      cBioPortal is an open-source platform designed to provide a web interface for exploring, visualizing, and analyzing cancer genomics data, and has grown to be widely used by researchers and clinicians worldwide. The current interface provides comprehensive tools for individual patient data exploration, including mutations, copy number variations, and clinical information as well as cohort exploration, analytics, and cohort comparisons.

      The endpoints which drive the histogram charts on the cBioPortal Study View calculate data bins and return them to the frontend for display. To do this, they must fetch the underlying data from the database and run it through custom binning logic written in Java. This is not performant for large data sets. The binning should be done in the database query so that we don't have to return voluminous data and keep it in web server memory. Clickhouse, the new database we are adopting, provides functions to do this.

      Image

      Goal:
      Optimize the cBioPortal Study View data binning algorithm by replacing the existing logic written in Java and re-implementing it so that the heavy lifting is performed by the database instead.

      Approach:
      We believe this is possible using the RoundDown function of Clickhouse (our new OLAP database).

      This project requires:

      Understanding the specific requirements of binning in the cBioPortal (e.g. custom bin definitions)
      Meeting these requirements using RoundDown.
      If 2 proves unfeasible, we may resort to Clickhouse's User Defined Functions.
      Getting started:
      The code which we want to replace can be examined here

      Image

      One case see that the current implementation requires that we load the clinical data into server memory for the purpose of running our custom binning logic in Java. We want to see if we can achieve the binning logic in SQL.

      Possible mentors:
      @alisman
      ~~~~~~~~~~
      Similar Patient Discovery
      cBioPortal
      Difficulty: Hard
      GSoC-2025
      GSoC 2025 Candidate Projects
      Pipeline
      Python
      Size: Large (350h)

      Background:
      The cBioPortal for Cancer Genomics is an open-source platform designed to provide a web interface for exploring, visualizing, and analyzing cancer genomics data, and has grown to be widely used by researchers and clinicians worldwide. The current interface provides comprehensive tools for individual patient data exploration, including mutations, copy number variations, and clinical information as well as cohort exploration, analytics, and cohort comparisons.

      A user can find similar patients by using the interface to look for patients that e.g. are of the same cancer type, have similar mutations, or received the same treatment. There are currently however no similar patients proposed automatically; finding similar ones requires many manual steps. Here, we propose to develop a new web service that would recommend similar patients a user could explore given a patient's molecular and clinical profile. In oncology, where genetic mutations and biomarkers play critical roles in determining the most effective treatments, the ability to easily find and compare similar patient cases is invaluable. Moreover, a patient similarity function within cBioPortal would empower users to leverage the vast amounts of data available in the portal more effectively. By integrating sophisticated similarity search capabilities, users could identify cohorts of patients based on specific criteria, compare their genomic landscapes, and analyze their treatment outcomes.

      image
      Goal:
      Develop a REST API that provides patient similarity information given a patient's molecular and clinical profile. For the similarity scoring we will use an existing algorithm

      Approach:
      We will develop a backend web service for an existing Python-based algorithm that generates a model for identifying similar patients. This web service will provide a RESTful API to allow for communication of the cBioPortal frontend with the patient similarity model. These endpoints will be designed to handle real-time data exchanges, leveraging JSON for its versatility and efficiency in data transmission.

      To manage data updates to the patient similarity model whenever new cBioPortal data is added to the system we propose to leverage event-driven triggers. When new data enters the system, we rerun the pipeline to regenerate the model and redeploy the backend web service Whenever a user visits the frontend page it will be using this new backend web service. This ensures that the frontend displays the most current data, enhancing the user experience in exploring patient similarities. Additionally, to maintain system efficiency and prevent overload, it's crucial to optimize the data payload and update frequency based on user interaction and system capabilities

      Need skills:
      Understanding of RESTful APIs, Familiarity with Python

      Possible mentors:
      @Thahmina
      

      ~~~~~~~~~~
      AI/LLM Generated gene alteration and expression based subtyping for each tumor type
      cBioPortal
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Prompt Engineering
      Python
      Size: Large (350h)
      Size: Medium (175h)

      Background:

      Cancer Classification: Cancer manifests in various forms across different tissues and organs of the body. The classification of cancer plays a pivotal role in understanding its behavior, prognosis, and treatment strategies. Over the years, advancements in medical research and technology have led to a deeper understanding of the molecular and cellular mechanisms underlying cancer development, thereby refining the classification systems used by oncologists and researchers. At its core, cancer classification categorizes malignancies based on a multitude of factors, including their tissue of origin, histological characteristics, genetic alterations, and clinical behavior.
      OncoTree: OncoTree is a dynamic and flexible community-driven cancer classification platform encompassing rare and common cancers that provides clinically relevant and appropriately granular cancer classification for clinical decision support systems and oncology research.
      cBioPortal: cBioPortal is an open-source platform for cancer genomics data analysis and visualization. It provides a centralized resource for exploring and analyzing large-scale cancer genomic data sets, including genomic alterations, gene expression, and clinical information. The platform integrates data from multiple sources, including The Cancer Genome Atlas (TCGA) and the International Cancer Genome Consortium (ICGC), and makes it available through a web interface for researchers, clinicians, and the general public. All samples in cBioPortal are assigned a particular cancer type based on OncoTree
      The Challenge: in cBioPortal there are many pages where it would be useful to list a set of default genes when we know what cancer type the user is looking at. E.g. imagine exploring a breast cancer dataset, it probably makes sense to look at BRCA1, BRCA2 and EGFR alterations. Similarly, for Glioblastoma you'll want to look at IDH1 and IDH2. We can use an LLM (or another method) to generate these recommended genes for each OncoTree code by e.g. constructing a prompt like "Which genes are relevant for subtype x"
      Goal:

      Generate a list of recommended default genes for each OncoTree code that are often used for molecular classification of that subtype
      Approach:

      Try different prompts on any LLM of choice and script a way to do this semi-automatically
      Some example prompts:
      Which genes and pathways are relevant for classifying Breast Cancer? Could you give your answer in a JSON structure like:
      {
          "Breast Cancer": {
              "Mutation-Based": ["Gene1", "Gene2", "Gene3"],
              "Expression-Based": ["GeneX","GeneY","GeneZ"]
              "Pathways": ["PathwayA","PathwayB"]
      }
      The LLM of choice can be vanilla ChatGPT, Gemini, something you train yourself, etc
      Start with just the main OncoTree Types, e.g. "Breast Cancer", "Lung Cancer", etc
      Explore ways to validate the proposed genes. One way would be to leverage the cBioPortal API to see if samples with this OncoTree code have any alterations in those genes
      For the 350h project we can try to do the same for the more detailed subtypes like e.g. 'Breast Lobular Carcinoma In Situ'.
      Need skills:
      Prompt Engineering, Python or similar scripting language

      Possible mentors:
      @inodb

      

      

      ~~~~~~~~~~
      Clinical Timeline Standalone Package and Documentation
      cBioPortal
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Size: Large (350h)
      Size: Medium (175h)

      Background:

      cBioPortal uses the React JS framework to aid in the reusability of components. Some cBioPortal components (i.e., clinical timeline) have been built with the goal of reusability, but require additional work and documentation for the wider community to reuse. The clinical timeline component aids research in understanding how the disease of a patient changes over time for specific samples taken from the patient along with information about their treatment.

      Example: https://www.cbioportal.org/patient?sampleId=gbm_columbia_2019_13&studyId=gbm_columbia_2019
      Screenshot 2024-01-12 at 12 13 16 PM

      Goal:

      The goal is to harden (ensure standalone use and document) the clinical timeline component. Documentation and standalone example for a previous version of the component: https://github.com/cBioPortal/clinical-timeline (the repository is for an old prototype; this is the minimum level of documentation expected as outcome from this project).

      For the larger project (350h) a secondary goal is to generate a wrapper for the standalone component for reuse within the R Shiny web framework (https://cran.r-project.org/web/packages/reactR/vignettes/intro_htmlwidgets.html).

      Approach:
      The clinical-timeline is already a package in the cBioPortal frontend monorepo. We will begin by adding a README file to the existing NPM package that explains how to embed this package into a new create-react-app project. Iteratively we'll add more documentation so it starts looking more similar to the old clinical timeline package README in terms of completeness.

      Need skills:

      Typescript, Javascript

      Code/Repositories:

      https://github.com/cBioPortal/cbioportal-frontend/tree/master/packages/cbioportal-clinical-timeline
      https://github.com/cBioPortal/cbioportal-frontend/blob/master/src/pages/patientView/timeline/timeline_helpers.tsx
      https://www.npmjs.com/package/cbioportal-clinical-timeline
      Possible mentors:

      Augustin Luna
      Ino de Bruijn
    
      ~~~~~~~~~~
      Create Chat Bot Interface Trained On Documentation Site
      cBioPortal
      Difficulty: Medium
      GSoC-2025
      GSoC 2025 Candidate Projects
      Size: Large (350h)
      Size: Medium (175h)

      Background:

      cBioPortal: cBioPortal is an open-source platform for cancer genomics data analysis and visualization. It provides a centralized resource for exploring and analyzing large-scale cancer genomic data sets, including genomic alterations, gene expression, and clinical information. The platform integrates data from multiple sources, including The Cancer Genome Atlas (TCGA) and the International Cancer Genome Consortium (ICGC), and makes it available through a web interface for researchers, clinicians, and the general public. Please refer to the cBioPortal home page for an overview.
      cBioPortal has lots of documentation available (https://docs.cbioportal.org/) on how (1) to install and configure cBioPortal locally, (2) use cBioPortal as a user, (3) programmatically use the API. Searching through the documentation is not always straightforward and we often get questions on the user group (https://groups.google.com/g/cbioportal) where we mainly point to a link in the docs. A chat interface might be a good solution for giving users quicker feedback on what they are searching for
      The cBioPortal documentation site uses ReType and all the markdown files are located here: https://github.com/cBioPortal/cbioportal/tree/master/docs
      Goal:

      Build a chat bot interface for cBioPortal's Documentation
      Approach:

      Evaluate existing services in this space, e.g. Custom GPT, PickAxe, Gitbook AI), or others. Contrast these against training a local LLM in terms of development time and cost
      Train one or more models on our documentation site
      Evaluate the models. Implement a suite of tests that can check output or provide a document for manual evaluation
      Integrate chat interface into the documentation site, which should allows users to interact with it (350h project). Note that we have ~3K users / day, so please keep cost into consideration for the deployment setup
      Need skills:
      Familiarity with the command line and the use of APIs

      Possible mentors:
      @zainasir
      @inodb
      @walleXD


      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/cbioportal-for-cancer-genomics/
    idea_list_url: https://github.com/cBioPortal/gsoc/issues?q=is%3Aissue%20state%3Aopen%20label%3AGSoC-2025

  - organization_id: 175
    organization_name: checkstyle
    no_of_ideas: 17
    ideas_content: |
      AI-Powered XPath Generator for Checkstyle Suppressions
      Improve Modules used in Google Style
      Auto-fix Module
      Markdown Javadoc Support
      Improve Performance of Html-formatted Javadoc parser and create new Markdown Javadocs parser
      Optimization of distance between methods in single Java class
      Reconcile formatters of Eclipse , NetBeans and IntelijIdea IDEs by Checkstyle config
      Coverage of Documentation Comments Style Guide and performance improvement
      Open JDK Code convention coverage
      Spellcheck of Identifiers by English dictionary
      Patch Suppression improvement
      Extend Checker Framework Integration
      New ANTLR Grammar for Javadoc Comments
      Upgrade dependencies to use latest version of libraries and use their features
      Enhance Mutation Testing Coverage
      Eliminate Maven Plugin Usage
      Automated Website Generation
      Project Name: AI-Powered XPath Generator for Checkstyle Suppressions
      Skills required:
      Java (advanced)
      Knowledge of XPath
      Experience with machine learning frameworks
      Basic understanding of Abstract Syntax Trees (AST)
      Familiarity with Docker
      Project goal: Develop a local LLM-based solution that generates optimal XPath queries to suppress specific Checkstyle violations based on user prompts, violation details, and code context.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Ruslan Diachenko, Roman Ivanov, Andrei Paikin, Timur Tibeyev
      Description: Creating XPath expressions to suppress Checkstyle violations is a complex task requiring deep understanding of both XPath syntax and AST structure. This leads to either overly broad suppressions hiding important issues or overly specific rules needing frequent updates. This project aims to create an AI-powered system to convert Checkstyle violations and user instructions into precise XPath expressions for violation suppression. The core focus is on developing a containerized LLM-based solution that can understand both the violation context and user intent to generate accurate XPath queries.
      A preliminary proof of concept (PoC) demonstrates the basic feasibility of using LLMs for XPath generation. While this PoC serves as an experimental starting point, the GSoC project will require a complete redesign and implementation to create a production-ready solution.
      Deliverables:
      Containerized LLM-based solution for XPath generation
      Command-line interface for basic interaction
      Basic documentation for setup and usage
      Fix for all issues with "xpath" label in the Checkstyle repository
      QnA: https://discord.com/channels/845645228467159061/1338507765207007242 (invite)

      ~~~~~~~~~~
      Project Name: Upgrade dependencies to use latest version of libraries and use their features
      Skills required: Java, Groovy, BASH, continuous integration, basic understanding of testing principles
      Project goal: upgrade our jdk to 17 and 21, bump all other dependencies
      Project size: medium (175 hours)
      Complexity Rating: intermediate
      Mentors: Roman Ivanov,
      Description:
      we use jdk11, whole world already use jdk21 , we need to bump minimal jdk usage to jdk17 and than to jdk21. Bump version of apache doxia, and other dependencies.
      Deliverables:
      bump jdk dependency
      bump for doxia dependencies
      bump for intelij idea inspection
      check if we can use BOMs for dependency management
      activate Checks UnusedLambdaParameterShouldBeUnnamed, UnusedCatchParameterShouldBeUnnamed, SealedShouldHavePermitsList, WhenShouldBeUsed, MissingNullCaseInSwitch
      use maven wrapper
      migrate our code base to new nio jdk api - https://github.com/checkstyle/checkstyle/issues/16155
      
      
      
      create module-info.java, see initial activity https://github.com/checkstyle/checkstyle/pull/14139
      QnA: https://discord.com/channels/845645228467159061/1338509064669495377 (invite)

      ~~~~~~~~~~
      Project Name: Markdown Javadoc Support
      Skills required: Java, basic understanding of testing principles, basic understanding of static analysis
      Project type: new feature implementation.
      Project goal: Integrate support for Markdown Javadoc comments in Checkstyle.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Nick Mancuso
      Description:
      With the introduction of JEP 467, Java supports Markdown-style documentation comments. This feature modernise Java's documentation capabilities but is not currently supported in Checkstyle. The current Javadoc parsing in Checkstyle is tightly coupled to the traditional /** ... */ syntax and HTML-based formatting, presenting challenges in extending support for Markdown's structure. This project aims to enhance Checkstyle by introducing new grammar and update exisiting checks to support Markdown Javadoc comments.
      Deliverables
      New implementation of grammar for Markdown Javadoc Comments
      New tokens to identify and validate elements specific to Markdown Javadoc syntax.
      New Checkstyle Checks for new format of javadoc, ideas on what should be validated should be taken from existing Checks.
      Creation of new checks (if necessary): Create new checks to enforce Markdown-specific best practices.
      


      QnA: https://discord.com/channels/845645228467159061/1338509670255562772 (invite)

      ~~~~~~~~~~
      Project Name: Improve Performance of Html-formatted Javadoc parser and create new Markdown Javadocs parser
      Skills required: strong Java, deep understanding of testing principles, understanding of how language grammar works
      Project type: improvement and new feature implementation.
      Project goal: improve Performance of Html formatted Javadoc Check and parsing support of Markdown Javadocs.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov
      Description:
      Performance improvement of existing javadoc parser are expected, see details at https://github.com/checkstyle/checkstyle/issues/11193 .
      With the introduction of JEP 467, Java supports Markdown-style documentation comments. This feature modernise Java's documentation capabilities but is not currently supported in Checkstyle. This project aims to enhance Checkstyle by introducing new grammar, implementation of few basic validations just as prove of concept and example of new parser posibilities.
      Deliverables
      Improved implementation of html based javadoc Checks, possible breaking changes is fine.
      Update for all AST based existing Checks to use new html based parser (we can update some Checks only if there will be time constraints).
      New implementation of grammar for Markdown Javadoc Comments
      New tokens to identify and validate elements specific to Markdown Javadoc syntax.
      Few Checkstyle Checks for new format of javadoc, ideas on what should be validated should be taken from existing Checks.
      New documentation html page to explain how to write Check for markdown javadoc validation.
      
      QnA: https://discord.com/channels/845645228467159061/1338849908211580969 (invite)

      ~~~~~~~~~~
      Project Name: Improve Modules used in Google Style
      Skills required: Java, basic understanding of testing principles, basic understanding of static analysis
      Project goal: improve quality of google style guide implementation
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Mauryan Kansara, Daniel Mühlbachler,
      Description:
      During GSoC'24, we successfully updated our implementation of google style guide to the latest version ( 03 Feb 20222 ). google_checks.xml is the configuration file where our google java style guide is implemented. Though we have covered almost all rules of the google style guide, users have reported bunch of issues pointing out flaws in our implementation, these issues are labeled as google style issues, we need to solve them. On top of this, we have few rules which we are not able to completely follow/implement, they are marked with "Blue Tick" in our coverage page, we need to find a way to reduce such blue ticks rules and improve our coverage.
      Deliverables:
      Resolve all issues labeled as google style
      Reduce "Blue Tick" rules by analyzing the rule and our coverage for that rule and provide solutions for them.
      Investigate the issues related to Modules/Checks in issue tracker of Checkstyle repository which are used in google_checks.xml, if the Module/Check configuration found in the issue is same as present in google_checks.xml then that issue is qualified for the project, it should be reported to us and marked by google style label.
      We already have started process of triaging issues which affects user experience, they're listed at: https://github.com/orgs/checkstyle/projects/10, this work should be continued and finished.
      
      QnA: https://discord.com/channels/845645228467159061/1338510140277522442 (invite)

      ~~~~~~~~~~
      Project Name: Auto-fix Module
      Skills required: intermediate Java
      Project type: new feature implementation.
      Project goal: implement new module, test it on real projects
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Baratali Izmailov
      Description: Checkstyle is known as tool that raises numerous minor issues. There are so many of these and they are so minor that it is hard to find time and engineer to fix them. Most of the issues are so easy to fix but navigation to certain part of the code and making the fix takes time. Engineers could spend this time doing something more valuable. Implementation of an auto-fix functionality could significantly simplify introduction of checkstyle to project as it will do most tedious work automatically.
      The major part of checkstyle violations are specifically targeting the formatting of the code. It is often that IDE formatting settings are not in sync with the checkstyle configuration. The IDE can fix the code itself as part of it’s auto-formatting. The same should be done by Checkstyle. Each Check that is targeting the formatting part of the code should have “Fix” functionality built-in. This functionality will convert the code with the violation to compliant code without any user interaction. Such functionality is in huge demand by users.
      In scope of this project, it is required to review all existing functionality of auto-fix of code in plugins and tools to learn challenges they have and see the whole list of requirements to resolve such a task. Make implementation of auto-fix for formatting Checks as part of a special Module that takes all reported violations and fix them that will support auto-fix. If the resulting functionality proves to be easy to maintain, and might be reused by checkstyle plugins, then propose API changes can be brought to the core library and allow any plugins to reuse it.
      More details at https://github.com/checkstyle/checkstyle/issues/7427
      Links to similar tools: https://docs.openrewrite.org/tutorials/automatically-fix-checkstyle-violations, https://github.com/solven-eu/cleanthat
      Ai autofix for checkstyle: https://link.springer.com/article/10.1007/s10664-021-10107-0
      Auto fix in Eclipse https://github.com/checkstyle/eclipse-cs/pull/566/files#diff-13e277cb135ea2a474dad0b4ac46b5cb020f9c03a2eb6676b15de010f8aec369R549
      OpenRewrite project - example of enabling at eclipse-cs https://github.com/checkstyle/eclipse-cs/pull/805
      Deliverables:
      selection of existing library that will do code modification or making our own implementation
      defining api for triggering code changes
      selection of Checks that can produce violations that are auto fixable
      implementation of auto fix for selected Checks
      find a model to avoid conflicts of auto fixes
      QnA: https://discord.com/channels/845645228467159061/1214569225247793282 (invite)

      ~~~~~~~~~~
      Project Name: Optimization of distance between methods in single Java class
      Skills required: basic Java , good analytical abilities, good background in mathematics.
      Project type: new feature implementation.
      Project goal: to make quality practices automated and publicly available.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Baratali Izmailov, Ruslan Diachenko
      Description:
      This task is ambitious attempt to improve code read-ability by minimizing user jump/scrolls in source file to look at details of method implementation when user looks at method first usage.
      It is required to analyse a lot of code and find a model to minimize distance between methods first usage and method declaration in the same file and respect users preferences to keep grouped overloaded and overridden methods together. Some other preferences may appear during investigation of open-source projects.
      First step is already done by our team, we created a web service that already calculate distances between methods and make DSM matrix to ease analysis - methods-distance. We already practice it in our project.
      As a second step it is required to use a matrix of distances between methods and optimize it by some empiric algorithm to allow user define expected model of class by arguments. This will allow to use this algorithm as a Check to enforce code structure automatically during build time.
      Prove of necessity: we have a number of PRs where contributors put new methods at any possible place in a class but better place is close to first usage. Example #1, Example #2, Example #3, ....
      Deliverables:
      new Checkstyle's Check with optimization algorithm to share the algorithm with whole java community.
      analytical report that proves reason why default values for Check parameters are selected
      article with all details of analysis and algorithm details;
      QnA: https://discord.com/channels/845645228467159061/1214569693336182864 (invite)

      ~~~~~~~~~~
      Project Name: Reconcile formatters of Eclipse , NetBeans and IntelliJ IDEA IDEs by Checkstyle config.
      Skills required: basic Java.
      Project type: new feature implementation, analysis of existing IDE features.
      Project goal: to make well-known quality practices publicly available.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Andrei Paikin, Mauryan Kansara
      Description:
      Usage of different IDEs in the same team is already a serious problem, as different IDEs format code base on their own rules and configurations. Unwanted formatting changes happen to code which complicate code-review process. Problem become more acute when project use static analysis tool like Checkstyle that has a wide range of code formatting Checks.
      It is required to make it possible to use the same Checkstyle config to work in IDEs without conflicts with IDEs internal formatters. This will help team members be independent on IDE choice but at the same time keep the same format and code style throughout the team.
      Main focus of this project is the analysis of formatting abilities of IDEs (indentation, imports order, declaration order, separator/operator wrap, .....) . Update existing Checkstyle Rules to be able to work in the similar and non-conflicting way.
      Deliverables:
      create configuration for IDEs for Checkstyle project to let Checkstyle team use it and auto-format code to conform with checkstyle_check.xml file that is used by Continuous Integration.
      create Checkstyle config that follows default Eclipse formatting + inspection rules
      create Checkstyle config that follows default IntelliJ IDEA formatting + inspection rules
      create Checkstyle config that follows default NetBeans formatting + inspection rules
      Deep refactoring of Indentation Check to fix its numerous problems.
      Prove of necessity: mail-list post #1, mail-list post #2, mail-list post #3 , discussion #1
      QnA: https://discord.com/channels/845645228467159061/1214571037451100180 (invite)

      ~~~~~~~~~~
      Project Name: Open JDK Code convention coverage
      Skills required: basic Java.
      Project type: new feature implementation.
      Project goal: to make well-known quality practices publicly available.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Baratali Izmailov, Daniel Mühlbachler, Mauryan Kansara
      Description:
      OpenJdk Code Convention was one of the first guidelines on how to write Java code. OpenJdk Code Convention is marked as outdated (because of date of last update made in it) but best practices described there do not have an expiration date. New OpenJDK Java Style Guidelines is close to the final version and most likely will be successor of OpenJdk Code Convention. But there is a number of projects in Apache that still follow OpenJdk rules, so both configurations are in need by community.
      OpenJdk Code Convention is already partly covered by Checkstyle, known as Sun Code Convention. A lot of validation Rules were added and changed in Checkstyle from the time when Sun's configuration was created (2004 year).
      During the project it is required to review both documents in detail and prove publicly that Checkstyle covers all guideline rules. Missed functionality needs to be created, blocking bugs need to be fixed. Page OpenJdk Java Style Checkstyle Coverage needs to be updated. New page "New OpenJDK's Java Style Checkstyle Coverage" need to be created. Both pages need to be formatted in the same way as it is done for Google's Java Style Checkstyle Coverage.
      Prove of necessity: javadoc issues on github; results of open survey; request from users for Openjdk coverage support.
      Deliverables:
      embedded config file with all modules that are required for coverage
      html page that explains how each paragraph in style guide is covered by Checkstyle
      
      QnA: https://discord.com/channels/845645228467159061/1214571550783840307 (invite)

      ~~~~~~~~~~
      Project Name: Coverage of Documentation Comments Style Guide and performance improvement
      Skills required: basic Java.
      Project type: new feature implementation.
      Project goal: to make well-known quality practices publicly available.
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Baratali Izmailov, Mauryan Kansara
      Description:
      Project will mainly be focusing on automation of Documentation Comments (javadoc) guidelines by Checkstyle Checks. Reliable comments parsing was a major improvement in Checkstyle during GSoC 2014, archived results need to be reused to reliably implement automation of Javadoc best practices.
      Separate configuration file with newly created Checks need to be created. Best practices in documentation make sense not for all projects. Javadoc validation matters only for library projects that need to expose online documentation in web publicly.
      Performance improvement of existing javadoc parser are expected, see details at https://github.com/checkstyle/checkstyle/issues/11193 .
      Deliverables: The result of this project will be a configuration file with the maximum possible coverage of Comment style guide. Report should look like Google's Java Style Checkstyle Coverage. Performance improvements of javadoc parsing. If there will be time left we can focus on coverage of guidelines from https://blog.joda.org/2012/11/javadoc-coding-standards.html
      Prove of necessity: javadoc issues on github.
      QnA: https://discord.com/channels/845645228467159061/1214571282776064130 (invite)

      ~~~~~~~~~~
      Project Name: Spellcheck of Identifiers by English dictionary
      Skills required: intermediate Java.
      Project type: new feature implementation.
      Project goal: implement spell checking for java code for all identifiers .
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Andrei Paikin
      Description:
      The correct spelling of words in code is very important, since a typo in the name of method that is part of API could result in serious problem. Mistakes in names also make reading of code frustrating and misleading, especially when a typo in one letter makes developer to read javadoc or even implementation of the method. Two most popular IDEs (Eclipse and IntelliJ IDEA) already have spell-check ability. It will be beneficial for Checkstyle to have the same functionality that could be used in any Continuous Integration system by Command Line Interface or as part of build tool (maven, ant, gradle, ....) with wide range of options to customize to users needs. Features of existing spell-checkers need to be analyzed -
      IntelliJ IDEA Spellchecking , Eclipse Spelling. There are numbers of open-source projects that do spell-check. It is ok to reuse them if license is compatible. Examples: https://code.google.com/archive/p/bspell/ , http://www.softcorporation.com/products/spellcheck/, ... https://github.com/giraciopide/shellcheck-maven-plugin, https://github.com/codespell-project/codespell
      Deliverables:
      regular Checkstyle module that does validation
      such module should be applied to all sources of our Code
      disablement of shell based implemnetation of spellcheck in our project for java sources.
      documentation on how to use module
      QnA: https://discord.com/channels/845645228467159061/1214572273038786631 (invite)

      ~~~~~~~~~~
      Project Name: Automated Website Generation
      Skills required: Java, basic understanding of testing principles, technical writing, continuous integration
      Project goal: organize documentation and automate its maintenance
      Project size: large (350 hours)
      Complexity Rating: intermediate
      Mentors: Roman Ivanov, Daniel Mühlbachler,Mauryan Kansara
      Description:
      This project is designed to tackle the persistent challenge of maintaining accurate and current documentation in our dynamic development environment. Acknowledging the limitations of manual documentation processes, this initiative introduces automation to streamline content creation, with a focus on ensuring consistent formats and robust verification checks. The project's goal is to provide users with reliable, standardized, and regularly updated information while equipping contributors with templates and automated tools to simplify the incorporation of details for new modules. By elevating documentation practices, this project aligns with industry best practices, fostering clarity for both users and contributors within the Checkstyle project.
      Deliverables:
      migration to latest maven site plugin and doxia library.
      Reusage of xdoc templates model that we already have.
      Introduction of description macros that would take content from javadoc of module
      Resolution of edge cases in documentation generation
      Extend and make consistent all check usage examples
      Reduce/eliminate manual documentation updates for examples
      Introduce checks to ensure that all configuration options are covered in examples
      Moving website generation logic to separate project to avoid extra classes and dependencies in checkstyle jar artifact.
      HTML Enhancements for our website to ease navigation and user experience by search toolbar
      QnA: https://discord.com/channels/845645228467159061/1214574452021530686 (invite)

      ~~~~~~~~~~

    
      Project Name: Enhance Mutation Testing Coverage
      Project goal: reduce technical debt and improve code quality
      Skills required: Java, basic understanding of testing principles
      Project size: large (350 hours)
      Complexity Rating: intermediate
      Mentors: Roman Ivanov, Daniel Mühlbachler, Mauryan Kansara
      Description:
      Checkstyle has recently enriched its mutation testing suite with a set of new mutators powered by pitest, a state-of-the-art mutation testing system renowned for providing gold standard test coverage in Java and the JVM. This project focuses on a meticulous review of suppressions employed within Checkstyle to manage pitest violations, aiming to identify opportunities for new tests or adjustments to existing ones that can effectively resolve these suppressions. The objective is to ensure the continued functional soundness of the code, potentially involving a deep dive into module logic to facilitate test identification and contribute to the resolution of suppression-related issues.
      Deliverables:
      Review of existing suppressions of pitest survivals
      New tests or improvements to existing tests
      Resolution of 100% of existing suppressions
      usage of new mutators https://docs.arcmutate.com/docs/extended-operators.html
      Documentation, including examples
      QnA: https://discord.com/channels/845645228467159061/1214573720056762468 (invite)


      ~~~~~~~~~~
      Project Name: Eliminate Maven Plugin Usage
      Skills required: Java, Groovy, Maven
      Project goal: remove all usages of maven-checkstyle-plugin in our tools
      Project size: medium (175 hours)
      Complexity Rating: intermediate
      Mentors: Roman Ivanov, Daniel Mühlbachler,
      Description:
      Checkstyle serves as a widely used library across various tools, with a notable dependency on the maven-checkstyle-plugin for continuous integration and regression testing. However, this reliance on an external tool has restricted our ability to introduce breaking changes to the Checkstyle project, given the potential disruptions it causes in testing. Consequently, we've had to implement workarounds to maintain the connection and dependence on the maven-checkstyle-plugin. To foster autonomy and minimize dependencies, Checkstyle is undertaking efforts to break away from this plugin and shift towards relying solely on tools under our maintenance. The list of connected issues below outlines specific areas that require modification to facilitate this transition.
      Deliverables:
      Remove all usages of maven-checkstyle-plugin in our tools
      Update documentation to reflect changes
      Update build, CI, and regression testing to use internal tools exclusively
      Connected Issues:
      Launch/Diff Groovy should remove use of maven-checkstyle-plugin
      Convert sevntu-checkstyle-check to ant run
      Convert regressions that use maven-checkstyle-plugin to CLI based
      Example of Plugin Issue: Upgrade XML logger to XML 1.1
      QnA: https://discord.com/channels/845645228467159061/1214574180591214592 (invite)

      ~~~~~~~~~~
      Project Name: Patch Suppression improvement
      Skills required: basic Java
      Project type: extension of existing feature implementation.
      Project goal: implement new strategies for existing filter/suppression module or improve existing
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov, Ruslan Diachenko
      Description: Introducing Checkstyle to a project can be a challenging and NOT an easy job, especially when a project has massive amount of code, very active in development, and there are no resources to start a new process of code cleanup. It may require an extensive effort, especially when there is legacy code from previous contributors that becomes a monotonous job, that everyone tries to avoid. It is easy to say how code should look like, but may be hard to actually enforce rules in existing codebase.
      For example Guava is not following google style, and it is easy to say how code should look like but hard to assign somebody to fix ALL problems from previous contributors. It is very boring activity that all will try to avoid. Good practice from openjdk actually discourage code changes without good reason.
      Better approach is to let existing code be as is and validate only new code. Checkstyle already has a wide array of filter functionality that could suppress certain violations if user classify a violation as “won’t fix”. Just getting started with setting up the initial suppressions still requires a huge effort to review all the violations, or organize a team on special cleanup process.
      This project was originally done at GSOC 2020, but during usage of this project we found problems that checkstyle violations are still going beyond changed code that creates avalanche of change so it complicate usage of it in real project.
      We need to invest focus on parsing of patch files to get more precise location of changes and be able skip violation if fix for it goes outside of changed lines. For example: user changing line wrapping of long signature of method and we should not demand decreasing of amount of parameters or fixing names, as this will trigger changes in other part of code.
      As proof of success for this project, it is required to get some open source project onboard to use checkstyle and this new feature. It would be good to try collaborate one more time with Guava project or we can ask our friends in Eclipse-CS or Spring or Hbase project.
      Deliverables:
      new Filter in Chekstyle that is applied to our code base.
      documentation on how to use new filter.
      apply filer to eclpse-cs project to work on each update (address feedback from usage).
      QnA: https://discord.com/channels/845645228467159061/1214572538043043890 (invite)

      ~~~~~~~~~~
      Project Name: Extend Checker Framework Integration
      Skills required: Java, basic understanding of testing principles, basic understanding of Java type system
      Project goal: Further usage of Checker Framework and increase internal knowledge base
      Project size: large (350 hours)
      Complexity Rating: hard
      Mentors: Roman Ivanov
      Description:
      The goal of this project is to advance the integration of the Checker Framework into our existing codebase, enhancing code quality, correctness, and maintainability. In addition to refining the setup already present in our build, the project will focus on incorporating the Checker Framework's type system into key components of our code and creating comprehensive documentation and best practices to guide developers in utilizing the framework effectively.
      Deliverables:
      Integrate Checker type system with codebase
      Refine existing build
      Develop internal documentation about our usage of Checker
      Provides examples, guidelines and best practices for developers to follow
      QnA: https://discord.com/channels/845645228467159061/1214572824736571472 (invite)

      ~~~~~~~~~~
      Project Name: New ANTLR Grammar for Javadoc Comments
      Skills Required: Java, understanding of testing principles, static analysis, and language grammar.
      Project Type: New feature implementation.
      Project Goal: Develop a new ANTLR-based parser for Javadoc comments to improve performance and maintainability.
      Project Size: Large (350 hours)
      Complexity Rating: Hard
      Mentors: Roman Ivanov, Nick Mancuso
      Description:
      The need for a new parser has been discussed multiple times due to growing issues with the old implementation(e.g., Performance Issue 1, Performance Issue 2). This project introduces a new ANTLR-based grammar for parsing Javadoc comments in Checkstyle. The existing Javadoc parser becomes inefficient and hard to maintain. making Javadoc validation a bottleneck. By replacing it, we aim to improve performance, accuracy, and maintainability while ensuring compatibility with existing Javadoc checks. The existing AST-based Javadoc checks will be incrementally migrated to the new parser, ensuring a seamless transition. Additionally, the old parser will be deprecated, allowing Checkstyle in the future to fully rely on the new parser for better maintainability.
      Speeding up Javadoc parsing will enable users to run Checkstyle more frequently without performance concerns, making Javadoc checks easier to integrate into code reviews and build cycles. Currently, enabling any Javadoc check significantly increases validation time, making it frustrating to use. The new parser aims to resolve this issue.
      Deliverables:
      A maintainable and effiecent ANTLR grammar for Javadoc comments.
      Update for all AST-based existing Checks to use the new parser (we can update some Checks only if there will be time constraints), possible breaking changes is fine.
      Update for all non-AST checks to use the new paresr (we can update some Checks only if there will be time constraints).
      Deprecation Plan: Transition strategy for phasing out the old parser.
      New documentation to help the community understand new parser and contribute to the migration process.
      QnA: https://discord.com/channels/845645228467159061/1338849908211580969 (invite)
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/checkstyle/
    idea_list_url: https://github.com/checkstyle/checkstyle/wiki/Checkstyle-GSoC-2025-Project-Ideas


  - organization_id: 176
    organization_name: dora-rs
    no_of_ideas: 4
    ideas_content: |
      
     
      Project #1: Robot Data Collection improvement.
      Description The robot data collection is expensive and hard to manage. The primary objective of this project is to create an end to end tutorials with affordable robot kit, specifically designed around the Dora platform, and utilize it to establish a comprehensive robot dataset collection system. This system is designed to facilitate the collection of data, which can be used for various applications such as robotics research, algorithm development, and model training.
      Expected Outcomes
      Designing and 3D printing the robot components. The robot will be constructed using 3D - printed components made from low - cost materials. This approach not only reduces the overall cost of the robot but also allows for easy customization and modification. The use of 3D printing enables the creation of complex geometries tailored to the specific requirements of the data collection tasks. This can be done with help from other open source projects such as Koch robot arms.
      Creating the Mojoco robot model. A Mojoco robot model will be created based on the robot arm. Mojoco is a high - performance physics simulation engine that provides accurate and efficient simulations. By creating a Mojoco model of the robot, we can collect data from the simulated model. This simulated data can serve as a baseline or supplement to the data collected from the real robot, and can also be used for preliminary testing and algorithm development in a controlled virtual environment.
      Implementing data collection nodes in Dora. The system will be programmed to collect a variety of data from the real robot, including the robot's joint angles, rotational speeds, and pose information. The data format can follow the ARIO unified data format or the LeRobot Dataset format.
      Create tutorials and documentation that will help the community replicate the data collection system.
      dataset collected will be shared within the open source community.
      Resources.
      https://imaei.github.io/project_pages/ario/
      Skills required/preferred. Python, CAD, DORA
      Difficulty rating. medium
      Expected size: 350h
      Mentors: bding@dora-rs.org, huangyu@dora-rs.org

      ~~~~~~~~~~
      Project #2: Improve Dora-Lerobot Demo Tutorial
      Description In robotics education, a gap often exists between theoretical knowledge and practical application. Dora-Lerobot bridges this gap by integrating hands-on learning with AI-powered, pre-trained models. Its primary goal is to lower the barrier to entry in robotics, enabling everyone to master end-to-end control.
      Recently, support for the SO-ARM100, a low-cost robotic arm, was added to Dora through its driver. However, there is currently no end-to-end tutorial available for using this arm. Tutorials and documentation are critical for making the project more accessible to new users.
      The goal of this project is to improve the Python-based tutorial for using the SO-ARM100 robotic arm with Dora-LeRobot, enabling users to easily get started and contribute to the ecosystem.
      Expected Outcomes
      Fix issues and add missing code so that Dora-LeRobot can be run with SO-ARM100 successfully.
      Writing detailed setup and usage tutorials.
      Implementing code for calibration, control, training, and inference.
      Creating video tutorials and improve based on community feedbacks.
      Creating test plan for user testing to ensure the tutorial is easy to follow.
      Resources.
      https://github.com/dora-rs/dora-lerobot/tree/main
      https://github.com/huggingface/lerobot
      Skills required/preferred. Python, Rust, DORA
      Difficulty rating. medium
      Expected size: 350h
      Mentors: shavtao@gmail.com, bding@dora-rs.org

      ~~~~~~~~~~
      Project #3: Enhancing Debugging with Rerun
      Description Currently, debugging Dora nodes has several limitations. There's limited real - time visibility as debug messages are only accessible from log files, forcing developers to halt the robot application, access and analyze logs, which is time - consuming and lacks real - time insights. There's also a lack of integrated visualization, making it hard to correlate debug messages with sensor data processing like LiDAR or camera feeds, and thus difficult to determine if issues in object detection are due to sensor data or the algorithm. Additionally, the absence of a unified real - time debugging solution leads to a fragmented debugging experience, with developers relying on multiple tools and techniques, making it more challenging to identify and fix issues efficiently.
      Expected Outcomes
      Improving the dora-rerun node to collect real-time debug messages. Improve dora-rerun node to allow rerun viewer to collect each node real time debug message with python or rust.
      Displaying sensor data processing examples. Create sensor data processing(e.g., LiDAR, camera feeds) python or Rust example code and documentation to show how to use debug messages.
      Visualizing robot trajectories and arm poses. Rerun will be used to visualize robot trajectories, arm poses, or other relevant data in the same rerun window and how to setup with detailed tutorials.
      Creating detailed tutorials. Create detailed tutorials on how to set up Rerun for debugging Dora nodes. This makes it easier for developers, especially those new to Rerun or Dora, to start using this debugging tool effectively.
      Resources.
      https://github.com/dora-rs/dora/tree/main/node-hub/dora-rerun
      Skills required/preferred. Rust, DORA
      Difficulty rating. medium
      Expected size: 175h
      Mentors: shavtao@gmail.com, bding@dora-rs.org

      ~~~~~~~~~~
      Project #4: Support additional hardware
      Description Dora currently lacks a library for many widely used robots such as UR5, Franka, .... This project aims to extend Dora’s capabilities by adding support for Universal Robots’ UR5 collaborative robots and more. The primary focus is to develop better hardware integration within the Dora framework. By doing so, it will empower developers to more effectively integrate and utilize Dora in combination with their existing assets, opening up new possibilities for seamless robotics development and enhanced productivity.
      Example Expected Outcomes
      Developing the Rust library for UR5 control. A well-documented, efficient, and effective Rust library that interfaces with UR5 cobots through Dora.
      Integrating with URSim. The project will include an implementation that demonstrates control of the UR5 robot model and its gripper within the URSim virtual machine environment.
      Porting the test_move example to Rust. A Rust version of the test_move example (originally in Python) will be developed, providing a concrete demonstration of how to use the library with Dora.
      Creating comprehensive documentation and tutorials. Comprehensive documentation and usage tutorials that guide developers on UR5 support within their robotics projects using Dora.
      Resources.
      (https://github.com/UniversalRobots/Universal_Robots_ROS_Driver/blob/master/ur_robot_driver/scripts/test_move)
      https://github.com/dora-rs/libfranka-rs. for reference on interfacing with robotics hardware using Rust
      Skills required/preferred. Rust,C++, Python, DORA
      Difficulty rating. hard
      Expected size: 350h
      Mentors: bding@dora-rs.org, shavtao@gmail.com
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/dora-rs/
    idea_list_url: https://github.com/dora-rs/dora/wiki/GSoC_2025


  - organization_id: 177
    organization_name: freifunk
    no_of_ideas: 17
    ideas_content: |
      
      
      Live Protocol Overhead Dissector/Statistics for Gluon
      Generate live protocol overhead visualizations of batman-adv packet subtypes and layer 2 multicast traffic in Gluon.
      Linus Lüssing
      medium 175 hours
      GSoC 2025

      The overall goal is to gather a better insight into the overhead details of a Gluon / batman-adv based mesh network. To be able to evaluate past protocol changes and to spot areas for future improvements regarding protocol overhead. A live view should also help to monitor and alert on unexpectedly high protocol overhead in a real world setup.

      A package/daemon on a Gluon mesh node needs to collect statistics on the protocol’s “background noise” on both the upper interfaces as well as the underlying mesh interfaces and shall do so with a configurable list of packet types based on the pcap-filter syntax. And must provide this to a server. This has already (mostly) been implemented via:

      gluon-statistics-mcast package:
      https://github.com/freifunk-gluon/gluon/pull/2367
      bpfcountd:
      https://github.com/lemoer/bpfcountd/
      this is used by gluon-statistics-mcast for getting the
      this uses libpcap + a (not yet upstream) batman-adv dissector patch
      The first and next steps would be to rebase, update with the needed changes to be able to be merged upstream and test it:

      libpcap: “Add support for B.A.T.M.A.N. Advanced #980”: https://github.com/the-tcpdump-group/libpcap/pull/980
      add the new batman-adv multicast packet type to this PR
      add support to dissect within TVLV enabled batman-adv packet types (needs BPF code which reads the TVLV length field and adjusts the inner header offsets with it)
      (try to) persuade libpcap to merge it (they haven’t merged it in three years yet, with no additional feedback on why not)
      submit the updated version to OpenWrt: https://github.com/openwrt/openwrt/blob/main/package/libs/libpcap/patches/300-Add-support-for-B.A.T.M.A.N.-Advanced.patch
      Gluon: “gluon-statistics-mcast: adding initial package #2367”: https://github.com/freifunk-gluon/gluon/pull/2367
      update it with the changes requested in the ticket, get it merged upstream in Gluon
      add dissectors for the new batman-adv multicast packet type
      replace gluon-neighbor-info and respondd usage in general with providing the (compressed) statistics data directly via HTTP (while keeping the previous JSON format?); only set some flag (and/or URL? http path?) in respondd “nodeinfo” (or “statistics”?) provider so that a respondd querier would be informed about where/what extra data to get and to make this PR obsolete: https://github.com/freifunk-gluon/packages/pull/256
      Then deploy and run this on either a WiFi router with enough RAM + CPU power, capable of Gluon, or an x86 VM.

      Then either add to requestd or implement something new (usable on Debian?) for the gathering side:

      from responses to general respondd queries, determine which nodes have the gluon-statistics-mcast package installed
      query this JSON formatted data via HTTP from the nodes determined in step 1); do this a lot less frequently than the general respondd queries (e.g. only every 30min?)
      parse and push this data into an InfluxDB (or Prometheus?)
      Create live graphs in Grafana from InfluxDB data (or Prometheus?)
      You can get access to a Requestd/InfluxDB/Grafana server at Freifunk Lübeck for real world statistics measurements in a network with a recent Gluon / batman-adv version.

      (Optional) Bonus Milestones:

      Likey all very much out of scope - but if you’d be interested about anything of this in particular, we could talk about it :-).

      reduce bpfcountd overhead through eBPF? Ideally this would be a feature in libpcap, to be able to count packets through eBPF in kernelspace, without needing to copy them to userspace, while staying easy to customize & use through libpcap’s pcap-filter syntax; another option would be to replace libpcap usage in bpfcountd with one’s own, new eBPF counting library which still uses/reimplements the libpcap pcap-filter syntax parsing (difficulty: hard?)
      add dissectors for OLSRv2 (+ Babel?) and compare protocol overhead between these with batman-adv (though currently no Gluon Babel setup active, size/status of Gluon with OLSRv2 at FunkFeuer Graz unknown/WIP?
      measure various batman-adv tweaks:
      measure ARP overhead reduction with pending batman-adv DAT DHT/Cache split and increased DAT DHT timeout? also needs rebase) https://patchwork.open-mesh.org/project/b.a.t.m.a.n./cover/20190407112320.32021-1-linus.luessing@c0d3.blue/
      measure multicast overhead with batctl multicast_forceflood 1 (disables batman-adv multicast packet type and unicasted multicast packets)
      might be useful to have a package that allows configuring these on all nodes, without requiring full SSH access on all these nodes, e.g. something like the gluon-authorized-keys package but with a lot less privileges (implement a site.conf list option in gluon-authorized-keys which contains allowed files to execute, which would disallow ash usage over SSH?)
      Milestones
      GSOC COMMUNITY BONDING
      Conceptual work should be finished.
      The contributor have a repository, know how to work with the community.
      The applicant should know the community.
      GSOC MIDTERM
      Everything listed here has to be reviewed and merged by midterm.
      No exceptions to that. Changing the goals is possible together with mentors.
      Yes, that includes tests and documentation.
      GSOC FINAL
      Everything has to be reviewed and merged.
      Including tests and docs, again.
      
      
      
      
      
      
      ~~~~~~~~~~
      Adding Wi-Fi Support to QEMU Simulations in LibreMesh
      Adding the wireless interfaces to the LibreMesh virtualized environemnt in QEMU is expected to greatly improve its continuous testing.
      Javier Jorge
      medium 350 hours
      GSoC 2025GSoC
      Synopsis
      LibreMesh relies on continuous testing to ensure its robustness across various network conditions and hardware setups. Currently, testing new firmware images lacks a standardized method to include Wi-Fi simulations within a virtualized environment. This project aims to add Wi-Fi support to existing QEMU simulations for LibreMesh, allowing near-realistic network testing using virtual Wi-Fi interfaces. By leveraging the mac80211_hwsim module and integrating existing OpenWrt-friendly virtual Wi-Fi tools, we can enhance testing automation and reproducibility.

      Benefits to the Community
      Improved Testing Framework: This project will enable LibreMesh developers to run “almost real” tests in a virtualized environment, improving debugging and validation before deploying changes to physical hardware.
      Enhanced Automation: By integrating virtual Wi-Fi support into QEMU, developers can automate complex test scenarios without requiring physical routers.
      A set of scripted tests that can be run on real hardware: Currently, real tests on physical hardware are performed manually at each release. With this new set of test scripts for QEMU and Wi-Fi, many tests will be automated and easily adapted to real hardware.
      Collaboration with OpenWrt: Given that OpenWrt is also working on virtual Wi-Fi support, this project can align efforts with the broader open-source networking community, benefiting multiple projects.
      Lower Barrier to Entry: New contributors will find it easier to test their changes without needing specialized hardware.
      Deliverables
      Initial Research & Setup

      Review existing tools (mac80211_hwsim, vwifi, OpenWrt test frameworks).
      Set up a basic QEMU-based LibreMesh test environment.
      Virtual Wi-Fi Interface Integration

      Configure and validate mac80211_hwsim in a QEMU LibreMesh instance.
      Enable multiple virtual Wi-Fi interfaces to simulate different network conditions.
      Script Development for Network Testing

      Develop and document a set of scripts using rpcd interfaces for network diagnostics.
      Implement automated tests using the virtualized Wi-Fi environment.
      Integration with Existing LibreMesh Testing Framework (Weeks 7-8)

      Ensure the developed solution integrates seamlessly with the current LibreMesh testing setup.
      Validate compatibility with different network topologies.
      Documentation and Final Testing (Weeks 9-10)

      Create detailed documentation for developers on setting up and using the virtual Wi-Fi testing environment.
      Final debugging and submission of the project for review.
      blog posts to spread the news.
      Related Work
      mac80211_hwsim: A kernel module that emulates multiple Wi-Fi radios, widely used for testing wireless protocols.
      VWIFI (Raizo62/vwifi): A project focused on virtual Wi-Fi interfaces, particularly OpenWrt-friendly solutions.
      Estimated Timeline & Milestones
      Week	Task	Deliverable
      May 5 - May 29	Intro to QEMU, research and setup QEMU-based LibreMesh instance	First post in Freifunk’s blog, Suggestions to improve libremesh documentation
      May 29- Jun 23	Configure mac80211_hwsim and enable virtual Wi-Fi	QEMU instance with functional Wi-Fi simulation
      Jun 23- July 14	Develop network testing scripts	Scripts for automated testing using rpcd
      July 14 MID TERM EVALUATION	 	 
      July 14 - Aug 11	Integrate with LibreMesh testing framework	Testing capabilities report, expanded current RPC tests to run against QEMU
      Aug 11 - Aug 25	Final documentation and debugging	Documentation in LibreMesh repo and blog posts in Freifunk’s blog
      September 1 FINAL EVALUATION	 	 
      This project will provide LibreMesh with a powerful new tool for virtualized testing, improving both development efficiency and deployment reliability.

      The communication with mentors and LibreMesh community is absolutely necessary for the success of the project. For this, the applicant will be required to write 3 blog posts, one at the beginning, one in the middle, and one at the end of the project, on Freifunk’s blog. Also, the applicant is expected to join the LibreMesh mailing list and chat channel, announce there the advancements and seek for feedback. Weekly meetings will be held with the mentor to ensure the success of the project.
      
      
      
      
      
      ~~~~~~~~~~
      Quantum Safe VPN Mesh
      Secure a WireGuard mesh network against quantum computers
      Paul Spooren
      high 350 hours
      GSoC 2025

      Quantum computers pose a threat to existing cryptographic algorithms, including those used in VPNs. This project aims to develop a quantum-safe VPN mesh network using WireGuard on OpenWrt. The core component, unetdunetd, is an OpenWrt daemon that creates mesh networks using WireGuard. However, WireGuard itself is not quantum-safe. To address this, the project will extend unetd to support injecting pre-shared keys generated or exchanged through quantum-safe methods. Additionally, unetd will be enhanced to incorporate peer properties that influence routing decisions, ensuring policies enforce routing over specially strengthened links.

      Tests will be performed in the german Q-net-Q research network, which is part of an european initiative to develop a quantum-safe communicationn. The project will be guided by the mentors and parts of the Q-net-Q team.

      Quantum Safe means in this case that pre-shared keys are available at both ends of the VPN tunnel, allowing an additional layer of security by symetrically encrypting the data. To generate these keys either Quantum Key Distribution (QKD) and/or Post-quantum Cryptography (PQC) is used. The detailed generation of these keys is out of the scope for this project and will be guided through the mentors, no prior knowledge is required.

      Milestones
      GSOC COMMUNITY BONDING
      Setup development environment of multiple OpenWrt instances.
      Deploy unetd on OpenWrt instances and document the process.
      Run Rosenpassrosenpass container on OpenWrt instances and document the process.
      unetd codebase understood sufficiently to extended injection of pre-shared key feature.
      GSOC MIDTERM
      Reproducible Rosenpass on OpenWrt setup documented and tested
      unetd extended to allow injection of pre-shared keys.
      Design of unetd peer properties, to influence routing decisions.
      GSOC FINAL
      Working unetd with pre-shared key injection feature.
      Working unetd with peer properties influencing routing decisions.
      Documentation of the project and how to use it.
      Presentation of the project including a demo to the OpenWrt community and Q-net-Q members.
      
      
      
      
      
      
      ~~~~~~~~~~
      Change SSID when servers are not accessible
      In larger installations there will be many routers at different parts of a building on different channels, and one these may not be able to reach to the project's servers, and consequently also not issue IP numbers. Users changing their location may interpret this as an instability of the Freifunk and not attempt to fix what may be a loose cable on their side. The routers should change their SSID to an indication that it needs help.
      Steffen Möller
      easy 175 hours
      GSoC 2024

      In larger installations there will be many routers at different parts of a building on different channels, and one these may not be able to reach to the project’s servers, and consequently also not issue IP numbers. Users changing their location may interpret this as an instability of the Freifunk and not attempt to fix what may be a loose cable on their side. The routers should change their SSID to an indication that it needs help, so local organisers can find the issue earlier and error reports improve. The meshing between routers should not be affected.

      This project idea is not new, above shows a respective suggestion from the community. But yet no solution has been integrated with the regular Freifunk images. The solution from 2016 may stimulate a better implementation.

      Milestones
      GSOC COMMUNITY BONDING
      Conceptual work should be finished.
      The contributor have a repository, know how to work with the community.
      The applicant should know the community.
      GSOC MIDTERM
      Everything listed here has to be reviewed and merged by midterm.
      No exceptions to that. Changing the goals is possible together with mentors.
      Yes, that includes tests and documentation.
      GSOC FINAL
      Everything has to be reviewed and merged.
      Including tests and docs, again.
      
      
      
      
      
      
      ~~~~~~~~~~
      OpenWrt integration with bird2 (UCI and LuCI) for BGP and Babel protocols
      Develop BIRD2 integration for OpenWrt, including support for Babel and BGP
      IlarioBruno
      high 350 hours
      GSoC 2025GSoC

      Abstract
      The project’s proposal consists on developing OpenWrt’s integration with bird2 to support the BGP and Babel routing protocols via UCI and LuCI in a way that is useful for community networks. The project aims to build upon previous work on bird1, which reached end of life in 2023, aiming to modernize and maintain interoperability for community networks. The plan outlines phased milestones to implement, test, and document bird2’s integration, ensuring robust support for both routing protocols while preparing for future transitions, including bird3.

      Context
      Years ago, Eloi Carbó successfully participated in the 2014 edition of Google Summer of Code to improve integration of Bird with OpenWrt. The code was retired on 2023 because bird1 reached end of life in 31 Dec 2023, see commit fa136b7.

      Bird version 2 comes also with Babel mesh routing protocol support. The Babel Routing Protocol (RFC6126) is a loop-avoiding distance-vector routing protocol that is robust and efficient both in ordinary wired networks and in wireless mesh networks.

      The overall idea of this project is to:

      Upgrade from bird1 to bird2
      Do some maintenance on existing code
      Include Babel as a protocol and make it interact with BGP both via UCI and LUCI
      Why is relevant to maintain and upgrade OpenWrt Bird bindings?
      Bird is relevant software, it is used in production for BGP in large scale deployments (see evidence1 and evidence2 via bird-users mailinglist).

      It is also appreciated by community networks. For example, the following internship report, used the bird1-openwrt package to enable community networks interoperability through BGP. In fact, in guifi.net we have some nodes that use the bird1-openwrt package to make interoperability between the backbone network in BGP and the mesh BMX6 networks. In fact, in the following table, we show some relevant networks that work with BMX6 but are reachable from guifi.net through BGP’s Bird:

      nodes	zone
      23	Sant Andreu
      41	Sants
      12	Raval
      14	Vallcarca
      : Number of mesh nodes in Barcelona per sub-zone as of 2025-02-01

      Why is relevant to add Babel?
      There are about a hundred nodes (see previous table and related links) running BMX6 in guifi.net, but BMX6 software is unmaintained (last code commit d8869ec is from 2018). In fact, it was removed from openwrt routing repository in 2023 (see #963); that’s why community networks are deciding migrations to BMX7 or Babel. BMX7 was unmaintained for long time, but looks like it came back in 2024. We believe Babel provides a distance-vector easy to use alternative to BMX6 and BMX7. It has two maintained implementations: (1) lightweight and experimental Babeld; and (2) heavier but production-ready Babel inside the Bird software.

      Relevant deployments of Babel
      Babeld is what communities choose in general when they go for the Babel protocol, but comes with some problems: (1) the CLI is very limited, (2) it is not easy to debug on it and (3) it has no WebGUI at all (this is just a LuCI status page that at least is not working in OpenWrt 23.05.5 release). Babeld is used as a default configuration for LibreRouter, and it is used in at least a relevant deployment in Quintana Libre of around 60 nodes.

      Bird2 OpenWrt package (without UCI and LuCI) is being used in a small community network of 9 nodes with good results.

      About the upcoming bird3
      On December 2024, a new bird3 package appeared in openwrt-routing repository.

      Working on bird2 OpenWrt integration is still relevant for the upcoming bird3, in the official announcement they said:

      There are some minor breaking changes in config and CLI, most notably unified route attribute names to the filter variant. We are expecting to add a compatibility mode for the CLI. Anyway, it should be possible to reuse most of the configs and CLI scriptings from BIRD 2.

      It’s also good to stay on bird2, specially, if we want to be able to run it on legacy and very old devices that are in the network:

      The memory consumption has gone up significantly. We are still working on reducing the memory footprint and the next versions should be better in that.

      Resources
      Bird2 babel docs
      Bird2 bgp docs
      OpenWrt package bird1 OpenWrt, project’s extra documentation
      User guide on babeld
      OpenWrt package babeld
      OpenWrt package of luci app for babeld
      Babel IETF standard
      [BSc] Interoperability between classic infrastructure and Libre-Mesh networks in Guifi.net. Gioacchino Mazzurco, 2015, Università di Pisa
      [MSc] LEDE Firmware optimization for wired deployments using BGP and BMX6 for routing by enhancing and extending Bird Daemon’s configuration and UI integration. Eloi Caso, 2017, Universitat Oberta de Catalunya
      GSoC 2025 plan
      Milestones
      Here are the milestones to track the project completion.

      During GSOC Community Bonding

      Blog post announcing GSOC starts
      Blog post that summarizes end of GSOC Community Bonding Phase
      During GSOC MidTerm

      Bird2 BGP is configurable through UCI
      Bird2 BGP is configurable through LUCI
      Blog post that summarizes end of GSOC MidTerm
      During GSOC Final

      Bird2 Babel is configurable through UCI
      Bird2 Babel is configurable through LUCI
      Bird2 BGP and babel working at the same time in the same device
      Blog post that summarizes end of GSOC Final
      GSOC Community Bonding
      Tasks for phase 1 (May 4 - 28), introducing the gsoc contributor to the project.

      Get familiar on OpenWrt version 23.05.x and its BuildRoot
      Get familiar on how LuCI works
      Get familiar on how ubus works
      Get familiar on how Babel routing protocol works
      Get familiar on how BGP routing protocol works
      Learn to develop a basic openwrt-routing package
      Get familiar with existing codebase of bird1-openwrt in Lua and shell
      Get familiar with test frameworks that could fit well with OpenWrt environment
      Document the entire process at least with a blog post
      GSOC MidTerm
      Tasks for phase 2 (May 29 - July 10), work mainly on BGP but start approaching Babel.

      Integrate and use end to end tests for frontend and backend in the project, to improve code quality and ensure no functionality is lost (specially on the unstable code or most complex UX journeys)
      Set up a small testbed for experimenting the routing protocols
      Adapt configuration syntax changes from BGP from bird1 to bgp bird2
      Upgrade bird1-openwrt code to reach a bird2
      Do code maintenance tasks, minor bugfixes and improvements
      First development iteration on UCI and LuCI bird2 Babel development
      Document the entire process at least with a blog post
      GSOC Final
      Tasks for phase 3 (July 14 - August 21), work mainly on babel and finish project.

      Last development iteration on UCI and LuCI bird2 babel development
      Improve bird2 BGP and Babel integration, ensure it will work for bird3
      Refactor code if needed, so it is easier to maintain
      Document the entire process at least with a blog post
      
      
      
      
      
      
      ~~~~~~~~~~
      Simplify LibreMesh and get it closer to OpenWrt
      Replace some tools developed or just used in LibreMesh with the OpenWrt's counterpart, for stability and quality. Also, develop a light version of LibreMesh more suited for smaller communities.
      Javier Jorge
      medium 350 hours
      GSoCGSoC 2025

      Project objectives
      LibreMesh is composed by a set of modules which configure OpenWrt.

      Over the past few years, OpenWrt has improved massively, and some of the features developed within the LibreMesh modules have been created inside OpenWrt as well. So, the first goal of this project is to migrate from LibreMesh’s own solutions to the OpenWrt’s ones, in order to merge the efforts of the two communities. In some cases, it could be needed to add features to the OpenWrt softwares, and the feasibility of this will be evaluated on a per-case basis.

      Also, the development of LibreMesh’s modules is going on since more than 10 years with a joint effort from several network communities worldwide. Complexity built up and it is time to review it, for checking which code lines can now be spared. So, the second goal of this project is to simplify LibreMesh modules.

      The communication with mentors and LibreMesh community is absolutely necessary for the success of the project. For this, the applicant will be required to write 3 blog posts, one at the beginning, one in the middle, and one at the end of the project, on Freifunk’s blog. Also, the applicant is expected to join the LibreMesh mailing list and chat channel, announce there the advancements and seek for feedback.

      Identified actions
      Some tasks have already been identified, and should be analyzed in the project. More tasks could be identified during the process.

      Tasks for getting closer to OpenWrt (first goal)
      Replace deferrable-reboot with watchcat. Within the José de la Quintana network community, several tools have been developed over the years. Between them, deferrable-reboot is a tool decreasing the need of maintenance of the network, simply rebooting the devices when they lose internet connectivity. This simple solution clearly will not fix real fundamental network issues, but will help in decreasing the annoyance caused by undetected and not-yet-fixed stability issues. Inside OpenWrt, a similar tool named watchcat has been created, and could be used for replacing deferrable-reboot.

      Replacing dnsmasq with odhcpcd. LibreMesh is using dnsmasq (also) as a DHCP server, while OpenWrt is using odhcpcd by default. The migration towards odhcpcd involves checking whether odhcpcd has all the required features, understanding how to use them, and adapting LibreMesh to using them. A reference ticket with already some information can be seen here:

      “Replace dnsmasq by odhcpd”
      Tasks for simplifying LibreMesh (second goal)
      Removing VLAN from Babel interfaces. LibreMesh creates one VLAN interface on top of each physical interface specifically for Babel routing protocol. This is not needed, decreases the maximum transmission unit (MTU) and increases the complexity of LibreMesh. There are two relevant tickets with some information on this:

      “Lets remove unneded vlans from protocol interfaces”
      “Babeld without VLAN does not run on LAN ethernet ports”
      “Support Babeld without VLAN on ethernet interfaces inside br-lan”
      Creating a layer2-only version of LibreMesh. LibreMesh has been designed for scalability. For this, it includes a layer 2 routing protocol -Batman-adv- for managing local networks, together with a layer 3 routing protocol -Babel- for connecting local networks with each other. With this two-layers approach, enormous networks can be created, at the cost of high complexity. But in most cases, communities are smaller than a hundred nodes, and having a complex structure increase the access barrier for community members to debug issues in their network and develop new features. So, a layer2-only version of LibreMesh could be developed. A ticket with some relevant info can be found here:

      “LibreMesh releases: only layer2+3 or both layer2+3 and layer2?”
      Milestones
      May 8 - June 1 Community Bonding Period
      The applicant is expected to:

      buy or gather somehow at least 3 LibreMesh-compatible routers and install a pre-compiled LibreMesh firmware image on them. At least one router model should have a switch that is DSA-supported within OpenWrt. At least one router should not be supported yet by DSA in OpenWrt.
      deploy LibreMesh in a virtual environment.
      compile a LibreMesh firmware image using the BuildRoot method.
      June 2 - July 14 First work period
      Analyze the already identified actions and select the ones that seems feasible and easiest to implement.
      Start implementing them while testing the results on a real testing network composed by at least 3 routers.
      July 14 MID TERM EVALUATION
      July 14 - September 1 Second work period
      Identify new actions that help with simplifying LibreMesh or to get it closer to OpenWrt. Write them down as issues on the lime-packages repository.
      Complete the implementation of the selected actions and test various network configuration to make sure that the solution is solid.
      Propose the changes as one or more pull requests on the lime-packages repository.
      September 1 FINAL EVALUATION
            
      
      
      
      
      
      ~~~~~~~~~~
      Renovate freifunk ICS Collector
      Update to latest libraries and versions, fix timezone issues
      andibraeu
      medium 90 hours
      GSoCGSoC 2025

      Back in 2015 during GSoC we developed this ICS Collector to merge multiple calendars from freifunk communities. The software is quite stable, but needs some updates and renovation, as calendars evolved, too.

      The software should be adopted to latest versions of php and libraries used.

      We also need to find a way to fix timezone issues we run into, when we want to use the merged calendar result. The API should be kept stable.

      Milestones
      Preparation/Bonding
      checkout the repository and try to understand how it works
      find possible library and dependency updates
      identify potential refactorings
      look for updated or new ical libraries
      Coding period
      update or replace libraries
      refactor code and add more tests
      add timezone to single events, if the source contains a timezone


      
      
      
      
      
      
      ~~~~~~~~~~
      Static Social Media Archive Explorer
      Develop a (static) website to display and search an archive of social media posts (e.g. tweets) gathered using Cyd, leveraging both HTML archives and a SQLite3 database.
      andibraeu
      medium 90 hours
      GSoCGSoC 2025

      Idea
      The project aims to create a static website that serves as an archive explorer for our social media posts, which were collected using Cyd. The archive exists in two formats: HTML files and a SQLite3 database. The resulting site should allow users to browse and search through historical posts in a clear, user-friendly interface.

      A key component of the project is to develop an easy-to-use extractor tool. This tool will:

      Process the existing HTML and SQLite3 data,
      Normalize and export it into a common format (e.g., JSON),
      Allow the results to be easily reproduced,
      Enable others to use the tool to set up their own static websites for similar archives.
      Since no new posts will be added, the focus is on efficient data extraction, processing, and client-side search capabilities.

      Milestones
      Milestone 1: Data Extraction and Processing Tool
      Analyze the archive formats (HTML and SQLite3).
      Develop an easy-to-use extraction tool that converts the data into a common format (e.g., JSON), ensuring that the process is reproducible.
      Document the tool and provide clear instructions so that others can use it for their own social media archives.
      Validate data consistency and completeness.
      Milestone 2: Static Website Setup
      Choose and set up a static site generator.
      Create basic templates for listing posts and individual post pages.
      Integrate the processed data into the static site build.
      Milestone 3: Client-side Search Integration
      Implement search functionality using a JavaScript library.
      Pre-index the data during the build process.
      Ensure the search interface is intuitive and responsive.
      Milestone 4: Testing, Optimization, and Deployment
      Conduct testing to ensure data integrity, search accuracy, and overall usability.
      Optimize the site for performance and accessibility.
      Prepare documentation and deploy the static site.
      Extra: Theming Support (Optional)
      If time permits, implement theming support to allow customization of the site’s appearance.
      Ensure that themes can be easily switched or customized via configuration files.
      
      
      
      
      
    
      ~~~~~~~~~~
      VocToWeb: Install and apply customizations
      Develop components to apply customizations to the default VocToWeb
      andibraeuchristian-draeger
      medium 175 hours
      GSoCGSoC 2025

      Voctoweb is the software behind media.ccc.de and used for distributing video recordings of a lot of events. We forked their repo to set up our own video portal, media.freifunk.net. As there was only one user of this software for years, content pages and templates are mixed with the business logic.

      Goal of this project should be: We’re able to set up a new instance of voctoweb and add our own contents, designs, templates and other customizations. When the projects is finished we have a document on how to get your own, independent and customized instance.

      It may be hard to split the original project in a first step. But if we find a way to make it easy for others to customize the installation, that doesn’t matter.

      Milestones
      Preparation/Bonding
      Install your own instance of voctoweb and try to understand how it works
      identify the components to be used for customizations
      Coding period
      merge upstream changes
      identify the general and the customizable parts
      find ways to apply the customizable parts to a default installation
      update media.freifunk.net, maybe use docker based components
      improve documentation on installing voctoweb
      add documentation on how to apply and develop customizable parts
      
      
      
      
      
      
      ~~~~~~~~~~
      Deep Q Network-based Rate Adaptation for IEEE 802.11ac Networks
      Implementation and performance evaluation of reinforcement learning algorithm based on the Deep Q Network approach for MCS rate adaptation in real WiFi networks
      thuehnSankalp Prakash Pawar
      tough 350 hours
      GSoCGSoC 2025

      The goal of MAC-layer Wi-Fi rate adaptation (RA) is to dynamically select modulation and coding scheme (MCS) rate parameters for the transmission of frames to optimize throughput given a varying channel. Conventional Wi-Fi RA algorithms rely on heuristics from older IEEE 802.11 amendments, which can struggle in denser, more complex networks. As Wi-Fi environments become more crowded, machine learning techniques, especially reinforcement learning (RL), are gaining attention for their potential to improve rate selection [3].

      RL addresses the exploration-exploitation tradeoff by continuously exploring actions and exploiting the best-performing ones. This dynamic approach can adapt to real-time network conditions, optimizing throughput, and improving overall performance. Unlike traditional heuristics, RL can evolve, offering a more flexible and robust solution for modern Wi-Fi networks. However, even with the promising potential of applying RL-based approaches for WiFi RA, there are limited investigations that offer an in-depth performance evaluation for real IEEE 802.11 networks using commercial off-the-shelf (COTS) hardware.

      The objective of this project is to investigate the use of Deep Q Networks (DQN) for Wi-Fi RA. In [2], R. Queirós et al. demonstrated the effectiveness of a DQN-based RA algorithm in an IEEE 802.11n network through simulation. Building on this work, this project aims to extend the algorithm for the IEEE 802.11ac standard, which involves a relatively larger action space. The implemented algorithm will be evaluated using an experimental toolchain based on the Open-source Resource Control API (ORCA) [1] which enables user space implementation of novel WiFi RA algorithms and their comparison. ORCA is a kernel-user space API for the Linux-based OpenWrt OS. Performance evaluation will include comparing the DQN-based RA algorithm and variants of Minstrel-HT based on metrics such as throughput.

      Milestones
      GSOC COMMUNITY BONDING
      Primer on existing Wi-Fi RA algorithms and their limitations (especially in dense environments).
      Gained hands-on experience using ORCA to learn about its control and monitoring capabilities for user space research on WiFi resource control for OpenWrt-based WiFi nodes.
      Overview report on reinforcement learning-based rate adaptation techniques, focusing on Deep Q Networks (DQN).
      GSOC MIDTERM
      Implemented the core DQN-based RA algorithm for the action space (MCS rates), state space (RSSI), and reward (expected throughput) using TensorFlow or an appropriate RL library.
      Tested the initial algorithm using a testbed involving an RF-isolated single-link Access Point (AP) and Station (STA) setup.
      Defined possibilities to tune hyperparameters (learning rate, discount factor, etc.) for stability and performance.
      Designed experiment plan with details on traffic flows and channel scenarios.
      GSOC FINAL
      Completed deploying a desk setup consisting of a single-link with AP and STA using IEEE 802.11ac Conducted measurements using the DQN-based RA algorithm and state-of-the-art Minstrel-HT based on the experiment plan.
      Performed statistical analysis of measurement data and visualization using libraries such as matplotlib.
      Improved the DQN-based RA algorithm based on analysis results.
      Presented a demo to highlight the potential performance improvements using the DQN-based RA algorithm.
      Published comprehensive source code and project documentation.
      Resources
      [1] Open-source Resource Control API for real IEEE 802.11 Networks
      [2] Wi-Fi Rate Adaptation using a Simple Deep Reinforcement Learning Approach
      [3] SmartLA: Reinforcement Learning-based Link Adaptation for High Throughput Wireless Access Networks
      
      
      
      
      
      ~~~~~~~~~~
      
      Freifunk Fiber Backbone over 100G
      Running Freifunk Fiber Backbone Links via Mellanox 100G Switches on OpenWrt
      schuzathuehn
      midrange 350 hours
      GSoCGSoC2024

      Current Freifunk Community networks across Europe are expanding their wireless P2P backbone infrastructure to wired fibre links, hence capacities beyond 10GBit/s are achievable. Today’s switching hardware can be categorised into three design approaches: - Switch Abstraction Interface (SAI) [1] which is leveraged by SONiC (NOS) [2] - OF-CONFIG [3] which enables to configure the forwarding plane of Broadcom-based switches - Switchdev (Linux kernel API [4]), which could be leveraged by the Distributed Switch Architecture (DSA) [5]

      Moreover, other approaches exist to expose the packet handling/forwarding into the user space

      DPDK/VPP interface that would require a significant re-implementation of the Freifunk network stack and features such as olsrd/batman/babel routing daemons. The flexible switchdev Linux kernel API builds upon standard Linux tools such as IP etc. this enables Freifunk communities to code as well as add features running atop a classical Linux-based system also on devices beyond 10 Gbps interfaces. Since NVIDIA Mellanox Spectrum II switches implement the Linux kernel switchdev API, they seem to be a reasonable choice to achieve this goal.
      Accordingly, the goal of this project is to port Freifunk/OpenWrt [6] OS to the Mellanox Spectrum II-based switch[7] hardware - in such a way, that the ONIE [8] bootloader triggers an OpenWrt boot, daemons such as olsrd/batman/babel routing daemons can run as usual, and (Q)SFP-based ports are deployable on fiber links.

      Resources
      [1] https://github.com/opencomputeproject/SAI
      [2] https://sonic-net.github.io/SONiC/
      [3] https://github.com/openvswitch/of-config
      [4] https://www.kernel.org/doc/html/latest/networking/switchdev.html
      [5] https://www.kernel.org/doc/Documentation/networking/dsa/dsa.txt
      [6] https://openwrt.org/
      [7] https://github.com/Mellanox/mlxsw/wiki
      [8] https://opencomputeproject.github.io/onie/
      Milestones
      DTS Integration for at least Mellanox Spectrum II-based switches in OpenWrt
      add new OpenWrt “Mellanox” target with ONIE bootloader support
      SFP+ p2p 100G link setup test on desk
      PREPARATION/BONDING
      Understanding of the OpenWrt build environment
      Understanding of the different Switching-based Architectures such as switchdev, SAI, OF-CONFIG
      Understanding of ONIE and Linux OS bring-up process
      Coding Period
      Porting Mellanox Switch with Sectrum II chipset to OpenWrt
      Add dedicated Mellanox target to the Freifunk/OpenWrt device set
      Evaluation 100G SFP+ fiber ports
      
      
      
      
      
      ~~~~~~~~~~
      
      OpenWrt Google Coral board support
      Integration of Google Coral board in Openwrt
      schuza
      tough 350 hours
      GSoCGSoC 2025

      The Coral Board integrates a Google Coral Edge Tensor Processing Unit (TPU) as Mini PCIe Accelerator [1], M.2 Accelerator A+E key or via USB. The TPU can be leveraged to run TensorFlow Light models on embedded systems. The goal is to integrate the board and environment into the OpenWrt build environment [2].

      Moreover, within the GSoC project, the task is to come up with a simple example [3] to demonstrate the capabilities of the Coral board. Thus, the goal is to develop and evaluate some use cases such as device fingerprinting etc.

      Accordingly, the participant will first integrate the board into the OpenWrt environment, design and describe possible use cases, and realize a use case that shows the benefits of the TPU.

      Resources
      [1] https://coral.ai/products/pcie-accelerator
      [2] https://openwrt.org/
      [3] https://trac.gateworks.com/wiki/TPU
      [4] https://coral.ai/docs/edgetpu/models-intro
      Milestones
      Integration plan for the Coral board in the OpenWrt build environment
      Integration of the tools and drivers into OpenWrt
      Description of different use cases that leverage the capabilities of the Google Coral Edge Tensor Processing Unit (TPU)
      Implementation of a dedicated use case that demonstrates the benefits of the TPU
      PREPARATION/BONDING
      Understanding of the OpenWrt build environment
      Understanding of convolutional neural networks (CNN) and frameworks
      Coding Period
      Integration of the Coral board support into OpenWrt
      Implementation of a use case
      Evaluation of the use case
      Demonstration of the benefits
            
      
      
      
      
      ~~~~~~~~~~
      
      Data-Driven Analysis of Rate Adaptation Using Machine Learning on Traces from a Real IEEE 802.11 Mesh Deployment
      thuehnprashiddhath
      high 350 hours
      GSoC 2025


      Rate Adaptation (RA) plays an important role in deciding the performance of a WiFi link. As WiFi operates within the limited and unlicensed ISM band, it is highly prone to interference. Newer standards of IEEE 802.11 offer faster Modulation and Coding Scheme (MCS) rates, higher bandwidth and more spatial stream, increasing the number of possible transmission configurations. However, efficiently navigating this growing search space for optimal rate selection remains a challenge. To address this challenge, we leverage data-driven machine learning techniques, such as LSTMs, to navigate the search space efficiently. Analyzing RA traces from a real rural ISP network could help us learn which data rates perform well and which do not across diverse environments. The access points run OpenWrt OS, based on Linux, with the ORCA API for monitoring frame transmissions and control of RA parameters. The details of the API and the trace format has been provided under Resources for Proposal.

      This project is positioned as a research initiative, exploring the following key questions:

      Can RA traces be effectively analyzed as time-series data?
      Are data rates inherently correlated, or are they primarily influenced by environmental factors?
      How effectively can historical RA data (RSSI and TX status) be leveraged in an LSTM model for optimal data rate prediction?
      The optimisation challenge in RA is framed as selecting the optimal data rate from a set of available options, where the best choice can be highly dynamic and fluctuate every 20-50ms. This rapid variability is influenced by factors such as channel conditions, interference, and device mobility, making real-time prediction crucial for maintaining optimal performance. We have real ISP traces from the Linux mac80211 subsystem of mesh access points, providing insights into the performance of data rates across different environments. The key challenge lies in accurately modelling with the limited information exposed to us, capturing the diversity of the channel environment for precise data rate predictions.

      Resources for Proposal
      IEEE 802.11 Rate Adaptation
      ORCA API Paper
      Inferring ORCA Trace Lines
      ORCA Trace Snippet
      Milestones
      GSOC COMMUNITY BONDING
      Knowledge on the basics of IEEE 802.11 Rate Adaptation.
      Familiarity with the ORCA API traces.
      Defined structured plan for data analysis and ML model development including data selection and preprocessing.
      GSOC MIDTERM
      Analysed (temporal) data rates correlation.
      Identified and engineered features to effectively characterise the wireless channel.
      Implemented a functional LSTM-RA model with preliminary trace evaluation.
      GSOC FINAL
      Evaluated LSTM on traces from selected productive Freifunk Mesh and Access deployments.
      Documented source code and project for future reference.
      Optional
      Implementation of LSTM RA for real WiFi access points using RateMan and ORCA.
      
      
      
      
      
      ~~~~~~~~~~
      
      uMesh: New mac80211 architecture for faster WiFi mesh networks
      Implement an alternative wifi mesh network mac80211 mode based on AP WDS<->WDS as successor of IEEE 802.11s
      thuehn
      tough 350 hours
      GSoCGSoC2024


      Our Freifunk community is a foundation of people building networks in a decentralized, hands-on DIY way - distributed, self-made and community managed. The network technology and components span from WiFi mesh routers over P2P 60GHz to fiber optical links.

      The objectives of the uMesh proposal are to plan, build and run fast and robust wireless mesh networks as FOSS based decentralized network infrastructure on current IEEE 802.11ax and upcoming IEEE802.11be chips.

      This goal is achieved through the strategic deployment of a highly dense arrangement of WiFi nodes, each possessing the capability to establish visual connectivity with neighboring nodes. The emphasis is placed on maximizing network interconnectivity, thereby enhancing redundancy and resilience within the system.

      To attain the desired level of interconnectivity, conventional AP (Access Point) station mode proves inadequate due to its inherent limitation in constructing solely star-shaped topologies. This limitation arises from the singular central instance, the AP, rendering the entire network susceptible to failure upon its malfunction. Additionally, under the AP station mode, stations lack the capacity to engage in data exchange amongst themselves. The introduction of the ad-hoc mode in WiFi was conceived as a solution, enabling decentralized and egalitarian data exchange among all stations. However, the universal support for ad-hoc mode was impeded by inconsistent and unreliable implementation across various drivers. Seeking a comprehensive remedy, the 802.11s mode was conceived, purporting to establish a mesh network capable of overcoming the drawbacks associated with traditional station and AP links. Nevertheless, the efficacy of IEEE 802.11s mode has been hindered by a lack of consistent support within Linux kernel wifi device drivers. Notably, disparities in performance between ad-hoc mesh links and conventional station-to-AP links have been observed, with the situation exacerbated by emerging chipsets designed to accommodate ever-increasing data rates, such as IEEE 802.11ax. The exigencies of these advanced data rates necessitate specialized offloading techniques, often not implemented and hence supported in the implementations of IEEE 802.11s, resulting in its neglect or outright abandonment in certain instances or low performance figures in data throughout.

      The LibresMesh community introduced the concept of utilizing Mesh while retaining AP WDS links. As the name implies, this approach ostensibly involves the criticized star-shaped topology where a failure could potentially cripple the network. The distinction lies in the modification of the WiFi stack, wherein all WiFi nodes operate in AP mode. Instead of functioning as APs, they emit beacon frames, which are received by all other nodes. Upon detecting identical SSIDs, the APs establish WDS-Station links with each other, facilitating subsequent communication.

      This configuration can be analogized to each node having an AP interface and connecting, as a Station, to the respective APs of others using the same radio, akin to proprietary products. The key distinction lies in the automated functionality of this process.

      Through this technique, we amalgamate the benefits of the resilient 802.11s mesh while concurrently leveraging the significantly better-maintained AP mode drivers embedded within the WiFi chip. This approach alleviates concerns regarding the potential absence or infrequent implementation of the 802.11s mode in future chips.

      Based on an initial proof-of-conecpt implementation of an AP-WDS-WDS mesh within the uMesh proposal we plan to implement, validate and evaluate the uMesh approach in different productive Freifunk WiFi Mesh networks using IEEE 802.11ax chips and OpenWrt Linux WiFi Routers. Our plan is to elevate the current implementation to a level where the rate negotiation functions properly, and the timeouts of the WiFi link distances operate correctly. Subsequently, we will conduct a performance analysis between the 802.11s and the new WDS-AP-AP mode across various WiFi generations, ranging from older 802.11n to newer standards such as 802.11ax.

      Milestones
      Connecting with the community. This includes joining all relevant channels and in touch with the mentors.
      Work on a hostapd patchset to enable IEEE 802.11n/ac/ax uMesh capabilities.
      Validate and evaluate the throughput performance of IEEE 802.11ac and IEEE 802.11ax uMesh WiFi links.
      Test and ensure the usability of the integration of common Freifunk mesh routing protocols (such as Babel, OLSR, BMW, or Batman) on uMesh interfaces for the purpose.
      Evaluate and publish a community white paper outlining the migration plan from the existing Freifunk Mesh utilizing IEEE 802.11s to the implementation of uMesh.
      Explore options for implementing encryption in this scenario.
      Identify limitations. How many WiFi routers can be connected to each other? Are there any other potential issues?
      GSOC 2024 COMMUNITY BONDING
      The conceptual work is aimed at generating a cohesive proposal for community review. Applicants are expected to participate in all project communication channels and attend periodic online meetings with the community. Additionally, an initial blog post will be authored, inviting proposals for alternative solutions to address identified challenges.

      GSOC 2024 MIDTERM
      In this milestone, the focus is on the aforementioned coding milestones. This involves delving into the hostapd, creating a corresponding patch set for WDS-AP-AP communication, resolving issues, establishing a testbed, identifying limitations. At the end, a blog post will then be published.

      GSOC 2024 FINAL
      Every aspect needs to undergo review and be merged. Comprehensive documentation should be made accessible. Lastly, a conclusive blog post will be authored.
      
      
      
      
      
      
      ~~~~~~~~~~
      WiFi device clustering and fingerprinting
      Realization of an approach to perform WiFi device clustering and fingerprinting
      schuza
      tough 350 hours
      GSoCGSoC2024

      The goal is to create an environment that allows to collect rate control and client capabilities to optimize transmission rate control for client devices. To this end, the project will leverage an interface provided by the supraconex [1] project to collect transmission rate statistics from OpenWrt-based [2] devices. Moreover, the system should also allow to leverage fingerprinting mechanisms based on the client capabilities such as WiFi taxonomy [3].

      Within the project, both approaches are combined to perform a client-based clustering of WiFi devices to create an understanding whether used rates etc. might correlate between different classes of devices. This should allow to further optimize transmission rate algorithms in the presence of handovers etc. Accordingly, a measurement environment needs to be proposed that allows to anonymously collect statistics from different home networks.

      Resources
      [1] https://supraconex.de/
      [2] https://openwrt.org/
      [3] https://github.com/NetworkDeviceTaxonomy/wifi_taxonomy
      Milestones
      Planing of the integration of different mechanisms into the OpenWrt build environment
      Integration of the tools and drivers into OpenWrt
      Design and description of a measurement environment
      Implementation of the measurement environment and necessary tools
      Evaluation of the collected statistics
      PREPARATION/BONDING
      Understanding of the OpenWrt build environment
      Understanding of statistics
      Understanding of WiFi such as transmission rate control and capabilities
      Coding Period
      Implementation of different tools
      Integration of the tools and APIs into OpenWrt
      Realization of the measurement environment
      Collection of privacy-preserving statistics
      Evaluation of the use case
      
      
      
      
      
      
      ~~~~~~~~~~
      qaul RPC user authentication layer
      libqaul <-> GUI protobuf RPC authentication
      MathJud
      medium 350 hours
      GSoCGSoC 2025

      User Authentication Layer
      The GUI communicates via protobuf RPC messaging with libqaul. At the moment there is only one user per node. libqaul is capable of having multi users per node. The GUI <-> libqaul RPC communication shall be organized in sessions. Each session shall be authenticated and encrypted.

      The user authentication layer shall have the following qualities:

      Secure authentication mechanism
      optional user password.
      The system should be zero-config for the user. A password and/or a session key (which can be cached) can be used.
      The system shall support multiple sessions per user & multiple users per node.
      Each session shall be transport encrypted via the Noise protocol.
      This work is also the foundation of a possible web interface in qaul, in which users interact with a node via a web GUI.

      Milestones
      During application period: Create a concept for your project. Discuss your concept with a mentor.
      Define the authentication system
      Define the encryption system
      Define the Protobuf communication structure
      Implement the Sessions.
      Implement the sessions into the CLI application.
      Implement the Authentication system.
      Encrypt the sessions
      Resources
      qaul Protobuf RPC
      About qaul
      qaul is an Internet independent wireless mesh communication app. To communicate P2P directly from device to device and mesh all interconnected devices together. qaul.net interconnects Android, iOS, Linux, MacOS & Windows devices via LAN, Bluetooth and Internet overlay connections.

      qaul is written in rust, uses rust-libp2p internally and has a cross platform flutter GUI.

      https://qaul.net

      Applying for this Project
      Please get in contact with the Mentor @MathJud (via Email or qaul matrix chat #qaul.net:c-base.org) to discuss and prepare your application and project.
      
      
      
      
      ~~~~~~~~~~
      
      
      A modular Wizard for OpenWrt
      Write a wizard to easen the initial configuration of OpenWrt based devices
      akira25Noki
      medium 175 hours
      GSoCGSoC2024

      OpenWrt is a distribution for embedded devices such as WiFi router and similar devices.

      While it gained very much popularity in the rather experienced Tech-Community, its further expansion is damped by the fact, that the further configuration of an OpenWrt-System needs knowledge of Wireless Routers.

      Therefor, commercial OpenWrt-based devices mostly come with a custom UI, which incorporates a setup wizard for initially setting up the device, like it is known from many other firmwares already.

      The objective of the project is, to develop such a wizard, which will ease the initial configuration of a device.

      That wizard will be implemented by using LuCI, which is a framework to build a web interface for configuration and monitoring.

      The to-be-developed wizard should be modular and adoptable to different scenarios by scripting. Thus it can be adjusted to the needs of OpenWrt-based communities, like Freifunk and others.

      Data will be provided by the user through the UI, the configuration of the actual router will be done by shell scripts in the backend.

      Milestones
      Learn how the LuCI client side API works
      Learn how to write rpcd services
      Learn how to set permissions and menu entries
      Discuss an easy and reliable approach to run the wizard on initial startup.
      Make a HowTo for others to help them adjusting the wizard for their needs.
      Preparation/Bonding
      Study the example app to see how it generally works.
      See other apps like luci-mod-freifunk that are more sophisticated to learn more details.
      Get familiar with rpcd and ubus.
      Have a look on the Mock-UI to get an idea of how the Freifunk specific implementation should look like
      Coding period
      Start creating an minimalist UI example and the related backend module
      Verify that example to be functional by testing it on an OpenWrt system
      Create documentation for implementing a specific wizard with code examples
      Once the example UI and its backend script work, start implementing the Freifunk Berlin wizard as specified by the mockups in the Freifunk Berlin Repo
      
      
      IN REVIEW
      This idea is currently in review. Please visit this idea later, too, as there may be some changes.
      
      
      
      
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/freifunk/
    idea_list_url: https://projects.freifunk.net/

  - organization_id: 178
    organization_name: gprMax
    no_of_ideas: 4
    ideas_content: |
      
      1. AI Chatbot for support
      This project will build upon the work done in the previous GSoC where an AI chatbot was developed capable of answering questions and assisting on building models with gprMax. For more information you can check the following link.
      The developed chatbot is based on ChatGPT from OpenAI, therefore it is not free. The current project will aim at building light chatbots using open-source LLMs such as Lama and Deepsheek, in order to provide a free and computationally cheap chatbot for gprMax.
      Moreover, the next generation of gprMax AI chatbots will be capable of building models automatically based on some given instructions. We currently have a set of gprMax commands that we can use to fine-tune open-source LLMs.
      To summarise, this project will aim at building AI chatbots based on open-source LLMs, and fine-tune them not only to answer questions related to gprMax, but also to automatically build full gprMax models based on simple and intuitive instrustions by the user.
      Expected outcomes: A functional AI chatbot based on open-source LLMs capable of automatically developing gprMax models using simple written commands.
      Skills required: Python, machine learning
      Difficulty: Medium
      Length: 350hrs

      ~~~~~~~~~~
      2. Apple Metal port
      The aim of the project is to develop an Apple Metal port. The performance (speed) of the solver is a critical feature as simulations become ever larger and more complex.
      The solver is based on the Finite-Difference Time-Domain (FDTD) method, which has shown significant performance benefits when parallelised – particularly on GPU. The project will require building on the already existing initial Apple Metal port and developing and testing it to ensure all main features in gprMax execute correctly and efficiently.
      Expected outcomes: A working port of the FDTD solver engine for gprMax using Apple Metal.
      Skills required: Python, C
      Hardware required: You must have your own access to Apple hardware.
      Difficulty: Medium
      Length: 350hrs

      ~~~~~~~~~~
      3. AMD ROCm HIP port
      The aim of the project is to develop an HIP port. The performance (speed) of the solver is a critical feature as simulations become ever larger and more complex.
      The solver is based on the Finite-Difference Time-Domain (FDTD) method, which has shown significant performance benefits when parallelised – particularly on GPU. The project will require porting existing code from the PyCUDA-based solver we already have, to the HIP API. There are automated translation tools, such as HIPIFY that can be used to support the process.
      Expected outcomes: An initial working port of the FDTD solver engine for gprMax using HIP.
      Skills required: Python, C
      Hardware required: You must have your own access to an AMD GPU.
      Difficulty: Medium
      Length: 350hrs

      ~~~~~~~~~~
      4. Implementation of a Near to Far Field Transformation (NFFT) calculation and output of relevant information
      The aim of this project is to implement a Near-to-far-field Transformation output process in gprMax based in well known theory and an existing algorithm.
      NFFT outputs are needed when information of the electromagnetic field response is needed far away from the object of interest modelled in detail by gprMax using the FDTD numerical mehtod.Initially we need to implement such a process, which is well documented in the literature and algorithmically available, for objects located in a simple homogenous background. This feature will allow us to easily perform an number of additional modelling tasks like radar cross section (RCS) calcualtions and complicated antenna patterns that are not possible at the moment.
      Skills required: Python
      Difficulty: Medium
      Length: 350hrs
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/gprmax/
    idea_list_url: https://github.com/gprMax/GSoC/blob/main/project-ideas-2025.md


  - organization_id: 179
    organization_name: kro | Kube Resource Orchestrator
    no_of_ideas: 4
    ideas_content: |
  
      1. Metrics and Observability for kro
      Difficulty: Medium
      Issues: #195, #190
      Skills needed: Go, Prometheus, Grafana
      Project goals:
      Implement CEL expression execution metrics with Prometheus integration
      Add performance metrics for resource creation/deletion cycles
      Add Grafana dashboard to visualize kro metrics

      ~~~~~~~~~~
      2. Enhanced Developer Tools and IDE Integration
      Difficulty: Medium
      Issues: #141
      Skills needed: Go, VSCode extension API
      Project goals:
      Create VSCode extension for kro ResourceGraphDefinitions
      Implement syntax highlighting for schema definitions
      Add auto-completion for CEL expressions
      Provide inline validation for resource templates
      Create real-time schema validation

      ~~~~~~~~~~
      3. Examples Validation and Generation in kro.run
      Difficulty: Easy/Medium
      Issues:: TBD
      Skills needed: Go, Web development
      Project goals:
      Build pipelines to expose ./examples content in the kro.run website
      Create example validation framework
      Implement automated testing for documentation examples
      Create categorized example library

      ~~~~~~~~~~
      4. Performance and Scale Study
      Difficulty: Hard
      Skills needed: Go, Kubernetes, Profiling, Performance testing
      Project goals:
      Design and implement performance benchmarks
      Study resource usage patterns under load
      Analyze CEL expression evaluation performance
      Create scale testing framework
      Document performance recommendations
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/kro-or-kube-resource-orchestrator/
    idea_list_url: https://github.com/kro-run/kro/issues/288


  - organization_id: 180
    organization_name: libssh
    no_of_ideas: 3
    ideas_content: |
      
      
      Support for FIDO/U2F keys on the client side
      The server side support (signature verification) and key type definitions are in place so authenticating using these keys from openssh client to libssh server should already work. But the libssh clients can not use the U2F based keys as well as it can not be used to enroll the hardware for authentication with ssh.
      The project should involve adding code paths to create U2F signatures, as well as possibility to test them without the actual hardware in the CI. Here we can get inspiration from OpenSSH, as they provide sk-dummy.so, which can simulate fido/u2f devices. This is packaged in Fedora.
      Difficulty: Medium
      Project length: 350 hours
      Language(s): Good knowledge of C, knowledge about elliptic curves cryptography or u2f is a plus 😉
      Possible Mentors: Jakub Jelen
      References:
      https://github.com/openssh/openssh-portable/blob/master/PROTOCOL.u2f

      ~~~~~~~~~~


      OpenSSH-compatible CLI
      The libssh is provided as a library and only provided binaries are examples implementing either specific client or server examples without an attempt to implement a CLI that can support most of the OpenSSH’s CLI use cases and could be used as a drop-in replacement. The libssh should already support most of the use cases (and if not, new issues should be opened and implemented). Similar exercise can be done for server, but there will many more gaps.
      Difficulty: Medium
      Project length: 350 hours
      Language(s): Good knowledge of C
      Possible Mentors: Jakub Jelen
      References:
      Manual page for ssh: https://linux.die.net/man/1/ssh

      ~~~~~~~~~~


      Improve configuration compatibility with OpenSSH
      The libssh is trying to be compatible with the OpenSSH configuration files to make the experience for our users as smooth as possible to be able to use only one configuration file for both. But OpenSSH configuration file options grow in complexity and we are not catching up with all the corner cases, which sometimes got reported to us. This project is about understanding the SSH configuration, how it is handled by OpenSSH and adjusting the libssh configuration parser to match as closely as possible, including adding a automated test coverage that can compare results with the OpenSSH parser.
      It might be possible to create a fuzzer for the configuration file, that would feed the inputs into both openssh and libssh to verify they result in the same effective configuration.
      Difficulty: Medium
      Project length: 350 hours
      Language(s): Good knowledge of C, understanding of fuzzing testing is a plus
      Possible Mentors: Jakub Jelen
      References:
      Manual page for ssh_config: https://linux.die.net/man/5/ssh_config

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/libssh/
    idea_list_url: https://www.libssh.org/development/google-summer-of-code/
  

  - organization_id: 181
    organization_name: omegaUp
    no_of_ideas: 6
    ideas_content: |
     
      AI Teaching Assistant
      Brief Description:
      We recently added the role of (human) Teaching Assistant, which has the capability of providing code-reviews to students and answering clarification questions asked by students about assignments. In this project we want to create a bot that can answer clarifications and perform code reviews both proactively and upon request. This will help tighten the feedback loop for students so they can grow more rapidly.
      Expected results:
      omegaUp has an AI Teaching Assistant bot that can answer clarification questions and perform code reviews, proactively and upon request.
      Preferred skills:
      Python
      PHP
      MySQL
      LLM Prompt Engineering
      REST APIs
      Possible mentor:
      Aritra8438, heduenas
      Estimated size of project:
      350 hours
      Skill level:
      Advanced

      ~~~~~~~~~~
      Generate Problem Editorials Using AI
      Brief Description:
      omegaUp has a problem base with thousands of public problems, the big majority of them do not have an official solution for students to read and learn when they can't solve the problem on their own. This project consists of using generative AI and validate official solutions to the thousands of public problems. Generative AI should also be used to validate the editorial by asking it to generate code based on the editorial.
      Expected results:
      A high percentage (> 70%) of existing and new problems should have an official editorial that has been generated and validated using AI.
      Preferred skills:
      Python
      LLM Prompt Engineering
      PHP
      Vue.js
      Possible mentor:
      heduenas, pabo99
      Estimated size of project:
      350 hours
      Skill level:
      Advanced

      ~~~~~~~~~~
      Public Courses on github
      Brief Description:
      omegaUp offers many public courses in Spanish open to everyone. They have been solely managed by omegaUp staff but we want to be able to manage them through github so anyone can suggest improvements to the content (through pull requests). The Mexican Olympiad in Informatics already does this on a public course that they offer through omegaUp. We need to replicate what they have on our courses.
      Expected results:
      The content of public courses offered by omegaUp is managed through github and anybody is able to propose improvements through pull requests.
      Preferred skills:
      git/github
      Python
      Continuos Integration
      REST APIs
      Possible mentor:
      heduenas, tvanessa
      Estimated size of project:
      175 hours
      Skill level:
      Medium to Advanced

      ~~~~~~~~~~
      Cronjob Optimization
      Brief Description:
      We have a number of cronjobs responsible for things such as updating student/school rankings, awarding badges to students, etc. Over the time they have become inefficient, error prone and hard to debug. We want to make them more efficient, increase their test coverage and improve their debug-ability.
      Expected results:
      Cronjobs become much leaner, faster and easier to maintain.
      Preferred skills:
      Python
      MySQL
      PHP
      Unit and Integration Testing
      Possible mentor:
      carlosabcs, tvanessa
      Estimated size of project:
      350 hours
      Skill level:
      High

      ~~~~~~~~~~
      Integrate Problem Creator with Create/Edit Problem Workflows
      Brief Description:
      A project from last year's GSoC introduced the Problem Creator, a visual editor that helps problem authors create and edit problems more easily. However, the Problem Creator isn't yet fully integrated with omegaUp. Currently, authors must:
      Write their problem using the Problem Creator
      Download it as a .zip file
      Upload it through a separate UI to add it to the platform
      The editing process is similarly cumbersome, requiring authors to download a .zip, upload it to Problem Creator, make changes, download again, and upload again to update. This year, we aim to streamline these workflows by fully integrating the Problem Creator with omegaUp's create and edit problem features.
      Expected Results:
      Authors will have access to a simple, straightforward workflow to create and edit problems without needing to handle .zip files.
      Preferred skills:
      Vue.js
      Typescript
      PHP
      Estimated size of project: 350 hours
      Skill level:
      Medium
      Possible mentor:
      Aritra8438, carlosabcs

      ~~~~~~~~~~
      Code Coverage Measurement for End-to-end Tests
      Brief Description:
      We recently migrated our integration tests written in Cypress. We use codecov to measure and enforce test coverage, however our codecov setup right now only takes into account unit tests and not end-to-end tests. In this project we want codecov to also measure cypress test coverage so we can enforce minimum levels of coverage.
      Expected results:
      Codecov reports cypress test coverage enabling coverage levels to be monitored and minimum levels of coverage to be enforced.
      Preferred skills:
      Integration testing
      Typescript
      PHP
      Possible mentor:
      pabo99, heduenas
      Estimated size of project:
      90 hours
      Skill level:
      Medium
      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/omegaup/
    idea_list_url: https://github.com/omegaup/omegaup/wiki/Google-Summer-of-Code-2025

  - organization_id: 182
    organization_name: openSUSE Project
    no_of_ideas: 17
    ideas_content: |
      
      New workflow for building and publishing openSUSE Leap Release Notes

      Project Title:
      New workflow for building and publishing openSUSE Leap Release Notes

      The deployment of openSUSE Leap release notes is currently a manual process.
      We can do much better!

      Goals:

      In ideal world Leap release notes include also content from SLES release-notes (as Leap is essentially SLES + community packages. And we use something like simple github CI to publish it.

      Avoid building packages in OBS. RN rpms were required by our legacy installer, new installer does not need it.

      Current process: https://progress.opensuse.org/issues/132053
      We could host new Leap releates notes next to SLES RN http://github.com/SUSE/release-notes

      Relevant Notes from last Release Notes discussion https://etherpad.opensuse.org/p/weeklymeeting20250225-rn
      Example build of SLES Release notes https://susedoc.github.io/release-notes/sles-15_SP4/html/release-notes/#jsc-SLE-21308

      Deliverables:

      Initial Leap release notes in asciidoc http://github.com/SUSE/release-notes
      Leap Release Notes include also SLES release notes content
      Automatic Build and Publish of Release Notes via CI, similar to the current SLES process https://github.com/SUSE/release-notes/actions
      Leap Release Notes have openSUSE theme (similar to https://github.com/openSUSE/release-notes-openSUSE / https://doc.opensuse.org/release-notes/x86_64/openSUSE/Leap/15.6/index.html)
      Preview build on each pull request?
      Mentor:
      @lkocman

      Skills:
      Github, CI / DevOPS, markdown/asiciidoc processing.

      Project Size: Small Sized Project (50 hours)

      ~~~~~~~~~~



      

      
      Support for Ubuntu Snap Packages in Uyuni

      Project Title:
      Support for Ubuntu Snap Packages in Uyuni

      Description:

      Since Ubuntu 20.04 LTS, the Snap package technology has gained significant traction, and with the upcoming Ubuntu 24.04 LTS release, many deb packages are being migrated to Snap.

      With this increasing adoption of Snap packages in Ubuntu, Uyuni lacks native support for managing Snap-based applications. This creates a gap in package management, especially as more software is distributed via Snap.

      Goals:

      Introduce Snap support in Uyuni, allowing users to:

      Install, update, and remove Snap packages.

      Manage Snap channels (stable, candidate, beta, edge).

      Handle Snap package management in airgapped environments.

      Deliverables:

      The code as a PR to the Uyuni repository
      Design decisions and evaluation as a Wiki page in Uyuni Wiki

      Mentor:

      @m-czernek , @wweellddeerr

      Skills:

      Java knowledge
      Python knowledge
      Good SQL knowledge
      Familiarity with PostgreSQL
      Skill Level: Medium

      Project Size: Medium Sized Project (125 hours)


      ~~~~~~~~~~
      



      Uyuni database optimisiation
      Project Title:

      Uyuni database optimization

      Description:

      Uyuni is an open source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API.

      Uyuni is based on an older project without much database refactoring and optimizations and so its database design is rather old. Previous design decisions are no longer state of the art and are now rather hurting the performance.

      Database was designed for more database engines which Uyuni no longer supports, for old postgresql version without useful features added in later version.

      Ultimately this project aims for overall database schema refactoring and optimizations, but given scale of the project, actual deliverables will be probably smaller.

      Goals:

      database in majority uses NUMERIC datatype as an ID column tied with custom sequence generator. NUMERIC is slow datatype for joins and selects and a plan how to migrate from NUMERIC to BIGINT type and autogenerated sequences instead of custom sequence generator. This includes:
      changes in database schema
      changes in mapped Java objects
      migration workflow
      performance evaluation of schema migrations
      replace VARCHARs with list constrains to ENUMs
      replace CHAR(1) to BOOLEANs
      Stretch goals:

      identify cross joins and replace them by inner or left or right joins when possible
      identify possible table decompositions
      or on the other hand where decomposition went too far and hurts performance
      explore using postgresql partitioning on large tables to improve performance
      Deliverables:

      The code as a PR to the Uyuni repository
      Design decisions and evaluation as a Wiki page in Uyuni Wiki
      Mentor:

      @aaannz
      Skills:

      Java knowledge
      Good SQL knowledge
      Familiarity with PostgreSQL
      Skill Level: Medium

      Project Size: Medium Sized Project (125 hours)

      Get started:

      Join GitHub Discussions and chatrooms: uyuni-project/devel uyuni-project/users
      Get familiar with uyuni
      Set up a development Uyuni server VM, e.g. with sumaform
      Uyuni schema and how updates are done

      ~~~~~~~~~~



      kubectl-like get command for mgrctl

      Project Title:

        kubectl-like get command for mgrctl

        Description:

        Uyuni is an open source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API.

        mgrctl is a tool meant to offer API access to the Uyuni server. At the moment it provides a limited set of features and only covers raw API calls.

        The goal of this task is to implement a get command that works like the one from kubectl. So users could query the API using a command like: mgrctl get <object_type> [options].

        The first object types to implement could be system, group as those are central concepts of Uyuni.
        The options would provide search by name, filtering using some of the object properties and output format options.
        For instance mgrctl get system -f cpu=x86_64 -o yaml would return a YAML file with the systems that have an x86_64 CPU.

        Note, this idea already exists as an uyuni-tools issue: uyuni-project/uyuni-tools#238

        Deliverable:

        The code as a PR in uyuni-tools repository.
        Documentation for the new command at least in the mgrctl get --help.
        Mentor:

        @cbosdo
        Skills:

        Good Golang knowledge.
        Skill Level: Medium

        Project Size: Medium Sized Project (125 hours)

        Beware this could easily turn into a rabbit hole: properly define the limits of the project with the mentor. Better have only a few objects covered correctly than a lot with many missing pieces.

        Get started:

        Join GitHub Discussions and chatrooms: uyuni-project/devel uyuni-project/users
        Get familiar with uyuni
        Get familiar with the mgrctl code. Starting with the api command code could be a good idea.
        Check the Uyuni API docs
        Set up a development Uyuni server VM, e.g. with sumaform. This page can help you getting started. The crucial part is the network setup as it would lead to various strange problems later. Make sure to read https://github.com/uyuni-project/uyuni/wiki/Libvirt-DNS-and-DHCP-without-Avahi to help with this.
      

      ~~~~~~~~~~
      AI-Driven Test Selection on Pull Request acceptance tests

      Project Title
      AI-Driven Test Selection on Pull Request acceptance tests

      Description
      Large test suites can slow down CI/CD pipelines, leading to longer feedback loops and inefficient resource usage. This project aims to leverage machine learning (ML) to predict which tests should be executed based on product code pre-processing, recent code changes, commit history, past test failures, and code coverage.

      By analyzing this data we can train an ML model to prioritize high-risk tests and reduce overall test execution time. The goal is to reduce the Pull Request acceptance tests execution time by running only the most relevant tests using this ML model.

      This project is a continuation of our current work in the Uyuni project, that will be presented during the SeleniumConf 2025

      The project will involve
      Extracting commit history to identify impacted files.
      Analyzing test execution history to track past failures.
      Processing code coverage data to map tests to code changes
      Research if we can process and integrate some parts of the product code, i.e. dependency graphs.
      Training a machine learning model (e.g., Random Forest, XGBoost) to recommend which tests to run.
      Integrating the trained model into our GH actions to dynamically select tests for each Pull Request.
      This approach ensures that tests are executed intelligently, reducing test cycle time while maintaining high test coverage.

      Deliverables
      Data extraction scripts for:
      Commit history from Git (files changed, commit messages)
      Test execution logs (pass/fail results, error messages)
      JaCoCo Code coverage reports
      A trained ML model that predicts which tests should run based on commit history and past test results.
      Integration with GitHub actions to automate test selection.
      Comprehensive documentation on setup, training, and deployment of the model.
      Mentor
      Oscar Barrios (@srbarrios)

      Skills Required
      Ruby (for test framework integration).
      Machine Learning Basics (feature engineering, model training).
      Python + Scikit-Learn/Pandas (for ML model development).
      GitHub actions (to integrate test selection into pipelines).
      Cucumber/Selenium Testing (understanding of automated tests).
      Skill Level
      Medium – Requires knowledge of Ruby (for test integration) and basic ML concepts (training and using models).
      Prior experience with CI/CD and automated testing is a plus.
      Project Size
      Medium-Sized Project (160 hours)

      Get Started
      Data Sources:

      Uyuni Git Commit History: Includes code changes, affected files, and commit messages.
      Test Execution Logs: Stores past test results, including failures, execution time, and errors. This content it gonna be publicly available through a web server located in AWS, for now we are publishing only the Cucumber reports here.
      Code Coverage Data: Tracks which tests touch specific parts of the codebase. This is available in a Redis database, and already in use in our GH actions
      Steps

      Data Collection & Preprocessing
      Extract Commit History
      Extract Test Execution History
      Extract Code Coverage Data
      Use Python + Scikit-Learn for training a model using all the data collected.
      Prepare Training Data
      Train a Classification Model
      Integrate it as GitHub action into every Pull Request
      Enhance the current GH action using the ML model.
      Useful links

      Scikit-Learn Guide
      Facebook article 1
      Facebook article 2
      Blog post
      Efficacy Presubmit

      


      ~~~~~~~~~~
      Refactoring Hibernate Queries in Uyuni: Towards a Unified Approach

      Project Title:

      In Hibernate's long history, there have been several ways to define a query:

      Description:

      HQL: Hibernate Query Language (HQL)
      Hibernate Criteria Queries: Documentation
      JPA Criteria Queries: Baeldung Guide
      Native SQL Queries
      Depending on the type used, queries can be defined in:

      An hbm.xml file
      An orm.xml file
      A JPA annotation
      Hardcoded in Java code
      Currently, Uyuni's codebase uses all of these approaches.
      Deliverable:

      Refactoring all queries to Named Native Queries using annotations: Example
      Adjust/create new hibenate entity (if required)
      Adding unit tests (if missing or applicable)
      Preventing developers from adding queries that are not Named Native Queries with annotations (e.g., via Checkstyle or another enforcement mechanism)
      Mentor:

      @mbussolotto

      Skills:

      Good Java knowledge.
      Good SQL knowledge.
      Hibernate, or motivation to learn it.
      JPA, or motivation to learn it.
      Skill Level: Easy/Medium

      Project Size: Medium Sized Project (125 hours)

      Get started:

      Join GitHub Discussions and chatrooms: uyuni-project/devel uyuni-project/users
      Get familiar with uyuni, especially with the Java code
      Hibernate documentation https://hibernate.org/orm/documentation/6.6/
      

      ~~~~~~~~~~
      UI Plugin infrastructure

      Project Title:

      UI plugin infrastucture

      Description:

      Uyuni is an open source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API.

      The user interface is currently implemented in a mix of Spring (old code) and TypeScript (what we aim at). Users may want to ship extensions to the UI, like adding a new entry in the main menu and displaying their application in the main content area.

      The project is about implementing such an extension mechanism. The basic workflow would be:

      Configure a remote location where to pull the extension from (already built)
      The extension would be stored in one of the container existing volumes
      Load entry points in the menu and main content area.
      Deliverable:

      The code UI extension implementation
      An example extension
      Documentation on how to create an extension
      Mentor:

      @cbosdo
      Skills:

      Good Java and TypeScript knowledge.
      Skill Level: Medium/Hard

      Project Size: Medium Sized Project (125 hours)

      Get started:

      Join GitHub Discussions and chatrooms: uyuni-project/devel uyuni-project/users
      Get familiar with uyuni, especially with the menu tree definition and the web UI loading mechanism.
      Set up a development Uyuni server VM, e.g. with sumaform
      

      ~~~~~~~~~~
      Remove use of Java raw types

      Project Title:

      Remove the use of Java raw types

      Description:

      Uyuni is an open source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API.

      The Java code of Uyuni evolved over the years but still contains raw types uses. This project is about removing them all! This may sound an easy task, but this requires quite some code reading and patience to achieve it.

      Here is a list of the reported uses: https://sonarcloud.io/project/issues?languages=java&rules=java%3AS3740&issueStatuses=OPEN%2CCONFIRMED&id=uyuni-project_uyuni

      Deliverable:

      The code without the raw types.
      SonarCloud reporting no raw type use any more: https://sonarcloud.io/project/issues?languages=java&rules=java%3AS3740&issueStatuses=OPEN%2CCONFIRMED&id=uyuni-project_uyuni
      Mentor:

      @cbosdo
      Skills:

      Good Java knowledge.
      Skill Level: Easy/Medium

      Project Size: Small Sized Project (90 hours)

      Get started:

      Join GitHub Discussions and chatrooms: uyuni-project/devel uyuni-project/users
      Get familiar with uyuni, especially with the Java code
      Set up a development Uyuni server VM, e.g. with sumaform
      

      ~~~~~~~~~~
      Log Detective for openSUSE / OBS

      Project Title: Log Detective for openSUSE

      Description: Fedora project has a project to train an AI model to help with rpm build errors: https://log-detective.com/. The

      The goal of this project is to explore different ways of contributing to Log Detective with some semi-automated data and investigate interesting ways of integrate the model in openSUSE development workflow, it could be with a new osc plugin, implementing some integration in OBS webpage, or any other tooling around building packages and reading logs of failing builds.

      Deliverable: The result of this project will be documentation with the research results about the usage of AI model to debug failing builds, experimental tools / scripts to feed log-detective.com and to use the model easily for openSUSE packagers.

      Mentor: @danigm

      Communication channels:

      Matrix direct message: @danigm:gnome.org
      Matrix openSUSE chat channel: mention me (danigm) openSUSE Chat
      Email: daniel.garcia@suse.com
      Be patient and wait one or two days before reping, I'll try to answer as soon as possible, but it's not always possible answer in the same day.

      Skills: AI, python, rpm, packaging, git, Linux

      Skill Level: Medium

      Get started:

      Get familiar with https://log-detective.com website
      Study log-detective API and source code, and open build service to start to think about different ways of integration.
      

      
      


      

      ~~~~~~~~~~
      Extract and containerize Uyuni Salt event processor

      Project Title:

      Extract and containerize Uyuni Salt event processor

      Description:

      Uyuni is an open-source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API.

      Salt project is used for the communication and management layer. Data is transferred between servers and is minions in the form of events. The events that arrive on the Uyuni server need more processing than the ones performed by salt master.

      The processing of Salt event cannot block the salt master. For this reason, salt is configured to save the salt events on the database to be asynchronously processed. Currently, the process responsible for this is Tomcat. However, tomcat should be focused on serving the web application and not processing the salt events.

      This project is focused on extracting the salt-event processing to an external process and containerizing it. The extraction is partially done in here.

      The major work will be focused on containerization and deployment using uyuni-tools project.

      Deliverable:

      Container image that can process the salt-event stream.
      Uyuni tools being able to deploy this container.
      Mentor:

      @rjmateus @mackdk @renner

      Skills:

      Java knowledge
      Go knowledge
      knowledge of containerized applications
      Skill Level:

      Medium,

      Project Size:

      Medium Sized Project (175 hours)

      Get started:

      Join GitHub Discussions and chatrooms: uyuni-project/devel uyuni-project/users
      Get familiar with uyuni
      Get familiar with uyuni-tools
      Set up a development Uyuni server VM, e.g. with sumaform
      

      ~~~~~~~~~~
      Packit support for OBS

      Project Title:

      Packit support for OBS

      Description:

      Packit is a CI system that builds rpms out of upstream projects. Currently it only supports building rpms in COPR and Koji. It would be beneficial for packit to gain support to build in OBS, as it would give access to more distributions and would allow packit to send submissions to openSUSE.

      Deliverable:

      Implement support for the packit CLI to build on OBS (finish OBS build support packit/packit#2067)
      Add support for the packit server to build on OBS
      stretch goals:

      implement support for sending submit requests on OBS via packit
      Mentor:

      @dcermak
      @lachmanfrantisek

      Skills:

      Python knowledge
      packaging rpms is beneficial
      Skill Level:

      Medium to Hard

      Project Size:

      Large Sized Project (350 hours)

      Get started:

      get acquainted with OBS and the OBS API
      learn the basics of building RPMs in COPR, koji and OBS
      give packit a try
      

      ~~~~~~~~~~
     
      Improve test coverage in rpmlint

      Project Title: Improve test coverage in rpmlint

      Description: The rpmlint project has a lot of tests. The past year during the GSoC we extend the test tools to make it easy to write tests mocking rpm files, but there are still a lot of tests that uses binary rpm files for tests.

      The goal of this project is to try to reduce the number of binary .rpm files in the repository and replace tests with mock and extend the test suite to increase the code coverage.

      Deliverable: The result of this project will be multiple pull requests to the rpmlint repository with new tests.

      Mentor: @danigm

      Communication channels:

      Matrix direct message: @danigm:gnome.org
      Matrix openSUSE chat channel: mention me (danigm) openSUSE Chat
      Email: daniel.garcia@suse.com
      Be patient and wait one or two days before reping, I'll try to answer as soon as possible, but it's not always possible answer in the same day.

      Skills: python, RPM, packaging, git, Linux

      Skill Level: Medium/Hard

      Get started:

      Get familiar with the rpmlint code base and current way of testing: https://github.com/rpm-software-management/rpmlint
      Study python testing and get familiar with options we can utilize
      Links

      Replace existing binary rpm in tests with FakePkg rpm-software-management/rpmlint#1105
      Create test FakePkgs to use in different tests  rpm-software-management/rpmlint#1104
      All the objects we have in place should have some basic tests rpm-software-management/rpmlint#156
      

      ~~~~~~~~~~
      Provide a library for determining keylength security

      Project Title: Project title, short enough to catch attention

      Provide a library for determining keylength security

      Description: General information about the project, avoid one Liners, the description should be as detailed as possible.

      The project would be writing a library for looking at keylength of algorithms and measuring their security according to different standards. For example RSA-4096 is currently considered secure, but RSA-1024 not. We want a library which embedds this knowledge and can be requested. Furtheron we want to be able to enhance the library or write a program which does scan keys or certificates and determines their security strength. This should be done according to different standards, think NIST standards or IETF or BSI standards.

      There's already a website which does this similarly, called keylength.com, but this is not usable as a library, nor cannot be used in a pipeline or an offline program

      This library could be done in Rust but the most important point is, that it can be linked to other (lowlevel) languages

      Deliverable: Expectations from the student at the end of the project

      The first task is reading and understanding the different Standards and Papers regarding keylengths for cryptographic primitives and their security
      The second task is implementing this knowledge into a library
      The third task would be to write a program which uses this library to scan keys or certificates so the program can say if the used primitives and their keylengths are secure according to specific standards
      Mentor: Who is the mentor? Who is the Co-Mentor? Also please assign the issue to the mentor!

      Dennis Knorr (dennis.knorr@suse.com)
      Martin Sirringhaus (martin.sirringhaus@suse.com)

      Skills: Which skills are needed? Programming languages, frameworks, concepts etc.

      have a bit knowledge in cryptography
      being somewhat able reading papers and standards about keylengths and their respective security
      being familiar with programming
      Skill Level: Easy, Medium, Hard

      Medium

      Prject Size: Medium Sized Project (175 hours), Large Sized Project (350 hours)

      As reading and grokking the papers might take some time and also writing a program which scans keys needs parsing, this is more a large project

      Get started: Tasks that mentors may want to suggest students so that they can start contributing to the code base (e.g. junior jobs, low hanging fruits, discussion on the mailing list)

      Get familiar with standards like https://infoscience.epfl.ch/record/164539/files/NPDF-32.pdf or https://infoscience.epfl.ch/record/164526/files/NPDF-22.pdf (you do not have to read them all now, just be aware of it)
      Get familiar with the language you want to do this with (we would prefer rust)
      

      ~~~~~~~~~~
      Migrate download endpoint to a independent service

      Project Title:

      Develop a new service to manage package download.

      Description:

      Uyuni is an open source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API.

      One of the main features of uyuni is package installation in managed machines (more information about the project at: https://www.uyuni-project.org/).
      To be able to install packages systems need to download information from the server: metadata and package files. All these calls go through the download endpoint which validates the user authentication and then provides the requested data.
      Being the most used endpoint this project has the goal to extract it to an independent service prepared to scale and run in a container.

      We would like to containerize this feature at the same time keeping the same proven business logic.

      Deliverable:

      The main goals/delivers would be:

      Extract the download endpoint to an independent service
      Run the new service in a container
      Replace the existing implementation of the feature with the containerized one
      Mentor:

      @rjmateus (co-mentor to be defined)

      Skills:

      Good knowledge of the Java programming language and best practices
      Good knowledge of web development worflow
      Knowledge of containers technology
      Skill Level:

      Medium. The java to validate the download data already exists.

      Prject Size:

      Medium Sized Project (175 hours)
      Get started: Tasks that mentors may want to suggest students so that they can start contributing to the code base (e.g. junior jobs, low hanging fruits, discussion on the mailing list)

      Set up a development environment for Uyuni locally using sumaform
      Container image with a running server is being prepared
      How to Contibut
      Select a good first bug from
      ... have fun :)
      

      ~~~~~~~~~~
      Migrate the Uyuni build process from Ant to Maven

      Project Title:

      Migrate the Uyuni build process from Ant to Maven

      Description:

      Uyuni is an open source systems management solution that can be used to manage various Linux distributions using a powerful web UI and API. The Uyuni Java code is built using Ant since a long time for the purpose of building official packages for installation, but also for development usage. We would like to achieve the following while preserving all of the existing use cases:

      Move all the Java code and tests to a maven like structure
      Use maven for the build process for developers and official releases
      Use maven to run checkstyle and unit tests on the Java code locally and in CI
      Deliverable:

      It should be possible to build and deploy the code to a local development server using maven
      It should be possible to run checkstyle and the unit tests locally or in CI (e.g. in Jenkins or GH Actions)
      The official package build process should be migrated to maven (see the spec file)
      Ant buildfiles should become obsolete and should finally be removed from the repo
      Mentor:

      @mackdk with @cbosdo as co-mentor.

      Skills:

      Very good knowledge of the Java programming language and best practices
      Expertise with both of the most common Java build tools (Ant and Maven)
      Experience with packaging software for Linux, ideally using the Open Build Service
      Skill Level:

      Be aware that even though it might sound rather easy, the skill level here is Medium / Hard. The reason is that the codebase is huge, there is a lot of dependencies (that we are resolving from OBS rather than from maven central), the package build process is very complex and this migration is a huge change for everyone involved, especially developers and release engineers.

      Project Size:

      Large Sized Project (350 hours)

      Get started:

      Set up a development environment for Uyuni locally using sumaform
      Get familiar with the dependency resolution mechanism used in the project and respective tools (especially obs-to-maven)
      Use the Open Build Service to build packages with maven, or migrate an existing package
      

      ~~~~~~~~~~
      
      Refresh Uyuni's YourRHN page

      Project Title: Refresh Uyuni's YourRhn page

      Description:

      The current landing page of a user, called Your RHN is written in JSP and the data it shows may not be super helpful.
      The old JSP pages in Uyuni are slowly being rewritten using ReactJS and this one is yet another on the waiting list.

      While changing this page, the idea is to provide more useful data like stats about the systems needing upgrades or reboots or the number of scheduled or failed actions. Ideas of data to show there are welcomed: the list is not fixed.

      Here is what the current page looks like:

      image

      Code pointers:

      Java code behind the JSP: https://github.com/uyuni-project/uyuni/blob/master/java/code/src/com/redhat/rhn/frontend/action/YourRhnAction.java
      JSP code: https://github.com/uyuni-project/uyuni/blob/master/java/code/webapp/WEB-INF/pages/yourrhn.jsp
      Code of existing ReactJS pages: https://github.com/uyuni-project/uyuni/tree/master/web/html/src/manager and https://github.com/uyuni-project/uyuni/tree/master/web/html/src/components
      Deliverable:

      The page is converted to ReactJS and shows some stats on the user's systems and quick actions.

      Mentor: @cbosdo, @wweellddeerr

      Skills: ReactJS and Java. Hibernate and SQL are a plus.

      Skill Level: Hard

      Get started:

      Installing the development environment:

      https://github.com/uyuni-project/uyuni/wiki/Java-Development-Environment
      https://github.com/uyuni-project/uyuni/wiki/Frontend-Development-Environment
      Installing a test environment:

      https://github.com/uyuni-project/uyuni/wiki/Uyuni-development-in-no-time

      Slides on how to get started developing Uyuni: https://bosdonnat.fr/slides/openSUSEAsiaSummit19/#/about

      Uyuni Wiki:

      Introduction to Uyuni and systems management (presentation): https://github.com/uyuni-project/uyuni/wiki/Presentations
      Uyuni development in no time: https://github.com/uyuni-project/uyuni/wiki/Uyuni-development-in-no-time
      Development pages: https://github.com/uyuni-project/uyuni/wiki/

      ~~~~~~~~~~
      
      Analytics Edge Ecosystem Workloads

      Project Title: Create open source sample microservice workload deployments and interfaces, spanning distributed edge-core-cloud infrastructure to address chosen market verticals to provide relevant analytics per market verticals

      Description: In the context of this Analytics Edge Ecosystem, such a digital transformation approach to cloud-native containerizing addresses how one can help strategically iterate and perform the necessary and even more comprehensive business/usage analytics requirements. This can be done across a truly distributed compute infrastructure (with various resource options), leveraging compute elements closer to where data is generated, validated or provided initially or in addition. Then you can more rapidly adapt the reaction, formulate predictions and forecasts, and have a larger context of all the elements that can potentially impact and internally secure your business positively plus for consumers, providers, and partners.

      Deliverable: Provide an opensource-based example deployment of a trained/tested/functional workload available for use cases:

      General
      Interact in sprint meetings, sharing progress, issues, and plans (via lightning talk approach) and peer reviews of other contributors or examples
      Provide content in a usable, accessible GitHub repo example for the team to access
      (Bonus Points) : publish blog/demo/documentation or webinar/conference sessions with an overview of why certain paths were chosen and how it was done
      Phase I (Bonding Period)
      Learn and interact plus become familiar with the overall application infrastructure layers (network + hardware + storage technology, operating system, containers, kubernetes, AI/ML/GenAI examples)
      Phase II (first coding)
      Pick a target role plus an interesting business vertical, research an existing example and deploy to learn about what underlying aspects are needed and what to provide above it
      Then either stay in same role, picking another vertical and retry or adopt another role to more completely adapt or provision it
      Phase III (second/final coding)
      Brainstorm and research an end-to-end example approach for a desired business vertical of your own personal interest
      Potentially port aspects/portions of other found examples to further improve the functionality and address better analytics plus multiple user case needs
      Deploy in multiple environments to validate usability
      Mentor: @bwgartner + more/others (Ann, Terry, plus maybe some previous GSoC contributors)

      Skills / Layers / (Roles):

      Application Infrastructure (ITOps, AIOps, Platform Engineering
      Network/Computing/Storage Platforms
      Operating System
      Programming languages (your choice)
      Bash, JavaScript, Java, Jupyter, Python, R, Ruby, ollama, LLM, RAG, Vector Databases...
      Build packages, virtual machines, container runtime and image creation, manifests/helm charts
      Cloud-Native Kubernetes leveraging Rancher offerings
      Data Pipeline (Data/Ops Analysis)
      Ingest, cleanse, validate, stream, flow, curate, conform
      Machine Learning Pipeline (MLOps)
      Train, test, flow, evaluate, secure AI (Artificial Intelligence)/ML (Machine Learning)/DL (Deep Learning)/LLM (Large and Small Language Models)
      User, Consumer, Operator, Programmer Interfaces, (DevOps/GitOps)
      Example business verticals
      agriculuture/environmental/weather, automotive, healthcare, retail, federal/military, finance, manufacturing, media/entertainment, smart building/city/home/light/parking, telecommunications, ...
      Skill Level: Easy, Medium

      Get started:

      Container Guide ( https://documentation.suse.com/container/all/single-html/SLES-container/ ) and access to registries
      Kubernetes ( https://rancher.com/learn-the-basics https://rancherdesktop.io/ )
      Datasets ( https://www.kaggle.com/datasets )
      Code/Data Science ( https://www.kaggle.com/code )
            

      
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/opensuse-project/
    idea_list_url: https://github.com/openSUSE/mentoring/issues

  - organization_id: 183
    organization_name: rocket.chat
    no_of_ideas: 23
    ideas_content: |
      
      
      💡Maestro as Mobile UI Testing Framework
      👥 Mentor(s): Diego Mello
      💬 Description:
      Migrate Rocket.Chat Mobile app's UI testing framework from Detox to Maestro. Maestro is a modern mobile UI testing framework that offers several advantages over Detox:
      More reliable test execution with fewer flaky tests
      Better debugging capabilities with detailed test reports and video recordings
      Simpler test writing syntax using YAML
      Cross-platform support for both iOS and Android
      Active community and development
      This migration will help improve the reliability and maintainability of our mobile app testing suite while reducing the time spent debugging flaky tests.
      💪 Desired Skills:
      Experience with mobile app testing
      Knowledge of React Native
      Familiarity with YAML syntax
      Understanding of CI/CD concepts
      Basic knowledge of iOS and Android development
      Good problem-solving skills
      Experience with Git and GitHub
      🎯 Goals/Deliverables:
      Setting up Maestro testing infrastructure in the mobile repo
      Converting existing Detox tests to Maestro format
      Creating new tests to improve coverage
      Implementing CI/CD pipeline integration on Github Actions
      Documentation of testing practices and guidelines
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Intermediate

      ~~~~~~~~~~


      🚀 Hugging Face Management Assistant for Rocket.Chat
      👥 Mentor(s): Prisha Gupta
      📢 Communication Channel: idea-HuggingFace-Management-Agent
      💬 **Description: **
      Managing models, datasets, and Spaces on Hugging Face can be challenging, especially within teams. This Rocket.Chat app will integrate with Hugging Face Hub APIs to allow users to list, update, and monitor HF resources directly from Rocket.Chat.
      The App will enable:
      Viewing available models, datasets, and Spaces
      Updating model metadata (e.g., descriptions, tags)
      Managing repository settings (private/public, visibility)
      Get updates on Space build status
      Manage PRs
      Real-time notifications for updates on Repos
      By integrating management functionalities directly into Rocket.Chat, teams can streamline collaboration and reduce the need to switch between multiple platforms.
      Bonus nice-to-haves are any additional innovative features that leverage generative AI (LLMs) to facilitate in-channel interactions with Hugging Face.
      💪 Desired Skills:
      Rocket.Chat Apps Engine and TypeScript
      Hugging Face Hub API
      API authentication and security
      🎯 Goals/Deliverables:
      A Rocket.Chat App that allows users to manage Hugging Face repositories, models, datasets, and Spaces efficiently through chat commands. It will provide an intuitive interface for listing, updating, and tracking resources with real-time notifications.
      ⏳ Project Duration: 90 hours (Small)

      ~~~~~~~~~~
      💡Real Time Message Rendering in Message Composer
      👥 Mentor(s): Martin Schoeler
      💬 Description:
      Any rich text content is rendered in its text form - for example emojis will be rendered as :grin: instead of 😬, Bold markdown highlight will be rendered as **Bold** while composing a message using Rocket.Chat.
      This project should upgrade the composer to support real-time in-message rendering of rich content while editing.
      Most of the complexity of this project comes from properly converting the existing Message Composer to display rich content, while integrating with ALL existing functionality of the Composer component
      💪 Desired Skills:
      Understanding of the composer component
      Understanding of Rocket.Chat's message rendering pipeline
      Advanced Typescript
      Good understandng of DOM elements and it's intricacies
      Desire to work on high impact projects (benefiting every single RC user)
      🎯 Goals/Deliverables:
      Having a working MVP of real time message rendering in the message composer
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Intermediate/Advanced

      ~~~~~~~~~~
      💡 Frequently Asked Questions (FAQ) Detection Assistant
      👥 Mentor(s): Aman Negi
      📢 Communication Channel: idea-Frequently-Asked-Questions-Detection-Assistant
      💬 Description:
      New contributors to open source often ask very similar questions. Answering similar questions repeatedly can be a tiring and tedious task for maintainers (or mentors).
      This LLM powered assistant will solve the problem by:
      monitoring Github webhooks or a set of specified Rocket.Chat channels for questions
      determine if the incoming question is similar to one in a set of configured FAQ
      if a match is found, do one of the following configurable action:
      notify one or more configured users of the incoming question
      notify one or more configured users of the incoming question via DM, providing a summarized answer as a suggestion
      notify one or more configured downstream LLM driven agents
      same as ii., but provide the capability for the notified users to "approve" the automated reply of the summarized answer; some final editing before reply should be possible
      answer the incoming question with a summarized answer; then notify one of the configured users in DM
      Considerations:
      the assistant must be designed to be 100% fail safe; it should never answer unrelated question or answer with hallucinations (nor answer with harmful content)
      the assistant should be designed to be functional in all FAQ/templated answers/Quick-reply situations, increasing its utility
      this project will involve very clever prompting and optimized prompt chaining (instead of tedious volumous Typescript code)
      💪 Desired Skills:
      Rocket.Chat Apps Development (Typescript)
      Github/Gitlab webhooks development
      Advanced prompt engineering
      Passion for creating LLM driven assistive applications
      🎯 Goals/Deliverables:
      A useful assistant in many automated public group chat/forum context with configurable abilities to help in handling frequently asked questions.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~

      💡Server Setup Agent
      👥 Mentor(s): Aditya Singh
      📢 Communication Channel: idea-Server-Setup-Agent
      💬 Description:
      As an administrator setting up a production Rocket.Chat server, one is typically required to create user accounts, create and assign roles, create default channels, possibly starting threads, starting discussions and populating with initial messages.
      These sort of tedious tasks are also often required in the testing and quality assurrance of Rocket.Chat or Rocket.Chat related apps/projects. Furthermore, they are also required in many demo and training situations.
      This project is a Setup Agent App that automates all of the above based on either a series of slash commands or by loading an automated script.
      The script should conform to an easy to learn, intuitive and simple DSL (Domain Specific Langauge) of the contributor's design.
      The language needs to incorporate basic variables, and be able to handle simple counted loops. Conditionals and conditional loops are nice to have.
      The agent should be tested to handle very large scripts that may involve the creation of thousands of objects and messages.
      DSL will be checked for LLM-generation suitability; although AI generation of the script is outside the scope of this project.
      💪 Desired Skills:
      Interest in DSL and AST (Domain Specific Language and Abstract Syntax Trees)
      Rocket.Chat Apps development (Typescript)
      Familiarity with Rocket.Chat's REST APIs
      🎯 Goals/Deliverables:
      A Rocket.Chat App "agent" that can help setup servers (or for QA or demo or training) by executing an automated script.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~
      💡Natural Language Bridge to Legacy Email (powered by Generative AI)
      👥 Mentor(s): Vipin Chaudhary
      📢 Communication Channel: idea-Natural-Language-Bridge-to-Legacy-Email
      💬 Description:
      Messaging systems such as Rocket.Chat were supposed to be replacing legacy email for communications and collaboration since the early nineteen nineties. But even after three decades of evolution and struggle, half the world still hangs onto legacy email worldwide despite most have grown up with SMS and asynchronous messaging.
      This project bridges the great divide most naturally with a Rocket.Chat App that responds to natural language instructions and brings the legacy email world right into every Rocket.Chat conversation for every user.
      The app will respond to command such as:
      /xuebot summarize this thread and send it as email to my boss who refuses to use chat
      OR:
      /xuebot post in the channel for everyone the budget for 2025 email pdf received between 11/1/2024 and 12/24/2024
      Details:
      You will be using the function calling/tools capabilities of modern LLMs, plus some extremely clever prompting, as well as some hardcore Typescript coding to realize this app.
      The agent must be able to perform the following reliably as a minimum:
      summarize thread/channel/discussion and send as email to specified recipient(s)
      search emails by date range and keywords and present in-channel as message and/or extract attachment and upload to channel
      report on daily email statistics
      secured per-user email connection over TLS
      💪 Desired Skills:
      Rocket.Chat Apps (Typescript) Development
      Advanced prompt engineering skills
      Familiarity with Gmail and other mail provider APIs
      Familiarity with LLM function calling / tools capabilities
      Note: This project is inspired by the prior work of our 2025 contributor ZilongXue -> claude-post
      🎯 Goals/Deliverables:
      A natural language bridge to legacy email system that every single Rocket.Chat user can use.
      ⏳ Project Duration: 90 hours (short)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~

      💡 AI Enhanced Message Composer Component
      👥 Mentor(s): Gabriel Engel, Ashutosh Singh Chauhan
      📢 Communication Channel: idea-AI-Enhanced-Message-Composer-Component
      💬 Description:
      This high impact project upgrades the Rocket.Chat message composer component to be fully AI powered. It empowers Rocket.Chat users to leverage all that modern AI technologies can offer while they are composing their message. These facilities, in 2025, may include:
      grammar corrections
      context sensitive spelling correction
      re-wording/re-phrasing for clarity / jargon-match
      tone Adjustments
      tone matching with messages in channel
      language translation
      message emojification
      message summarization and/or message verbose-tization
      and many more to come in 2025/2026
      Features:
      Inline Suggestions: Highlight areas needing improvement (grammar, clarity). Click to apply changes.
      Tone Selector: Add a dropdown to adjust the tone (e.g., formal or casual), and apply the change automatically.
      Message Preview: Allow users to toggle between the original and enhanced/translate message.
      Hinting: Display suggestions as subtle highlights or underlines, ensuring a smooth, non-intrusive experience.
      AI Integration Consideration
      This project / upgraded component will not include the LLM access mechanism. It is a pure UI component project. However, care must be taken to design it in such a way that it can be totally compatible with all kinds of LLM access -- client-side, server-side on-premises, server-side third party, cloud, and so on.
      💪 Desired Skills:
      Advanced understanding of Rocket.Chat Composer Component
      Advanced understanding of UI/Kit and Fuselage design philosophy
      Advanced JavaScript/TypeScript**
      Like coding, love design
      Love to work in maximum impact projects
      🎯 Goals/Deliverables:
      AI Enhancements in the Message Composer.
      UI/UX Polish for a seamless experience.
      Cross-Platform Support across web, mobile, and electron clients.
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Advanced

      ~~~~~~~~~~

      💡 Project Management Integration via Asana
      👥 Mentor(s): Gustavo Bauer
      📢 Communication Channel: idea-Project-Management-via-Asana-Integration
      💬 Description:
      Integrate Asana with Rocket.Chat to boost team collaboration. Instead of duplicating Asana’s complex task creation, focus on contextual notifications and quick access to task updates. Rocket.Chat project management users can stay informed collaborating within Rocket.Chat, while complex workflows that are better handled by Asana's rich UI remains in Asana. The transition to and from Asana should be seamless.
      Details:*
      Setup & Authentication
      Implement OAuth and channel configuration.
      Contextual Notifications
      Real-time alerts for task updates and deadlines.
      Quick Commands & Summaries
      Slash commands for task details and simple updates.
      Deep Linking
      Direct links from notifications to tasks in Asana.
      Optional Activity Feed
      A mini feed for recent Asana activity in channels.
      💪 Desired Skills:
      Experience with Rocket.Chat Apps Engine (TypeScript)
      OAuth and REST API experience
      🎯 Goals/Deliverables:
      An app delivering userful integration workflows for project management teams collaborating on Rocket.Chat. Including minimally contextual task notifications and summaries.
      For workflows that are better handled with Asana's rich UI, seamless redirect to Asana and seamless return to the Rocket.Chat collaboration context (channel / thread / discussions).
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy/Intermediate
      🔑 Passkey-Based WebAuthn Authentication for Rocket.Chat
      👥 Mentor(s): Julio Araujo, Dnouv
      📢 Communication Channel: idea-Passkey-Based-WebAuthn-Authentication-for-Rocket-Chat
      💬 Description:
      The WebAuthn standard, now widely available on modern Android and iOS devices, enable convenient passwordless authentication satisfying 2FA (biometrics and "have device"). Frequently this involves scanning a QR code followed by unintrusive biometrics such as FaceID on iOS. This project aims to integrate WebAuthn in Rocket.Chat authentication to offer a passwordless, secure login experience. The implementation needs to be aligned with Rocket.Chat’s existing authentication system while ensuring backward compatibility with all existing login methods.
      💪 Desired Skills:
      Node.js
      React.js
      WebAuthn API
      MongoDB
      Keen interest in cybersecurity
      Authentication & Security Best Practices
      🎯 Goals/Deliverables:
      Implement passkey-based authentication using WebAuthn
      Support QR Codes and Bluetooth hybrid transport
      Modify authentication modules to support passkey registration and login
      Update the frontend for seamless passkey interactions
      Ensure secure storage of public keys in the user database
      Conduct extensive testing across different devices and browsers
      Provide detailed documentation and promote community awareness
      ⏳ Project Duration: 175 hours (Medium)
      Server Guide Agent
      👥 Mentor(s): Gabriel Casals, Jeffery Yu
      📢 Communication Channel: idea-Server-Guide-AI-Agent
      💬 Description:
      As a new user joins a Rocket.Chat server there is not much guidance on what to do or where to go.
      Right now, the only mechanism is a passive landing page that may display resources for each grouping (persona) of users.
      For example, on the open.rocket.chat server, a user may be:
      A Rocket.Chat server administrators looking to connect with other administrators
      An end-user of Rocket.Chat looking to resolve problem or receive support information.
      A new community contributor looking for Google Summer of Code program information
      others
      Each one of these personas demand different style of conversation and would need to know about/join different sets of channels and other resources.
      Details:
      The project aims to replace the boring "easy to miss, difficult to understand" landing page, with an AI guide agent. This agent should start a conversation with the new user and then using modern LLM's discrimination/classification ability to positively identify the persona (users grouping/ sub-communities on a server) that the new user belongs to. The agent should continue to tune the conversation to the lingo-preferred of that persona, and finally guide the user to all the resources and channels available for that persona. This agent must be configurable (via Rocket.Chat Apps configuration) to handle any arbitrary persona and related resources set.
      Recommended Approach:
      The agent should be able to add (and join) the appropriate channel for the new user, after confirming the action with the new user. A default/catch-all persona should be used to precisely scoped the project and ensure the LLM can converge onto a useful result. Since direct user input will be passed to the LLM for analysis, the agent MUST make sure that there is no prompt-injection possibility. Safety of server operation must be taken into account as this agent has ability to change the state of the server permanently.
      💪 Desired Skills:
      Experience with Natural Language Processing (NLP) systems
      Rocket.Chat Apps Engine (TypeScript)
      Rocket.Chat messaging APIs
      Advanced prompt engineering skills
      Experience with tools/function-calling capabilities of modern LLMs
      Understanding of how to implement "safety first" when creating AI apps that may permanently change the state of a production system
      🎯 Goals/Deliverables:
      An AI Agent that will help to onboard new users.
      ⏳ Project Duration: 175 hours (Medium)

      ~~~~~~~~~~
      💡 Code Review Assistant for Open Source projects
      👥 Mentor(s): Felipe Scuciatto, Samad Kahn
      📢 Communication Channel: idea-Code-Review-Agent-for-Open-Source-projects
      💬 Description:
      Finding reviewers for contributors' PRs on open source projects can often be difficult. Slow response can possibly result in the loss of a communtiy contributor.
      This assistant will monitor new pull requests (either via incoming github integration messages in a channel or directly via github events) and identify the most suitable maintainer to review the PR based on a statistical scoring system. It will follow up with a friendly yet frequent reminder (“nagging”) mechanism to ensure timely reviews.
      Additionally, the bot will leverage code-specialized LLMs to perform an initial review, automatically filtering out minor improvements before they reach human reviewers.
      This will streamline the review process, reduce unnecessary delays, and ensure that only meaningful changes require manual attention.
      💪 Desired Skills:
      Rocket.Chat Apps Engine and TypeScript
      Knowledge of general statistics
      Prompt engineering with code-specialized LLMs
      Ideally GitHub API
      🎯 Goals/Deliverables:
      A Rocket.Chat App that will interact with open source maintainers and monitors open pull requests, assigns the most suitable reviewer based on past reviews, persistently reminds them until the review is completed, and leverages AI for initial code assessments.
      ⏳ Project Duration: 175 hours (Medium)

      ~~~~~~~~~~
      💡 Embedded Chat 2025
      👥 Mentor(s): Zishan Ahmad
      📢 Communication Channel: idea-Embedded-Chat-2025
      💬 Description:
      Improvement to the EmbeddedChat project this year includes:
      Upgrading the current API and authentication packages to the latest Rocket.Chat SDKs, such as ddp-client. Other components will be aligned with updated abstractions and SDKs. For reference, see this link. These packages will be managed internally by Rocket.Chat moving forward.
      Ensuring compatibility with the latest Rocket.Chat API versions to keep the integration updated and error-free.
      Upgrading to the latest stable versions of React, Node.js, and other libraries for long-term maintainability.
      Making the EmbeddedChat fully mobile-responsive for a seamless experience across all devices.
      Improving the UI and adding more customization options to enhance the user experience.
      Aligning the design and features of the EmbeddedChat Web Client with the React Native Client, which is already built but needs updates for complete consistency.
      Welcoming any other creative ideas that improve the project.
      💪 Desired Skills:
      Strong understanding of Rocket.Chat APIs and SDKs
      Love for coding and UI design
      React.Js
      🎯 Goals/Deliverables:
      Integration of the latest Rocket.Chat SDK packages
      Fully mobile-responsive EmbeddedChat
      Improved UI with more customization options
      Native app development
      Increased stability and maintainability
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Intermediate

      ~~~~~~~~~~
      💡 Smart Market Bot for Rocket.Chat
      👥 Mentor(s): Zishan Ahmad, TBD
      📢 Communication Channel: idea-Smart-Market-Bot-for-Rocket-Chat
      💬 Description:
      An interactive Rocket.Chat app that fetches real-time prices for cryptocurrencies, stocks, and forex using open-source APIs. It provides insights, summaries, and predictions while ensuring fail-proof accuracy—if the bot is unsure, it withholds speculative responses.
      Key Features:
      Live Price Updates – Fetch real-time data for crypto, stocks, and forex using free and open APIs.
      Market Alerts – Get notifications on significant price movements, trends, or unusual activities.
      Smart Insights & Summaries – Summarize asset trends, news, and market behavior.
      Predictive Analysis – Provide data-backed forecasts and trends (without unreliable speculations).
      Fail-Safe AI Responses – Ensures that if the LLM is uncertain, it explicitly avoids misinformation.
      Custom Asset Watchlists – Users can create personalized lists to track selected assets.
      Interactive Commands – Users can request price comparisons, asset history, and more via Rocket.Chat commands.
      💪 Desired Skills:
      JavaScript / TypeScript
      Rocket.Chat App Development
      API Integration (REST/WebSockets)
      🎯 Goals/Deliverables:
      Functional Rocket.Chat app with real-time asset tracking.
      Market alert system for price fluctuations and significant events.
      Intelligent summarization and prediction module.
      Fail-proof mechanism to avoid incorrect or misleading AI responses.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~

      💡 Receipts Processor and Reporting App powered by Multi-modal LLMs
      👥 Mentor(s): Maria Khelli, Sing Li
      📢 Communication Channel: idea-Receipts-Processor-and-Reporting-App-powered-by-Multi-modal-LLMs
      💬 Description:
      While attending a busy conferences or event, the need to keep track of receipts and then having to adding them up manually to fill in expense reports is a very common and tedious problem. This project is a Rocket.Chat app that completely automate the process.
      Details:
      The user will be able to take pictures of restaurant receipts on their phone and upload it into a specific channel (representing a single event, duration of time, or trip, and so on...).
      Upon request, the app should read and sum all the receipts producing a detailed report. Ideally, the input format and image size should be flexible and the report format should be customizable via templates.
      The app should never produce erraneous result under any circumstances, it should be able to recognize its limitation and decline to complete the task instead of giving potentially erraneous output.
      💪 Desired Skills:
      Rocket.Chat Apps Engine (TypeScript)
      Intermediate prompt engineering Skills
      Experience with image reasoning capabilities of available open source multi-modal LLMs
      🎯 Goals/Deliverables:
      A working Rocket.Chat app that will scan and sum all the restaurant receipts uploaded to a specific channel.
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~
      💡 Perfect AI Docs Assistant App
      👥 Mentor(s): Dnouv, Jeffery Yu
      📢 Communication Channel: idea-Perfect-AI-Docs-Assistant-App
      💬 Description:
      This project aims to build a Rocket.Chat App that provides a natural language interface for querying Rocket.Chat Docs (docs.rocket.chat). Instead of manually searching for answers, users can simply ask the app, and it will return a perfect, relevant response extracted and summarized from the documentation.
      For the very small dataset that we are working with, we aim to tune and optimize the well-known RAG agentic workflow for our specific purpose; ideally producing an optimized and perfect Ask the Docs Assistant for this subset of the Rocket.Chat documentation.
      Consider possibly:
      Retrieval-Augmented Generation (RAG) agentic workflow the AI/ML design pattern we're all familiar with
      Local embedding model needs to run in memory/CPU for maximum efficiency
      In-memory vector store run in the client with no persistence, subject of further optimization (chunking, match-selection, metadata) to tune for perfect results
      Context-aware follow-up responses not required but nice to have
      💪 Desired Skills:
      Rocket.Chat Apps Engine (TypeScript)
      Modern agentic workflows (including classic-RAG)
      Web Storage & IndexedDB (for caching, if needed)
      Intermediate prompt engineering
      Keen interest in contemporary applications of LLMs
      🎯 Goals/Deliverables:
      generation/creation of a perfect validation dataset, consisting of (1500, 5000, 10000) queriies and corresponding answer, that will be used in the benchmark/validation of the final assistant
      a fine-tuned compact LLM to be used in the last stage of the RAG agentic workflow (fine-tuned minimally on the dataset above)
      the perfect "ask the docs assistant" for our small dataset, running mostly on the client without heavy compute overhead, ideally scoring 90% plus on the benchmark
      (we like to thank our early community for helping us to fine-tune this set of deliverables)
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Intermediate/Advanced

      ~~~~~~~~~~
      💡Google Summer of Code Community Hub 2025
      👥 Mentor(s): Anjaneya Gupta
      📢 Communication Channel: idea-Google-Summer-of-Code-Community-Hub-2025
      💬 Description:
      Continuing our work on a "full stack component framework" in which a scalable website can be created by non-technical users using drag-and-drop components that not only include UI and client-side logic, but also pre-scaled server-side behaviors (or serverless impl).
      The ultimate use-case we have been working on is the community hub for Rocket.Chat Google Summer of Code. It will link all the despearate servers into one easy to customize and maintain uniform scalable web app (comprise of a set of full-stack components).
      This year's work will include:
      rebasing of the existing platform and components on Svelte 5
      moving the WYSIWYG "Syntax Sweetening" work done last year to this new platform
      implementation of auth via OIDC
      migrate over the event poster component (used for our demo day)
      migrate over the video-meet-your-mentor component
      implement the gsoc leaderboard component
      implement embeddedchat component
      💪 Desired Skills:
      Advanced Typescript
      Svelte 5
      AST concepts
      🎯 Goals/Deliverables:
      A functional community hub website that we will use for 2026; showcasing the platform and new components.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~
      💡AI Chat Workflows Automation App with multi-step reasoning
      👥 Mentor(s): Hardik Bhatia
      📢 Communication Channel: idea-AI-Chat-Workflows-Automation-App-with-multi-step-reasoning
      💬 Description:
      Build a Rocket.Chat app that will monitor messages in specified channels (possibly sent by specified individuals, possibly within certain specified time period, and so on... ) and then (as a second step) perform additional messaging operations based on those messages. Command should be issued in simple English. Bonus point for more than 2 steps in the reasoning.
      Some examples:
      "whenever @sing.li posts any welcome messages in #gsoc2025, immediately DM him with a thank-you note"
      
      "if any picture is uploaded to the #pets channel, send a message that says meow! if the pet is a cat, and a woof! otherwise"
      
      "whenever a message is posted that contains a four letter word beginning with letter F, delete that message immediately"
      
      "if my wife messaged with 'arrived' before I do, DM her sorry I will be late after 1 minute" 
      Recommended approach:
      leverage the latest open source specialized multi-step reasoning LLMs such as the DeepSeek distilled models
      make intelligent use of tools/function-calling and structured inference
      be sure to built in safety to offset erraneous output and/or hallucinations
      💪 Desired Skills:
      Rocket.Chat Apps Engine (TypeScript)
      Rocket.Chat messaging APIs
      Advanced prompt engineering Skills
      Experience with image reasoning capabilities of available open source multi-modal LLMs
      Experience working with multi-step reasoning LLMs
      Experience with tools/function-calling capabilities of modern LLMs
      Expereince with code generation and code completion LLMs
      Understanding of how to implement "safety first" when creating AI apps that may permenantly change the state of a production system
      🎯 Goals/Deliverables:
      Platform for generating functional automated chat workflows using LLMs.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Intermediate/Advanced
      📅 Message Timestamp Date Picker Components
      👥 Mentor(s): Martin Schoeler
      📢 Communication Channel: idea-Message-Timestamp-Date-Picker-Components
      💬 Description: Currently Rocket.Chat has a feature that allows users to send timestamps on messages, but not in an intuitive way. To send a timestamp you need to manually write it down with the correct date code. For example <t:1732557600:t>. This feature was added for Rocket.Chat Apps engine, but users can benefit from this too. The objective of this project is to create a new MessageToolBar item that displays a calendar and let the users select the date and time they would like to share, both in the desktop app and mobile apps.
      Some examples of the usage of the timestamp feature (you can test them today on the open.rocket.chat server!)
      Pattern: <t:{timestamp}:?{format}>
      {timestamp} is a Unix timestamp
      {format} is an optional parameter that can be used to customize the date and time format.
      Formats
      Format Description Example
      t Short time 12:00 AM
      T Long time 12:00:00 AM
      d Short date 12/31/2020
      D Long date Thursday, December 31, 2020
      f Full date and time Thursday, December 31, 2020 12:00 AM
      F Full date and time (long) Thursday, December 31, 2020 12:00:00 AM
      R Relative time 1 year ago
      The creation of tests for the new component is also expected, both end to end and unit if applicable.
      💪 Desired Skills: React, Typescript, React Native
      🎯 Goals/Deliverables: A new component on the MessageToolBar that allows users to add timestamps to their messages, both in desktop and mobile.
      ⏳ Project Duration: 90 hours. (Small)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~
      💡 Messages scheduling
      👥 Mentor(s): Ricardo Swarovsky
      📢 Communication Channel: idea-Message-Scheduling
      💬 Description:
      Add a native Rocket.Chat feature that lets users schedule messages to be sent later, directly integrated with the current send button. Since we serve users across multiple time zones, this feature will make it easier to schedule messages for the right time, no matter where they are.
      💪 Desired Skills:
      Awareness of Rocket.Chat server and client codebase (NodeJS and React)
      🎯 Goals/Deliverables:
      A Rocket.Chat feature that will allow users to schedule messages to be sent in the future
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Advanced

      ~~~~~~~~~~
      💡Client-side AI Support
      👥 Mentor(s): Sing Li, Ashutosh Singh Chauhan
      📢 Communication Channel: idea-Client-side-AI-Support
      💬 Description:
      This project adds applicaton API access to LLMs running in-browser, on-device and distributes the AI compute load from the server - allowing AI applications to scale massively.
      Not all client devices are capable of handling LLM loads, the deployment flow must detect and behave accordingly.
      Details:
      Modify current server deployment flows to install client-side LLMs as an option.
      Extend Apps Engine to support client-side logic; (optional) loading of the LLMs; and API access to the in-browser/on-device LLMs.
      Essential background:
      recent high performance lightweight models became available (Llama 3.2, Intern LM 2, Phi 3 mini, Qwen 2.5, Smol LM, Gemma 2b, DeepSeek distlled, and so on) requiring ONLY about 2GB additional memory and reasonable compute load
      breakthrough webgpu and webllm technology matured; and in-browser inference and LLM API access (WASM'ed Python code on top of HTML5/WebGPU standard) is a stable working reality
      big-tech vendors (phone and OS vendors such as Apple, Samsung, Microsoft, and so on ... ) are rapidly bringing client-side CLOSED SOURCE inference capability to their own applications with no roadmap in 2025 for general access
      💪 Desired Skills:
      Rocket.Chat Deployment Flows (DevOps)
      Advanced Typescript
      Awareness of WASM and webllm
      Python magician
      Good system design mindset
      🎯 Goals/Deliverables:
      Empower the development of scalable open source AI applications running in-browser for all Rocket.Chat users
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Advanced

      ~~~~~~~~~~
      💡End to End Encrypted Message Handling for Ruqola
      👥 Mentor(s): Montel Laurant, Aaron Ogle
      📢 Communication Channel: idea-E2E-messages-handling-for-Ruqola
      💬 Description:
      Add end to end encrypted message feature to the Ruqola client from KDE. Ruqola is the de-facto standard Rocket.Chat client running on KDE. This project will be co-mentored by an expert mentor from the KDE progject.
      Details:
      some UI elements to handle E2E encrypted messages is already in place
      careful consideration for key management is essential to a successful implementation
      how does the user get the key? what happens when he/she loses the key?
      what UI is needed to support re-generation of key?
      how does one display a channel with messages that may be encrypted by different keys?
      see End to End Encryption Specification
      💪 Desired Skills:
      Rocket.Chat API programming (REST and DDP)
      Solid experience with C++ programming
      Experience with large and complex C++ projects
      Working experience with KDE on Linux (such as kubuntu)
      Ideally already user of Ruqola
      🎯 Goals/Deliverables:
      Add support for E2E Encrypted messages in Ruqola.
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Advanced

      ~~~~~~~~~~
      💡 AI Google Forms / Typeform Survey Integration App
      👥 Mentor(s): Abhinav kumar
      📢 Communication Channel: idea-AI-Google-Forms-Typeform-Survey-Integration-App
      💬 Description:
      This app integrates any one of the popular survey tools (Google Forms, Typeform etc.) into Rocket.Chat to allow teams to create, distribute, and analyze quick polls or feedback forms without leaving the chat. Users can launch surveys, receive immediate notifications when responses are submitted, and have summary reports automatically posted to designated channels.
      Using natural language to create forms would be a huge plus for the project. Example - "Create a form to accept registration for the Annual Tech Conference. It should collect full name, email address, company, and dietary restrictions. Validate the email field, send me a notification on each new registration, and post a summary report in the #conference-registrations channel."
      Key Features:
      Slash Commands: Launch new surveys or share form links directly from Rocket.Chat.
      Inline Notifications: Receive real-time alerts when survey responses are submitted.
      Automated Reporting: Generate and post periodic summary reports in designated channels.
      Use Case:
      Enables teams to capture immediate feedback and conduct internal polls seamlessly within Rocket.Chat, enhancing decision-making and team engagement.
      💪 Desired Skills:
      Proficiency with Rocket.Chat Apps Engine (TypeScript)
      Experience with REST APIs and third‑party service integrations
      Familiarity with survey platforms (Google Forms, Typeform) and their APIs
      🎯 Goals/Deliverables:
      Develop a Rocket.Chat App that connects to Google Forms/Typeform.
      Implement slash commands for survey creation and sharing.
      Integrate real-time notifications for survey responses.
      Automate the generation and posting of summary reports.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy/Intermediate

      ~~~~~~~~~~
      💡Trip Helper App
      👥 Mentor(s): Yuriko Kikuchi, Sing Li
      📢 Communication Channel: idea-Trip-Helper-App
      💬 Description:
      This LLM-powered app will suggest interesting events and happenings for users during their trip.
      Details:
      While on trip in a foreign place, a user can take a photo of his surroundings and upload it to a channel
      The app will first process the image by passing it to an image reasoning multi-modal LLM to ascertain the location or point of interest or event venue (perhaps reinforced by GPS location information).
      Then in a second step an(other) LLM's tools/function-calling capability is used to fetch up-to-date events and happening information over the Internet, catering for the user's current interest.
      Finally, a friendly summary report is produced by an(other) LLM as the last step of a RAG pipeline.
      This app should never produce erraneous output. It should know its own limitaion and decline to report if in doubt.
      💪 Desired Skills:
      Rocket.Chat Apps Engine (TypeScript)
      Familiarity with the "RAG" agentic workflow
      Intermediate prompt engineering Skills
      Experience with image reasoning capabilities of modern open source multi-modal LLMs
      Experience with tools/function-calling capabilities of modern LLMs
      🎯 Goals/Deliverables:
      A working Rocket.Chat App that assists users with latest happenings around them wherever they may be while on any trip.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Intermediate/Advanced

      ~~~~~~~~~~
      💡 AI Transcription and Translation for Voice Messages App
      👥 Mentor(s): Dhurv Jain, Abhinav Kumar
      📢 Communication Channel: idea-AI-Transcription-and-Translation-for-Voice-Messages-App
      💬 Description:
      Rocket.Chat already supports sending voice messages. This project enhances that feature by providing on-demand or real-time transcription and translation of voice messages. Users can choose to transcribe voice messages to text and optionally translate into their preferred language, thereby boosting accessibility and making communication more inclusive.
      Possible Milestones:
      UI/UX Enhancements:
      Integrate options into the existing voice message interface for triggering transcription and translation.
      Backend Processing:
      Integrate with a speech-to-text service (e.g., Google Cloud Speech-to-Text or open‑source alternatives like Vosk) to transcribe voice messages.
      Translation Integration:
      Connect with a translation API (e.g., Google Translate or LibreTranslate) to convert transcriptions into the target language.
      Performance & Accuracy Tuning:
      Optimize for low latency and high transcription accuracy, ensuring the system gracefully handles slow or unavailable external APIs.
      💪 Desired Skills:
      Experience with Rocket.Chat Apps Engine (TypeScript)
      Familiarity with speech-to-text and translation APIs
      Skills in mobile and web UI/UX enhancement
      Ability to optimize performance and implement robust error handling
      🎯 Goals/Deliverables:
      A Rocket.Chat App that enhances the existing voice message feature with transcription and translation capabilities.
      Seamless integration with external speech-to-text and translation services.
      An intuitive interface that allows users to trigger transcription and translation on demand or in real time.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Intermediate/Advanced

      ~~~~~~~~~~
      💡Improve Private Team and Private Channel Administration
      👥 Mentor(s): John Crisp
      📢 Communication Channel: idea-Private-Teams-and-Private-Channels-Adminitration-Improvements
      💬 Description:
      While it is possible to create private team and private channels in Rocket.Chat, the ability for the server's administrator to perform administrative tasks on them are currently very limited (unless the server admin is part of the private channel or private team). This was done by the original "team designer" to afford some local privacy for these these users.
      This project aims to improve this situation by adding the ability for the server administrator to (optionally) override (via configuration on admin panel) to directly access and administer private team and private channels.
      This should include minimally the following abilities:
      add/remove users in private channels
      assign and change the roles of private channel users
      add/remove/rename private team channels
      add/remove/modify the members of private teams
      assign and change the roles of private team users
      access private channels and private teams in the Directory
      💪 Desired Skills:
      In depth understanding of Rocket.Chat core
      Advanced Typescript
      Familiarity with Rocket.Chat UI/Ux
      Interest in administration and management of sub-communities on large chat servers (our Team concept)
      🎯 Goals/Deliverables:
      Ability for server administrator to better administer private teams and private channels.
      ⏳ Project Duration: 175 hours (Medium)
      📈 Difficulty: Intermediate

      ~~~~~~~~~~
      💡Channel Header Customization
      👥 Mentor(s): TBD
      💬 Description:
      Currently, all elements on the channel header are fixed and mandatory.
      This project aims to make the channel header customizable, allowing the owner/administrator to hide some components (where it makes sense).
      One should be able to hide any combination of the buttons in the header.
      Implementation must take UI/Ux design into consideration to ensure the elements showing are still consistent with the overall Rocket.Chat design aesthetics.
      💪 Desired Skills:
      Understanding of Rocket.Chat core
      UI/Ux development
      Advanced Typescript
      Like coding, love design
      🎯 Goals/Deliverables:
      Fully customizable channel header for Rocket.Chat.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Easy

      ~~~~~~~~~~
      💡Fine-grained upload/download permissions
      👥 Mentor(s): TBD
      💬 Description:
      Add and implement permissions to make possible the fine-grained control of who can upload or download files/attachments. The implementation must enable the per user control of upload, download individually (or in combination) when users are on mobile, desktop, or web app. (and any combinations of)
      💪 Desired Skills:
      Understanding of Rocket.Chat core
      Understanding of Rocket.Chat's role and permission system
      Advanced Typescript
      Interest in cyber security
      🎯 Goals/Deliverables:
      Ability for administrators to control the upload/download capability per user, in combination with access client type.
      ⏳ Project Duration: 90 hours (Small)
      📈 Difficulty: Intermediate
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/rocket.chat/
    idea_list_url: https://github.com/RocketChat/google-summer-of-code/blob/main/google-summer-of-code-2025.md#-project-ideas

  - organization_id: 184
    organization_name: stdlib
    no_of_ideas: 43
    ideas_content: |
      
      Implement a broader range of statistical distributions
      Linked issue: #2
      Idea
      The goal of this idea is to implement all distributions found in SciPy stats. Distribution support will entail implementing APIs for computing PDFs, CDFs, quantiles, and other distribution properties. Additionally, stdlib should support APIs for drawing random variates from any implemented distributions.
      Expected Outcomes
      stdlib users will be able to construct, and compute various properties of, every statistical distribution present in SciPy in JavaScript.
      Involved Software
      No runtime dependencies should be necessary. SciPy will be necessary in order to provide reference test results.
      Prerequisite Knowledge
      JavaScript, Node.js. Familiarity with C/C++/Fortran would help.
      Difficulty
      Intermediate. Difficulties may arise for distributions whose properties and moments have complicated formulations. Developing JavaScript implementations will likely require consulting C/C++ and possibly Fortran code.
      Project Length
      350 hours.

      ~~~~~~~~~~
      Provide APIs for computing Fast Fourier Transforms
      Linked issue: #3
      Idea
      The goal of this idea is to expose a set of Fast Fourier Transform (FFT) interfaces similar to those available in NumPy and as documented in the Data APIs Array API specification. Similar to stdlib's BLAS interfaces, we may want to allow switching out the FFT backend.
      One potential reference implementation which could form the basis of this idea is pocketfft, as done in NumPy:
      https://github.com/mreineck/pocketfft
      https://gitlab.mpcdf.mpg.de/mtr/pocketfft
      Expected Outcomes
      stdlib users would be able to evaluate FFT operations on stdlib ndarrays. Ideally, we'd also provide a set of C APIs.
      Involved Software
      Will need to consult reference implementations in C/Fortran.
      Prerequisite Knowledge
      JavaScript, Node.js, C/C++/Fortran
      Difficulty
      Hard. This may be a straightforward port, or it may not be. More R&D is needed.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @rreusser @Pranavchiku @czgdp1807

      ~~~~~~~~~~
      Developer dashboard for tracking ecosystem build failures
      Linked issue: #4
      Idea
      The stdlib project encompasses over 3500 repositories which are orchestrated via a centralized repository. While orchestration largely works as intended, build failures do happen, and quickly detecting and resolving build failures in standalone repositories is critical to prevent downstream breakages and ensure ecosystem integrity.
      The goal of this idea is to build a developer dashboard to display in real-time standalone repository build failures. We currently have the backend database which collects build results in real-time; however, we have yet to build a frontend for viewing and analyzing such data.
      The expected roadmap is as follows:
      Build a Node.js backend for querying a PostgreSQL database.
      Build a frontend dashboard which interfaces with the backend. As this will be a developer facing application, the choice of technologies is greenfield. Potential options may include ESBuild, tailwind, etc.
      Add support for filtering the dashboard based on build status and other features.
      Allow for quick navigation to repository resources and build artifacts.
      Extend the dashboard to support historical overviews and other drill down metrics.
      Expected Outcomes
      stdlib developers will be able to navigate to a webpage and see the build status for all repositories at once.
      Involved Software
      This will involve building a frontend application and interfacing with a backend for querying a PostgreSQL database. We may want to try more "cutting edge" technology here, such as ESBuild, tailwind, etc.
      Prerequisite Knowledge
      JavaScript, Node.js, CSS, HTML, JSX.
      Difficulty
      Intermediate. Requires a fair amount of frontend engineering knowledge and modern frontend application development.
      Project Length
      175/350 hours. A skilled contributor may be able to execute on this faster. If so, scope could be expanded to include analytics and historical overviews.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Expand support for additional pseudorandom number generators
      Linked issue: #5
      Idea
      The goal of this idea is to implement a variety of PRNGs for use within stdlib to generate pseudorandom numbers. The project currently uses Mersenne Twister as its default PRNG; however, this PRNG, while common, is not ideal given its comparatively large internal state. Would be great to have a collection of PRNGs, such as PCG, Philox, Xorshift, and more.
      Expected Outcomes
      stdlib users will have a wide selection of PRNGs from which to choose from based on their individual needs and considerations. Having a large selection of PRNGs will useful when replicating the results of numerical simulations which may use a PRNG which is not one of the currently supported stdlib PRNGs. Additionally, a desired outcome would be if we could replace MT19937 with a new default PRNG.
      Involved Software
      No other software should be necessary. We may be a bit constrained based on 32-bit limitations in JS. This would not, however, stop us from implementing in C for use in generating arrays of random numbers.
      Prerequisite Knowledge
      JavaScript, Node.js. Familiarity with C/C++/Fortran would help.
      Difficulty
      Intermediate/Hard. Depends. Some PRNGs may be straightforward to implement. Others, not so much.
      Project Length
      175/350 hours. This idea can be adjusted according to needs and availability.
      Potential Mentors
      @kgryte @Planeshifter @Pranavchiku

      ~~~~~~~~~~
      Add support for visualizing benchmark results
      Linked issue: #6
      Idea
      While we currently support running benchmarks, we have yet to provide a means for easily visualizing and comparing benchmark results. Previously, when wanting to visualize and compare benchmark results, one has needed to manually parse TAP results and then plug into some other software (e.g., vega or Plotly).
      The idea for this project would be to 1) implement a TAP parser with support for the latest TAP specification and 2) provide a plot frontend for consuming parsed TAP results. The plot frontend could be as simple as a Unicode bar chart plotter, which would be in line with our existing Unicode plotting facilities.
      Expected Outcomes
      Developers will be able to run benchmarks and visually compare benchmark results based on the namespace and parameterization. Ideally, the plot would include small multiple/facet visualizations.
      Involved Software
      No other software or dependencies should be necessary. Will need to consult a reference TAP parser implementation (e.g., node-tap).
      Prerequisite Knowledge
      JavaScript and Node.js.
      Difficulty
      Intermediate.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Develop a project test runner
      Linked issue: #7
      Idea
      Currently, stdlib uses tape. The goal of this idea is to migrate away from tape and develop a test runner in-house, similar to @stdlib/bench/harness. This has long been on our TODO list and would allow us to have a simple test runner which is oriented toward stdlib conventions (e.g., we don't use most of the assertion methods in tape).
      Bonus points if we can migrate away from istanbul to nyc or c8; however, this may be tricky if we want to support older Node.js versions.
      Expected Outcomes
      All unit tests have migrated to the in-house runner.
      Involved Software
      No additional runtime deps. Will need to consult tape as a reference implementation, along with our existing @stdlib/bench/harness implementation.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate.
      Project Length
      175/350 hours. The scope of this idea can be adjusted depending on availability.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Reimagine the stdlib plot API and implementation
      Linked issue: #8
      Idea
      Currently, stdlib has a bespoke plot API which is useful for fast static rendering. However, our implementation is quite limited in the types of plots it can produce. The goal of this idea is to refactor our plot API to build atop of vega (or its specifications). For this, we'd need to migrate to an async plot generation API, which is probably necessary regardless if we want to support WebGL or some other async rendering engine.
      Ideally, we would retain the same plot API and internally generate a vega specification.
      Expected Outcomes
      We can generate simple plots using the new plot implementation.
      Involved Software
      This will involve using vega (or something similar depending on whether vega is sufficiently maintained). We will want to transpile to ES5 and vendor in order to ensure that we can support our supported Node.js versions.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate/Hard.
      Project Length
      350 hours. This project has the potential to spiral out of control, as there are many unknowns we'd need to answer. Mentor would likely need to be actively involved in order to perform R&D and properly scope.
      Potential Mentors
      @kgryte @Planeshifter @rreusser

      ~~~~~~~~~~
      Achieve feature parity with async.js
      Linked issue: #9
      Idea
      Currently, stdlib has a limited set of dedicated "async" APIs for performing various utility operations. The goal of this idea is to achieve feature parity with async.js, a popular library providing callback-based async APIs.
      Motivation for this idea stems from certain advantages afforded by callback-based asynchronous programming. Notable among them is superior performance and the ability to more readily return and inspect status objects.
      Expected Outcomes
      stdlib will have more or less 1:1 feature parity with async.js APIs.
      Involved Software
      async.js will serve as a reference implementation for API design. Will want to modify to match stdlib conventions.
      Prerequisite Knowledge
      JavaScript.
      Difficulty
      Beginner. Would benefit from someone with JavaScript experience.
      Project Length
      175/350 hours. Can be scoped accordingly.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Achieve feature parity with builtin Node.js fs module
      Linked issue: #10
      Idea
      Achieve feature parity with Node.js fs package. We currently only support a limited selection of fs methods. Would be useful to support more.
      Part of this work involves providing an abstraction layer of Node.js built-ins in order to support newer functionality (e.g., options and/or behavior) not present in older Node.js versions. This is similar in concept to the userland readable-stream package.
      Expected Outcomes
      stdlib will have complete feature parity with Node.js built-ins.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate. Could require some creative solutions to ensure that abstractions work for older Node.js versions.
      Project Length
      175/350 hours. Can be scoped accordingly.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Add support for the multivariate normal distribution
      Linked issue: #11
      Idea
      The goal of this idea is to implement the multivariate normal distribution. This distribution is fundamental in a wide variety of statistical applications and will help unblock stdlib in offering additional statistics APIs.
      As a starting point, SciPy's multivariate normal distribution API and implementation could provide a suitable point of reference:
      https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html
      Expected Outcomes
      Users will be able to evaluate the PDF, CDF, logPDF, and logCDF and be able to draw random variates from a specified distribution.
      Involved Software
      No other software is necessary. Will require reading reference implementations written in Python, R, and Julia.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate.
      Project Length
      175/350 hours. Can be scoped accordingly. A skilled contributor should be able to complete in 175 hours with the potential of using their implementation to implement higher order statistics APIs.
      Potential Mentors
      @kgryte @Planeshifter @Pranavchiku

      ~~~~~~~~~~
      Develop a Google Sheets extension which exposes stdlib functionality
      Linked issue: #13
      Idea
      The goal of this idea is to allow users to call stdlib APIs from within Google Sheets. This will allow users to perform linear algebra and various machine learning operations directly on spreadsheet data and all within the browser.
      In order to execute on this idea, we'll want to support
      two-dimensional array broadcasting semantics
      performant element-wise iteration APIs
      input argument validation tailored to the Sheets context
      Fused operations to avoid unnecessary network calls
      documentation and tutorials demonstrating API usage
      good generation and automation for creating extension builds
      testing and performance measurement to guard against regressions
      Expected Outcomes
      Google Sheets users will be able to install an extension which exposes stdlib functionality, run statistical tests, evaluate mathematical functions, and perform linear algebra operations using stdlib.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Beginner/Intermediate.
      Project Length
      175/350 hours. Can be scoped accordingly. A skilled contributor can work on a strategy for performant fused operations.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Stdlib API dependency explorer
      Linked issue: #14
      Idea
      stdlib is a large (and growing!) project, which can make project navigation challenging. The goal of this idea is to provide a visual representation of an API's dependency graph directly in the stdlib API documentation. Initial thinking is that would be an interactive network diagram in which nodes present package dependencies and allow for navigation; however, other visual representations may be possible.
      By providing such a means for navigating the project, users could more readily deepen their understanding of the stdlib code base, identify potential issues, and better understand how underlying APIs are used.
      Expected Outcomes
      A user will be able to navigate to a package's documentation page, click to display a network graph, and then click on nodes within that graph to explore the documentation of package dependencies.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js, HTML/CSS, JSX.
      Difficulty
      Beginner/Intermediate.
      Project Length
      175 hours.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Add support for bootstrap and jackknife resampling
      Linked issue: #15
      Idea
      Manually constructing confidence intervals and other statistical properties can be useful when no analytic solution exists. The goal of this idea to implement APIs for bootstrap and jackknife resampling.
      Expected Outcomes
      Users will be to resample provided datasets.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Beginner/Intermediate.
      Project Length
      175/350 hours. Can be scoped accordingly. Scope can be expanded to implement different bootstrap algorithms.
      ~~~~~~~~~~
      Develop a Jupyter backend for interfacing with the stdlib REPL
      Linked issue: #16
      Idea
      Jupyter is a dominate force in scientific computing. While some effort has been done to expose JavaScript kernels to Jupyter/JupyterLab, most of these kernels are under-developed or lack numerical functionality.
      The goal of this idea would be to develop a Jupyter backend based on stdlib.
      Expected Outcomes
      A JupyterLab user will be able to connect to a stdlib kernel and invoke stdlib operations.
      Involved Software
      This goal will require interfacing with the Jupyter technology stack, including ZeroMQ and implementing messaging protocols.
      Prerequisite Knowledge
      JavaScript, Node.js. Experience with Python would be very helpful.
      Difficulty
      Hard.
      Project Length
      350 hours. This idea has many unknowns and will be hard to scope.
      Potential Mentors
      @kgryte @Planeshifter

      ~~~~~~~~~~
      Implement additional statistical tests
      Linked issue: #17
      Idea
      Implement various statistical tests which are not currently implemented in stdlib, but are implemented in other envs such as R, Python (SciPy, statsmodels), Julia, and MATLAB.
      Expected Outcomes
      stdlib will have a broader array of statistical tests which can operate on ndarrays.
      Involved Software
      No other software should be necessary. However, we will need to do a needs analysis to determine which prerequisite packages/functionality is necessary in order to allow these tests to be implemented (e.g., BLAS, ndarray slicing, etc).
      Prerequisite Knowledge
      JavaScript, Node.js. Familiarity with R, Python, C/C++ would be very useful, as will need to consult reference implementations.
      Difficulty
      Hard. Depends on the reference implementation requirements and algorithmic difficulty.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @Pranavchiku

      ~~~~~~~~~~
      Generate web documentation from JSDoc comments
      Linked issue: #19
      Idea
      stdlib relies heavily on JSDoc comments to document its source code. Currently, the project has only rudimentary support for generating HTML docs from those comments. The goal of this idea would be to
      Write an in-house JSDoc parser.
      Generate HTML documentation from the parsed comments which is capable of supporting project conventions and its embrace of radical modularity.
      JSDoc comments are oriented toward JavaScript source files; however, stdlib also uses similar documentation practices for documenting C source files and make files. A possible extension to the in-house JSDoc parser would be to support these other source file types. As those file types may require separate AST parsers, supporting other file types is likely to require writing separate comment parsers for each source type.
      Expected Outcomes
      In addition to the current API documentation, a user will be able to navigate to a package's JSDoc documentation to gain more insight into supported input and output dtypes and implemented algorithms. This would be especially useful for rendering the extended JSDoc comment of elementary mathematical functions.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js, HTML/CSS.
      Difficulty
      Intermediate.
      Project Length
      350 hours. The length can likely be scaled down; however, there are several unknowns, and it may not be straightforward to develop an in-house parser which caters to the unique structure and setup of stdlib. For advanced contributors, possibility to explore support for source file types other than JavaScript (e.g., C and make).
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Refactor generated TypeScript interface documentation
      Linked issue: #20
      Idea
      Currently, stdlib publishes TypeScript interface documentation in its web-based API documentation. The generated documentation monkey-patches tsdoc to handle generating documentation across the entire mono-repo. The goal of this project is to refactor/rethink this approach and provide a solution capable of addressing the unique constraints of the stdlib project.
      Expected Outcomes
      At a base level, it would be great if we had a working documentation render which did not require monkey-patching. A more difficult, but potentially more desirable, outcome would be if TypeScript documentation was not rendered as a separate website, but rather was integrated within the docs as simply another page/fragment.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js, HTML/CSS, TypeScript, JSX/React.
      Difficulty
      Intermediate.
      Project Length
      175/350 hours. Length will depend on the nature of the proposed solution (e.g., needing to write a custom TypeScript parser vs modifying the existing tsdoc library).
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Use ES6 modules for running unit tests and benchmarks in web browsers
      Linked issue: #21
      Idea
      Currently, when generating stdlib API documentation, we generate UMD bundles for unit tests and benchmarks. When a user navigates to our package documentation, they can load unit tests and benchmarks and have those run without needing to setup a local environment. The pain point here is that creating separate bundles for each package is time consuming and adds significant heft to the www repo.
      The goal of this idea is to refactor the way we support unit tests and benchmarks to use ES6 modules and potentially skip bundling altogether. This has the downside of not supporting older browsers which don't support the <module> tag, but is probably fine considering that running package unit tests and benchmarks is likely a forward looking concern.
      Expected Outcomes
      Users will be able to run unit tests and benchmarks directly in their web browsers by navigating to project API documentation and what is loaded are ES6 modules, not UMD bundles.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js, HTML/CSS, JSX/React.
      Difficulty
      Intermediate.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @steff456
      
      ~~~~~~~~~~
      Migrate web API documentation to use matomo and instrument for better understanding user navigation behavior
      Linked issue: #22
      Idea
      Currently, the stdlib web-based API docs use GA for analytics and have only minimal integration. E.g., the API docs application is a SPA which uses React and the app does not record changes in page views; we only record first hits.
      The goal of this idea is to migrate to using matomo and take advantage of its privacy features. The work will involve instrumenting the API documentation application and integrating with matomo. A potential stretch goal would be to setup dashboards for reporting so that we can better understand user behavior and continue to improve project documentation.
      Expected Outcomes
      All user interaction data is logged to matomo and stored in a hosted database.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js, HTML/CSS, JSX/React.
      Difficulty
      Intermediate.
      Project Length
      350 hours. Can be adjusted depending on skill and ability.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~

      Improve the REPL presentation framework
      Linked issue: #23
      Idea
      stdlib currently offers a REPL presentation framework for authoring presentations for use directly in the REPL. This is particularly useful for creating interactive tutorials illustrating how to use stdlib functionality for data analysis and visualization from the terminal. Some functionality is missing which would be quite useful. E.g.,
      ASCII plotting
      ASCII animations
      syntax highlighting
      pretty printing tables
      speaker notes
      multiplexing
      theming
      Expected Outcomes
      The REPL presentation framework will have additional features similar to those in WYSIWYG presentation applications.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate.
      Project Length
      175/350 hours. Can be scoped according to project length.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Functions for numerical integration and differentiation
      Linked issue: #24
      Idea
      The goal of this idea is to add functions for numerical integration or differentiation to stdlib as building blocks for downstream algorithms. The functions could be ported from permissively licensed open-source libraries in other languages such as C or Fortran or alternatively be implemented from scratch by consulting the literature and reference implementations from various languages.
      Some work along these lines has been started in the scijs ecosystem, which can be used for initial inspiration (e.g., https://github.com/scijs/ode45-cash-karp), and more generally in SciPy (e.g., https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.ode.html).
      Expected Outcomes
      stdlib will have a range of robust functions for performing numerical integration or differentiation
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @rreusser @Pranavchiku @czgdp1807

      ~~~~~~~~~~
      Symbolic Math
      Linked issue: #25
      Idea
      The goal of this idea is to add basic support for symbolic math operations in stdlib.
      Expected Outcome
      Users have the ability to perform basic symbolic math operations in JavaScript, such as solving equations, simplifying expressions, and using mathematical functions.
      Involved Software
      No other software should be necessary.
      Prerequisite Knowledge
      JavaScript, Node.js, and an understanding of mathematics and calculus.
      Difficulty
      Intermediate
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @rreusser

      ~~~~~~~~~~
      Make code blocks on website documentation interactive
      Linked issue: #26
      Idea
      Currently, all code blocks in the documentation at https://stdlib.io/docs/api/latest are static. To make example code more useful and engaging, it would be nice to have interactive code shells on the website that could be edited and would provide real-time return annotations.
      Some initial brainstorming has been done to inform how this would work, but, at minimum, we'd need to
      convert READMEs to structured data to allow for more straightforward transformation
      support dynamic loading of relevant stdlib packages used in example code blocks
      lazily integrate a code editor into documentation pages
      implement security measures to prevent malicious usage
      Expected Outcomes
      Improved user experience on the website, as the code examples would become editable and interactive. Return annotations would have to update in real-time, and additional contextual help could be provided via overlays etc. Another outcome would be to make it easy to switch between ES5 and ES6 for code blocks.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, HTML/CSS, React + JSX
      Difficulty
      Hard.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Optimization Algorithms
      Linked issue: #27
      Idea
      We currently do not have optimization algorithms in stdlib. Having support for Linear Programming, Convex Optimization, Quadratic Programming, and/or Non-Linear Optimization algorithms would be a great addition.
      Expected Outcomes
      stdlib will have a broad array of optimization algorithms for solving problems.
      Involved Software
      No other software should be necessary. However, we will need to do a needs analysis to determine which prerequisite packages/functionality is necessary in order to allow these algorithms to be implemented (e.g., BLAS).
      Prerequisite Knowledge
      JavaScript, Node.js. Familiarity with R, Python, C/C++ would be very useful, as will need to consult reference implementations.
      Difficulty
      Hard. Depends on the reference implementation requirements and algorithmic difficulty.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @rreusser @Pranavchiku @czgdp1807
      
      ~~~~~~~~~~
      Linear Algebra Functionality
      Linked issue: #28
      Idea
      Currently, support for linear algebra operations in stdlib is limited. The goal of this idea would be to implement algorithms for linear algebra operations such as matrix multiplication, calculating the matrix inverse, eigenvalue calculation, singular value decomposition, Cholesky & LU Decomposition, and the like. This overlaps with the goal of increasing the amount of BLAS and LAPACK that is available in stdlib.
      Expected Outcomes
      stdlib will have extended support for linear algebra operations which can be used to solve problems involving matrices and vectors.
      Involved Software
      No other software should be necessary. However, we will need to do a needs analysis to determine which prerequisite packages/functionality is necessary in order to allow these operations to be implemented (e.g., BLAS, ndarray slicing, etc).
      Prerequisite Knowledge
      JavaScript, Node.js. C, Fortran. Familiarity with linear algebra would be very useful, as will need to consult and understand reference implementations.
      Difficulty
      Hard. Depends on the reference implementation requirements and algorithmic difficulty.
      Project Length
      350 hours.
      Potential Mentors
      @kgryte @Planeshifter @Pranavchiku @czgdp1807 @rreusser

      ~~~~~~~~~~
      Achieve ndarray API parity with built-in JavaScript arrays
      Linked issue: #33
      Idea
      Built-in JavaScript arrays (and typed arrays) have a number of methods for creating, transforming, and manipulating array contents (e.g., forEach, map, reverse, slice, filter, etc). These APIs provide base level functionality forming a default vocabulary for working with array data.
      The goal of this idea is to create functional analogs of array methods for working with ndarrays, which are efficient data structures for operating on multi-dimensional data. The main difficulty in implementing analogs is in ensuring efficient iteration of non-contiguous data. The main patterns for such iteration have been established in stdlib, but work remains to apply such patterns for top-level array-equivalent APIs.
      Expected Outcomes
      Users will be able to use functional APIs (exposed as part of individual packages) for operating on ndarrays in a manner similar to how users can use prototype methods available on built-in arrays and typed arrays.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      For APIs not accepting callbacks, certain kernels can be implemented in C, as time and scope allow.
      Difficulty
      Intermediate. Writing the loop kernels can be involved, but, once understood, are straightforward to apply.
      Project Length
      90/175/350 hours. Can be scoped accordingly. Scope can be expanded to implement additional ndarray kernels outside of Array method equivalents.
      Potential Mentors
      @kgryte @Planeshifter @steff456 @rreusser

      ~~~~~~~~~~
      Develop C implementations for base special mathematical functions
      Linked issue: #34
      Idea
      This idea builds on the work outlined in stdlib-js/stdlib#649. Namely, implementing base special mathematical functions in C. Currently, all special mathematical functions have JavaScript implementations, which are often ports from other languages.
      The goal of this idea is to port all JavaScript implementations to C. Having such implementations will allow stdlib to provide Node.js native add-ons for higher performance ndarray computation and is more generally necessary for achieving NumPy/SciPy parity.
      Expected Outcomes
      Users will be able to leverage C implementations for use in Node.js native add-ons, and stdlib will be able to expose element-wise APIs for evaluating base special math functions over ndarrays.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      C, JavaScript, Node.js.
      Difficulty
      Intermediate. Familiarity with C is beneficial. This idea mainly involves porting existing implementations (many of which are written in C/C++) and doing so in a manner which conforms with stdlib conventions.
      Project Length
      90/175/350 hours. Can be scoped accordingly. Scope can be expanded to implement new special mathematical functions.
      Potential Mentors
      @kgryte @Planeshifter @steff456 @rreusser @Pranavchiku @czgdp1807

      ~~~~~~~~~~
      Develop an Excel add-on which exposes stdlib functionality
      Linked issue: #35
      Idea
      The goal of this idea is to allow users to call stdlib APIs from within Excel. This will allow users to perform linear algebra and various machine learning operations directly on spreadsheet data and all within the browser.
      In order to execute on this idea, we'll want to support
      two-dimensional array broadcasting semantics
      performant element-wise iteration APIs
      input argument validation tailored to the Sheets context
      Fused operations to avoid unnecessary network calls
      documentation and tutorials demonstrating API usage
      good generation and automation for creating extension builds
      testing and performance measurement to guard against regressions
      This idea is the Excel version of #13.
      Expected Outcomes
      Excel users will be able to install an extension which exposes stdlib functionality, run statistical tests, evaluate mathematical functions, and perform linear algebra operations using stdlib.
      Involved Software
      No other software is necessary; however, access to a local copy of Excel will be beneficial. While Microsoft 360 can be used, debugging is more difficult and less stable.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Beginner/Intermediate.
      Project Length
      175/350 hours. Can be scoped accordingly. A skilled contributor can work on a strategy for performant fused operations.
      Potential Mentors
      @kgryte @Planeshifter @steff456

      ~~~~~~~~~~
      Add BLAS bindings and implementations for linear algebra
      Linked issue: #36
      Idea
      BLAS routines are standard building blocks for performing basic vector and matrix operations. These building blocks are leveraged by most modern numerical programming languages and libraries, including NumPy, SciPy, Julia, MATLAB, R, and others.
      The goal of this idea is to
      reimplement reference BLAS routines in free-form Fortran 95
      port reference BLAS routines to C
      port reference BLAS routines to JavaScript
      write Node.js bindings to allow calling BLAS routines in compiled C/ Fortran from JavaScript
      Expected Outcomes
      Users will be able to call BLAS routines from JavaScript. In web browsers, BLAS routines will be in JavaScript. In Node.js, provided native bindings have been compiled, BLAS routines will either be ported reference implementations or hardware optimized system libraries.
      Involved Software
      No other software is necessary apart from standard compilers (GCC, gfortran).
      Prerequisite Knowledge
      C, Fortran, JavaScript, Node.js.
      Difficulty
      Intermediate. Familiarity with C and Fortran will be beneficial. This idea mainly involves porting existing implementations and doing so in a manner which conforms with stdlib conventions.
      Project Length
      90/175/350 hours. Can be scoped accordingly.
      Potential Mentors
      @kgryte @Planeshifter @steff456 @rreusser @Pranavchiku @czgdp1807
      
      ~~~~~~~~~~
      Implement incremental (online) machine learning algorithms
      Linked issue: #37
      Idea
      The goal of this idea is to implement incremental machine learning algorithms to allow for real-time regression and classification. Such online algorithms would allow for point-by-point data processing and avoid the sometimes costly overhead of batch processing. Online algorithms are particularly useful in data streaming contexts (e.g., user clicks, photon collection, etc).
      While stdlib includes some incremental algorithms (binary classification, k-means, and stochastic gradient descent regression), the project would benefit from additional algorithms.
      Individuals interested in pursuing this idea should be prepared to research possible algorithms and propose specific APIs.
      Expected Outcomes
      stdlib will expose one or more additional APIs for incremental machine learning.
      Involved Software
      No other software is necessary.
      Prerequisite Knowledge
      JavaScript, Node.js.
      Difficulty
      Intermediate. In order to implement ML algorithms, individuals will likely need to consult reference implementations written in other languages. Porting from these implementations may not be straightforward depending on the features involved.
      Project Length
      90/175/350 hours. Can be scoped accordingly.
      Potential Mentors
      @kgryte @Planeshifter
      
      ~~~~~~~~~~
      Add support for string arrays in stdlib
      Linked issue: #44
      Idea
      Similar to what's described in #43, a need exists to expand array data type support beyond numeric data types. One such data type is a string data type. The rationale for having a dedicated string data type is for better interoperation between JavaScript and C, and this is particularly paramount for supporting ndarrays having a string data type, as much of ndarray iteration machinery is written in C.
      Accordingly, the goal of this project is to add a dedicated string typed array called a StringArray, which will support variable-length strings. This new array type should follow a similar path to that of @stdlib/array/complex64, which provides a typed array dedicated to single-precision complex floating-point numbers; namely, StringArray should support standard typed array methods, as well as provide accessors for getting and setting array elements.
      Note, however, that a StringArray should be a typed array. A StringArray should not wrap a "generic" array. Instead, the array should be backed by fixed length memory, similar to how @stdlib/array/complex64 is backed by a Float32Array. One possibility is backing StringArray instances with Node.js Buffer objects, which are, in turn, Uint8Arrays.
      There are, however, some design considerations; namely, how to handle setting of array elements. In particular, what happens when a user attempts to update a StringArray element with a larger string? Does that lead to a new memory allocation and data copy? Or should elements have a fixed allocation to allow for elements to grow until some maximum size?
      As part of this project, not only will a new StringArray be added to the project, but it will be integrated throughout stdlib. This will entail adding support for StringArrays wherever arrays are accepted/used, following the same precedent established by @stdlib/array/complex64 and other custom array types in stdlib. This includes adding support for string arrays in ndarray APIs.
      Prior Art
      Recent work in NumPy adding UTF-8 variable length string support: https://numpy.org/neps/nep-0055-string_dtype.html
      Expected outcomes
      The expected outcomes of this idea should be (1) creation of a new @stdlib/array/string package exposing a new typed array constructor, (2) support for StringArray instances throughout @stdlib/array/*, (3) support for StringArray instances as backing arrays for ndarrays (which may involve working with various C APIs), and (4) any other integration opportunities.
      Status
      While no work has been done to create a new @stdlib/array/string package, there exists prior art for adding custom typed arrays to stdlib; namely, Complex64Array and Complex128Array.
      Involved software
      No special software for initial work. Once work has progressed to ndarray support, will need access to a C compiler, as documented in the project development guide.
      Technology
      JavaScript, C, nodejs, native addons
      Other technology
      n/a
      Difficulty
      Intermediate/Advanced
      Difficulty justification
      This project is ambitious, as there are many design considerations which need to be addressed in order to ensure performance and allow for efficient JS/C interoperation.
      Additionally, there will be difficulty beyond the creation of a new StringArray class in finding all the various bits of code throughout the project which need to be updated in order to more universally support StringArray instances throughout stdlib on equal footing with other array data types.
      Prerequisite knowledge
      Familiarity and comfort with JavaScript would be highly recommended, given that this project will require considerable programming in JavaScript. Some familiarity with C would also be good, especially for string array integration with ndarrays.
      Project length
      350hrs, as will likely involve a decent amount of R&D.
      Potential mentors
      @kgryte @Planeshifter

      ~~~~~~~~~~
      ESLint 9 Migration for JSON and YAML Linting
      Linked issue: #90
      Idea
      We will migrate stdlib-js to ESLint 9 to take advantage of new features, performance improvements, and enhanced file type support (including JSON and YAML). Additionally, this idea posits that we will create new ESLint rules that enforce project-specific coding standards for stdlib. This dual approach ensures both modern linting capabilities and adherence to stdlib’s code expectations and style guidelines.
      Expected outcomes
      ESLint 9 Integration: A full migration of the linting infrastructure to ESLint 9.
      Extended File Support: Ability to lint not just JavaScript but also JSON and YAML files with the help of ESLint.
      New Custom Rules: New rules to enforce more of stdlib’s conventions.
      Enhanced Code Quality: Improved consistency and code quality by enforcing additional project-specific standards across the codebase.
      Updated Configurations: Comprehensive configuration updates that incorporate both ESLint 9 changes and the new custom rules.
      Status
      stdlib currently uses ESLint 8. The stdlib project already has an extensive collection of custom lint rules.
      Involved software
      No additional external dependencies aside from ESLint.
      Technology
      nodejs, JavaScript
      Other technology
      n/a
      Difficulty
      3
      Difficulty justification
      Migrating to ESLint 9 requires a detailed review of current linting configurations and potential refactoring of custom rules. The project will involve understanding new semantics and breaking changes introduced in ESLint 9, addressing compatibility issues, and integrating support for additional file types such as JSON and YAML and bespoke rules for these new file types. Additionally, thorough testing across various scenarios is necessary to ensure stability, making this a task that is intermediate in complexity.
      Prerequisite knowledge
      A thorough understanding of ESLint, including its configuration system and plugin architecture, is essential. Familiarity with JavaScript and Node.js is required, along with experience in developing custom linting rules. Additionally, knowledge of continuous integration and automated testing practices is recommended to ensure that any new linting rules integrate smoothly into stdlib’s development workflow.
      Project length
      175

      ~~~~~~~~~~
      Improve stdlib publishing pipeline
      Linked issue: #92
      Idea
      stdlib is composed of thousands of individual packages. Managing this complexity requires an intricate publishing pipeline that handles automatic updates to repositories, generation of various bundle types, publishing packages to the npm registry, changelog generation, and more.
      The project aims to refactor the current workflows by breaking down the monolithic, feature-rich scripts (example) into discrete, standalone tooling packages in the _tools namespace, which can be independently tested and maintained.
      In addition, while we still will lean on GitHub Actions for the publishing flow, this project will ensure that our publishing pipeline will not be tightly coupled with it anymore.
      Goals of the refactoring will also include to improve logging and observability, enable rigorous testing and checkpointing, and the ability to trigger all steps locally via a CLI tool.
      Expected outcomes
      Having the publishing pipeline fully composed into modular packages.
      Each module having its own suite of unit tests.
      Integration tests and end-to-end tests for the entire workflow.
      Enhanced observability and diagnostic tools integrated into the publishing process.
      A reduction in the complexity of the existing scripts by making GitHub Actions interactions explicit and manageable.
      Better error recovery, collection of statistics, and a more maintainable architecture.
      Status
      No effort has been undertaken to start modularizing the publishing pipeline architecture, but there is agreement among the TSC that this is a desirable goal.
      Involved software
      GitHub Actions, Bash.
      Technology
      JavaScript, nodejs
      Other technology
      None.
      Difficulty
      3
      Difficulty justification
      The project involves a large refactor of an existing, complex system.
      Decoupling the interwoven dependencies of the current monolithic script requires careful planning and modular design.
      Handling platform variability between local development and GitHub Actions orchestration, including differences between Linux and MacOS, adds complexity.
      Introducing enhanced testing and observability requires integrating new tools and extending the current functionality.
      Prerequisite knowledge
      Proficiency in JavaScript and Node.js development as well as Bash scripting.
      Familiarity with GitHub Actions and CI/CD pipeline design.
      Understanding of modular design principles and software refactoring techniques.
      Project length
      350

      ~~~~~~~~~~
      Add support for Float16Array
      Linked issue: #94
      Idea
      With Float16Array now on track for stage 4 approval in JavaScript (see tc39/proposal-float16array#7), it is time we start thinking about adding support for Float16Array in stdlib. We have prior experience adding new array types, such as array/bool, array/complex128, and array/complex64, and this idea is a continuation of those efforts.
      The expected roadmap is as follows:
      add a new array/float16 package which includes a polyfill for backward compatibility support. The polyfill should expose all common methods and properties as found on other typed array constructors. This package should contain complete tests, documentation, and benchmarks, as found in other typed array packages (e.g., array/bool).
      add support for float16 array dtypes throughout the array/* namespace.
      add support for float16 array dtypes throughout the strided/* namespace.
      add support for float16 array dtypes throughout the ndarray/* namespace.
      Expected outcomes
      stdlib users will be able to create and operate on Float16Array instances the same way they do throughout the project, with Float16Array on equal footing with all other typed array classes.
      Status
      No work has been done on this idea; however, we expect that this should follow as similar path to array/bool and its integration throughout the project.
      Related: #43
      Involved software
      No special software for initial work. Once work has progressed to ndarray support, will need access to a C compiler, as documented in the project development guide.
      Technology
      JavaScript, C, nodejs, native addons
      Other technology
      None.
      Difficulty
      4
      Difficulty justification
      Implementing the polyfill will likely take some time, with the need for adding additional functionality to support the implementation (e.g., bit manipulation utilities, math utils, etc).
      This project is ambitious, as arrays are fundamental to a lot of stdlib functionality; however, many of the more difficult integration aspects have already addressed given the widespread support for other array types throughout the project. The main project difficulty beyond the creation of a new Float16Array class will be finding all the various bits of code throughout the project which need to be updated.
      Prerequisite knowledge
      Familiarity and comfort with JavaScript would be highly recommended, given that this project will require considerable programming in JavaScript. Some familiarity with C would also be good, especially for float16 array integration with ndarrays.
      Project length
      350
      
      ~~~~~~~~~~  
      Add LAPACK bindings and implementations for linear algebra
      Linked issue: #95
      Idea
      LAPACK routines are standard building blocks for performing basic vector and matrix operations. These building blocks are leveraged by most modern numerical programming languages and libraries, including NumPy, SciPy, Julia, MATLAB, R, and others.
      The goal of this idea is to
      reimplement reference LAPACK routines in free-form Fortran 95
      port reference LAPACK routines to pure C
      port reference LAPACK routines to pure JavaScript
      write Node.js bindings to allow calling LAPACK routines in compiled C/ Fortran from JavaScript
      Expected outcomes
      Users will be able to call LAPACK routines from JavaScript. In web browsers, LAPACK routines will be in JavaScript. In Node.js, provided native bindings have been compiled, LAPACK routines will either be ported reference implementations or hardware optimized system libraries.
      Status
      Some work has begun toward this effort. See https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/lapack/base.
      Involved software
      No other software is necessary apart from standard compilers (GCC, gfortran).
      Technology
      C, JavaScript, Fortran, nodejs, native addons
      Other technology
      None.
      Difficulty
      4
      Difficulty justification
      Familiarity with C and Fortran will be beneficial. This idea mainly involves porting existing implementations and doing so in a manner which conforms with stdlib conventions. Some of the reference implementations are likely to be quite involved and testing the correct output can be tricky, especially for lower-level helper routines.
      Prerequisite knowledge
      C, Fortran, JavaScript, Node.js.
      Project length
      350

      ~~~~~~~~~~

      Extend stdlib's doctesting approach to C examples
      Linked issue: #96
      Idea
      We heavily rely on doctesting (see https://github.com/stdlib-js/stdlib/blob/develop/docs/doctest.md) to ensure that our Markdown and JSDoc examples are correct and do not become out-of-date. However, we currently have no such framework for ensuring that our C source code and Markdown examples are correct.
      The goal of this project would be to implement doctesting for C source code and associated Markdown examples. While the approach is likely to be similar (e.g., parsing source code in scripts, Markdown code blocks, and in DOXYGEN examples), the technology stack is likely to be different and will require some R&D, especially as we won't be able to rely on things like ESLint. Instead, we'll need other tooling for identifying // returns annotations, instrumenting examples to collect return values, resolving source files to compile, compiling source files, executing scripts, and asserting that the output results match expectation.
      Expected outcomes
      As part of our CI workflows and in local development, developers will be able to test that their C examples are correct.
      Status
      stdlib has its own doctesting framework for checking JavaScript examples. This should serve as inspiration and provide an idea of what we are looking for.
      Involved software
      C compilers, AST generators, and stdlib tooling.
      Technology
      C
      Other technology
      None.
      Difficulty
      5
      Difficulty justification
      There is likely a need for R&D to determine the best tools and approach. For JavaScript examples, we are able to rely on the fact that we can lint and execute within the same JavaScript runtime. In this case, there will be additional steps needed to separately instrument, create temporary files, compile, execute, and collect.
      Prerequisite knowledge
      Experience with C and creating tooling will be beneficial.
      Project length
      350

      ~~~~~~~~~~
      Add WebAssembly implementations for extended BLAS routines
      Linked issue: #97
      Idea
      We've worked toward compiling BLAS routines to WebAssembly and offering ergonomic APIs for interfacing between JavaScript and WebAssembly binaries (see https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/blas/base/wasm). The goal of this project would be to extend these efforts to the blas/ext/base namespace, such that, for each typed interface in blas/ext/base/(d|s|c|z|)*, there would be a corresponding WebAssembly package in blas/ext/base/wasm/*.
      Expected outcomes
      Users wanting to potentially accelerate computation of extended BLAS routines will be able to consume a corresponding WebAssembly API.
      Status
      Work has primarily happened in https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/blas/base/wasm. The efforts there would need to be replicated for the blas/ext/base/wasm/* namespace.
      Involved software
      Emscripten, which is necessary for compiling C to WebAssembly. stdlib already offers tooling for automatically installing the emsdk and getting things up and running.
      Technology
      C, JavaScript
      Other technology
      None.
      Difficulty
      3
      Difficulty justification
      Given that most blas/ext/base/* routines are straightforward one-dimensional strided array interfaces, developing the wasm packages should be similarly straightforward. The main time-consuming task will be writing tests and documentation.
      Prerequisite knowledge
      Some familiarity with WebAssembly will be helpful. Experience with JavaScript.
      Project length
      90/175/350. Can be scoped accordingly.
      
      ~~~~~~~~~~
      Add WebAssembly implementations for stats/strided routines
      Linked issue: #98
      Idea
      We've worked toward compiling BLAS routines to WebAssembly and offering ergonomic APIs for interfacing between JavaScript and WebAssembly binaries (see https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/blas/base/wasm). The goal of this project would be to extend these efforts to the stats/strided namespace, such that, for each typed interface in stats/strided/(d|s|c|z|)*, there would be a corresponding WebAssembly package in stats/strided/wasm/*.
      Expected outcomes
      Users wanting to potentially accelerate computation of strided statistics routines will be able to consume a corresponding WebAssembly API.
      Status
      Work has primarily happened in https://github.com/stdlib-js/stdlib/tree/develop/lib/node_modules/%40stdlib/blas/base/wasm. The efforts there would need to be replicated for the stats/strided/* namespace.
      Involved software
      Emscripten, which is necessary for compiling C to WebAssembly. stdlib already offers tooling for automatically installing the emsdk and getting things up and running.
      Technology
      C, JavaScript
      Other technology
      None.
      Difficulty
      3
      Difficulty justification
      Given that most stats/strided/* routines are straightforward one-dimensional strided array interfaces, developing the wasm packages should be similarly straightforward. The main time-consuming task will be writing tests and documentation.
      Prerequisite knowledge
      Some familiarity with WebAssembly will be helpful. Experience with JavaScript.
      Project length
      90/175/350. Can be scoped accordingly.

      ~~~~~~~~~~
      Create a prototype for transpiling a subset of TypeScript to C with automatic add-on generation
      Linked issue: #99
      Idea
      Drawing on some of the recent innovations in the numerical Python ecosystem (e.g., see pyccel), the goal of this project would be to see if we can define a restricted subset of TypeScript which can be transpiled to C for faster execution in Node.js and other server runtimes.
      There is some prior art here; namely, AssemblyScript, which provides a TypeScript-like language which compiles to WebAssembly. However, we should be able to go farther here, especially in leveraging stdlib's richer collection of types (in particular, complex number dtypes). From this restricted subset, we can then automate transpilation of TypeScript to C, with the ability to automatically generate Node.js native add-ons bindings similar to what can be found in, e.g., https://github.com/stdlib-js/stdlib/blob/954e7c1e1716bfdd15903b4be7039741396927eb/lib/node_modules/%40stdlib/blas/base/dcopy/src/addon.c.
      There would be some puzzle pieces to put together here. Namely,
      defining a richer set of numeric types. Currently, stdlib uses number, boolean, Float64Array, and other built-in types, along with a couple of custom types, such as Complex128 and Complex64. We'd like want to create named aliases for specific numeric types, such as int64, int32, etc (similar to AssemblyScript). These would not impact consumption of project type declarations in TypeScript; although, they would have the benefit of signaling expected types.
      updating the TypeScript declarations for various packages (e.g., blas/ext/base) to use the newly defined types.
      creating tooling which can resolve and read a TypeScript declaration for an exported function and then automatically generate an addon.c file. If we can reproduce the addon.c file in blas/base/dcopy, that would be a win.
      potentially porting a subset of JavaScript implementations to TypeScript using the aliases defined above.
      from the ports, creating tooling which can, with high fidelity, generate one or more JavaScript implementations.
      from the ports, creating tooling which can, with high fidelity, generate one or more C implementations.
      Note that, when transpiling from TypeScript to C, we'd need to properly determine appropriate stdlib includes and dependencies. If we could auto-generate a basic manifest.json file, that could also be useful.
      We could also explore a TypeScript to Fortran transpiler.
      Expected outcomes
      A working end-to-end prototype which is capable of transpiling stdlib-flavored TypeScript to C and which can reproduce hand-authored C and JavaScript code.
      Status
      No work has begun on this.
      Involved software
      TypeScript and C/Fortran compilers.
      Technology
      C, JavaScript, native addons, Fortran
      Other technology
      None.
      Difficulty
      4
      Difficulty justification
      This idea is exploratory, and, while conceptually straightforward, the project does involve a number of unknowns, particularly around how easy it will be to reproduce hand-optimized code. Given that the blas/base/*, blas/ext/base/*, and stats/strided/* namespaces provide a relatively contained environment for API design, it's possible that this will be achievable, but we won't know the best approach until after some R&D.
      Prerequisite knowledge
      TypeScript, C, and JavaScript experience would be beneficial.
      Project length
      350
      
      ~~~~~~~~~~
      Add matrix format parsers and data loaders
      Linked issue: #100
      Idea
      The goal of this project would be to implement various matrix and multi-dimensional format parsers and data loaders. E.g.,
      Matrix Market
      NumPy npy
      DLPack
      MATLAB mat
      others?
      Implementing these parsers and loaders would facilitate array data interchange with other numerical computing ecosystems.
      Expected outcomes
      Users will be able to load multi-dimensional array data saved in other numerical computing environments into stdlib's ndarray data structure.
      Status
      No work has begun on this.
      Involved software
      Access to MATLAB/Octave would be useful for implementing the MAT-file parser. One would likely need to use Python and NumPy in order to save and work with npy files.
      Technology
      JavaScript
      Other technology
      None.
      Difficulty
      4
      Difficulty justification
      Some of the file format specifications can be quite involved. It is also likely that we may encounter situations in which we cannot support particular formats in full due to dtype incompatibility, etc.
      Prerequisite knowledge
      Familiarity with JavaScript, Python, and MATLAB would be useful. Experience writing parsers and performing IO will also be beneficial.
      Project length
      90/175/350. Can be scoped accordingly.
      
      ~~~~~~~~~~
      Add support for working with arrays backed by memory-mapped files
      Linked issue: #101
      Idea
      Memory-mapped files allow accessing small segments of large disks stored on disk, without reading the entire file into memory. Not only can this be advantageous for memory performance, but it also facilitates shared memory between processes (e.g., operating on the same array in both Node.js and Python running in two separate processes).
      The goal of this project is to add support for working with typed arrays backed by memory-mapped files. Memory-mapped-backed typed arrays should support all the APIs of built-in typed arrays, with the exceptions that the constructors will need to support mmap-related arguments (e.g., filename, mode, offset) and indexing will require accessors, not square bracket syntax. The project is well-prepared to support accessors (see array/bool, array/complex128, etc), such that, provided a memory-mapped typed array supports the accessor protocol, passing to downstream utilities should just work.
      Similar to how we've approached fixed-endian typed arrays (see array/fixed-endian-factory), we can likely create a package exposing a constructor factory and then create lightweight wrappers for type-specific constructors (e.g., array/little-endian-float64).
      This project may require figuring out a strategy for C-JS iterop which can be used across constructors.
      Expected outcomes
      Ideally, we would have the following constructors:
      Float64ArrayMMap
      Float32ArrayMMap
      Int32ArrayMMap
      Int16ArrayMMap
      Int8ArrayMMap
      Uint32ArrayMMap
      Uint16ArrayMMap
      Uint8ArrayMMap
      Uint8ClampedArrayMMap
      BooleanArrayMMap
      Complex128ArrayMMap
      Complex64ArrayMMap
      Additionally, the following constructors would also be useful:
      DataViewMMap
      Status
      None.
      Involved software
      C compiler such as GCC or Clang.
      Technology
      C, JavaScript, nodejs, native addons
      Other technology
      None
      Difficulty
      5
      Difficulty justification
      Figuring out an effective bridge between JavaScript and C for working with memory-mapped files will likely require some R&D. It is not clear whether we'd need to first develop separate dedicated mmap(2)-like functionality in JavaScript or whether we can directly interface into C. Once the lower-level details are determined, the next steps will be implementing all the user-facing APIs expected from typed arrays. This should be straightforward; however, there may be some unexpected challenges and constraints surrounding read-only access, etc.
      Prerequisite knowledge
      C, JavaScript, and Node.js experience will be useful.
      Project length
      350
      
      ~~~~~~~~~~
      Improve project supply chain security by bringing production dependencies in-house
      Linked issue: #102
      Idea
      stdlib currently depends on 14 external packages. Ideally, we'd reduce this number to 0 in order to (a) reduce the risk of supply-chain security vulnerabilities and (b) ensure that all production code used within stdlib follows the "stdlib way" (i.e., docs, tests, examples, benchmarks, backward-compatibility guarantees, etc).
      Accordingly, this project seeks to bring external packages "in-house" by implementing stdlib equivalents which can replace their usage within stdlib. Immediate targets are dependencies such as debug, glob, resolve, and minimist which we'd like to bring in-house for their own sake.
      Bringing acorn and friends in-house would likely require more work and impose an increased maintenance burden, so we'd want to be careful in determining whether we want to prioritize a stdlib implementation. That said, having a stdlib suite of JavaScript AST manipulators would be useful. The main concern is simply keeping up with yearly ECMAScript versions. If we stayed close enough to acorn, we could potentially just mirror changes into stdlib. Regardless, some thought would be required to determine whether we want to model any stdlib implementation after acorn or some other high-quality and performant AST parser third-party package.
      For d3-* and friends, these would likely go away once we migrated our plot functionality to use vega. So their priority is lower.
      For vdom-to-html and virtual-dom, these have been useful in the past; however, it is not clear whether these deserve inclusion in stdlib. They are currently used in the stdlib plot API. Similar to the d3-* packages, they might just naturally go away after migrating plot functionality to vega.
      readable-stream is a harder package to migrate. First and foremost, one should evaluate how much we actually need readable-stream and whether we can still retain desired backward compatible behavior with built-in Node.js streams. It is possible that the answer is yes; however, historically, using readable-stream has been critical in ensuring consistent behavior across Node.js versions.
      Expected outcomes
      Third-party party production dependencies would have equivalent stdlib implementations, and we can remove them as dependencies in the project package.json.
      Status
      No work has begun on this.
      Involved software
      None.
      Technology
      JavaScript, nodejs
      Other technology
      None.
      Difficulty
      4
      Difficulty justification
      It depends on which dependencies are prioritized. Some, such as acorn, could be quite involved and require extensive testing. Others, such as resolve should be more straightforward. glob is likely to require significant R&D in order to understand and determine an ideal API.
      Prerequisite knowledge
      Experience and a high degree of comfort with JavaScript and Node.js.
      Project length
      90/175/350. Scope can be tailored accordingly.

      ~~~~~~~~~~
      Automated Code Reviews and Fixes via LLM-powered stdlib-bot
      Linked issue: #103
      Idea
      Maintaining a large-scale open-source project like stdlib requires code review and automated tooling for linting, running tests, etc. Many small but important code fixes, such as formatting corrections, documentation improvements, and minor refactorings, are often flagged by maintainers but require manual intervention from contributors. This creates overhead and slows down the resolution of trivial issues.
      This project aims to leverage LLM-powered automation to streamline these processes. The core idea is to enhance stdlib-bot with the ability to not only surface review comments but also propose and submit fixes in the form of automated pull requests.
      In addition to automated code fixes, the project will explore fine-tuning an LLM on historical PR reviews and code comments to build an automated PR review assistant. This would allow stdlib-bot to provide real-time feedback on pull requests, flagging common mistakes based on past code review patterns and enforcing best practices in a scalable way.
      A broader goal of the project is to make stdlib more LLM-friendly. This may involve adding llms.txt, refining documentation formatting, and curating structured datasets (think of maintaining Cursor rules) to improve compatibility with AI-driven tooling.
      Expected outcomes
      stdlib-bot automatically creates pull requests with suggested fixes based on commit comments; can be extended as an agent able to iteratively fix lint failures, formatting issues and test errors from CI workflow runs.
      Fine-tuning or retrieval-augmented generation (RAG) for automated PR review using past stdlib review comments (optional)
      Enhanced codebase compatibility with LLMs and AI code assistance (e.g., adding llms.txt or Cursor rules).
      Metrics to evaluate LLM-generated fixes and PR reviews.
      Integration with GitHub Actions for seamless automation.
      Status
      Currently, the stdlib-bot only reports necessary changes by creating issues, requiring human intervention. No automation of fixes or PR reviews exists yet.
      Involved software
      GitHub Actions
      LLM APIs (e.g. OpenAI)
      GitHub REST or GraphQL API to collect data from past stdlib PR reviews
      Technology
      JavaScript, nodejs
      Other technology
      Depending on skill set and ambition of candidate, this can involve fine-tuning a model via the OpenAI Fine-Tuning APIs or from
      Difficulty
      4
      Difficulty justification
      Requires integrating LLMs with structured commit comments and generating meaningful PRs.
      Need to come up with robust validation strategy to ensure correctness of auto-generated fixes.
      Fine-tuning an LLM on past stdlib code review comments involves data collection, preprocessing, and iterative testing.
      Prerequisite knowledge
      Knowledge of Node.js / JavaScript, experience with GitHub Actions and CI/CD, understanding of LLM APIs and optionally fine-tuning methodologies. Familiarity with automated code refactoring tools is a plus.
      Project length
      350
    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/stdlib/
    idea_list_url: https://github.com/stdlib-js/google-summer-of-code/blob/main/ideas.md

  - organization_id: 185
    organization_name: webpack
    no_of_ideas: 3
    ideas_content: |
      


      Tooling: Unified Webpack Dev Tools
      Difficulty: Medium
      Project Size: 175 hours
      Mentors: Alexander, Nitin
      Introduction

      Let's simplify and enhance Webpack's development tools! Currently, we have webpack-dev-server, webpack-hot-middleware, and webpack-dev-middleware, leading to duplication and suboptimal user experiences. The objective is to unify these tools into a more cohesive structure.

      What We Need:
      Extract hot and client logic from webpack-dev-server into a dedicated middleware package (let's call it webpack-hmr-middleware).
      Move relevant options and logic from webpack-hot-middleware to webpack-hmr-middleware.
      Deprecate webpack-hot-middleware.
      Transform webpack-dev-server into a monorepo with three packages: webpack-dev-middleware, webpack-hmr-middleware, and webpack-dev-server itself.


      Prerequisites
      JavaScript, NodeJS, CSS, HTML


      ~~~~~~~~~~













      Webpack: ESM Module Output
      Difficulty: Hard
      Project Size: 350 hours
      Mentors: Alexander, Nitin
      Introduction

      We want to enhance Webpack's core functionality by refining how it handles module output. This project targets a more streamlined approach, optimizing build outputs to support features like tree-shaking and ensuring smooth transitions from CommonJS to ESM. Our goal is to elevate the developer experience with clearer warnings and improved runtime consumption.


      Related Issue(s): #17121

      Prerequisites
      JavaScript, NodeJS, CSS, HTML

      Webpack: Universal Targets
      Difficulty: Hard
      Project Size: 350 hours
      Mentors: Alexander, Nitin
      Introduction


      This project aims to enhance the versatility of Webpack's targets. Currently, there are limitations, and a web bundle doesn't seamlessly fit into Node.js or a web worker environment. The proposal is to introduce a Universal Target that incorporates runtime code suitable for web, web worker, and Node.js. While this may increase code size slightly, the benefit is the ability to create Universal Module Definition (UMD) bundles that work seamlessly across all environments. Additionally, this enhancement facilitates sharing chunks between web and web worker environments.

      Related Issue(s): #6525

      Prerequisites
      JavaScript, NodeJS, CSS, HTML

      ~~~~~~~~~~







      Webpack: Destructuring
      Difficulty: Hard
      Project Size: 175 hours
      Mentors: Alexander, Nitin
      Introduction

      This project revolves around enhancing Webpack's support for destructuring in various contexts. Currently, we're looking to extend this support to plugins such as EnvironmentPlugin, DefinePlugin, ImportMetaPlugin (with partial support), and potentially other plugins. Additionally, we aim to improve the tree shaking capabilities when using destructuring with dynamic imports, namespace objects, and JSON files. Webpack should seamlessly support destructuring on the parser level, allowing developers to utilize this modern language feature across different plugins and scenarios.


      Related Issue(s): #14800 and #16872

      Prerequisites
      JavaScript, NodeJS, CSS, HTML





      Webpack: Benchmark Tooling
      Difficulty: Hard
      Project Size: 90 hours
      Mentors: Alexander, Nitin
      Introduction

      Revamp Webpack's performance tracking! We need a solid CI system to run benchmarks on every webpack PR. This ensures maintainers easily assess performance impacts, blocks significant regressions, and provides contributors clear feedback. Join us in building a reliable benchmarking system for Webpack's continuous improvement!


      Related Issue(s): #16827

      Prerequisites
      JavaScript, NodeJS, CSS, HTML



    totalCharacters_of_ideas_content_parent: 
    totalwords_of_ideas_content_parent: 
    totalTokenCount_of_ideas_content_parent: 
    gsocorganization_dev_url: https://www.gsocorganizations.dev/organization/webpack/
    idea_list_url: https://docs.google.com/document/d/1JOtAdpoqHGieg_nJpjkWDv1BoErPQ9L1GnZmX55E-W0/edit?usp=sharing


  




  


  

 